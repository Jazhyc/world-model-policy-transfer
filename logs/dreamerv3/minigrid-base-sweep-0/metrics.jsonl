{"step": 1560, "time": 176.4190149307251, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1560, "time": 177.31699681282043, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1560, "time": 181.89837336540222, "eval_episode/length": 217.0, "eval_episode/score": 0.3218750059604645, "eval_episode/reward_rate": 0.0045871559633027525}
{"step": 1560, "time": 183.76719117164612, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 183.77717661857605, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 183.78602051734924, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 183.79587817192078, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 183.80665755271912, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 306.79413080215454, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.86273193359375, "train/action_min": 0.0, "train/action_std": 1.846929907798767, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0009604598162695765, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.8772966861724854, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.5945179462432861, "train/cont_loss_std": 0.24282915890216827, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.70703125, "train/cont_pos_loss": 0.5945179462432861, "train/cont_pred": 0.5673712491989136, "train/cont_rate": 1.0, "train/dyn_loss_mean": 10.967687606811523, "train/dyn_loss_std": 0.35676392912864685, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 10.547558784484863, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 41928.46484375, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 5007.8662109375, "train/image_loss_std": 39.69886016845703, "train/model_loss_mean": 5020.5830078125, "train/model_loss_std": 39.70353317260742, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 50205832.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9413528442382812, "train/policy_entropy_max": 1.9413528442382812, "train/policy_entropy_mean": 1.6436288356781006, "train/policy_entropy_min": 0.6191356182098389, "train/policy_entropy_std": 0.14179733395576477, "train/policy_logprob_mag": 4.4044671058654785, "train/policy_logprob_max": -0.15660524368286133, "train/policy_logprob_mean": -1.653026819229126, "train/policy_logprob_min": -4.4044671058654785, "train/policy_logprob_std": 0.7212846875190735, "train/policy_randomness_mag": 0.9976580739021301, "train/policy_randomness_max": 0.9976580739021301, "train/policy_randomness_mean": 0.8446581959724426, "train/policy_randomness_min": 0.31817278265953064, "train/policy_randomness_std": 0.07286942005157471, "train/post_ent_mag": 105.6143569946289, "train/post_ent_max": 105.6143569946289, "train/post_ent_mean": 105.30128479003906, "train/post_ent_min": 104.94532775878906, "train/post_ent_std": 0.10974807292222977, "train/prior_ent_mag": 106.28421020507812, "train/prior_ent_max": 106.28421020507812, "train/prior_ent_mean": 105.59397888183594, "train/prior_ent_min": 104.71577453613281, "train/prior_ent_std": 0.25307512283325195, "train/rep_loss_mean": 10.967687606811523, "train/rep_loss_std": 0.35676392912864685, "train/reward_avg": 0.0, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 0.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.6254367828369141, "report/cont_loss_std": 0.2665340006351471, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.6552734375, "report/cont_pos_loss": 0.6254367828369141, "report/cont_pred": 0.5530587434768677, "report/cont_rate": 1.0, "report/dyn_loss_mean": 11.003592491149902, "report/dyn_loss_std": 0.3634815812110901, "report/image_loss_mean": 5009.3603515625, "report/image_loss_std": 39.99909973144531, "report/model_loss_mean": 5022.1298828125, "report/model_loss_std": 40.01957321166992, "report/post_ent_mag": 105.64035034179688, "report/post_ent_max": 105.64035034179688, "report/post_ent_mean": 105.31301879882812, "report/post_ent_min": 104.96320343017578, "report/post_ent_std": 0.1062120795249939, "report/prior_ent_mag": 106.32579040527344, "report/prior_ent_max": 106.32579040527344, "report/prior_ent_mean": 105.54536437988281, "report/prior_ent_min": 104.4759292602539, "report/prior_ent_std": 0.2883899509906769, "report/rep_loss_mean": 11.003592491149902, "report/rep_loss_std": 0.3634815812110901, "report/reward_avg": 0.0, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.6680766344070435, "eval/cont_loss_std": 0.2828327715396881, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.5888671875, "eval/cont_pos_loss": 0.6680766344070435, "eval/cont_pred": 0.5322985053062439, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 11.003230094909668, "eval/dyn_loss_std": 0.35421961545944214, "eval/image_loss_mean": 4998.0361328125, "eval/image_loss_std": 38.49937438964844, "eval/model_loss_mean": 5010.84765625, "eval/model_loss_std": 38.51320266723633, "eval/post_ent_mag": 105.58429718017578, "eval/post_ent_max": 105.58429718017578, "eval/post_ent_mean": 105.29167938232422, "eval/post_ent_min": 104.9349594116211, "eval/post_ent_std": 0.10704723000526428, "eval/prior_ent_mag": 106.36062622070312, "eval/prior_ent_max": 106.36062622070312, "eval/prior_ent_mean": 105.57843780517578, "eval/prior_ent_min": 104.7677230834961, "eval/prior_ent_std": 0.2676275372505188, "eval/rep_loss_mean": 11.003230094909668, "eval/rep_loss_std": 0.35421961545944214, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.979077211955638e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.770904268537249e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.7678935850601016e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0664973940168108e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 159.64497923851013, "timer/env.step_count": 196.0, "timer/env.step_total": 2.055284261703491, "timer/env.step_frac": 0.012874092699356925, "timer/env.step_avg": 0.010486144192364752, "timer/env.step_min": 0.00811910629272461, "timer/env.step_max": 0.019931793212890625, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.17596220970153809, "timer/replay._sample_frac": 0.0011022094809423975, "timer/replay._sample_avg": 0.0015710911580494472, "timer/replay._sample_min": 0.0005397796630859375, "timer/replay._sample_max": 0.016417503356933594, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.6918065547943115, "timer/agent.save_frac": 0.016861203951630346, "timer/agent.save_avg": 2.6918065547943115, "timer/agent.save_min": 2.6918065547943115, "timer/agent.save_max": 2.6918065547943115, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 30.17814803123474, "timer/agent.policy_frac": 0.18903286639630856, "timer/agent.policy_avg": 0.10406257941805083, "timer/agent.policy_min": 0.009379386901855469, "timer/agent.policy_max": 23.365061044692993, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 5.555152893066406e-05, "timer/dataset_train_frac": 3.4796915753717434e-07, "timer/dataset_train_avg": 5.555152893066406e-05, "timer/dataset_train_min": 5.555152893066406e-05, "timer/dataset_train_max": 5.555152893066406e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 94.04279494285583, "timer/agent.train_frac": 0.5890745539974395, "timer/agent.train_avg": 94.04279494285583, "timer/agent.train_min": 94.04279494285583, "timer/agent.train_max": 94.04279494285583, "timer/agent.report_count": 2.0, "timer/agent.report_total": 25.77072286605835, "timer/agent.report_frac": 0.1614252010240598, "timer/agent.report_avg": 12.885361433029175, "timer/agent.report_min": 0.24706411361694336, "timer/agent.report_max": 25.523658752441406, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.459785461425781e-05, "timer/dataset_eval_frac": 3.419954380944761e-07, "timer/dataset_eval_avg": 5.459785461425781e-05, "timer/dataset_eval_min": 5.459785461425781e-05, "timer/dataset_eval_max": 5.459785461425781e-05}
{"step": 1864, "time": 316.00695753097534, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 329.7661032676697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 329.77490973472595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 329.7849807739258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 329.7955889701843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 329.8025710582733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 329.81121706962585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 329.82184171676636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 3128, "time": 355.17161870002747, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 4176, "time": 387.80054092407227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4280, "time": 390.8370668888092, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 401.7816574573517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 401.7904052734375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 401.80252742767334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 401.8159282207489, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 401.82626032829285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 5440, "time": 426.980348110199, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 5936, "time": 442.279985666275, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 6160, "time": 449.1161971092224, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 6488, "time": 458.93522810935974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6592, "time": 462.361181974411, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 472.78238701820374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 472.7906885147095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 472.80390071868896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 472.82237911224365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 7752, "time": 497.9117908477783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 8472, "time": 520.6483352184296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 8704, "time": 528.0875341892242, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 8800, "time": 531.0434069633484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 8904, "time": 534.0186593532562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9112, "time": 540.44287109375, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 544.8454060554504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 544.8548159599304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 544.863529920578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 576.4626944065094, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 576.4858818054199, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 576.4935350418091, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 576.5034675598145, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 576.5113644599915, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 576.5197522640228, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 576.5279576778412, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 576.5369057655334, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10784, "time": 598.2108941078186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11016, "time": 605.1074109077454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11112, "time": 608.0382535457611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11216, "time": 611.5027062892914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11424, "time": 618.007298707962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 621.9489312171936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 621.9560990333557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 621.966114282608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13096, "time": 668.9776363372803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13328, "time": 676.4275488853455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13424, "time": 679.3787500858307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13528, "time": 682.3707737922668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13736, "time": 688.817302942276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 693.2529733181, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 693.2608525753021, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 693.2695381641388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 14056, "time": 698.7674033641815, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 15408, "time": 740.5901136398315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 15640, "time": 747.4815924167633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 15736, "time": 750.4071888923645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16048, "time": 760.1760818958282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 764.21506524086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 764.224191904068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 764.2334222793579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16368, "time": 770.096129655838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 17720, "time": 811.9981830120087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 17952, "time": 819.3583450317383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18048, "time": 822.3419613838196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18360, "time": 831.8333487510681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 836.1974949836731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 836.2049596309662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 836.21440076828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18680, "time": 841.6324806213379, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20032, "time": 883.2506973743439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 890.9272501468658, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 890.9357175827026, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 890.9451539516449, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 890.9548189640045, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 890.960526227951, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 890.967892408371, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 890.9745156764984, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 890.9830393791199, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20264, "time": 896.959520816803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20360, "time": 899.9180688858032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20672, "time": 909.7032272815704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 913.6904435157776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 913.7149424552917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 913.7239525318146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20992, "time": 919.6701774597168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 22344, "time": 961.1615607738495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 22576, "time": 968.5064702033997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 22672, "time": 971.468770980835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 22984, "time": 980.9406852722168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 985.3355071544647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 985.3425741195679, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 985.3512065410614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23304, "time": 990.7684938907623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 24656, "time": 1033.3385219573975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 24888, "time": 1040.4125039577484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 24984, "time": 1043.3690345287323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25296, "time": 1053.1768481731415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1057.127053976059, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1057.1351454257965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1057.1448485851288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25616, "time": 1063.0288770198822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 26968, "time": 1104.3519933223724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27200, "time": 1111.8029217720032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27296, "time": 1114.7900981903076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27608, "time": 1124.2572281360626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1128.6617062091827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1128.669933795929, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1128.6778738498688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27928, "time": 1134.0877938270569, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29280, "time": 1176.104463338852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29512, "time": 1183.0080642700195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29608, "time": 1186.109262228012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29920, "time": 1195.9085547924042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1199.862692117691, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1199.871129989624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1199.8797585964203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1205.6084260940552, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1205.6154136657715, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1205.6215376853943, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1205.6276185512543, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1205.6334626674652, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1205.6399688720703, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1205.6459684371948, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1205.651605606079, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30240, "time": 1211.552369594574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31272, "time": 1243.2268886566162, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 31592, "time": 1253.0999341011047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31824, "time": 1260.4601316452026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31920, "time": 1263.3836393356323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32232, "time": 1272.7201454639435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1277.1895382404327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1277.1969001293182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1277.2035434246063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32489, "time": 1281.623545408249, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0023493791491256, "train/action_min": 0.0, "train/action_std": 2.000037576250462, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00037665511718403775, "train/actor_opt_grad_steps": 970.0, "train/actor_opt_loss": 6.454114387410215, "train/adv_mag": 0.0010804989923912432, "train/adv_max": 0.001080496185596787, "train/adv_mean": 0.0006357763960122227, "train/adv_min": 7.939924313316488e-05, "train/adv_std": 0.0002955180945804932, "train/cont_avg": 0.9967414183937824, "train/cont_loss_mean": 0.025127007468654483, "train/cont_loss_std": 0.31079805786034553, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.756892626402808, "train/cont_pos_acc": 0.9982188989461395, "train/cont_pos_loss": 0.006437293037459388, "train/cont_pred": 0.9944672562915426, "train/cont_rate": 0.9967414183937824, "train/dyn_loss_mean": 1.0694397286429924, "train/dyn_loss_std": 0.004932610763688819, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.388748553209972, "train/extr_critic_critic_opt_grad_steps": 970.0, "train/extr_critic_critic_opt_loss": 9106.652270381315, "train/extr_critic_mag": 0.009464396713928855, "train/extr_critic_max": 0.009464393625605291, "train/extr_critic_mean": 0.009437718801424215, "train/extr_critic_min": 0.00941766234877196, "train/extr_critic_std": 5.173413487235467e-06, "train/extr_return_normed_mag": 0.0018863863435195, "train/extr_return_normed_max": 0.0018863822243168308, "train/extr_return_normed_mean": 0.0014551808820739824, "train/extr_return_normed_min": 0.0009089511252513698, "train/extr_return_normed_std": 0.000295286614619859, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.010504703320214108, "train/extr_return_raw_max": 0.010504697547475907, "train/extr_return_raw_mean": 0.01007349659379933, "train/extr_return_raw_min": 0.009527266455059743, "train/extr_return_raw_std": 0.00029528661411091893, "train/extr_reward_mag": 0.0001290604240536072, "train/extr_reward_max": 0.00012905857105946912, "train/extr_reward_mean": 0.00012882020298292745, "train/extr_reward_min": 0.0001281240443491565, "train/extr_reward_std": 9.529127341259934e-08, "train/image_loss_mean": 27.171469942661766, "train/image_loss_std": 0.3948667001924984, "train/model_loss_mean": 27.949780474672664, "train/model_loss_std": 0.7248813674394331, "train/model_opt_grad_norm": 103.28024943172932, "train/model_opt_grad_steps": 960.0, "train/model_opt_loss": 531.2079318940948, "train/model_opt_model_opt_grad_overflow": 0.0051813471502590676, "train/model_opt_model_opt_grad_scale": 14.420741580310882, "train/policy_entropy_mag": 1.9457877985554037, "train/policy_entropy_max": 1.9457877985554037, "train/policy_entropy_mean": 1.9412811488067547, "train/policy_entropy_min": 1.8898659073627058, "train/policy_entropy_std": 0.002858025410002667, "train/policy_logprob_mag": 2.347387856152391, "train/policy_logprob_max": -1.545799006761047, "train/policy_logprob_mean": -1.9412442785470596, "train/policy_logprob_min": -2.347387856152391, "train/policy_logprob_std": 0.08445089487986243, "train/policy_randomness_mag": 0.9999371844252156, "train/policy_randomness_max": 0.9999371844252156, "train/policy_randomness_mean": 0.9976212150692322, "train/policy_randomness_min": 0.9711990149527634, "train/policy_randomness_std": 0.0014687346044500778, "train/post_ent_mag": 76.95589407490942, "train/post_ent_max": 76.95589407490942, "train/post_ent_mean": 76.88079822125212, "train/post_ent_min": 76.76803215303569, "train/post_ent_std": 0.028800127492165626, "train/prior_ent_mag": 81.93980012409428, "train/prior_ent_max": 81.93980012409428, "train/prior_ent_mean": 81.84380866332376, "train/prior_ent_min": 81.55543233446507, "train/prior_ent_std": 0.05598001064336979, "train/rep_loss_mean": 1.0694397286429924, "train/rep_loss_std": 0.004932610763688819, "train/reward_avg": 0.0002211180380322377, "train/reward_loss_mean": 0.11152106976146216, "train/reward_loss_std": 0.11410948880810644, "train/reward_max_data": 0.1877428749527956, "train/reward_max_pred": 0.00012901162854130405, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.10746120525809931, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.923305114110311, "train/reward_pred": 0.00012879108604757898, "train/reward_rate": 0.00045539183937823833, "train_stats/mean_log_entropy": 1.9263179157091224, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.0442386269569397, "report/cont_loss_std": 0.5078979730606079, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.166163921356201, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0021014802623540163, "report/cont_pred": 0.9979009032249451, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2910193204879761, "report/image_loss_std": 0.06692230701446533, "report/model_loss_mean": 0.9547461271286011, "report/model_loss_std": 0.8329388499259949, "report/post_ent_mag": 60.4007568359375, "report/post_ent_max": 60.4007568359375, "report/post_ent_mean": 60.19197082519531, "report/post_ent_min": 60.17047119140625, "report/post_ent_std": 0.03360177204012871, "report/prior_ent_mag": 68.17861938476562, "report/prior_ent_max": 68.17861938476562, "report/prior_ent_mean": 68.12308502197266, "report/prior_ent_min": 67.76742553710938, "report/prior_ent_std": 0.06314137578010559, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.000885009765625, "report/reward_loss_mean": 0.019488133490085602, "report/reward_loss_std": 0.4256952106952667, "report/reward_max_data": 0.6312500238418579, "report/reward_max_pred": 9.1552734375e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0006575672887265682, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 9.641902923583984, "report/reward_pred": 9.143573697656393e-05, "report/reward_rate": 0.001953125, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.00210148049518466, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00210148049518466, "eval/cont_pred": 0.9979009032249451, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.29581159353256226, "eval/image_loss_std": 0.0703851506114006, "eval/model_loss_mean": 0.8985706567764282, "eval/model_loss_std": 0.07038513571023941, "eval/post_ent_mag": 60.40184783935547, "eval/post_ent_max": 60.40184783935547, "eval/post_ent_mean": 60.18973922729492, "eval/post_ent_min": 60.16847610473633, "eval/post_ent_std": 0.028790520504117012, "eval/prior_ent_mag": 68.18229675292969, "eval/prior_ent_max": 68.18229675292969, "eval/prior_ent_mean": 68.12675476074219, "eval/prior_ent_min": 67.76742553710938, "eval/prior_ent_std": 0.05370543897151947, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0006575691513717175, "eval/reward_loss_std": 7.065633411684757e-08, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 9.1552734375e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0006575691513717175, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 9.143620263785124e-05, "eval/reward_rate": 0.0, "replay/size": 31985.0, "replay/inserts": 30928.0, "replay/samples": 30928.0, "replay/insert_wait_avg": 1.360962443936383e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.226308729879238e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10304.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.246782047663318e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2814998626708984e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 974.8212072849274, "timer/env.step_count": 3866.0, "timer/env.step_total": 39.667999029159546, "timer/env.step_frac": 0.04069258930018858, "timer/env.step_avg": 0.010260734358292691, "timer/env.step_min": 0.008635282516479492, "timer/env.step_max": 0.04936671257019043, "timer/replay._sample_count": 30928.0, "timer/replay._sample_total": 17.022687196731567, "timer/replay._sample_frac": 0.017462368554889328, "timer/replay._sample_avg": 0.0005503972839088065, "timer/replay._sample_min": 0.0003571510314941406, "timer/replay._sample_max": 0.0325617790222168, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4733.0, "timer/agent.policy_total": 52.52089047431946, "timer/agent.policy_frac": 0.053877459868359526, "timer/agent.policy_avg": 0.011096744237126444, "timer/agent.policy_min": 0.008881568908691406, "timer/agent.policy_max": 0.10361695289611816, "timer/dataset_train_count": 1933.0, "timer/dataset_train_total": 0.2209606170654297, "timer/dataset_train_frac": 0.00022666783961425023, "timer/dataset_train_avg": 0.00011430968291020677, "timer/dataset_train_min": 7.724761962890625e-05, "timer/dataset_train_max": 0.0003533363342285156, "timer/agent.train_count": 1933.0, "timer/agent.train_total": 867.6465997695923, "timer/agent.train_frac": 0.8900571646221794, "timer/agent.train_avg": 0.44886011369352935, "timer/agent.train_min": 0.435122013092041, "timer/agent.train_max": 0.7108769416809082, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4752340316772461, "timer/agent.report_frac": 0.000487508917661802, "timer/agent.report_avg": 0.23761701583862305, "timer/agent.report_min": 0.2299206256866455, "timer/agent.report_max": 0.24531340599060059, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.375158815805171e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 31.72636587244116}
{"step": 33584, "time": 1315.9316534996033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 33904, "time": 1325.781025648117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34136, "time": 1332.6693062782288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34232, "time": 1335.743089914322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34544, "time": 1345.5271971225739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1349.451516866684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1349.4605858325958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1349.4700951576233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35896, "time": 1386.7268331050873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36216, "time": 1396.7167234420776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36448, "time": 1404.0335960388184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36544, "time": 1406.9485177993774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36856, "time": 1416.2570233345032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1420.6235978603363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1420.6325566768646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1420.6414432525635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38208, "time": 1458.155931711197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38528, "time": 1467.9434340000153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38760, "time": 1474.8182961940765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38856, "time": 1477.7644200325012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39168, "time": 1487.61563706398, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1491.9449472427368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1491.9533503055573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1491.9623425006866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 1520.3389036655426, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1520.3571269512177, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1520.3655562400818, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1520.3735585212708, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1520.3797955513, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1520.3884212970734, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1520.397512435913, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1520.4053072929382, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40288, "time": 1528.200125694275, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 40520, "time": 1535.0432453155518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40840, "time": 1545.0734407901764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41072, "time": 1553.096114397049, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41480, "time": 1565.3911633491516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1569.773204088211, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1569.7831842899323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1569.7926125526428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42600, "time": 1599.8916234970093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42832, "time": 1607.32790017128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43152, "time": 1617.0685548782349, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43232, "time": 1619.5110285282135, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 43384, "time": 1623.905523777008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43792, "time": 1636.6498918533325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1640.5596208572388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1640.5686914920807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44912, "time": 1671.1098067760468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45144, "time": 1677.9966588020325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45464, "time": 1687.7943060398102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45544, "time": 1690.22806930542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45696, "time": 1695.2034084796906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46104, "time": 1707.4074611663818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1711.8897438049316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1712.0001547336578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47224, "time": 1742.1312336921692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47456, "time": 1749.4412508010864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47776, "time": 1759.438621044159, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47856, "time": 1761.9050159454346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48008, "time": 1766.3529427051544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48416, "time": 1779.046516418457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1783.0748045444489, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1783.0842599868774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49536, "time": 1814.2716653347015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49680, "time": 1818.6706948280334, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 49768, "time": 1821.1428751945496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 1834.803234577179, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1834.812040090561, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1834.8218927383423, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1834.8305332660675, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1834.8395268917084, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1834.8506174087524, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1834.860936164856, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1834.870510816574, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50088, "time": 1836.8410947322845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50168, "time": 1839.2754883766174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50320, "time": 1844.3430531024933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50728, "time": 1856.7445056438446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1861.1503403186798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51848, "time": 1891.437641620636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51992, "time": 1895.8646099567413, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52080, "time": 1898.7952110767365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52400, "time": 1908.7979044914246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52480, "time": 1911.286147594452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52632, "time": 1915.774211883545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53040, "time": 1928.5379025936127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53096, "time": 1930.0560419559479, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1932.5113611221313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54160, "time": 1963.3460800647736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54392, "time": 1970.5220267772675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54712, "time": 1980.4182724952698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54792, "time": 1982.8842957019806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54944, "time": 1987.7941889762878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55352, "time": 2000.2788500785828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55408, "time": 2002.2226696014404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 2004.7140092849731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56472, "time": 2035.141048192978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56704, "time": 2042.5597088336945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57024, "time": 2052.5172407627106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57104, "time": 2055.162110567093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57256, "time": 2059.7386145591736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57664, "time": 2073.1633808612823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57720, "time": 2074.696369409561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57800, "time": 2077.1596071720123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58784, "time": 2107.7445950508118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59016, "time": 2114.8726563453674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59336, "time": 2124.707643032074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59416, "time": 2127.160512447357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59568, "time": 2132.1239240169525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59808, "time": 2139.5921063423157, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 59976, "time": 2144.61953830719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 2152.1915040016174, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2152.198415517807, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2152.207687139511, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2152.216076850891, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2152.223854780197, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2152.2329823970795, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2152.2417571544647, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2152.2489354610443, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60032, "time": 2153.2253584861755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60112, "time": 2155.730634689331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61096, "time": 2185.8805549144745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61648, "time": 2203.0163049697876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61696, "time": 2204.591293811798, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 61728, "time": 2205.5955843925476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61880, "time": 2210.105695962906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62120, "time": 2217.590279340744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62344, "time": 2224.530880689621, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62424, "time": 2227.0037245750427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63408, "time": 2257.380774974823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63960, "time": 2274.194273710251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64008, "time": 2275.6675758361816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64040, "time": 2276.647228002548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64185, "time": 2282.045795440674, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.001242589468908, "train/action_min": 0.0, "train/action_std": 1.9993193288042088, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 6.938793675581477e-05, "train/actor_opt_grad_steps": 2925.0, "train/actor_opt_loss": -3.0302735927580584, "train/adv_mag": 0.00029573140835220164, "train/adv_max": 0.00029112817249213807, "train/adv_mean": 0.0001395012729053541, "train/adv_min": -3.1915041759158626e-05, "train/adv_std": 7.128959026716195e-05, "train/cont_avg": 0.9963600852272727, "train/cont_loss_mean": 0.02415693189708911, "train/cont_loss_std": 0.33069076686432414, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.68441674417379, "train/cont_pos_acc": 0.9999999864534899, "train/cont_pos_loss": 0.0034976104513102335, "train/cont_pred": 0.9965088563133971, "train/cont_rate": 0.9963600852272727, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08650275602033644, "train/extr_critic_critic_opt_grad_steps": 2925.0, "train/extr_critic_critic_opt_loss": 7821.807779947917, "train/extr_critic_mag": 0.021855813084226666, "train/extr_critic_max": 0.021855813084226666, "train/extr_critic_mean": 0.021808580533046313, "train/extr_critic_min": 0.021762994804767646, "train/extr_critic_std": 1.2096163598161554e-05, "train/extr_return_normed_mag": 0.0005226085677441924, "train/extr_return_normed_max": 0.0005179395090148907, "train/extr_return_normed_mean": 0.0004048794943168394, "train/extr_return_normed_min": 0.0002592473074492782, "train/extr_return_normed_std": 6.864737876107157e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.022061151226587368, "train/extr_return_raw_max": 0.022061151226587368, "train/extr_return_raw_mean": 0.02194809229724636, "train/extr_return_raw_min": 0.021802459025021755, "train/extr_return_raw_std": 6.86473788058573e-05, "train/extr_reward_mag": 8.762605262525153e-05, "train/extr_reward_max": 8.762605262525153e-05, "train/extr_reward_mean": 8.753348629397806e-05, "train/extr_reward_min": 8.744422835533066e-05, "train/extr_reward_std": 3.343068573932935e-08, "train/image_loss_mean": 0.27410972253842786, "train/image_loss_std": 0.08403835641314285, "train/model_loss_mean": 0.9011819979759178, "train/model_loss_std": 0.3974282848037253, "train/model_opt_grad_norm": 79.97808250273117, "train/model_opt_grad_steps": 2915.0, "train/model_opt_loss": 50.39800164193818, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 56.0290404040404, "train/policy_entropy_mag": 1.945890921534914, "train/policy_entropy_max": 1.945890921534914, "train/policy_entropy_mean": 1.9449530045191448, "train/policy_entropy_min": 1.9300928567395066, "train/policy_entropy_std": 0.0006544594808759149, "train/policy_logprob_mag": 2.1862825841614693, "train/policy_logprob_max": -1.725461407141252, "train/policy_logprob_mean": -1.9449411287452236, "train/policy_logprob_min": -2.1862825841614693, "train/policy_logprob_std": 0.04350014616067362, "train/policy_randomness_mag": 0.9999901769739209, "train/policy_randomness_max": 0.9999901769739209, "train/policy_randomness_mean": 0.9995081828098105, "train/policy_randomness_min": 0.9918715767186097, "train/policy_randomness_std": 0.00033632569550654163, "train/post_ent_mag": 50.993989674731935, "train/post_ent_max": 50.993989674731935, "train/post_ent_mean": 50.7980579414753, "train/post_ent_min": 50.77200014904292, "train/post_ent_std": 0.02854417237180351, "train/prior_ent_mag": 59.49760423525415, "train/prior_ent_max": 59.49760423525415, "train/prior_ent_mean": 59.413473476063125, "train/prior_ent_min": 59.326917089597146, "train/prior_ent_std": 0.02306078106748185, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00014147517709955197, "train/reward_loss_mean": 0.0029153249795652097, "train/reward_loss_std": 0.07357807388051119, "train/reward_max_data": 0.12981376232522907, "train/reward_max_pred": 8.761641955134845e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00041430676973311966, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.71940008799235, "train/reward_pred": 8.75088147527416e-05, "train/reward_rate": 0.0002564709595959596, "train_stats/mean_log_entropy": 1.9379780639301647, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.008810214698314667, "report/cont_loss_std": 0.17935572564601898, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.745389938354492, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0032026097178459167, "report/cont_pred": 0.9968023896217346, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.28715234994888306, "report/image_loss_std": 0.06327743828296661, "report/model_loss_mean": 0.8962358236312866, "report/model_loss_std": 0.18782314658164978, "report/post_ent_mag": 43.491310119628906, "report/post_ent_max": 43.491310119628906, "report/post_ent_mean": 43.31304931640625, "report/post_ent_min": 43.293453216552734, "report/post_ent_std": 0.023727944120764732, "report/prior_ent_mag": 53.913272857666016, "report/prior_ent_max": 53.913272857666016, "report/prior_ent_mean": 53.80864715576172, "report/prior_ent_min": 53.775062561035156, "report/prior_ent_std": 0.01785183884203434, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0002732547000050545, "report/reward_loss_std": 1.1022311952046948e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 7.545948028564453e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0002732547000050545, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.545948028564453e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0032026097178459167, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0032026097178459167, "eval/cont_pred": 0.9968023896217346, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.289055198431015, "eval/image_loss_std": 0.06552707403898239, "eval/model_loss_mean": 0.8925310969352722, "eval/model_loss_std": 0.0655270665884018, "eval/post_ent_mag": 43.49273681640625, "eval/post_ent_max": 43.49273681640625, "eval/post_ent_mean": 43.31333923339844, "eval/post_ent_min": 43.288047790527344, "eval/post_ent_std": 0.023391243070364, "eval/prior_ent_mag": 53.8952522277832, "eval/prior_ent_max": 53.8952522277832, "eval/prior_ent_mean": 53.81045150756836, "eval/prior_ent_min": 53.77136993408203, "eval/prior_ent_std": 0.018413307145237923, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.000273250974714756, "eval/reward_loss_std": 1.0276248474383465e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 7.545948028564453e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.000273250974714756, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.545948028564453e-05, "eval/reward_rate": 0.0, "replay/size": 63681.0, "replay/inserts": 31696.0, "replay/samples": 31696.0, "replay/insert_wait_avg": 1.3574198121557569e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.269936406088862e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17240.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2130954548836854e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.087784767150879e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4012033939362, "timer/env.step_count": 3962.0, "timer/env.step_total": 40.849549293518066, "timer/env.step_frac": 0.040833166888377286, "timer/env.step_avg": 0.010310335510731466, "timer/env.step_min": 0.008547782897949219, "timer/env.step_max": 0.05313420295715332, "timer/replay._sample_count": 31696.0, "timer/replay._sample_total": 17.80284595489502, "timer/replay._sample_frac": 0.017795706257147163, "timer/replay._sample_avg": 0.0005616748471382831, "timer/replay._sample_min": 0.0003650188446044922, "timer/replay._sample_max": 0.0294344425201416, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4829.0, "timer/agent.policy_total": 54.14011478424072, "timer/agent.policy_frac": 0.05411840229756454, "timer/agent.policy_avg": 0.011211454707856849, "timer/agent.policy_min": 0.00920867919921875, "timer/agent.policy_max": 0.09590458869934082, "timer/dataset_train_count": 1981.0, "timer/dataset_train_total": 0.23514151573181152, "timer/dataset_train_frac": 0.00023504721399182277, "timer/dataset_train_avg": 0.00011869839259556361, "timer/dataset_train_min": 9.965896606445312e-05, "timer/dataset_train_max": 0.00029659271240234375, "timer/agent.train_count": 1981.0, "timer/agent.train_total": 889.9327816963196, "timer/agent.train_frac": 0.8895758808337654, "timer/agent.train_avg": 0.44923411494009063, "timer/agent.train_min": 0.43718576431274414, "timer/agent.train_max": 0.8579778671264648, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47590184211730957, "timer/agent.report_frac": 0.00047571098525549233, "timer/agent.report_avg": 0.23795092105865479, "timer/agent.report_min": 0.2305915355682373, "timer/agent.report_max": 0.24531030654907227, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.3126891873666917e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 31.682750794319396}
{"step": 64192, "time": 2282.070474624634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64432, "time": 2289.8632006645203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64656, "time": 2296.838037967682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64736, "time": 2299.2978208065033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65720, "time": 2329.924361228943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66272, "time": 2347.03218126297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66320, "time": 2348.5038459300995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66352, "time": 2349.512142896652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66504, "time": 2354.0553708076477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66744, "time": 2361.4384570121765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66968, "time": 2368.2831432819366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67048, "time": 2370.732959985733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68032, "time": 2401.22230219841, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68584, "time": 2417.9528365135193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68632, "time": 2419.4430215358734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68664, "time": 2420.424172639847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68816, "time": 2425.300329685211, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69056, "time": 2432.5936720371246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69280, "time": 2439.4513008594513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69360, "time": 2441.902754545212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 2466.4094960689545, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 70096, "time": 2470.6732335090637, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2470.680837869644, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2470.6890058517456, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2470.6966111660004, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2470.706319093704, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2470.7156200408936, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2470.7248406410217, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70344, "time": 2478.249377012253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70896, "time": 2495.3392992019653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70944, "time": 2496.801514148712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70976, "time": 2497.7776539325714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71128, "time": 2502.2565217018127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71368, "time": 2509.8224942684174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71592, "time": 2516.734743833542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71672, "time": 2519.1815905570984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72656, "time": 2549.5335948467255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73208, "time": 2566.322091817856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73256, "time": 2567.8114154338837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73288, "time": 2568.793103456497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73440, "time": 2573.7410085201263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73680, "time": 2581.1156735420227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73904, "time": 2588.5247247219086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73984, "time": 2590.9673771858215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74968, "time": 2621.0036566257477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75520, "time": 2638.2119302749634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75568, "time": 2639.6841354370117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75600, "time": 2640.6651322841644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75752, "time": 2645.092361688614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75992, "time": 2652.4869606494904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76216, "time": 2659.431025981903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76296, "time": 2661.8883380889893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77280, "time": 2692.316560268402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77832, "time": 2708.945248365402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77880, "time": 2710.4371049404144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77912, "time": 2711.4258422851562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78064, "time": 2716.4719076156616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78304, "time": 2723.7946836948395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78528, "time": 2730.707983970642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78608, "time": 2733.1723215579987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78800, "time": 2739.154319047928, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 79592, "time": 2763.627972841263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 2785.2592272758484, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2785.2666935920715, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2785.274867773056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2785.2831366062164, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2785.2928915023804, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2785.3012578487396, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2785.310823202133, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2785.3195009231567, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80144, "time": 2787.300171852112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80224, "time": 2789.744018793106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80376, "time": 2794.161478281021, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80616, "time": 2801.5233502388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80840, "time": 2808.526839733124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80920, "time": 2811.0080287456512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81112, "time": 2816.923077583313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81904, "time": 2841.906532049179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82456, "time": 2859.312668323517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82536, "time": 2861.798778295517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82688, "time": 2866.8229587078094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82728, "time": 2867.8324987888336, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 82928, "time": 2874.207858324051, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83152, "time": 2881.1379895210266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83424, "time": 2889.4924018383026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84216, "time": 2913.9049966335297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84768, "time": 2931.2350041866302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84848, "time": 2933.6860826015472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85000, "time": 2938.157288312912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85040, "time": 2939.6062371730804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85240, "time": 2945.580441236496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85464, "time": 2952.5900468826294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85736, "time": 2961.131765604019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86528, "time": 2985.8761281967163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87080, "time": 3003.279116153717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87160, "time": 3005.756527900696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87312, "time": 3010.656429052353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87352, "time": 3011.6628556251526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87552, "time": 3018.155485868454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87776, "time": 3025.0549132823944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88048, "time": 3033.471212387085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88840, "time": 3057.8798031806946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89392, "time": 3075.2420601844788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89472, "time": 3077.7006623744965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89624, "time": 3082.1730229854584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89664, "time": 3083.6396238803864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89784, "time": 3087.134109735489, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 89864, "time": 3089.6062626838684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 3100.621941804886, "eval_episode/length": 215.0, "eval_episode/score": 0.328125, "eval_episode/reward_rate": 0.004629629629629629}
{"step": 90064, "time": 3101.0961616039276, "eval_episode/length": 236.0, "eval_episode/score": 0.26249998807907104, "eval_episode/reward_rate": 0.004219409282700422}
{"step": 90064, "time": 3102.844379425049, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3102.853568315506, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3102.862292766571, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3102.870702266693, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3102.8801889419556, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3102.891065120697, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90088, "time": 3103.4101514816284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90360, "time": 3112.4944870471954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90624, "time": 3120.9266698360443, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 91152, "time": 3137.3188569545746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91704, "time": 3154.096437692642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91936, "time": 3161.4452102184296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92096, "time": 3166.530418395996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92176, "time": 3169.0114500522614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92400, "time": 3175.9272701740265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92672, "time": 3184.304342031479, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92936, "time": 3192.281457424164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93464, "time": 3208.6333858966827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94016, "time": 3226.0361750125885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94248, "time": 3233.017041683197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94408, "time": 3238.0017256736755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94488, "time": 3240.474315881729, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94712, "time": 3247.3960151672363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94984, "time": 3255.9583446979523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95248, "time": 3264.2923583984375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95776, "time": 3280.675476551056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95801, "time": 3282.245846271515, "train_stats/mean_log_entropy": 1.938100947865418, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.000217322147254, "train/action_min": 0.0, "train/action_std": 2.000062968393769, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 4.064625468482986e-05, "train/actor_opt_grad_steps": 4905.0, "train/actor_opt_loss": -5.016498316944849, "train/adv_mag": 0.00019647978773020734, "train/adv_max": 0.000154821728967657, "train/adv_mean": 3.5585218437968206e-05, "train/adv_min": -8.679710968275263e-05, "train/adv_std": 4.5074588464411486e-05, "train/cont_avg": 0.9966905381944444, "train/cont_loss_mean": 0.02227427958242708, "train/cont_loss_std": 0.30896689496789737, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.6829386186347435, "train/cont_pos_acc": 0.9999999876576241, "train/cont_pos_loss": 0.003475643981323399, "train/cont_pred": 0.996530573175411, "train/cont_rate": 0.9966905381944444, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.02439073816581507, "train/extr_critic_critic_opt_grad_steps": 4905.0, "train/extr_critic_critic_opt_loss": 8392.802073469065, "train/extr_critic_mag": 0.02459090105210892, "train/extr_critic_max": 0.02459090105210892, "train/extr_critic_mean": 0.024540109635151998, "train/extr_critic_min": 0.024490186060317838, "train/extr_critic_std": 1.3951212848669927e-05, "train/extr_return_normed_mag": 0.0002699348454674085, "train/extr_return_normed_max": 0.00020894085555666625, "train/extr_return_normed_mean": 0.00013270253981983275, "train/extr_return_normed_min": 4.5860703620645734e-05, "train/extr_return_normed_std": 4.046775707896207e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.024651936923313623, "train/extr_return_raw_max": 0.024651936923313623, "train/extr_return_raw_mean": 0.024575699544088406, "train/extr_return_raw_min": 0.0244888567713776, "train/extr_return_raw_std": 4.046775709044559e-05, "train/extr_reward_mag": 7.944034807609789e-05, "train/extr_reward_max": 7.944034807609789e-05, "train/extr_reward_mean": 7.93270067544948e-05, "train/extr_reward_min": 7.923985972548976e-05, "train/extr_reward_std": 3.1358505649072964e-08, "train/image_loss_mean": 0.2630587988580116, "train/image_loss_std": 0.08279995797107918, "train/model_loss_mean": 0.887521536061258, "train/model_loss_std": 0.36710785427177794, "train/model_opt_grad_norm": 64.18704058907248, "train/model_opt_grad_steps": 4895.0, "train/model_opt_loss": 196.5282975399133, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 221.74873737373738, "train/policy_entropy_mag": 1.945898913373851, "train/policy_entropy_max": 1.945898913373851, "train/policy_entropy_mean": 1.9453426352655045, "train/policy_entropy_min": 1.934541966577973, "train/policy_entropy_std": 0.00041722909725539273, "train/policy_logprob_mag": 2.150705108738909, "train/policy_logprob_max": -1.7605913088779257, "train/policy_logprob_mean": -1.9453631302323005, "train/policy_logprob_min": -2.150705108738909, "train/policy_logprob_std": 0.03361070343302657, "train/policy_randomness_mag": 0.9999942890923432, "train/policy_randomness_max": 0.9999942890923432, "train/policy_randomness_mean": 0.999708417389128, "train/policy_randomness_min": 0.9941579684464619, "train/policy_randomness_std": 0.00021441335051386345, "train/post_ent_mag": 40.235892825656464, "train/post_ent_max": 40.235892825656464, "train/post_ent_mean": 40.07205660656245, "train/post_ent_min": 40.03894601687036, "train/post_ent_std": 0.024771527236685006, "train/prior_ent_mag": 48.777208752102325, "train/prior_ent_max": 48.777208752102325, "train/prior_ent_mean": 48.72120585586085, "train/prior_ent_min": 48.36761004515368, "train/prior_ent_std": 0.06856723069542586, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 9.736340584684953e-05, "train/reward_loss_mean": 0.002188435482858407, "train/reward_loss_std": 0.058576079675375474, "train/reward_max_data": 0.09199810720453358, "train/reward_max_pred": 7.944155221033578e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00024284640308869343, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.859842432869804, "train/reward_pred": 7.93279102777667e-05, "train/reward_rate": 0.00019728535353535353, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025581151247024536, "report/cont_loss_std": 0.3391793966293335, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.441841125488281, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004340909421443939, "report/cont_pred": 0.9956684708595276, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2603272795677185, "report/image_loss_std": 0.07589609920978546, "report/model_loss_mean": 0.9056375026702881, "report/model_loss_std": 0.7418354153633118, "report/post_ent_mag": 38.10070037841797, "report/post_ent_max": 38.10070037841797, "report/post_ent_mean": 38.04412078857422, "report/post_ent_min": 37.97937774658203, "report/post_ent_std": 0.01723966747522354, "report/prior_ent_mag": 45.91803741455078, "report/prior_ent_max": 45.91803741455078, "report/prior_ent_mean": 45.86829376220703, "report/prior_ent_min": 45.62372589111328, "report/prior_ent_std": 0.05425168201327324, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006317138904705644, "report/reward_loss_mean": 0.01972910389304161, "report/reward_loss_std": 0.4412636160850525, "report/reward_max_data": 0.37187498807907104, "report/reward_max_pred": 7.903575897216797e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00021171476691961288, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 9.993115425109863, "report/reward_pred": 7.891911081969738e-05, "report/reward_rate": 0.001953125, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0043409098871052265, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0043409098871052265, "eval/cont_pred": 0.9956684708595276, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24422205984592438, "eval/image_loss_std": 0.0774260014295578, "eval/model_loss_mean": 0.8487746715545654, "eval/model_loss_std": 0.0774260014295578, "eval/post_ent_mag": 38.102195739746094, "eval/post_ent_max": 38.102195739746094, "eval/post_ent_mean": 38.045406341552734, "eval/post_ent_min": 37.97904586791992, "eval/post_ent_std": 0.01591164991259575, "eval/prior_ent_mag": 45.920597076416016, "eval/prior_ent_max": 45.920597076416016, "eval/prior_ent_mean": 45.87360763549805, "eval/prior_ent_min": 45.62372589111328, "eval/prior_ent_std": 0.04782858490943909, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00021171290427446365, "eval/reward_loss_std": 3.63931498270631e-08, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 7.903575897216797e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00021171290427446365, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.891864515841007e-05, "eval/reward_rate": 0.0, "replay/size": 95297.0, "replay/inserts": 31616.0, "replay/samples": 31616.0, "replay/insert_wait_avg": 1.3645647870384247e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.29836983140181e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24176.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2776155922789613e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1802167892456, "timer/env.step_count": 3952.0, "timer/env.step_total": 40.20235300064087, "timer/env.step_frac": 0.04019510916712339, "timer/env.step_avg": 0.010172660172226941, "timer/env.step_min": 0.008389472961425781, "timer/env.step_max": 0.06321215629577637, "timer/replay._sample_count": 31616.0, "timer/replay._sample_total": 17.800308227539062, "timer/replay._sample_frac": 0.017797100891158577, "timer/replay._sample_avg": 0.0005630158219742872, "timer/replay._sample_min": 0.00039577484130859375, "timer/replay._sample_max": 0.011725902557373047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4819.0, "timer/agent.policy_total": 54.182233572006226, "timer/agent.policy_frac": 0.05417247078325617, "timer/agent.policy_avg": 0.011243459965139287, "timer/agent.policy_min": 0.008388757705688477, "timer/agent.policy_max": 0.09456110000610352, "timer/dataset_train_count": 1976.0, "timer/dataset_train_total": 0.23540711402893066, "timer/dataset_train_frac": 0.00023536469735887088, "timer/dataset_train_avg": 0.00011913315487294062, "timer/dataset_train_min": 0.00010132789611816406, "timer/dataset_train_max": 0.00044608116149902344, "timer/agent.train_count": 1976.0, "timer/agent.train_total": 889.7046656608582, "timer/agent.train_frac": 0.8895443548333385, "timer/agent.train_avg": 0.45025539760164884, "timer/agent.train_min": 0.43841028213500977, "timer/agent.train_max": 1.0016705989837646, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48401975631713867, "timer/agent.report_frac": 0.000483932543547929, "timer/agent.report_avg": 0.24200987815856934, "timer/agent.report_min": 0.23172283172607422, "timer/agent.report_max": 0.25229692459106445, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.910064697265625e-05, "timer/dataset_eval_frac": 3.9093601649286966e-08, "timer/dataset_eval_avg": 3.910064697265625e-05, "timer/dataset_eval_min": 3.910064697265625e-05, "timer/dataset_eval_max": 3.910064697265625e-05, "fps": 31.609737964872807}
{"step": 96328, "time": 3298.395201921463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96560, "time": 3305.758640527725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96720, "time": 3310.6963305473328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96800, "time": 3313.1732518672943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97024, "time": 3320.083235025406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97296, "time": 3328.339198589325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97560, "time": 3336.1720974445343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98088, "time": 3352.4384541511536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98640, "time": 3370.1137340068817, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98872, "time": 3377.135271549225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99032, "time": 3382.0374829769135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99112, "time": 3384.4792783260345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99336, "time": 3391.3851313591003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99608, "time": 3399.761055469513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99872, "time": 3408.2160110473633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 3419.503424167633, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3419.516582250595, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3419.5253920555115, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3419.5347855091095, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3419.5439150333405, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3419.5528037548065, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3419.5637667179108, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3419.575541496277, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100400, "time": 3430.32950258255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100952, "time": 3447.0963089466095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101184, "time": 3454.3741981983185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101344, "time": 3459.2960357666016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101424, "time": 3461.8026175498962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101648, "time": 3468.783946275711, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101920, "time": 3477.1421988010406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101920, "time": 3477.152757883072, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 102184, "time": 3485.009845972061, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102448, "time": 3493.3149518966675, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 102712, "time": 3501.2518734931946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103264, "time": 3518.2906715869904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103656, "time": 3530.108364343643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103736, "time": 3532.5308015346527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103960, "time": 3539.3355448246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104232, "time": 3547.560398578644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104232, "time": 3547.568387746811, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104760, "time": 3563.876842737198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105024, "time": 3572.1674239635468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105576, "time": 3589.037551879883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105968, "time": 3601.332267522812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106048, "time": 3603.809291124344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106272, "time": 3610.737050294876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106544, "time": 3619.7883155345917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106544, "time": 3619.7972569465637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107072, "time": 3635.9790217876434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107336, "time": 3644.07545542717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107888, "time": 3661.268488883972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108280, "time": 3673.070813894272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108360, "time": 3675.6102492809296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108584, "time": 3682.4767644405365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108856, "time": 3690.8775045871735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108856, "time": 3690.8865778446198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109384, "time": 3707.239663362503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109648, "time": 3715.617007255554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 3733.1603722572327, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3733.1733572483063, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3733.18097615242, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3733.1885347366333, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3733.1965470314026, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3733.205193758011, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3733.214026451111, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3733.221146583557, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110200, "time": 3738.300361394882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110592, "time": 3750.563318967819, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110672, "time": 3753.0538103580475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110872, "time": 3759.036348104477, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 110896, "time": 3760.0093178749084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111168, "time": 3768.4790790081024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111168, "time": 3768.488221883774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111960, "time": 3792.666379928589, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112512, "time": 3809.949629306793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112904, "time": 3821.850950241089, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112984, "time": 3824.4893095493317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113184, "time": 3830.8689136505127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113208, "time": 3831.3941655158997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113464, "time": 3839.2595942020416, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 113480, "time": 3839.758329629898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113480, "time": 3839.777354955673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114272, "time": 3864.65705537796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115216, "time": 3894.609241962433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115296, "time": 3897.1144819259644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115496, "time": 3903.1168406009674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115520, "time": 3904.0869607925415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115776, "time": 3911.987277984619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115792, "time": 3912.515408039093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115792, "time": 3912.5234727859497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116584, "time": 3936.8011572360992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117528, "time": 3966.2196295261383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117608, "time": 3968.7120456695557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117808, "time": 3975.2520275115967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117832, "time": 3975.781724691391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118088, "time": 3983.72394490242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118104, "time": 3984.220803976059, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118104, "time": 3984.2468645572662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118896, "time": 4009.2456374168396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119840, "time": 4038.703950405121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119920, "time": 4041.1759157180786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 4050.189526796341, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4050.1963653564453, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4050.206705093384, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4050.21474981308, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4050.221602678299, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4050.2311475276947, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4050.2413201332092, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4050.2496106624603, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120120, "time": 4053.2209725379944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120144, "time": 4054.1799881458282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120400, "time": 4062.042586326599, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120416, "time": 4062.5407400131226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120416, "time": 4062.550397634506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120656, "time": 4070.1506888866425, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 121208, "time": 4087.159807443619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122152, "time": 4116.47624874115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122432, "time": 4125.484390497208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122456, "time": 4126.003417730331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122712, "time": 4133.852109670639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122728, "time": 4134.350116968155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122728, "time": 4134.437845945358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122968, "time": 4142.345215082169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123520, "time": 4159.665487766266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124464, "time": 4188.505291938782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124744, "time": 4196.794833660126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124768, "time": 4197.772439241409, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125024, "time": 4205.5775578022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125040, "time": 4206.076590299606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125040, "time": 4206.085632562637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125280, "time": 4213.493760585785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125832, "time": 4230.277168273926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126776, "time": 4259.223891019821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127056, "time": 4268.078251361847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127080, "time": 4268.593926668167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127336, "time": 4276.530498743057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127352, "time": 4277.034430980682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127352, "time": 4277.042184352875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127497, "time": 4282.437802314758, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9986384228022414, "train/action_min": 0.0, "train/action_std": 2.0003507739365705, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 5.145378459892159e-05, "train/actor_opt_grad_steps": 6885.0, "train/actor_opt_loss": -5.28282062453453, "train/adv_mag": 0.00020152573106866893, "train/adv_max": 0.00014304200356656855, "train/adv_mean": 2.1562407800727192e-05, "train/adv_min": -0.00010692621722365871, "train/adv_std": 4.730647249243243e-05, "train/cont_avg": 0.9964784564393939, "train/cont_loss_mean": 0.023468599995748712, "train/cont_loss_std": 0.3203804167210962, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.658048157916643, "train/cont_pos_acc": 0.999999984948322, "train/cont_pos_loss": 0.0035424716888240193, "train/cont_pred": 0.9964639568569684, "train/cont_rate": 0.9964784564393939, "train/dyn_loss_mean": 1.0052915992158833, "train/dyn_loss_std": 0.00017324317660596635, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.01369122392145183, "train/extr_critic_critic_opt_grad_steps": 6885.0, "train/extr_critic_critic_opt_loss": 8522.46182528409, "train/extr_critic_mag": 0.02527107253219142, "train/extr_critic_max": 0.02527107253219142, "train/extr_critic_mean": 0.02521657349184306, "train/extr_critic_min": 0.025171810930425472, "train/extr_critic_std": 1.5794244076646052e-05, "train/extr_return_normed_mag": 0.000266730540780106, "train/extr_return_normed_max": 0.0002011775387206463, "train/extr_return_normed_mean": 0.00011645949491433596, "train/extr_return_normed_min": 2.937385755957979e-05, "train/extr_return_normed_std": 4.2094671770924336e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.025322837604567258, "train/extr_return_raw_max": 0.025322837604567258, "train/extr_return_raw_mean": 0.025238121003665105, "train/extr_return_raw_min": 0.02515103392340619, "train/extr_return_raw_std": 4.209467212232002e-05, "train/extr_reward_mag": 7.919470469156901e-05, "train/extr_reward_max": 7.919470469156901e-05, "train/extr_reward_mean": 7.914101541870758e-05, "train/extr_reward_min": 7.90863326101592e-05, "train/extr_reward_std": 2.7356630775502804e-08, "train/image_loss_mean": 0.2579817787715883, "train/image_loss_std": 0.084010339351465, "train/model_loss_mean": 0.8866920362819325, "train/model_loss_std": 0.37583053063112076, "train/model_opt_grad_norm": 56.15542630474977, "train/model_opt_grad_steps": 6875.0, "train/model_opt_loss": 779.0888061523438, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 877.5252525252525, "train/policy_entropy_mag": 1.9458920010412581, "train/policy_entropy_max": 1.9458920010412581, "train/policy_entropy_mean": 1.9452977126294917, "train/policy_entropy_min": 1.9301360899751836, "train/policy_entropy_std": 0.0005349573169804338, "train/policy_logprob_mag": 2.1755043725774748, "train/policy_logprob_max": -1.7357894218329228, "train/policy_logprob_mean": -1.9452795747554663, "train/policy_logprob_min": -2.1755043725774748, "train/policy_logprob_std": 0.03402341555126689, "train/policy_randomness_mag": 0.9999907347891066, "train/policy_randomness_max": 0.9999907347891066, "train/policy_randomness_mean": 0.9996853269109822, "train/policy_randomness_min": 0.9918937975108021, "train/policy_randomness_std": 0.000274913681031915, "train/post_ent_mag": 38.9126907888085, "train/post_ent_max": 38.9126907888085, "train/post_ent_mean": 38.883805785516294, "train/post_ent_min": 38.734871392298224, "train/post_ent_std": 0.03384016629195574, "train/prior_ent_mag": 43.867604881826075, "train/prior_ent_max": 43.867604881826075, "train/prior_ent_mean": 43.820416421601266, "train/prior_ent_min": 43.58408579200205, "train/prior_ent_std": 0.05044342492321374, "train/rep_loss_mean": 1.0052915992158833, "train/rep_loss_std": 0.00017324317660596635, "train/reward_avg": 0.00010940089387903836, "train/reward_loss_mean": 0.002066670608885511, "train/reward_loss_std": 0.05690440398519533, "train/reward_max_data": 0.10471906565656566, "train/reward_max_pred": 7.916761167121656e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00019859713549264755, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.942401422773088, "train/reward_pred": 7.912389007444032e-05, "train/reward_rate": 0.00018742108585858585, "train_stats/mean_log_entropy": 1.9378093711116857, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025562211871147156, "report/cont_loss_std": 0.3433215916156769, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.507968902587891, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004062574822455645, "report/cont_pred": 0.9959457516670227, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.26546308398246765, "report/image_loss_std": 0.08023210614919662, "report/model_loss_mean": 0.8911845684051514, "report/model_loss_std": 0.34981852769851685, "report/post_ent_mag": 37.34320068359375, "report/post_ent_max": 37.34320068359375, "report/post_ent_mean": 37.33230972290039, "report/post_ent_min": 37.264530181884766, "report/post_ent_std": 0.012504375539720058, "report/prior_ent_mag": 38.49928283691406, "report/prior_ent_max": 38.49928283691406, "report/prior_ent_mean": 38.47254943847656, "report/prior_ent_min": 38.271419525146484, "report/prior_ent_std": 0.03725600615143776, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00015926361083984375, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 7.021427154541016e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00015926361083984375, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.021427154541016e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.004062574822455645, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004062574822455645, "eval/cont_pred": 0.9959457516670227, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.28079497814178467, "eval/image_loss_std": 0.07792636752128601, "eval/model_loss_mean": 0.8850167989730835, "eval/model_loss_std": 0.07792636007070541, "eval/post_ent_mag": 37.34300994873047, "eval/post_ent_max": 37.34300994873047, "eval/post_ent_mean": 37.332923889160156, "eval/post_ent_min": 37.26326370239258, "eval/post_ent_std": 0.011424168944358826, "eval/prior_ent_mag": 38.496559143066406, "eval/prior_ent_max": 38.496559143066406, "eval/prior_ent_mean": 38.47361373901367, "eval/prior_ent_min": 38.271419525146484, "eval/prior_ent_std": 0.033788762986660004, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00015926361083984375, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 7.021427154541016e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00015926361083984375, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.021427154541016e-05, "eval/reward_rate": 0.0, "replay/size": 126993.0, "replay/inserts": 31696.0, "replay/samples": 31696.0, "replay/insert_wait_avg": 1.3603082755068105e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.113703635772751e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31112.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2810186256311895e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.179801940918, "timer/env.step_count": 3962.0, "timer/env.step_total": 39.73397994041443, "timer/env.step_frac": 0.03972683697801925, "timer/env.step_avg": 0.010028768283799705, "timer/env.step_min": 0.007880687713623047, "timer/env.step_max": 0.035903215408325195, "timer/replay._sample_count": 31696.0, "timer/replay._sample_total": 18.06237006187439, "timer/replay._sample_frac": 0.01805912299650834, "timer/replay._sample_avg": 0.0005698627606598431, "timer/replay._sample_min": 0.00038242340087890625, "timer/replay._sample_max": 0.02852010726928711, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4829.0, "timer/agent.policy_total": 53.877068281173706, "timer/agent.policy_frac": 0.05386738282119029, "timer/agent.policy_avg": 0.011156982456238083, "timer/agent.policy_min": 0.009336471557617188, "timer/agent.policy_max": 0.09047508239746094, "timer/dataset_train_count": 1981.0, "timer/dataset_train_total": 0.23652958869934082, "timer/dataset_train_frac": 0.0002364870678655366, "timer/dataset_train_avg": 0.00011939908566347341, "timer/dataset_train_min": 0.00010061264038085938, "timer/dataset_train_max": 0.0005958080291748047, "timer/agent.train_count": 1981.0, "timer/agent.train_total": 891.3152310848236, "timer/agent.train_frac": 0.8911549996862212, "timer/agent.train_avg": 0.44993196925028955, "timer/agent.train_min": 0.436969518661499, "timer/agent.train_max": 0.7342379093170166, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4752383232116699, "timer/agent.report_frac": 0.0004751528897998511, "timer/agent.report_avg": 0.23761916160583496, "timer/agent.report_min": 0.23107051849365234, "timer/agent.report_max": 0.24416780471801758, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.098884342900779e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 31.689720344470636}
{"step": 127592, "time": 4285.1027619838715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128144, "time": 4302.126145839691, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129088, "time": 4331.017327308655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129368, "time": 4339.457367181778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129392, "time": 4340.446888685226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129648, "time": 4348.301842927933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129664, "time": 4348.802457809448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129664, "time": 4348.812384843826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129904, "time": 4356.225775241852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 4365.610636949539, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4365.619236707687, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4365.62982916832, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4365.641451358795, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4365.652815818787, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4365.665213108063, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4365.675247907639, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4365.686390399933, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130456, "time": 4379.4148552417755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131400, "time": 4408.875384569168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131680, "time": 4417.674869060516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131704, "time": 4418.187846660614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131928, "time": 4425.116505384445, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 131960, "time": 4426.119516372681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131976, "time": 4426.612454414368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132216, "time": 4433.979606151581, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132768, "time": 4451.145845890045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133712, "time": 4480.129825592041, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133992, "time": 4488.654532194138, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134016, "time": 4489.625330924988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134240, "time": 4496.53514623642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134272, "time": 4497.518447637558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134288, "time": 4498.014225721359, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134528, "time": 4505.420762062073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135080, "time": 4522.206416130066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136024, "time": 4551.3293561935425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136096, "time": 4553.761855840683, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 136304, "time": 4560.122506141663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136328, "time": 4560.641700267792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136584, "time": 4568.475382566452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136600, "time": 4568.992554664612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136840, "time": 4576.472838878632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137392, "time": 4593.654264450073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138336, "time": 4622.746814966202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138408, "time": 4624.744814634323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138616, "time": 4631.117625713348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138640, "time": 4632.0728714466095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138896, "time": 4639.964593410492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138912, "time": 4640.460009098053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139152, "time": 4647.779927015305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139704, "time": 4665.048973083496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 4682.342775344849, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4682.350955247879, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4682.358615875244, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4682.366269111633, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4682.374403953552, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4682.382840633392, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4682.391243696213, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4682.400806188583, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140648, "time": 4700.261128902435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140720, "time": 4702.685365438461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140928, "time": 4709.030623435974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140952, "time": 4709.542497396469, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141208, "time": 4717.358971595764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141224, "time": 4717.855127573013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141464, "time": 4725.274794101715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142016, "time": 4742.320374727249, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142960, "time": 4771.230846166611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143032, "time": 4773.226076364517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143240, "time": 4779.599571943283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143264, "time": 4780.562460184097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143520, "time": 4788.50988984108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143536, "time": 4789.003739595413, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143776, "time": 4796.331124544144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144328, "time": 4812.834837198257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145272, "time": 4841.73449587822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145344, "time": 4844.262369155884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145552, "time": 4850.638125181198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145576, "time": 4851.153692007065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145832, "time": 4858.947033405304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145848, "time": 4859.438673019409, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146088, "time": 4866.756905078888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146640, "time": 4883.897432088852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147584, "time": 4913.322527885437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147656, "time": 4915.319861650467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147864, "time": 4921.656892776489, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147888, "time": 4922.613781452179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148144, "time": 4930.435689210892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148160, "time": 4930.929929733276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148400, "time": 4938.386215209961, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148952, "time": 4954.992977619171, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149896, "time": 4983.950040102005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149968, "time": 4986.389582872391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 4995.199933052063, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4995.300009489059, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4995.308992147446, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4995.316146612167, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4995.325056314468, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4995.331780910492, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4995.339061975479, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4995.3470895290375, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150176, "time": 4998.776242733002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150200, "time": 4999.312553882599, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150456, "time": 5007.08051776886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150472, "time": 5007.570194482803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150712, "time": 5014.909126520157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151264, "time": 5032.107018947601, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152208, "time": 5061.032430648804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152280, "time": 5063.034632444382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152488, "time": 5069.368843317032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152512, "time": 5070.322082281113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152768, "time": 5078.1535387039185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152784, "time": 5078.646353960037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153024, "time": 5086.063279628754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153576, "time": 5102.759932041168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154520, "time": 5131.524147748947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154592, "time": 5133.9343729019165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154800, "time": 5140.288251399994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154824, "time": 5140.81175327301, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155080, "time": 5148.742673158646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155096, "time": 5149.257895231247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155336, "time": 5156.578660964966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155888, "time": 5174.534413099289, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156832, "time": 5203.296834468842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156904, "time": 5205.374149799347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157112, "time": 5211.746688127518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157136, "time": 5212.7054789066315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157344, "time": 5219.036406993866, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 157392, "time": 5220.511231660843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157408, "time": 5221.0012447834015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157648, "time": 5228.293917894363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157800, "time": 5232.719957828522, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 158296, "time": 5247.933751821518, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 159144, "time": 5273.869251966476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159401, "time": 5282.687000513077, "train_stats/mean_log_entropy": 1.9379944527914765, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9984391562303707, "train/action_min": 0.0, "train/action_std": 2.000364443165573, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 4.9012086748377474e-05, "train/actor_opt_grad_steps": 8870.0, "train/actor_opt_loss": -5.2523936651759415, "train/adv_mag": 0.00024005686443055694, "train/adv_max": 0.0001673093861221668, "train/adv_mean": 2.3105486221411915e-05, "train/adv_min": -0.00013446806925325537, "train/adv_std": 5.5115956776497836e-05, "train/cont_avg": 0.9964078203517588, "train/cont_loss_mean": 0.023858603415308734, "train/cont_loss_std": 0.32576420155573804, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.659031041463217, "train/cont_pos_acc": 0.999999985922521, "train/cont_pos_loss": 0.0035268036828811594, "train/cont_pred": 0.99647953791834, "train/cont_rate": 0.9964078203517588, "train/dyn_loss_mean": 1.0000000011980834, "train/dyn_loss_std": 2.6702938116408285e-08, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.014044660880656248, "train/extr_critic_critic_opt_grad_steps": 8870.0, "train/extr_critic_critic_opt_loss": 8742.501482019472, "train/extr_critic_mag": 0.026400930917442743, "train/extr_critic_max": 0.026400930917442743, "train/extr_critic_mean": 0.026333846245429025, "train/extr_critic_min": 0.026285834048860635, "train/extr_critic_std": 1.8694910661142534e-05, "train/extr_return_normed_mag": 0.0003120289488353921, "train/extr_return_normed_max": 0.00022046483266892746, "train/extr_return_normed_mean": 0.00011822408217327694, "train/extr_return_normed_min": 1.244689688910192e-05, "train/extr_return_normed_std": 4.9064526488155254e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.026459183403520128, "train/extr_return_raw_max": 0.026459183403520128, "train/extr_return_raw_mean": 0.02635694417784262, "train/extr_return_raw_min": 0.026251165467740305, "train/extr_return_raw_std": 4.90645269920336e-05, "train/extr_reward_mag": 8.279055207218956e-05, "train/extr_reward_max": 8.279055207218956e-05, "train/extr_reward_mean": 8.275450074424541e-05, "train/extr_reward_min": 8.269949774047238e-05, "train/extr_reward_std": 2.110867335587385e-08, "train/image_loss_mean": 0.25156713685198645, "train/image_loss_std": 0.08328409783130315, "train/model_loss_mean": 0.8782412990852816, "train/model_loss_std": 0.3964301642386158, "train/model_opt_grad_norm": 49.69064679936548, "train/model_opt_grad_steps": 8859.613065326634, "train/model_opt_loss": 2205.444676998273, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2512.5628140703516, "train/policy_entropy_mag": 1.9458932103823179, "train/policy_entropy_max": 1.9458932103823179, "train/policy_entropy_mean": 1.945084902509373, "train/policy_entropy_min": 1.9296423717958844, "train/policy_entropy_std": 0.000657747567504944, "train/policy_logprob_mag": 2.215160777221373, "train/policy_logprob_max": -1.7187846743281763, "train/policy_logprob_mean": -1.9451000145332298, "train/policy_logprob_min": -2.215160777221373, "train/policy_logprob_std": 0.04051429724049328, "train/policy_randomness_mag": 0.9999913534327368, "train/policy_randomness_max": 0.9999913534327368, "train/policy_randomness_mean": 0.999575967165693, "train/policy_randomness_min": 0.9916400762658623, "train/policy_randomness_std": 0.0003380154229667805, "train/post_ent_mag": 38.867495570350535, "train/post_ent_max": 38.867495570350535, "train/post_ent_mean": 38.85498930581251, "train/post_ent_min": 38.81993333059339, "train/post_ent_std": 0.007044603342620946, "train/prior_ent_mag": 38.4715500644703, "train/prior_ent_max": 38.4715500644703, "train/prior_ent_mean": 38.441282876172856, "train/prior_ent_min": 38.293023535953694, "train/prior_ent_std": 0.027692666684450515, "train/rep_loss_mean": 1.0000000011980834, "train/rep_loss_std": 2.6702938116408285e-08, "train/reward_avg": 0.00014622367199816877, "train/reward_loss_mean": 0.002815540323043289, "train/reward_loss_std": 0.07910207051969201, "train/reward_max_data": 0.13709170846783336, "train/reward_max_pred": 8.271447378187324e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00019555407881633794, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.853765954776685, "train/reward_pred": 8.266431047819817e-05, "train/reward_rate": 0.0002649968592964824, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020014513283967972, "report/cont_loss_std": 0.3139384984970093, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.811591148376465, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0029971525073051453, "report/cont_pred": 0.9970073103904724, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2180442065000534, "report/image_loss_std": 0.08675777912139893, "report/model_loss_mean": 0.8382313847541809, "report/model_loss_std": 0.3231157958507538, "report/post_ent_mag": 40.28581237792969, "report/post_ent_max": 40.28581237792969, "report/post_ent_mean": 40.26985168457031, "report/post_ent_min": 40.253780364990234, "report/post_ent_std": 0.005156316328793764, "report/prior_ent_mag": 38.438316345214844, "report/prior_ent_max": 38.438316345214844, "report/prior_ent_mean": 38.405845642089844, "report/prior_ent_min": 38.349388122558594, "report/prior_ent_std": 0.012004910036921501, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00017261505126953125, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 7.033348083496094e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00017261505126953125, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.033348083496094e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0029971522744745016, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0029971522744745016, "eval/cont_pred": 0.9970073103904724, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2575116753578186, "eval/image_loss_std": 0.08815109729766846, "eval/model_loss_mean": 0.860681414604187, "eval/model_loss_std": 0.08815110474824905, "eval/post_ent_mag": 40.28412628173828, "eval/post_ent_max": 40.28412628173828, "eval/post_ent_mean": 40.26869583129883, "eval/post_ent_min": 40.257572174072266, "eval/post_ent_std": 0.004641982726752758, "eval/prior_ent_mag": 38.433128356933594, "eval/prior_ent_max": 38.433128356933594, "eval/prior_ent_mean": 38.403560638427734, "eval/prior_ent_min": 38.338356018066406, "eval/prior_ent_std": 0.01107729785144329, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00017261505126953125, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 7.033348083496094e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00017261505126953125, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.033348083496094e-05, "eval/reward_rate": 0.0, "replay/size": 158897.0, "replay/inserts": 31904.0, "replay/samples": 31904.0, "replay/insert_wait_avg": 1.333997684830768e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.149492325012758e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38048.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2131985771064802e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2277917861938, "timer/env.step_count": 3988.0, "timer/env.step_total": 38.55379819869995, "timer/env.step_frac": 0.03854501796020992, "timer/env.step_avg": 0.009667451905391162, "timer/env.step_min": 0.007819652557373047, "timer/env.step_max": 0.0359654426574707, "timer/replay._sample_count": 31904.0, "timer/replay._sample_total": 17.89106297492981, "timer/replay._sample_frac": 0.017886988465877537, "timer/replay._sample_avg": 0.0005607780521229253, "timer/replay._sample_min": 0.0003979206085205078, "timer/replay._sample_max": 0.030449628829956055, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4855.0, "timer/agent.policy_total": 52.97170090675354, "timer/agent.policy_frac": 0.05295963713641406, "timer/agent.policy_avg": 0.010910751989032654, "timer/agent.policy_min": 0.008763551712036133, "timer/agent.policy_max": 0.10825800895690918, "timer/dataset_train_count": 1994.0, "timer/dataset_train_total": 0.23076772689819336, "timer/dataset_train_frac": 0.00023071517187708945, "timer/dataset_train_avg": 0.00011573105661895354, "timer/dataset_train_min": 9.942054748535156e-05, "timer/dataset_train_max": 0.0006644725799560547, "timer/agent.train_count": 1994.0, "timer/agent.train_total": 894.0548770427704, "timer/agent.train_frac": 0.8938512650665092, "timer/agent.train_avg": 0.4483725561899551, "timer/agent.train_min": 0.4379606246948242, "timer/agent.train_max": 1.1149792671203613, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4749488830566406, "timer/agent.report_frac": 0.00047484071824127486, "timer/agent.report_avg": 0.2374744415283203, "timer/agent.report_min": 0.23021197319030762, "timer/agent.report_max": 0.244736909866333, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.265590658962223e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 31.89619494169636}
{"step": 159448, "time": 5283.939153432846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159656, "time": 5290.344739198685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159704, "time": 5291.8110184669495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159720, "time": 5292.310341358185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159960, "time": 5299.729744911194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 5308.198938846588, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5308.269654750824, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5308.2767062187195, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5308.285430908203, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5308.293630599976, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5308.299360990524, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5308.306387662888, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5308.314030647278, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160112, "time": 5310.294802904129, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160608, "time": 5325.566247701645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161456, "time": 5351.443818092346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161760, "time": 5360.815778017044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161968, "time": 5367.139786481857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162016, "time": 5368.6010155677795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162032, "time": 5369.119970798492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162272, "time": 5376.428706169128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162424, "time": 5380.8325572013855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162920, "time": 5396.009480237961, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163104, "time": 5401.903849840164, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 163768, "time": 5422.379848003387, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164072, "time": 5432.202961683273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164328, "time": 5440.03448343277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164344, "time": 5440.529430150986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164584, "time": 5447.965990304947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164736, "time": 5452.820216178894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165232, "time": 5467.903370857239, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165416, "time": 5473.291823387146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166080, "time": 5493.858211278915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166384, "time": 5503.166414499283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166640, "time": 5511.083676338196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166656, "time": 5511.577593326569, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166896, "time": 5518.90034365654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167040, "time": 5523.292144775391, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 167048, "time": 5523.321936368942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167544, "time": 5538.545430421829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167728, "time": 5544.367454767227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168392, "time": 5564.542408466339, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168952, "time": 5581.626738548279, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168968, "time": 5582.121408700943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169208, "time": 5589.428348779678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169352, "time": 5593.952952623367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169360, "time": 5594.426668167114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169856, "time": 5609.529540061951, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 5614.932706832886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 5621.334228992462, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5621.341072797775, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5621.349129676819, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5621.355166435242, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5621.3640196323395, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5621.3705813884735, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5621.377743721008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5621.385254383087, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170704, "time": 5641.901311635971, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171264, "time": 5659.098806858063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171280, "time": 5659.5950491428375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171520, "time": 5666.917026281357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171664, "time": 5671.336404800415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171672, "time": 5671.365112066269, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172168, "time": 5687.121607303619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172352, "time": 5692.978929042816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172848, "time": 5708.217178583145, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 173016, "time": 5713.213512182236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173376, "time": 5724.545505523682, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 173576, "time": 5730.461724996567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173832, "time": 5738.225534915924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173976, "time": 5742.625099897385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174352, "time": 5754.525775432587, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 174480, "time": 5758.472655057907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174664, "time": 5763.856289386749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175160, "time": 5779.111290931702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175688, "time": 5795.196359634399, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175888, "time": 5801.500284910202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176144, "time": 5809.418943405151, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176288, "time": 5813.811784744263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176664, "time": 5825.036340713501, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176792, "time": 5828.94534611702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176976, "time": 5834.973860025406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177472, "time": 5850.2646725177765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177848, "time": 5861.470263719559, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 178000, "time": 5866.462097644806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178200, "time": 5872.377591371536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178456, "time": 5880.165071249008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178976, "time": 5896.436345815659, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179104, "time": 5900.338575839996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179288, "time": 5905.730060100555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179784, "time": 5920.858700037003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 5934.093852519989, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5934.117691278458, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5934.125866889954, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5934.135393857956, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5934.188585281372, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5934.201347827911, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5934.209921836853, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5934.218245744705, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180160, "time": 5938.597899913788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180312, "time": 5943.507671356201, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180512, "time": 5949.864095926285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180768, "time": 5957.815561056137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181288, "time": 5973.471094369888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181416, "time": 5977.375372409821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181600, "time": 5983.218153476715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182096, "time": 5998.392876148224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182472, "time": 6009.635143041611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182624, "time": 6014.616468191147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182824, "time": 6020.489645957947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183080, "time": 6028.310599803925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183600, "time": 6044.513606548309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183728, "time": 6048.424475431442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183912, "time": 6053.811309814453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184336, "time": 6066.933219432831, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 184408, "time": 6068.89799952507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184784, "time": 6080.7196345329285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184936, "time": 6085.1531772613525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185392, "time": 6099.271522521973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185912, "time": 6115.052638053894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186040, "time": 6118.968968629837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186224, "time": 6124.830540895462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186264, "time": 6125.824511289597, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 186648, "time": 6137.65274143219, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186720, "time": 6140.0819482803345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187048, "time": 6149.863228082657, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 187096, "time": 6151.337779760361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187704, "time": 6170.0751321315765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188224, "time": 6186.189066886902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188352, "time": 6190.111809015274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188576, "time": 6197.6087391376495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188960, "time": 6209.438317060471, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189032, "time": 6211.436762571335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189360, "time": 6221.72362613678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189408, "time": 6223.2287883758545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 6241.516559123993, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 6247.298760890961, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6247.31362080574, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6247.321741342545, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6247.330863714218, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6247.340381860733, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6247.348951101303, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6247.357291460037, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6247.366365671158, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190016, "time": 6247.8418045043945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190536, "time": 6263.658865451813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190664, "time": 6267.573014259338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190888, "time": 6274.4786632061005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191129, "time": 6282.834108829498, "train_stats/mean_log_entropy": 1.9312484809036912, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9940876045612375, "train/action_min": 0.0, "train/action_std": 2.002939917824485, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00013908059921996396, "train/actor_opt_grad_steps": 10855.0, "train/actor_opt_loss": -5.880265538387866, "train/adv_mag": 0.00038530677556991577, "train/adv_max": 0.00029450116886032955, "train/adv_mean": -1.0634032808063051e-05, "train/adv_min": -0.0003188510020874968, "train/adv_std": 8.066517193124081e-05, "train/cont_avg": 0.9965031171085859, "train/cont_loss_mean": 0.023304415141194683, "train/cont_loss_std": 0.31910331667245717, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.666153511248137, "train/cont_pos_acc": 0.9999999825400535, "train/cont_pos_loss": 0.0034950963583671385, "train/cont_pred": 0.9965110686090257, "train/cont_rate": 0.9965031171085859, "train/dyn_loss_mean": 1.0000000012041343, "train/dyn_loss_std": 2.693178026270794e-08, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.007488498200822358, "train/extr_critic_critic_opt_grad_steps": 10855.0, "train/extr_critic_critic_opt_loss": 8665.961258088699, "train/extr_critic_mag": 0.02614665151846529, "train/extr_critic_max": 0.02614665151846529, "train/extr_critic_mean": 0.025943137432514418, "train/extr_critic_min": 0.025742368866698912, "train/extr_critic_std": 5.280444750237299e-05, "train/extr_return_normed_mag": 0.000363183706396758, "train/extr_return_normed_max": 0.00027776728713452216, "train/extr_return_normed_mean": 7.844426179739035e-05, "train/extr_return_normed_min": -0.00011775242823241937, "train/extr_return_normed_std": 6.180109464752825e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.02613179214449242, "train/extr_return_raw_max": 0.02613179214449242, "train/extr_return_raw_mean": 0.025932470571738902, "train/extr_return_raw_min": 0.02573627242912548, "train/extr_return_raw_std": 6.180109508160527e-05, "train/extr_reward_mag": 7.619159390227963e-05, "train/extr_reward_max": 7.619159390227963e-05, "train/extr_reward_mean": 7.61174985815858e-05, "train/extr_reward_min": 7.604047505542486e-05, "train/extr_reward_std": 3.855226219743694e-08, "train/image_loss_mean": 0.23529802232679695, "train/image_loss_std": 0.08726678766084439, "train/model_loss_mean": 0.860296206642883, "train/model_loss_std": 0.3669307298506751, "train/model_opt_grad_norm": 44.163542188779275, "train/model_opt_grad_steps": 10842.90404040404, "train/model_opt_loss": 2336.639965943616, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2714.6464646464647, "train/policy_entropy_mag": 1.9458001478753908, "train/policy_entropy_max": 1.9458001478753908, "train/policy_entropy_mean": 1.938861846321761, "train/policy_entropy_min": 1.871111030530448, "train/policy_entropy_std": 0.005594804916222758, "train/policy_logprob_mag": 2.480471213658651, "train/policy_logprob_max": -1.455440874051566, "train/policy_logprob_mean": -1.9389163436311665, "train/policy_logprob_min": -2.480471213658651, "train/policy_logprob_std": 0.10397730451641661, "train/policy_randomness_mag": 0.9999435279104445, "train/policy_randomness_max": 0.9999435279104445, "train/policy_randomness_mean": 0.9963779464514568, "train/policy_randomness_min": 0.9615609161179475, "train/policy_randomness_std": 0.0028751611568779223, "train/post_ent_mag": 42.51321694345185, "train/post_ent_max": 42.51321694345185, "train/post_ent_mean": 42.35385114496405, "train/post_ent_min": 42.258579562408755, "train/post_ent_std": 0.047784136213136444, "train/prior_ent_mag": 41.13998698224925, "train/prior_ent_max": 41.13998698224925, "train/prior_ent_mean": 39.9176569851962, "train/prior_ent_min": 39.398456226695664, "train/prior_ent_std": 0.23742408911706975, "train/rep_loss_mean": 1.0000000012041343, "train/rep_loss_std": 2.693178026270794e-08, "train/reward_avg": 9.404962643983332e-05, "train/reward_loss_mean": 0.0016937474249815098, "train/reward_loss_std": 0.0453225441051633, "train/reward_max_data": 0.08876262567561082, "train/reward_max_pred": 7.628912877554845e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00018637378922324967, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.797390290669032, "train/reward_pred": 7.621240931459599e-05, "train/reward_rate": 0.000152896148989899, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025584230199456215, "report/cont_loss_std": 0.35282447934150696, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.6597394943237305, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0034895052667707205, "report/cont_pred": 0.9965164661407471, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.21852435171604156, "report/image_loss_std": 0.08358052372932434, "report/model_loss_mean": 0.8442525863647461, "report/model_loss_std": 0.3651280999183655, "report/post_ent_mag": 45.20542526245117, "report/post_ent_max": 45.20542526245117, "report/post_ent_mean": 44.66133117675781, "report/post_ent_min": 44.390655517578125, "report/post_ent_std": 0.13703103363513947, "report/prior_ent_mag": 46.900211334228516, "report/prior_ent_max": 46.900211334228516, "report/prior_ent_mean": 43.17845916748047, "report/prior_ent_min": 40.79600143432617, "report/prior_ent_std": 0.7979480028152466, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00014400482177734375, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 6.115436553955078e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00014400482177734375, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 6.115436553955078e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.009013187140226364, "eval/cont_loss_std": 0.17667149007320404, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.6597394943237305, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003489505499601364, "eval/cont_pred": 0.9965164661407471, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21715861558914185, "eval/image_loss_std": 0.10954000800848007, "eval/model_loss_mean": 0.8363635540008545, "eval/model_loss_std": 0.5158359408378601, "eval/post_ent_mag": 45.17705535888672, "eval/post_ent_max": 45.17705535888672, "eval/post_ent_mean": 44.65116500854492, "eval/post_ent_min": 44.413612365722656, "eval/post_ent_std": 0.1362430304288864, "eval/prior_ent_mag": 47.33294677734375, "eval/prior_ent_max": 47.33294677734375, "eval/prior_ent_mean": 43.33202362060547, "eval/prior_ent_min": 40.72118377685547, "eval/prior_ent_std": 0.7652148008346558, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0003143310605082661, "eval/reward_loss_mean": 0.010191773064434528, "eval/reward_loss_std": 0.32137155532836914, "eval/reward_max_data": 0.3218750059604645, "eval/reward_max_pred": 6.115436553955078e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00014400482177734375, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.289058685302734, "eval/reward_pred": 6.115436553955078e-05, "eval/reward_rate": 0.0009765625, "replay/size": 190625.0, "replay/inserts": 31728.0, "replay/samples": 31728.0, "replay/insert_wait_avg": 1.3335975684484808e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.066037799875602e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 47296.0, "eval_replay/inserts": 9248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2223334873423857e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3262033462524414e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1328921318054, "timer/env.step_count": 3966.0, "timer/env.step_total": 38.960769176483154, "timer/env.step_frac": 0.038955592284778684, "timer/env.step_avg": 0.009823693690489953, "timer/env.step_min": 0.007976293563842773, "timer/env.step_max": 0.038758277893066406, "timer/replay._sample_count": 31728.0, "timer/replay._sample_total": 17.744226455688477, "timer/replay._sample_frac": 0.017741868700934596, "timer/replay._sample_avg": 0.0005592607934848864, "timer/replay._sample_min": 0.00039577484130859375, "timer/replay._sample_max": 0.026581525802612305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5122.0, "timer/agent.policy_total": 55.707732915878296, "timer/agent.policy_frac": 0.05570033078017865, "timer/agent.policy_avg": 0.010876168081975458, "timer/agent.policy_min": 0.00912332534790039, "timer/agent.policy_max": 0.09271812438964844, "timer/dataset_train_count": 1983.0, "timer/dataset_train_total": 0.23151278495788574, "timer/dataset_train_frac": 0.00023148202281839879, "timer/dataset_train_avg": 0.00011674875691270083, "timer/dataset_train_min": 9.965896606445312e-05, "timer/dataset_train_max": 0.0005130767822265625, "timer/agent.train_count": 1983.0, "timer/agent.train_total": 887.8730475902557, "timer/agent.train_frac": 0.8877550719262264, "timer/agent.train_avg": 0.4477423336309913, "timer/agent.train_min": 0.4369523525238037, "timer/agent.train_max": 0.7061121463775635, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4737203121185303, "timer/agent.report_frac": 0.0004736573667813134, "timer/agent.report_avg": 0.23686015605926514, "timer/agent.report_min": 0.22957348823547363, "timer/agent.report_max": 0.24414682388305664, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.0275136218505663e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 31.723239703364204}
{"step": 191272, "time": 6287.192045211792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191344, "time": 6289.640282154083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191720, "time": 6300.922632932663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192320, "time": 6319.801797866821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192328, "time": 6319.833249568939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192848, "time": 6336.026940584183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192976, "time": 6339.9724934101105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193200, "time": 6346.969364643097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193584, "time": 6358.7368586063385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193656, "time": 6360.71623134613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194032, "time": 6372.4352333545685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194400, "time": 6383.811557769775, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 194640, "time": 6391.153872966766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195160, "time": 6407.050444602966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195288, "time": 6410.985163927078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195408, "time": 6414.877329826355, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 195512, "time": 6417.854326963425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195896, "time": 6429.622744560242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195968, "time": 6432.07123374939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196344, "time": 6443.516083240509, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196712, "time": 6455.270833969116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196952, "time": 6462.649843215942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197600, "time": 6482.814953804016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197720, "time": 6486.282936096191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197824, "time": 6489.660923957825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198208, "time": 6501.584128141403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198280, "time": 6503.565323829651, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198656, "time": 6515.30556511879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199024, "time": 6526.657445192337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199264, "time": 6533.986363649368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199448, "time": 6539.40963602066, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 199760, "time": 6549.213461637497, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 199912, "time": 6553.744242191315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200032, "time": 6557.707185506821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 6566.167377948761, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6566.174095869064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6566.186125993729, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6566.263149499893, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6566.270426750183, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6566.276374340057, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6566.282083272934, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6566.290025949478, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200136, "time": 6567.310672044754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200592, "time": 6582.318691730499, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200968, "time": 6593.714053153992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201576, "time": 6612.400804042816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201760, "time": 6618.436982631683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202072, "time": 6627.791752576828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202224, "time": 6632.699939489365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202344, "time": 6636.1339654922485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202448, "time": 6639.566125631332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202576, "time": 6643.52037525177, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 202904, "time": 6653.418477535248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203280, "time": 6665.157124757767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203888, "time": 6683.8912880420685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204072, "time": 6689.288018703461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204384, "time": 6699.097449541092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204536, "time": 6703.592213392258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204760, "time": 6710.576976060867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204888, "time": 6715.0428829193115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205216, "time": 6725.351011514664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205592, "time": 6736.766540765762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206200, "time": 6755.438480138779, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206384, "time": 6761.336551427841, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206696, "time": 6770.80831861496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206848, "time": 6775.701986551285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207072, "time": 6782.564856767654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207200, "time": 6786.485892534256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207528, "time": 6796.433063030243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207904, "time": 6808.189141988754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208512, "time": 6827.000774860382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208696, "time": 6832.412263870239, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209008, "time": 6842.228775024414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209160, "time": 6846.653347730637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209384, "time": 6853.52641415596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209512, "time": 6857.622029304504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209840, "time": 6867.9001557827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 6881.298064947128, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6881.305770158768, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6881.315805435181, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6881.324225902557, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6881.330899000168, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6881.339015483856, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6881.346410274506, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6881.354180812836, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210216, "time": 6885.435547113419, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210824, "time": 6904.061059474945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211008, "time": 6909.946093797684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211320, "time": 6919.4899780750275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211472, "time": 6924.4120852947235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211696, "time": 6931.2882604599, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211824, "time": 6935.233046531677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212152, "time": 6945.223698616028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212528, "time": 6956.996098279953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213136, "time": 6976.309007167816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213320, "time": 6981.731984615326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213632, "time": 6991.518004655838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213784, "time": 6995.926038503647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214008, "time": 7002.778815031052, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214136, "time": 7006.8078789711, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214464, "time": 7017.090955495834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214840, "time": 7028.427627801895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215448, "time": 7047.17668056488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215632, "time": 7053.082127332687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215944, "time": 7062.368953704834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216096, "time": 7067.402581691742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216320, "time": 7074.326920747757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216448, "time": 7078.300163507462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216776, "time": 7088.143844366074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217152, "time": 7100.114649057388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217760, "time": 7118.9526953697205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217944, "time": 7124.5657567977905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218256, "time": 7134.382002830505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218408, "time": 7138.833960056305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218632, "time": 7145.728968858719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218760, "time": 7149.699212551117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219088, "time": 7160.132152795792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219464, "time": 7171.486149072647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219792, "time": 7181.770491361618, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 7195.816504240036, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7195.835801124573, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7195.844202518463, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7195.851582527161, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7195.859695672989, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7195.867640256882, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7195.877687454224, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7195.886043787003, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220072, "time": 7195.916261434555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220256, "time": 7201.749219894409, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220568, "time": 7210.9486038684845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220720, "time": 7215.9283130168915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220944, "time": 7222.7266545295715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221400, "time": 7236.918580293655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221776, "time": 7248.700398206711, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222104, "time": 7258.4375784397125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222384, "time": 7267.160778045654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222568, "time": 7272.53733587265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222873, "time": 7283.023907899857, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.998837571647299, "train/action_min": 0.0, "train/action_std": 1.9993036128767772, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00013361131039976923, "train/actor_opt_grad_steps": 12840.0, "train/actor_opt_loss": -4.4335901781766855, "train/adv_mag": 0.0007702866522361286, "train/adv_max": 0.0006688192636523415, "train/adv_mean": 6.488729444978372e-05, "train/adv_min": -0.000569888488880953, "train/adv_std": 0.00014269048551796004, "train/cont_avg": 0.9963096733668342, "train/cont_loss_mean": 0.024396769946965217, "train/cont_loss_std": 0.33125453776020053, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.638496575621784, "train/cont_pos_acc": 0.9999999847244377, "train/cont_pos_loss": 0.0035963760333219963, "train/cont_pred": 0.996410186865821, "train/cont_rate": 0.9963096733668342, "train/dyn_loss_mean": 1.0000036739224765, "train/dyn_loss_std": 8.015661973075651e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.007998653574631405, "train/extr_critic_critic_opt_grad_steps": 12840.0, "train/extr_critic_critic_opt_loss": 8950.918645964195, "train/extr_critic_mag": 0.027922837578471582, "train/extr_critic_max": 0.027922837578471582, "train/extr_critic_mean": 0.027429334744436658, "train/extr_critic_min": 0.027007471376927054, "train/extr_critic_std": 9.285333629547801e-05, "train/extr_return_normed_mag": 0.0007726508543718999, "train/extr_return_normed_max": 0.0007386938692187544, "train/extr_return_normed_mean": 0.00031242986471908407, "train/extr_return_normed_min": -0.00010374556272173647, "train/extr_return_normed_std": 0.00011301729002535745, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.027920454272522998, "train/extr_return_raw_max": 0.027920454272522998, "train/extr_return_raw_mean": 0.027494191730291998, "train/extr_return_raw_min": 0.027078014840582507, "train/extr_return_raw_std": 0.00011301728925754284, "train/extr_reward_mag": 9.932889411197835e-05, "train/extr_reward_max": 9.932889411197835e-05, "train/extr_reward_mean": 9.28584792457893e-05, "train/extr_reward_min": 9.11855218398511e-05, "train/extr_reward_std": 1.1100000233404932e-06, "train/image_loss_mean": 0.20184306613164932, "train/image_loss_std": 0.09876093182282232, "train/model_loss_mean": 0.8285194027363955, "train/model_loss_std": 0.3932871302243453, "train/model_opt_grad_norm": 39.46758168153089, "train/model_opt_grad_steps": 12825.934673366834, "train/model_opt_loss": 2092.126402275047, "train/model_opt_model_opt_grad_overflow": 0.005025125628140704, "train/model_opt_model_opt_grad_scale": 2512.5628140703516, "train/policy_entropy_mag": 1.9457464451765893, "train/policy_entropy_max": 1.9457464451765893, "train/policy_entropy_mean": 1.934784236864828, "train/policy_entropy_min": 1.8404320562305163, "train/policy_entropy_std": 0.0087810408244443, "train/policy_logprob_mag": 2.6799361154661705, "train/policy_logprob_max": -1.2696374918348226, "train/policy_logprob_mean": -1.9348407792086577, "train/policy_logprob_min": -2.6799361154661705, "train/policy_logprob_std": 0.14829318738313177, "train/policy_randomness_mag": 0.9999159322911172, "train/policy_randomness_max": 0.9999159322911172, "train/policy_randomness_mean": 0.9942824657837949, "train/policy_randomness_min": 0.9457950370395602, "train/policy_randomness_std": 0.00451256260720442, "train/post_ent_mag": 41.19576736910259, "train/post_ent_max": 41.19576736910259, "train/post_ent_mean": 40.62542172532585, "train/post_ent_min": 40.29559945341331, "train/post_ent_std": 0.1444876609959794, "train/prior_ent_mag": 44.0835428094145, "train/prior_ent_max": 44.0835428094145, "train/prior_ent_mean": 41.115082783914694, "train/prior_ent_min": 38.01101048148457, "train/prior_ent_std": 1.0849163397472708, "train/rep_loss_mean": 1.0000036739224765, "train/rep_loss_std": 8.015661973075651e-05, "train/reward_avg": 0.00011016998956876166, "train/reward_loss_mean": 0.002277341245406836, "train/reward_loss_std": 0.06229942964956165, "train/reward_max_data": 0.10216708466335757, "train/reward_max_pred": 9.265377293879063e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0002171722864942747, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.763384109888321, "train/reward_pred": 9.159108766602662e-05, "train/reward_rate": 0.0002110160175879397, "train_stats/mean_log_entropy": 1.9238322793909934, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.01454892847687006, "report/cont_loss_std": 0.24938414990901947, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.651954174041748, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00351682654581964, "report/cont_pred": 0.9964894652366638, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.21163862943649292, "report/image_loss_std": 0.10056104511022568, "report/model_loss_mean": 0.8264232277870178, "report/model_loss_std": 0.2704741954803467, "report/post_ent_mag": 36.14481735229492, "report/post_ent_max": 36.14481735229492, "report/post_ent_mean": 35.59497833251953, "report/post_ent_min": 35.26784896850586, "report/post_ent_std": 0.13969862461090088, "report/prior_ent_mag": 40.062503814697266, "report/prior_ent_max": 40.062503814697266, "report/prior_ent_mean": 38.047752380371094, "report/prior_ent_min": 35.24652862548828, "report/prior_ent_std": 0.9303593039512634, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00023565907031297684, "report/reward_loss_std": 4.984690804121783e-06, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0001138448715209961, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00023565907031297684, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00010592048056423664, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.025581028312444687, "eval/cont_loss_std": 0.35233715176582336, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.651954174041748, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0035168263129889965, "eval/cont_pred": 0.9964894652366638, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17627045512199402, "eval/image_loss_std": 0.08803017437458038, "eval/model_loss_mean": 0.8113982677459717, "eval/model_loss_std": 0.582050621509552, "eval/post_ent_mag": 36.10418701171875, "eval/post_ent_max": 36.10418701171875, "eval/post_ent_mean": 35.59191131591797, "eval/post_ent_min": 35.29190444946289, "eval/post_ent_std": 0.13638067245483398, "eval/prior_ent_mag": 40.07770919799805, "eval/prior_ent_max": 40.07770919799805, "eval/prior_ent_mean": 38.094818115234375, "eval/prior_ent_min": 35.36153030395508, "eval/prior_ent_std": 1.0034376382827759, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007568359142169356, "eval/reward_loss_mean": 0.009546753950417042, "eval/reward_loss_std": 0.2977980673313141, "eval/reward_max_data": 0.7749999761581421, "eval/reward_max_pred": 0.0001138448715209961, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00023601621796842664, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 9.534431457519531, "eval/reward_pred": 0.0001060789218172431, "eval/reward_rate": 0.0009765625, "replay/size": 222369.0, "replay/inserts": 31744.0, "replay/samples": 31744.0, "replay/insert_wait_avg": 1.3558554553216503e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.623716675466106e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 54232.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2221014623410973e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2516975402832031e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1709914207458, "timer/env.step_count": 3968.0, "timer/env.step_total": 39.30862259864807, "timer/env.step_frac": 0.03930190231053398, "timer/env.step_avg": 0.009906406904901228, "timer/env.step_min": 0.008186817169189453, "timer/env.step_max": 0.03972053527832031, "timer/replay._sample_count": 31744.0, "timer/replay._sample_total": 17.955143690109253, "timer/replay._sample_frac": 0.01795207403946391, "timer/replay._sample_avg": 0.0005656232261249135, "timer/replay._sample_min": 0.0004107952117919922, "timer/replay._sample_max": 0.03650689125061035, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4835.0, "timer/agent.policy_total": 53.662397384643555, "timer/agent.policy_frac": 0.053653223143790604, "timer/agent.policy_avg": 0.011098737825158956, "timer/agent.policy_min": 0.009284257888793945, "timer/agent.policy_max": 0.09725451469421387, "timer/dataset_train_count": 1984.0, "timer/dataset_train_total": 0.23621106147766113, "timer/dataset_train_frac": 0.00023617067831783705, "timer/dataset_train_avg": 0.00011905799469640178, "timer/dataset_train_min": 0.00010180473327636719, "timer/dataset_train_max": 0.001070261001586914, "timer/agent.train_count": 1984.0, "timer/agent.train_total": 892.2918498516083, "timer/agent.train_frac": 0.89213930168491, "timer/agent.train_avg": 0.4497438759332703, "timer/agent.train_min": 0.4361741542816162, "timer/agent.train_max": 1.2673912048339844, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46872496604919434, "timer/agent.report_frac": 0.000468644831803579, "timer/agent.report_avg": 0.23436248302459717, "timer/agent.report_min": 0.22382044792175293, "timer/agent.report_max": 0.2449045181274414, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.00010895729064941406, "timer/dataset_eval_frac": 1.0893866307264112e-07, "timer/dataset_eval_avg": 0.00010895729064941406, "timer/dataset_eval_min": 0.00010895729064941406, "timer/dataset_eval_max": 0.00010895729064941406, "fps": 31.738028219832678}
{"step": 222880, "time": 7283.05072760582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223032, "time": 7287.850531578064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223256, "time": 7294.708404541016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223712, "time": 7309.02410030365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224088, "time": 7320.36604642868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224416, "time": 7330.617799043655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224696, "time": 7339.1984350681305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224880, "time": 7345.056069135666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225192, "time": 7354.425559997559, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225344, "time": 7359.325085639954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225568, "time": 7366.349463701248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226024, "time": 7380.206814527512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226400, "time": 7392.019287586212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226728, "time": 7401.983886241913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227008, "time": 7410.835371732712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227192, "time": 7416.245380401611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227504, "time": 7426.142560482025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227656, "time": 7430.597515583038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227880, "time": 7437.479268550873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228336, "time": 7451.664549589157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228712, "time": 7462.987464666367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229040, "time": 7473.235345125198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229320, "time": 7481.6280426979065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229504, "time": 7488.140789031982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229816, "time": 7497.517957448959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229968, "time": 7502.414439678192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 7510.669555902481, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7510.678053617477, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7510.687992572784, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7510.697471141815, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7510.709579706192, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7510.72095823288, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7510.7301461696625, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7510.739466190338, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230192, "time": 7515.330612897873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230648, "time": 7529.1024215221405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231024, "time": 7540.862474441528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231352, "time": 7550.789973497391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231632, "time": 7559.601797103882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231816, "time": 7565.0208151340485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232128, "time": 7574.94549703598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232280, "time": 7579.394164323807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232504, "time": 7586.287468671799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232960, "time": 7600.810077428818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233336, "time": 7612.248644590378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233664, "time": 7622.537145376205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233720, "time": 7624.040745258331, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 233944, "time": 7630.893938541412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234128, "time": 7636.87384057045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234440, "time": 7646.192704677582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234592, "time": 7651.0569858551025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235272, "time": 7671.851100921631, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235648, "time": 7683.597106218338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235976, "time": 7693.445993185043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236032, "time": 7695.502342939377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236256, "time": 7702.34681725502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236440, "time": 7707.767032384872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236752, "time": 7717.593784809113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236904, "time": 7722.0184235572815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237584, "time": 7743.740720272064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237960, "time": 7755.176152467728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238288, "time": 7765.443523645401, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238344, "time": 7766.941276550293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238568, "time": 7773.81506896019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238752, "time": 7779.647650241852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239064, "time": 7789.085235834122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239216, "time": 7793.96602845192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239896, "time": 7814.755313158035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 7825.701612472534, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7825.709066390991, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7825.71892952919, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7825.77929520607, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7825.788790464401, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7825.798336267471, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7825.807062625885, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7825.816935062408, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240272, "time": 7833.18591594696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240600, "time": 7843.0343697071075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240656, "time": 7845.100918769836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240880, "time": 7851.949282169342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241064, "time": 7857.360239267349, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241376, "time": 7867.167741060257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241528, "time": 7871.617456912994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242208, "time": 7892.915969848633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242584, "time": 7904.286871910095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242912, "time": 7914.496619939804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242968, "time": 7915.990070819855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243192, "time": 7922.80247092247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243376, "time": 7928.616323471069, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243688, "time": 7938.031077623367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243840, "time": 7942.857377290726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244520, "time": 7963.363847732544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244896, "time": 7975.162622213364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245224, "time": 7984.915907859802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245280, "time": 7986.854637384415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245504, "time": 7993.693168640137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245688, "time": 7999.14587521553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246000, "time": 8009.398651361465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246152, "time": 8013.828037023544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246832, "time": 8034.871698379517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247208, "time": 8046.130002975464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247536, "time": 8056.45591044426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247592, "time": 8057.933495759964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247816, "time": 8064.789599180222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248000, "time": 8070.588417768478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248312, "time": 8079.903975009918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248464, "time": 8084.922729253769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249144, "time": 8105.338056564331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249520, "time": 8117.132373571396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249848, "time": 8126.91473531723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249904, "time": 8128.84986281395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 8134.679303646088, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 250016, "time": 8137.968332767487, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8138.044335126877, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8138.05495262146, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8138.0646369457245, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8138.077412366867, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8138.091007471085, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8138.101610422134, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250128, "time": 8141.50368309021, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250312, "time": 8146.977098226547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250624, "time": 8156.6565663814545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250776, "time": 8161.059606075287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251456, "time": 8181.922222614288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251832, "time": 8193.09554886818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252160, "time": 8203.277905702591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252216, "time": 8204.871831417084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252440, "time": 8211.665579080582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252624, "time": 8217.48585987091, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252936, "time": 8226.708003759384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253088, "time": 8231.547518968582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253768, "time": 8252.012892723083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254144, "time": 8264.220085144043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254472, "time": 8273.94432759285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254528, "time": 8275.870586156845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254745, "time": 8283.188351154327, "train_stats/mean_log_entropy": 1.9114991211676382, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0282552901224875, "train/action_min": 0.0, "train/action_std": 1.9729679715094255, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0002368924982436136, "train/actor_opt_grad_steps": 14830.0, "train/actor_opt_loss": -4.317972899157199, "train/adv_mag": 0.001054572147415511, "train/adv_max": 0.0009060306334166072, "train/adv_mean": 7.925278614333475e-05, "train/adv_min": -0.0006003797934133203, "train/adv_std": 0.0002233972992697127, "train/cont_avg": 0.9966531878140703, "train/cont_loss_mean": 0.022449451070466083, "train/cont_loss_std": 0.31205259436804034, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.669398260613282, "train/cont_pos_acc": 0.9999999832268336, "train/cont_pos_loss": 0.0034976513019702093, "train/cont_pred": 0.9965085632836999, "train/cont_rate": 0.9966531878140703, "train/dyn_loss_mean": 1.4188094905872441, "train/dyn_loss_std": 0.0144981727595433, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.014196409657319666, "train/extr_critic_critic_opt_grad_steps": 14830.0, "train/extr_critic_critic_opt_loss": 9648.709430943782, "train/extr_critic_mag": 0.03173115325333485, "train/extr_critic_max": 0.03173115325333485, "train/extr_critic_mean": 0.031320448833793854, "train/extr_critic_min": 0.030933468186076563, "train/extr_critic_std": 0.00011859505390368131, "train/extr_return_normed_mag": 0.0013470365268051924, "train/extr_return_normed_max": 0.0011941871638573593, "train/extr_return_normed_mean": 0.0004640198010978355, "train/extr_return_normed_min": -5.83249139576102e-05, "train/extr_return_normed_std": 0.0002196112596428422, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.032129878777280525, "train/extr_return_raw_max": 0.032129878777280525, "train/extr_return_raw_mean": 0.03139971337987849, "train/extr_return_raw_min": 0.030877366699465555, "train/extr_return_raw_std": 0.00021961126174519175, "train/extr_reward_mag": 0.00014873245852676468, "train/extr_reward_max": 0.00014873245852676468, "train/extr_reward_mean": 0.00010108028242879913, "train/extr_reward_min": 8.119230893389064e-05, "train/extr_reward_std": 2.031235658912924e-05, "train/image_loss_mean": 0.22480941754789208, "train/image_loss_std": 0.0916124738415881, "train/model_loss_mean": 1.1002156312142186, "train/model_loss_std": 0.3689333414986505, "train/model_opt_grad_norm": 36.70104082864733, "train/model_opt_grad_steps": 14811.718592964824, "train/model_opt_loss": 1492.5551588355597, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1059.9874371859296, "train/policy_entropy_mag": 1.944183368778708, "train/policy_entropy_max": 1.944183368778708, "train/policy_entropy_mean": 1.9206979172912675, "train/policy_entropy_min": 1.832288675571806, "train/policy_entropy_std": 0.010843536900777613, "train/policy_logprob_mag": 2.694872120516983, "train/policy_logprob_max": -1.3339569550662784, "train/policy_logprob_mean": -1.9208207148403378, "train/policy_logprob_min": -2.694872120516983, "train/policy_logprob_std": 0.17200195620856693, "train/policy_randomness_mag": 0.9991126677498745, "train/policy_randomness_max": 0.9991126677498745, "train/policy_randomness_mean": 0.9870435275025105, "train/policy_randomness_min": 0.9416101670744431, "train/policy_randomness_std": 0.005572476009510682, "train/post_ent_mag": 79.13672912060915, "train/post_ent_max": 79.13672912060915, "train/post_ent_mean": 78.92535049591831, "train/post_ent_min": 78.7205938406326, "train/post_ent_std": 0.06586999946213024, "train/prior_ent_mag": 80.1930928637634, "train/prior_ent_max": 80.1930928637634, "train/prior_ent_mean": 79.10150884503695, "train/prior_ent_min": 77.69757977202909, "train/prior_ent_std": 0.5075228007594544, "train/rep_loss_mean": 1.4188094905872441, "train/rep_loss_std": 0.0144981727595433, "train/reward_avg": 7.670800302215108e-05, "train/reward_loss_mean": 0.0016710363239536632, "train/reward_loss_std": 0.04685206936766631, "train/reward_max_data": 0.0785489950946827, "train/reward_max_pred": 0.0001407148850024046, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00020698689529204264, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.624037250395745, "train/reward_pred": 8.966932927337873e-05, "train/reward_rate": 0.00015212782663316584, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025567837059497833, "report/cont_loss_std": 0.34265127778053284, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.497270584106445, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0041101789101958275, "report/cont_pred": 0.9958983659744263, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0000345706939697, "report/dyn_loss_std": 0.0008126632892526686, "report/image_loss_mean": 0.24721413850784302, "report/image_loss_std": 0.0919027179479599, "report/model_loss_mean": 0.8728904724121094, "report/model_loss_std": 0.3560006022453308, "report/post_ent_mag": 103.84051513671875, "report/post_ent_max": 103.84051513671875, "report/post_ent_mean": 103.81678771972656, "report/post_ent_min": 103.79653930664062, "report/post_ent_std": 0.008032300509512424, "report/prior_ent_mag": 104.18708801269531, "report/prior_ent_max": 104.18708801269531, "report/prior_ent_mean": 103.68885803222656, "report/prior_ent_min": 103.1977310180664, "report/prior_ent_std": 0.13162286579608917, "report/rep_loss_mean": 1.0000345706939697, "report/rep_loss_std": 0.0008126632892526686, "report/reward_avg": 0.0, "report/reward_loss_mean": 8.7738037109375e-05, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 3.5881996154785156e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 8.7738037109375e-05, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 3.5881996154785156e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0201973058283329, "eval/cont_loss_std": 0.29676753282546997, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.495001792907715, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004110714420676231, "eval/cont_pred": 0.9958978295326233, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0000224113464355, "eval/dyn_loss_std": 0.0007175277569331229, "eval/image_loss_mean": 0.2259281873703003, "eval/image_loss_std": 0.09047804772853851, "eval/model_loss_mean": 0.846226692199707, "eval/model_loss_std": 0.3114592730998993, "eval/post_ent_mag": 103.83975219726562, "eval/post_ent_max": 103.83975219726562, "eval/post_ent_mean": 103.81718444824219, "eval/post_ent_min": 103.79420471191406, "eval/post_ent_std": 0.008000875823199749, "eval/prior_ent_mag": 104.1294174194336, "eval/prior_ent_max": 104.1294174194336, "eval/prior_ent_mean": 103.71859741210938, "eval/prior_ent_min": 103.1977310180664, "eval/prior_ent_std": 0.14809837937355042, "eval/rep_loss_mean": 1.0000224113464355, "eval/rep_loss_std": 0.0007175277569331229, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 8.7738037109375e-05, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 3.5881996154785156e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 8.7738037109375e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.5881996154785156e-05, "eval/reward_rate": 0.0, "replay/size": 254241.0, "replay/inserts": 31872.0, "replay/samples": 31872.0, "replay/insert_wait_avg": 1.3504775772133027e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.187553302351251e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 61168.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.203264469643915e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2218952178955078e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.150367975235, "timer/env.step_count": 3984.0, "timer/env.step_total": 39.39108753204346, "timer/env.step_frac": 0.03938516526448834, "timer/env.step_avg": 0.00988732116768159, "timer/env.step_min": 0.007893085479736328, "timer/env.step_max": 0.036374568939208984, "timer/replay._sample_count": 31872.0, "timer/replay._sample_total": 18.012073516845703, "timer/replay._sample_frac": 0.018009365485022452, "timer/replay._sample_avg": 0.0005651378487966147, "timer/replay._sample_min": 0.0004107952117919922, "timer/replay._sample_max": 0.02537059783935547, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4851.0, "timer/agent.policy_total": 53.11196494102478, "timer/agent.policy_frac": 0.05310397980310487, "timer/agent.policy_avg": 0.010948663150077259, "timer/agent.policy_min": 0.008739948272705078, "timer/agent.policy_max": 0.09077310562133789, "timer/dataset_train_count": 1992.0, "timer/dataset_train_total": 0.23395347595214844, "timer/dataset_train_frac": 0.00023391830213068663, "timer/dataset_train_avg": 0.00011744652407236367, "timer/dataset_train_min": 0.00010180473327636719, "timer/dataset_train_max": 0.00028061866760253906, "timer/agent.train_count": 1992.0, "timer/agent.train_total": 892.2245440483093, "timer/agent.train_frac": 0.8920904022208008, "timer/agent.train_avg": 0.4479038875744525, "timer/agent.train_min": 0.4349372386932373, "timer/agent.train_max": 0.6888251304626465, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46724867820739746, "timer/agent.report_frac": 0.00046717842953287515, "timer/agent.report_avg": 0.23362433910369873, "timer/agent.report_min": 0.2222752571105957, "timer/agent.report_max": 0.24497342109680176, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.456549642601599e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 31.866683063854765}
{"step": 254752, "time": 8283.204706668854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254936, "time": 8289.034469127655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255248, "time": 8298.871567726135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255400, "time": 8303.266688585281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256080, "time": 8324.222886562347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256456, "time": 8335.431123495102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256784, "time": 8345.583198308945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256840, "time": 8347.060104131699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257064, "time": 8353.97103691101, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257248, "time": 8359.781586647034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257560, "time": 8369.031939029694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257712, "time": 8373.917644262314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258392, "time": 8394.439949035645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258768, "time": 8406.123473405838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259096, "time": 8416.132835388184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259152, "time": 8418.062915802002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259376, "time": 8424.828732728958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259560, "time": 8430.235199213028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259872, "time": 8440.046910524368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 8449.588973999023, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8449.596529483795, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8449.602696180344, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8449.60851597786, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8449.614121437073, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8449.620526313782, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8449.626429796219, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8449.632184028625, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260024, "time": 8450.148826599121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260040, "time": 8450.634996175766, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 260704, "time": 8470.955360889435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261080, "time": 8482.2654671669, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261408, "time": 8492.481395244598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261464, "time": 8493.979130983353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261688, "time": 8500.857734680176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262184, "time": 8516.445115327835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262336, "time": 8521.278494596481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262352, "time": 8521.788751602173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263016, "time": 8541.877831697464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263392, "time": 8553.696031093597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263720, "time": 8563.44704079628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263776, "time": 8565.474781513214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264000, "time": 8572.267530441284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264496, "time": 8587.283751010895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264648, "time": 8591.667307376862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264664, "time": 8592.166852474213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265328, "time": 8612.69866681099, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265704, "time": 8624.041391134262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266032, "time": 8634.204638004303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266088, "time": 8635.684768915176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266312, "time": 8642.463501930237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266808, "time": 8657.637553691864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266960, "time": 8662.472789049149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266976, "time": 8662.962634086609, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267640, "time": 8682.90374493599, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268016, "time": 8694.667027235031, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268344, "time": 8704.389548778534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268400, "time": 8706.31208395958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268624, "time": 8713.146973848343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269120, "time": 8728.333348274231, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269272, "time": 8732.733508586884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269288, "time": 8733.223915576935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269952, "time": 8753.802140951157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 8765.216706752777, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8765.223927974701, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8765.231473207474, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8765.239335298538, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8765.248918533325, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8765.34847331047, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8765.356929779053, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8765.363734960556, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270328, "time": 8772.658880233765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270656, "time": 8783.529844760895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270712, "time": 8785.03141117096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270936, "time": 8791.815218925476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271432, "time": 8807.003419399261, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271584, "time": 8811.866022109985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271600, "time": 8812.35970878601, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272152, "time": 8828.894557714462, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 272264, "time": 8832.280622005463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272640, "time": 8844.042227745056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273024, "time": 8855.684115409851, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273248, "time": 8862.514250516891, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273576, "time": 8872.427193641663, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 273744, "time": 8877.825052261353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273896, "time": 8882.232702732086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273912, "time": 8882.723980903625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274576, "time": 8903.242198944092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274952, "time": 8914.553984642029, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275336, "time": 8926.425824642181, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275560, "time": 8933.216007709503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275888, "time": 8943.394925117493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276008, "time": 8946.844970941544, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 276056, "time": 8948.308886289597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276208, "time": 8953.155906438828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276224, "time": 8953.670938491821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276888, "time": 8973.638289928436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277648, "time": 8997.01206111908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277872, "time": 9003.844824314117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278200, "time": 9013.626025915146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278320, "time": 9017.552373170853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278368, "time": 9019.024150133133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278520, "time": 9023.409951925278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278536, "time": 9024.1475212574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279200, "time": 9044.984848499298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279960, "time": 9067.876539945602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 9077.126820802689, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9077.134269475937, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9077.144097328186, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9077.154472589493, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9077.164926052094, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9077.191504240036, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9077.2454226017, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9077.259704113007, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280184, "time": 9080.659323453903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280512, "time": 9090.822446107864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280632, "time": 9094.24030470848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280680, "time": 9095.693083286285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280832, "time": 9100.50809264183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280848, "time": 9100.999587059021, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281512, "time": 9121.071893453598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282272, "time": 9144.528110027313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282496, "time": 9151.338186740875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282824, "time": 9161.140018939972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282944, "time": 9165.138907670975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282992, "time": 9166.607167243958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283144, "time": 9171.011783599854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283160, "time": 9171.52381014824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283824, "time": 9191.9745054245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284584, "time": 9215.062477111816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284808, "time": 9221.892006158829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285136, "time": 9232.325306653976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285256, "time": 9235.784135103226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285304, "time": 9237.243329524994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285456, "time": 9242.115958690643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285472, "time": 9242.611312866211, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286136, "time": 9262.671288251877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286761, "time": 9283.210406780243, "train_stats/mean_log_entropy": 1.8533188572951727, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0696475219726564, "train/action_min": 0.0, "train/action_std": 1.9245765811204911, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00039754447699124284, "train/actor_opt_grad_steps": 16825.0, "train/actor_opt_loss": -1.8528142505697907, "train/adv_mag": 0.0019177711196243763, "train/adv_max": 0.0017452301364392043, "train/adv_mean": 0.0002454949149409913, "train/adv_min": -0.001040277974680066, "train/adv_std": 0.0003829624709760537, "train/cont_avg": 0.9965869140625, "train/cont_loss_mean": 0.022823569865431638, "train/cont_loss_std": 0.3188687335955649, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.65723767498423, "train/cont_pos_acc": 0.9999999845027924, "train/cont_pos_loss": 0.003521049066912383, "train/cont_pred": 0.9964852303266525, "train/cont_rate": 0.9965869140625, "train/dyn_loss_mean": 1.0000324308872224, "train/dyn_loss_std": 0.0006252983617378049, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.011174781601876021, "train/extr_critic_critic_opt_grad_steps": 16825.0, "train/extr_critic_critic_opt_loss": 9775.892583007813, "train/extr_critic_mag": 0.032875050902366636, "train/extr_critic_max": 0.032875050902366636, "train/extr_critic_mean": 0.03223352611996234, "train/extr_critic_min": 0.03135671377182007, "train/extr_critic_std": 0.00020689089866209542, "train/extr_return_normed_mag": 0.0026872265711426735, "train/extr_return_normed_max": 0.0026004472747445107, "train/extr_return_normed_mean": 0.0010814832056348677, "train/extr_return_normed_min": -0.0001313846930861473, "train/extr_return_normed_std": 0.0004161346918226627, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.03399793870747089, "train/extr_return_raw_max": 0.03399793870747089, "train/extr_return_raw_mean": 0.0324789759144187, "train/extr_return_raw_min": 0.03126610673964023, "train/extr_return_raw_std": 0.00041613469236835956, "train/extr_reward_mag": 0.0002833801507949829, "train/extr_reward_max": 0.0002833801507949829, "train/extr_reward_mean": 0.00011944670623051934, "train/extr_reward_min": 4.64022159576416e-05, "train/extr_reward_std": 7.41746041392477e-05, "train/image_loss_mean": 0.20028326481580735, "train/image_loss_std": 0.09660042583942413, "train/model_loss_mean": 0.8251200950145722, "train/model_loss_std": 0.37530272126197817, "train/model_opt_grad_norm": 34.938961749076846, "train/model_opt_grad_steps": 16805.0, "train/model_opt_loss": 480.4900064849854, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 585.9375, "train/policy_entropy_mag": 1.9331266808509826, "train/policy_entropy_max": 1.9331266808509826, "train/policy_entropy_mean": 1.8522802954912185, "train/policy_entropy_min": 1.5564678652584554, "train/policy_entropy_std": 0.03827558902441524, "train/policy_logprob_mag": 3.544887253046036, "train/policy_logprob_max": -0.9316675130650401, "train/policy_logprob_mean": -1.8524757206439972, "train/policy_logprob_min": -3.544887253046036, "train/policy_logprob_std": 0.3232488680630922, "train/policy_randomness_mag": 0.993430655002594, "train/policy_randomness_max": 0.993430655002594, "train/policy_randomness_mean": 0.951883832514286, "train/policy_randomness_min": 0.7998663023114204, "train/policy_randomness_std": 0.01966976292373147, "train/post_ent_mag": 85.5424125289917, "train/post_ent_max": 85.5424125289917, "train/post_ent_mean": 85.08590869903564, "train/post_ent_min": 84.5834321975708, "train/post_ent_std": 0.19292877385858445, "train/prior_ent_mag": 86.62890712738037, "train/prior_ent_max": 86.62890712738037, "train/prior_ent_mean": 84.51550918579102, "train/prior_ent_min": 82.9694002532959, "train/prior_ent_std": 0.56889922529459, "train/rep_loss_mean": 1.0000324308872224, "train/rep_loss_std": 0.0006252983617378049, "train/reward_avg": 9.613037040253403e-05, "train/reward_loss_mean": 0.001993781616911292, "train/reward_loss_std": 0.05431114692486567, "train/reward_max_data": 0.09114062417298556, "train/reward_max_pred": 0.0002690809965133667, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00017805127728934167, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.693586658028995, "train/reward_pred": 7.580789213534444e-05, "train/reward_rate": 0.000185546875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02563180774450302, "report/cont_loss_std": 0.35818517208099365, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.745389938354492, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0032013875897973776, "report/cont_pred": 0.9968036413192749, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.16514964401721954, "report/image_loss_std": 0.10347877442836761, "report/model_loss_mean": 0.7983753681182861, "report/model_loss_std": 0.5397281050682068, "report/post_ent_mag": 80.7362060546875, "report/post_ent_max": 80.7362060546875, "report/post_ent_mean": 80.16807556152344, "report/post_ent_min": 79.52700805664062, "report/post_ent_std": 0.2280641496181488, "report/prior_ent_mag": 81.59407043457031, "report/prior_ent_max": 81.59407043457031, "report/prior_ent_mean": 79.40834045410156, "report/prior_ent_min": 77.7315902709961, "report/prior_ent_std": 0.6186397671699524, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004119873046875, "report/reward_loss_mean": 0.007593837101012468, "report/reward_loss_std": 0.23638178408145905, "report/reward_max_data": 0.421875, "report/reward_max_pred": 0.0009282827377319336, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00020330882398411632, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 7.568104267120361, "report/reward_pred": 8.692324627190828e-05, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020024556666612625, "eval/cont_loss_std": 0.31034940481185913, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.745389938354492, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0032017428893595934, "eval/cont_pred": 0.9968032836914062, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20376154780387878, "eval/image_loss_std": 0.11742552369832993, "eval/model_loss_mean": 0.8239623308181763, "eval/model_loss_std": 0.33179694414138794, "eval/post_ent_mag": 80.76197814941406, "eval/post_ent_max": 80.76197814941406, "eval/post_ent_mean": 80.22274780273438, "eval/post_ent_min": 79.60533142089844, "eval/post_ent_std": 0.23730315268039703, "eval/prior_ent_mag": 81.59407043457031, "eval/prior_ent_max": 81.59407043457031, "eval/prior_ent_mean": 79.37670135498047, "eval/prior_ent_min": 77.51587677001953, "eval/prior_ent_std": 0.6465710997581482, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00017615407705307007, "eval/reward_loss_std": 0.0004064113600179553, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0009452104568481445, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00017615407705307007, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.484911475330591e-05, "eval/reward_rate": 0.0, "replay/size": 286257.0, "replay/inserts": 32016.0, "replay/samples": 32016.0, "replay/insert_wait_avg": 1.3275735679714159e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.201857997202265e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 68104.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2104486511652856e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.296401023864746e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0051026344299, "timer/env.step_count": 4002.0, "timer/env.step_total": 38.83634877204895, "timer/env.step_frac": 0.03883615060536975, "timer/env.step_avg": 0.0097042350754745, "timer/env.step_min": 0.007930517196655273, "timer/env.step_max": 0.04929637908935547, "timer/replay._sample_count": 32016.0, "timer/replay._sample_total": 17.90295720100403, "timer/replay._sample_frac": 0.01790286584922435, "timer/replay._sample_avg": 0.0005591878186220648, "timer/replay._sample_min": 0.00039505958557128906, "timer/replay._sample_max": 0.012650489807128906, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4869.0, "timer/agent.policy_total": 53.697720527648926, "timer/agent.policy_frac": 0.053697446529209464, "timer/agent.policy_avg": 0.011028490558153404, "timer/agent.policy_min": 0.007986068725585938, "timer/agent.policy_max": 1.0040485858917236, "timer/dataset_train_count": 2001.0, "timer/dataset_train_total": 0.23180103302001953, "timer/dataset_train_frac": 0.0002317998502301229, "timer/dataset_train_avg": 0.00011584259521240357, "timer/dataset_train_min": 9.894371032714844e-05, "timer/dataset_train_max": 0.001074075698852539, "timer/agent.train_count": 2001.0, "timer/agent.train_total": 892.3981885910034, "timer/agent.train_frac": 0.8923936350325162, "timer/agent.train_avg": 0.44597610624238054, "timer/agent.train_min": 0.43621277809143066, "timer/agent.train_max": 0.871016263961792, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46984338760375977, "timer/agent.report_frac": 0.0004698409901769467, "timer/agent.report_avg": 0.23492169380187988, "timer/agent.report_min": 0.2239072322845459, "timer/agent.report_max": 0.24593615531921387, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.2663178668654e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 32.0153027138905}
{"step": 286896, "time": 9287.556603193283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287120, "time": 9294.387258529663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287448, "time": 9304.24988079071, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287568, "time": 9308.163469314575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287616, "time": 9309.639430761337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287768, "time": 9314.217718839645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287784, "time": 9314.711595058441, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288448, "time": 9335.281672239304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289208, "time": 9358.459775924683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289432, "time": 9365.35106754303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289760, "time": 9375.713448286057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289880, "time": 9379.180424690247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289928, "time": 9380.651824951172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 9390.637107610703, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9390.644316673279, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9390.651056528091, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9390.749311685562, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9390.758125066757, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9390.777043104172, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9390.784379005432, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9390.79025387764, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290080, "time": 9391.834631681442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290096, "time": 9392.329298496246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290760, "time": 9412.492843151093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291520, "time": 9436.142225980759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291744, "time": 9443.016514778137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292072, "time": 9452.883420467377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292192, "time": 9456.79299736023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292240, "time": 9458.275309562683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292392, "time": 9462.725212335587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292408, "time": 9463.221141815186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293072, "time": 9483.92668747902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293128, "time": 9485.420719861984, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 293832, "time": 9507.087876081467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294000, "time": 9512.49309873581, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 294056, "time": 9514.007358312607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294304, "time": 9521.841603755951, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 294384, "time": 9524.423438549042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294504, "time": 9527.860664606094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294552, "time": 9529.353078126907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294720, "time": 9534.756690740585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295384, "time": 9555.557488679886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295440, "time": 9557.50495004654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296312, "time": 9584.126274347305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296616, "time": 9593.394693374634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296696, "time": 9595.854051113129, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296816, "time": 9599.774301290512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296864, "time": 9601.245262861252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297032, "time": 9606.158945798874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297696, "time": 9626.794613599777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297752, "time": 9628.304017066956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298624, "time": 9655.277543783188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298928, "time": 9664.579617500305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299008, "time": 9667.017447948456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299128, "time": 9670.433981180191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299176, "time": 9671.913645744324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299344, "time": 9677.426268100739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299896, "time": 9694.118220567703, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 300008, "time": 9697.562398433685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 9704.847525596619, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9704.856468439102, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9704.86574602127, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9704.87509894371, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9704.8851146698, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9704.895410299301, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9704.906671524048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9704.918497562408, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300064, "time": 9705.892172813416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300936, "time": 9732.259172677994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301240, "time": 9741.631573677063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301320, "time": 9744.06701374054, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 301440, "time": 9747.96828365326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301488, "time": 9749.434889316559, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301656, "time": 9754.339974403381, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302320, "time": 9775.148332357407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302376, "time": 9776.66407418251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303248, "time": 9804.320522546768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303544, "time": 9813.253779649734, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 303552, "time": 9813.735693693161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303608, "time": 9815.22279715538, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 303632, "time": 9816.20654797554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303752, "time": 9819.653129339218, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303968, "time": 9826.685257911682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304688, "time": 9848.756530284882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304920, "time": 9855.786763906479, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 305560, "time": 9875.513469219208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305856, "time": 9884.929603338242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305864, "time": 9884.95880818367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305920, "time": 9886.909969568253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305944, "time": 9887.426822900772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306280, "time": 9897.695877313614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307000, "time": 9919.881349563599, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307232, "time": 9927.203539609909, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307824, "time": 9945.545034646988, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 307872, "time": 9947.014648199081, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307984, "time": 9950.463472366333, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 308168, "time": 9955.889645814896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308232, "time": 9957.858245372772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308592, "time": 9969.148268461227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308776, "time": 9974.70915722847, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 309312, "time": 9991.443743467331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309544, "time": 9998.323109865189, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 10020.027033090591, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10020.099782943726, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10020.108165740967, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10020.114464521408, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10020.122067213058, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10020.128078222275, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10020.134969711304, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10020.142753601074, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310184, "time": 10025.049836397171, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310296, "time": 10028.536331176758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310480, "time": 10034.561576128006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310544, "time": 10036.539765119553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310904, "time": 10047.316707372665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311088, "time": 10053.184598207474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311624, "time": 10069.997884988785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311856, "time": 10077.340509176254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312496, "time": 10096.950698137283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312608, "time": 10100.360317468643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312792, "time": 10105.745391845703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312856, "time": 10107.689785003662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313216, "time": 10118.89315700531, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313400, "time": 10124.471738815308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313936, "time": 10141.044997215271, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314168, "time": 10147.925986289978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314808, "time": 10167.621431827545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314920, "time": 10171.1068649292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315104, "time": 10176.990606069565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315168, "time": 10178.986068964005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315528, "time": 10189.94879937172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315712, "time": 10195.787193775177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316248, "time": 10211.913745164871, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316480, "time": 10219.4053003788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317120, "time": 10239.100386857986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317232, "time": 10242.561076879501, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317416, "time": 10248.11209321022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317480, "time": 10250.104751825333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317840, "time": 10261.358531713486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318024, "time": 10266.806124687195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318120, "time": 10269.77381324768, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 318537, "time": 10283.670693159103, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.034303598068467, "train/action_min": 0.0, "train/action_std": 1.8341650992781673, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0013398243081884636, "train/actor_opt_grad_steps": 18820.0, "train/actor_opt_loss": 5.760859021926345, "train/adv_mag": 0.005672648979641085, "train/adv_max": 0.005386839878169736, "train/adv_mean": 0.0009811351362839732, "train/adv_min": -0.0025321056495359795, "train/adv_std": 0.0010848783663574644, "train/cont_avg": 0.9963980056532663, "train/cont_loss_mean": 0.02388504657651012, "train/cont_loss_std": 0.32821744313491646, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.653722228716366, "train/cont_pos_acc": 0.9999999847244377, "train/cont_pos_loss": 0.0035239934918924643, "train/cont_pred": 0.9964822282144172, "train/cont_rate": 0.9963980056532663, "train/dyn_loss_mean": 1.0000118460487482, "train/dyn_loss_std": 0.0003519863170020554, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.06770126429961494, "train/extr_critic_critic_opt_grad_steps": 18820.0, "train/extr_critic_critic_opt_loss": 12831.014481587627, "train/extr_critic_mag": 0.0654042288286602, "train/extr_critic_max": 0.0654042288286602, "train/extr_critic_mean": 0.0636021041091363, "train/extr_critic_min": 0.06075771609742438, "train/extr_critic_std": 0.0006141678386849898, "train/extr_return_normed_mag": 0.008707037541884274, "train/extr_return_normed_max": 0.008690618895855382, "train/extr_return_normed_mean": 0.00391180230330997, "train/extr_return_normed_min": 0.00011379812755177368, "train/extr_return_normed_std": 0.0012185998562543217, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.06936203675279067, "train/extr_return_raw_max": 0.06936203675279067, "train/extr_return_raw_mean": 0.06458322277021168, "train/extr_return_raw_min": 0.06078521598448705, "train/extr_return_raw_std": 0.0012185998555230698, "train/extr_reward_mag": 0.0018585968257194788, "train/extr_reward_max": 0.0018585968257194788, "train/extr_reward_mean": 0.00032784164611243726, "train/extr_reward_min": 4.572484960508107e-06, "train/extr_reward_std": 0.0004261142246503542, "train/image_loss_mean": 0.17866474599694487, "train/image_loss_std": 0.10538995614153655, "train/model_loss_mean": 0.8043780422689927, "train/model_loss_std": 0.38170233863082964, "train/model_opt_grad_norm": 33.02058970389054, "train/model_opt_grad_steps": 18799.97487437186, "train/model_opt_loss": 1809.756854646769, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2267.5879396984924, "train/policy_entropy_mag": 1.8239792333775429, "train/policy_entropy_max": 1.8239792333775429, "train/policy_entropy_mean": 1.4121735392503403, "train/policy_entropy_min": 0.49921410351093093, "train/policy_entropy_std": 0.20226551760830472, "train/policy_logprob_mag": 5.405220431898107, "train/policy_logprob_max": -0.12073979614742437, "train/policy_logprob_mean": -1.41268761912782, "train/policy_logprob_min": -5.405220431898107, "train/policy_logprob_std": 0.8351216370136894, "train/policy_randomness_mag": 0.9373399576350073, "train/policy_randomness_max": 0.9373399576350073, "train/policy_randomness_mean": 0.7257136822345868, "train/policy_randomness_min": 0.2565453147993016, "train/policy_randomness_std": 0.10394392052113112, "train/post_ent_mag": 81.67551629147937, "train/post_ent_max": 81.67551629147937, "train/post_ent_mean": 81.1439090517897, "train/post_ent_min": 80.59707944477024, "train/post_ent_std": 0.21617864940933246, "train/prior_ent_mag": 81.96356829925998, "train/prior_ent_max": 81.96356829925998, "train/prior_ent_mean": 79.88579260284577, "train/prior_ent_min": 78.36385905203508, "train/prior_ent_std": 0.5032685487414125, "train/rep_loss_mean": 1.0000118460487482, "train/rep_loss_std": 0.0003519863170020554, "train/reward_avg": 0.0001154913967440195, "train/reward_loss_mean": 0.0018211211915591255, "train/reward_loss_std": 0.049508067579538066, "train/reward_max_data": 0.10529208527737527, "train/reward_max_pred": 0.0013830961294509657, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0001738674226037084, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.759874428019804, "train/reward_pred": 7.624629225076443e-05, "train/reward_rate": 0.00019138662060301506, "train_stats/mean_log_entropy": 1.390539969643976, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.01444886066019535, "report/cont_loss_std": 0.24465425312519073, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.544930458068848, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0036259996704757214, "report/cont_pred": 0.9963800311088562, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.15185630321502686, "report/image_loss_std": 0.09674394875764847, "report/model_loss_mean": 0.7663560509681702, "report/model_loss_std": 0.26687759160995483, "report/post_ent_mag": 82.41691589355469, "report/post_ent_max": 82.41691589355469, "report/post_ent_mean": 81.8203125, "report/post_ent_min": 81.32975769042969, "report/post_ent_std": 0.2268272042274475, "report/prior_ent_mag": 82.70539093017578, "report/prior_ent_max": 82.70539093017578, "report/prior_ent_mean": 81.073974609375, "report/prior_ent_min": 79.65559387207031, "report/prior_ent_std": 0.44195517897605896, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 5.084089934825897e-05, "report/reward_loss_std": 0.00022279468248598278, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.000952601432800293, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.084089934825897e-05, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 2.0966981537640095e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.03642944619059563, "eval/cont_loss_std": 0.4276210367679596, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.605907440185547, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0036034462973475456, "eval/cont_pred": 0.9964025020599365, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22111928462982178, "eval/image_loss_std": 0.1131049320101738, "eval/model_loss_mean": 0.8575706481933594, "eval/model_loss_std": 0.4406166076660156, "eval/post_ent_mag": 82.37129211425781, "eval/post_ent_max": 82.37129211425781, "eval/post_ent_mean": 81.82476806640625, "eval/post_ent_min": 81.29558563232422, "eval/post_ent_std": 0.21897263824939728, "eval/prior_ent_mag": 82.15521240234375, "eval/prior_ent_max": 82.15521240234375, "eval/prior_ent_mean": 81.11001586914062, "eval/prior_ent_min": 79.73751068115234, "eval/prior_ent_std": 0.41382867097854614, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 2.183765172958374e-05, "eval/reward_loss_std": 0.00013443120406009257, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0012046098709106445, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 2.183765172958374e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 9.165727533400059e-06, "eval/reward_rate": 0.0, "replay/size": 318033.0, "replay/inserts": 31776.0, "replay/samples": 31776.0, "replay/insert_wait_avg": 1.3522616205858921e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.273759427987797e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 75040.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3203425665902707e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4367084503174, "timer/env.step_count": 3972.0, "timer/env.step_total": 39.102784395217896, "timer/env.step_frac": 0.03908571533304526, "timer/env.step_avg": 0.009844608357305613, "timer/env.step_min": 0.007895708084106445, "timer/env.step_max": 0.03571724891662598, "timer/replay._sample_count": 31776.0, "timer/replay._sample_total": 17.913567066192627, "timer/replay._sample_frac": 0.017905747474961063, "timer/replay._sample_avg": 0.0005637451871284185, "timer/replay._sample_min": 0.0004067420959472656, "timer/replay._sample_max": 0.014295339584350586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4839.0, "timer/agent.policy_total": 53.76651477813721, "timer/agent.policy_frac": 0.05374304473635506, "timer/agent.policy_avg": 0.011111079722698328, "timer/agent.policy_min": 0.009287595748901367, "timer/agent.policy_max": 0.10455083847045898, "timer/dataset_train_count": 1986.0, "timer/dataset_train_total": 0.23609375953674316, "timer/dataset_train_frac": 0.00023599070040368055, "timer/dataset_train_avg": 0.00011887903299936715, "timer/dataset_train_min": 9.918212890625e-05, "timer/dataset_train_max": 0.001081705093383789, "timer/agent.train_count": 1986.0, "timer/agent.train_total": 892.2072455883026, "timer/agent.train_frac": 0.8918177812270974, "timer/agent.train_avg": 0.4492483613234152, "timer/agent.train_min": 0.4363396167755127, "timer/agent.train_max": 0.7611820697784424, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.474808931350708, "timer/agent.report_frac": 0.00047460166879141207, "timer/agent.report_avg": 0.237404465675354, "timer/agent.report_min": 0.2312004566192627, "timer/agent.report_max": 0.2436084747314453, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4332275390625e-05, "timer/dataset_eval_frac": 3.431728874063998e-08, "timer/dataset_eval_avg": 3.4332275390625e-05, "timer/dataset_eval_min": 3.4332275390625e-05, "timer/dataset_eval_max": 3.4332275390625e-05, "fps": 31.761516208111804}
{"step": 318560, "time": 10284.34773683548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318792, "time": 10291.344017982483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319432, "time": 10311.136237382889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319544, "time": 10315.082026481628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319728, "time": 10320.928987264633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 10335.587167263031, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10335.594891786575, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10335.604426145554, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10335.613341331482, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10335.621526002884, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10335.630628824234, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10335.6385140419, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10335.646549224854, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320152, "time": 10340.079362630844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320336, "time": 10345.963265657425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320432, "time": 10348.922244548798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320872, "time": 10362.152119398117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321104, "time": 10369.632225751877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321744, "time": 10389.266842126846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321856, "time": 10392.69852399826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322040, "time": 10398.284766674042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322464, "time": 10411.583966493607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322648, "time": 10417.032658338547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322744, "time": 10419.99911570549, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 323184, "time": 10433.843424320221, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 323416, "time": 10440.733908891678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324056, "time": 10460.514956951141, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324168, "time": 10463.980847120285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324352, "time": 10469.90227484703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324776, "time": 10482.842751026154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324960, "time": 10488.829580068588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325056, "time": 10491.761823654175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325160, "time": 10494.738823413849, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 325496, "time": 10505.162469625473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326368, "time": 10532.299271583557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326480, "time": 10535.74120426178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326664, "time": 10541.21060681343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326664, "time": 10541.22164273262, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 327088, "time": 10554.547010660172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327272, "time": 10559.955846786499, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327432, "time": 10564.865468025208, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 327472, "time": 10566.333543777466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327688, "time": 10573.01356101036, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 327808, "time": 10577.345633983612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 328136, "time": 10587.240216255188, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 328592, "time": 10601.516439437866, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 328600, "time": 10601.55373764038, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 328680, "time": 10604.177735328674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329400, "time": 10626.18498826027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329480, "time": 10628.616305589676, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 329744, "time": 10637.049037218094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329784, "time": 10638.05662035942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 10653.646351099014, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10653.662543058395, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10653.673350095749, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10653.68507027626, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10653.69385766983, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10653.704506158829, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10653.714852333069, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10653.724888563156, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330120, "time": 10654.243650197983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330448, "time": 10664.642149448395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330904, "time": 10678.369245290756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330912, "time": 10678.841024160385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331672, "time": 10701.880042791367, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 331712, "time": 10703.339969158173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331792, "time": 10705.790174484253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332096, "time": 10715.040689706802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332432, "time": 10725.53186416626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332760, "time": 10735.475128889084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 333216, "time": 10749.686279058456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 333224, "time": 10749.717762231827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 333984, "time": 10773.372792005539, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334024, "time": 10774.379868268967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334104, "time": 10776.865187168121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334408, "time": 10786.364357471466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334744, "time": 10796.706195116043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335056, "time": 10806.436723709106, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 335072, "time": 10806.931010484695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335528, "time": 10820.901032686234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335536, "time": 10821.375774383545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336296, "time": 10845.132578849792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336416, "time": 10849.044264316559, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336720, "time": 10858.412657260895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336768, "time": 10859.900566339493, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 337056, "time": 10868.685775518417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337136, "time": 10871.15373301506, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 337384, "time": 10878.660468578339, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337848, "time": 10892.867400169373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338608, "time": 10916.666968345642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338728, "time": 10920.117486953735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339032, "time": 10929.438784360886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339080, "time": 10930.921796321869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339368, "time": 10939.942250967026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339448, "time": 10942.39022397995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339696, "time": 10950.25035071373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 10962.478989601135, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 340080, "time": 10968.72454404831, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10968.731175661087, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10968.738680839539, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10968.799844264984, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10968.80801486969, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10968.827843427658, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10968.835409402847, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340160, "time": 10971.347868204117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340920, "time": 10994.675924777985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341040, "time": 10998.558746099472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341344, "time": 11007.910155057907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341392, "time": 11009.408797740936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341680, "time": 11018.234511852264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341760, "time": 11020.711068630219, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342008, "time": 11028.18062710762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342472, "time": 11042.515110254288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343232, "time": 11066.137123823166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343352, "time": 11069.597347021103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343400, "time": 11071.07548046112, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 343704, "time": 11080.390510559082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343992, "time": 11089.33067369461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344072, "time": 11092.035896062851, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344320, "time": 11100.20020532608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344784, "time": 11114.572106599808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345544, "time": 11137.520567417145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345664, "time": 11141.408281326294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345712, "time": 11142.903052091599, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346016, "time": 11152.331158161163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346304, "time": 11161.13642835617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346384, "time": 11163.61034655571, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346496, "time": 11167.054805278778, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 347096, "time": 11185.507044553757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347856, "time": 11209.29142832756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347976, "time": 11212.762064695358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348024, "time": 11214.229640007019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348328, "time": 11223.530089139938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348616, "time": 11232.391148805618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348696, "time": 11235.006757736206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348808, "time": 11238.484854221344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 349408, "time": 11257.239793777466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 349696, "time": 11266.17260169983, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 11284.922800064087, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11284.959530353546, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11284.994487285614, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11285.006069898605, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11285.017904758453, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11285.080327033997, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11285.092174768448, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11285.10124707222, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350065, "time": 11285.668388843536, "train_stats/mean_log_entropy": 1.2354047863106978, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.639020116196066, "train/action_min": 0.0, "train/action_std": 2.029955813727403, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.001273198490684644, "train/actor_opt_grad_steps": 20800.0, "train/actor_opt_loss": 0.8434399283930735, "train/adv_mag": 0.006240824228010807, "train/adv_max": 0.005711745376211738, "train/adv_mean": 0.0006680125617443308, "train/adv_min": -0.0034249953660868146, "train/adv_std": 0.001167620379751936, "train/cont_avg": 0.9965002379441624, "train/cont_loss_mean": 0.023268350585586, "train/cont_loss_std": 0.3191731011307075, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.628124001099891, "train/cont_pos_acc": 0.9999999863847258, "train/cont_pos_loss": 0.003577601026299263, "train/cont_pred": 0.9964286848373219, "train/cont_rate": 0.9965002379441624, "train/dyn_loss_mean": 1.000008308947994, "train/dyn_loss_std": 0.00022120058296016667, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.041823720659051315, "train/extr_critic_critic_opt_grad_steps": 20800.0, "train/extr_critic_critic_opt_loss": 13065.312941188135, "train/extr_critic_mag": 0.10187658440643156, "train/extr_critic_max": 0.10187658440643156, "train/extr_critic_mean": 0.09897497201782798, "train/extr_critic_min": 0.09569828703923879, "train/extr_critic_std": 0.0009057525226841609, "train/extr_return_normed_mag": 0.010199724568933399, "train/extr_return_normed_max": 0.01019654763380283, "train/extr_return_normed_mean": 0.0036842086022349074, "train/extr_return_normed_min": -0.0007546434396414587, "train/extr_return_normed_std": 0.0014932162821562347, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.10615535492673138, "train/extr_return_raw_max": 0.10615535492673138, "train/extr_return_raw_mean": 0.09964302038480788, "train/extr_return_raw_min": 0.09520416385328709, "train/extr_return_raw_std": 0.001493216282451705, "train/extr_reward_mag": 0.0024742196659146226, "train/extr_reward_max": 0.0024742196659146226, "train/extr_reward_mean": 0.0003666978117309305, "train/extr_reward_min": 1.7427550959708121e-06, "train/extr_reward_std": 0.0005852120538740915, "train/image_loss_mean": 0.1659674913750082, "train/image_loss_std": 0.108988376778697, "train/model_loss_mean": 0.7912553451993138, "train/model_loss_std": 0.37845682280922904, "train/model_opt_grad_norm": 31.506813136454163, "train/model_opt_grad_steps": 20778.53299492386, "train/model_opt_loss": 2078.5157861080265, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2626.903553299492, "train/policy_entropy_mag": 1.7901060690129469, "train/policy_entropy_max": 1.7901060690129469, "train/policy_entropy_mean": 1.2752279067402563, "train/policy_entropy_min": 0.23239520328299043, "train/policy_entropy_std": 0.29880569565114634, "train/policy_logprob_mag": 5.7404784696356295, "train/policy_logprob_max": -0.04325267100980893, "train/policy_logprob_mean": -1.2740654497582296, "train/policy_logprob_min": -5.7404784696356295, "train/policy_logprob_std": 0.9583979672586858, "train/policy_randomness_mag": 0.9199325947592101, "train/policy_randomness_max": 0.9199325947592101, "train/policy_randomness_mean": 0.655337546531319, "train/policy_randomness_min": 0.11942751635679133, "train/policy_randomness_std": 0.153555760793577, "train/post_ent_mag": 82.89810742218482, "train/post_ent_max": 82.89810742218482, "train/post_ent_mean": 82.40399785695342, "train/post_ent_min": 81.92281504209876, "train/post_ent_std": 0.1791604838244201, "train/prior_ent_mag": 82.92434339959004, "train/prior_ent_max": 82.92434339959004, "train/prior_ent_mean": 81.4774851145478, "train/prior_ent_min": 79.87099832447652, "train/prior_ent_std": 0.46519823092494517, "train/rep_loss_mean": 1.000008308947994, "train/rep_loss_std": 0.00022120058296016667, "train/reward_avg": 0.00010724527584648866, "train/reward_loss_mean": 0.0020144935460940836, "train/reward_loss_std": 0.05674001870913695, "train/reward_max_data": 0.10642449247655529, "train/reward_max_pred": 0.0018785011949878053, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00021110559942724943, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 7.5829344521398125, "train/reward_pred": 8.892960643140495e-05, "train/reward_rate": 0.00023794416243654823, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014920135959982872, "report/cont_loss_std": 0.25850775837898254, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.858332633972168, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0034848880022764206, "report/cont_pred": 0.9965225458145142, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.16044141352176666, "report/image_loss_std": 0.10066021978855133, "report/model_loss_mean": 0.7755960822105408, "report/model_loss_std": 0.28393521904945374, "report/post_ent_mag": 82.69419860839844, "report/post_ent_max": 82.69419860839844, "report/post_ent_mean": 82.26786804199219, "report/post_ent_min": 81.82986450195312, "report/post_ent_std": 0.182210773229599, "report/prior_ent_mag": 83.96821594238281, "report/prior_ent_max": 83.96821594238281, "report/prior_ent_mean": 81.485595703125, "report/prior_ent_min": 79.59774780273438, "report/prior_ent_std": 0.5219800472259521, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00023450562730431557, "report/reward_loss_std": 0.0009634655434638262, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.004397034645080566, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00023450562730431557, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 9.854382369667292e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.009298743680119514, "eval/cont_loss_std": 0.18311627209186554, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.866118907928467, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0035736022982746363, "eval/cont_pred": 0.9964337348937988, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18105503916740417, "eval/image_loss_std": 0.12300514429807663, "eval/model_loss_mean": 0.7904515266418457, "eval/model_loss_std": 0.22339491546154022, "eval/post_ent_mag": 82.77588653564453, "eval/post_ent_max": 82.77588653564453, "eval/post_ent_mean": 82.30862426757812, "eval/post_ent_min": 81.81195068359375, "eval/post_ent_std": 0.20203423500061035, "eval/prior_ent_mag": 83.61273956298828, "eval/prior_ent_max": 83.61273956298828, "eval/prior_ent_mean": 81.46537780761719, "eval/prior_ent_min": 79.74913024902344, "eval/prior_ent_std": 0.4805189073085785, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 9.771576151251793e-05, "eval/reward_loss_std": 0.0005696170264855027, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.003272414207458496, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 9.771576151251793e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.113861359655857e-05, "eval/reward_rate": 0.0, "replay/size": 349561.0, "replay/inserts": 31528.0, "replay/samples": 31520.0, "replay/insert_wait_avg": 1.3536273813041991e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.630612915542524e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 84288.0, "eval_replay/inserts": 9248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.254275595853073e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.9838750362396, "timer/env.step_count": 3941.0, "timer/env.step_total": 38.96809148788452, "timer/env.step_frac": 0.03889093672937115, "timer/env.step_avg": 0.009887868938818706, "timer/env.step_min": 0.008003711700439453, "timer/env.step_max": 0.04954648017883301, "timer/replay._sample_count": 31520.0, "timer/replay._sample_total": 17.72068500518799, "timer/replay._sample_frac": 0.017685598986857017, "timer/replay._sample_avg": 0.0005622044735148473, "timer/replay._sample_min": 0.0004208087921142578, "timer/replay._sample_max": 0.028699159622192383, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5097.0, "timer/agent.policy_total": 57.637070417404175, "timer/agent.policy_frac": 0.057522952068784106, "timer/agent.policy_avg": 0.011308038143496993, "timer/agent.policy_min": 0.00926971435546875, "timer/agent.policy_max": 1.2152786254882812, "timer/dataset_train_count": 1970.0, "timer/dataset_train_total": 0.23445343971252441, "timer/dataset_train_frac": 0.00023398923431182435, "timer/dataset_train_avg": 0.00011901189833123067, "timer/dataset_train_min": 0.00010180473327636719, "timer/dataset_train_max": 0.0010724067687988281, "timer/agent.train_count": 1970.0, "timer/agent.train_total": 886.6755015850067, "timer/agent.train_frac": 0.8849199310247757, "timer/agent.train_avg": 0.4500890870989882, "timer/agent.train_min": 0.4378962516784668, "timer/agent.train_max": 0.7481157779693604, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47776103019714355, "timer/agent.report_frac": 0.0004768150886458766, "timer/agent.report_avg": 0.23888051509857178, "timer/agent.report_min": 0.23089861869812012, "timer/agent.report_max": 0.24686241149902344, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.504753112792969e-05, "timer/dataset_eval_frac": 3.497813887140858e-08, "timer/dataset_eval_avg": 3.504753112792969e-05, "timer/dataset_eval_min": 3.504753112792969e-05, "timer/dataset_eval_max": 3.504753112792969e-05, "fps": 31.465044786726647}
{"step": 350168, "time": 11288.857792139053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350288, "time": 11292.785985469818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350336, "time": 11294.378577709198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350640, "time": 11303.713183879852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350928, "time": 11312.600700855255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 351008, "time": 11315.090018033981, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 351720, "time": 11336.925752162933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352008, "time": 11345.801200389862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352480, "time": 11361.218311548233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352600, "time": 11364.68791794777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352648, "time": 11366.166282892227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352952, "time": 11375.550384521484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352960, "time": 11376.024276971817, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 353240, "time": 11384.587175607681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353320, "time": 11387.05035161972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353408, "time": 11389.985785961151, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 353640, "time": 11396.899534225464, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 354784, "time": 11432.447090864182, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 354792, "time": 11432.477493286133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 354912, "time": 11436.418540239334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 354960, "time": 11437.901672363281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355264, "time": 11447.446315050125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355272, "time": 11447.475417613983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355632, "time": 11458.7830991745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355720, "time": 11461.254249572754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357096, "time": 11503.716449975967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357104, "time": 11504.274626493454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357224, "time": 11507.730571746826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357272, "time": 11509.226281404495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357576, "time": 11518.540867805481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357584, "time": 11519.017430067062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357944, "time": 11529.827217578888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358032, "time": 11532.786050796509, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358536, "time": 11548.17725944519, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 359408, "time": 11575.301552534103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359416, "time": 11575.331248998642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359536, "time": 11579.238731622696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359584, "time": 11580.71396112442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359888, "time": 11590.047666788101, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359896, "time": 11590.077677488327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 11597.010004758835, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 360048, "time": 11599.753636360168, "eval_episode/length": 229.0, "eval_episode/score": 0.28437501192092896, "eval_episode/reward_rate": 0.004347826086956522}
{"step": 360048, "time": 11600.927936553955, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11600.936637878418, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11600.944239139557, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11600.951868057251, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11600.96020245552, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11600.96754527092, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360344, "time": 11609.856210231781, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 360848, "time": 11626.208067893982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361000, "time": 11630.65194106102, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 361080, "time": 11633.126633405685, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 361440, "time": 11644.371258735657, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 361720, "time": 11652.746730089188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361848, "time": 11656.765923500061, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361896, "time": 11658.25233745575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362208, "time": 11668.019694805145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363160, "time": 11697.062483787537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363312, "time": 11701.948333024979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363392, "time": 11704.403613328934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363752, "time": 11715.30701828003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 364032, "time": 11724.112312793732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 364160, "time": 11728.067803382874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 364208, "time": 11729.552332639694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 364520, "time": 11738.923167228699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 364944, "time": 11752.3836414814, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 365472, "time": 11768.586947441101, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365704, "time": 11775.615623235703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 366064, "time": 11786.886474609375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 366344, "time": 11795.236757993698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 366472, "time": 11799.226227521896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 366520, "time": 11800.737976312637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 366832, "time": 11810.693272829056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367256, "time": 11823.4313352108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367784, "time": 11839.808762788773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368016, "time": 11847.18722820282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368376, "time": 11858.01844573021, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368656, "time": 11867.539881944656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368664, "time": 11867.569930791855, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 368696, "time": 11868.554697275162, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 368784, "time": 11871.499007940292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369144, "time": 11882.300496339798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369568, "time": 11895.717787027359, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 11913.162989854813, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 370032, "time": 11913.511455774307, "eval_episode/length": 169.0, "eval_episode/score": 0.47187501192092896, "eval_episode/reward_rate": 0.0058823529411764705}
{"step": 370032, "time": 11915.898519039154, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11915.909769535065, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11915.933391809464, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11915.946722745895, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11915.963633298874, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11915.977620363235, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370096, "time": 11917.937511444092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370688, "time": 11936.19977235794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370712, "time": 11936.714169502258, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 370968, "time": 11944.544647216797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370976, "time": 11945.016073226929, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371008, "time": 11946.018850803375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371072, "time": 11947.976642608643, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 371880, "time": 11972.666972637177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 372408, "time": 11988.96346449852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373000, "time": 12007.138014793396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373024, "time": 12008.101907014847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373200, "time": 12013.51869893074, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 373280, "time": 12016.12767791748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373288, "time": 12016.159815073013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373320, "time": 12017.145000696182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373384, "time": 12019.109045743942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373488, "time": 12022.53504061699, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 374168, "time": 12043.225593328476, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 375312, "time": 12078.868212461472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375512, "time": 12084.80252790451, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375592, "time": 12087.247832536697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375600, "time": 12087.726461648941, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375632, "time": 12088.742768526077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375696, "time": 12090.726545095444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375800, "time": 12093.71114730835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376368, "time": 12111.531591892242, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 376480, "time": 12114.998222827911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377624, "time": 12150.747966051102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377888, "time": 12159.139748334885, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 377904, "time": 12159.640213012695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377912, "time": 12159.67129945755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377944, "time": 12160.670365810394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378112, "time": 12166.221457004547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378200, "time": 12168.712910175323, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 378680, "time": 12183.613077878952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378792, "time": 12187.077456235886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378800, "time": 12187.551908016205, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 379032, "time": 12194.639456987381, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 12226.884752511978, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 380016, "time": 12227.01525425911, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 380016, "time": 12229.192495584488, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 380016, "time": 12230.349461317062, "eval_episode/length": 207.0, "eval_episode/score": 0.3531250059604645, "eval_episode/reward_rate": 0.004807692307692308}
{"step": 380016, "time": 12230.710495710373, "eval_episode/length": 224.0, "eval_episode/score": 0.30000001192092896, "eval_episode/reward_rate": 0.0044444444444444444}
{"step": 380016, "time": 12231.163689136505, "eval_episode/length": 167.0, "eval_episode/score": 0.4781250059604645, "eval_episode/reward_rate": 0.005952380952380952}
{"step": 380016, "time": 12231.62287068367, "eval_episode/length": 267.0, "eval_episode/score": 0.16562500596046448, "eval_episode/reward_rate": 0.0037313432835820895}
{"step": 380016, "time": 12231.71313381195, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 380064, "time": 12233.191388368607, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 380200, "time": 12237.192216157913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380216, "time": 12237.689926862717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380256, "time": 12239.151539564133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380424, "time": 12244.12057876587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380456, "time": 12245.133296489716, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 380992, "time": 12261.9844019413, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 381104, "time": 12265.478916406631, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 381456, "time": 12276.317392349243, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 381737, "time": 12285.832239627838, "train_stats/mean_log_entropy": 1.257238828256482, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5323344529277145, "train/action_min": 0.0, "train/action_std": 2.0076730040588764, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.001511951299199618, "train/actor_opt_grad_steps": 22775.0, "train/actor_opt_loss": -3.568884136324579, "train/adv_mag": 0.0193041790314395, "train/adv_max": 0.018152389035682486, "train/adv_mean": 0.000505837851873403, "train/adv_min": -0.004663783680609983, "train/adv_std": 0.0021225878956487795, "train/cont_avg": 0.9961923926767676, "train/cont_loss_mean": 0.024982159283491925, "train/cont_loss_std": 0.3363364994168138, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.630917923791068, "train/cont_pos_acc": 0.9999999831421207, "train/cont_pos_loss": 0.003569019993654255, "train/cont_pred": 0.9964371492164303, "train/cont_rate": 0.9961923926767676, "train/dyn_loss_mean": 1.0000042945447594, "train/dyn_loss_std": 0.0001088657718539271, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09025925761141645, "train/extr_critic_critic_opt_grad_steps": 22775.0, "train/extr_critic_critic_opt_loss": 11558.135855626579, "train/extr_critic_mag": 0.12337774881208786, "train/extr_critic_max": 0.12337774881208786, "train/extr_critic_mean": 0.11984309324561948, "train/extr_critic_min": 0.11584845877657032, "train/extr_critic_std": 0.001201219147663902, "train/extr_return_normed_mag": 0.023033779490776736, "train/extr_return_normed_max": 0.02300117759391515, "train/extr_return_normed_mean": 0.0039047447393790614, "train/extr_return_normed_min": -0.0015287986307433157, "train/extr_return_normed_std": 0.0024739775402151574, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.13944536598041804, "train/extr_return_raw_max": 0.13944536598041804, "train/extr_return_raw_mean": 0.12034893886308477, "train/extr_return_raw_min": 0.11491538983101797, "train/extr_return_raw_std": 0.002473977531689793, "train/extr_reward_mag": 0.015353037853433628, "train/extr_reward_max": 0.015353037853433628, "train/extr_reward_mean": 0.0003765087128498396, "train/extr_reward_min": 9.759507998071536e-07, "train/extr_reward_std": 0.0010595575576639884, "train/image_loss_mean": 0.16102857857641548, "train/image_loss_std": 0.10940080184978668, "train/model_loss_mean": 0.7880800086440463, "train/model_loss_std": 0.3937102613048722, "train/model_opt_grad_norm": 29.1066442354761, "train/model_opt_grad_steps": 22752.21212121212, "train/model_opt_loss": 2843.1797818270597, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3636.3636363636365, "train/policy_entropy_mag": 1.8558707821248757, "train/policy_entropy_max": 1.8558707821248757, "train/policy_entropy_mean": 1.2730085602914445, "train/policy_entropy_min": 0.1382466856427867, "train/policy_entropy_std": 0.3616762129646359, "train/policy_logprob_mag": 6.034752867438576, "train/policy_logprob_max": -0.023054602010307287, "train/policy_logprob_mean": -1.2730488394848023, "train/policy_logprob_min": -6.034752867438576, "train/policy_logprob_std": 0.9530120780973723, "train/policy_randomness_mag": 0.9537289720593076, "train/policy_randomness_max": 0.9537289720593076, "train/policy_randomness_mean": 0.6541970229209072, "train/policy_randomness_min": 0.07104474667346838, "train/policy_randomness_std": 0.1858648175392488, "train/post_ent_mag": 81.5491029758646, "train/post_ent_max": 81.5491029758646, "train/post_ent_mean": 81.15573721220998, "train/post_ent_min": 80.78610757384638, "train/post_ent_std": 0.1364491276367746, "train/prior_ent_mag": 82.31420401370886, "train/prior_ent_max": 82.31420401370886, "train/prior_ent_mean": 80.3664779663086, "train/prior_ent_min": 78.46073000358813, "train/prior_ent_std": 0.6050917748549972, "train/rep_loss_mean": 1.0000042945447594, "train/rep_loss_std": 0.0001088657718539271, "train/reward_avg": 0.0001300387895128671, "train/reward_loss_mean": 0.002066671032213954, "train/reward_loss_std": 0.053017725054814946, "train/reward_max_data": 0.11087436831057673, "train/reward_max_pred": 0.003183966935283006, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00022032903136204543, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 7.817108753399971, "train/reward_pred": 9.272051881058048e-05, "train/reward_rate": 0.00023674242424242425, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02525322139263153, "report/cont_loss_std": 0.3538645803928375, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.6724629402160645, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0031073002610355616, "report/cont_pred": 0.9968962669372559, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.15680211782455444, "report/image_loss_std": 0.11307469010353088, "report/model_loss_mean": 0.7885214686393738, "report/model_loss_std": 0.5092419385910034, "report/post_ent_mag": 80.5453109741211, "report/post_ent_max": 80.5453109741211, "report/post_ent_mean": 80.21089172363281, "report/post_ent_min": 79.89370727539062, "report/post_ent_std": 0.12813560664653778, "report/prior_ent_mag": 80.57827758789062, "report/prior_ent_max": 80.57827758789062, "report/prior_ent_mean": 78.95447540283203, "report/prior_ent_min": 76.49888610839844, "report/prior_ent_std": 0.7812353372573853, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0003234863397665322, "report/reward_loss_mean": 0.006466148421168327, "report/reward_loss_std": 0.19826269149780273, "report/reward_max_data": 0.33125001192092896, "report/reward_max_pred": 0.0038384199142456055, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00026749400421977043, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 6.347689628601074, "report/reward_pred": 0.00012010929640382528, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014878428541123867, "eval/cont_loss_std": 0.2659464180469513, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.025867462158203, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003115241415798664, "eval/cont_pred": 0.99689120054245, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17629694938659668, "eval/image_loss_std": 0.10785374790430069, "eval/model_loss_mean": 0.7913919687271118, "eval/model_loss_std": 0.2853702902793884, "eval/post_ent_mag": 80.55513000488281, "eval/post_ent_max": 80.55513000488281, "eval/post_ent_mean": 80.19503021240234, "eval/post_ent_min": 79.85778045654297, "eval/post_ent_std": 0.12785105407238007, "eval/prior_ent_mag": 81.10906219482422, "eval/prior_ent_max": 81.10906219482422, "eval/prior_ent_mean": 79.01277923583984, "eval/prior_ent_min": 76.24468994140625, "eval/prior_ent_std": 0.733187735080719, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00021660560742020607, "eval/reward_loss_std": 0.0008647379581816494, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0037169456481933594, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00021660560742020607, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 9.52031696215272e-05, "eval/reward_rate": 0.0, "replay/size": 381233.0, "replay/inserts": 31672.0, "replay/samples": 31680.0, "replay/insert_wait_avg": 1.357650479815108e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.514165647102125e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 91088.0, "eval_replay/inserts": 6800.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2356042861938477e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.145003080368, "timer/env.step_count": 3959.0, "timer/env.step_total": 39.41507387161255, "timer/env.step_frac": 0.03940935939310522, "timer/env.step_avg": 0.009955815577573263, "timer/env.step_min": 0.008301019668579102, "timer/env.step_max": 0.0361173152923584, "timer/replay._sample_count": 31680.0, "timer/replay._sample_total": 17.87705373764038, "timer/replay._sample_frac": 0.017874461885607047, "timer/replay._sample_avg": 0.0005643009386881434, "timer/replay._sample_min": 0.0003979206085205078, "timer/replay._sample_max": 0.025844335556030273, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4809.0, "timer/agent.policy_total": 53.462684869766235, "timer/agent.policy_frac": 0.053454933739713106, "timer/agent.policy_avg": 0.011117214570548187, "timer/agent.policy_min": 0.009316682815551758, "timer/agent.policy_max": 0.09502863883972168, "timer/dataset_train_count": 1980.0, "timer/dataset_train_total": 0.23890924453735352, "timer/dataset_train_frac": 0.0002388746069835192, "timer/dataset_train_avg": 0.000120661234614825, "timer/dataset_train_min": 0.0001010894775390625, "timer/dataset_train_max": 0.0010788440704345703, "timer/agent.train_count": 1980.0, "timer/agent.train_total": 892.2799582481384, "timer/agent.train_frac": 0.892150593663905, "timer/agent.train_avg": 0.4506464435596659, "timer/agent.train_min": 0.43935060501098633, "timer/agent.train_max": 0.7180788516998291, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4692366123199463, "timer/agent.report_frac": 0.000469168581430427, "timer/agent.report_avg": 0.23461830615997314, "timer/agent.report_min": 0.22481298446655273, "timer/agent.report_max": 0.24442362785339355, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.4088913814014005e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 31.666852312427462}
{"step": 381928, "time": 12291.530346393585, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 381976, "time": 12293.015761137009, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 382376, "time": 12305.380355834961, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382432, "time": 12307.322772026062, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 382528, "time": 12310.289665222168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382704, "time": 12315.830233573914, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 382736, "time": 12316.820478439331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383304, "time": 12334.16531920433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383312, "time": 12334.660880088806, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 383416, "time": 12337.635843992233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383584, "time": 12343.08201098442, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 383680, "time": 12346.195152044296, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 383840, "time": 12351.13470196724, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 383960, "time": 12354.610816001892, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 384024, "time": 12356.576436519623, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 384232, "time": 12362.986969470978, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 384536, "time": 12372.40126156807, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 384584, "time": 12374.02564406395, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 384624, "time": 12375.511225700378, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 384744, "time": 12378.997844696045, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 384744, "time": 12379.01015496254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 384864, "time": 12382.953597068787, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 384952, "time": 12385.471665382385, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 385208, "time": 12393.932856082916, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 385992, "time": 12418.232403755188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386848, "time": 12444.958480834961, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386896, "time": 12446.441775083542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386936, "time": 12447.452652454376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387056, "time": 12451.378904819489, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387056, "time": 12451.389498472214, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 387264, "time": 12457.78684258461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387520, "time": 12465.807072401047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388304, "time": 12490.025743246078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388528, "time": 12497.030582904816, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 388832, "time": 12506.41270494461, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 389048, "time": 12512.954731941223, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 389048, "time": 12512.969518184662, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 389160, "time": 12516.489059448242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389368, "time": 12522.959915161133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389544, "time": 12528.523495435715, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 389832, "time": 12537.449934005737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389848, "time": 12537.945559978485, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 389976, "time": 12541.92209482193, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 12543.467522621155, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 390000, "time": 12544.6664083004, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 390000, "time": 12545.161417484283, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 390000, "time": 12545.95622754097, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 390000, "time": 12546.289191961288, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 390000, "time": 12547.329802751541, "eval_episode/length": 204.0, "eval_episode/score": 0.36250001192092896, "eval_episode/reward_rate": 0.004878048780487805}
{"step": 390000, "time": 12547.942647457123, "eval_episode/length": 206.0, "eval_episode/score": 0.35624998807907104, "eval_episode/reward_rate": 0.004830917874396135}
{"step": 390000, "time": 12548.266399383545, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 390096, "time": 12551.239477157593, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 390112, "time": 12551.739541053772, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 390704, "time": 12570.148899555206, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 390840, "time": 12574.175761938095, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 391304, "time": 12588.62086892128, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 391360, "time": 12590.593740463257, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 391360, "time": 12590.602066755295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391680, "time": 12600.510658025742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391808, "time": 12604.509808778763, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 391992, "time": 12609.979177236557, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 392136, "time": 12614.583815813065, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 392144, "time": 12615.063572406769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392160, "time": 12615.564832687378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392968, "time": 12640.318607091904, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 392992, "time": 12641.306909561157, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 392992, "time": 12641.316406488419, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 393016, "time": 12641.846300840378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393152, "time": 12646.394739627838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393672, "time": 12662.757443189621, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393856, "time": 12668.677233934402, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 393912, "time": 12670.197790622711, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 394072, "time": 12675.250965356827, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 394424, "time": 12686.089385271072, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 394448, "time": 12687.064522981644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394456, "time": 12687.095021486282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394648, "time": 12693.016083478928, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 394944, "time": 12702.389617204666, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 395280, "time": 12712.903774261475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 395304, "time": 12713.425653219223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 395712, "time": 12726.285885095596, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 395928, "time": 12732.740220308304, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 395968, "time": 12734.364227771759, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 396168, "time": 12740.325261116028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396248, "time": 12742.795436382294, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 396344, "time": 12745.760565042496, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 396560, "time": 12752.667337179184, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 396712, "time": 12757.133444547653, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 396712, "time": 12757.145598888397, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 396760, "time": 12758.66519498825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396816, "time": 12760.619294643402, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 397016, "time": 12766.717242240906, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 397360, "time": 12777.621492385864, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 397760, "time": 12789.980350017548, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 397792, "time": 12790.973937988281, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 398240, "time": 12804.960250616074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 398376, "time": 12808.94402885437, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 398376, "time": 12808.955397129059, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 398656, "time": 12817.838922977448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 398856, "time": 12823.931524038315, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 398872, "time": 12824.433245658875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399072, "time": 12830.835578918457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399128, "time": 12832.34490776062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399248, "time": 12836.287851333618, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 399272, "time": 12836.808708906174, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 399656, "time": 12848.669146060944, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 399672, "time": 12849.169877767563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399728, "time": 12851.111535072327, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 399808, "time": 12853.633913755417, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 399856, "time": 12855.206892251968, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 400072, "time": 12861.62995171547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 12863.07559132576, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 400088, "time": 12863.23063325882, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 400088, "time": 12864.902053117752, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 400088, "time": 12865.035064697266, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 400088, "time": 12865.63363957405, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 400088, "time": 12865.664882183075, "eval_episode/length": 164.0, "eval_episode/score": 0.48750001192092896, "eval_episode/reward_rate": 0.006060606060606061}
{"step": 400088, "time": 12866.49358701706, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 400088, "time": 12866.776813268661, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 400128, "time": 12868.255344867706, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 400184, "time": 12869.75205039978, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 400264, "time": 12872.225907087326, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 400584, "time": 12882.123831033707, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 400608, "time": 12883.119122982025, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 400824, "time": 12889.663331985474, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 400968, "time": 12894.119062423706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 401040, "time": 12896.570059537888, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 401184, "time": 12901.035814285278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 401256, "time": 12903.057042598724, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 402040, "time": 12927.995974302292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402128, "time": 12930.940429925919, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 402232, "time": 12933.92846107483, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 402440, "time": 12940.349264144897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402496, "time": 12942.31401014328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402496, "time": 12942.34186387062, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 402776, "time": 12950.929893732071, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 402920, "time": 12955.385550260544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402968, "time": 12956.879050970078, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 403280, "time": 12966.778581619263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403432, "time": 12971.24336194992, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 403496, "time": 12973.242664575577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403520, "time": 12974.330275058746, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 403640, "time": 12977.813999414444, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 403664, "time": 12978.777344703674, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 403944, "time": 12987.198434829712, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 404496, "time": 13004.586621761322, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 404544, "time": 13006.0800075531, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404752, "time": 13012.523985147476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404864, "time": 13015.989454507828, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 405232, "time": 13027.420066356659, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405464, "time": 13034.507496356964, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 405640, "time": 13039.95132470131, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 405744, "time": 13043.407870054245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405832, "time": 13045.913113117218, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405864, "time": 13046.908346414566, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 405952, "time": 13049.898703575134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405976, "time": 13050.426373243332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 406008, "time": 13051.426096916199, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 406096, "time": 13054.384047746658, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 406536, "time": 13067.933544874191, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 406688, "time": 13072.85595202446, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 406760, "time": 13074.852208852768, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 406808, "time": 13076.337819099426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 406832, "time": 13077.33158659935, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 407064, "time": 13084.252148628235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407232, "time": 13089.674958467484, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 407248, "time": 13090.168773174286, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 407560, "time": 13099.684196710587, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 407568, "time": 13100.16111779213, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 407616, "time": 13101.643020391464, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 407728, "time": 13105.11355638504, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 407952, "time": 13112.080418586731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408144, "time": 13118.012394428253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408176, "time": 13119.004809617996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408224, "time": 13120.492960691452, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 408240, "time": 13120.992063760757, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 408344, "time": 13124.125747680664, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 408448, "time": 13127.561655282974, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 408760, "time": 13137.00014948845, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 408976, "time": 13143.892566680908, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 408984, "time": 13143.9226603508, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 409560, "time": 13161.873787164688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409696, "time": 13166.793595314026, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 409720, "time": 13167.330398321152, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 409880, "time": 13172.272730588913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409952, "time": 13174.724770069122, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 410040, "time": 13177.234618663788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 13178.944618940353, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 410072, "time": 13179.432736158371, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 410072, "time": 13179.995589256287, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 410072, "time": 13180.04534816742, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 410072, "time": 13180.534593582153, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 410072, "time": 13180.792645215988, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 410072, "time": 13180.84160733223, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 410072, "time": 13181.63032412529, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 410080, "time": 13182.105264902115, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 410224, "time": 13186.684048891068, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 410392, "time": 13191.646546125412, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 410464, "time": 13194.083280801773, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 410528, "time": 13196.0770175457, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 410552, "time": 13196.599784851074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410648, "time": 13199.542739391327, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 410760, "time": 13203.006533622742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410792, "time": 13203.998616695404, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 410960, "time": 13209.42801809311, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 411408, "time": 13223.437962532043, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 411432, "time": 13223.959141254425, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 411496, "time": 13225.96304178238, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 411816, "time": 13235.852548122406, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 411848, "time": 13236.83606338501, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 412024, "time": 13242.285262584686, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 412392, "time": 13253.855749130249, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412536, "time": 13258.309053659439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412776, "time": 13265.739558696747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412920, "time": 13270.196614027023, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 412960, "time": 13271.667799949646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 413176, "time": 13278.194564580917, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 413401, "time": 13286.120525836945, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.390542078499842, "train/action_min": 0.0, "train/action_std": 1.904954447890773, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0020257957237643292, "train/actor_opt_grad_steps": 24755.0, "train/actor_opt_loss": 17.186671151657297, "train/adv_mag": 0.021046133504973516, "train/adv_max": 0.02018814729620712, "train/adv_mean": 0.005160666266778152, "train/adv_min": -0.006971418406024124, "train/adv_std": 0.0034120956840313446, "train/cont_avg": 0.996389678030303, "train/cont_loss_mean": 0.0235639833163169, "train/cont_loss_std": 0.3198199739092914, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.52150908819179, "train/cont_pos_acc": 0.9999999882596912, "train/cont_pos_loss": 0.003641687361805728, "train/cont_pred": 0.9963626696003808, "train/cont_rate": 0.996389678030303, "train/dyn_loss_mean": 1.0000088672445278, "train/dyn_loss_std": 0.00024987059618014786, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.23621943237311724, "train/extr_critic_critic_opt_grad_steps": 24755.0, "train/extr_critic_critic_opt_loss": 8971.525486185094, "train/extr_critic_mag": 0.20556999577416313, "train/extr_critic_max": 0.20556999577416313, "train/extr_critic_mean": 0.19813983812175615, "train/extr_critic_min": 0.18977606176125883, "train/extr_critic_std": 0.0026798696753115047, "train/extr_return_normed_mag": 0.03536362803042537, "train/extr_return_normed_max": 0.03465509708180572, "train/extr_return_normed_mean": 0.01594401979294924, "train/extr_return_normed_min": 0.0023872947151010685, "train/extr_return_normed_std": 0.004550057712053372, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2220115800096531, "train/extr_return_raw_max": 0.2220115800096531, "train/extr_return_raw_mean": 0.20330051325186335, "train/extr_return_raw_min": 0.18974377764294845, "train/extr_return_raw_std": 0.004550057723812496, "train/extr_reward_mag": 0.012781627250440193, "train/extr_reward_max": 0.012781627250440193, "train/extr_reward_mean": 0.001255547018169609, "train/extr_reward_min": 6.303642735336766e-07, "train/extr_reward_std": 0.0025790815990984987, "train/image_loss_mean": 0.15575245015247904, "train/image_loss_std": 0.10960804607079487, "train/model_loss_mean": 0.7823995782269372, "train/model_loss_std": 0.39282367623063047, "train/model_opt_grad_norm": 27.713637569834134, "train/model_opt_grad_steps": 24731.010101010103, "train/model_opt_loss": 2744.95937278054, "train/model_opt_model_opt_grad_overflow": 0.005050505050505051, "train/model_opt_model_opt_grad_scale": 3497.4747474747473, "train/policy_entropy_mag": 1.7167903618379072, "train/policy_entropy_max": 1.7167903618379072, "train/policy_entropy_mean": 0.6465438794006001, "train/policy_entropy_min": 0.06590258484386434, "train/policy_entropy_std": 0.40314002244761493, "train/policy_logprob_mag": 6.519284026791351, "train/policy_logprob_max": -0.00879672005057636, "train/policy_logprob_mean": -0.6462235649426779, "train/policy_logprob_min": -6.519284026791351, "train/policy_logprob_std": 0.9619843592547407, "train/policy_randomness_mag": 0.8822557718464823, "train/policy_randomness_max": 0.8822557718464823, "train/policy_randomness_mean": 0.33225784864690566, "train/policy_randomness_min": 0.0338672310715974, "train/policy_randomness_std": 0.20717300188661825, "train/post_ent_mag": 77.50848411791253, "train/post_ent_max": 77.50848411791253, "train/post_ent_mean": 77.1343106356534, "train/post_ent_min": 76.74514146284623, "train/post_ent_std": 0.14060593403951085, "train/prior_ent_mag": 78.98772522897431, "train/prior_ent_max": 78.98772522897431, "train/prior_ent_mean": 76.62431223705562, "train/prior_ent_min": 74.25923599859681, "train/prior_ent_std": 0.7430439365632606, "train/rep_loss_mean": 1.0000088672445278, "train/rep_loss_std": 0.00024987059618014786, "train/reward_avg": 0.00021211258056361905, "train/reward_loss_mean": 0.003077799470794171, "train/reward_loss_std": 0.07654084088080892, "train/reward_max_data": 0.18181818181818182, "train/reward_max_pred": 0.008268164865898363, "train/reward_neg_acc": 0.9999999996989665, "train/reward_neg_loss": 0.0004057914698161326, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 6.517060628577845, "train/reward_pred": 0.00017814056811421507, "train/reward_rate": 0.00041429924242424244, "train_stats/mean_log_entropy": 0.5286577524607663, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.024495603516697884, "report/cont_loss_std": 0.31982019543647766, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.121526718139648, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004507248755544424, "report/cont_pred": 0.9954994320869446, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.13704735040664673, "report/image_loss_std": 0.09735497087240219, "report/model_loss_mean": 0.7618038654327393, "report/model_loss_std": 0.3335224986076355, "report/post_ent_mag": 73.58422088623047, "report/post_ent_max": 73.58422088623047, "report/post_ent_mean": 73.24551391601562, "report/post_ent_min": 72.81497192382812, "report/post_ent_std": 0.13759544491767883, "report/prior_ent_mag": 75.6018295288086, "report/prior_ent_max": 75.6018295288086, "report/prior_ent_mean": 73.56362915039062, "report/prior_ent_min": 71.22468566894531, "report/prior_ent_std": 0.8412585854530334, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0002608918584883213, "report/reward_loss_std": 0.0012828427134081721, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.007284283638000488, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0002608918584883213, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00011800648644566536, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.019668806344270706, "eval/cont_loss_std": 0.28617051243782043, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.2904486656188965, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004181696102023125, "eval/cont_pred": 0.9958270192146301, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18718677759170532, "eval/image_loss_std": 0.11391318589448929, "eval/model_loss_mean": 0.8201937675476074, "eval/model_loss_std": 0.6573107242584229, "eval/post_ent_mag": 73.55818939208984, "eval/post_ent_max": 73.55818939208984, "eval/post_ent_mean": 73.23062896728516, "eval/post_ent_min": 72.84175109863281, "eval/post_ent_std": 0.13207831978797913, "eval/prior_ent_mag": 75.50878143310547, "eval/prior_ent_max": 75.50878143310547, "eval/prior_ent_mean": 73.39167785644531, "eval/prior_ent_min": 70.75028991699219, "eval/prior_ent_std": 0.8915191888809204, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0003204345703125, "eval/reward_loss_mean": 0.013338128104805946, "eval/reward_loss_std": 0.4216971695423126, "eval/reward_max_data": 0.328125, "eval/reward_max_pred": 0.006978869438171387, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001536902564112097, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 13.501017570495605, "eval/reward_pred": 6.946641951799393e-05, "eval/reward_rate": 0.0009765625, "replay/size": 412897.0, "replay/inserts": 31664.0, "replay/samples": 31664.0, "replay/insert_wait_avg": 1.3766368872713355e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.90735213524046e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 96064.0, "eval_replay/inserts": 4976.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2527516417181377e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1473894119262695e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2664184570312, "timer/env.step_count": 3958.0, "timer/env.step_total": 40.77576780319214, "timer/env.step_frac": 0.040764907279493716, "timer/env.step_avg": 0.010302114149366381, "timer/env.step_min": 0.008892059326171875, "timer/env.step_max": 0.03655529022216797, "timer/replay._sample_count": 31664.0, "timer/replay._sample_total": 18.024304151535034, "timer/replay._sample_frac": 0.018019503423236546, "timer/replay._sample_avg": 0.0005692364878579786, "timer/replay._sample_min": 0.0004069805145263672, "timer/replay._sample_max": 0.012454509735107422, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4580.0, "timer/agent.policy_total": 51.935317039489746, "timer/agent.policy_frac": 0.051921484197783, "timer/agent.policy_avg": 0.011339588873251037, "timer/agent.policy_min": 0.009581565856933594, "timer/agent.policy_max": 0.09029579162597656, "timer/dataset_train_count": 1979.0, "timer/dataset_train_total": 0.24490761756896973, "timer/dataset_train_frac": 0.0002448423870379992, "timer/dataset_train_avg": 0.00012375321756895894, "timer/dataset_train_min": 0.00010895729064941406, "timer/dataset_train_max": 0.0006110668182373047, "timer/agent.train_count": 1979.0, "timer/agent.train_total": 894.2828047275543, "timer/agent.train_frac": 0.894044614740778, "timer/agent.train_avg": 0.4518862075429784, "timer/agent.train_min": 0.4407923221588135, "timer/agent.train_max": 0.7420194149017334, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4847683906555176, "timer/agent.report_frac": 0.0004846392738079729, "timer/agent.report_avg": 0.2423841953277588, "timer/agent.report_min": 0.2346041202545166, "timer/agent.report_max": 0.250164270401001, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 3.3608065844274277e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 31.654992445131963}
{"step": 413712, "time": 13295.76860833168, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 413720, "time": 13295.799364089966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 413872, "time": 13300.745634555817, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 413936, "time": 13302.716741085052, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 414072, "time": 13306.833574533463, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 414104, "time": 13307.821772098541, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 414160, "time": 13309.783165454865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414312, "time": 13314.282955408096, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 414336, "time": 13315.257920265198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414648, "time": 13324.646933317184, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 414704, "time": 13326.61807012558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414752, "time": 13328.11261844635, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 414792, "time": 13329.128573417664, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 415056, "time": 13337.626597166061, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 415088, "time": 13338.618790864944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 415304, "time": 13345.068342924118, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 415848, "time": 13361.763554573059, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 416008, "time": 13366.77732515335, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 416024, "time": 13367.273243427277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 416624, "time": 13385.978883981705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 416984, "time": 13396.936603784561, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 417016, "time": 13397.930270671844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417064, "time": 13399.404248952866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417320, "time": 13407.266189813614, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 417368, "time": 13408.74714255333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417616, "time": 13416.652373552322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417672, "time": 13418.1615152359, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 417728, "time": 13420.13235783577, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 417816, "time": 13423.163628339767, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 418160, "time": 13434.073370695114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418320, "time": 13438.99149274826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418336, "time": 13439.491975784302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418504, "time": 13444.422545194626, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 418512, "time": 13444.916051864624, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 418840, "time": 13454.841384410858, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 418984, "time": 13459.225805521011, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 419472, "time": 13474.534189939499, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 419928, "time": 13488.463480949402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 420040, "time": 13491.895961761475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 13492.81946516037, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 420056, "time": 13495.658440589905, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 420056, "time": 13495.762300729752, "eval_episode/length": 168.0, "eval_episode/score": 0.4749999940395355, "eval_episode/reward_rate": 0.005917159763313609}
{"step": 420056, "time": 13498.766382455826, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13498.775080680847, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13498.784494638443, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13498.794930458069, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13498.803010225296, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420472, "time": 13511.618582725525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 420528, "time": 13513.581805229187, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 420568, "time": 13514.695230722427, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 420632, "time": 13516.679564237595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421296, "time": 13537.210218191147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421376, "time": 13539.654722213745, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 421696, "time": 13549.607967615128, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 421784, "time": 13552.092639923096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421792, "time": 13552.559254646301, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 421880, "time": 13555.020175933838, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 422016, "time": 13559.382639169693, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 422240, "time": 13566.226344108582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422352, "time": 13569.653350114822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422384, "time": 13570.639008283615, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 422488, "time": 13573.650006055832, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 422648, "time": 13578.610777139664, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 422808, "time": 13583.539469003677, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 422840, "time": 13584.551488399506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422912, "time": 13586.983014822006, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 423280, "time": 13598.215121507645, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 423360, "time": 13600.657751321793, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 423640, "time": 13609.179357767105, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 423944, "time": 13618.453284025192, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 424008, "time": 13620.430826425552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424192, "time": 13626.297206401825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424320, "time": 13630.249248743057, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 424384, "time": 13632.232247114182, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 424552, "time": 13637.325130224228, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424584, "time": 13638.316941022873, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 424656, "time": 13640.76856803894, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 424696, "time": 13641.77014374733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424912, "time": 13648.587058544159, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 425024, "time": 13651.999245643616, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 425064, "time": 13652.997150421143, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 425120, "time": 13654.960312843323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 425224, "time": 13657.903662443161, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 425576, "time": 13668.824404716492, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 426008, "time": 13682.704938173294, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 426848, "time": 13708.696994543076, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 426864, "time": 13709.18766117096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 426968, "time": 13712.152606964111, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427000, "time": 13713.173038959503, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 427224, "time": 13719.997346878052, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427336, "time": 13723.425427675247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427432, "time": 13726.508845567703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427536, "time": 13729.913393735886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 428240, "time": 13751.369647741318, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 428424, "time": 13756.922459602356, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 428656, "time": 13764.271417856216, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 428936, "time": 13772.665601015091, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 429176, "time": 13779.98555278778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429280, "time": 13783.407636404037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429312, "time": 13784.531264543533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429744, "time": 13797.712561130524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429848, "time": 13800.642474889755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429872, "time": 13801.612914085388, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 429880, "time": 13801.64043021202, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 13807.463487386703, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 430040, "time": 13807.491384744644, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 430040, "time": 13808.02421927452, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 430040, "time": 13808.195882797241, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 430040, "time": 13808.312157154083, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 430040, "time": 13808.535062074661, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 430040, "time": 13808.733645439148, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 430040, "time": 13810.280037641525, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 430224, "time": 13816.177434921265, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 430320, "time": 13819.093692541122, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 430392, "time": 13821.075103282928, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 430616, "time": 13827.87838768959, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 430736, "time": 13831.777112007141, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 431248, "time": 13847.558339595795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 431392, "time": 13852.003308296204, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 431592, "time": 13857.931252002716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 431640, "time": 13859.41346001625, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 431984, "time": 13870.14113497734, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 432184, "time": 13876.192271471024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 432192, "time": 13876.658596515656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 432536, "time": 13886.932090997696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 432560, "time": 13887.88436794281, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 432656, "time": 13890.843242168427, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 432680, "time": 13891.362174272537, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 432704, "time": 13892.333308458328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 432888, "time": 13897.73996925354, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 433064, "time": 13903.113193750381, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 433256, "time": 13909.08075094223, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 433352, "time": 13911.983696937561, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 433952, "time": 13930.575358867645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 434464, "time": 13946.917366743088, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 434496, "time": 13947.897571325302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 434848, "time": 13958.698662757874, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 434968, "time": 13962.121979236603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435016, "time": 13963.680162191391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435200, "time": 13969.615743160248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435664, "time": 13983.788675069809, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436168, "time": 13999.153798818588, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 436264, "time": 14002.087793827057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436368, "time": 14005.509793996811, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 436456, "time": 14007.998056173325, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 436776, "time": 14017.816324710846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436808, "time": 14018.809932231903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436944, "time": 14023.200907707214, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 437120, "time": 14028.666015148163, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 437328, "time": 14035.01869893074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 438480, "time": 14070.377866506577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 438680, "time": 14076.302234172821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 438768, "time": 14079.215738296509, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 439000, "time": 14086.221532821655, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 439088, "time": 14089.113328695297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 439256, "time": 14094.01422548294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 439272, "time": 14094.506635904312, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 439432, "time": 14099.39211010933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 439632, "time": 14105.72747683525, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 439752, "time": 14109.170209646225, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 439816, "time": 14111.167464971542, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 439944, "time": 14115.189728736877, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 14118.945754289627, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 440024, "time": 14119.31826710701, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 440024, "time": 14119.784553289413, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 440024, "time": 14120.562062740326, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 440024, "time": 14122.393505334854, "eval_episode/length": 232.0, "eval_episode/score": 0.2750000059604645, "eval_episode/reward_rate": 0.004291845493562232}
{"step": 440024, "time": 14122.461956262589, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 440024, "time": 14122.784858465195, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 440024, "time": 14123.571274280548, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14123.608833789825, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14123.617574691772, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 441080, "time": 14157.175360441208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441416, "time": 14167.391200780869, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 441568, "time": 14172.24780011177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441584, "time": 14172.741134881973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441648, "time": 14174.762368917465, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 441720, "time": 14176.739114761353, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 441744, "time": 14177.702857494354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441872, "time": 14181.663367271423, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 442064, "time": 14187.53135895729, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 442128, "time": 14189.48302078247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 442200, "time": 14191.4740588665, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 442336, "time": 14195.822729110718, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 442576, "time": 14203.834885835648, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 442984, "time": 14216.116835594177, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 443344, "time": 14227.3770840168, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 443352, "time": 14227.406674861908, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 443696, "time": 14238.191870689392, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 443896, "time": 14244.108681201935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444032, "time": 14248.488597393036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444232, "time": 14254.390997886658, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 444376, "time": 14258.801424264908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444648, "time": 14267.2158806324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444888, "time": 14274.540968894958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 445241, "time": 14286.332871675491, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2758531426664574, "train/action_min": 0.0, "train/action_std": 1.894967595536505, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0020953546326148826, "train/actor_opt_grad_steps": 26740.0, "train/actor_opt_loss": 8.583898791715727, "train/adv_mag": 0.02078006794704265, "train/adv_max": 0.02032664163627816, "train/adv_mean": 0.005355225299472889, "train/adv_min": -0.011007325283846065, "train/adv_std": 0.003907805179999252, "train/cont_avg": 0.9961918969849246, "train/cont_loss_mean": 0.02398593269695701, "train/cont_loss_std": 0.31963319702766574, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.337667449396484, "train/cont_pos_acc": 0.999999982627792, "train/cont_pos_loss": 0.0037626705434285665, "train/cont_pred": 0.9962378997898581, "train/cont_rate": 0.9961918969849246, "train/dyn_loss_mean": 1.00000572623919, "train/dyn_loss_std": 0.00016179317655275815, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.23800551551089963, "train/extr_critic_critic_opt_grad_steps": 26740.0, "train/extr_critic_critic_opt_loss": 9312.594230306808, "train/extr_critic_mag": 0.4268925136058175, "train/extr_critic_max": 0.4268925136058175, "train/extr_critic_mean": 0.4175563369264555, "train/extr_critic_min": 0.4030512020216515, "train/extr_critic_std": 0.004076218270537579, "train/extr_return_normed_mag": 0.038288200171149554, "train/extr_return_normed_max": 0.038276646304969214, "train/extr_return_normed_mean": 0.018841596148719768, "train/extr_return_normed_min": 0.00023019553428918274, "train/extr_return_normed_std": 0.005760951325690477, "train/extr_return_rate": 0.041347363984673556, "train/extr_return_raw_mag": 0.44234656404011213, "train/extr_return_raw_max": 0.44234656404011213, "train/extr_return_raw_mean": 0.4229115366037168, "train/extr_return_raw_min": 0.4043001132694321, "train/extr_return_raw_std": 0.00576095132335047, "train/extr_reward_mag": 0.012003411599739113, "train/extr_reward_max": 0.012003411599739113, "train/extr_reward_mean": 0.001901319642415523, "train/extr_reward_min": 5.013978661005221e-07, "train/extr_reward_std": 0.003588410326041019, "train/image_loss_mean": 0.1465559906546195, "train/image_loss_std": 0.11113938356014952, "train/model_loss_mean": 0.7747492167218846, "train/model_loss_std": 0.40503536239640797, "train/model_opt_grad_norm": 26.516782755827784, "train/model_opt_grad_steps": 26714.909547738695, "train/model_opt_loss": 3071.824569625471, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3969.8492462311556, "train/policy_entropy_mag": 1.5548145657208696, "train/policy_entropy_max": 1.5548145657208696, "train/policy_entropy_mean": 0.25778000416168617, "train/policy_entropy_min": 0.06475218160817371, "train/policy_entropy_std": 0.28292291390536417, "train/policy_logprob_mag": 6.5504270630266195, "train/policy_logprob_max": -0.008618475827177865, "train/policy_logprob_mean": -0.25722329071418726, "train/policy_logprob_min": -6.5504270630266195, "train/policy_logprob_std": 0.7967612887147683, "train/policy_randomness_mag": 0.79901667455932, "train/policy_randomness_max": 0.79901667455932, "train/policy_randomness_mean": 0.13247272349781727, "train/policy_randomness_min": 0.03327604078093366, "train/policy_randomness_std": 0.14539362598753455, "train/post_ent_mag": 72.08245715424044, "train/post_ent_max": 72.08245715424044, "train/post_ent_mean": 71.5788274410382, "train/post_ent_min": 71.00097322703606, "train/post_ent_std": 0.18758769033841752, "train/prior_ent_mag": 73.65646906713745, "train/prior_ent_max": 73.65646906713745, "train/prior_ent_mean": 70.90924950221076, "train/prior_ent_min": 68.13635378506915, "train/prior_ent_std": 0.890766798850879, "train/rep_loss_mean": 1.00000572623919, "train/rep_loss_std": 0.00016179317655275815, "train/reward_avg": 0.0003716396925085805, "train/reward_loss_mean": 0.004203834800264943, "train/reward_loss_std": 0.09763894069807641, "train/reward_max_data": 0.29678077939616976, "train/reward_max_pred": 0.010601380961624222, "train/reward_neg_acc": 0.9999999994009583, "train/reward_neg_loss": 0.0006222030234636608, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.966218371967693, "train/reward_pred": 0.0003013652357408524, "train/reward_rate": 0.0006085113065326633, "train_stats/mean_log_entropy": 0.2097338813208264, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.04218204319477081, "report/cont_loss_std": 0.4710409343242645, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.641418933868408, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003642558353021741, "report/cont_pred": 0.9963542222976685, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.12824614346027374, "report/image_loss_std": 0.11004895716905594, "report/model_loss_mean": 0.7841335535049438, "report/model_loss_std": 0.6692603230476379, "report/post_ent_mag": 69.65179443359375, "report/post_ent_max": 69.65179443359375, "report/post_ent_mean": 69.01042175292969, "report/post_ent_min": 68.33351135253906, "report/post_ent_std": 0.22114384174346924, "report/prior_ent_mag": 70.48645782470703, "report/prior_ent_max": 70.48645782470703, "report/prior_ent_mean": 67.96619415283203, "report/prior_ent_min": 64.90087127685547, "report/prior_ent_std": 1.0486711263656616, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0012756347423419356, "report/reward_loss_mean": 0.013705315068364143, "report/reward_loss_std": 0.2946311831474304, "report/reward_max_data": 0.9156249761581421, "report/reward_max_pred": 0.01213383674621582, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0008158898563124239, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 6.600201606750488, "report/reward_pred": 0.00038778933230787516, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.023523380979895592, "eval/cont_loss_std": 0.3242204785346985, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.191418647766113, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0032571246847510338, "eval/cont_pred": 0.9967402219772339, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16666008532047272, "eval/image_loss_std": 0.11168880760669708, "eval/model_loss_mean": 0.7902824878692627, "eval/model_loss_std": 0.3363419771194458, "eval/post_ent_mag": 69.52425384521484, "eval/post_ent_max": 69.52425384521484, "eval/post_ent_mean": 68.94233703613281, "eval/post_ent_min": 68.34066772460938, "eval/post_ent_std": 0.2248312383890152, "eval/prior_ent_mag": 70.52020263671875, "eval/prior_ent_max": 70.52020263671875, "eval/prior_ent_mean": 67.68437194824219, "eval/prior_ent_min": 64.756103515625, "eval/prior_ent_std": 1.085881233215332, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 9.902939200401306e-05, "eval/reward_loss_std": 0.0007747307536192238, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.008210420608520508, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 9.902939200401306e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.515727050602436e-05, "eval/reward_rate": 0.0, "replay/size": 444737.0, "replay/inserts": 31840.0, "replay/samples": 31840.0, "replay/insert_wait_avg": 1.3494985786514665e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.790362425185928e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6064.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2102966887340696e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2018392086029, "timer/env.step_count": 3980.0, "timer/env.step_total": 39.90523838996887, "timer/env.step_frac": 0.03989718557360721, "timer/env.step_avg": 0.010026441806524842, "timer/env.step_min": 0.008191108703613281, "timer/env.step_max": 0.04940605163574219, "timer/replay._sample_count": 31840.0, "timer/replay._sample_total": 17.563706874847412, "timer/replay._sample_frac": 0.017560162545536284, "timer/replay._sample_avg": 0.0005516239596371675, "timer/replay._sample_min": 0.00040268898010253906, "timer/replay._sample_max": 0.013000965118408203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4738.0, "timer/agent.policy_total": 52.814799547195435, "timer/agent.policy_frac": 0.05280414160104373, "timer/agent.policy_avg": 0.011147066177120185, "timer/agent.policy_min": 0.009112834930419922, "timer/agent.policy_max": 0.09761714935302734, "timer/dataset_train_count": 1990.0, "timer/dataset_train_total": 0.23530292510986328, "timer/dataset_train_frac": 0.00023525544133776413, "timer/dataset_train_avg": 0.00011824267593460466, "timer/dataset_train_min": 0.00010061264038085938, "timer/dataset_train_max": 0.0007531642913818359, "timer/agent.train_count": 1990.0, "timer/agent.train_total": 893.438606262207, "timer/agent.train_frac": 0.8932583117114932, "timer/agent.train_avg": 0.4489641237498528, "timer/agent.train_min": 0.43553924560546875, "timer/agent.train_max": 1.7423865795135498, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4772477149963379, "timer/agent.report_frac": 0.0004771514071339382, "timer/agent.report_avg": 0.23862385749816895, "timer/agent.report_min": 0.23087406158447266, "timer/agent.report_max": 0.24637365341186523, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.456371765630844e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 31.83305877107945}
{"step": 445296, "time": 14287.999320268631, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 445336, "time": 14288.993683576584, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 445456, "time": 14292.894824266434, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 445560, "time": 14296.002051591873, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 445704, "time": 14300.36709356308, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 445784, "time": 14302.83716583252, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 445952, "time": 14308.203203439713, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 446008, "time": 14309.72763800621, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446312, "time": 14319.047605514526, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 446528, "time": 14326.009669542313, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 446560, "time": 14326.990881443024, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 446688, "time": 14330.91355228424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446704, "time": 14331.405303955078, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 446944, "time": 14338.721178531647, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 446960, "time": 14339.220129013062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 447432, "time": 14353.484968185425, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 447576, "time": 14358.049350976944, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 447608, "time": 14359.029666662216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 447640, "time": 14360.0353307724, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 447872, "time": 14367.358087301254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448120, "time": 14374.755698680878, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 448152, "time": 14375.737347364426, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 448872, "time": 14397.885401725769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449000, "time": 14401.8132584095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449072, "time": 14404.25626540184, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 449256, "time": 14409.675461769104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449272, "time": 14410.172642230988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449320, "time": 14411.637672424316, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 449648, "time": 14422.042734861374, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 449696, "time": 14423.514066934586, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 449760, "time": 14425.484312295914, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 449888, "time": 14429.411482334137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449920, "time": 14430.415104150772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 14433.636784791946, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 450008, "time": 14433.664602518082, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 450008, "time": 14434.213253259659, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 450008, "time": 14435.290541410446, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 450008, "time": 14435.299094438553, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 450008, "time": 14435.846659898758, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 450008, "time": 14435.894246339798, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 450008, "time": 14436.390455722809, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 450392, "time": 14448.345785617828, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 450464, "time": 14450.813232660294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450496, "time": 14451.798398256302, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 450512, "time": 14452.308240652084, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 450624, "time": 14456.201379776001, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 450952, "time": 14465.934903144836, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 451048, "time": 14468.866857767105, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 451192, "time": 14473.253221273422, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 451232, "time": 14474.792114019394, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 451432, "time": 14480.644872426987, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 451568, "time": 14484.996588468552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451584, "time": 14485.489846229553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451720, "time": 14489.401641845703, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 452200, "time": 14504.094956874847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452512, "time": 14513.7554936409, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 452704, "time": 14519.579488277435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 453264, "time": 14536.681139469147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 453368, "time": 14539.604035377502, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 453376, "time": 14540.073137283325, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 453504, "time": 14543.985720396042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 453544, "time": 14544.99141216278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 453848, "time": 14554.258600950241, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 453880, "time": 14555.255496740341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 453896, "time": 14555.744351387024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 453920, "time": 14556.69081401825, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 454192, "time": 14565.086130142212, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 454312, "time": 14568.50024986267, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 454416, "time": 14571.888201475143, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 454512, "time": 14574.841831684113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454544, "time": 14575.815903902054, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 454832, "time": 14584.550573587418, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 454840, "time": 14584.577795028687, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 454936, "time": 14587.475960969925, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 455632, "time": 14608.90983915329, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 455816, "time": 14614.304873466492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455856, "time": 14615.74125957489, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 456728, "time": 14642.125626564026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 456824, "time": 14645.079347133636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 456856, "time": 14646.06303858757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457144, "time": 14654.937554597855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457152, "time": 14655.408514022827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457800, "time": 14674.80741238594, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 457880, "time": 14677.253068685532, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 457944, "time": 14679.196936130524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 458128, "time": 14685.139218568802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 458168, "time": 14686.134312152863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 458280, "time": 14689.566938877106, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 458392, "time": 14693.013389825821, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 458456, "time": 14694.957948207855, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 458528, "time": 14697.373659610748, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 458664, "time": 14701.276881694794, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 458880, "time": 14708.608031988144, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 459040, "time": 14713.49497127533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459216, "time": 14718.96810388565, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 459456, "time": 14726.23231959343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459664, "time": 14732.552373170853, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 459880, "time": 14738.877695798874, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 459880, "time": 14738.888812303543, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 14747.002884864807, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 460096, "time": 14747.636642932892, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 460096, "time": 14747.68114233017, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 460096, "time": 14748.172497034073, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 460096, "time": 14748.53866481781, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 460096, "time": 14749.240177631378, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 460096, "time": 14749.666055440903, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 460096, "time": 14751.020701885223, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 460112, "time": 14751.528771877289, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460544, "time": 14764.621554136276, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 460648, "time": 14767.565633058548, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 460704, "time": 14769.500477552414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460768, "time": 14771.453868865967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460840, "time": 14773.423885583878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460920, "time": 14776.020510911942, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 461184, "time": 14784.28253865242, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 461600, "time": 14797.120831489563, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 461768, "time": 14802.064016103745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 461976, "time": 14808.567771434784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 462328, "time": 14819.300992965698, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 462856, "time": 14835.519721984863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 462960, "time": 14838.897210359573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463152, "time": 14844.744489431381, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463232, "time": 14847.17367720604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463496, "time": 14855.015079021454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463808, "time": 14864.84080338478, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 463808, "time": 14864.8541533947, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 463912, "time": 14867.795812368393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463952, "time": 14869.261542081833, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 464288, "time": 14879.493514537811, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464536, "time": 14886.809905529022, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 464640, "time": 14890.204337120056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464768, "time": 14894.222762823105, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 464888, "time": 14897.6350979805, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 464912, "time": 14898.599568128586, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 465160, "time": 14905.899894714355, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 465168, "time": 14906.368455171585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 465768, "time": 14924.57912325859, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 465776, "time": 14925.050354480743, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 466040, "time": 14932.86481666565, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 466120, "time": 14935.288690805435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466224, "time": 14938.67588353157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466744, "time": 14954.391250610352, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 466848, "time": 14957.788354635239, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466848, "time": 14957.798172235489, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 466952, "time": 14960.978226423264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 467024, "time": 14963.663700342178, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 467200, "time": 14969.006388187408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 467536, "time": 14979.195791482925, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 467808, "time": 14987.60234093666, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 468088, "time": 14995.854809761047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468320, "time": 15003.109685659409, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 468432, "time": 15006.521702289581, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468536, "time": 15009.443039655685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469016, "time": 15024.228377103806, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 469032, "time": 15024.720535039902, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 469056, "time": 15025.666510820389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469160, "time": 15028.623795747757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469264, "time": 15032.013833284378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469848, "time": 15049.654566287994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469864, "time": 15050.150027036667, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 470072, "time": 15056.47305393219, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 15057.99464392662, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 470080, "time": 15058.040246248245, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 470080, "time": 15059.00082397461, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 470080, "time": 15059.465074300766, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 470080, "time": 15059.554786682129, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 470080, "time": 15061.861037254333, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 470080, "time": 15062.276322603226, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 470080, "time": 15063.135037899017, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 470232, "time": 15067.547044038773, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 470240, "time": 15068.01285624504, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 470272, "time": 15068.984382867813, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 470632, "time": 15079.827777147293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470848, "time": 15086.601523160934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470920, "time": 15088.559115409851, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 471328, "time": 15101.147018909454, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 472136, "time": 15125.650528430939, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 472176, "time": 15127.104862213135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472384, "time": 15133.456827402115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472392, "time": 15133.48626279831, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 472552, "time": 15138.472760677338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472584, "time": 15139.454941749573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472944, "time": 15150.629786252975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472960, "time": 15151.117619514465, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 472976, "time": 15151.613181352615, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 472992, "time": 15152.102690458298, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 473232, "time": 15159.384547472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473656, "time": 15172.140923261642, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 473680, "time": 15173.096084356308, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 473760, "time": 15175.529238939285, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 473896, "time": 15179.436774969101, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 474056, "time": 15184.283649682999, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 474152, "time": 15187.20227432251, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 474608, "time": 15201.473236322403, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 474896, "time": 15210.249388933182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475288, "time": 15222.462114334106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475320, "time": 15223.458873033524, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 475544, "time": 15230.40256524086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475808, "time": 15238.618690252304, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 475928, "time": 15242.03829908371, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 475968, "time": 15243.501382112503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475992, "time": 15244.017697811127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476208, "time": 15250.814679145813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476312, "time": 15253.856174707413, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 476336, "time": 15254.851204156876, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 476600, "time": 15262.697705745697, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 476696, "time": 15265.623076915741, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 476768, "time": 15268.048505544662, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 477064, "time": 15276.795107364655, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 477208, "time": 15281.227021455765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477353, "time": 15286.724348783493, "train_stats/mean_log_entropy": 0.18100258175243614, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.247012939453125, "train/action_min": 0.0, "train/action_std": 1.902315039038658, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.001481166582670994, "train/actor_opt_grad_steps": 28735.0, "train/actor_opt_loss": 1.5237941211275756, "train/adv_mag": 0.017828642427921294, "train/adv_max": 0.015867049396038054, "train/adv_mean": 0.0028055004533780446, "train/adv_min": -0.013592078238725663, "train/adv_std": 0.0034468515118351206, "train/cont_avg": 0.9960205078125, "train/cont_loss_mean": 0.024470055530546233, "train/cont_loss_std": 0.3186810781771783, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.169140117509024, "train/cont_pos_acc": 0.9999999833106995, "train/cont_pos_loss": 0.003946867461781949, "train/cont_pred": 0.9960503461956978, "train/cont_rate": 0.9960205078125, "train/dyn_loss_mean": 1.0000673997402192, "train/dyn_loss_std": 0.0005459701726977073, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.17382590909255669, "train/extr_critic_critic_opt_grad_steps": 28735.0, "train/extr_critic_critic_opt_loss": 7078.240454101562, "train/extr_critic_mag": 0.5734675806760788, "train/extr_critic_max": 0.5734675806760788, "train/extr_critic_mean": 0.565299813747406, "train/extr_critic_min": 0.5508172452449799, "train/extr_critic_std": 0.003602267517708242, "train/extr_return_normed_mag": 0.032226675301790235, "train/extr_return_normed_max": 0.0322201843559742, "train/extr_return_normed_mean": 0.014092860426171683, "train/extr_return_normed_min": -0.004898381978273391, "train/extr_return_normed_std": 0.005407617501914501, "train/extr_return_rate": 0.9889655008912086, "train/extr_return_raw_mag": 0.5862325915694236, "train/extr_return_raw_max": 0.5862325915694236, "train/extr_return_raw_mean": 0.5681052981317043, "train/extr_return_raw_min": 0.549114025235176, "train/extr_return_raw_std": 0.005407617511227727, "train/extr_reward_mag": 0.013046196699142455, "train/extr_reward_max": 0.013046196699142455, "train/extr_reward_mean": 0.001825353678141255, "train/extr_reward_min": 3.594160079956055e-07, "train/extr_reward_std": 0.0036094149388372896, "train/image_loss_mean": 0.13417231373488903, "train/image_loss_std": 0.10969992883503438, "train/model_loss_mean": 0.7637530449032783, "train/model_loss_std": 0.4134577859565616, "train/model_opt_grad_norm": 26.154561514854432, "train/model_opt_grad_steps": 28707.79, "train/model_opt_loss": 2479.1798724365235, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3250.0, "train/policy_entropy_mag": 1.5377004277706146, "train/policy_entropy_max": 1.5377004277706146, "train/policy_entropy_mean": 0.2461975622177124, "train/policy_entropy_min": 0.06471272557973862, "train/policy_entropy_std": 0.2759061589092016, "train/policy_logprob_mag": 6.550883235931397, "train/policy_logprob_max": -0.008612388395704329, "train/policy_logprob_mean": -0.24642279654741286, "train/policy_logprob_min": -6.550883235931397, "train/policy_logprob_std": 0.7818772971630097, "train/policy_randomness_mag": 0.7902217477560043, "train/policy_randomness_max": 0.7902217477560043, "train/policy_randomness_mean": 0.12652052614837886, "train/policy_randomness_min": 0.03325576424598694, "train/policy_randomness_std": 0.1417877262085676, "train/post_ent_mag": 67.78307514190674, "train/post_ent_max": 67.78307514190674, "train/post_ent_mean": 67.16543281555175, "train/post_ent_min": 66.55175640106201, "train/post_ent_std": 0.20780722975730895, "train/prior_ent_mag": 70.90227558135986, "train/prior_ent_max": 70.90227558135986, "train/prior_ent_mean": 68.77931388854981, "train/prior_ent_min": 66.51132558822631, "train/prior_ent_std": 0.6918853989243507, "train/rep_loss_mean": 1.0000673997402192, "train/rep_loss_std": 0.0005459701726977073, "train/reward_avg": 0.000520645140131819, "train/reward_loss_mean": 0.005070211170241237, "train/reward_loss_std": 0.11053074386232765, "train/reward_max_data": 0.37332812301814555, "train/reward_max_pred": 0.011755414605140686, "train/reward_neg_acc": 0.9999999994039536, "train/reward_neg_loss": 0.0007745580164919374, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.519581971849714, "train/reward_pred": 0.0003890158934518695, "train/reward_rate": 0.0007763671875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.01762412115931511, "report/cont_loss_std": 0.22853606939315796, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.193694591522217, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005353590007871389, "report/cont_pred": 0.9946411848068237, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10448834300041199, "report/image_loss_std": 0.10267875343561172, "report/model_loss_mean": 0.7289271950721741, "report/model_loss_std": 0.3769553303718567, "report/post_ent_mag": 66.46192932128906, "report/post_ent_max": 66.46192932128906, "report/post_ent_mean": 65.75274658203125, "report/post_ent_min": 65.09373474121094, "report/post_ent_std": 0.22192008793354034, "report/prior_ent_mag": 70.03828430175781, "report/prior_ent_max": 70.03828430175781, "report/prior_ent_mean": 68.2708511352539, "report/prior_ent_min": 65.64622497558594, "report/prior_ent_std": 0.7385138869285583, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0003875732363667339, "report/reward_loss_mean": 0.0068147131241858006, "report/reward_loss_std": 0.1840260624885559, "report/reward_max_data": 0.3968749940395355, "report/reward_max_pred": 0.0100250244140625, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.001062377355992794, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.891454219818115, "report/reward_pred": 0.0005247588269412518, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.03291030600667, "eval/cont_loss_std": 0.4068717062473297, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.833516597747803, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0044480604119598866, "eval/cont_pred": 0.9955974817276001, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18113331496715546, "eval/image_loss_std": 0.10618975013494492, "eval/model_loss_mean": 0.8141124844551086, "eval/model_loss_std": 0.4215948283672333, "eval/post_ent_mag": 66.4738540649414, "eval/post_ent_max": 66.4738540649414, "eval/post_ent_mean": 65.67327880859375, "eval/post_ent_min": 64.98877716064453, "eval/post_ent_std": 0.23197998106479645, "eval/prior_ent_mag": 69.91572570800781, "eval/prior_ent_max": 69.91572570800781, "eval/prior_ent_mean": 67.58799743652344, "eval/prior_ent_min": 65.30734252929688, "eval/prior_ent_std": 0.7767810821533203, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 6.884895265102386e-05, "eval/reward_loss_std": 0.0006849518395029008, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00876462459564209, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 6.884895265102386e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.230723086744547e-05, "eval/reward_rate": 0.0, "replay/size": 476849.0, "replay/inserts": 32112.0, "replay/samples": 32112.0, "replay/insert_wait_avg": 1.3674915163565703e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.669791897791325e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5536.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.202816563534599e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1175870895385742e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.370697259903, "timer/env.step_count": 4014.0, "timer/env.step_total": 39.919548749923706, "timer/env.step_frac": 0.03990475616615582, "timer/env.step_avg": 0.00994507940954751, "timer/env.step_min": 0.007972955703735352, "timer/env.step_max": 0.037139892578125, "timer/replay._sample_count": 32112.0, "timer/replay._sample_total": 17.614301919937134, "timer/replay._sample_frac": 0.01760777476607836, "timer/replay._sample_avg": 0.0005485270901823971, "timer/replay._sample_min": 0.00038123130798339844, "timer/replay._sample_max": 0.011204242706298828, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4706.0, "timer/agent.policy_total": 51.804033279418945, "timer/agent.policy_frac": 0.05178483678231922, "timer/agent.policy_avg": 0.01100808186982978, "timer/agent.policy_min": 0.009142398834228516, "timer/agent.policy_max": 0.08893918991088867, "timer/dataset_train_count": 2007.0, "timer/dataset_train_total": 0.23203563690185547, "timer/dataset_train_frac": 0.00023194965380075609, "timer/dataset_train_avg": 0.00011561317234771075, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.0004477500915527344, "timer/agent.train_count": 2007.0, "timer/agent.train_total": 895.262745141983, "timer/agent.train_frac": 0.8949309966737139, "timer/agent.train_avg": 0.4460701271260503, "timer/agent.train_min": 0.4350261688232422, "timer/agent.train_max": 0.6962177753448486, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48099231719970703, "timer/agent.report_frac": 0.0004808140807374549, "timer/agent.report_avg": 0.24049615859985352, "timer/agent.report_min": 0.23299407958984375, "timer/agent.report_max": 0.24799823760986328, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.600120544433594e-05, "timer/dataset_eval_frac": 3.598786484144945e-08, "timer/dataset_eval_avg": 3.600120544433594e-05, "timer/dataset_eval_min": 3.600120544433594e-05, "timer/dataset_eval_max": 3.600120544433594e-05, "fps": 32.09954497056829}
{"step": 477600, "time": 15294.30807185173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477712, "time": 15297.724552631378, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 477856, "time": 15302.093748807907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477856, "time": 15302.155617713928, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 478304, "time": 15315.922532320023, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 478520, "time": 15322.28093457222, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 478648, "time": 15326.166434764862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478904, "time": 15333.989383220673, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 479008, "time": 15337.37768983841, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479064, "time": 15338.857908010483, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 479080, "time": 15339.353058815002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479448, "time": 15350.676253795624, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 479912, "time": 15364.769023418427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480024, "time": 15368.231061935425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 15370.296837091446, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 480064, "time": 15372.274353027344, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 480064, "time": 15372.823053836823, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 480064, "time": 15374.238190889359, "eval_episode/length": 204.0, "eval_episode/score": 0.36250001192092896, "eval_episode/reward_rate": 0.004878048780487805}
{"step": 480064, "time": 15376.012171268463, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15376.028852701187, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15376.03639793396, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15376.044096946716, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15376.052547454834, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480616, "time": 15392.668260097504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480736, "time": 15396.5421936512, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 480832, "time": 15399.471046924591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 481024, "time": 15405.469235181808, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 481152, "time": 15409.369701862335, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 481216, "time": 15411.321075201035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 481376, "time": 15416.23772740364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 481392, "time": 15416.753191232681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 481624, "time": 15423.573255062103, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 481680, "time": 15425.48945260048, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 481752, "time": 15427.45377612114, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 481760, "time": 15427.923283338547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482048, "time": 15436.809387207031, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 482272, "time": 15443.628952980042, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 482520, "time": 15450.98349738121, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 482928, "time": 15463.670240402222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 483464, "time": 15480.27278637886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 483480, "time": 15480.785987854004, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 483688, "time": 15487.115083694458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 483704, "time": 15487.604023218155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 483944, "time": 15495.028672218323, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 484064, "time": 15498.901135921478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484152, "time": 15501.372223854065, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 484312, "time": 15506.237050533295, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 484360, "time": 15507.692413568497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484456, "time": 15510.62042927742, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 484584, "time": 15514.510207891464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484864, "time": 15523.246704816818, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 485072, "time": 15529.695732831955, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 485104, "time": 15530.660915851593, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 485240, "time": 15534.566048383713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485520, "time": 15543.323000907898, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 485608, "time": 15545.83211183548, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 485808, "time": 15552.175290346146, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 486016, "time": 15558.59251832962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 486544, "time": 15574.719757080078, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 486544, "time": 15574.748637676239, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 486624, "time": 15577.180269002914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 486624, "time": 15577.19225525856, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 486672, "time": 15578.671340227127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 486904, "time": 15585.62184882164, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 487240, "time": 15595.780695438385, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 487400, "time": 15600.6270403862, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 487416, "time": 15601.120041847229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487456, "time": 15602.555416345596, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 487552, "time": 15605.478778123856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487696, "time": 15609.852073192596, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 487832, "time": 15613.886497735977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 488080, "time": 15621.657968044281, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 488208, "time": 15625.562729358673, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 488272, "time": 15627.523154735565, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 488584, "time": 15636.745614528656, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 488856, "time": 15645.12568449974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489184, "time": 15655.340826034546, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 489216, "time": 15656.320140838623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489368, "time": 15660.728781461716, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 489424, "time": 15662.666484832764, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 489728, "time": 15671.89564538002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489768, "time": 15672.91643691063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490008, "time": 15680.35040974617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490016, "time": 15680.830466270447, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 15683.29405450821, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 490048, "time": 15684.106022834778, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 490048, "time": 15684.39491033554, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 490048, "time": 15684.904740810394, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 490048, "time": 15686.602299451828, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 490048, "time": 15686.710790157318, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 490048, "time": 15687.699411153793, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15687.70923614502, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15687.718343019485, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15687.728074550629, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15687.73775267601, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490392, "time": 15697.955832719803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490520, "time": 15701.835337638855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490704, "time": 15707.773980379105, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 490728, "time": 15708.279578208923, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 490896, "time": 15713.609345197678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490984, "time": 15716.075768709183, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 491448, "time": 15730.202545166016, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 491496, "time": 15731.67494058609, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 491536, "time": 15733.633504152298, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 491704, "time": 15738.597562789917, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 491736, "time": 15739.584657907486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491808, "time": 15742.012558221817, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 491832, "time": 15742.525006532669, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 492040, "time": 15748.861268043518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492080, "time": 15750.295766115189, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492216, "time": 15754.19981265068, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 492360, "time": 15758.571331501007, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 492512, "time": 15763.40106511116, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 492704, "time": 15769.358156442642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492832, "time": 15773.252928733826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 493016, "time": 15778.615228891373, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 493096, "time": 15781.066451787949, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 493264, "time": 15786.403894901276, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 493872, "time": 15804.975292921066, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 494016, "time": 15809.33294725418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494048, "time": 15810.332608938217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494056, "time": 15810.36033320427, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 494352, "time": 15819.764117479324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494704, "time": 15830.743801116943, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 494848, "time": 15835.170041799545, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 495144, "time": 15844.042161941528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495328, "time": 15849.925754785538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495408, "time": 15852.386447906494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495416, "time": 15852.416820764542, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 495608, "time": 15858.450165271759, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 496184, "time": 15876.021084308624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 496232, "time": 15877.492483377457, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 496360, "time": 15881.434126615524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 496664, "time": 15890.946229457855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 496736, "time": 15893.362053155899, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 497160, "time": 15906.134194135666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497456, "time": 15915.522803783417, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 497456, "time": 15915.53295636177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497528, "time": 15917.50867509842, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 497720, "time": 15923.434759378433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497728, "time": 15923.909939527512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497760, "time": 15924.890768289566, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 497952, "time": 15930.81085896492, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 498104, "time": 15935.253470182419, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 498136, "time": 15936.238533735275, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 498248, "time": 15939.700581550598, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 498496, "time": 15947.67690038681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498672, "time": 15953.04575586319, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498944, "time": 15961.30156326294, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 499208, "time": 15969.151578426361, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 499320, "time": 15972.583102703094, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 499368, "time": 15974.167118310928, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 499840, "time": 15989.223072052002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 499992, "time": 15993.650065660477, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 15996.28042626381, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 500032, "time": 15996.387797832489, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 500032, "time": 15996.779381036758, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 500032, "time": 15996.971527814865, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 500032, "time": 15997.709758758545, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 500032, "time": 15998.271020650864, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 500032, "time": 15998.835164308548, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 500032, "time": 15999.628222227097, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 500040, "time": 15999.657518148422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 500072, "time": 16000.644409656525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 500424, "time": 16011.496476888657, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 500440, "time": 16012.005179643631, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 500560, "time": 16015.890754699707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 500976, "time": 16028.662781715393, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 500984, "time": 16028.692706108093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 500984, "time": 16028.702110052109, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 501400, "time": 16041.504629611969, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 501632, "time": 16048.791004180908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501656, "time": 16049.302842140198, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 501680, "time": 16050.255603551865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501808, "time": 16054.143198490143, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 502008, "time": 16060.041809558868, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 502192, "time": 16066.115451812744, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 502304, "time": 16069.552090406418, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 502384, "time": 16072.022109746933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502736, "time": 16082.762356758118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502808, "time": 16084.737195253372, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 502872, "time": 16086.723163843155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502992, "time": 16090.627139806747, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 503224, "time": 16097.644410610199, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 503240, "time": 16098.135258674622, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 503296, "time": 16100.064613103867, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 503944, "time": 16119.877425909042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 503968, "time": 16120.864636659622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 504280, "time": 16130.355022907257, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 504616, "time": 16140.624795913696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 504928, "time": 16150.37321138382, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 505048, "time": 16153.932255744934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505304, "time": 16161.776496171951, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505536, "time": 16169.10779619217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505552, "time": 16169.62699842453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505616, "time": 16171.579795598984, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 505880, "time": 16179.444923877716, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 506016, "time": 16183.92398905754, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 506256, "time": 16191.269991397858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506280, "time": 16191.787590503693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506552, "time": 16200.126730680466, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 506792, "time": 16207.449698925018, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 507120, "time": 16217.839491128922, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 507144, "time": 16218.348281383514, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 507360, "time": 16225.166271209717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 507496, "time": 16229.120772600174, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 507616, "time": 16233.015606880188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 507848, "time": 16239.888093948364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 507864, "time": 16240.38247513771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 507928, "time": 16242.881591320038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 508192, "time": 16251.255188941956, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 508368, "time": 16256.65769124031, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 508432, "time": 16258.632429361343, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 508528, "time": 16261.574746608734, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 508704, "time": 16266.961719751358, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 508840, "time": 16270.93083024025, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 509104, "time": 16279.408745527267, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 509321, "time": 16286.77611207962, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.244260559082031, "train/action_min": 0.0, "train/action_std": 1.949688993692398, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.003111618593975436, "train/actor_opt_grad_steps": 30735.0, "train/actor_opt_loss": -0.2959920703526586, "train/adv_mag": 0.23514272034168243, "train/adv_max": 0.021566180288791658, "train/adv_mean": 0.002460729837221152, "train/adv_min": -0.23170849412679673, "train/adv_std": 0.0077872680604923515, "train/cont_avg": 0.9960693359375, "train/cont_loss_mean": 0.02250880331033841, "train/cont_loss_std": 0.29857562479330224, "train/cont_neg_acc": 0.018903319281761092, "train/cont_neg_loss": 4.759426758746908, "train/cont_pos_acc": 0.9999656412005424, "train/cont_pos_loss": 0.003912069237558171, "train/cont_pred": 0.9960196542739869, "train/cont_rate": 0.9960693359375, "train/dyn_loss_mean": 1.0000085681676865, "train/dyn_loss_std": 0.00022790485047153198, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1912142593576573, "train/extr_critic_critic_opt_grad_steps": 30735.0, "train/extr_critic_critic_opt_loss": 7386.450299072266, "train/extr_critic_mag": 0.6521857851743698, "train/extr_critic_max": 0.6521857851743698, "train/extr_critic_mean": 0.6400310981273651, "train/extr_critic_min": 0.6209696120023728, "train/extr_critic_std": 0.0053178613842464985, "train/extr_return_normed_mag": 0.2410726946592331, "train/extr_return_normed_max": 0.03907616376876831, "train/extr_return_normed_mean": 0.014023786967154592, "train/extr_return_normed_min": -0.22468208342790605, "train/extr_return_normed_std": 0.010177034130319952, "train/extr_return_rate": 0.9996901223063469, "train/extr_return_raw_mag": 0.6675441721081734, "train/extr_return_raw_max": 0.6675441721081734, "train/extr_return_raw_mean": 0.6424918296933174, "train/extr_return_raw_min": 0.403785924911499, "train/extr_return_raw_std": 0.010177034081425517, "train/extr_reward_mag": 0.019656645059585573, "train/extr_reward_max": 0.019656645059585573, "train/extr_reward_mean": 0.0017946974877850153, "train/extr_reward_min": 2.8133392333984374e-07, "train/extr_reward_std": 0.0036915732338093222, "train/image_loss_mean": 0.12776535894721747, "train/image_loss_std": 0.11052794504910707, "train/model_loss_mean": 0.756476032435894, "train/model_loss_std": 0.41457470186054707, "train/model_opt_grad_norm": 24.952466583251955, "train/model_opt_grad_steps": 30706.795, "train/model_opt_loss": 3231.6332885742186, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4300.0, "train/policy_entropy_mag": 1.5469290119409562, "train/policy_entropy_max": 1.5469290119409562, "train/policy_entropy_mean": 0.20267315424978732, "train/policy_entropy_min": 0.06469999365508557, "train/policy_entropy_std": 0.24616284132003785, "train/policy_logprob_mag": 6.5510008430480955, "train/policy_logprob_max": -0.008610419342294335, "train/policy_logprob_mean": -0.20235033385455609, "train/policy_logprob_min": -6.5510008430480955, "train/policy_logprob_std": 0.7426634699106216, "train/policy_randomness_mag": 0.794964302778244, "train/policy_randomness_max": 0.794964302778244, "train/policy_randomness_mean": 0.10415340404957533, "train/policy_randomness_min": 0.03324922133237124, "train/policy_randomness_std": 0.12650268394500017, "train/post_ent_mag": 64.34913047790528, "train/post_ent_max": 64.34913047790528, "train/post_ent_mean": 63.40903064727783, "train/post_ent_min": 62.606704235076904, "train/post_ent_std": 0.29168887712061403, "train/prior_ent_mag": 68.07953350067139, "train/prior_ent_max": 68.07953350067139, "train/prior_ent_mean": 65.41446712493897, "train/prior_ent_min": 61.912392921447754, "train/prior_ent_std": 1.0974177673459053, "train/rep_loss_mean": 1.0000085681676865, "train/rep_loss_std": 0.00022790485047153198, "train/reward_avg": 0.0006104431104904507, "train/reward_loss_mean": 0.006196704448666423, "train/reward_loss_std": 0.13758627504110335, "train/reward_max_data": 0.4568124993145466, "train/reward_max_pred": 0.012836174964904785, "train/reward_neg_acc": 0.9999999994039536, "train/reward_neg_loss": 0.0009437571385933551, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.53817329477908, "train/reward_pred": 0.0004784205777104944, "train/reward_rate": 0.0009521484375, "train_stats/mean_log_entropy": 0.1329236161456537, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.015614689327776432, "report/cont_loss_std": 0.2504406273365021, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.464350700378418, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004951799754053354, "report/cont_pred": 0.9950999617576599, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.14537182450294495, "report/image_loss_std": 0.11887345463037491, "report/model_loss_mean": 0.7671792507171631, "report/model_loss_std": 0.3817974030971527, "report/post_ent_mag": 62.238189697265625, "report/post_ent_max": 62.238189697265625, "report/post_ent_mean": 61.18413543701172, "report/post_ent_min": 60.378387451171875, "report/post_ent_std": 0.30450382828712463, "report/prior_ent_mag": 64.94652557373047, "report/prior_ent_max": 64.94652557373047, "report/prior_ent_mean": 62.659698486328125, "report/prior_ent_min": 58.53215789794922, "report/prior_ent_std": 1.1879560947418213, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007843017810955644, "report/reward_loss_mean": 0.006192686501890421, "report/reward_loss_std": 0.15479053556919098, "report/reward_max_data": 0.8031250238418579, "report/reward_max_pred": 0.025536417961120605, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0013551035663112998, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.955039978027344, "report/reward_pred": 0.0006750592729076743, "report/reward_rate": 0.0009765625, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.00364376581273973, "eval/cont_loss_std": 0.00949410255998373, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00364376581273973, "eval/cont_pred": 0.9964062571525574, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21064826846122742, "eval/image_loss_std": 0.12895873188972473, "eval/model_loss_mean": 0.8144500255584717, "eval/model_loss_std": 0.12905368208885193, "eval/post_ent_mag": 62.197940826416016, "eval/post_ent_max": 62.197940826416016, "eval/post_ent_mean": 61.17781066894531, "eval/post_ent_min": 60.330543518066406, "eval/post_ent_std": 0.302143394947052, "eval/prior_ent_mag": 64.94652557373047, "eval/prior_ent_max": 64.94652557373047, "eval/prior_ent_mean": 62.03136444091797, "eval/prior_ent_min": 58.37437438964844, "eval/prior_ent_std": 1.1141300201416016, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001579425297677517, "eval/reward_loss_std": 0.0011216163402423263, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.009459137916564941, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001579425297677517, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.538276258856058e-05, "eval/reward_rate": 0.0, "replay/size": 508817.0, "replay/inserts": 31968.0, "replay/samples": 31968.0, "replay/insert_wait_avg": 1.3546781377630072e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.624897180734812e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6408.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.231457261408164e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2367963790893555e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0366115570068, "timer/env.step_count": 3996.0, "timer/env.step_total": 39.71089458465576, "timer/env.step_frac": 0.03970944076020166, "timer/env.step_avg": 0.009937661307471412, "timer/env.step_min": 0.007860660552978516, "timer/env.step_max": 0.03983664512634277, "timer/replay._sample_count": 31968.0, "timer/replay._sample_total": 17.656129598617554, "timer/replay._sample_frac": 0.01765548320388775, "timer/replay._sample_avg": 0.0005523063563131116, "timer/replay._sample_min": 0.0004398822784423828, "timer/replay._sample_max": 0.025923967361450195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4797.0, "timer/agent.policy_total": 52.61232662200928, "timer/agent.policy_frac": 0.052610400473333194, "timer/agent.policy_avg": 0.010967756227227283, "timer/agent.policy_min": 0.009231805801391602, "timer/agent.policy_max": 0.0854039192199707, "timer/dataset_train_count": 1998.0, "timer/dataset_train_total": 0.23201847076416016, "timer/dataset_train_frac": 0.0002320099765176787, "timer/dataset_train_avg": 0.0001161253607428229, "timer/dataset_train_min": 9.846687316894531e-05, "timer/dataset_train_max": 0.0005979537963867188, "timer/agent.train_count": 1998.0, "timer/agent.train_total": 893.1391088962555, "timer/agent.train_frac": 0.8931064108799804, "timer/agent.train_avg": 0.4470165710191469, "timer/agent.train_min": 0.43630075454711914, "timer/agent.train_max": 0.7124757766723633, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4783763885498047, "timer/agent.report_frac": 0.0004783588750865797, "timer/agent.report_avg": 0.23918819427490234, "timer/agent.report_min": 0.23253345489501953, "timer/agent.report_max": 0.24584293365478516, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4332275390625e-05, "timer/dataset_eval_frac": 3.433101847858487e-08, "timer/dataset_eval_avg": 3.4332275390625e-05, "timer/dataset_eval_min": 3.4332275390625e-05, "timer/dataset_eval_max": 3.4332275390625e-05, "fps": 31.96627579820808}
{"step": 509360, "time": 16287.97802066803, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 509432, "time": 16289.993618488312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 509736, "time": 16299.304692268372, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 509768, "time": 16300.282200813293, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 509808, "time": 16301.730884552002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 16311.224826097488, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 510016, "time": 16314.75625371933, "eval_episode/length": 173.0, "eval_episode/score": 0.4593749940395355, "eval_episode/reward_rate": 0.005747126436781609}
{"step": 510016, "time": 16314.784794807434, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16314.837239027023, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16314.846539735794, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16314.856065273285, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16314.865282773972, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16314.874498844147, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16314.885519981384, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510176, "time": 16319.78230381012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510504, "time": 16329.653253793716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510840, "time": 16340.09321975708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510992, "time": 16344.965896606445, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 511016, "time": 16345.491742610931, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 511512, "time": 16360.608045101166, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 511744, "time": 16368.082349300385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512048, "time": 16377.396321296692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512080, "time": 16378.390334367752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512120, "time": 16379.427297592163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512400, "time": 16388.203273773193, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 512488, "time": 16390.688685894012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 513152, "time": 16411.352054834366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 513304, "time": 16415.780638694763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514056, "time": 16438.795004606247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514360, "time": 16448.099352121353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514392, "time": 16449.074573278427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514432, "time": 16450.510284423828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514712, "time": 16458.96217560768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514800, "time": 16461.856112003326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 515464, "time": 16481.88889837265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 515616, "time": 16486.936428308487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516368, "time": 16510.522794008255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516672, "time": 16520.017014026642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516704, "time": 16521.0039331913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516744, "time": 16522.00465130806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517024, "time": 16530.79731988907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517112, "time": 16533.298269987106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517776, "time": 16553.932814836502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517928, "time": 16558.35387611389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518592, "time": 16578.949801683426, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 518680, "time": 16581.428883075714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518816, "time": 16585.80984187126, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 518824, "time": 16585.83925843239, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 519056, "time": 16593.15826845169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 519280, "time": 16599.988956212997, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 519280, "time": 16599.99835920334, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 519336, "time": 16601.514439821243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 519920, "time": 16619.7159512043, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 16623.251153707504, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 520000, "time": 16623.395100593567, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 520000, "time": 16623.586310863495, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 520000, "time": 16623.752180099487, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 520000, "time": 16624.109630584717, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 520000, "time": 16624.56813597679, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 520000, "time": 16624.829765558243, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 520000, "time": 16625.174163103104, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 520088, "time": 16627.668207406998, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 520088, "time": 16627.67780470848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520168, "time": 16630.182738542557, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 520240, "time": 16632.61628818512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520728, "time": 16647.43116569519, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 520904, "time": 16652.790185451508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520992, "time": 16655.714933156967, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 521088, "time": 16658.654985666275, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 521192, "time": 16661.61109828949, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 521624, "time": 16674.9197473526, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 521832, "time": 16681.317311048508, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 522232, "time": 16693.639061689377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522400, "time": 16699.10015463829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522552, "time": 16703.535202264786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522912, "time": 16714.812620401382, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 523040, "time": 16718.728613376617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 523144, "time": 16721.67745423317, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 523304, "time": 16726.67033100128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 523504, "time": 16733.02295899391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 523936, "time": 16746.45321702957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 524128, "time": 16752.338702440262, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 524144, "time": 16752.836791992188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 524768, "time": 16772.724891662598, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 525008, "time": 16780.130575418472, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 525104, "time": 16783.100628376007, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 525352, "time": 16790.57665205002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525456, "time": 16794.007803201675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525816, "time": 16804.926094532013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525856, "time": 16806.376543283463, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 525968, "time": 16809.812363624573, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 526152, "time": 16815.38383412361, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 526248, "time": 16818.32189130783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 526312, "time": 16820.282685756683, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 526456, "time": 16824.727479457855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 526912, "time": 16838.95065498352, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 527080, "time": 16844.043502807617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 527320, "time": 16851.390008211136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 527416, "time": 16854.312497854233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 527416, "time": 16854.325827360153, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 527752, "time": 16864.852286815643, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 527920, "time": 16870.660347938538, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 528104, "time": 16876.20569753647, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 528280, "time": 16881.628583431244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 528464, "time": 16887.48221063614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 528624, "time": 16892.380494594574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 528768, "time": 16896.79731440544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529048, "time": 16905.282382249832, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 529112, "time": 16907.249841928482, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 529152, "time": 16908.696531057358, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 529504, "time": 16919.443895339966, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 529632, "time": 16923.383367061615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530064, "time": 16936.769874334335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 16937.86650443077, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 530088, "time": 16938.247660160065, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 530088, "time": 16939.99610543251, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 530088, "time": 16940.476858377457, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 530088, "time": 16940.52249598503, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 530088, "time": 16940.787039518356, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 530088, "time": 16941.397215604782, "eval_episode/length": 194.0, "eval_episode/score": 0.39375001192092896, "eval_episode/reward_rate": 0.005128205128205128}
{"step": 530088, "time": 16942.3901450634, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 530232, "time": 16946.839191913605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530328, "time": 16949.77901172638, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 530456, "time": 16953.703142404556, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 530592, "time": 16958.09219646454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530664, "time": 16960.069447040558, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 531360, "time": 16981.754171848297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 531424, "time": 16983.6994907856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 531464, "time": 16984.708917617798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 531736, "time": 16993.02784204483, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 531944, "time": 16999.52516102791, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 532640, "time": 17021.594191789627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 532768, "time": 17025.657093524933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 532976, "time": 17031.999025583267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 533144, "time": 17036.905079364777, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 533296, "time": 17041.81260561943, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 533520, "time": 17048.64936351776, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 533672, "time": 17053.09414958954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 533680, "time": 17053.5884206295, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 533736, "time": 17055.210874080658, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 534024, "time": 17064.018886327744, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 534048, "time": 17065.002646684647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534216, "time": 17069.92262196541, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 534256, "time": 17071.371770381927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534480, "time": 17078.214034318924, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 534480, "time": 17078.222610473633, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 535016, "time": 17094.585375785828, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 535376, "time": 17105.808221578598, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 535592, "time": 17112.215141296387, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 535944, "time": 17123.112498044968, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 535984, "time": 17124.583927869797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 535992, "time": 17124.61383843422, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 536016, "time": 17125.593744277954, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 536048, "time": 17126.57531785965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 536360, "time": 17135.88091278076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 536792, "time": 17149.251584768295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 537656, "time": 17175.80036187172, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 537904, "time": 17183.60564184189, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538256, "time": 17194.37849164009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538296, "time": 17195.400058031082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538304, "time": 17195.878027677536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538328, "time": 17196.397518634796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538672, "time": 17207.288192033768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538936, "time": 17215.10529112816, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 538952, "time": 17215.598081588745, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 539968, "time": 17246.968497276306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 17255.846086502075, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17255.868088245392, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17255.88045477867, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17255.890571832657, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17255.901976823807, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17255.91300344467, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17255.92324066162, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17255.93483901024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540216, "time": 17260.347276687622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540568, "time": 17271.269453048706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540608, "time": 17272.75719332695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540640, "time": 17273.73556280136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540984, "time": 17284.526236772537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 541033, "time": 17287.046101808548, "train_stats/mean_log_entropy": 0.1624301943468721, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.240289244988952, "train/action_min": 0.0, "train/action_std": 1.415896482840933, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01765940709255937, "train/actor_opt_grad_steps": 32725.0, "train/actor_opt_loss": 0.9085271545130797, "train/adv_mag": 0.6478404848262517, "train/adv_max": 0.32756099014571216, "train/adv_mean": 0.01252596179255742, "train/adv_min": -0.6161161372155854, "train/adv_std": 0.05350821011351666, "train/cont_avg": 0.9958323469065656, "train/cont_loss_mean": 0.021129155393943867, "train/cont_loss_std": 0.28398571767129305, "train/cont_neg_acc": 0.12083131052097495, "train/cont_neg_loss": 4.151578336174847, "train/cont_pos_acc": 0.9998712578807214, "train/cont_pos_loss": 0.003805182133377953, "train/cont_pred": 0.9957764184836185, "train/cont_rate": 0.9958323469065656, "train/dyn_loss_mean": 1.000022505268906, "train/dyn_loss_std": 0.0005598857294696952, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.4161473317918452, "train/extr_critic_critic_opt_grad_steps": 32725.0, "train/extr_critic_critic_opt_loss": 12725.831335819128, "train/extr_critic_mag": 0.8146841965540491, "train/extr_critic_max": 0.8146841965540491, "train/extr_critic_mean": 0.787244279276241, "train/extr_critic_min": 0.7565359930799465, "train/extr_critic_std": 0.012154107878097531, "train/extr_return_normed_mag": 0.6252075578227188, "train/extr_return_normed_max": 0.38800181011960966, "train/extr_return_normed_mean": 0.055980417495264174, "train/extr_return_normed_min": -0.5661835706595219, "train/extr_return_normed_std": 0.05623147308102085, "train/extr_return_rate": 0.9936444936978697, "train/extr_return_raw_mag": 1.1317916193393747, "train/extr_return_raw_max": 1.1317916193393747, "train/extr_return_raw_mean": 0.7997702643124744, "train/extr_return_raw_min": 0.17760623825920951, "train/extr_return_raw_std": 0.056231472885819395, "train/extr_reward_mag": 0.3220752670307352, "train/extr_reward_max": 0.3220752670307352, "train/extr_reward_mean": 0.004059608734866232, "train/extr_reward_min": 3.395658550840436e-07, "train/extr_reward_std": 0.020157987879906844, "train/image_loss_mean": 0.11554810720862764, "train/image_loss_std": 0.10838809014871867, "train/model_loss_mean": 0.7429312783660311, "train/model_loss_std": 0.4013618458476331, "train/model_opt_grad_norm": 22.88965262788715, "train/model_opt_grad_steps": 32695.19191919192, "train/model_opt_loss": 2778.29550633286, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3737.373737373737, "train/policy_entropy_mag": 1.4228915289194897, "train/policy_entropy_max": 1.4228915289194897, "train/policy_entropy_mean": 0.18677418107035185, "train/policy_entropy_min": 0.06468925252556801, "train/policy_entropy_std": 0.21413330936973746, "train/policy_logprob_mag": 6.551075465751417, "train/policy_logprob_max": -0.008608679019027588, "train/policy_logprob_mean": -0.18737416469840087, "train/policy_logprob_min": -6.551075465751417, "train/policy_logprob_std": 0.7140795410883547, "train/policy_randomness_mag": 0.7312216421570441, "train/policy_randomness_max": 0.7312216421570441, "train/policy_randomness_mean": 0.09598294733976474, "train/policy_randomness_min": 0.03324370155807095, "train/policy_randomness_std": 0.11004275862466205, "train/post_ent_mag": 59.50762093669236, "train/post_ent_max": 59.50762093669236, "train/post_ent_mean": 58.16088138927113, "train/post_ent_min": 57.10982717648901, "train/post_ent_std": 0.4214164105930714, "train/prior_ent_mag": 63.00564544369476, "train/prior_ent_max": 63.00564544369476, "train/prior_ent_mean": 59.218059327867294, "train/prior_ent_min": 55.271017421375625, "train/prior_ent_std": 1.3709700258091242, "train/rep_loss_mean": 1.000022505268906, "train/rep_loss_std": 0.0005598857294696952, "train/reward_avg": 0.0006906528658947362, "train/reward_loss_mean": 0.006240493358075243, "train/reward_loss_std": 0.13128787871259687, "train/reward_max_data": 0.48009785249678777, "train/reward_max_pred": 0.07515767608026061, "train/reward_neg_acc": 0.9998864630858103, "train/reward_neg_loss": 0.0010749269297435841, "train/reward_pos_acc": 0.09532828312931639, "train/reward_pos_loss": 5.059262027343114, "train/reward_pred": 0.0005834980243393643, "train/reward_rate": 0.0010209517045454545, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.022526852786540985, "report/cont_loss_std": 0.31321999430656433, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.9178466796875, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0033295212779194117, "report/cont_pred": 0.9966698884963989, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10430388152599335, "report/image_loss_std": 0.10264910757541656, "report/model_loss_mean": 0.7371399402618408, "report/model_loss_std": 0.4820634722709656, "report/post_ent_mag": 56.717071533203125, "report/post_ent_max": 56.717071533203125, "report/post_ent_mean": 55.183326721191406, "report/post_ent_min": 54.187171936035156, "report/post_ent_std": 0.47110190987586975, "report/prior_ent_mag": 60.32308578491211, "report/prior_ent_max": 60.32308578491211, "report/prior_ent_mean": 56.17546844482422, "report/prior_ent_min": 51.956878662109375, "report/prior_ent_std": 1.4496707916259766, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0016265868907794356, "report/reward_loss_mean": 0.010309142991900444, "report/reward_loss_std": 0.20740219950675964, "report/reward_max_data": 0.875, "report/reward_max_pred": 0.024666190147399902, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.001137195504270494, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.697174549102783, "report/reward_pred": 0.0006198444170877337, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.015435166656970978, "eval/cont_loss_std": 0.3095879554748535, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.979674339294434, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0018065199255943298, "eval/cont_pred": 0.9982039928436279, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1528257131576538, "eval/image_loss_std": 0.13553686439990997, "eval/model_loss_mean": 0.7683302760124207, "eval/model_loss_std": 0.3367414176464081, "eval/post_ent_mag": 56.71650695800781, "eval/post_ent_max": 56.71650695800781, "eval/post_ent_mean": 55.07439041137695, "eval/post_ent_min": 53.59920120239258, "eval/post_ent_std": 0.47327205538749695, "eval/prior_ent_mag": 60.32308578491211, "eval/prior_ent_max": 60.32308578491211, "eval/prior_ent_mean": 55.682865142822266, "eval/prior_ent_min": 52.12535858154297, "eval/prior_ent_std": 1.3333733081817627, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 6.939470767974854e-05, "eval/reward_loss_std": 0.0012502793688327074, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.02006363868713379, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 6.939470767974854e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.552634734660387e-05, "eval/reward_rate": 0.0, "replay/size": 540529.0, "replay/inserts": 31712.0, "replay/samples": 31712.0, "replay/insert_wait_avg": 1.3749366090468514e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.759809487282207e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7712.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2091581257547085e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1324882507324219e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2515954971313, "timer/env.step_count": 3964.0, "timer/env.step_total": 39.656564235687256, "timer/env.step_frac": 0.03964658933233463, "timer/env.step_avg": 0.010004178666924131, "timer/env.step_min": 0.007969379425048828, "timer/env.step_max": 0.04009127616882324, "timer/replay._sample_count": 31712.0, "timer/replay._sample_total": 17.489652395248413, "timer/replay._sample_frac": 0.017485253184281048, "timer/replay._sample_avg": 0.0005515152748249374, "timer/replay._sample_min": 0.00041794776916503906, "timer/replay._sample_max": 0.03516840934753418, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4928.0, "timer/agent.policy_total": 54.492600440979004, "timer/agent.policy_frac": 0.05447889379661108, "timer/agent.policy_avg": 0.011057751712860999, "timer/agent.policy_min": 0.009161949157714844, "timer/agent.policy_max": 0.0960087776184082, "timer/dataset_train_count": 1982.0, "timer/dataset_train_total": 0.23108220100402832, "timer/dataset_train_frac": 0.0002310240763866805, "timer/dataset_train_avg": 0.00011659041423008492, "timer/dataset_train_min": 9.775161743164062e-05, "timer/dataset_train_max": 0.0005159378051757812, "timer/agent.train_count": 1982.0, "timer/agent.train_total": 889.7145357131958, "timer/agent.train_frac": 0.8894907438473038, "timer/agent.train_avg": 0.4488973439521674, "timer/agent.train_min": 0.4369666576385498, "timer/agent.train_max": 0.7875747680664062, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5126864910125732, "timer/agent.report_frac": 0.000512557533845037, "timer/agent.report_avg": 0.2563432455062866, "timer/agent.report_min": 0.2556273937225342, "timer/agent.report_max": 0.25705909729003906, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.574920654296875e-05, "timer/dataset_eval_frac": 2.5742729788070204e-08, "timer/dataset_eval_avg": 2.574920654296875e-05, "timer/dataset_eval_min": 2.574920654296875e-05, "timer/dataset_eval_max": 2.574920654296875e-05, "fps": 31.703404714264824}
{"step": 541248, "time": 17293.696313619614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 541264, "time": 17294.27959370613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542280, "time": 17325.332261562347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542528, "time": 17333.149596452713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542880, "time": 17343.908244609833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542920, "time": 17344.91519999504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542952, "time": 17345.89821267128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 543296, "time": 17356.726269245148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 543560, "time": 17364.57689356804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 543576, "time": 17365.07020831108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 544592, "time": 17398.108751773834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 544840, "time": 17405.47892832756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545192, "time": 17416.44922399521, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545232, "time": 17417.918840885162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545264, "time": 17418.900116205215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545608, "time": 17429.19402885437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545872, "time": 17437.499316692352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545888, "time": 17437.994418382645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 546904, "time": 17468.91571688652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547152, "time": 17476.916481018066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547504, "time": 17487.666536808014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547544, "time": 17488.672037363052, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547576, "time": 17489.652307271957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547920, "time": 17500.355768442154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 548184, "time": 17508.295169591904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 548200, "time": 17508.783964157104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549216, "time": 17540.565913438797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549464, "time": 17547.92258644104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549816, "time": 17558.67682814598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549856, "time": 17560.122119665146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549888, "time": 17561.120229005814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 550056, "time": 17572.562697649002, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17572.571473121643, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17572.581484556198, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17572.59185576439, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17572.60230922699, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17572.61054944992, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17572.620203495026, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17572.628441810608, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550232, "time": 17577.99950861931, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 550496, "time": 17586.267056703568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 550512, "time": 17586.784229040146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551528, "time": 17617.675973892212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551776, "time": 17625.606472969055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552128, "time": 17636.37263584137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552168, "time": 17637.37016272545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552200, "time": 17638.345195293427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552544, "time": 17649.071405172348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552808, "time": 17657.037172555923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552824, "time": 17657.535560131073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 553840, "time": 17688.903749227524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554088, "time": 17696.23719716072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554440, "time": 17706.96175980568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554480, "time": 17708.416624069214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554512, "time": 17709.424102306366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554856, "time": 17719.87136411667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 555120, "time": 17728.14602971077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 555136, "time": 17728.641103982925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556152, "time": 17759.60484480858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556400, "time": 17767.388978242874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556752, "time": 17778.225404262543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556792, "time": 17779.2215924263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556824, "time": 17780.20325422287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557168, "time": 17791.4475646019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557432, "time": 17799.325224399567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557448, "time": 17799.823955774307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 558464, "time": 17831.16063928604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 558712, "time": 17838.66174507141, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559064, "time": 17849.33909511566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559104, "time": 17850.774584054947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559136, "time": 17851.748793125153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559480, "time": 17862.031671524048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559744, "time": 17870.405576229095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559760, "time": 17870.896371603012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 17884.901663541794, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17884.911768198013, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17884.92293524742, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17884.935358524323, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17884.944631814957, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17884.957162618637, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17884.97047972679, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17884.98022198677, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560776, "time": 17907.549352407455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 561024, "time": 17915.62959909439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 561376, "time": 17926.651059389114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 561416, "time": 17927.68478870392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 561448, "time": 17928.679790496826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 561792, "time": 17939.55635714531, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 562056, "time": 17947.462717056274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 562072, "time": 17947.95721578598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563088, "time": 17979.296238183975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563336, "time": 17986.73853302002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563688, "time": 17997.50274205208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563728, "time": 17998.951853752136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563760, "time": 17999.934359788895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 564104, "time": 18010.212609291077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 564368, "time": 18018.687613725662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 564384, "time": 18019.178273677826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 565400, "time": 18050.7458152771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 565648, "time": 18058.536549329758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566000, "time": 18069.29614186287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566040, "time": 18070.31635785103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566072, "time": 18071.300916433334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566416, "time": 18082.182426929474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566680, "time": 18090.05829143524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566696, "time": 18090.550426483154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 567712, "time": 18121.868579864502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 567960, "time": 18129.22460269928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568312, "time": 18140.09333062172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568352, "time": 18141.540201187134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568384, "time": 18142.517292022705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568728, "time": 18152.790016174316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568992, "time": 18161.072288513184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 569008, "time": 18161.566700458527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 18192.418345928192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 18198.615344762802, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18198.623057127, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18198.631674528122, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18198.640395641327, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18198.651278972626, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18198.65852212906, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18198.66707277298, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18198.676280736923, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570272, "time": 18206.44946694374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 570624, "time": 18217.182268619537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 570664, "time": 18218.175917625427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 570696, "time": 18219.172925949097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571040, "time": 18230.04751610756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571304, "time": 18237.875237941742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571320, "time": 18238.385814666748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 572336, "time": 18269.747861385345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 572584, "time": 18277.089247465134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 572873, "time": 18287.02415704727, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.6938746466708543, "train/action_min": 0.0, "train/action_std": 0.6096045599510921, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0028545971712373645, "train/actor_opt_grad_steps": 34710.0, "train/actor_opt_loss": -8.808106746505853, "train/adv_mag": 0.4711988544344303, "train/adv_max": 0.034705233633817736, "train/adv_mean": -0.006992217696192277, "train/adv_min": -0.46429057606500596, "train/adv_std": 0.010711494490420024, "train/cont_avg": 0.9960888426507538, "train/cont_loss_mean": 0.017368551831570777, "train/cont_loss_std": 0.25180935038337904, "train/cont_neg_acc": 0.22384377028131244, "train/cont_neg_loss": 3.600926444636478, "train/cont_pos_acc": 0.9998325504849305, "train/cont_pos_loss": 0.003348414171908294, "train/cont_pred": 0.995915489580164, "train/cont_rate": 0.9960888426507538, "train/dyn_loss_mean": 1.0000078833881934, "train/dyn_loss_std": 0.00023879148618870382, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1815656539492646, "train/extr_critic_critic_opt_grad_steps": 34710.0, "train/extr_critic_critic_opt_loss": 9941.267944949355, "train/extr_critic_mag": 0.8062688226076826, "train/extr_critic_max": 0.8062688226076826, "train/extr_critic_mean": 0.7696995875943247, "train/extr_critic_min": 0.7423689053885302, "train/extr_critic_std": 0.008749646813276425, "train/extr_return_normed_mag": 0.4592868964276721, "train/extr_return_normed_max": 0.05174857617622644, "train/extr_return_normed_mean": 0.003512058190343435, "train/extr_return_normed_min": -0.4456592259095542, "train/extr_return_normed_std": 0.014135122771875643, "train/extr_return_rate": 0.9997962135166379, "train/extr_return_raw_mag": 0.8109438110835588, "train/extr_return_raw_max": 0.8109438110835588, "train/extr_return_raw_mean": 0.76270733286987, "train/extr_return_raw_min": 0.31353600899777817, "train/extr_return_raw_std": 0.014135122811655753, "train/extr_reward_mag": 0.07549867078886559, "train/extr_reward_max": 0.07549867078886559, "train/extr_reward_mean": 0.000243608356131243, "train/extr_reward_min": 2.3003199591708542e-07, "train/extr_reward_std": 0.0019289222801128758, "train/image_loss_mean": 0.11079810578469655, "train/image_loss_std": 0.10738649604907587, "train/model_loss_mean": 0.7334907662928404, "train/model_loss_std": 0.3619121468097121, "train/model_opt_grad_norm": 22.715980409976826, "train/model_opt_grad_steps": 34678.90452261306, "train/model_opt_loss": 3132.7654011021905, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4271.356783919598, "train/policy_entropy_mag": 1.0876351157624518, "train/policy_entropy_max": 1.0876351157624518, "train/policy_entropy_mean": 0.09082394362843815, "train/policy_entropy_min": 0.06468662245189724, "train/policy_entropy_std": 0.09967940600223876, "train/policy_logprob_mag": 6.55108021491736, "train/policy_logprob_max": -0.0086082573980093, "train/policy_logprob_mean": -0.09115347576950064, "train/policy_logprob_min": -6.55108021491736, "train/policy_logprob_std": 0.6300616120573265, "train/policy_randomness_mag": 0.558933914756056, "train/policy_randomness_max": 0.558933914756056, "train/policy_randomness_mean": 0.04667427639790516, "train/policy_randomness_min": 0.03324235043483763, "train/policy_randomness_std": 0.051225084511928226, "train/post_ent_mag": 55.7599249413265, "train/post_ent_max": 55.7599249413265, "train/post_ent_mean": 54.047992035372175, "train/post_ent_min": 52.81319695860896, "train/post_ent_std": 0.5434172285262064, "train/prior_ent_mag": 58.823784487930375, "train/prior_ent_max": 58.823784487930375, "train/prior_ent_mean": 54.31322047938055, "train/prior_ent_min": 50.54457901231009, "train/prior_ent_std": 1.4413551799016981, "train/rep_loss_mean": 1.0000078833881934, "train/rep_loss_std": 0.00023879148618870382, "train/reward_avg": 0.0005864282351805613, "train/reward_loss_mean": 0.005319354109742196, "train/reward_loss_std": 0.11773752470339306, "train/reward_max_data": 0.4394786438375861, "train/reward_max_pred": 0.07741948048673084, "train/reward_neg_acc": 0.9999263265624119, "train/reward_neg_loss": 0.0009262741517173782, "train/reward_pos_acc": 0.11410256417898032, "train/reward_pos_loss": 4.812020521897536, "train/reward_pred": 0.0005271104369172125, "train/reward_rate": 0.000912766959798995, "train_stats/mean_log_entropy": 0.07025450047243524, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.011634571477770805, "report/cont_loss_std": 0.158985435962677, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 2.749807357788086, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003589009866118431, "report/cont_pred": 0.9961607456207275, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08898243308067322, "report/image_loss_std": 0.0879635214805603, "report/model_loss_mean": 0.713617205619812, "report/model_loss_std": 0.41033026576042175, "report/post_ent_mag": 56.822975158691406, "report/post_ent_max": 56.822975158691406, "report/post_ent_mean": 55.06263732910156, "report/post_ent_min": 53.650390625, "report/post_ent_std": 0.5593700408935547, "report/prior_ent_mag": 56.69023895263672, "report/prior_ent_max": 56.69023895263672, "report/prior_ent_mean": 53.151649475097656, "report/prior_ent_min": 50.429073333740234, "report/prior_ent_std": 1.1219029426574707, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0021606446243822575, "report/reward_loss_mean": 0.013000201433897018, "report/reward_loss_std": 0.22554926574230194, "report/reward_max_data": 0.78125, "report/reward_max_pred": 0.07583749294281006, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0010507515398785472, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.07979679107666, "report/reward_pred": 0.0006326967850327492, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.011409820057451725, "eval/cont_loss_std": 0.2946121096611023, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.429767608642578, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0022032137494534254, "eval/cont_pred": 0.9978423118591309, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1253241002559662, "eval/image_loss_std": 0.1263047605752945, "eval/model_loss_mean": 0.7369033098220825, "eval/model_loss_std": 0.32698196172714233, "eval/post_ent_mag": 56.83842468261719, "eval/post_ent_max": 56.83842468261719, "eval/post_ent_mean": 54.957462310791016, "eval/post_ent_min": 53.89969253540039, "eval/post_ent_std": 0.5422440767288208, "eval/prior_ent_mag": 56.69023895263672, "eval/prior_ent_max": 56.69023895263672, "eval/prior_ent_mean": 52.78722381591797, "eval/prior_ent_min": 49.563194274902344, "eval/prior_ent_std": 1.1071025133132935, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.000169350765645504, "eval/reward_loss_std": 0.0010498660849407315, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.008468270301818848, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.000169350765645504, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 8.438434451818466e-05, "eval/reward_rate": 0.0, "replay/size": 572369.0, "replay/inserts": 31840.0, "replay/samples": 31840.0, "replay/insert_wait_avg": 1.364287419534808e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.751574477957721e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.210792391907935e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2367963790893555e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9584560394287, "timer/env.step_count": 3980.0, "timer/env.step_total": 39.66755509376526, "timer/env.step_frac": 0.03966920310957514, "timer/env.step_avg": 0.009966722385368155, "timer/env.step_min": 0.008035421371459961, "timer/env.step_max": 0.0369415283203125, "timer/replay._sample_count": 31840.0, "timer/replay._sample_total": 17.493062496185303, "timer/replay._sample_frac": 0.01749378925747646, "timer/replay._sample_avg": 0.0005494052291515484, "timer/replay._sample_min": 0.00041937828063964844, "timer/replay._sample_max": 0.012078046798706055, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4847.0, "timer/agent.policy_total": 53.00253415107727, "timer/agent.policy_frac": 0.05300473617774713, "timer/agent.policy_avg": 0.010935121549634262, "timer/agent.policy_min": 0.00897979736328125, "timer/agent.policy_max": 0.08615684509277344, "timer/dataset_train_count": 1990.0, "timer/dataset_train_total": 0.23024344444274902, "timer/dataset_train_frac": 0.00023025301006472057, "timer/dataset_train_avg": 0.00011570022333806483, "timer/dataset_train_min": 0.00010061264038085938, "timer/dataset_train_max": 0.00042366981506347656, "timer/agent.train_count": 1990.0, "timer/agent.train_total": 892.4272782802582, "timer/agent.train_frac": 0.8924643547842246, "timer/agent.train_avg": 0.4484559187337981, "timer/agent.train_min": 0.43604040145874023, "timer/agent.train_max": 1.9794270992279053, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4832890033721924, "timer/agent.report_frac": 0.0004833090819456365, "timer/agent.report_avg": 0.2416445016860962, "timer/agent.report_min": 0.23995637893676758, "timer/agent.report_max": 0.2433326244354248, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.6703990248892997e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 31.84076542111757}
{"step": 572936, "time": 18288.768429994583, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 572976, "time": 18290.206437826157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 573008, "time": 18291.184111356735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 573352, "time": 18301.460146665573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 573616, "time": 18310.202681541443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 573632, "time": 18310.69466972351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 574648, "time": 18341.70511198044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 574896, "time": 18349.64525079727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 575248, "time": 18360.421262025833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 575288, "time": 18361.434582710266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 575320, "time": 18362.444951295853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 575664, "time": 18373.275416612625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 575928, "time": 18381.252074956894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 575944, "time": 18381.755578756332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 576960, "time": 18413.36352777481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577208, "time": 18420.713661432266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577560, "time": 18431.46209216118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577600, "time": 18432.926021575928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577632, "time": 18434.06882739067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577976, "time": 18444.3910882473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578240, "time": 18452.698751688004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578256, "time": 18453.19690513611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 579272, "time": 18484.049503087997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 579520, "time": 18491.90664076805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 579872, "time": 18502.771905899048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 579912, "time": 18503.765725135803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 579944, "time": 18504.748061418533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 18513.29206109047, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 18513.299810409546, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 18513.308313846588, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 18513.316413879395, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 18513.324691057205, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 18513.333570718765, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 18513.34193611145, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 18513.350571870804, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580288, "time": 18522.165281057358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 580552, "time": 18530.1257417202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 580568, "time": 18530.61884021759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 581160, "time": 18548.643685102463, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 581360, "time": 18555.09500479698, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 581408, "time": 18556.581550359726, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 581520, "time": 18559.987421512604, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 581576, "time": 18561.49317407608, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 581584, "time": 18561.966284751892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582224, "time": 18582.01131415367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582256, "time": 18582.999935626984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582296, "time": 18584.131576538086, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 582880, "time": 18602.192356348038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582984, "time": 18605.130807876587, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 583672, "time": 18626.277668714523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 583720, "time": 18627.738564252853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 583888, "time": 18633.081419229507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 583896, "time": 18633.11223101616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584536, "time": 18652.88894200325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584608, "time": 18655.333224773407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 585192, "time": 18672.96529340744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 585296, "time": 18676.501648902893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 585984, "time": 18697.460307359695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 586032, "time": 18698.94576573372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 586200, "time": 18703.978031396866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 586208, "time": 18704.451083898544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 586456, "time": 18711.847932338715, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 586640, "time": 18717.712851047516, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 586832, "time": 18723.582065343857, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 586920, "time": 18726.028432130814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 587504, "time": 18744.276161193848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 587608, "time": 18747.221206188202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588344, "time": 18769.811583518982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588360, "time": 18770.307467460632, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 588512, "time": 18775.194818735123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588768, "time": 18783.101204156876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588952, "time": 18788.494228839874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589232, "time": 18797.464343309402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589816, "time": 18815.146122455597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589920, "time": 18819.07456588745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 18825.532247781754, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 590096, "time": 18827.36759877205, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 590096, "time": 18827.726506233215, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 590096, "time": 18829.718118190765, "eval_episode/length": 260.0, "eval_episode/score": 0.1875, "eval_episode/reward_rate": 0.0038314176245210726}
{"step": 590096, "time": 18830.26676416397, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590096, "time": 18830.28548336029, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590096, "time": 18830.294805288315, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590096, "time": 18830.304357290268, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590536, "time": 18843.559924840927, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 590656, "time": 18847.434262752533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 590672, "time": 18847.947892665863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 590680, "time": 18847.976547956467, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 590824, "time": 18852.348611593246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591264, "time": 18866.083914518356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591528, "time": 18873.915800094604, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 591544, "time": 18874.42227578163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591904, "time": 18885.846702098846, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 592232, "time": 18895.644082069397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 592624, "time": 18907.903797388077, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 592808, "time": 18913.371108055115, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 592848, "time": 18914.969884634018, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 592984, "time": 18918.911138772964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593000, "time": 18919.409138917923, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 593200, "time": 18925.7779006958, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 593800, "time": 18944.103273630142, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 594136, "time": 18954.412262678146, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 594216, "time": 18956.924551725388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594440, "time": 18963.87836265564, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 594544, "time": 18967.30402779579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594680, "time": 18971.25633573532, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 594800, "time": 18975.304646253586, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 594936, "time": 18979.31810951233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 595072, "time": 18983.737243652344, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 595120, "time": 18985.20623421669, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 595576, "time": 18998.887128829956, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 595696, "time": 19002.771678447723, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 596032, "time": 19013.143479585648, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 596048, "time": 19013.632879972458, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 596448, "time": 19025.801118850708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 596752, "time": 19035.160948991776, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 596856, "time": 19038.098841667175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 597056, "time": 19044.420792341232, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 597112, "time": 19045.930678844452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 597192, "time": 19048.386397600174, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 597248, "time": 19050.3714056015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 597384, "time": 19054.366983413696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 597640, "time": 19062.29608798027, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 597744, "time": 19065.82539319992, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 597792, "time": 19067.281912088394, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 598008, "time": 19073.69850540161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598120, "time": 19077.64835333824, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 598280, "time": 19082.5647919178, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 598400, "time": 19086.455114364624, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 598472, "time": 19088.443797826767, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 598840, "time": 19099.89176940918, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 598848, "time": 19100.367438316345, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 598928, "time": 19102.837598085403, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 599168, "time": 19110.24310898781, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 599296, "time": 19114.1683883667, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 599368, "time": 19116.17579650879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 599856, "time": 19131.449492692947, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 599952, "time": 19134.374787569046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 600064, "time": 19137.776518821716, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 19139.244814395905, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 600080, "time": 19139.292754650116, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 600080, "time": 19139.82465839386, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 600080, "time": 19139.936805009842, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 600080, "time": 19140.883532762527, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 600080, "time": 19141.471879959106, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 600080, "time": 19141.49792456627, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 600080, "time": 19142.692861557007, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 600120, "time": 19143.714017391205, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 600320, "time": 19150.105420589447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 600384, "time": 19152.092343568802, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 600504, "time": 19155.64059472084, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 600504, "time": 19155.649334430695, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 601024, "time": 19171.85676217079, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 601072, "time": 19173.36063027382, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 601184, "time": 19176.803082227707, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 601208, "time": 19177.33248066902, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 601496, "time": 19186.27003288269, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 601592, "time": 19189.222730398178, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 601680, "time": 19192.129752874374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 602112, "time": 19205.3894572258, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 602376, "time": 19213.263395786285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 602816, "time": 19227.082611083984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 603304, "time": 19241.83093357086, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 603384, "time": 19244.399255752563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 603520, "time": 19248.799865722656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 603808, "time": 19257.563844919205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 603904, "time": 19260.458102464676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 603992, "time": 19262.91486644745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 604424, "time": 19276.166784524918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 604584, "time": 19281.04758954048, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 604712, "time": 19284.957266807556, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 604720, "time": 19285.429750680923, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 604744, "time": 19285.943705558777, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 604761, "time": 19287.47552061081, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.9861126708984376, "train/action_min": 0.0, "train/action_std": 1.7131860181689262, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008500279810396022, "train/actor_opt_grad_steps": 36705.0, "train/actor_opt_loss": -4.895249616205692, "train/adv_mag": 0.5522202275693416, "train/adv_max": 0.22715005844831468, "train/adv_mean": 0.0031314780760294523, "train/adv_min": -0.5335324428975582, "train/adv_std": 0.028209080944070593, "train/cont_avg": 0.996123046875, "train/cont_loss_mean": 0.016039145957911387, "train/cont_loss_std": 0.2403460064716637, "train/cont_neg_acc": 0.2830972775052755, "train/cont_neg_loss": 3.3468079031468965, "train/cont_pos_acc": 0.9998333078622818, "train/cont_pos_loss": 0.0030789146944880485, "train/cont_pred": 0.9960203105211258, "train/cont_rate": 0.996123046875, "train/dyn_loss_mean": 1.00000383913517, "train/dyn_loss_std": 0.00012017737864425726, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.4704163047671318, "train/extr_critic_critic_opt_grad_steps": 36705.0, "train/extr_critic_critic_opt_loss": 7644.210258789062, "train/extr_critic_mag": 0.7108027249574661, "train/extr_critic_max": 0.7108027249574661, "train/extr_critic_mean": 0.6357532134652137, "train/extr_critic_min": 0.6064313977956772, "train/extr_critic_std": 0.011506679211743176, "train/extr_return_normed_mag": 0.5355855214595795, "train/extr_return_normed_max": 0.27238436460494997, "train/extr_return_normed_mean": 0.026431869592879593, "train/extr_return_normed_min": -0.5063470089435578, "train/extr_return_normed_std": 0.03148809394799173, "train/extr_return_rate": 0.9970036259293557, "train/extr_return_raw_mag": 0.8848371770977974, "train/extr_return_raw_max": 0.8848371770977974, "train/extr_return_raw_mean": 0.6388847145438195, "train/extr_return_raw_min": 0.10610580354928971, "train/extr_return_raw_std": 0.03148809392005205, "train/extr_reward_mag": 0.27508089065551755, "train/extr_reward_max": 0.27508089065551755, "train/extr_reward_mean": 0.0017484548247921339, "train/extr_reward_min": 2.199411392211914e-07, "train/extr_reward_std": 0.010439481827925192, "train/image_loss_mean": 0.10927380207926035, "train/image_loss_std": 0.1062021979317069, "train/model_loss_mean": 0.7314589148759842, "train/model_loss_std": 0.3672653729096055, "train/model_opt_grad_norm": 22.662233471870422, "train/model_opt_grad_steps": 36672.525, "train/model_opt_loss": 3029.4661419677736, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4137.5, "train/policy_entropy_mag": 1.3962402993440628, "train/policy_entropy_max": 1.3962402993440628, "train/policy_entropy_mean": 0.14522140741348266, "train/policy_entropy_min": 0.06468674629926681, "train/policy_entropy_std": 0.18377172149717808, "train/policy_logprob_mag": 6.5510799193382265, "train/policy_logprob_max": -0.008608198850415647, "train/policy_logprob_mean": -0.14514686658978462, "train/policy_logprob_min": -6.5510799193382265, "train/policy_logprob_std": 0.6804329940676689, "train/policy_randomness_mag": 0.717525617480278, "train/policy_randomness_max": 0.717525617480278, "train/policy_randomness_mean": 0.0746290455199778, "train/policy_randomness_min": 0.033242413252592085, "train/policy_randomness_std": 0.09443998858332633, "train/post_ent_mag": 52.60568170547485, "train/post_ent_max": 52.60568170547485, "train/post_ent_mean": 50.80883373260498, "train/post_ent_min": 49.506858806610104, "train/post_ent_std": 0.6166230478882789, "train/prior_ent_mag": 54.7888210105896, "train/prior_ent_max": 54.7888210105896, "train/prior_ent_mean": 50.67881072998047, "train/prior_ent_min": 47.29849514007569, "train/prior_ent_std": 1.322426708340645, "train/rep_loss_mean": 1.00000383913517, "train/rep_loss_std": 0.00012017737864425726, "train/reward_avg": 0.000698242186117568, "train/reward_loss_mean": 0.006143640141235664, "train/reward_loss_std": 0.13063523391407217, "train/reward_max_data": 0.466890621855855, "train/reward_max_pred": 0.07935824096202851, "train/reward_neg_acc": 0.9999218168854713, "train/reward_neg_loss": 0.000936651682259253, "train/reward_pos_acc": 0.11132315551961651, "train/reward_pos_loss": 4.958532057645667, "train/reward_pred": 0.0005363901535747573, "train/reward_rate": 0.0010546875, "train_stats/mean_log_entropy": 0.12088732829166425, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.014324607327580452, "report/cont_loss_std": 0.2301209717988968, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 3.1072916984558105, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0021953240502625704, "report/cont_pred": 0.9968266487121582, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09127579629421234, "report/image_loss_std": 0.09740307182073593, "report/model_loss_mean": 0.7123559713363647, "report/model_loss_std": 0.3617400527000427, "report/post_ent_mag": 52.96760559082031, "report/post_ent_max": 52.96760559082031, "report/post_ent_mean": 51.13186264038086, "report/post_ent_min": 49.79465866088867, "report/post_ent_std": 0.6344239711761475, "report/prior_ent_mag": 54.78959274291992, "report/prior_ent_max": 54.78959274291992, "report/prior_ent_mean": 49.93665313720703, "report/prior_ent_min": 46.9874153137207, "report/prior_ent_std": 1.2685229778289795, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0012756347423419356, "report/reward_loss_mean": 0.006755563896149397, "report/reward_loss_std": 0.15699292719364166, "report/reward_max_data": 0.684374988079071, "report/reward_max_pred": 0.4719853401184082, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0008485275320708752, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 3.0252511501312256, "report/reward_pred": 0.0009076507994905114, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.03251844644546509, "eval/cont_loss_std": 0.4785516560077667, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.533610820770264, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.003102399641647935, "eval/cont_pred": 0.9974197149276733, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17118409276008606, "eval/image_loss_std": 0.14089195430278778, "eval/model_loss_mean": 0.8154377937316895, "eval/model_loss_std": 0.7563619613647461, "eval/post_ent_mag": 52.96397399902344, "eval/post_ent_max": 52.96397399902344, "eval/post_ent_mean": 51.034873962402344, "eval/post_ent_min": 49.92919158935547, "eval/post_ent_std": 0.6400634050369263, "eval/prior_ent_mag": 54.90563201904297, "eval/prior_ent_max": 54.90563201904297, "eval/prior_ent_mean": 49.64522933959961, "eval/prior_ent_min": 47.30595397949219, "eval/prior_ent_std": 1.3455287218093872, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0003448486386332661, "eval/reward_loss_mean": 0.011735252104699612, "eval/reward_loss_std": 0.36935946345329285, "eval/reward_max_data": 0.3531250059604645, "eval/reward_max_pred": 0.006973147392272949, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00018717513012234122, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 11.825417518615723, "eval/reward_pred": 9.381957352161407e-05, "eval/reward_rate": 0.0009765625, "replay/size": 604257.0, "replay/inserts": 31888.0, "replay/samples": 31888.0, "replay/insert_wait_avg": 1.3751237163936082e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.597304832737948e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6304.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2380066256837797e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2367963790893555e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.435136795044, "timer/env.step_count": 3986.0, "timer/env.step_total": 39.63802981376648, "timer/env.step_frac": 0.039620789350471405, "timer/env.step_avg": 0.009944312547357372, "timer/env.step_min": 0.008119821548461914, "timer/env.step_max": 0.03635144233703613, "timer/replay._sample_count": 31888.0, "timer/replay._sample_total": 17.620245695114136, "timer/replay._sample_frac": 0.017612581812711702, "timer/replay._sample_avg": 0.0005525666612868207, "timer/replay._sample_min": 0.0004355907440185547, "timer/replay._sample_max": 0.03153872489929199, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4774.0, "timer/agent.policy_total": 52.5179922580719, "timer/agent.policy_frac": 0.0524951496868818, "timer/agent.policy_avg": 0.011000836250119795, "timer/agent.policy_min": 0.009145021438598633, "timer/agent.policy_max": 0.09523558616638184, "timer/dataset_train_count": 1993.0, "timer/dataset_train_total": 0.23511528968811035, "timer/dataset_train_frac": 0.00023501302687280333, "timer/dataset_train_avg": 0.00011797054174014569, "timer/dataset_train_min": 0.00010251998901367188, "timer/dataset_train_max": 0.00107574462890625, "timer/agent.train_count": 1993.0, "timer/agent.train_total": 893.9276461601257, "timer/agent.train_frac": 0.8935388345354187, "timer/agent.train_avg": 0.44853369099855783, "timer/agent.train_min": 0.4337446689605713, "timer/agent.train_max": 0.6958043575286865, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4998204708099365, "timer/agent.report_frac": 0.0004996030751290308, "timer/agent.report_avg": 0.24991023540496826, "timer/agent.report_min": 0.24068045616149902, "timer/agent.report_max": 0.2591400146484375, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.2887453374956886e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 31.873558441317805}
{"step": 604984, "time": 19294.097256183624, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 605064, "time": 19296.542234182358, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 605128, "time": 19298.52641272545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 605616, "time": 19313.837701797485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 605632, "time": 19314.332721710205, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 605640, "time": 19314.361170053482, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 605680, "time": 19315.819780111313, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 605696, "time": 19316.31396842003, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 605832, "time": 19320.241759300232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 606400, "time": 19338.449843645096, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 606520, "time": 19341.917643785477, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 606520, "time": 19341.927350521088, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 606800, "time": 19350.69204235077, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 606824, "time": 19351.207382678986, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 606928, "time": 19354.587703943253, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 607440, "time": 19370.45511651039, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 607880, "time": 19383.709075450897, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 608008, "time": 19387.64321255684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608144, "time": 19392.0736014843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608336, "time": 19398.068469285965, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 608464, "time": 19402.029469251633, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 608832, "time": 19413.361637830734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608832, "time": 19413.36919617653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 609112, "time": 19421.783219337463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 609136, "time": 19422.755981445312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 609336, "time": 19428.831260204315, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 609640, "time": 19438.19840669632, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 609704, "time": 19440.1647503376, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 610024, "time": 19450.011137485504, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 610024, "time": 19450.021858215332, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 19453.35676074028, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 610064, "time": 19453.478177547455, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 610064, "time": 19453.853823661804, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 610064, "time": 19454.70735859871, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 610064, "time": 19456.72711110115, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 610064, "time": 19457.574646234512, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610064, "time": 19457.584547281265, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610064, "time": 19457.596161842346, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610064, "time": 19457.60537648201, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610064, "time": 19457.615542411804, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610592, "time": 19473.797847747803, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 610648, "time": 19475.29254436493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 610776, "time": 19479.22344636917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 610848, "time": 19481.691083669662, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 611040, "time": 19487.710230588913, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 611120, "time": 19490.159895181656, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 611144, "time": 19490.677176475525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 611384, "time": 19498.00577569008, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 611424, "time": 19499.45483827591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 611576, "time": 19503.89564538002, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 611928, "time": 19514.70106625557, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 612168, "time": 19522.04243159294, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 612296, "time": 19525.97552537918, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 612336, "time": 19527.421283006668, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 612904, "time": 19544.75719809532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 613352, "time": 19558.40497136116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 613400, "time": 19559.89281654358, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 613736, "time": 19570.190116643906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 614240, "time": 19585.899785518646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 614304, "time": 19587.8562335968, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 614392, "time": 19590.314238786697, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 614416, "time": 19591.774538517, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 614528, "time": 19595.1875269413, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 614608, "time": 19597.61937403679, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 614664, "time": 19599.109781980515, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 614768, "time": 19602.513659000397, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 614792, "time": 19603.033084392548, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 614976, "time": 19609.012721538544, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 615000, "time": 19609.556398153305, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 615240, "time": 19616.858109235764, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 615400, "time": 19621.752432346344, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 615776, "time": 19633.4283118248, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 616616, "time": 19658.82595348358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 616976, "time": 19670.114094257355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617080, "time": 19673.093611478806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617104, "time": 19674.053113222122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617312, "time": 19680.403259515762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617464, "time": 19684.819069862366, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 617480, "time": 19685.31436276436, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 617552, "time": 19687.75483584404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617712, "time": 19692.658722400665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 618088, "time": 19704.059436798096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 618864, "time": 19728.488975286484, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 618880, "time": 19728.985508680344, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 619184, "time": 19738.323878526688, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 619360, "time": 19743.737756967545, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 619368, "time": 19743.766791820526, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 619392, "time": 19744.730343818665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 619512, "time": 19748.19382739067, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 619792, "time": 19757.174020290375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 620024, "time": 19764.110762119293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 19766.74000453949, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 620048, "time": 19767.145237207413, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 620048, "time": 19768.221569299698, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 620048, "time": 19770.153755664825, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 620048, "time": 19771.66656255722, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 19771.67599415779, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 19771.685453414917, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 19771.695196151733, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 19771.7034137249, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 19771.711458206177, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620080, "time": 19772.697427988052, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 620096, "time": 19773.19189310074, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 620304, "time": 19779.536070108414, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 620360, "time": 19781.01556277275, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 620808, "time": 19794.8100938797, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 621192, "time": 19806.565852880478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 621424, "time": 19814.109862804413, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 621704, "time": 19822.528401851654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 621736, "time": 19823.53622341156, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 622056, "time": 19833.386195898056, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 622256, "time": 19839.752161979675, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 622336, "time": 19842.209675312042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 622392, "time": 19843.79193520546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 622512, "time": 19847.802374601364, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 622632, "time": 19851.761377811432, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 622976, "time": 19862.554260253906, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 623064, "time": 19865.04430747032, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 623072, "time": 19865.519483089447, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 623120, "time": 19867.012345552444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 623664, "time": 19884.033745765686, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 623736, "time": 19886.0592918396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 623760, "time": 19887.041324853897, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 623896, "time": 19891.04713654518, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 624048, "time": 19895.922826051712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 624176, "time": 19899.865678310394, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 624568, "time": 19911.793395519257, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 624672, "time": 19915.203812599182, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 624736, "time": 19917.163935661316, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 625168, "time": 19930.42686033249, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 625288, "time": 19934.045653104782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 625376, "time": 19936.966064929962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 625376, "time": 19936.97420525551, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 625640, "time": 19944.849118709564, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 625832, "time": 19950.74400448799, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 626016, "time": 19956.63748717308, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 626304, "time": 19965.601142406464, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 626360, "time": 19967.10012292862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 626936, "time": 19984.788488149643, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 627024, "time": 19987.710800647736, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 627112, "time": 19990.186456680298, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 627128, "time": 19990.686705112457, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 627480, "time": 20001.633447885513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 627688, "time": 20008.098693847656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 627824, "time": 20012.537175416946, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 627984, "time": 20017.45617222786, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 628056, "time": 20019.451454877853, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 628144, "time": 20022.40220427513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 628328, "time": 20027.99411869049, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 628760, "time": 20041.295809030533, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 629008, "time": 20049.14603447914, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 629248, "time": 20056.64421248436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 629440, "time": 20062.529516220093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 629552, "time": 20065.975788354874, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 629784, "time": 20072.87082672119, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 630000, "time": 20079.752835035324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 630016, "time": 20080.260353565216, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 20081.508775234222, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 630032, "time": 20082.145066976547, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 630032, "time": 20082.469898700714, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 630032, "time": 20082.640964984894, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 630032, "time": 20083.295268297195, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 630032, "time": 20084.153225898743, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 630032, "time": 20085.025730848312, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 630032, "time": 20085.138744831085, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 630072, "time": 20086.155453681946, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 630136, "time": 20088.12890148163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 630280, "time": 20092.55514883995, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 630368, "time": 20095.49170732498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 630568, "time": 20101.38716006279, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 630688, "time": 20105.2862098217, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 631040, "time": 20116.659782409668, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 631208, "time": 20121.57514858246, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 631280, "time": 20124.008219003677, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 631560, "time": 20132.40626335144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 631672, "time": 20135.860910654068, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 632040, "time": 20147.308192014694, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 632096, "time": 20149.26596736908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 632096, "time": 20149.275141954422, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 632448, "time": 20160.091537952423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 632680, "time": 20166.94217967987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 632688, "time": 20167.415073156357, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 632880, "time": 20173.31882596016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 633352, "time": 20187.696293115616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 633624, "time": 20196.070764541626, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 633680, "time": 20198.013897180557, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 633912, "time": 20205.02479815483, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 633984, "time": 20207.454914569855, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 633984, "time": 20207.462190389633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 634120, "time": 20211.445702314377, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 634176, "time": 20213.366490125656, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 634408, "time": 20220.239827156067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 634408, "time": 20220.28678035736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 634848, "time": 20234.05702495575, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 635016, "time": 20238.961327552795, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 635064, "time": 20240.4358689785, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 635064, "time": 20240.445068836212, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 635464, "time": 20252.62342429161, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 635728, "time": 20260.95372247696, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 635736, "time": 20260.981016874313, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 635936, "time": 20267.463364124298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 635976, "time": 20268.481703281403, "episode/length": 286.0, "episode/score": 0.10625000298023224, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.0}
{"step": 636120, "time": 20272.901746749878, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 636192, "time": 20275.33309841156, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 636208, "time": 20275.83587384224, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 636248, "time": 20276.852065563202, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 636320, "time": 20279.312690496445, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 636560, "time": 20286.64905333519, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 636569, "time": 20287.72641849518, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3225763494318183, "train/action_min": 0.0, "train/action_std": 1.7782625134545142, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013249813210374365, "train/actor_opt_grad_steps": 38695.0, "train/actor_opt_loss": -2.6416568267958787, "train/adv_mag": 0.754306288680645, "train/adv_max": 0.27876215510898167, "train/adv_mean": 0.005618000069831635, "train/adv_min": -0.7421903495836739, "train/adv_std": 0.041053845119107556, "train/cont_avg": 0.9956843828914141, "train/cont_loss_mean": 0.01640280692560617, "train/cont_loss_std": 0.2430221294052899, "train/cont_neg_acc": 0.34425913047064377, "train/cont_neg_loss": 3.0231034394441085, "train/cont_pos_acc": 0.9998513713027491, "train/cont_pos_loss": 0.003053775428784917, "train/cont_pred": 0.995711490662411, "train/cont_rate": 0.9956843828914141, "train/dyn_loss_mean": 1.0000079545107754, "train/dyn_loss_std": 0.00022699374985126215, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.522716635744078, "train/extr_critic_critic_opt_grad_steps": 38695.0, "train/extr_critic_critic_opt_loss": 8256.457007822364, "train/extr_critic_mag": 0.875314555384896, "train/extr_critic_max": 0.875314555384896, "train/extr_critic_mean": 0.8234885563754072, "train/extr_critic_min": 0.7803009628045439, "train/extr_critic_std": 0.014360569222275205, "train/extr_return_normed_mag": 0.7260558400491272, "train/extr_return_normed_max": 0.33795932958824465, "train/extr_return_normed_mean": 0.04226565121842379, "train/extr_return_normed_min": -0.7041900555292765, "train/extr_return_normed_std": 0.044730708760331674, "train/extr_return_rate": 0.9965044798875096, "train/extr_return_raw_mag": 1.124800200414176, "train/extr_return_raw_max": 1.124800200414176, "train/extr_return_raw_mean": 0.8291065732035974, "train/extr_return_raw_min": 0.08265081529665474, "train/extr_return_raw_std": 0.044730708732109783, "train/extr_reward_mag": 0.35204644757087783, "train/extr_reward_max": 0.35204644757087783, "train/extr_reward_mean": 0.002705922946107522, "train/extr_reward_min": 1.27638229215988e-07, "train/extr_reward_std": 0.014949733230892118, "train/image_loss_mean": 0.1094846541833396, "train/image_loss_std": 0.10809173148990882, "train/model_loss_mean": 0.732299376918812, "train/model_loss_std": 0.3691074810545854, "train/model_opt_grad_norm": 21.178906421468714, "train/model_opt_grad_steps": 38660.818181818184, "train/model_opt_loss": 3172.590369022254, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4330.80808080808, "train/policy_entropy_mag": 1.3985671057845608, "train/policy_entropy_max": 1.3985671057845608, "train/policy_entropy_mean": 0.1377631522564575, "train/policy_entropy_min": 0.0646866268356039, "train/policy_entropy_std": 0.17733940783173147, "train/policy_logprob_mag": 6.551080236531267, "train/policy_logprob_max": -0.008608152859402125, "train/policy_logprob_mean": -0.13806846941059286, "train/policy_logprob_min": -6.551080236531267, "train/policy_logprob_std": 0.6748077583433402, "train/policy_randomness_mag": 0.7187213587640512, "train/policy_randomness_max": 0.7187213587640512, "train/policy_randomness_mean": 0.07079625933083018, "train/policy_randomness_min": 0.03324235264550556, "train/policy_randomness_std": 0.09113443302310477, "train/post_ent_mag": 51.65240482368855, "train/post_ent_max": 51.65240482368855, "train/post_ent_mean": 49.62542820940114, "train/post_ent_min": 48.10498328160758, "train/post_ent_std": 0.745372289057934, "train/prior_ent_mag": 53.10118673305319, "train/prior_ent_max": 53.10118673305319, "train/prior_ent_mean": 49.02306811014811, "train/prior_ent_min": 45.59828987506905, "train/prior_ent_std": 1.3499525520536635, "train/rep_loss_mean": 1.0000079545107754, "train/rep_loss_std": 0.00022699374985126215, "train/reward_avg": 0.0007472028637953418, "train/reward_loss_mean": 0.0064071212199074455, "train/reward_loss_std": 0.12776282337562397, "train/reward_max_data": 0.4664457066718376, "train/reward_max_pred": 0.12507860528098214, "train/reward_neg_acc": 0.9999160263875518, "train/reward_neg_loss": 0.0010579724114381172, "train/reward_pos_acc": 0.1891025653252235, "train/reward_pos_loss": 4.551267908169673, "train/reward_pred": 0.0006247688016637859, "train/reward_rate": 0.0011639835858585858, "train_stats/mean_log_entropy": 0.11284270510077477, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.01769237220287323, "report/cont_loss_std": 0.2790006697177887, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 3.841766834259033, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0026960016693919897, "report/cont_pred": 0.9964039325714111, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10803742706775665, "report/image_loss_std": 0.10253554582595825, "report/model_loss_mean": 0.7314883470535278, "report/model_loss_std": 0.3950542211532593, "report/post_ent_mag": 49.703453063964844, "report/post_ent_max": 49.703453063964844, "report/post_ent_mean": 47.60249710083008, "report/post_ent_min": 46.10444641113281, "report/post_ent_std": 0.7344893217086792, "report/prior_ent_mag": 51.18183135986328, "report/prior_ent_max": 51.18183135986328, "report/prior_ent_mean": 47.366092681884766, "report/prior_ent_min": 43.12681579589844, "report/prior_ent_std": 1.5118547677993774, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006652831798419356, "report/reward_loss_mean": 0.005758456885814667, "report/reward_loss_std": 0.15094058215618134, "report/reward_max_data": 0.6812499761581421, "report/reward_max_pred": 0.01991879940032959, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0010407527443021536, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.831969738006592, "report/reward_pred": 0.0005252702394500375, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9912109375, "eval/cont_loss_mean": 0.06879977136850357, "eval/cont_loss_std": 0.7288249731063843, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.560390949249268, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002371867885813117, "eval/cont_pred": 0.9977655410766602, "eval/cont_rate": 0.9912109375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18369121849536896, "eval/image_loss_std": 0.14981630444526672, "eval/model_loss_mean": 0.859423041343689, "eval/model_loss_std": 0.8172896504402161, "eval/post_ent_mag": 49.70741271972656, "eval/post_ent_max": 49.70741271972656, "eval/post_ent_mean": 47.41168975830078, "eval/post_ent_min": 45.95900344848633, "eval/post_ent_std": 0.7787927985191345, "eval/prior_ent_mag": 51.14192581176758, "eval/prior_ent_max": 51.14192581176758, "eval/prior_ent_mean": 46.98210525512695, "eval/prior_ent_min": 42.8855094909668, "eval/prior_ent_std": 1.5075457096099854, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0004791259707417339, "eval/reward_loss_mean": 0.006932015065103769, "eval/reward_loss_std": 0.21103502810001373, "eval/reward_max_data": 0.4906249940395355, "eval/reward_max_pred": 0.02000141143798828, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00033427917514927685, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.756415843963623, "eval/reward_pred": 0.00016337435226887465, "eval/reward_rate": 0.0009765625, "replay/size": 636065.0, "replay/inserts": 31808.0, "replay/samples": 31808.0, "replay/insert_wait_avg": 1.3776078550388635e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.670238979385652e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6136.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2366992398377658e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2814998626708984e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2311758995056, "timer/env.step_count": 3976.0, "timer/env.step_total": 39.5928430557251, "timer/env.step_frac": 0.03958369226006112, "timer/env.step_avg": 0.009957958515021403, "timer/env.step_min": 0.007997751235961914, "timer/env.step_max": 0.036829471588134766, "timer/replay._sample_count": 31808.0, "timer/replay._sample_total": 17.475839614868164, "timer/replay._sample_frac": 0.017471800555658727, "timer/replay._sample_avg": 0.0005494164868859458, "timer/replay._sample_min": 0.0003902912139892578, "timer/replay._sample_max": 0.010762691497802734, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4743.0, "timer/agent.policy_total": 52.715216875076294, "timer/agent.policy_frac": 0.05270303320396869, "timer/agent.policy_avg": 0.011114319391751275, "timer/agent.policy_min": 0.009282112121582031, "timer/agent.policy_max": 0.0943460464477539, "timer/dataset_train_count": 1988.0, "timer/dataset_train_total": 0.23399090766906738, "timer/dataset_train_frac": 0.00023393682711263212, "timer/dataset_train_avg": 0.00011770166381743832, "timer/dataset_train_min": 9.870529174804688e-05, "timer/dataset_train_max": 0.0006499290466308594, "timer/agent.train_count": 1988.0, "timer/agent.train_total": 893.2390508651733, "timer/agent.train_frac": 0.8930326032498292, "timer/agent.train_avg": 0.44931541794022806, "timer/agent.train_min": 0.4349653720855713, "timer/agent.train_max": 0.6934549808502197, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5226225852966309, "timer/agent.report_frac": 0.0005225017954740689, "timer/agent.report_avg": 0.26131129264831543, "timer/agent.report_min": 0.2569723129272461, "timer/agent.report_max": 0.26565027236938477, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.838539123535156e-05, "timer/dataset_eval_frac": 3.837651950893419e-08, "timer/dataset_eval_avg": 3.838539123535156e-05, "timer/dataset_eval_min": 3.838539123535156e-05, "timer/dataset_eval_max": 3.838539123535156e-05, "fps": 31.800084316580183}
{"step": 636720, "time": 20292.4124417305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636752, "time": 20293.415800333023, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 636808, "time": 20295.054309129715, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 636848, "time": 20296.512778043747, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 637000, "time": 20300.974637031555, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 637296, "time": 20310.33374285698, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 637464, "time": 20315.2892267704, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 637688, "time": 20322.169403076172, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 637896, "time": 20328.717742919922, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 638248, "time": 20339.606392860413, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 638360, "time": 20343.089096546173, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 638432, "time": 20345.531132221222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 639064, "time": 20365.468737602234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 639160, "time": 20368.434113264084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 639312, "time": 20373.363033771515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 639344, "time": 20374.34716653824, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 639696, "time": 20385.281147241592, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 639728, "time": 20386.26721072197, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 639776, "time": 20387.739983081818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 20396.143448591232, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 640016, "time": 20396.259994983673, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 640016, "time": 20396.443398952484, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 640016, "time": 20396.672263145447, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 640016, "time": 20396.772889137268, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 640016, "time": 20397.71791100502, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 640016, "time": 20398.020123958588, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 640016, "time": 20398.122861385345, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 640208, "time": 20404.047626256943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640240, "time": 20405.038986206055, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 640600, "time": 20416.08711862564, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 640632, "time": 20417.072646141052, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 640744, "time": 20420.4951877594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640872, "time": 20424.43937444687, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 640920, "time": 20425.940091133118, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 641376, "time": 20440.116250276566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 641424, "time": 20441.617395401, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 641592, "time": 20446.731584072113, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 641840, "time": 20454.572454214096, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 641840, "time": 20454.581308841705, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 641912, "time": 20456.591349363327, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 641928, "time": 20457.088052272797, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 642088, "time": 20461.996344089508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 642128, "time": 20463.450576782227, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 642520, "time": 20475.50217652321, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 642696, "time": 20480.97580265999, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 642744, "time": 20482.501169919968, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 642816, "time": 20484.94274520874, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 643232, "time": 20497.722941875458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643424, "time": 20503.65480685234, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 643560, "time": 20507.721612930298, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 643656, "time": 20510.70227766037, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 643688, "time": 20511.697632551193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643856, "time": 20517.114725351334, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 644056, "time": 20523.011806726456, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 644152, "time": 20525.964382886887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 644152, "time": 20525.972348213196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 644168, "time": 20526.46807909012, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 644224, "time": 20528.397700548172, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 644552, "time": 20538.433235406876, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 644640, "time": 20541.379026174545, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 644688, "time": 20542.85814857483, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 644784, "time": 20545.829302549362, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 644832, "time": 20547.308584213257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 644920, "time": 20549.798127651215, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 645128, "time": 20556.20759820938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 645312, "time": 20562.096212863922, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 645320, "time": 20562.124204158783, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 645368, "time": 20563.652616262436, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 645672, "time": 20573.084321022034, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 646376, "time": 20594.83568406105, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 646448, "time": 20597.287281036377, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 646480, "time": 20598.278812408447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 646672, "time": 20604.239535808563, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 646728, "time": 20605.751605272293, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 646864, "time": 20610.1747610569, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 647048, "time": 20615.63450860977, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 647232, "time": 20622.005427360535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 647552, "time": 20631.998861551285, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 647616, "time": 20633.977349996567, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 647624, "time": 20634.009273052216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 647632, "time": 20634.511790275574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 647840, "time": 20640.934235572815, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 648760, "time": 20669.178952217102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 648776, "time": 20669.676079034805, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 648984, "time": 20676.061475276947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 649176, "time": 20681.938329458237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 649248, "time": 20684.54367184639, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 649264, "time": 20685.04344344139, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 649272, "time": 20685.07355427742, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 649736, "time": 20699.356410741806, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 650000, "time": 20708.4467959404, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 650000, "time": 20708.76946759224, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 650000, "time": 20709.433901548386, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 650000, "time": 20709.69794535637, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 650000, "time": 20709.87782073021, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 650000, "time": 20709.883057832718, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 650000, "time": 20710.12632036209, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 650000, "time": 20710.71026611328, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 650096, "time": 20713.705637216568, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 650224, "time": 20717.744509220123, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 650248, "time": 20718.27175760269, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 650464, "time": 20725.147948741913, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 650488, "time": 20725.66908621788, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 650520, "time": 20726.680457115173, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 650568, "time": 20728.169665813446, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 650792, "time": 20735.103869199753, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 650896, "time": 20738.545218467712, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 651008, "time": 20742.038724422455, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 651176, "time": 20747.145748138428, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 651320, "time": 20751.634213924408, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 651552, "time": 20759.034519672394, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 651584, "time": 20760.031979084015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 651656, "time": 20762.041119337082, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 651664, "time": 20762.515076637268, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 651808, "time": 20766.944016456604, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 651848, "time": 20767.956691265106, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 652752, "time": 20796.177174806595, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 652880, "time": 20800.094913959503, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 653200, "time": 20810.056660175323, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 653208, "time": 20810.084187746048, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 653376, "time": 20815.446753263474, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 653488, "time": 20818.87858247757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 653696, "time": 20825.25587773323, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 653864, "time": 20830.198291778564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 653896, "time": 20831.210127830505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 654120, "time": 20838.180755376816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 654432, "time": 20847.97970223427, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 654536, "time": 20850.943258047104, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 654632, "time": 20853.887954711914, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 655064, "time": 20867.338459968567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 655264, "time": 20873.703649044037, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 655304, "time": 20874.714763641357, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 655512, "time": 20881.61769104004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 655688, "time": 20886.99955368042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 655776, "time": 20889.913861751556, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 655960, "time": 20895.534803390503, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 656008, "time": 20897.003391742706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656256, "time": 20904.809466362, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 656432, "time": 20910.238411188126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656744, "time": 20919.59568810463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656848, "time": 20923.024953126907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 657312, "time": 20937.44032073021, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 657608, "time": 20946.300293922424, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 657784, "time": 20951.702917337418, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 657896, "time": 20955.24375462532, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 658000, "time": 20958.646412849426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 658088, "time": 20961.142414093018, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 658272, "time": 20967.006662130356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 658320, "time": 20968.491537094116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 658576, "time": 20976.366434812546, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 658848, "time": 20984.876230716705, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 659040, "time": 20990.790193796158, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 659064, "time": 20991.31143927574, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 659088, "time": 20992.28688788414, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 659160, "time": 20994.28912472725, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 659168, "time": 20994.7650141716, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 659608, "time": 21008.02036547661, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 659624, "time": 21008.518162965775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 659672, "time": 21010.010021686554, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 659744, "time": 21012.443991184235, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 659784, "time": 21013.4623606205, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 660048, "time": 21021.947823524475, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 21023.249694108963, "eval_episode/length": 14.0, "eval_episode/score": 0.956250011920929, "eval_episode/reward_rate": 0.06666666666666667}
{"step": 660088, "time": 21024.28340268135, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 660088, "time": 21024.52836203575, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 660088, "time": 21025.143297195435, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 660088, "time": 21025.485610723495, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 660088, "time": 21026.406908988953, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 660088, "time": 21026.791605949402, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 660088, "time": 21026.817413806915, "eval_episode/length": 195.0, "eval_episode/score": 0.390625, "eval_episode/reward_rate": 0.00510204081632653}
{"step": 660096, "time": 21027.291248083115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 660472, "time": 21040.422739505768, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 660776, "time": 21049.903821229935, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 660920, "time": 21054.344355344772, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 660968, "time": 21055.825796842575, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 660984, "time": 21056.323457479477, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 661472, "time": 21071.54576420784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 661512, "time": 21072.54376935959, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 661824, "time": 21082.434814214706, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 662056, "time": 21089.32110285759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662360, "time": 21098.61486887932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662472, "time": 21102.054989099503, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 662784, "time": 21111.9885597229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 663032, "time": 21119.384435653687, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 663088, "time": 21121.352150201797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 663232, "time": 21125.776314735413, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 663680, "time": 21140.161103487015, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 663824, "time": 21144.587758541107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 663896, "time": 21146.579600572586, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 664280, "time": 21158.353143692017, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 664384, "time": 21161.751854658127, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 664392, "time": 21161.781849384308, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 664472, "time": 21164.39751124382, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 665296, "time": 21189.920316696167, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 665344, "time": 21191.40777015686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 665640, "time": 21200.418170928955, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 665832, "time": 21206.31068587303, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 666136, "time": 21215.666417837143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 666696, "time": 21233.008463859558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 666704, "time": 21233.484810590744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 666784, "time": 21235.94093489647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 667264, "time": 21250.66429400444, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 667472, "time": 21257.183644771576, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 667560, "time": 21259.64567732811, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 667608, "time": 21261.126145124435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 667656, "time": 21262.613728523254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 667784, "time": 21266.540459394455, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 668144, "time": 21277.812268018723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668232, "time": 21280.28483605385, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 668441, "time": 21287.841007232666, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1780328369140625, "train/action_min": 0.0, "train/action_std": 1.76621120095253, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012551236772560514, "train/actor_opt_grad_steps": 40685.0, "train/actor_opt_loss": -4.267581324558705, "train/adv_mag": 0.8220600220561027, "train/adv_max": 0.27840198427438734, "train/adv_mean": 0.00493400395802837, "train/adv_min": -0.8088165637850762, "train/adv_std": 0.041952497703023256, "train/cont_avg": 0.995771484375, "train/cont_loss_mean": 0.014967084781965241, "train/cont_loss_std": 0.22545132492901757, "train/cont_neg_acc": 0.3812594782542344, "train/cont_neg_loss": 2.7782755871862057, "train/cont_pos_acc": 0.9998578161001206, "train/cont_pos_loss": 0.0029804499153397047, "train/cont_pred": 0.9956447583436966, "train/cont_rate": 0.995771484375, "train/dyn_loss_mean": 1.0000147223472595, "train/dyn_loss_std": 0.00030066902341786773, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.5108263464085758, "train/extr_critic_critic_opt_grad_steps": 40685.0, "train/extr_critic_critic_opt_loss": 7904.483376464844, "train/extr_critic_mag": 0.9785321033000947, "train/extr_critic_max": 0.9785321033000947, "train/extr_critic_mean": 0.9196228423714637, "train/extr_critic_min": 0.857614597082138, "train/extr_critic_std": 0.014571070014499128, "train/extr_return_normed_mag": 0.7907597434520721, "train/extr_return_normed_max": 0.32608398705720903, "train/extr_return_normed_mean": 0.04316375401249388, "train/extr_return_normed_min": -0.7684170758724213, "train/extr_return_normed_std": 0.04535846029408276, "train/extr_return_rate": 0.9975579899549484, "train/extr_return_raw_mag": 1.2074770271778106, "train/extr_return_raw_max": 1.2074770271778106, "train/extr_return_raw_mean": 0.9245568436384201, "train/extr_return_raw_min": 0.11297596424818039, "train/extr_return_raw_std": 0.04535846034996212, "train/extr_reward_mag": 0.3447845488786697, "train/extr_reward_max": 0.3447845488786697, "train/extr_reward_mean": 0.0028350105859863105, "train/extr_reward_min": 5.7220458984375e-08, "train/extr_reward_std": 0.01511117712012492, "train/image_loss_mean": 0.10421976443380117, "train/image_loss_std": 0.10629996433854103, "train/model_loss_mean": 0.7265181571245194, "train/model_loss_std": 0.36982496034353973, "train/model_opt_grad_norm": 21.142429213523865, "train/model_opt_grad_steps": 40649.17, "train/model_opt_loss": 3687.1119018554687, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5075.0, "train/policy_entropy_mag": 1.4102676278352737, "train/policy_entropy_max": 1.4102676278352737, "train/policy_entropy_mean": 0.1222810297459364, "train/policy_entropy_min": 0.06468655601143837, "train/policy_entropy_std": 0.15940978214144708, "train/policy_logprob_mag": 6.551080253124237, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.12202003177255392, "train/policy_logprob_min": -6.551080253124237, "train/policy_logprob_std": 0.6578807148337364, "train/policy_randomness_mag": 0.7247342398762703, "train/policy_randomness_max": 0.7247342398762703, "train/policy_randomness_mean": 0.06284002209082246, "train/policy_randomness_min": 0.0332423160970211, "train/policy_randomness_std": 0.08192042782902717, "train/post_ent_mag": 50.10341932296753, "train/post_ent_max": 50.10341932296753, "train/post_ent_mean": 47.64323703765869, "train/post_ent_min": 45.88260639190674, "train/post_ent_std": 0.893350965976715, "train/prior_ent_mag": 50.48921510696411, "train/prior_ent_max": 50.48921510696411, "train/prior_ent_mean": 46.75687828063965, "train/prior_ent_min": 43.6413623046875, "train/prior_ent_std": 1.2361803904175759, "train/rep_loss_mean": 1.0000147223472595, "train/rep_loss_std": 0.00030066902341786773, "train/reward_avg": 0.000825531008595135, "train/reward_loss_mean": 0.007322450178908185, "train/reward_loss_std": 0.14449140738870483, "train/reward_max_data": 0.4942968727648258, "train/reward_max_pred": 0.10783056795597076, "train/reward_neg_acc": 0.9999217531085014, "train/reward_neg_loss": 0.0011641463705745992, "train/reward_pos_acc": 0.15045977070413788, "train/reward_pos_loss": 4.763950555900047, "train/reward_pred": 0.0006758144951891154, "train/reward_rate": 0.001298828125, "train_stats/mean_log_entropy": 0.10169792308195218, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.014634802006185055, "report/cont_loss_std": 0.2801028788089752, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 4.110392093658447, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002600256586447358, "report/cont_pred": 0.9964922666549683, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07195553183555603, "report/image_loss_std": 0.08857358992099762, "report/model_loss_mean": 0.6888831853866577, "report/model_loss_std": 0.29429861903190613, "report/post_ent_mag": 49.94623565673828, "report/post_ent_max": 49.94623565673828, "report/post_ent_mean": 47.14991760253906, "report/post_ent_min": 45.102867126464844, "report/post_ent_std": 0.9469819068908691, "report/prior_ent_mag": 50.49769592285156, "report/prior_ent_max": 50.49769592285156, "report/prior_ent_mean": 46.42890167236328, "report/prior_ent_min": 42.838470458984375, "report/prior_ent_std": 1.1830644607543945, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0005371093866415322, "report/reward_loss_mean": 0.0022928868420422077, "report/reward_loss_std": 0.03429180756211281, "report/reward_max_data": 0.550000011920929, "report/reward_max_pred": 0.5501618385314941, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0012327622389420867, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 1.086800456047058, "report/reward_pred": 0.001126583432778716, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.03631160035729408, "eval/cont_loss_std": 0.566370964050293, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.847232818603516, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0017589641502127051, "eval/cont_pred": 0.9982948303222656, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22396445274353027, "eval/image_loss_std": 0.17012912034988403, "eval/model_loss_mean": 0.8728058934211731, "eval/model_loss_std": 0.8742745518684387, "eval/post_ent_mag": 49.94715881347656, "eval/post_ent_max": 49.94715881347656, "eval/post_ent_mean": 46.97193145751953, "eval/post_ent_min": 44.969993591308594, "eval/post_ent_std": 0.9468691945075989, "eval/prior_ent_mag": 50.50724792480469, "eval/prior_ent_max": 50.50724792480469, "eval/prior_ent_mean": 46.09861755371094, "eval/prior_ent_min": 42.85858154296875, "eval/prior_ent_std": 1.1749969720840454, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0005126952892169356, "eval/reward_loss_mean": 0.012529797852039337, "eval/reward_loss_std": 0.3858441412448883, "eval/reward_max_data": 0.5249999761581421, "eval/reward_max_pred": 0.0177001953125, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00046654531615786254, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 12.35323715209961, "eval/reward_pred": 0.00022850302048027515, "eval/reward_rate": 0.0009765625, "replay/size": 667937.0, "replay/inserts": 31872.0, "replay/samples": 31872.0, "replay/insert_wait_avg": 1.3700615330393535e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.671167795916637e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3944.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1718418245141452e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0954120159149, "timer/env.step_count": 3984.0, "timer/env.step_total": 39.558162212371826, "timer/env.step_frac": 0.03955438824845076, "timer/env.step_avg": 0.009929257583426663, "timer/env.step_min": 0.007883787155151367, "timer/env.step_max": 0.04059028625488281, "timer/replay._sample_count": 31872.0, "timer/replay._sample_total": 17.47326397895813, "timer/replay._sample_frac": 0.01747159697866914, "timer/replay._sample_avg": 0.0005482324290586762, "timer/replay._sample_min": 0.0004088878631591797, "timer/replay._sample_max": 0.011757850646972656, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4477.0, "timer/agent.policy_total": 48.97825837135315, "timer/agent.policy_frac": 0.04897358570281466, "timer/agent.policy_avg": 0.010939972832555985, "timer/agent.policy_min": 0.00918889045715332, "timer/agent.policy_max": 0.08475542068481445, "timer/dataset_train_count": 1992.0, "timer/dataset_train_total": 0.23296570777893066, "timer/dataset_train_frac": 0.0002329434821717024, "timer/dataset_train_avg": 0.00011695065651552744, "timer/dataset_train_min": 9.846687316894531e-05, "timer/dataset_train_max": 0.0003657341003417969, "timer/agent.train_count": 1992.0, "timer/agent.train_total": 900.4454879760742, "timer/agent.train_frac": 0.9003595828532259, "timer/agent.train_avg": 0.4520308674578686, "timer/agent.train_min": 0.4378330707550049, "timer/agent.train_max": 2.2302021980285645, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5184738636016846, "timer/agent.report_frac": 0.0005184243996846112, "timer/agent.report_avg": 0.2592369318008423, "timer/agent.report_min": 0.25380802154541016, "timer/agent.report_max": 0.2646658420562744, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.122985415896265e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 31.868389285988876}
{"step": 668448, "time": 21287.86509180069, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668624, "time": 21293.68890619278, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 668920, "time": 21302.49803161621, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 669008, "time": 21305.398233890533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 669136, "time": 21309.308593034744, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 669512, "time": 21320.75032711029, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 669600, "time": 21323.68533873558, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 669784, "time": 21329.08149075508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 669872, "time": 21332.02544927597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 21340.557718992233, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 670072, "time": 21340.653718948364, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 670072, "time": 21341.1625623703, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 670072, "time": 21343.554977178574, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 670072, "time": 21343.801085472107, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 670072, "time": 21344.782602787018, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 21344.790883541107, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 21344.79858970642, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 21344.805704832077, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 21344.814118623734, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670456, "time": 21356.560075998306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670544, "time": 21359.489117860794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 671016, "time": 21373.796337366104, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 671072, "time": 21375.780282974243, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 671320, "time": 21383.192059755325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 671336, "time": 21383.68746805191, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 671448, "time": 21387.10978245735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 671824, "time": 21399.338993549347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 671912, "time": 21401.810950517654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 672080, "time": 21407.26536679268, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 672096, "time": 21407.764210939407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 672152, "time": 21409.27758860588, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 672232, "time": 21411.73204922676, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 672672, "time": 21425.407739162445, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 672736, "time": 21427.37616276741, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 672896, "time": 21432.32217979431, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 673088, "time": 21438.332181930542, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 673216, "time": 21442.23316669464, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 673384, "time": 21447.156054973602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 673440, "time": 21449.130011320114, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 673648, "time": 21455.48197197914, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 673824, "time": 21460.84451317787, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 673864, "time": 21461.84564805031, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 674008, "time": 21466.3894803524, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 674512, "time": 21482.005009651184, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 674544, "time": 21482.98101758957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 674984, "time": 21496.308639526367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 675128, "time": 21500.687341451645, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 675208, "time": 21503.143236398697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 675592, "time": 21514.997123241425, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 675696, "time": 21518.4651556015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 675872, "time": 21524.046097517014, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 675960, "time": 21526.527478694916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 676176, "time": 21533.340582370758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 676368, "time": 21539.215596675873, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 676672, "time": 21548.52081012726, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 676824, "time": 21552.938504695892, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 676824, "time": 21552.947214603424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 676968, "time": 21557.49610066414, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 677064, "time": 21560.42725086212, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 677296, "time": 21567.76002931595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 677448, "time": 21572.21796131134, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 677520, "time": 21574.65516090393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 677536, "time": 21575.15046954155, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 677552, "time": 21575.667078495026, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 677768, "time": 21582.060794591904, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 677880, "time": 21585.654336452484, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 677904, "time": 21586.616273880005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 678080, "time": 21591.9994866848, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 678200, "time": 21595.447434425354, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 678400, "time": 21601.76654434204, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 678616, "time": 21608.120018720627, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 678648, "time": 21609.110184907913, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 678760, "time": 21612.54830479622, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 678784, "time": 21613.50447487831, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 678840, "time": 21615.159049987793, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 678896, "time": 21617.093901872635, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 678936, "time": 21618.08937215805, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 679040, "time": 21621.482975006104, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 679160, "time": 21624.92450404167, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 679240, "time": 21627.354460716248, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 679600, "time": 21638.53433728218, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 679616, "time": 21639.02810549736, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 679672, "time": 21640.543030261993, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 679864, "time": 21646.62492632866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679944, "time": 21649.334589719772, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 21654.230103731155, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 680056, "time": 21654.53339457512, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 680056, "time": 21654.802491664886, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 680056, "time": 21655.438693523407, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 680056, "time": 21655.741405248642, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 680056, "time": 21655.869292020798, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 680056, "time": 21656.04390192032, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 680056, "time": 21657.00217962265, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 680064, "time": 21657.472447395325, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 680088, "time": 21657.984703302383, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 680664, "time": 21675.725217819214, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 680792, "time": 21679.634892225266, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 680824, "time": 21680.614660978317, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 680840, "time": 21681.11154270172, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 681056, "time": 21687.948837041855, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 681136, "time": 21690.409732580185, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 681552, "time": 21703.18033003807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 681584, "time": 21704.294680595398, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 681616, "time": 21705.292726516724, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 681840, "time": 21712.2510368824, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 681928, "time": 21714.767696142197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 681960, "time": 21715.75096678734, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 682176, "time": 21722.61444735527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 682296, "time": 21726.090352535248, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 682360, "time": 21728.089754343033, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 682592, "time": 21735.57411789894, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 682744, "time": 21740.014807224274, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 682784, "time": 21741.465046405792, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 682832, "time": 21742.953429937363, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 683152, "time": 21752.88332915306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 683304, "time": 21757.384397268295, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 683768, "time": 21772.002657413483, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 683936, "time": 21777.411011219025, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 683960, "time": 21777.945955514908, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 684152, "time": 21783.812739372253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684192, "time": 21785.26018857956, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 684272, "time": 21787.708842992783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684432, "time": 21792.59540605545, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 684520, "time": 21795.19210958481, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 684608, "time": 21798.118215322495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684752, "time": 21802.520795822144, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 684784, "time": 21803.49549460411, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 684904, "time": 21806.93325638771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 685176, "time": 21815.302988052368, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 685224, "time": 21816.7918112278, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 685344, "time": 21820.735373020172, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 685624, "time": 21829.163959503174, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 685904, "time": 21837.997297763824, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 686024, "time": 21841.442421913147, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 686248, "time": 21848.273606300354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 686920, "time": 21868.91378068924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 686968, "time": 21870.386569738388, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 687016, "time": 21871.869944810867, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 687096, "time": 21874.302371263504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 687168, "time": 21876.737287044525, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 687184, "time": 21877.237664461136, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 687192, "time": 21877.266191005707, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 687216, "time": 21878.228390932083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 687304, "time": 21880.710065603256, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 687472, "time": 21886.22230863571, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 687568, "time": 21889.147390842438, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 687656, "time": 21891.6072909832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 687816, "time": 21896.474781036377, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 687856, "time": 21897.909309387207, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 687888, "time": 21898.880167484283, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 688136, "time": 21906.42204093933, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 688208, "time": 21909.151427984238, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 688256, "time": 21910.636367321014, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 688376, "time": 21914.19468522072, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 688536, "time": 21919.062597751617, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 688640, "time": 21922.46509194374, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 688680, "time": 21923.463186502457, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 688936, "time": 21931.25068283081, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 688936, "time": 21931.25697684288, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 689208, "time": 21939.47731113434, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 689312, "time": 21942.859662532806, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 689456, "time": 21947.414510965347, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 689584, "time": 21951.333290338516, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 689672, "time": 21953.784455537796, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 689752, "time": 21956.256206035614, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 689928, "time": 21961.644340515137, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 689960, "time": 21962.631570339203, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 689968, "time": 21963.104066371918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 690024, "time": 21964.60553598404, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 21966.762533187866, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 690040, "time": 21966.948181390762, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 690040, "time": 21967.398089408875, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 690040, "time": 21967.425938129425, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 690040, "time": 21967.581777334213, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 690040, "time": 21969.22244977951, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 690040, "time": 21969.67529988289, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 690040, "time": 21970.1912753582, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 690440, "time": 21982.529169797897, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 690528, "time": 21985.44170832634, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 690560, "time": 21986.421444892883, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 690568, "time": 21986.452392578125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 690744, "time": 21991.888176202774, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 690936, "time": 21997.779610157013, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 691056, "time": 22001.72104382515, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 691160, "time": 22004.80615067482, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 691160, "time": 22004.815707683563, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 691248, "time": 22007.717605113983, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 691632, "time": 22019.45081305504, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 691640, "time": 22019.478791952133, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 691992, "time": 22030.205731630325, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 692184, "time": 22036.157856941223, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 692224, "time": 22037.598860263824, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 692840, "time": 22056.079139232635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 692872, "time": 22057.050926208496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 693248, "time": 22068.859179019928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 693368, "time": 22072.273913621902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 693440, "time": 22074.701233625412, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 693456, "time": 22075.190498828888, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 693472, "time": 22075.687898159027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 693648, "time": 22081.03272652626, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 693728, "time": 22083.481564998627, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 693768, "time": 22084.471163511276, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 693832, "time": 22086.40627002716, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 694088, "time": 22094.252895355225, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 694304, "time": 22101.048221588135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 694496, "time": 22106.86949801445, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 694752, "time": 22114.66759109497, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 694760, "time": 22114.697865962982, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 695160, "time": 22127.125480413437, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 695256, "time": 22130.04372859001, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 695768, "time": 22145.67267727852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 695784, "time": 22146.16908478737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 695960, "time": 22151.551938533783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 696144, "time": 22157.52296423912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 696408, "time": 22165.951171398163, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 696568, "time": 22170.901923179626, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 696616, "time": 22172.3780503273, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 697064, "time": 22186.20051407814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 697072, "time": 22186.69435787201, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 697160, "time": 22189.171538829803, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 697272, "time": 22192.64011311531, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 697472, "time": 22199.058896541595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 697568, "time": 22202.04981994629, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 697888, "time": 22211.90916109085, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 697992, "time": 22215.015167713165, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 698000, "time": 22215.485796928406, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 698160, "time": 22220.38714814186, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 698240, "time": 22222.844158411026, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 698456, "time": 22229.24511218071, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 698896, "time": 22242.89497256279, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 699008, "time": 22246.467391967773, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 699712, "time": 22268.008862018585, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 699784, "time": 22269.972235918045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 699832, "time": 22271.459919929504, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 699880, "time": 22272.937215805054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 700024, "time": 22278.621596574783, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 700024, "time": 22279.531325817108, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 700024, "time": 22279.55742430687, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 700024, "time": 22279.777403831482, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 700024, "time": 22279.860169172287, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 700024, "time": 22279.92520594597, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 700024, "time": 22279.952199935913, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 700024, "time": 22280.265810728073, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 700152, "time": 22284.189482450485, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 700249, "time": 22288.13860154152, "train_stats/mean_log_entropy": 0.08474517344009308, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2814226246843434, "train/action_min": 0.0, "train/action_std": 1.5646871894296974, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007182939257943118, "train/actor_opt_grad_steps": 42675.0, "train/actor_opt_loss": -5.919825982166022, "train/adv_mag": 0.755312366919084, "train/adv_max": 0.17714646819866064, "train/adv_mean": 0.0006856524339559426, "train/adv_min": -0.7368350619017475, "train/adv_std": 0.02189914945917524, "train/cont_avg": 0.9957682291666666, "train/cont_loss_mean": 0.015208941864936302, "train/cont_loss_std": 0.22518628688218692, "train/cont_neg_acc": 0.3583882845365084, "train/cont_neg_loss": 2.863065338693559, "train/cont_pos_acc": 0.9998761641256737, "train/cont_pos_loss": 0.002952875098509883, "train/cont_pred": 0.9956909327796011, "train/cont_rate": 0.9957682291666666, "train/dyn_loss_mean": 1.0000025738369336, "train/dyn_loss_std": 8.12428508211407e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2499449487606233, "train/extr_critic_critic_opt_grad_steps": 42675.0, "train/extr_critic_critic_opt_loss": 7880.0860447739105, "train/extr_critic_mag": 0.9658739043004585, "train/extr_critic_max": 0.9658739043004585, "train/extr_critic_mean": 0.9231549092013427, "train/extr_critic_min": 0.8611360806407351, "train/extr_critic_std": 0.011554305961430825, "train/extr_return_normed_mag": 0.7510485022959082, "train/extr_return_normed_max": 0.18756884155851422, "train/extr_return_normed_mean": 0.022825618962345133, "train/extr_return_normed_min": -0.7264074279804422, "train/extr_return_normed_std": 0.02532964137693246, "train/extr_return_rate": 0.9989692288817782, "train/extr_return_raw_mag": 1.0885837656078916, "train/extr_return_raw_max": 1.0885837656078916, "train/extr_return_raw_mean": 0.923840587187295, "train/extr_return_raw_min": 0.1746074960689352, "train/extr_return_raw_std": 0.02532964138163611, "train/extr_reward_mag": 0.24172935582170582, "train/extr_reward_max": 0.24172935582170582, "train/extr_reward_mean": 0.001712234859087862, "train/extr_reward_min": 1.0837208140980113e-07, "train/extr_reward_std": 0.006970504048336862, "train/image_loss_mean": 0.10114565702399822, "train/image_loss_std": 0.10426099538201034, "train/model_loss_mean": 0.7248687145083842, "train/model_loss_std": 0.3901572993984728, "train/model_opt_grad_norm": 20.657688921148125, "train/model_opt_grad_steps": 42637.25252525252, "train/model_opt_loss": 3770.546500157828, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5227.272727272727, "train/policy_entropy_mag": 1.3261182073390845, "train/policy_entropy_max": 1.3261182073390845, "train/policy_entropy_mean": 0.10896750584696278, "train/policy_entropy_min": 0.06468651831300572, "train/policy_entropy_std": 0.13889519422493798, "train/policy_logprob_mag": 6.551080241347805, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10877465543271315, "train/policy_logprob_min": -6.551080241347805, "train/policy_logprob_std": 0.6449168845258578, "train/policy_randomness_mag": 0.681489988107874, "train/policy_randomness_max": 0.681489988107874, "train/policy_randomness_mean": 0.055998223560928095, "train/policy_randomness_min": 0.03324229650274672, "train/policy_randomness_std": 0.07137801436086495, "train/post_ent_mag": 49.944036946152195, "train/post_ent_max": 49.944036946152195, "train/post_ent_mean": 46.69973396532463, "train/post_ent_min": 44.393210574834036, "train/post_ent_std": 1.1863916176136093, "train/prior_ent_mag": 51.66502293673429, "train/prior_ent_max": 51.66502293673429, "train/prior_ent_mean": 46.221033635765615, "train/prior_ent_min": 42.801579061180654, "train/prior_ent_std": 1.4981671156305256, "train/rep_loss_mean": 1.0000025738369336, "train/rep_loss_std": 8.12428508211407e-05, "train/reward_avg": 0.0010178999457848752, "train/reward_loss_mean": 0.008512544719093112, "train/reward_loss_std": 0.16340031760105053, "train/reward_max_data": 0.59226641190624, "train/reward_max_pred": 0.12877453818465723, "train/reward_neg_acc": 0.999896252998198, "train/reward_neg_loss": 0.0012623249897686295, "train/reward_pos_acc": 0.14743589820005956, "train/reward_pos_loss": 4.668201491618768, "train/reward_pred": 0.0007315097550739243, "train/reward_rate": 0.001524029356060606, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.013858802616596222, "report/cont_loss_std": 0.2059672772884369, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.297177791595459, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002655079122632742, "report/cont_pred": 0.9954191446304321, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.099897101521492, "report/image_loss_std": 0.1011718362569809, "report/model_loss_mean": 0.7287540435791016, "report/model_loss_std": 0.4800206422805786, "report/post_ent_mag": 48.55678939819336, "report/post_ent_max": 48.55678939819336, "report/post_ent_mean": 45.239768981933594, "report/post_ent_min": 42.742530822753906, "report/post_ent_std": 1.2412378787994385, "report/prior_ent_mag": 51.316184997558594, "report/prior_ent_max": 51.316184997558594, "report/prior_ent_mean": 44.37879943847656, "report/prior_ent_min": 40.296016693115234, "report/prior_ent_std": 1.781769037246704, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0023468018043786287, "report/reward_loss_mean": 0.014998089522123337, "report/reward_loss_std": 0.24930444359779358, "report/reward_max_data": 0.8343750238418579, "report/reward_max_pred": 0.023883342742919922, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00149067142046988, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.612022876739502, "report/reward_pred": 0.0007994384504854679, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.02022785320878029, "eval/cont_loss_std": 0.3931168019771576, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.955380439758301, "eval/cont_pos_acc": 0.9980430603027344, "eval/cont_pos_loss": 0.004699178971350193, "eval/cont_pred": 0.9962656497955322, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.14298956096172333, "eval/image_loss_std": 0.13798612356185913, "eval/model_loss_mean": 0.7690346240997314, "eval/model_loss_std": 0.4812450706958771, "eval/post_ent_mag": 48.557220458984375, "eval/post_ent_max": 48.557220458984375, "eval/post_ent_mean": 45.05107116699219, "eval/post_ent_min": 43.02798843383789, "eval/post_ent_std": 1.2044548988342285, "eval/prior_ent_mag": 51.316184997558594, "eval/prior_ent_max": 51.316184997558594, "eval/prior_ent_mean": 44.16016387939453, "eval/prior_ent_min": 40.73567199707031, "eval/prior_ent_std": 1.6852689981460571, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007263183360919356, "eval/reward_loss_mean": 0.005817170720547438, "eval/reward_loss_std": 0.14434128999710083, "eval/reward_max_data": 0.7437499761581421, "eval/reward_max_pred": 0.06604433059692383, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013089473359286785, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.617729663848877, "eval/reward_pred": 0.000679827993735671, "eval/reward_rate": 0.0009765625, "replay/size": 699745.0, "replay/inserts": 31808.0, "replay/samples": 31808.0, "replay/insert_wait_avg": 1.362676711629334e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.61042445910049e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6816.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2267573338719041e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2840375900269, "timer/env.step_count": 3976.0, "timer/env.step_total": 39.53668022155762, "timer/env.step_frac": 0.03952545350699877, "timer/env.step_avg": 0.009943833053711675, "timer/env.step_min": 0.00807499885559082, "timer/env.step_max": 0.05369758605957031, "timer/replay._sample_count": 31808.0, "timer/replay._sample_total": 17.648393630981445, "timer/replay._sample_frac": 0.017643382247208024, "timer/replay._sample_avg": 0.0005548413490625454, "timer/replay._sample_min": 0.0004284381866455078, "timer/replay._sample_max": 0.035349369049072266, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4828.0, "timer/agent.policy_total": 53.44226336479187, "timer/agent.policy_frac": 0.053427088063456175, "timer/agent.policy_avg": 0.011069234334049683, "timer/agent.policy_min": 0.008658170700073242, "timer/agent.policy_max": 0.09763646125793457, "timer/dataset_train_count": 1988.0, "timer/dataset_train_total": 0.23144841194152832, "timer/dataset_train_frac": 0.0002313826905597278, "timer/dataset_train_avg": 0.00011642274242531605, "timer/dataset_train_min": 9.965896606445312e-05, "timer/dataset_train_max": 0.0005857944488525391, "timer/agent.train_count": 1988.0, "timer/agent.train_total": 891.3917758464813, "timer/agent.train_frac": 0.8911386589694079, "timer/agent.train_avg": 0.44838620515416566, "timer/agent.train_min": 0.4353513717651367, "timer/agent.train_max": 0.7201395034790039, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5164284706115723, "timer/agent.report_frac": 0.0005162818271656095, "timer/agent.report_avg": 0.25821423530578613, "timer/agent.report_min": 0.25511741638183594, "timer/agent.report_max": 0.26131105422973633, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.504753112792969e-05, "timer/dataset_eval_frac": 3.5037579138390844e-08, "timer/dataset_eval_avg": 3.504753112792969e-05, "timer/dataset_eval_min": 3.504753112792969e-05, "timer/dataset_eval_max": 3.504753112792969e-05, "fps": 31.798398330282467}
{"step": 700304, "time": 22289.89742398262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 700312, "time": 22289.92913031578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 700472, "time": 22294.80567264557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 700472, "time": 22294.816184043884, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 700512, "time": 22296.270152807236, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 700552, "time": 22297.277854204178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 700616, "time": 22299.24804162979, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 700648, "time": 22300.228237867355, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 700672, "time": 22301.182270526886, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 700680, "time": 22301.211271047592, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 701192, "time": 22316.954754829407, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 701352, "time": 22321.866827964783, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 701736, "time": 22333.759592294693, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 702072, "time": 22344.175864458084, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 702168, "time": 22347.112798452377, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 702784, "time": 22366.459491729736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 702784, "time": 22366.468898296356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 702792, "time": 22366.499500513077, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 702808, "time": 22366.98939180374, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 702960, "time": 22371.830896377563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 702984, "time": 22372.354153633118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 702992, "time": 22372.848308086395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 703032, "time": 22373.845643997192, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 703232, "time": 22380.134342432022, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 703536, "time": 22389.410410642624, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 703680, "time": 22393.90070748329, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 703752, "time": 22395.867998838425, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 703768, "time": 22396.360700130463, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 704312, "time": 22412.96302676201, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 704392, "time": 22415.409726142883, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 704408, "time": 22415.906438827515, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 704888, "time": 22431.264877319336, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 705096, "time": 22437.630310297012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 705104, "time": 22438.102653980255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 705304, "time": 22444.00022816658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 705544, "time": 22451.37544989586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 705624, "time": 22453.956926822662, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 705968, "time": 22464.73832345009, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 706064, "time": 22467.684564590454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 706224, "time": 22472.568198680878, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 706360, "time": 22476.507973194122, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 706624, "time": 22484.966378450394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 706704, "time": 22487.46914601326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 706824, "time": 22490.9482049942, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 707128, "time": 22500.335414886475, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 707280, "time": 22505.232088565826, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 707408, "time": 22509.210741519928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 707448, "time": 22510.217948913574, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 707528, "time": 22512.720076084137, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 707552, "time": 22513.714553833008, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 707776, "time": 22520.722041368484, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 707776, "time": 22520.731508255005, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 707864, "time": 22523.244345664978, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 707888, "time": 22524.209388256073, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 708024, "time": 22528.199337482452, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 708240, "time": 22535.02832531929, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 708304, "time": 22537.004348278046, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 708488, "time": 22542.42926955223, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 708536, "time": 22544.044634342194, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 708616, "time": 22546.540927648544, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 708952, "time": 22556.907581567764, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 709000, "time": 22558.386065721512, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 709008, "time": 22558.859850406647, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 709352, "time": 22569.15421962738, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 709728, "time": 22581.001357078552, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 709840, "time": 22584.40203857422, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 709864, "time": 22584.91797184944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 22590.03956103325, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 710008, "time": 22590.501139640808, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 710008, "time": 22590.563408374786, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 710008, "time": 22590.591351032257, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 710008, "time": 22591.37265276909, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 710008, "time": 22592.11145877838, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 710008, "time": 22594.27999639511, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 710008, "time": 22595.12055706978, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710008, "time": 22595.126982688904, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710008, "time": 22595.13297367096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710200, "time": 22600.99940443039, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 710336, "time": 22605.51094174385, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 710544, "time": 22611.868507146835, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 710552, "time": 22611.898370742798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 710616, "time": 22613.846391439438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 710664, "time": 22615.31701731682, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 710824, "time": 22620.209992408752, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 710896, "time": 22622.653573989868, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 710944, "time": 22624.118565797806, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 711016, "time": 22626.11499428749, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 711176, "time": 22631.007695913315, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 711312, "time": 22635.546183109283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 711512, "time": 22641.413367271423, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 711576, "time": 22643.375027656555, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 711576, "time": 22643.38397049904, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 711960, "time": 22655.20501089096, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 712384, "time": 22668.494954109192, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 712496, "time": 22671.92621088028, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 712512, "time": 22672.42906165123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 712816, "time": 22682.24359869957, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 712864, "time": 22683.7243745327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 712944, "time": 22686.219763994217, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 713152, "time": 22692.59702372551, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 713256, "time": 22695.68329834938, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 713448, "time": 22701.54524064064, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 713488, "time": 22703.007548093796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 713672, "time": 22708.38450407982, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 713824, "time": 22713.26592731476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 713888, "time": 22715.23262476921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 714216, "time": 22725.10890030861, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 714320, "time": 22728.487617254257, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 714504, "time": 22733.889913082123, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 714704, "time": 22740.212500333786, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 714736, "time": 22741.188646554947, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 715128, "time": 22752.965391874313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 715216, "time": 22756.01545238495, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 715240, "time": 22756.527614593506, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 715256, "time": 22757.02028274536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 715760, "time": 22772.618507385254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 715800, "time": 22773.64073729515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 715880, "time": 22776.075845479965, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 715880, "time": 22776.085078954697, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 716280, "time": 22788.47979903221, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 716520, "time": 22795.811182022095, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 716632, "time": 22799.260527849197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 716864, "time": 22806.568074464798, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 717328, "time": 22820.934332370758, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 717528, "time": 22826.80423760414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 717552, "time": 22827.780906915665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 717568, "time": 22828.274676322937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 717936, "time": 22839.506863832474, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 717952, "time": 22840.00212931633, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 718072, "time": 22843.455852508545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 718096, "time": 22844.53770494461, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 718192, "time": 22847.485202550888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 718480, "time": 22856.265875816345, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 718616, "time": 22860.19685959816, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 718800, "time": 22866.045248746872, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 718944, "time": 22870.453571558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 719392, "time": 22884.32751560211, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 719504, "time": 22887.736809253693, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 719544, "time": 22888.733387231827, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 719840, "time": 22898.017840385437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 719912, "time": 22900.000730276108, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 719912, "time": 22900.014042139053, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 720096, "time": 22907.24567270279, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 720096, "time": 22907.559243917465, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 720096, "time": 22907.646602869034, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 720096, "time": 22908.222671747208, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 720096, "time": 22909.261360645294, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 720096, "time": 22912.271903276443, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 22912.279544353485, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 22912.290643453598, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 22912.298794031143, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 22912.305329799652, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720400, "time": 22921.545215845108, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 720504, "time": 22924.509685516357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 720536, "time": 22925.48916363716, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 720544, "time": 22925.960958003998, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 720920, "time": 22937.839525938034, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 721112, "time": 22943.712683916092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 721144, "time": 22944.70811510086, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 721304, "time": 22949.67684364319, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 721704, "time": 22961.896859407425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 721816, "time": 22965.470223903656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 721944, "time": 22969.385831832886, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 722152, "time": 22975.756769180298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 722432, "time": 22984.53946352005, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 722816, "time": 22996.338985681534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 722880, "time": 22998.31061244011, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 723376, "time": 23013.4750123024, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 723424, "time": 23014.949369192123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 723456, "time": 23015.926329135895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 723464, "time": 23015.953827142715, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 724120, "time": 23036.04080057144, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 724128, "time": 23036.51060771942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 724648, "time": 23052.175045728683, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 725128, "time": 23066.957287311554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 725192, "time": 23068.918481111526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 725688, "time": 23084.235453605652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 725736, "time": 23085.724652051926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 725768, "time": 23086.70544242859, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 725912, "time": 23091.09845519066, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 726424, "time": 23106.688987493515, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 726440, "time": 23107.18487405777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 726704, "time": 23115.6111638546, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 726736, "time": 23116.59284567833, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 726960, "time": 23123.423135519028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 727328, "time": 23134.67116856575, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 727504, "time": 23140.14536190033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 727560, "time": 23141.64370393753, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 727584, "time": 23142.611625432968, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 728048, "time": 23156.9349629879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 728304, "time": 23164.760097503662, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 728512, "time": 23171.105008363724, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 728528, "time": 23171.602855443954, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 728736, "time": 23178.122804164886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 729016, "time": 23186.467965602875, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 729048, "time": 23187.443682670593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 729232, "time": 23193.809062719345, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 729272, "time": 23194.81219983101, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 729448, "time": 23200.18075156212, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 729536, "time": 23203.074553489685, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 729872, "time": 23213.50973010063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 729896, "time": 23214.020922660828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 23220.514654159546, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 730080, "time": 23221.598517656326, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 730080, "time": 23221.74129319191, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 730080, "time": 23221.766897439957, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 730080, "time": 23221.793118476868, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 730080, "time": 23222.81840968132, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 730080, "time": 23222.98245859146, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 730080, "time": 23223.064384937286, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 730256, "time": 23228.41148996353, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 730304, "time": 23229.873441696167, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 730784, "time": 23244.64915728569, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 730840, "time": 23246.151200532913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 730952, "time": 23249.547554016113, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 731048, "time": 23252.536749362946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 731544, "time": 23267.914172410965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 731584, "time": 23269.387523174286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 731848, "time": 23277.25336766243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 731904, "time": 23279.171761274338, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 732185, "time": 23288.515432834625, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1209393310546876, "train/action_min": 0.0, "train/action_std": 1.4449445641040801, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009494686804828234, "train/actor_opt_grad_steps": 44665.0, "train/actor_opt_loss": -6.442362644902897, "train/adv_mag": 0.863126363158226, "train/adv_max": 0.28952592343091965, "train/adv_mean": 0.001984944674802591, "train/adv_min": -0.8406457695364952, "train/adv_std": 0.03273683913052082, "train/cont_avg": 0.9956396484375, "train/cont_loss_mean": 0.015537322807358579, "train/cont_loss_std": 0.22825016184477134, "train/cont_neg_acc": 0.33387188780672694, "train/cont_neg_loss": 2.8860696334646043, "train/cont_pos_acc": 0.9998872229456901, "train/cont_pos_loss": 0.0029839228780474516, "train/cont_pred": 0.9956715121865273, "train/cont_rate": 0.9956396484375, "train/dyn_loss_mean": 1.0000014311075212, "train/dyn_loss_std": 4.5778268977301194e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.27008387046866117, "train/extr_critic_critic_opt_grad_steps": 44665.0, "train/extr_critic_critic_opt_loss": 13111.52267578125, "train/extr_critic_mag": 1.0876100850105286, "train/extr_critic_max": 1.0876100850105286, "train/extr_critic_mean": 1.0355805644392968, "train/extr_critic_min": 0.9482885766029358, "train/extr_critic_std": 0.014701185747981071, "train/extr_return_normed_mag": 0.853167288005352, "train/extr_return_normed_max": 0.3035985431075096, "train/extr_return_normed_mean": 0.03222134053823538, "train/extr_return_normed_min": -0.8270918411016465, "train/extr_return_normed_std": 0.036468945513479414, "train/extr_return_rate": 0.9986751732230187, "train/extr_return_raw_mag": 1.3089427250623702, "train/extr_return_raw_max": 1.3089427250623702, "train/extr_return_raw_mean": 1.0375655779242516, "train/extr_return_raw_min": 0.17825234085321426, "train/extr_return_raw_std": 0.036468945750966666, "train/extr_reward_mag": 0.3206604880094528, "train/extr_reward_max": 0.3206604880094528, "train/extr_reward_mean": 0.002306789040667354, "train/extr_reward_min": 4.9471855163574216e-08, "train/extr_reward_std": 0.010477661768090911, "train/image_loss_mean": 0.09635852746665478, "train/image_loss_std": 0.10336604673415423, "train/model_loss_mean": 0.7207167515158653, "train/model_loss_std": 0.39214245542883874, "train/model_opt_grad_norm": 20.217346839904785, "train/model_opt_grad_steps": 44625.36, "train/model_opt_loss": 3764.709138183594, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5225.0, "train/policy_entropy_mag": 1.3374872344732285, "train/policy_entropy_max": 1.3374872344732285, "train/policy_entropy_mean": 0.11185958866029978, "train/policy_entropy_min": 0.06468652423471212, "train/policy_entropy_std": 0.1427158462256193, "train/policy_logprob_mag": 6.551080241203308, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11276602640748024, "train/policy_logprob_min": -6.551080241203308, "train/policy_logprob_std": 0.6541885769367218, "train/policy_randomness_mag": 0.6873325139284134, "train/policy_randomness_max": 0.6873325139284134, "train/policy_randomness_mean": 0.057484460473060606, "train/policy_randomness_min": 0.03324229970574379, "train/policy_randomness_std": 0.07334144096821546, "train/post_ent_mag": 49.8662389755249, "train/post_ent_max": 49.8662389755249, "train/post_ent_mean": 46.46180435180664, "train/post_ent_min": 44.05214687347412, "train/post_ent_std": 1.2118439823389053, "train/prior_ent_mag": 52.27328531265259, "train/prior_ent_max": 52.27328531265259, "train/prior_ent_mean": 46.0692190361023, "train/prior_ent_min": 42.68176609039307, "train/prior_ent_std": 1.5860298854112624, "train/rep_loss_mean": 1.0000014311075212, "train/rep_loss_std": 4.5778268977301194e-05, "train/reward_avg": 0.001053161625568464, "train/reward_loss_mean": 0.008820016513345763, "train/reward_loss_std": 0.16314615268609486, "train/reward_max_data": 0.572921875230968, "train/reward_max_pred": 0.12412428855895996, "train/reward_neg_acc": 0.9998972323536873, "train/reward_neg_loss": 0.001351266832643887, "train/reward_pos_acc": 0.13688172082747183, "train/reward_pos_loss": 4.576279963216474, "train/reward_pred": 0.0007882952783256769, "train/reward_rate": 0.001611328125, "train_stats/mean_log_entropy": 0.08782776196797688, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 0.02956276386976242, "report/cont_loss_std": 0.32803773880004883, "report/cont_neg_acc": 0.30000001192092896, "report/cont_neg_loss": 2.6557528972625732, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003663453971967101, "report/cont_pred": 0.9935013651847839, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 1.0000430345535278, "report/dyn_loss_std": 0.001375896972604096, "report/image_loss_mean": 0.11192020773887634, "report/image_loss_std": 0.12374798208475113, "report/model_loss_mean": 0.7626739740371704, "report/model_loss_std": 0.5945350527763367, "report/post_ent_mag": 50.27530288696289, "report/post_ent_max": 50.27530288696289, "report/post_ent_mean": 47.165103912353516, "report/post_ent_min": 44.732337951660156, "report/post_ent_std": 1.1926333904266357, "report/prior_ent_mag": 51.45382308959961, "report/prior_ent_max": 51.45382308959961, "report/prior_ent_mean": 44.92089080810547, "report/prior_ent_min": 40.548828125, "report/prior_ent_std": 1.6611063480377197, "report/rep_loss_mean": 1.0000430345535278, "report/rep_loss_std": 0.001375896972604096, "report/reward_avg": 0.00408020056784153, "report/reward_loss_mean": 0.021165205165743828, "report/reward_loss_std": 0.2981368899345398, "report/reward_max_data": 0.9312499761581421, "report/reward_max_pred": 0.5344173908233643, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0012518687872216105, "report/reward_pos_acc": 0.20000000298023224, "report/reward_pos_loss": 4.079503059387207, "report/reward_pred": 0.0012241668300703168, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.034103505313396454, "eval/cont_loss_std": 0.5238233804702759, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.015413284301758, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.002804248360916972, "eval/cont_pred": 0.9973127841949463, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.000051736831665, "eval/dyn_loss_std": 0.0016547623090445995, "eval/image_loss_mean": 0.1489541381597519, "eval/image_loss_std": 0.14965346455574036, "eval/model_loss_mean": 0.7925588488578796, "eval/model_loss_std": 0.6837137937545776, "eval/post_ent_mag": 50.274871826171875, "eval/post_ent_max": 50.274871826171875, "eval/post_ent_mean": 46.58529281616211, "eval/post_ent_min": 44.54450988769531, "eval/post_ent_std": 1.1921546459197998, "eval/prior_ent_mag": 51.330387115478516, "eval/prior_ent_max": 51.330387115478516, "eval/prior_ent_mean": 44.223819732666016, "eval/prior_ent_min": 40.77574920654297, "eval/prior_ent_std": 1.6890413761138916, "eval/rep_loss_mean": 1.000051736831665, "eval/rep_loss_std": 0.0016547623090445995, "eval/reward_avg": 0.0003448486386332661, "eval/reward_loss_mean": 0.009470164775848389, "eval/reward_loss_std": 0.28739333152770996, "eval/reward_max_data": 0.3531250059604645, "eval/reward_max_pred": 0.02172553539276123, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0004852496203966439, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 9.201040267944336, "eval/reward_pred": 0.00025352626107633114, "eval/reward_rate": 0.0009765625, "replay/size": 731681.0, "replay/inserts": 31936.0, "replay/samples": 31936.0, "replay/insert_wait_avg": 1.3743633617141205e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0584303754603934e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5888.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1902302503585815e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3574688434601, "timer/env.step_count": 3992.0, "timer/env.step_total": 39.590802907943726, "timer/env.step_frac": 0.03957665548667889, "timer/env.step_avg": 0.009917535798583097, "timer/env.step_min": 0.008031368255615234, "timer/env.step_max": 0.03684091567993164, "timer/replay._sample_count": 31936.0, "timer/replay._sample_total": 17.533045768737793, "timer/replay._sample_frac": 0.017526780490786174, "timer/replay._sample_avg": 0.0005490056916563688, "timer/replay._sample_min": 0.00039577484130859375, "timer/replay._sample_max": 0.011587381362915039, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4728.0, "timer/agent.policy_total": 51.6573281288147, "timer/agent.policy_frac": 0.05163886884209213, "timer/agent.policy_avg": 0.01092583082250734, "timer/agent.policy_min": 0.00923609733581543, "timer/agent.policy_max": 0.09730696678161621, "timer/dataset_train_count": 1996.0, "timer/dataset_train_total": 0.2314314842224121, "timer/dataset_train_frac": 0.0002313487842400739, "timer/dataset_train_avg": 0.00011594763738597802, "timer/dataset_train_min": 0.00010156631469726562, "timer/dataset_train_max": 0.0005688667297363281, "timer/agent.train_count": 1996.0, "timer/agent.train_total": 895.409322977066, "timer/agent.train_frac": 0.8950893564200332, "timer/agent.train_avg": 0.44860186521897094, "timer/agent.train_min": 0.4344043731689453, "timer/agent.train_max": 0.6828441619873047, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5166363716125488, "timer/agent.report_frac": 0.0005164517562005568, "timer/agent.report_avg": 0.2583181858062744, "timer/agent.report_min": 0.25341081619262695, "timer/agent.report_max": 0.2632255554199219, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.8361672498819192e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 31.924018978783902}
{"step": 732208, "time": 23289.17946791649, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 732504, "time": 23298.289766788483, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 732512, "time": 23298.757883310318, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 732640, "time": 23302.684864521027, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 732752, "time": 23306.10368990898, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 732920, "time": 23311.068419218063, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 733096, "time": 23316.488602876663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 733152, "time": 23318.42342376709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 733400, "time": 23325.98500061035, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 733584, "time": 23331.865030050278, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 733816, "time": 23338.76709651947, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 733912, "time": 23341.734838724136, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 734080, "time": 23347.105949401855, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 734160, "time": 23349.54771924019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 734312, "time": 23354.15690755844, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 734328, "time": 23354.651136875153, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 734384, "time": 23356.602224588394, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 734768, "time": 23368.346433401108, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 734824, "time": 23369.84757089615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 734952, "time": 23373.785120010376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 735016, "time": 23375.754688739777, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 735168, "time": 23380.62727165222, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 735232, "time": 23382.602108716965, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 735704, "time": 23396.915645122528, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 735960, "time": 23404.790251016617, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 736016, "time": 23406.726632356644, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 736080, "time": 23408.68703341484, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 736176, "time": 23411.641254663467, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 736472, "time": 23420.588371038437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 736504, "time": 23421.569885730743, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 736512, "time": 23422.04218506813, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 736672, "time": 23426.910920858383, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 736792, "time": 23430.349233150482, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 736936, "time": 23434.754890680313, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 736976, "time": 23436.20253801346, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 737008, "time": 23437.185618638992, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 737136, "time": 23441.11563706398, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 737288, "time": 23445.8752784729, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 737304, "time": 23446.68925333023, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 737832, "time": 23462.930934906006, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 737976, "time": 23467.358989953995, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 738016, "time": 23468.819115638733, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 738328, "time": 23478.275203227997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 738440, "time": 23481.71390581131, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 738624, "time": 23487.593580007553, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 738768, "time": 23492.02207183838, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 738784, "time": 23492.51566386223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 739104, "time": 23502.32225203514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 739128, "time": 23502.837047100067, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 739216, "time": 23505.89408135414, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 739288, "time": 23507.874101400375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 739616, "time": 23518.12593793869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 739640, "time": 23518.659939050674, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 739696, "time": 23520.584279060364, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 739768, "time": 23522.550268888474, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 739872, "time": 23525.96572113037, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 740048, "time": 23531.365284204483, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 740064, "time": 23533.072036266327, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 740064, "time": 23533.238929271698, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 740064, "time": 23533.38447856903, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 740064, "time": 23533.398394346237, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 740064, "time": 23533.97222161293, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 740064, "time": 23534.160186052322, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 740064, "time": 23534.376121997833, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 740064, "time": 23534.849785089493, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 740256, "time": 23540.70465540886, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 740464, "time": 23547.10014462471, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 740560, "time": 23550.033928871155, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 740792, "time": 23556.945308208466, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 741080, "time": 23565.905472278595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 741192, "time": 23569.314798355103, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 741568, "time": 23581.070467233658, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 741592, "time": 23581.585813999176, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 741904, "time": 23591.362976789474, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 741952, "time": 23592.847200632095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742184, "time": 23599.8784198761, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742360, "time": 23605.308965682983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742568, "time": 23611.663675785065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742608, "time": 23613.120623111725, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 742688, "time": 23615.581491947174, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 742776, "time": 23618.038965940475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 743144, "time": 23629.42844772339, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 743360, "time": 23636.238573789597, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 743392, "time": 23637.21674847603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 743616, "time": 23644.08510327339, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 743904, "time": 23652.88339614868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 743968, "time": 23655.012805700302, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 744216, "time": 23662.382853507996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 744264, "time": 23663.86416554451, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 744288, "time": 23664.843524217606, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 744872, "time": 23682.44475889206, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 744896, "time": 23683.41320705414, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 745000, "time": 23686.523641109467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 745088, "time": 23689.479753494263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 745456, "time": 23700.70963025093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 745928, "time": 23715.55718779564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 746216, "time": 23724.385409832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 746472, "time": 23732.31649875641, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 746528, "time": 23734.266645669937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 747184, "time": 23754.464014530182, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 747184, "time": 23754.479704856873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 747208, "time": 23755.00150871277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 747400, "time": 23760.855617046356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 747768, "time": 23772.077888727188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 748032, "time": 23780.78888440132, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 748240, "time": 23787.128154993057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 748360, "time": 23790.603978395462, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 748440, "time": 23793.079778671265, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 748528, "time": 23795.979325294495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 748960, "time": 23809.364191293716, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 749496, "time": 23825.525686979294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 749496, "time": 23825.543411254883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 749520, "time": 23826.49727988243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 749712, "time": 23832.380129098892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 23842.80611038208, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 23844.365066051483, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 750048, "time": 23845.66130232811, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 750048, "time": 23846.881787776947, "eval_episode/length": 201.0, "eval_episode/score": 0.37187498807907104, "eval_episode/reward_rate": 0.0049504950495049506}
{"step": 750048, "time": 23847.31761956215, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 750048, "time": 23847.590022325516, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 750048, "time": 23848.67343902588, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750048, "time": 23848.68152999878, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750048, "time": 23848.688861608505, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750048, "time": 23848.69834971428, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750048, "time": 23848.706797599792, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750752, "time": 23870.351087093353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 750840, "time": 23872.83901500702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 751272, "time": 23886.008350610733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 751624, "time": 23896.92792749405, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 751808, "time": 23902.781223773956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 751808, "time": 23902.791058540344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 751832, "time": 23903.308642864227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 752024, "time": 23909.209749937057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 752360, "time": 23919.498462677002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 752560, "time": 23925.994574785233, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 752616, "time": 23927.49750828743, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 752624, "time": 23927.968000888824, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 753016, "time": 23939.649981737137, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 753056, "time": 23941.102955579758, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 753064, "time": 23941.13529253006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 753272, "time": 23947.513582229614, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 753344, "time": 23949.922449827194, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 753360, "time": 23950.41206097603, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 753560, "time": 23956.47745656967, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 753896, "time": 23967.25829267502, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 753936, "time": 23968.693914175034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 754120, "time": 23974.086665153503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 754144, "time": 23975.04451417923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 754176, "time": 23976.025312185287, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 754496, "time": 23985.985855340958, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 754904, "time": 23998.24191379547, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 754952, "time": 23999.708079099655, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 755120, "time": 24005.05389404297, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 755584, "time": 24019.425337314606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 755800, "time": 24025.819489955902, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 755872, "time": 24028.22418475151, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 755872, "time": 24028.234399795532, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 756184, "time": 24037.508703947067, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 756240, "time": 24039.42461657524, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 756312, "time": 24041.42297053337, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 756368, "time": 24043.353395938873, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 756432, "time": 24045.480601787567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 756680, "time": 24052.866897583008, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 756832, "time": 24057.745620250702, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 756848, "time": 24058.238409280777, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 756880, "time": 24059.223014354706, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 757376, "time": 24074.47319459915, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 757688, "time": 24083.752487182617, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 757848, "time": 24088.635625600815, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 758088, "time": 24096.002036094666, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 758112, "time": 24096.9529838562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 758184, "time": 24098.9172475338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 758216, "time": 24099.91210269928, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 758288, "time": 24102.323734760284, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 758496, "time": 24108.794693231583, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 759128, "time": 24127.820964813232, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 759192, "time": 24129.779285907745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 759544, "time": 24140.62882399559, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 759760, "time": 24147.455588579178, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 760032, "time": 24156.03867459297, "eval_episode/length": 11.0, "eval_episode/score": 0.965624988079071, "eval_episode/reward_rate": 0.08333333333333333}
{"step": 760032, "time": 24157.44508457184, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 760032, "time": 24162.199278593063, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "time": 24162.206974506378, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "time": 24162.224194526672, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "time": 24162.232094049454, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "time": 24162.239646196365, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "time": 24162.2469894886, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760224, "time": 24168.198430776596, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 760400, "time": 24173.57315349579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 760424, "time": 24174.087921142578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 760480, "time": 24176.02976155281, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 760496, "time": 24176.523676872253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 760528, "time": 24177.500306367874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 760808, "time": 24185.865464687347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 760848, "time": 24187.31189107895, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 760968, "time": 24190.754860639572, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 760968, "time": 24190.762422323227, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 761384, "time": 24203.519503116608, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 761424, "time": 24204.986408233643, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 761440, "time": 24205.48204112053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 761504, "time": 24207.43850851059, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 761584, "time": 24209.912543535233, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 761856, "time": 24218.43736076355, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 761880, "time": 24219.365421056747, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 761984, "time": 24222.763515233994, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 762024, "time": 24223.835065841675, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 762152, "time": 24227.800017356873, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 762232, "time": 24230.264160633087, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 762712, "time": 24244.969982385635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 763056, "time": 24255.83827853203, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 763752, "time": 24276.7857940197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 764105, "time": 24288.67096209526, "train_stats/mean_log_entropy": 0.08681191242224462, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2174798583984376, "train/action_min": 0.0, "train/action_std": 1.5064045947790146, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01017275801859796, "train/actor_opt_grad_steps": 46665.0, "train/actor_opt_loss": -7.425280112735927, "train/adv_mag": 0.856525042951107, "train/adv_max": 0.282682569026947, "train/adv_mean": 0.0009620489268093024, "train/adv_min": -0.8300549712777138, "train/adv_std": 0.034446502784267065, "train/cont_avg": 0.9955322265625, "train/cont_loss_mean": 0.016063543446944096, "train/cont_loss_std": 0.23535916960099712, "train/cont_neg_acc": 0.3313053418793271, "train/cont_neg_loss": 2.9241396152386887, "train/cont_pos_acc": 0.999867608845234, "train/cont_pos_loss": 0.003075876273214817, "train/cont_pred": 0.9955232864618302, "train/cont_rate": 0.9955322265625, "train/dyn_loss_mean": 1.0000006026029586, "train/dyn_loss_std": 1.9266243543825113e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.22376164040062577, "train/extr_critic_critic_opt_grad_steps": 46665.0, "train/extr_critic_critic_opt_loss": 13421.23326171875, "train/extr_critic_mag": 1.1249440097808838, "train/extr_critic_max": 1.1249440097808838, "train/extr_critic_mean": 1.05309974193573, "train/extr_critic_min": 0.9547354918718338, "train/extr_critic_std": 0.014159764172509312, "train/extr_return_normed_mag": 0.8477788445353508, "train/extr_return_normed_max": 0.2984499904513359, "train/extr_return_normed_mean": 0.029591567056486384, "train/extr_return_normed_min": -0.8106276068091393, "train/extr_return_normed_std": 0.03793706430122256, "train/extr_return_rate": 0.9985863074660302, "train/extr_return_raw_mag": 1.3229201114177704, "train/extr_return_raw_max": 1.3229201114177704, "train/extr_return_raw_mean": 1.0540617364645004, "train/extr_return_raw_min": 0.21384251415729522, "train/extr_return_raw_std": 0.03793706443626434, "train/extr_reward_mag": 0.3300112211704254, "train/extr_reward_max": 0.3300112211704254, "train/extr_reward_mean": 0.002376601879368536, "train/extr_reward_min": -2.4068355560302736e-06, "train/extr_reward_std": 0.011583511533681303, "train/image_loss_mean": 0.09249021600931882, "train/image_loss_std": 0.10122373960912227, "train/model_loss_mean": 0.717343544960022, "train/model_loss_std": 0.39124998994171617, "train/model_opt_grad_norm": 19.314724712371827, "train/model_opt_grad_steps": 46623.455, "train/model_opt_loss": 3766.605382080078, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5250.0, "train/policy_entropy_mag": 1.3293470734357833, "train/policy_entropy_max": 1.3293470734357833, "train/policy_entropy_mean": 0.106247583553195, "train/policy_entropy_min": 0.06468652937561274, "train/policy_entropy_std": 0.1359279802814126, "train/policy_logprob_mag": 6.551080245971679, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10615805573761464, "train/policy_logprob_min": -6.551080245971679, "train/policy_logprob_std": 0.6435591143369674, "train/policy_randomness_mag": 0.6831492972373963, "train/policy_randomness_max": 0.6831492972373963, "train/policy_randomness_mean": 0.054600460007786754, "train/policy_randomness_min": 0.03324230218306184, "train/policy_randomness_std": 0.06985316755250097, "train/post_ent_mag": 50.89364976882935, "train/post_ent_max": 50.89364976882935, "train/post_ent_mean": 46.3010996055603, "train/post_ent_min": 43.082572841644286, "train/post_ent_std": 1.6528586101531983, "train/prior_ent_mag": 51.687139434814455, "train/prior_ent_max": 51.687139434814455, "train/prior_ent_mean": 45.47589319229126, "train/prior_ent_min": 42.21738464355469, "train/prior_ent_std": 1.5616288363933564, "train/rep_loss_mean": 1.0000006026029586, "train/rep_loss_std": 1.9266243543825113e-05, "train/reward_avg": 0.0010921478248201312, "train/reward_loss_mean": 0.008789405381539836, "train/reward_loss_std": 0.1598184732417576, "train/reward_max_data": 0.5927968738973141, "train/reward_max_pred": 0.13792217314243316, "train/reward_neg_acc": 0.9998679262399673, "train/reward_neg_loss": 0.0015460237170918845, "train/reward_pos_acc": 0.13343949131904895, "train/reward_pos_loss": 4.439208405033039, "train/reward_pred": 0.0008740530727664008, "train/reward_rate": 0.00162109375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02243974804878235, "report/cont_loss_std": 0.3665443956851959, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 5.066545486450195, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.002658940153196454, "report/cont_pred": 0.996423602104187, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10137522965669632, "report/image_loss_std": 0.10327186435461044, "report/model_loss_mean": 0.7251364588737488, "report/model_loss_std": 0.37749844789505005, "report/post_ent_mag": 51.08087158203125, "report/post_ent_max": 51.08087158203125, "report/post_ent_mean": 46.380035400390625, "report/post_ent_min": 43.02520751953125, "report/post_ent_std": 1.7018018960952759, "report/prior_ent_mag": 52.9792366027832, "report/prior_ent_max": 52.9792366027832, "report/prior_ent_mean": 45.752418518066406, "report/prior_ent_min": 41.59620666503906, "report/prior_ent_std": 1.8644887208938599, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0013214843347668648, "report/reward_loss_std": 0.004444758873432875, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.012808084487915039, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0013214843347668648, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0006894737016409636, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.053740374743938446, "eval/cont_loss_std": 0.7339399456977844, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.921783447265625, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0014729248359799385, "eval/cont_pred": 0.9985151886940002, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1566954255104065, "eval/image_loss_std": 0.140269935131073, "eval/model_loss_mean": 0.8213187456130981, "eval/model_loss_std": 0.8375087976455688, "eval/post_ent_mag": 51.269065856933594, "eval/post_ent_max": 51.269065856933594, "eval/post_ent_mean": 45.653770446777344, "eval/post_ent_min": 42.57701873779297, "eval/post_ent_std": 1.9358264207839966, "eval/prior_ent_mag": 52.90049362182617, "eval/prior_ent_max": 52.90049362182617, "eval/prior_ent_mean": 45.28302001953125, "eval/prior_ent_min": 41.80813217163086, "eval/prior_ent_std": 1.9467781782150269, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0011932372581213713, "eval/reward_loss_mean": 0.010882945731282234, "eval/reward_loss_std": 0.23306652903556824, "eval/reward_max_data": 0.6781250238418579, "eval/reward_max_pred": 0.013607621192932129, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0005733043071813881, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.279109001159668, "eval/reward_pred": 0.0003091854741796851, "eval/reward_rate": 0.001953125, "replay/size": 763601.0, "replay/inserts": 31920.0, "replay/samples": 31920.0, "replay/insert_wait_avg": 1.3425684811776145e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.698825970030668e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5680.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.206490355478206e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1920928955078125e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1407465934753, "timer/env.step_count": 3990.0, "timer/env.step_total": 39.65642714500427, "timer/env.step_frac": 0.03965084642344176, "timer/env.step_avg": 0.009938954171680269, "timer/env.step_min": 0.00796651840209961, "timer/env.step_max": 0.05089378356933594, "timer/replay._sample_count": 31920.0, "timer/replay._sample_total": 17.531293630599976, "timer/replay._sample_frac": 0.017528826507981356, "timer/replay._sample_avg": 0.0005492259909335832, "timer/replay._sample_min": 0.00041556358337402344, "timer/replay._sample_max": 0.025475740432739258, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4700.0, "timer/agent.policy_total": 51.3848237991333, "timer/agent.policy_frac": 0.05137759257799698, "timer/agent.policy_avg": 0.01093294123385815, "timer/agent.policy_min": 0.008430957794189453, "timer/agent.policy_max": 0.09589004516601562, "timer/dataset_train_count": 1995.0, "timer/dataset_train_total": 0.23323845863342285, "timer/dataset_train_frac": 0.00023320563573461396, "timer/dataset_train_avg": 0.00011691150808692875, "timer/dataset_train_min": 0.00010085105895996094, "timer/dataset_train_max": 0.0008707046508789062, "timer/agent.train_count": 1995.0, "timer/agent.train_total": 895.2262597084045, "timer/agent.train_frac": 0.8951002773935426, "timer/agent.train_avg": 0.4487349672723832, "timer/agent.train_min": 0.437974214553833, "timer/agent.train_max": 0.7309536933898926, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5122592449188232, "timer/agent.report_frac": 0.0005121871563213492, "timer/agent.report_avg": 0.2561296224594116, "timer/agent.report_min": 0.25261688232421875, "timer/agent.report_max": 0.2596423625946045, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6464462280273438e-05, "timer/dataset_eval_frac": 2.646073802153606e-08, "timer/dataset_eval_avg": 2.6464462280273438e-05, "timer/dataset_eval_min": 2.6464462280273438e-05, "timer/dataset_eval_max": 2.6464462280273438e-05, "fps": 31.91497733168316}
{"step": 764168, "time": 24290.38636827469, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 764176, "time": 24290.85583257675, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 764296, "time": 24294.314614534378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 764336, "time": 24295.76169204712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 764464, "time": 24299.678040266037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 764544, "time": 24302.1282851696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 764632, "time": 24304.617069482803, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 764792, "time": 24310.04979634285, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 765024, "time": 24318.110100507736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 765312, "time": 24326.847194433212, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 765336, "time": 24327.364292144775, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 765368, "time": 24328.351021289825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 765376, "time": 24328.821343421936, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 765656, "time": 24337.137387275696, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 765704, "time": 24338.603514909744, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 765720, "time": 24339.116987466812, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 765976, "time": 24347.08461022377, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 766304, "time": 24357.305212259293, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 766368, "time": 24359.28067588806, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 766608, "time": 24366.60233783722, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 766648, "time": 24367.60565686226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 766712, "time": 24369.578053474426, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 767104, "time": 24382.018815755844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 767648, "time": 24398.650201559067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 767968, "time": 24408.625739574432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 768288, "time": 24418.447825670242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 768352, "time": 24420.39207959175, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 768616, "time": 24428.242601633072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 768872, "time": 24436.202999830246, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 768920, "time": 24437.68722653389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 768960, "time": 24439.12826180458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 769024, "time": 24441.108372449875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 769416, "time": 24452.90211057663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 769552, "time": 24457.297923326492, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 769960, "time": 24469.648425340652, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 770016, "time": 24472.15779542923, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 770016, "time": 24472.482039690018, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 770016, "time": 24472.610826015472, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 770016, "time": 24473.61061811447, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 770016, "time": 24473.68402147293, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 770016, "time": 24474.092402219772, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 770016, "time": 24474.979791402817, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 770016, "time": 24476.469816446304, "eval_episode/length": 226.0, "eval_episode/score": 0.29374998807907104, "eval_episode/reward_rate": 0.004405286343612335}
{"step": 770280, "time": 24484.809131383896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 770600, "time": 24494.667115926743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 770696, "time": 24497.584947109222, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 770824, "time": 24501.477642297745, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 770976, "time": 24506.321731328964, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 771016, "time": 24507.333313941956, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 771184, "time": 24512.750214099884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 771232, "time": 24514.208428382874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 771336, "time": 24517.17181992531, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 771400, "time": 24519.116513729095, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 771632, "time": 24526.5739133358, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 771728, "time": 24529.493440389633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 771736, "time": 24529.522572278976, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 771792, "time": 24531.462794303894, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 771896, "time": 24534.391146183014, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 772640, "time": 24557.42125940323, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 772720, "time": 24559.856509447098, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 772720, "time": 24559.866273641586, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 772848, "time": 24563.778285741806, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 773136, "time": 24572.510549783707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 773136, "time": 24572.51867365837, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 773328, "time": 24578.367023944855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 773464, "time": 24582.261750936508, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 773512, "time": 24583.780415534973, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 773528, "time": 24584.325676202774, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 773728, "time": 24590.63391852379, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 773936, "time": 24596.924514770508, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 774048, "time": 24600.331609249115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 774080, "time": 24601.306928396225, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 774208, "time": 24605.189108371735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 774224, "time": 24605.675364017487, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 774488, "time": 24613.476021051407, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 774488, "time": 24613.48373389244, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 774496, "time": 24614.088213682175, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 774696, "time": 24619.98390197754, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 774832, "time": 24624.38408780098, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 774960, "time": 24628.278526306152, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 774976, "time": 24628.77165412903, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 775688, "time": 24650.396746873856, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 775824, "time": 24654.73537516594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 775840, "time": 24655.22434592247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 776360, "time": 24670.740678310394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 776656, "time": 24680.082304239273, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 776800, "time": 24684.50617957115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 777144, "time": 24694.798701763153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 777272, "time": 24698.71621775627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 777288, "time": 24699.20780467987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 777440, "time": 24704.188752174377, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 777568, "time": 24708.1049888134, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 778000, "time": 24721.21600461006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 778136, "time": 24725.12993311882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 778256, "time": 24729.482380867004, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 778288, "time": 24730.448018074036, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 778672, "time": 24742.331423521042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 778672, "time": 24742.350296497345, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 778824, "time": 24746.75017476082, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 778912, "time": 24749.664281606674, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 779296, "time": 24761.3391828537, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 779296, "time": 24761.347407341003, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 779344, "time": 24762.84599328041, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 779584, "time": 24770.324892044067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 779744, "time": 24775.189969539642, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 779784, "time": 24776.17886853218, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 779880, "time": 24779.120859861374, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 780000, "time": 24783.97621846199, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 780000, "time": 24784.27067899704, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 780000, "time": 24784.407558441162, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 780000, "time": 24784.55624270439, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 780000, "time": 24784.66804766655, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 780000, "time": 24784.69531440735, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 780000, "time": 24785.17392849922, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 780000, "time": 24786.58459019661, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 780192, "time": 24792.487139225006, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 780312, "time": 24796.09143614769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 780448, "time": 24800.51121878624, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 780584, "time": 24804.43970489502, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 780664, "time": 24806.896567106247, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 780768, "time": 24810.31905412674, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 781608, "time": 24835.924418449402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 781656, "time": 24837.400037765503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 781728, "time": 24839.827612638474, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 781832, "time": 24842.76385164261, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 782008, "time": 24848.11184167862, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 782080, "time": 24850.538360118866, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 782096, "time": 24851.031376838684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 782216, "time": 24854.629536390305, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 782368, "time": 24859.539965867996, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 782744, "time": 24870.79698228836, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 783168, "time": 24884.07805299759, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 783728, "time": 24901.23488354683, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 783776, "time": 24902.705443143845, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 783968, "time": 24908.581254959106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 784040, "time": 24910.53048324585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 784048, "time": 24910.996741771698, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 784144, "time": 24914.078842639923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 784224, "time": 24916.520894050598, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 784240, "time": 24917.021832942963, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 784392, "time": 24921.45001769066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 784424, "time": 24922.435749292374, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 784592, "time": 24927.77282810211, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 784688, "time": 24930.684287548065, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 784752, "time": 24932.66001200676, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 785016, "time": 24940.527606248856, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 785080, "time": 24942.489325284958, "episode/length": 7.0, "episode/score": 0.9781249761581421, "episode/reward_rate": 0.125, "episode/intrinsic_return": 0.0}
{"step": 785088, "time": 24942.961970090866, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 785200, "time": 24946.525255203247, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 785360, "time": 24951.43958544731, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 785504, "time": 24955.851001501083, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 785936, "time": 24969.041125297546, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 785952, "time": 24969.53077340126, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 786416, "time": 24983.901379346848, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 786608, "time": 24990.246921777725, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 786704, "time": 24993.16490674019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 786728, "time": 24993.674820423126, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 786736, "time": 24994.14377975464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 786904, "time": 24999.008222579956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 787000, "time": 25001.955775260925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 787256, "time": 25009.863196611404, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 787368, "time": 25013.280317544937, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 787400, "time": 25014.258405923843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 787528, "time": 25018.161653757095, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 787648, "time": 25022.036988019943, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 787760, "time": 25025.447201251984, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 788072, "time": 25034.77733373642, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 788152, "time": 25037.214495182037, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 788176, "time": 25038.16003060341, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 788184, "time": 25038.187772989273, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 788280, "time": 25041.1192009449, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 788304, "time": 25042.078056573868, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 788312, "time": 25042.10649394989, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 788728, "time": 25054.742508411407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 788792, "time": 25056.71017932892, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 788800, "time": 25057.17824602127, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 788944, "time": 25061.560002088547, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 789224, "time": 25069.971753120422, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 789560, "time": 25080.256852388382, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 789568, "time": 25080.728988170624, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 790088, "time": 25097.99463891983, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 790088, "time": 25098.647236585617, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 790088, "time": 25098.96993947029, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 790088, "time": 25099.095657110214, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 790088, "time": 25101.06177663803, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 790088, "time": 25102.46011376381, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790088, "time": 25102.46724295616, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790088, "time": 25102.472794532776, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790088, "time": 25102.48120689392, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790488, "time": 25116.706705093384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 790496, "time": 25117.17617702484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 790592, "time": 25120.108644008636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 790616, "time": 25120.619791030884, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 791040, "time": 25133.91131711006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 791056, "time": 25134.400333166122, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 791104, "time": 25135.867498636246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 791216, "time": 25139.281062602997, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 791256, "time": 25140.283826828003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 791656, "time": 25152.440060138702, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 791776, "time": 25156.468881845474, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 791776, "time": 25156.47719669342, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 791824, "time": 25157.963854074478, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 791832, "time": 25157.99156188965, "episode/length": 6.0, "episode/score": 0.981249988079071, "episode/reward_rate": 0.14285714285714285, "episode/intrinsic_return": 0.0}
{"step": 791880, "time": 25159.459385871887, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 791880, "time": 25159.466419935226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 792208, "time": 25169.68438744545, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 792424, "time": 25176.040747880936, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 792592, "time": 25181.38382744789, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 792688, "time": 25184.39422917366, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 792808, "time": 25187.814399003983, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 792808, "time": 25187.820807933807, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 792824, "time": 25188.31577539444, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 792832, "time": 25188.795679330826, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 793208, "time": 25200.09468793869, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 793656, "time": 25213.95150232315, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 793712, "time": 25215.903979301453, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 793744, "time": 25216.880175828934, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 793896, "time": 25221.31491947174, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 794072, "time": 25226.71216249466, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 794192, "time": 25230.611954689026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 794736, "time": 25247.752101421356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 794824, "time": 25250.21381211281, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 794832, "time": 25250.70467710495, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 794928, "time": 25253.654688358307, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 795120, "time": 25259.534919977188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 795192, "time": 25261.55366420746, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 795664, "time": 25276.34861922264, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 795912, "time": 25283.74681544304, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 796041, "time": 25288.730260133743, "train_stats/mean_log_entropy": 0.09591570727784059, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3029438574709484, "train/action_min": 0.0, "train/action_std": 1.6225345146715942, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009264368622390618, "train/actor_opt_grad_steps": 48660.0, "train/actor_opt_loss": -6.6376693081461715, "train/adv_mag": 0.8861542727479983, "train/adv_max": 0.2655921455603748, "train/adv_mean": 0.0019481823244987667, "train/adv_min": -0.8629738562670185, "train/adv_std": 0.03079898465406056, "train/cont_avg": 0.995583385678392, "train/cont_loss_mean": 0.016016149569312157, "train/cont_loss_std": 0.231527957211169, "train/cont_neg_acc": 0.3509900648937081, "train/cont_neg_loss": 2.86731372152942, "train/cont_pos_acc": 0.9998717583603596, "train/cont_pos_loss": 0.003182511531570037, "train/cont_pred": 0.9954349362670477, "train/cont_rate": 0.995583385678392, "train/dyn_loss_mean": 1.0000746549673416, "train/dyn_loss_std": 0.0007238419885611414, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.22341187806547286, "train/extr_critic_critic_opt_grad_steps": 48660.0, "train/extr_critic_critic_opt_loss": 13071.256276499686, "train/extr_critic_mag": 1.123999469843342, "train/extr_critic_max": 1.123999469843342, "train/extr_critic_mean": 1.0621038938886556, "train/extr_critic_min": 0.9558529626184972, "train/extr_critic_std": 0.013264625511090061, "train/extr_return_normed_mag": 0.87982572023593, "train/extr_return_normed_max": 0.2825795645689845, "train/extr_return_normed_mean": 0.02802075040830889, "train/extr_return_normed_min": -0.848219690610416, "train/extr_return_normed_std": 0.034064219099230804, "train/extr_return_rate": 0.9989086515340374, "train/extr_return_raw_mag": 1.318610863469953, "train/extr_return_raw_max": 1.318610863469953, "train/extr_return_raw_mean": 1.0640521175298259, "train/extr_return_raw_min": 0.1878116082905525, "train/extr_return_raw_std": 0.03406421914603093, "train/extr_reward_mag": 0.3297731684679961, "train/extr_reward_max": 0.3297731684679961, "train/extr_reward_mean": 0.00252672796162201, "train/extr_reward_min": 4.8522374138760206e-08, "train/extr_reward_std": 0.01074747101113612, "train/image_loss_mean": 0.0910007602830029, "train/image_loss_std": 0.10081925157027029, "train/model_loss_mean": 0.7162477248278095, "train/model_loss_std": 0.3975897463572085, "train/model_opt_grad_norm": 18.811034571585342, "train/model_opt_grad_steps": 48616.48743718593, "train/model_opt_loss": 3617.047949709485, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5050.251256281407, "train/policy_entropy_mag": 1.3340716655529923, "train/policy_entropy_max": 1.3340716655529923, "train/policy_entropy_mean": 0.108561814430371, "train/policy_entropy_min": 0.06468650986950601, "train/policy_entropy_std": 0.141593750884485, "train/policy_logprob_mag": 6.551080246067526, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1083858813248088, "train/policy_logprob_min": -6.551080246067526, "train/policy_logprob_std": 0.6457584590169053, "train/policy_randomness_mag": 0.6855772589918357, "train/policy_randomness_max": 0.6855772589918357, "train/policy_randomness_mean": 0.055789739249189896, "train/policy_randomness_min": 0.03324229120459389, "train/policy_randomness_std": 0.0727647979505098, "train/post_ent_mag": 52.005553739154756, "train/post_ent_max": 52.005553739154756, "train/post_ent_mean": 46.34550819205279, "train/post_ent_min": 42.21113628598314, "train/post_ent_std": 2.0697654899041256, "train/prior_ent_mag": 53.06702940667694, "train/prior_ent_max": 53.06702940667694, "train/prior_ent_mean": 46.55430493762146, "train/prior_ent_min": 41.784190614019806, "train/prior_ent_std": 2.1195890484143742, "train/rep_loss_mean": 1.0000746549673416, "train/rep_loss_std": 0.0007238419885611414, "train/reward_avg": 0.0011008257775692663, "train/reward_loss_mean": 0.009185998652004005, "train/reward_loss_std": 0.17006852781638765, "train/reward_max_data": 0.6043969859280179, "train/reward_max_pred": 0.14384448767906458, "train/reward_neg_acc": 0.999872173795748, "train/reward_neg_loss": 0.0015704337758744539, "train/reward_pos_acc": 0.15558943161513747, "train/reward_pos_loss": 4.575996920829866, "train/reward_pred": 0.0009055107758244752, "train/reward_rate": 0.0016635913944723617, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.014605827629566193, "report/cont_loss_std": 0.23024870455265045, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.432311534881592, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0027426995802670717, "report/cont_pred": 0.9954119920730591, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08708439767360687, "report/image_loss_std": 0.10072369128465652, "report/model_loss_mean": 0.70795738697052, "report/model_loss_std": 0.3514785170555115, "report/post_ent_mag": 53.63812255859375, "report/post_ent_max": 53.63812255859375, "report/post_ent_mean": 47.38471984863281, "report/post_ent_min": 42.46404266357422, "report/post_ent_std": 2.1392581462860107, "report/prior_ent_mag": 54.810569763183594, "report/prior_ent_max": 54.810569763183594, "report/prior_ent_mean": 47.179039001464844, "report/prior_ent_min": 41.91336441040039, "report/prior_ent_std": 2.513439178466797, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007598876836709678, "report/reward_loss_mean": 0.006267117336392403, "report/reward_loss_std": 0.1446949541568756, "report/reward_max_data": 0.778124988079071, "report/reward_max_pred": 0.08534753322601318, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0017537417588755488, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.62345027923584, "report/reward_pred": 0.0008920897962525487, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.04417427256703377, "eval/cont_loss_std": 0.6365887522697449, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.529986381530762, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0025363354943692684, "eval/cont_pred": 0.9975066184997559, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.15447257459163666, "eval/image_loss_std": 0.15197977423667908, "eval/model_loss_mean": 0.8118218183517456, "eval/model_loss_std": 0.796286940574646, "eval/post_ent_mag": 53.62757873535156, "eval/post_ent_max": 53.62757873535156, "eval/post_ent_mean": 47.187686920166016, "eval/post_ent_min": 42.734352111816406, "eval/post_ent_std": 2.2548999786376953, "eval/prior_ent_mag": 54.810569763183594, "eval/prior_ent_max": 54.810569763183594, "eval/prior_ent_mean": 46.987388610839844, "eval/prior_ent_min": 42.02539825439453, "eval/prior_ent_std": 2.6923162937164307, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0011810302967205644, "eval/reward_loss_mean": 0.013174941763281822, "eval/reward_loss_std": 0.26708173751831055, "eval/reward_max_data": 0.6781250238418579, "eval/reward_max_pred": 0.05150175094604492, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013655750080943108, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.047761917114258, "eval/reward_pred": 0.0006813299842178822, "eval/reward_rate": 0.001953125, "replay/size": 795537.0, "replay/inserts": 31936.0, "replay/samples": 31936.0, "replay/insert_wait_avg": 1.351556223714519e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.646262219530308e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5504.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2155708878539329e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0413966178894, "timer/env.step_count": 3992.0, "timer/env.step_total": 39.44810509681702, "timer/env.step_frac": 0.03944647214628249, "timer/env.step_avg": 0.009881789853912078, "timer/env.step_min": 0.007971763610839844, "timer/env.step_max": 0.035334110260009766, "timer/replay._sample_count": 31936.0, "timer/replay._sample_total": 17.649197578430176, "timer/replay._sample_frac": 0.01764846699158579, "timer/replay._sample_avg": 0.0005526427097454339, "timer/replay._sample_min": 0.0004165172576904297, "timer/replay._sample_max": 0.028381824493408203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4680.0, "timer/agent.policy_total": 51.178996562957764, "timer/agent.policy_frac": 0.051176878013293875, "timer/agent.policy_avg": 0.010935683026273027, "timer/agent.policy_min": 0.009195089340209961, "timer/agent.policy_max": 0.15092849731445312, "timer/dataset_train_count": 1996.0, "timer/dataset_train_total": 0.23264265060424805, "timer/dataset_train_frac": 0.00023263302038399475, "timer/dataset_train_avg": 0.00011655443417046496, "timer/dataset_train_min": 0.0001010894775390625, "timer/dataset_train_max": 0.0003116130828857422, "timer/agent.train_count": 1996.0, "timer/agent.train_total": 895.8066358566284, "timer/agent.train_frac": 0.8957695540266835, "timer/agent.train_avg": 0.4488009197678499, "timer/agent.train_min": 0.43352842330932617, "timer/agent.train_max": 2.5152556896209717, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5200412273406982, "timer/agent.report_frac": 0.0005200197002838706, "timer/agent.report_avg": 0.2600206136703491, "timer/agent.report_min": 0.256575345993042, "timer/agent.report_max": 0.26346588134765625, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8132227754901626e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 31.934119190820763}
{"step": 796208, "time": 25293.948442697525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 796384, "time": 25299.356107711792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 796448, "time": 25301.337500572205, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 797048, "time": 25319.551245212555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 797096, "time": 25321.033698558807, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 797136, "time": 25322.472863197327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 797240, "time": 25325.446313142776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 797320, "time": 25327.888874053955, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 797448, "time": 25331.801855564117, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 797504, "time": 25333.74846291542, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 797536, "time": 25334.793798923492, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 797864, "time": 25344.5659263134, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 797952, "time": 25347.483798980713, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 797976, "time": 25347.99748110771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 798000, "time": 25348.948947906494, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 798072, "time": 25350.928866624832, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 798088, "time": 25351.41964173317, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 798224, "time": 25355.78418946266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 798232, "time": 25355.812580108643, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 798240, "time": 25356.28637433052, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 798416, "time": 25361.619045495987, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 798440, "time": 25362.13543987274, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 798528, "time": 25365.157252788544, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 798528, "time": 25365.16683292389, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 798576, "time": 25366.626296281815, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 798656, "time": 25369.057910442352, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 798800, "time": 25373.47221493721, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 799000, "time": 25379.381405353546, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 799128, "time": 25383.301889657974, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 799496, "time": 25394.68285894394, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 799768, "time": 25402.968760728836, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 799848, "time": 25405.419265031815, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 800032, "time": 25411.23974585533, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 800072, "time": 25412.801557302475, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 800072, "time": 25413.17019844055, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 800072, "time": 25414.544025182724, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 800072, "time": 25414.69259738922, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 800072, "time": 25414.699860811234, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 800072, "time": 25415.76076745987, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 800072, "time": 25417.14724087715, "eval_episode/length": 235.0, "eval_episode/score": 0.265625, "eval_episode/reward_rate": 0.00423728813559322}
{"step": 800072, "time": 25417.25214624405, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 800256, "time": 25423.10306620598, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 800544, "time": 25432.016957998276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 800552, "time": 25432.046577453613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 800840, "time": 25440.854497909546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 800968, "time": 25444.760627508163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801016, "time": 25446.209907770157, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 801272, "time": 25454.130022764206, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 801272, "time": 25454.13992190361, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 801312, "time": 25455.57897734642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801408, "time": 25458.505375146866, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 801440, "time": 25459.47486424446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 802056, "time": 25477.874307632446, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 802096, "time": 25479.320521116257, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 802200, "time": 25482.285056352615, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 802232, "time": 25483.265961408615, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 802272, "time": 25484.817690849304, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 802432, "time": 25489.73000884056, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 802608, "time": 25495.074778318405, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 802720, "time": 25498.484166145325, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 802864, "time": 25503.39999485016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 802920, "time": 25504.89924788475, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 802984, "time": 25506.839915275574, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 803032, "time": 25508.314461946487, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 803176, "time": 25512.69140648842, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 803408, "time": 25520.065213918686, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 803536, "time": 25523.981205940247, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 803584, "time": 25525.44885110855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 803672, "time": 25527.94576191902, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 803728, "time": 25529.87358188629, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 803736, "time": 25529.90110397339, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 804000, "time": 25538.20102953911, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 804264, "time": 25546.195117235184, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 804424, "time": 25551.100831270218, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 804456, "time": 25552.107124090195, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 804472, "time": 25552.600154399872, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 804512, "time": 25554.064289331436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 804744, "time": 25560.917358636856, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 804936, "time": 25566.808616638184, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 804944, "time": 25567.282558918, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 805024, "time": 25569.715830802917, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 805032, "time": 25569.743448972702, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 805304, "time": 25578.188446998596, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 805448, "time": 25582.612273693085, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 805456, "time": 25583.083693265915, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 805672, "time": 25589.493206501007, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 805712, "time": 25590.982980966568, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 805720, "time": 25591.01310110092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 805728, "time": 25591.491163015366, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 806048, "time": 25601.448743104935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 806056, "time": 25601.476824760437, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 806344, "time": 25610.470064878464, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 806480, "time": 25614.888800382614, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 806624, "time": 25619.320315361023, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 806656, "time": 25620.30304145813, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 807080, "time": 25633.04546737671, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 807096, "time": 25633.538647651672, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 807264, "time": 25639.048771619797, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 807336, "time": 25641.044142723083, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 807384, "time": 25642.517153978348, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 807536, "time": 25647.383773565292, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 807544, "time": 25647.411620140076, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 807616, "time": 25649.820917367935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 807672, "time": 25651.332051038742, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 808024, "time": 25662.06211900711, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 808184, "time": 25667.088327884674, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 808296, "time": 25670.515275239944, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 808448, "time": 25675.414587020874, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 808760, "time": 25684.784143209457, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 808840, "time": 25687.25004386902, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 808872, "time": 25688.234694242477, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 809192, "time": 25698.149618148804, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 809240, "time": 25699.638374328613, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 809392, "time": 25704.495809793472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 809704, "time": 25713.8928937912, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 809848, "time": 25718.300847768784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 809960, "time": 25721.71753025055, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 809984, "time": 25722.677195072174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 810056, "time": 25726.67180299759, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 810056, "time": 25731.219963550568, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 25731.22835803032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 25731.236904382706, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 25731.24542069435, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 25731.253193855286, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 25731.261972904205, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 25731.27138519287, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810080, "time": 25732.231825590134, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 810152, "time": 25734.22541952133, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 810408, "time": 25742.041009664536, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 810608, "time": 25748.410134077072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 810672, "time": 25750.37449169159, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 810696, "time": 25750.887501239777, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 811152, "time": 25765.61111140251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 811200, "time": 25767.078550338745, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 811248, "time": 25768.543081760406, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 811392, "time": 25772.915998220444, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 811504, "time": 25776.365787744522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 811792, "time": 25785.3241686821, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 811952, "time": 25790.21343946457, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 812160, "time": 25796.572722911835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 812272, "time": 25800.00818014145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 812448, "time": 25805.405227422714, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 812848, "time": 25817.867923498154, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 812888, "time": 25818.867928743362, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 812920, "time": 25819.863821983337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 812952, "time": 25820.838403224945, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 813512, "time": 25837.92620563507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 813560, "time": 25839.412996292114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 814104, "time": 25856.04586839676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 814264, "time": 25860.895628213882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 814344, "time": 25863.31714272499, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 815040, "time": 25884.892279863358, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 815160, "time": 25888.3533911705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 815176, "time": 25888.85099673271, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 815200, "time": 25889.80833005905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 815264, "time": 25891.73512673378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 815544, "time": 25900.005941152573, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 815544, "time": 25900.013081550598, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 815632, "time": 25902.92077112198, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 815792, "time": 25907.914180755615, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 815856, "time": 25909.86906695366, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 815936, "time": 25912.310234069824, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 815960, "time": 25912.848138809204, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 816416, "time": 25926.97259235382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 816632, "time": 25933.36378455162, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 816640, "time": 25933.95833325386, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 816656, "time": 25934.45927786827, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 816800, "time": 25938.90917444229, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 817000, "time": 25944.761959075928, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 817320, "time": 25954.457602977753, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 817328, "time": 25954.940318107605, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 817512, "time": 25960.32963514328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 817520, "time": 25960.798430919647, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 817648, "time": 25964.81582427025, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 817680, "time": 25965.784474611282, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 817856, "time": 25971.12400007248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 817992, "time": 25975.08004307747, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 818320, "time": 25985.339126586914, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 818328, "time": 25985.374288082123, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 818344, "time": 25985.86867761612, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 818552, "time": 25992.24210500717, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 818832, "time": 26001.09846138954, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 818944, "time": 26004.518757104874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 819600, "time": 26025.256036281586, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 819728, "time": 26029.16317820549, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 819792, "time": 26031.156455993652, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 819888, "time": 26034.094065904617, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 820040, "time": 26039.577483415604, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 820040, "time": 26039.84853863716, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 820040, "time": 26040.804770469666, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 820040, "time": 26041.078503370285, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 820040, "time": 26041.610274791718, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 820040, "time": 26041.75423359871, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 820040, "time": 26041.897297143936, "eval_episode/length": 164.0, "eval_episode/score": 0.48750001192092896, "eval_episode/reward_rate": 0.006060606060606061}
{"step": 820040, "time": 26042.507034778595, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 820168, "time": 26046.412596940994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 820216, "time": 26047.8636033535, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 820304, "time": 26050.790910482407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 820864, "time": 26067.95180797577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 820912, "time": 26069.44979119301, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 821088, "time": 26074.87167739868, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 821416, "time": 26084.806602478027, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 821672, "time": 26092.581624746323, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 821784, "time": 26096.025997638702, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 821912, "time": 26099.982704877853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 821944, "time": 26100.9748005867, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 822104, "time": 26105.906989574432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 822144, "time": 26107.353510141373, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 822176, "time": 26108.334900140762, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 822200, "time": 26108.86663198471, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 822304, "time": 26112.24391102791, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 822352, "time": 26113.784180402756, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 822600, "time": 26121.190507888794, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 822784, "time": 26126.990213871002, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 822952, "time": 26131.900255918503, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 823104, "time": 26136.770045042038, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 823144, "time": 26137.770178556442, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 823224, "time": 26140.231492996216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 823472, "time": 26148.146744012833, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 823504, "time": 26149.125598669052, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 823664, "time": 26154.0232026577, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 823752, "time": 26156.503216028214, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 823792, "time": 26157.967582702637, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 823808, "time": 26158.45894908905, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 824224, "time": 26171.1516661644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 824256, "time": 26172.13918709755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 824296, "time": 26173.16258621216, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 824344, "time": 26174.720722913742, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 824664, "time": 26184.510184764862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 824808, "time": 26188.932730913162, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 824840, "time": 26189.90783405304, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 824912, "time": 26192.324407339096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 825080, "time": 26197.21768426895, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 825264, "time": 26203.070913791656, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 825296, "time": 26204.189141750336, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 825320, "time": 26204.710859298706, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 825320, "time": 26206.19856762886, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 825336, "time": 26206.696386814117, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 825464, "time": 26210.610991716385, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 826000, "time": 26227.127819299698, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 826056, "time": 26228.616472244263, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 826656, "time": 26247.23918414116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 827184, "time": 26263.35365152359, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 827328, "time": 26267.908854961395, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 827376, "time": 26269.383200645447, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 827392, "time": 26270.060797214508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 827608, "time": 26276.753234624863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 827648, "time": 26278.20774292946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 827688, "time": 26279.201494932175, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 827776, "time": 26282.118362903595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 827816, "time": 26283.15826368332, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 827912, "time": 26286.12532067299, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 827977, "time": 26289.175594091415, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.227899475097656, "train/action_min": 0.0, "train/action_std": 1.5959844756126405, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00896371828392148, "train/actor_opt_grad_steps": 50655.0, "train/actor_opt_loss": -6.385207071863115, "train/adv_mag": 0.8773883655667305, "train/adv_max": 0.2640991538763046, "train/adv_mean": 0.002414926938381541, "train/adv_min": -0.842866025865078, "train/adv_std": 0.029461690664757043, "train/cont_avg": 0.9953076171875, "train/cont_loss_mean": 0.016245524485129864, "train/cont_loss_std": 0.23003640692215413, "train/cont_neg_acc": 0.3384114949382501, "train/cont_neg_loss": 2.7559964937777828, "train/cont_pos_acc": 0.9999068069458008, "train/cont_pos_loss": 0.0032099554396700113, "train/cont_pred": 0.9953006064891815, "train/cont_rate": 0.9953076171875, "train/dyn_loss_mean": 1.0000006407499313, "train/dyn_loss_std": 2.0489070407165856e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2590784276649356, "train/extr_critic_critic_opt_grad_steps": 50655.0, "train/extr_critic_critic_opt_loss": 8494.889084472656, "train/extr_critic_mag": 1.1986334609985352, "train/extr_critic_max": 1.1986334609985352, "train/extr_critic_mean": 1.1425274550914764, "train/extr_critic_min": 1.0476877146959305, "train/extr_critic_std": 0.014081249157898127, "train/extr_return_normed_mag": 0.8757468926906585, "train/extr_return_normed_max": 0.28942581653594973, "train/extr_return_normed_mean": 0.03266826927196234, "train/extr_return_normed_min": -0.8261754262447357, "train/extr_return_normed_std": 0.033643775125965475, "train/extr_return_rate": 0.9991914489865303, "train/extr_return_raw_mag": 1.4016999250650406, "train/extr_return_raw_max": 1.4016999250650406, "train/extr_return_raw_mean": 1.1449424463510514, "train/extr_return_raw_min": 0.28609868228435514, "train/extr_return_raw_std": 0.03364377496298403, "train/extr_reward_mag": 0.3240583550930023, "train/extr_reward_max": 0.3240583550930023, "train/extr_reward_mean": 0.002613501744635869, "train/extr_reward_min": 1.728534698486328e-07, "train/extr_reward_std": 0.010540659149410204, "train/image_loss_mean": 0.09196723479777574, "train/image_loss_std": 0.10217863008379936, "train/model_loss_mean": 0.7181737634539604, "train/model_loss_std": 0.4060982409492135, "train/model_opt_grad_norm": 18.67445202448859, "train/model_opt_grad_steps": 50609.515, "train/model_opt_loss": 3627.716207275391, "train/model_opt_model_opt_grad_overflow": 0.005, "train/model_opt_model_opt_grad_scale": 5050.0, "train/policy_entropy_mag": 1.3356486362218858, "train/policy_entropy_max": 1.3356486362218858, "train/policy_entropy_mean": 0.10462175406515599, "train/policy_entropy_min": 0.06468649785965681, "train/policy_entropy_std": 0.1355909812450409, "train/policy_logprob_mag": 6.55108026266098, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10431240878999233, "train/policy_logprob_min": -6.55108026266098, "train/policy_logprob_std": 0.6421718445420265, "train/policy_randomness_mag": 0.6863876608014107, "train/policy_randomness_max": 0.6863876608014107, "train/policy_randomness_mean": 0.05376494821161032, "train/policy_randomness_min": 0.033242284469306466, "train/policy_randomness_std": 0.0696799843199551, "train/post_ent_mag": 53.89191305160522, "train/post_ent_max": 53.89191305160522, "train/post_ent_mean": 46.44925912857056, "train/post_ent_min": 41.33947200775147, "train/post_ent_std": 2.637666096687317, "train/prior_ent_mag": 54.726537246704105, "train/prior_ent_max": 54.726537246704105, "train/prior_ent_mean": 46.591267337799074, "train/prior_ent_min": 40.82858163833618, "train/prior_ent_std": 2.669790073633194, "train/rep_loss_mean": 1.0000006407499313, "train/rep_loss_std": 2.0489070407165856e-05, "train/reward_avg": 0.0012418670620536433, "train/reward_loss_mean": 0.009960595367010683, "train/reward_loss_std": 0.17940263903932646, "train/reward_max_data": 0.6435000002384186, "train/reward_max_pred": 0.14103216469287871, "train/reward_neg_acc": 0.9998580923676491, "train/reward_neg_loss": 0.0016441469005076216, "train/reward_pos_acc": 0.12796934925276657, "train/reward_pos_loss": 4.477711094864484, "train/reward_pred": 0.0009508999343961478, "train/reward_rate": 0.0018505859375, "train_stats/mean_log_entropy": 0.08472363209645999, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.01060497760772705, "report/cont_loss_std": 0.23320618271827698, "report/cont_neg_acc": 0.75, "report/cont_neg_loss": 1.8754109144210815, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0032920120283961296, "report/cont_pred": 0.993919849395752, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09261490404605865, "report/image_loss_std": 0.10069943219423294, "report/model_loss_mean": 0.7065867781639099, "report/model_loss_std": 0.25812673568725586, "report/post_ent_mag": 52.841583251953125, "report/post_ent_max": 52.841583251953125, "report/post_ent_mean": 44.981136322021484, "report/post_ent_min": 40.669273376464844, "report/post_ent_std": 2.490236282348633, "report/prior_ent_mag": 56.95231246948242, "report/prior_ent_max": 56.95231246948242, "report/prior_ent_mean": 47.49944305419922, "report/prior_ent_min": 41.06072235107422, "report/prior_ent_std": 2.95731258392334, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00079345703125, "report/reward_loss_mean": 0.0033669043332338333, "report/reward_loss_std": 0.04509971663355827, "report/reward_max_data": 0.8125, "report/reward_max_pred": 0.49008965492248535, "report/reward_neg_acc": 0.9990224838256836, "report/reward_neg_loss": 0.0020133373327553272, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 1.388066053390503, "report/reward_pred": 0.0014901889953762293, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.03790447860956192, "eval/cont_loss_std": 0.5306366086006165, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.277842998504639, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002379754791036248, "eval/cont_pred": 0.9976619482040405, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18061935901641846, "eval/image_loss_std": 0.1491224765777588, "eval/model_loss_mean": 0.8408842086791992, "eval/model_loss_std": 0.937823474407196, "eval/post_ent_mag": 52.84148025512695, "eval/post_ent_max": 52.84148025512695, "eval/post_ent_mean": 44.589054107666016, "eval/post_ent_min": 39.530887603759766, "eval/post_ent_std": 2.953871488571167, "eval/prior_ent_mag": 56.95231246948242, "eval/prior_ent_max": 56.95231246948242, "eval/prior_ent_mean": 46.95672607421875, "eval/prior_ent_min": 40.4498291015625, "eval/prior_ent_std": 3.3649654388427734, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0016448975075036287, "eval/reward_loss_mean": 0.022360386326909065, "eval/reward_loss_std": 0.49785226583480835, "eval/reward_max_data": 0.856249988079071, "eval/reward_max_pred": 0.019641995429992676, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0005792022566311061, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 11.152545928955078, "eval/reward_pred": 0.0002980041317641735, "eval/reward_rate": 0.001953125, "replay/size": 827473.0, "replay/inserts": 31936.0, "replay/samples": 31936.0, "replay/insert_wait_avg": 1.3704738301600149e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.62543344211005e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5808.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2019038528778665e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3560056686401367e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4278719425201, "timer/env.step_count": 3992.0, "timer/env.step_total": 39.81159949302673, "timer/env.step_frac": 0.039794572511984275, "timer/env.step_avg": 0.009972845564385454, "timer/env.step_min": 0.007819414138793945, "timer/env.step_max": 0.043100833892822266, "timer/replay._sample_count": 31936.0, "timer/replay._sample_total": 17.669360637664795, "timer/replay._sample_frac": 0.01766180364742976, "timer/replay._sample_avg": 0.0005532740680631511, "timer/replay._sample_min": 0.00041604042053222656, "timer/replay._sample_max": 0.028411388397216797, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4718.0, "timer/agent.policy_total": 51.87786602973938, "timer/agent.policy_frac": 0.05185567843987461, "timer/agent.policy_avg": 0.01099573252008041, "timer/agent.policy_min": 0.008758306503295898, "timer/agent.policy_max": 0.09937524795532227, "timer/dataset_train_count": 1996.0, "timer/dataset_train_total": 0.23454546928405762, "timer/dataset_train_frac": 0.00023444515677941197, "timer/dataset_train_avg": 0.00011750775014231343, "timer/dataset_train_min": 9.942054748535156e-05, "timer/dataset_train_max": 0.0010821819305419922, "timer/agent.train_count": 1996.0, "timer/agent.train_total": 893.3179528713226, "timer/agent.train_frac": 0.8929358906572412, "timer/agent.train_avg": 0.44755408460487106, "timer/agent.train_min": 0.4353816509246826, "timer/agent.train_max": 0.703805685043335, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5169677734375, "timer/agent.report_frac": 0.0005167466720351455, "timer/agent.report_avg": 0.25848388671875, "timer/agent.report_min": 0.254638671875, "timer/agent.report_max": 0.2623291015625, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5987625122070312e-05, "timer/dataset_eval_frac": 2.59765105020619e-08, "timer/dataset_eval_avg": 2.5987625122070312e-05, "timer/dataset_eval_min": 2.5987625122070312e-05, "timer/dataset_eval_max": 2.5987625122070312e-05, "fps": 31.921769113396994}
{"step": 828168, "time": 26295.013134002686, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 828192, "time": 26295.978246450424, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 828272, "time": 26298.461409330368, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 828392, "time": 26301.91882443428, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 828472, "time": 26304.38398194313, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 828560, "time": 26307.28408074379, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 828640, "time": 26309.747854948044, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 829216, "time": 26327.471855163574, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 829232, "time": 26327.985038280487, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 829280, "time": 26329.451409101486, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 829288, "time": 26329.478983163834, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 829496, "time": 26335.87022137642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 829576, "time": 26338.32167840004, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 829736, "time": 26343.188222169876, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 829952, "time": 26349.97189950943, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 829984, "time": 26350.94665670395, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 830024, "time": 26352.136502742767, "eval_episode/length": 8.0, "eval_episode/score": 0.9750000238418579, "eval_episode/reward_rate": 0.1111111111111111}
{"step": 830024, "time": 26353.450742959976, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 830024, "time": 26353.556153535843, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 830024, "time": 26354.695254802704, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 830024, "time": 26354.73134970665, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 830024, "time": 26355.00253891945, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 830024, "time": 26355.12505054474, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 830024, "time": 26355.18955874443, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 830128, "time": 26358.6000187397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 830184, "time": 26360.082461595535, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 830328, "time": 26364.460924625397, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 830504, "time": 26369.81405735016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 830784, "time": 26378.54411840439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 830800, "time": 26379.034388065338, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 830856, "time": 26380.548527240753, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 831216, "time": 26391.890872716904, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 831248, "time": 26392.86904501915, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 831376, "time": 26396.807417154312, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 831720, "time": 26407.113705396652, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 831888, "time": 26412.488092422485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 832048, "time": 26417.492702245712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 832264, "time": 26423.811500549316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 832264, "time": 26423.81942820549, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 832552, "time": 26432.534384965897, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 832624, "time": 26434.96991586685, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 832816, "time": 26440.809220790863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 833008, "time": 26446.70174598694, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 833152, "time": 26451.06445670128, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 833168, "time": 26451.557337522507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 833440, "time": 26459.832990169525, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 833560, "time": 26463.315742492676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 833560, "time": 26463.324894428253, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 833576, "time": 26463.818075180054, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 833728, "time": 26468.699461698532, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 833816, "time": 26471.144963502884, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 833824, "time": 26471.617568016052, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 834232, "time": 26483.989708423615, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 834320, "time": 26486.881196260452, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 834480, "time": 26491.75585269928, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 834568, "time": 26494.224889039993, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 834576, "time": 26494.696214199066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 834736, "time": 26499.58265709877, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 834744, "time": 26499.612092256546, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 834752, "time": 26500.088559389114, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 834896, "time": 26504.626487016678, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 834944, "time": 26506.092624664307, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 835016, "time": 26508.072255134583, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 835024, "time": 26508.54377269745, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 835392, "time": 26519.777561903, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 835448, "time": 26521.26818919182, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 835584, "time": 26525.81788301468, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 835608, "time": 26526.68473124504, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 836024, "time": 26539.531362771988, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 836040, "time": 26540.0238571167, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 836136, "time": 26542.968130350113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 836168, "time": 26543.94135069847, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 836272, "time": 26547.33380007744, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 836600, "time": 26557.128487825394, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 836816, "time": 26564.06663775444, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 836824, "time": 26564.094984054565, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 836880, "time": 26566.03067302704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 837144, "time": 26573.898740291595, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 837200, "time": 26575.827192783356, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 837328, "time": 26579.751118183136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 837512, "time": 26585.137845039368, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 837792, "time": 26594.075628757477, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 838024, "time": 26600.938269615173, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 838304, "time": 26609.711102247238, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 838336, "time": 26610.690335989, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 838440, "time": 26613.648193597794, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 838448, "time": 26614.124918699265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 838584, "time": 26618.06896662712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 838592, "time": 26618.53879594803, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 838880, "time": 26627.528779268265, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 839152, "time": 26635.856270313263, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 839160, "time": 26635.883174419403, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 839640, "time": 26650.526079177856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 839664, "time": 26651.484766960144, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 839712, "time": 26652.959369659424, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 839824, "time": 26656.54583477974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 839872, "time": 26658.014776945114, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 839928, "time": 26659.513170957565, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 840008, "time": 26662.82236790657, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 840008, "time": 26663.075587511063, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 840008, "time": 26663.10266971588, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 840008, "time": 26663.700377464294, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 840008, "time": 26663.835399627686, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 840008, "time": 26663.864278316498, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 840008, "time": 26664.041320085526, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 840008, "time": 26664.091624975204, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 840248, "time": 26671.440593719482, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 840320, "time": 26673.89213323593, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 840792, "time": 26688.141112804413, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 840896, "time": 26691.534123659134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 840904, "time": 26691.564250469208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 841136, "time": 26698.89572906494, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 841160, "time": 26699.407798290253, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 841248, "time": 26702.352263450623, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 841744, "time": 26717.64363837242, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 841960, "time": 26724.02146577835, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 841976, "time": 26724.51413655281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 842024, "time": 26725.977778196335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 842136, "time": 26729.4078643322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 842384, "time": 26737.191201210022, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 842440, "time": 26738.679691791534, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 842560, "time": 26742.573969841003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 842600, "time": 26743.629820108414, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 842704, "time": 26747.10366511345, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 842784, "time": 26749.540192842484, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 843216, "time": 26762.73728966713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 843472, "time": 26770.562664031982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 843776, "time": 26780.111362218857, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 844080, "time": 26789.75088739395, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 844152, "time": 26791.756305933, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 844208, "time": 26793.679690122604, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 844336, "time": 26797.608688354492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 844776, "time": 26810.979054689407, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 844808, "time": 26811.958678007126, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 844872, "time": 26813.908482313156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 844880, "time": 26814.377627134323, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 845096, "time": 26820.799906015396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 845336, "time": 26828.124484539032, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 845432, "time": 26831.070274829865, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 845560, "time": 26835.097685813904, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 845632, "time": 26837.517171382904, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 845664, "time": 26838.490533828735, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 845736, "time": 26840.477501630783, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 845952, "time": 26847.321507692337, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 846232, "time": 26855.72062921524, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 846648, "time": 26868.549387216568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 846704, "time": 26870.49307155609, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 847184, "time": 26885.137368679047, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 847184, "time": 26885.148183345795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 847256, "time": 26887.118998765945, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 847648, "time": 26899.41733932495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 847744, "time": 26902.33384013176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 847744, "time": 26902.341908454895, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 847864, "time": 26905.809577703476, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 847944, "time": 26908.248770952225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 848264, "time": 26918.18992471695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 848320, "time": 26920.160513162613, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 848368, "time": 26921.638437271118, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 848416, "time": 26923.114456176758, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 848680, "time": 26931.087970733643, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 848744, "time": 26933.065806388855, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 848896, "time": 26937.952217817307, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 848896, "time": 26937.991988897324, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 848992, "time": 26941.00009202957, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 849016, "time": 26941.51681494713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 849232, "time": 26948.376176595688, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 849376, "time": 26952.751801490784, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 849416, "time": 26953.88045144081, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 849496, "time": 26956.325519561768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 849608, "time": 26959.745661258698, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 849680, "time": 26962.1492664814, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 849760, "time": 26964.592897892, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 849904, "time": 26968.971259355545, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 850048, "time": 26973.36704325676, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 850096, "time": 26975.79561138153, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 850096, "time": 26976.474817752838, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 850096, "time": 26977.229264497757, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 850096, "time": 26977.42360520363, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 850096, "time": 26978.203210115433, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 850096, "time": 26979.97291493416, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 850096, "time": 26980.21316576004, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 850096, "time": 26980.851370096207, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 850096, "time": 26980.859746694565, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 850096, "time": 26980.868631601334, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 850096, "time": 26980.87834906578, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 850096, "time": 26980.886565446854, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 850176, "time": 26983.356602430344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 850832, "time": 27003.556636095047, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 851328, "time": 27018.93500828743, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 851544, "time": 27025.34706711769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 851728, "time": 27031.207787513733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 851768, "time": 27032.205995559692, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 851808, "time": 27033.6711332798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 852216, "time": 27046.58020210266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 852360, "time": 27051.051597118378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 852488, "time": 27054.998484373093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 852568, "time": 27057.443181037903, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 852696, "time": 27061.37105178833, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 852864, "time": 27066.736245155334, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 852960, "time": 27069.684893369675, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 853096, "time": 27073.66243839264, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 853144, "time": 27075.215547323227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 853392, "time": 27083.008842229843, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 853416, "time": 27083.52235531807, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 853416, "time": 27083.53102707863, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 853856, "time": 27097.234163045883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 853912, "time": 27098.73883485794, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 853952, "time": 27100.18046927452, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 854120, "time": 27105.19959807396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 854240, "time": 27109.113684415817, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 854272, "time": 27110.091086149216, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 854520, "time": 27117.460104465485, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 854688, "time": 27122.814426898956, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 854696, "time": 27122.84271836281, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 854800, "time": 27126.242911815643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 854848, "time": 27127.72479534149, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 855080, "time": 27134.690845251083, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 855296, "time": 27141.496220350266, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 855360, "time": 27143.468918800354, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 855408, "time": 27144.92879486084, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 855504, "time": 27147.85703587532, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 855512, "time": 27147.886134147644, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 855704, "time": 27153.744687080383, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 855712, "time": 27154.217527151108, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 855768, "time": 27155.704111099243, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 856064, "time": 27165.06643152237, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 856120, "time": 27166.566957473755, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 856208, "time": 27169.454900741577, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 856432, "time": 27176.365442276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 856752, "time": 27186.1334900856, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 856848, "time": 27189.040992498398, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 857112, "time": 27197.01767730713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 857264, "time": 27201.87148785591, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 857432, "time": 27206.76218509674, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 857600, "time": 27212.101694107056, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 857720, "time": 27215.54532456398, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 857784, "time": 27217.50266265869, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 857816, "time": 27218.479489326477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 858080, "time": 27226.957520008087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 858192, "time": 27230.3878800869, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 858296, "time": 27233.330780744553, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 858416, "time": 27237.266114473343, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 858520, "time": 27240.25897717476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 858552, "time": 27241.24968791008, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 858688, "time": 27245.666216373444, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 858816, "time": 27249.56099486351, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 858816, "time": 27249.577550649643, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 859352, "time": 27265.78454399109, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 859440, "time": 27268.676475524902, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 859744, "time": 27277.992120027542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 859744, "time": 27278.00026202202, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 859752, "time": 27278.028967380524, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 859856, "time": 27281.441823720932, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 27289.664353847504, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 860080, "time": 27289.91017651558, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 860080, "time": 27289.982275485992, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 860080, "time": 27291.024524450302, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 860080, "time": 27291.377880096436, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 860080, "time": 27291.58817434311, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 860080, "time": 27292.462944746017, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 860080, "time": 27292.529190778732, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 860081, "time": 27293.132219314575, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.313741455078125, "train/action_min": 0.0, "train/action_std": 1.6851297289133071, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009542902398970909, "train/actor_opt_grad_steps": 52655.0, "train/actor_opt_loss": -7.516027388423681, "train/adv_mag": 0.9002420264482498, "train/adv_max": 0.3030642056465149, "train/adv_mean": 0.001994820928266563, "train/adv_min": -0.8407524585723877, "train/adv_std": 0.03064054430928081, "train/cont_avg": 0.9952783203125, "train/cont_loss_mean": 0.01748120617121458, "train/cont_loss_std": 0.24717164300382138, "train/cont_neg_acc": 0.2884583390504122, "train/cont_neg_loss": 3.015023966729641, "train/cont_pos_acc": 0.9998625805974006, "train/cont_pos_loss": 0.003382944500190206, "train/cont_pred": 0.9953449985384941, "train/cont_rate": 0.9952783203125, "train/dyn_loss_mean": 1.0000005388259887, "train/dyn_loss_std": 1.5669201129639987e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.3336714238859713, "train/extr_critic_critic_opt_grad_steps": 52655.0, "train/extr_critic_critic_opt_loss": 3540.990057373047, "train/extr_critic_mag": 1.2499029588699342, "train/extr_critic_max": 1.2499029588699342, "train/extr_critic_mean": 1.2015356832742692, "train/extr_critic_min": 1.1154300248622895, "train/extr_critic_std": 0.013651126718614251, "train/extr_return_normed_mag": 0.8947821033000946, "train/extr_return_normed_max": 0.3306926369667053, "train/extr_return_normed_mean": 0.033199381385929885, "train/extr_return_normed_min": -0.8236885407567024, "train/extr_return_normed_std": 0.034836680223233996, "train/extr_return_rate": 0.9992549225687981, "train/extr_return_raw_mag": 1.5010237032175064, "train/extr_return_raw_max": 1.5010237032175064, "train/extr_return_raw_mean": 1.2035305124521256, "train/extr_return_raw_min": 0.3466425254940987, "train/extr_return_raw_std": 0.03483668027911335, "train/extr_reward_mag": 0.3516975784301758, "train/extr_reward_max": 0.3516975784301758, "train/extr_reward_mean": 0.0027124182158149777, "train/extr_reward_min": 1.6033649444580078e-07, "train/extr_reward_std": 0.01087717987364158, "train/image_loss_mean": 0.09050985949113965, "train/image_loss_std": 0.1019625324383378, "train/model_loss_mean": 0.7186034217476844, "train/model_loss_std": 0.42222717244178054, "train/model_opt_grad_norm": 17.849045207500456, "train/model_opt_grad_steps": 52607.545, "train/model_opt_loss": 3628.8112829589845, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5050.0, "train/policy_entropy_mag": 1.3457322865724564, "train/policy_entropy_max": 1.3457322865724564, "train/policy_entropy_mean": 0.09899719141423702, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.127594225294888, "train/policy_logprob_mag": 6.551080253124237, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09884357411414385, "train/policy_logprob_min": -6.551080253124237, "train/policy_logprob_std": 0.6373086759448051, "train/policy_randomness_mag": 0.6915696305036545, "train/policy_randomness_max": 0.6915696305036545, "train/policy_randomness_mean": 0.050874494500458244, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06557046445086598, "train/post_ent_mag": 55.74155179977417, "train/post_ent_max": 55.74155179977417, "train/post_ent_mean": 46.88352468490601, "train/post_ent_min": 40.75802421569824, "train/post_ent_std": 3.2466389775276183, "train/prior_ent_mag": 56.60511819839478, "train/prior_ent_max": 56.60511819839478, "train/prior_ent_mean": 47.00615537643433, "train/prior_ent_min": 40.32342241287231, "train/prior_ent_std": 3.1894586062431336, "train/rep_loss_mean": 1.0000005388259887, "train/rep_loss_std": 1.5669201129639987e-05, "train/reward_avg": 0.0013791961636161433, "train/reward_loss_mean": 0.010612008313764819, "train/reward_loss_std": 0.18348027931991964, "train/reward_max_data": 0.6821406220644712, "train/reward_max_pred": 0.17785051345825195, "train/reward_neg_acc": 0.9998189604282379, "train/reward_neg_loss": 0.0017944806725427042, "train/reward_pos_acc": 0.16741573140862281, "train/reward_pos_loss": 4.20437541336156, "train/reward_pred": 0.00106370004999917, "train/reward_rate": 0.00205078125, "train_stats/mean_log_entropy": 0.08163428707255257, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00951855443418026, "report/cont_loss_std": 0.14894412457942963, "report/cont_neg_acc": 0.6000000238418579, "report/cont_neg_loss": 1.3499778509140015, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002941227750852704, "report/cont_pred": 0.9941235184669495, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10551837831735611, "report/image_loss_std": 0.10736127197742462, "report/model_loss_mean": 0.7253975868225098, "report/model_loss_std": 0.3717235028743744, "report/post_ent_mag": 58.704254150390625, "report/post_ent_max": 58.704254150390625, "report/post_ent_mean": 47.72529602050781, "report/post_ent_min": 39.519832611083984, "report/post_ent_std": 4.374067783355713, "report/prior_ent_mag": 56.7692985534668, "report/prior_ent_max": 56.7692985534668, "report/prior_ent_mean": 46.46977996826172, "report/prior_ent_min": 39.62149429321289, "report/prior_ent_std": 3.508103609085083, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0013885498046875, "report/reward_loss_mean": 0.010360630229115486, "report/reward_loss_std": 0.192323237657547, "report/reward_max_data": 0.765625, "report/reward_max_pred": 0.04871988296508789, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0018636552849784493, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.3523149490356445, "report/reward_pred": 0.0009835491655394435, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02392292022705078, "eval/cont_loss_std": 0.4115525484085083, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.120926856994629, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003069825004786253, "eval/cont_pred": 0.9969778060913086, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.14866119623184204, "eval/image_loss_std": 0.14288261532783508, "eval/model_loss_mean": 0.7881536483764648, "eval/model_loss_std": 0.7565447688102722, "eval/post_ent_mag": 59.075801849365234, "eval/post_ent_max": 59.075801849365234, "eval/post_ent_mean": 47.99302673339844, "eval/post_ent_min": 38.78382873535156, "eval/post_ent_std": 4.761684894561768, "eval/prior_ent_mag": 56.7692985534668, "eval/prior_ent_max": 56.7692985534668, "eval/prior_ent_mean": 46.7930908203125, "eval/prior_ent_min": 39.73143768310547, "eval/prior_ent_std": 3.7115061283111572, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0012481689918786287, "eval/reward_loss_mean": 0.015569522976875305, "eval/reward_loss_std": 0.3371984362602234, "eval/reward_max_data": 0.715624988079071, "eval/reward_max_pred": 0.029129981994628906, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0012669282732531428, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.324195861816406, "eval/reward_pred": 0.000645320862531662, "eval/reward_rate": 0.001953125, "replay/size": 859577.0, "replay/inserts": 32104.0, "replay/samples": 32096.0, "replay/insert_wait_avg": 1.341869431245425e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.492470521632125e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5616.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1893758746633502e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1003.935818195343, "timer/env.step_count": 4013.0, "timer/env.step_total": 39.70506453514099, "timer/env.step_frac": 0.039549405266278974, "timer/env.step_avg": 0.009894110275390229, "timer/env.step_min": 0.007951498031616211, "timer/env.step_max": 0.052497148513793945, "timer/replay._sample_count": 32096.0, "timer/replay._sample_total": 17.638351678848267, "timer/replay._sample_frac": 0.017569202492002577, "timer/replay._sample_avg": 0.0005495498404426803, "timer/replay._sample_min": 0.0003535747528076172, "timer/replay._sample_max": 0.011127948760986328, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4715.0, "timer/agent.policy_total": 51.61017870903015, "timer/agent.policy_frac": 0.051407846770328086, "timer/agent.policy_avg": 0.01094595518749314, "timer/agent.policy_min": 0.009217500686645508, "timer/agent.policy_max": 0.10412263870239258, "timer/dataset_train_count": 2006.0, "timer/dataset_train_total": 0.2600080966949463, "timer/dataset_train_frac": 0.00025898876400518527, "timer/dataset_train_avg": 0.00012961520273925537, "timer/dataset_train_min": 0.00010180473327636719, "timer/dataset_train_max": 0.024875879287719727, "timer/agent.train_count": 2006.0, "timer/agent.train_total": 898.6306211948395, "timer/agent.train_frac": 0.8951076402575233, "timer/agent.train_avg": 0.44797139640819517, "timer/agent.train_min": 0.43463706970214844, "timer/agent.train_max": 0.6691336631774902, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5181024074554443, "timer/agent.report_frac": 0.0005160712448598317, "timer/agent.report_avg": 0.25905120372772217, "timer/agent.report_min": 0.2548196315765381, "timer/agent.report_max": 0.26328277587890625, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9448001827185818e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 31.977589741783788}
{"step": 860296, "time": 27300.254153966904, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 860328, "time": 27301.237791776657, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 860328, "time": 27301.247794628143, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 860408, "time": 27303.711617946625, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 860728, "time": 27313.635151147842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 861192, "time": 27327.9776597023, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 861280, "time": 27330.911212682724, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 861448, "time": 27335.827993154526, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 861520, "time": 27338.24769806862, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 861696, "time": 27343.667445659637, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 861856, "time": 27348.653134822845, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 861912, "time": 27350.185100317, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 862056, "time": 27354.58966445923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 862056, "time": 27354.597878217697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 862064, "time": 27355.07214832306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 862200, "time": 27359.020441055298, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 862328, "time": 27362.926630973816, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 862640, "time": 27372.743861675262, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 862728, "time": 27375.34689116478, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 862800, "time": 27377.762334108353, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 862856, "time": 27379.258564710617, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 862944, "time": 27382.172092437744, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 863040, "time": 27385.12527489662, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 863328, "time": 27393.94966006279, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 863504, "time": 27399.311755895615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 863616, "time": 27402.724336624146, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 863704, "time": 27405.30581521988, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 863832, "time": 27409.222722053528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 863992, "time": 27414.156763792038, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 864712, "time": 27436.364804029465, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 864776, "time": 27438.324805498123, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 865112, "time": 27448.61160159111, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 865176, "time": 27450.568566322327, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 865224, "time": 27452.03592133522, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 865256, "time": 27453.024357557297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 865352, "time": 27455.940613269806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 865640, "time": 27464.823823928833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 865752, "time": 27468.258645296097, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 865936, "time": 27474.112334012985, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 865960, "time": 27474.631803750992, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 866080, "time": 27478.531733989716, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 866104, "time": 27479.044863700867, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 866152, "time": 27480.502932071686, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 866160, "time": 27480.9749917984, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 866352, "time": 27486.856295585632, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 866664, "time": 27496.242792844772, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 866672, "time": 27496.732428073883, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 866856, "time": 27502.160155773163, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 867016, "time": 27507.092307806015, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 867088, "time": 27509.527384519577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 867144, "time": 27511.042439460754, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 867320, "time": 27516.450055599213, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 867328, "time": 27516.922394752502, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 867424, "time": 27519.85436320305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 867656, "time": 27526.843905210495, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 867712, "time": 27528.768223285675, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 867896, "time": 27534.17441391945, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 868184, "time": 27543.00699853897, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 868200, "time": 27543.499415159225, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 868248, "time": 27544.968953609467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 868400, "time": 27550.34446167946, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 868912, "time": 27566.099621534348, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 869456, "time": 27582.748255252838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 869640, "time": 27588.25037765503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870024, "time": 27599.988206148148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870064, "time": 27602.18101501465, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 870064, "time": 27603.095586061478, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 870064, "time": 27604.34986925125, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 870064, "time": 27604.417467355728, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 870064, "time": 27606.209347963333, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 870064, "time": 27607.402561903, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 27607.41206216812, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 27607.421164035797, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 27607.431636810303, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870208, "time": 27611.90369796753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870208, "time": 27611.912559986115, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 870512, "time": 27621.390374422073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870560, "time": 27622.850656986237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 871224, "time": 27642.91485452652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 871544, "time": 27652.83605313301, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 871672, "time": 27656.790625333786, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 871736, "time": 27658.73902440071, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 871768, "time": 27659.722614765167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 871952, "time": 27665.623379468918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 871992, "time": 27666.622686624527, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 872064, "time": 27669.04586315155, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 872336, "time": 27677.48657488823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 872576, "time": 27684.79336619377, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 872760, "time": 27690.19478750229, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 872872, "time": 27693.61601138115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 873032, "time": 27698.5042283535, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 873040, "time": 27698.974196195602, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 873240, "time": 27705.025257349014, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 873536, "time": 27714.282073020935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 873648, "time": 27717.701720952988, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 873808, "time": 27722.585110902786, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 873928, "time": 27726.04977965355, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 873960, "time": 27727.025592803955, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 874064, "time": 27730.451110839844, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 874280, "time": 27736.963672161102, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 874304, "time": 27737.9201772213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 874440, "time": 27741.857822179794, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 874704, "time": 27750.167465925217, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 874904, "time": 27756.08307981491, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 874944, "time": 27757.526156663895, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 875152, "time": 27764.04044008255, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 875152, "time": 27764.049144744873, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 875344, "time": 27769.913350105286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 875368, "time": 27770.428560256958, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 875408, "time": 27771.888051748276, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 875664, "time": 27779.73538994789, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 875960, "time": 27788.626267194748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 876128, "time": 27794.112725257874, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 876168, "time": 27795.110596895218, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 876232, "time": 27797.071882009506, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 876240, "time": 27797.546014785767, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 876272, "time": 27798.552106380463, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 876384, "time": 27801.963136672974, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 876472, "time": 27804.457515478134, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 876504, "time": 27805.442531347275, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 876536, "time": 27806.42121696472, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 876728, "time": 27812.869695663452, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 877000, "time": 27821.170038700104, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 877240, "time": 27828.659741163254, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 877424, "time": 27834.498881340027, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 877984, "time": 27851.580864667892, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 878024, "time": 27852.577521800995, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 878024, "time": 27852.586360692978, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 878440, "time": 27865.43632888794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 878480, "time": 27866.889272212982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 878600, "time": 27870.388550043106, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 878784, "time": 27876.279824256897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 878848, "time": 27878.258139371872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 878864, "time": 27878.752242803574, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 879040, "time": 27884.217799901962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 879192, "time": 27888.630916833878, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 879264, "time": 27891.04674887657, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 879280, "time": 27891.541425466537, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 879592, "time": 27900.922096014023, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 879688, "time": 27903.885981798172, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 879768, "time": 27906.31937479973, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 879840, "time": 27908.76857328415, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 27916.660667181015, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 880048, "time": 27916.688362121582, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 880048, "time": 27916.864102602005, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 880048, "time": 27917.575877428055, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 880048, "time": 27917.858553409576, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 880048, "time": 27918.73363685608, "eval_episode/length": 164.0, "eval_episode/score": 0.48750001192092896, "eval_episode/reward_rate": 0.006060606060606061}
{"step": 880048, "time": 27918.843960285187, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 880048, "time": 27919.167154312134, "eval_episode/length": 185.0, "eval_episode/score": 0.421875, "eval_episode/reward_rate": 0.005376344086021506}
{"step": 880072, "time": 27919.681946516037, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 880296, "time": 27926.517246484756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 880384, "time": 27929.42495584488, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 880624, "time": 27936.77381849289, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 880768, "time": 27941.180512666702, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 880840, "time": 27943.153176784515, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 880856, "time": 27943.710443735123, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 881000, "time": 27948.18716788292, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 881096, "time": 27951.148777246475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 881240, "time": 27955.5818464756, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 881360, "time": 27959.471811056137, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 881376, "time": 27959.96769309044, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 881400, "time": 27960.51274561882, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 881432, "time": 27961.497829914093, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 881560, "time": 27965.439395427704, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 881720, "time": 27970.3330347538, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 881800, "time": 27972.799950122833, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 881872, "time": 27975.357654571533, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 881912, "time": 27976.36012649536, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 881984, "time": 27978.775948762894, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 882144, "time": 27983.6806371212, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 882384, "time": 27991.020785570145, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 882384, "time": 27991.029646635056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 882400, "time": 27991.52841114998, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 882600, "time": 27997.431978464127, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 882760, "time": 28002.368137836456, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 883120, "time": 28013.770416498184, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 883352, "time": 28020.690658569336, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 883408, "time": 28022.641638040543, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 883688, "time": 28031.009511470795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 884032, "time": 28041.931753396988, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 884184, "time": 28046.366896390915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 884192, "time": 28046.840173006058, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 884224, "time": 28047.825559854507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 884320, "time": 28050.77593445778, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 884344, "time": 28051.291231393814, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 884912, "time": 28069.64104294777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 884952, "time": 28070.64644551277, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 885008, "time": 28072.57942008972, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 885072, "time": 28074.559804916382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 885136, "time": 28076.50464987755, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 885264, "time": 28080.42242717743, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 885360, "time": 28083.356427431107, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 885376, "time": 28083.85552382469, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 885408, "time": 28084.8610162735, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 885752, "time": 28095.33834338188, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 885856, "time": 28098.729092359543, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 886096, "time": 28106.0717086792, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 886216, "time": 28109.537014245987, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 886488, "time": 28117.876219034195, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 886496, "time": 28118.34994983673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 886632, "time": 28122.31015062332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 886704, "time": 28124.886345148087, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 887072, "time": 28136.14511656761, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 887104, "time": 28137.12109398842, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 887288, "time": 28142.50824189186, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 887296, "time": 28142.97929596901, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 887320, "time": 28143.515080928802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 887488, "time": 28148.91233730316, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 887760, "time": 28157.35543704033, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 887824, "time": 28159.34520959854, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 887896, "time": 28161.31600666046, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 887952, "time": 28163.26890850067, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 888168, "time": 28169.627593278885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 888368, "time": 28175.97345161438, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 888528, "time": 28180.869161605835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 888664, "time": 28184.92950773239, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 888680, "time": 28185.41973567009, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 888800, "time": 28189.297389268875, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 889064, "time": 28197.10333442688, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 889336, "time": 28205.422693014145, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 889408, "time": 28207.862852573395, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 889416, "time": 28207.89240527153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 889592, "time": 28213.268459796906, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 889600, "time": 28213.81144952774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 889848, "time": 28221.217893362045, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 890032, "time": 28228.128088474274, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 890032, "time": 28228.138656377792, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 890032, "time": 28228.98286128044, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 890032, "time": 28229.010935544968, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 890032, "time": 28229.460796117783, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 890032, "time": 28229.778774499893, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 890032, "time": 28229.97452378273, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 890032, "time": 28230.07980298996, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 890208, "time": 28235.496322870255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 890328, "time": 28238.913327217102, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 890336, "time": 28239.389775514603, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 890368, "time": 28240.394350528717, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 890584, "time": 28246.8874437809, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 890864, "time": 28255.746504068375, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 890952, "time": 28258.251496076584, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 890992, "time": 28259.716896295547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 891224, "time": 28266.549863815308, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 891376, "time": 28271.43066072464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 891464, "time": 28274.059176921844, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 891552, "time": 28277.02565741539, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 891584, "time": 28278.01682162285, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 891720, "time": 28281.963544607162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 891792, "time": 28284.4017868042, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 892057, "time": 28293.293644189835, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2524264526367186, "train/action_min": 0.0, "train/action_std": 1.5407710921764375, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012799929120810703, "train/actor_opt_grad_steps": 54655.0, "train/actor_opt_loss": -7.715545041188598, "train/adv_mag": 1.0041755506396293, "train/adv_max": 0.3180170613527298, "train/adv_mean": 0.002769473191569887, "train/adv_min": -0.9737587884068489, "train/adv_std": 0.03850829283706844, "train/cont_avg": 0.995107421875, "train/cont_loss_mean": 0.017885995035758242, "train/cont_loss_std": 0.24728327858028934, "train/cont_neg_acc": 0.29322421219199896, "train/cont_neg_loss": 2.981850092205859, "train/cont_pos_acc": 0.9998920968174935, "train/cont_pos_loss": 0.0034165891364682467, "train/cont_pred": 0.9952171644568444, "train/cont_rate": 0.995107421875, "train/dyn_loss_mean": 1.0000025129318237, "train/dyn_loss_std": 8.039649241254664e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.46347516149282453, "train/extr_critic_critic_opt_grad_steps": 54655.0, "train/extr_critic_critic_opt_loss": 7327.435001220703, "train/extr_critic_mag": 1.3184608781337739, "train/extr_critic_max": 1.3184608781337739, "train/extr_critic_mean": 1.241696566939354, "train/extr_critic_min": 1.1346193313598634, "train/extr_critic_std": 0.01783783034654334, "train/extr_return_normed_mag": 0.9915938472747803, "train/extr_return_normed_max": 0.3503331971168518, "train/extr_return_normed_mean": 0.038628789433278146, "train/extr_return_normed_min": -0.9480815541744232, "train/extr_return_normed_std": 0.043590547554194926, "train/extr_return_rate": 0.9990208771824837, "train/extr_return_raw_mag": 1.5561704069375992, "train/extr_return_raw_max": 1.5561704069375992, "train/extr_return_raw_mean": 1.2444660568237305, "train/extr_return_raw_min": 0.25775565564632413, "train/extr_return_raw_std": 0.04359054753556848, "train/extr_reward_mag": 0.3718566799163818, "train/extr_reward_max": 0.3718566799163818, "train/extr_reward_mean": 0.003232999847386964, "train/extr_reward_min": 1.895427703857422e-07, "train/extr_reward_std": 0.013978078672662377, "train/image_loss_mean": 0.0886984147131443, "train/image_loss_std": 0.1010770883783698, "train/model_loss_mean": 0.7180774715542794, "train/model_loss_std": 0.4349429784715176, "train/model_opt_grad_norm": 18.157527170181275, "train/model_opt_grad_steps": 54605.595, "train/model_opt_loss": 3715.990997314453, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5175.0, "train/policy_entropy_mag": 1.288209899663925, "train/policy_entropy_max": 1.288209899663925, "train/policy_entropy_mean": 0.10806208215653897, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13894786931574343, "train/policy_logprob_mag": 6.551080241203308, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10799524165689946, "train/policy_logprob_min": -6.551080241203308, "train/policy_logprob_std": 0.6449613577127457, "train/policy_randomness_mag": 0.6620089688897133, "train/policy_randomness_max": 0.6620089688897133, "train/policy_randomness_mean": 0.05553292721509934, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07140508364886046, "train/post_ent_mag": 57.50670530319214, "train/post_ent_max": 57.50670530319214, "train/post_ent_mean": 47.66361585617065, "train/post_ent_min": 40.732725296020504, "train/post_ent_std": 3.678453576564789, "train/prior_ent_mag": 58.60513807296753, "train/prior_ent_max": 58.60513807296753, "train/prior_ent_mean": 47.55101442337036, "train/prior_ent_min": 40.50298309326172, "train/prior_ent_std": 3.613403571844101, "train/rep_loss_mean": 1.0000025129318237, "train/rep_loss_std": 8.039649241254664e-05, "train/reward_avg": 0.0015064849876216613, "train/reward_loss_mean": 0.011491530771600082, "train/reward_loss_std": 0.19526693829568104, "train/reward_max_data": 0.6960312509536744, "train/reward_max_pred": 0.1454666692018509, "train/reward_neg_acc": 0.999838510453701, "train/reward_neg_loss": 0.0019138121273135765, "train/reward_pos_acc": 0.1247222234805425, "train/reward_pos_loss": 4.397228312161234, "train/reward_pred": 0.0011182626843219622, "train/reward_rate": 0.0021826171875, "train_stats/mean_log_entropy": 0.0923818440974823, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.006754995323717594, "report/cont_loss_std": 0.10645990818738937, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.0650475025177002, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0026048277504742146, "report/cont_pred": 0.9950925707817078, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09610261023044586, "report/image_loss_std": 0.10420975089073181, "report/model_loss_mean": 0.710601270198822, "report/model_loss_std": 0.28822675347328186, "report/post_ent_mag": 54.53559875488281, "report/post_ent_max": 54.53559875488281, "report/post_ent_mean": 44.5081672668457, "report/post_ent_min": 38.325416564941406, "report/post_ent_std": 3.3454761505126953, "report/prior_ent_mag": 58.568885803222656, "report/prior_ent_max": 58.568885803222656, "report/prior_ent_mean": 46.210731506347656, "report/prior_ent_min": 39.73115539550781, "report/prior_ent_std": 3.6351799964904785, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0015228271950036287, "report/reward_loss_mean": 0.007743643596768379, "report/reward_loss_std": 0.14473971724510193, "report/reward_max_data": 0.815625011920929, "report/reward_max_pred": 0.17359554767608643, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0016830615932121873, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 3.104701042175293, "report/reward_pred": 0.001060261856764555, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014713476411998272, "eval/cont_loss_std": 0.2655438184738159, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.643442153930664, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003698353422805667, "eval/cont_pred": 0.9963349103927612, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13693779706954956, "eval/image_loss_std": 0.12380725890398026, "eval/model_loss_mean": 0.7617522478103638, "eval/model_loss_std": 0.5492811799049377, "eval/post_ent_mag": 54.53571319580078, "eval/post_ent_max": 54.53571319580078, "eval/post_ent_mean": 45.113128662109375, "eval/post_ent_min": 38.15802764892578, "eval/post_ent_std": 3.734870672225952, "eval/prior_ent_mag": 58.777503967285156, "eval/prior_ent_max": 58.777503967285156, "eval/prior_ent_mean": 46.90594482421875, "eval/prior_ent_min": 38.96998596191406, "eval/prior_ent_std": 4.193552017211914, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008728027460165322, "eval/reward_loss_mean": 0.01010090857744217, "eval/reward_loss_std": 0.27030378580093384, "eval/reward_max_data": 0.893750011920929, "eval/reward_max_pred": 0.02692282199859619, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0016518906923010945, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.653447151184082, "eval/reward_pred": 0.0008718622848391533, "eval/reward_rate": 0.0009765625, "replay/size": 891553.0, "replay/inserts": 31976.0, "replay/samples": 31984.0, "replay/insert_wait_avg": 1.3718537637702458e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.587357913690427e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5000.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.177835464477539e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2367963790893555e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1447284221649, "timer/env.step_count": 3997.0, "timer/env.step_total": 40.02937436103821, "timer/env.step_frac": 0.04002358181119329, "timer/env.step_avg": 0.010014854731308033, "timer/env.step_min": 0.008037090301513672, "timer/env.step_max": 0.04913949966430664, "timer/replay._sample_count": 31984.0, "timer/replay._sample_total": 17.577703714370728, "timer/replay._sample_frac": 0.017575160089181724, "timer/replay._sample_avg": 0.0005495780300891298, "timer/replay._sample_min": 0.00038886070251464844, "timer/replay._sample_max": 0.02382946014404297, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4622.0, "timer/agent.policy_total": 50.39622473716736, "timer/agent.policy_frac": 0.05038893202654058, "timer/agent.policy_avg": 0.010903553599560224, "timer/agent.policy_min": 0.00938725471496582, "timer/agent.policy_max": 0.13291478157043457, "timer/dataset_train_count": 1999.0, "timer/dataset_train_total": 0.2366478443145752, "timer/dataset_train_frac": 0.0002366135996016421, "timer/dataset_train_avg": 0.00011838311371414468, "timer/dataset_train_min": 0.00010251998901367188, "timer/dataset_train_max": 0.001085042953491211, "timer/agent.train_count": 1999.0, "timer/agent.train_total": 896.8227126598358, "timer/agent.train_frac": 0.8966929357060847, "timer/agent.train_avg": 0.4486356741670014, "timer/agent.train_min": 0.436814546585083, "timer/agent.train_max": 0.7308664321899414, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5246689319610596, "timer/agent.report_frac": 0.0005245930084426689, "timer/agent.report_avg": 0.2623344659805298, "timer/agent.report_min": 0.2609255313873291, "timer/agent.report_max": 0.26374340057373047, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8129321221707386e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 31.97075392160624}
{"step": 892216, "time": 28297.960408210754, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 892280, "time": 28299.953615427017, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 892320, "time": 28301.40744996071, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 892352, "time": 28302.392745018005, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 892648, "time": 28311.360609531403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 892848, "time": 28317.68778347969, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 892920, "time": 28319.681552410126, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 893024, "time": 28323.607380390167, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 893360, "time": 28334.002634048462, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 893688, "time": 28343.8104865551, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 893752, "time": 28345.792682409286, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 894168, "time": 28358.476395130157, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 894328, "time": 28363.36096572876, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 894400, "time": 28365.93541622162, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 894528, "time": 28369.84146475792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 894592, "time": 28371.795827150345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 894664, "time": 28373.77610373497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 894872, "time": 28380.143108844757, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 894960, "time": 28383.05904150009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 895000, "time": 28384.079701185226, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 895152, "time": 28388.93718600273, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 895160, "time": 28388.970227479935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 895208, "time": 28390.440969944, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 895208, "time": 28390.451508522034, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 895264, "time": 28392.3929977417, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 895752, "time": 28407.092742681503, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 895824, "time": 28409.542087078094, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 896104, "time": 28417.854578495026, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 896272, "time": 28423.210000753403, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 896576, "time": 28432.56111884117, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 896712, "time": 28436.487503528595, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 896832, "time": 28440.350881814957, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 897048, "time": 28446.686838150024, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 897272, "time": 28453.46824336052, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 897312, "time": 28455.036649227142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 897368, "time": 28456.508897542953, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 897448, "time": 28458.94906258583, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 897472, "time": 28459.922205209732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 897944, "time": 28474.090442180634, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 898024, "time": 28476.52651166916, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 898064, "time": 28477.986313581467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 898136, "time": 28479.958632946014, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 898152, "time": 28480.46053814888, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 898296, "time": 28485.050170898438, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 898448, "time": 28489.942903280258, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 898512, "time": 28491.915521860123, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 899024, "time": 28507.529820919037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 899096, "time": 28509.49494791031, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 899176, "time": 28511.968019485474, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 899568, "time": 28524.219952106476, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 899696, "time": 28528.10956096649, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 899704, "time": 28528.136132717133, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 899760, "time": 28530.063291072845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 899984, "time": 28536.874399900436, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 900016, "time": 28538.931149482727, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 900016, "time": 28539.019302606583, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 900016, "time": 28540.112947702408, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 900016, "time": 28540.180324792862, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 900016, "time": 28540.331136465073, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 900016, "time": 28540.668195724487, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 900016, "time": 28541.06409215927, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 900016, "time": 28541.230367183685, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 900200, "time": 28546.75439786911, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 900216, "time": 28547.25247836113, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 900256, "time": 28548.701612472534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 900408, "time": 28553.142076730728, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 900464, "time": 28555.081705093384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 900648, "time": 28560.47229743004, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 900760, "time": 28563.906577587128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 900824, "time": 28565.8610394001, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 900928, "time": 28569.25806903839, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 901152, "time": 28576.683611631393, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 901208, "time": 28578.168801784515, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 901336, "time": 28582.074323177338, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 901352, "time": 28582.564952611923, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 901672, "time": 28592.32049012184, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 901736, "time": 28594.28638625145, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 901768, "time": 28595.263996839523, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 901848, "time": 28597.710793733597, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 901952, "time": 28601.179796218872, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 902240, "time": 28610.137947797775, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 902296, "time": 28611.636834859848, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 902328, "time": 28612.619475126266, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 902344, "time": 28613.110426187515, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 902512, "time": 28618.51004052162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 902680, "time": 28623.436371564865, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 902792, "time": 28626.836925029755, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 903120, "time": 28637.19136404991, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 903264, "time": 28641.573168992996, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 903344, "time": 28644.017871141434, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 903360, "time": 28644.50593161583, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 903600, "time": 28651.80354833603, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 903648, "time": 28653.28503727913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 903896, "time": 28660.620832681656, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 903984, "time": 28663.539333581924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 903984, "time": 28663.547870874405, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 904360, "time": 28674.968467235565, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 904496, "time": 28679.372444152832, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 904560, "time": 28681.32858324051, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 904808, "time": 28688.727758407593, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 904856, "time": 28690.20908856392, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 904992, "time": 28694.736570835114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 905288, "time": 28703.553831100464, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 905312, "time": 28704.521078824997, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 905440, "time": 28708.44476699829, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 905544, "time": 28711.44505596161, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 905648, "time": 28714.887892007828, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 905656, "time": 28714.917323589325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 905672, "time": 28715.413227558136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 905824, "time": 28720.29487967491, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 905864, "time": 28721.289762735367, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 905912, "time": 28722.779255867004, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 906096, "time": 28728.66361951828, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 906232, "time": 28732.591491937637, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 906424, "time": 28738.452127456665, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 906456, "time": 28739.4258749485, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 906456, "time": 28739.43479847908, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 906672, "time": 28746.254793405533, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 906976, "time": 28755.555566310883, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 907000, "time": 28756.084232330322, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 907104, "time": 28759.457870960236, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 907304, "time": 28765.302806854248, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 907488, "time": 28771.144930124283, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 907600, "time": 28774.548193454742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 907632, "time": 28775.551833868027, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 907696, "time": 28777.49633359909, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 907960, "time": 28785.524727106094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 907976, "time": 28786.019174575806, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 908224, "time": 28793.774155139923, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 908384, "time": 28798.653834342957, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 908512, "time": 28802.567708969116, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 908544, "time": 28803.54976582527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 908696, "time": 28807.987550973892, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 908768, "time": 28810.423095226288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 908824, "time": 28811.92262005806, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 908992, "time": 28817.46744298935, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 909304, "time": 28826.75467300415, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 909352, "time": 28828.70245575905, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 909432, "time": 28831.148141384125, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 909544, "time": 28834.54287481308, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 909632, "time": 28837.457502126694, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 909704, "time": 28839.432679653168, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 909800, "time": 28842.370692014694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 910000, "time": 28850.719296693802, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 910000, "time": 28850.976539373398, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 910000, "time": 28851.098452329636, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 910000, "time": 28851.220701932907, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 910000, "time": 28851.330662965775, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 910000, "time": 28851.609025001526, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 910000, "time": 28852.027626037598, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 910000, "time": 28852.6722741127, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 910176, "time": 28858.036983966827, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 910232, "time": 28859.53301382065, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 910288, "time": 28861.462515115738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 910352, "time": 28863.445739269257, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 910792, "time": 28876.859194517136, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 910792, "time": 28876.868495225906, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 910984, "time": 28882.695187330246, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 911168, "time": 28888.545562028885, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 911224, "time": 28890.033393859863, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 911328, "time": 28893.436836481094, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 911536, "time": 28899.808154821396, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 911640, "time": 28902.78842639923, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 911664, "time": 28903.81022286415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 911744, "time": 28906.297773122787, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 911744, "time": 28906.306676626205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 911856, "time": 28909.73720598221, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 912000, "time": 28914.147873401642, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 912456, "time": 28927.87766289711, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 912488, "time": 28928.8521566391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 912512, "time": 28929.813722372055, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 912640, "time": 28933.798465013504, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 912880, "time": 28941.188683986664, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 912896, "time": 28941.683685541153, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 913032, "time": 28945.630751132965, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 913096, "time": 28947.602675676346, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 913232, "time": 28951.99367904663, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 913368, "time": 28955.906597852707, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 913680, "time": 28965.75082373619, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 913752, "time": 28967.73694562912, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 913776, "time": 28968.69400215149, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 913952, "time": 28974.085840940475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 914008, "time": 28975.57564806938, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 914128, "time": 28979.47420978546, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 914312, "time": 28984.84063744545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 914368, "time": 28986.780374765396, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 914392, "time": 28987.300389051437, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 914400, "time": 28987.775091409683, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 914712, "time": 28997.201800107956, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 914808, "time": 29000.140449285507, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 914872, "time": 29002.12206840515, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 914896, "time": 29003.08884716034, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 915024, "time": 29007.02562069893, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 915192, "time": 29011.937547445297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 915272, "time": 29014.37120938301, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 915432, "time": 29019.23202753067, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 915536, "time": 29022.629348516464, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 915664, "time": 29026.638556480408, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 915792, "time": 29030.552327632904, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 915840, "time": 29032.025790691376, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 916000, "time": 29036.94130897522, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 916400, "time": 29049.15806055069, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 916440, "time": 29050.178914546967, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 916464, "time": 29051.13818192482, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 917024, "time": 29068.427879810333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 917096, "time": 29070.42418718338, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 917120, "time": 29071.379049777985, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 917184, "time": 29073.341812610626, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 917504, "time": 29083.24195456505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 917504, "time": 29083.284244298935, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 917584, "time": 29086.26378107071, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 917784, "time": 29092.15633225441, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 917824, "time": 29093.59289741516, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 917968, "time": 29098.00149178505, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 918120, "time": 29102.45293903351, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 918152, "time": 29103.45201444626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 918200, "time": 29104.96041727066, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 918352, "time": 29109.869374990463, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 918520, "time": 29114.907804727554, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 918592, "time": 29117.33386850357, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 918688, "time": 29120.287044763565, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 918736, "time": 29121.748012304306, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 918920, "time": 29127.138215780258, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 918928, "time": 29127.610314130783, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 918944, "time": 29128.111969947815, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 918992, "time": 29129.625207424164, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 919328, "time": 29139.875343561172, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 919384, "time": 29141.377106904984, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 919392, "time": 29141.850038290024, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 919448, "time": 29143.34474849701, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 919896, "time": 29157.178649187088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 919992, "time": 29160.121736764908, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 920088, "time": 29164.715702295303, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 920088, "time": 29165.05332303047, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 920088, "time": 29165.269600629807, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 920088, "time": 29165.477355241776, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 920088, "time": 29165.744581222534, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 920088, "time": 29165.86920952797, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 920088, "time": 29166.870557546616, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 920088, "time": 29167.069927930832, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 920152, "time": 29169.039266347885, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 920216, "time": 29170.988414525986, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 920288, "time": 29173.4275765419, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 920536, "time": 29180.959330797195, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 920568, "time": 29181.943552017212, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 920624, "time": 29183.900491952896, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 920664, "time": 29184.910566091537, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 920720, "time": 29186.855912685394, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 921008, "time": 29195.748562335968, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 921048, "time": 29196.776517629623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 921120, "time": 29199.25031733513, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 921224, "time": 29202.244361162186, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 921232, "time": 29202.73903799057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 921272, "time": 29203.770522594452, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 921488, "time": 29210.613520860672, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 921704, "time": 29216.93612408638, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 921768, "time": 29218.891664266586, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 922096, "time": 29229.159066438675, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 922168, "time": 29231.130423069, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 922400, "time": 29238.565439224243, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 922720, "time": 29248.319867134094, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 922880, "time": 29253.19240808487, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 923032, "time": 29257.63622570038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 923168, "time": 29262.0083360672, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 923320, "time": 29266.547773122787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 923536, "time": 29273.331973791122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 923544, "time": 29273.36102795601, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 923584, "time": 29274.804595708847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 923768, "time": 29280.194487571716, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 924088, "time": 29289.943694353104, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 924120, "time": 29290.939233779907, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 924144, "time": 29291.897766828537, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 924160, "time": 29292.398689508438, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 924169, "time": 29293.46330165863, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2384980614505596, "train/action_min": 0.0, "train/action_std": 1.6309682504454655, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012118826721058185, "train/actor_opt_grad_steps": 56660.0, "train/actor_opt_loss": -9.57334415584951, "train/adv_mag": 0.9927923370949665, "train/adv_max": 0.3412785891869768, "train/adv_mean": 0.002665615956759021, "train/adv_min": -0.9497050758618027, "train/adv_std": 0.03436583068583216, "train/cont_avg": 0.9949082711442786, "train/cont_loss_mean": 0.01802368403704309, "train/cont_loss_std": 0.23979414307248237, "train/cont_neg_acc": 0.30739556805263113, "train/cont_neg_loss": 2.8052620834633895, "train/cont_pos_acc": 0.9998974387918539, "train/cont_pos_loss": 0.0035688322951405575, "train/cont_pred": 0.9949771667001259, "train/cont_rate": 0.9949082711442786, "train/dyn_loss_mean": 1.0000048674161162, "train/dyn_loss_std": 0.0001214086078107357, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.29795271869915635, "train/extr_critic_critic_opt_grad_steps": 56660.0, "train/extr_critic_critic_opt_loss": 10231.310860249534, "train/extr_critic_mag": 1.3637878740604836, "train/extr_critic_max": 1.3637878740604836, "train/extr_critic_mean": 1.277653261203671, "train/extr_critic_min": 1.1618542552587405, "train/extr_critic_std": 0.018053582609997162, "train/extr_return_normed_mag": 0.9880821948027729, "train/extr_return_normed_max": 0.3874732024634062, "train/extr_return_normed_mean": 0.039710367121617886, "train/extr_return_normed_min": -0.927646447770038, "train/extr_return_normed_std": 0.03965556134113032, "train/extr_return_rate": 0.9994166964915261, "train/extr_return_raw_mag": 1.6280816882403928, "train/extr_return_raw_max": 1.6280816882403928, "train/extr_return_raw_mean": 1.2803189321536923, "train/extr_return_raw_min": 0.3129620380069486, "train/extr_return_raw_std": 0.03965556148013369, "train/extr_reward_mag": 0.39834742581666405, "train/extr_reward_max": 0.39834742581666405, "train/extr_reward_mean": 0.002940714478015492, "train/extr_reward_min": 2.657003070584577e-07, "train/extr_reward_std": 0.012062829434964343, "train/image_loss_mean": 0.08803839846259326, "train/image_loss_std": 0.10220058751640035, "train/model_loss_mean": 0.7186824818748739, "train/model_loss_std": 0.442760457372784, "train/model_opt_grad_norm": 17.245550837516785, "train/model_opt_grad_steps": 56608.706467661694, "train/model_opt_loss": 3787.659367955146, "train/model_opt_model_opt_grad_overflow": 0.004975124378109453, "train/model_opt_model_opt_grad_scale": 5273.63184079602, "train/policy_entropy_mag": 1.2914918097690564, "train/policy_entropy_max": 1.2914918097690564, "train/policy_entropy_mean": 0.09841893587391175, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12369135085178252, "train/policy_logprob_mag": 6.551080250621435, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09803467444074687, "train/policy_logprob_min": -6.551080250621435, "train/policy_logprob_std": 0.6343271782742211, "train/policy_randomness_mag": 0.6636955373322786, "train/policy_randomness_max": 0.6636955373322786, "train/policy_randomness_mean": 0.0505773303705958, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06356478376842256, "train/post_ent_mag": 57.83037071797385, "train/post_ent_max": 57.83037071797385, "train/post_ent_mean": 47.77949861744743, "train/post_ent_min": 40.68736071610332, "train/post_ent_std": 3.7768828157168715, "train/prior_ent_mag": 58.74995577987747, "train/prior_ent_max": 58.74995577987747, "train/prior_ent_mean": 47.99828023578397, "train/prior_ent_min": 40.572905070746124, "train/prior_ent_std": 3.792358575175651, "train/rep_loss_mean": 1.0000048674161162, "train/rep_loss_std": 0.0001214086078107357, "train/reward_avg": 0.0016669430001117567, "train/reward_loss_mean": 0.012617457151848508, "train/reward_loss_std": 0.20571388536137505, "train/reward_max_data": 0.7059546022569362, "train/reward_max_pred": 0.15987417828384323, "train/reward_neg_acc": 0.9998441836727199, "train/reward_neg_loss": 0.00201523179461744, "train/reward_pos_acc": 0.11831866905255162, "train/reward_pos_loss": 4.3398780641348464, "train/reward_pred": 0.0011887494075014742, "train/reward_rate": 0.002443835509950249, "train_stats/mean_log_entropy": 0.08661455406721337, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 0.019217047840356827, "report/cont_loss_std": 0.24915415048599243, "report/cont_neg_acc": 0.4444444477558136, "report/cont_neg_loss": 1.7630010843276978, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003754922654479742, "report/cont_pred": 0.9919183254241943, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0869334414601326, "report/image_loss_std": 0.09960652887821198, "report/model_loss_mean": 0.7198340892791748, "report/model_loss_std": 0.43385791778564453, "report/post_ent_mag": 61.57960510253906, "report/post_ent_max": 61.57960510253906, "report/post_ent_mean": 50.05014419555664, "report/post_ent_min": 41.3016242980957, "report/post_ent_std": 4.4479594230651855, "report/prior_ent_mag": 60.601261138916016, "report/prior_ent_max": 60.601261138916016, "report/prior_ent_mean": 50.14620590209961, "report/prior_ent_min": 41.16804122924805, "report/prior_ent_std": 4.229556083679199, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0021270751021802425, "report/reward_loss_mean": 0.013683551922440529, "report/reward_loss_std": 0.2009081095457077, "report/reward_max_data": 0.8187500238418579, "report/reward_max_pred": 0.049490928649902344, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0028078865725547075, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.7150352001190186, "report/reward_pred": 0.0015810203040018678, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.021643754094839096, "eval/cont_loss_std": 0.3097779452800751, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.75879430770874, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.003066691569983959, "eval/cont_pred": 0.9968951940536499, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12413787096738815, "eval/image_loss_std": 0.13228969275951385, "eval/model_loss_mean": 0.7565648555755615, "eval/model_loss_std": 0.47526878118515015, "eval/post_ent_mag": 61.314449310302734, "eval/post_ent_max": 61.314449310302734, "eval/post_ent_mean": 50.63835144042969, "eval/post_ent_min": 41.968936920166016, "eval/post_ent_std": 4.769419193267822, "eval/prior_ent_mag": 62.410091400146484, "eval/prior_ent_max": 62.410091400146484, "eval/prior_ent_mean": 50.50666046142578, "eval/prior_ent_min": 41.05180358886719, "eval/prior_ent_std": 4.595302104949951, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0014556884998455644, "eval/reward_loss_mean": 0.010783215053379536, "eval/reward_loss_std": 0.20105217397212982, "eval/reward_max_data": 0.9281250238418579, "eval/reward_max_pred": 0.03258037567138672, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001923769130371511, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.537960052490234, "eval/reward_pred": 0.0010852018604055047, "eval/reward_rate": 0.001953125, "replay/size": 923665.0, "replay/inserts": 32112.0, "replay/samples": 32112.0, "replay/insert_wait_avg": 1.3706469690259203e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.431536659769117e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4104.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2159115157396938e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3113021850585938e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1507651805878, "timer/env.step_count": 4014.0, "timer/env.step_total": 40.12070035934448, "timer/env.step_frac": 0.04011465246652115, "timer/env.step_avg": 0.009995191918122691, "timer/env.step_min": 0.008028745651245117, "timer/env.step_max": 0.050450801849365234, "timer/replay._sample_count": 32112.0, "timer/replay._sample_total": 17.709826231002808, "timer/replay._sample_frac": 0.017707156608339054, "timer/replay._sample_avg": 0.0005515018133720357, "timer/replay._sample_min": 0.0003998279571533203, "timer/replay._sample_max": 0.01239013671875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4527.0, "timer/agent.policy_total": 49.83571219444275, "timer/agent.policy_frac": 0.04982819983689597, "timer/agent.policy_avg": 0.011008551401467363, "timer/agent.policy_min": 0.009378910064697266, "timer/agent.policy_max": 0.08393120765686035, "timer/dataset_train_count": 2007.0, "timer/dataset_train_total": 0.23561620712280273, "timer/dataset_train_frac": 0.00023558068975756844, "timer/dataset_train_avg": 0.00011739721331479957, "timer/dataset_train_min": 0.00010061264038085938, "timer/dataset_train_max": 0.001081228256225586, "timer/agent.train_count": 2007.0, "timer/agent.train_total": 898.146249294281, "timer/agent.train_frac": 0.8980108605247242, "timer/agent.train_avg": 0.44750685066979623, "timer/agent.train_min": 0.4350776672363281, "timer/agent.train_max": 0.8230931758880615, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5139696598052979, "timer/agent.report_frac": 0.0005138921827575617, "timer/agent.report_avg": 0.2569848299026489, "timer/agent.report_min": 0.2524120807647705, "timer/agent.report_max": 0.26155757904052734, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027459519108723e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 32.10660364925342}
{"step": 924208, "time": 29294.883348464966, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 924408, "time": 29300.755431175232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 924488, "time": 29303.213438987732, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 924592, "time": 29306.601778030396, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 924792, "time": 29312.50911951065, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 924936, "time": 29316.932224988937, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 924992, "time": 29318.86349773407, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 925176, "time": 29324.374163150787, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 925192, "time": 29324.86604642868, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 925232, "time": 29326.325490236282, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 925344, "time": 29329.741721391678, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 925712, "time": 29341.4857981205, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 925856, "time": 29345.872483968735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 925936, "time": 29348.336585521698, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 925960, "time": 29348.848618745804, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 925984, "time": 29349.798921346664, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 926136, "time": 29354.31417965889, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 926264, "time": 29358.227837085724, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 926296, "time": 29359.201679468155, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 926336, "time": 29360.63887834549, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 926400, "time": 29362.60656762123, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 926400, "time": 29362.61583018303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 926864, "time": 29376.783527612686, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 927024, "time": 29381.663964271545, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 927088, "time": 29383.624004364014, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 927096, "time": 29383.67572259903, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 927096, "time": 29383.70299911499, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 927224, "time": 29387.68866944313, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 927240, "time": 29388.1815700531, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 927256, "time": 29388.67449235916, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 927280, "time": 29389.631775140762, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 927632, "time": 29400.46964097023, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 927664, "time": 29401.46651673317, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 927784, "time": 29404.97430062294, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 927816, "time": 29405.973588466644, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 927832, "time": 29406.46339893341, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 928008, "time": 29411.847678661346, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 928104, "time": 29414.887904167175, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 928256, "time": 29419.73900294304, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 928448, "time": 29425.60658288002, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 928656, "time": 29431.9178314209, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 928728, "time": 29433.887132167816, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 928816, "time": 29436.80634522438, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 928848, "time": 29437.785229682922, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 928904, "time": 29439.261801481247, "episode/length": 6.0, "episode/score": 0.981249988079071, "episode/reward_rate": 0.14285714285714285, "episode/intrinsic_return": 0.0}
{"step": 929024, "time": 29443.141431570053, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 929320, "time": 29452.07483816147, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 929400, "time": 29454.540549993515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 929632, "time": 29461.826287031174, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 929856, "time": 29468.63228082657, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 929888, "time": 29469.614139318466, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 929976, "time": 29472.070622444153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 930064, "time": 29475.11020565033, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 930072, "time": 29476.068372011185, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 930072, "time": 29477.573492527008, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 930072, "time": 29477.59969496727, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 930072, "time": 29477.810875177383, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 930072, "time": 29477.957180023193, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 930072, "time": 29478.06702899933, "eval_episode/length": 22.0, "eval_episode/score": 0.9312499761581421, "eval_episode/reward_rate": 0.043478260869565216}
{"step": 930072, "time": 29478.374205827713, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 930072, "time": 29479.176157951355, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 930096, "time": 29480.13795185089, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 930264, "time": 29485.05427455902, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 930320, "time": 29486.97303056717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 930496, "time": 29492.343096733093, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 930840, "time": 29502.56852579117, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 931216, "time": 29514.40627360344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 931288, "time": 29516.412492990494, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 931352, "time": 29518.39567708969, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 931600, "time": 29526.210203886032, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 931712, "time": 29529.62520313263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 931848, "time": 29533.541214942932, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 932064, "time": 29540.448912620544, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 932120, "time": 29541.952518701553, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 932200, "time": 29544.385744571686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 932288, "time": 29547.29777765274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 932328, "time": 29548.298440933228, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 932416, "time": 29551.225563764572, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 932568, "time": 29555.713910341263, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 932632, "time": 29557.705003499985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 932752, "time": 29561.61417222023, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 932872, "time": 29565.141193151474, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 933152, "time": 29573.899630069733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 933328, "time": 29579.253995656967, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 933392, "time": 29581.234377384186, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 933472, "time": 29583.701323270798, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 933624, "time": 29588.146011590958, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 933864, "time": 29595.598825454712, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 934048, "time": 29601.893132209778, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 934296, "time": 29609.25150203705, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 934376, "time": 29611.720038175583, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 934456, "time": 29614.149382829666, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 934472, "time": 29614.64628624916, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 934576, "time": 29618.035423994064, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 934728, "time": 29622.436695814133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 934880, "time": 29627.41943669319, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 935064, "time": 29632.76732325554, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 935128, "time": 29634.69549179077, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 935216, "time": 29637.6047873497, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 935328, "time": 29641.02116394043, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 935424, "time": 29643.9515376091, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 935672, "time": 29651.28112411499, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 935840, "time": 29656.787123441696, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 936176, "time": 29667.082460165024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 936256, "time": 29669.52925848961, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 936264, "time": 29669.558661937714, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 936320, "time": 29671.496972084045, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 936520, "time": 29679.677278757095, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 936688, "time": 29685.11391377449, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 936848, "time": 29689.974417209625, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 936880, "time": 29690.955736637115, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 937000, "time": 29694.395448446274, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 937040, "time": 29695.83179974556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 937152, "time": 29699.24335885048, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 937352, "time": 29705.139554023743, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 937440, "time": 29708.063814401627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 937696, "time": 29716.065865516663, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 937720, "time": 29716.601523399353, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 937760, "time": 29718.056094408035, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 937960, "time": 29723.93699979782, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 938216, "time": 29731.84003353119, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 938512, "time": 29741.12742304802, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 938528, "time": 29741.618262529373, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 938568, "time": 29742.622246980667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 938880, "time": 29752.488797426224, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 939184, "time": 29761.774792432785, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 939256, "time": 29763.741993427277, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 939464, "time": 29770.090751171112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 939480, "time": 29770.603055000305, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 939624, "time": 29775.136645793915, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 939664, "time": 29776.602386713028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 939984, "time": 29786.429285287857, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 940024, "time": 29787.43798685074, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 940032, "time": 29787.91104912758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 940056, "time": 29789.869473695755, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 940056, "time": 29789.978380680084, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 940056, "time": 29790.00425338745, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 940056, "time": 29790.091086387634, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 940056, "time": 29790.443341732025, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 940056, "time": 29790.648671150208, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 940056, "time": 29790.815450906754, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 940056, "time": 29790.99111223221, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 940216, "time": 29795.91236782074, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 940320, "time": 29799.328202962875, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 940368, "time": 29800.80139684677, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 940680, "time": 29810.190950870514, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 940816, "time": 29814.568281650543, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 941008, "time": 29820.41779112816, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 941040, "time": 29821.3972158432, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 941048, "time": 29821.425515174866, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 941088, "time": 29822.883774995804, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 941496, "time": 29835.22299671173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 941640, "time": 29839.598012924194, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 941728, "time": 29842.52835035324, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 941728, "time": 29842.53547525406, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 941760, "time": 29843.518001556396, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 941800, "time": 29844.511063575745, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 941936, "time": 29848.886021375656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 942000, "time": 29850.847402095795, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 942096, "time": 29854.328545331955, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 942296, "time": 29860.250243902206, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 942448, "time": 29865.26926445961, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 942448, "time": 29865.27686214447, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 942584, "time": 29869.258078575134, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 942640, "time": 29871.198682308197, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 942944, "time": 29880.50364804268, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 942960, "time": 29880.99626493454, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 943088, "time": 29884.912882089615, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 943160, "time": 29886.899995803833, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 943280, "time": 29890.75689482689, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 943560, "time": 29899.15039730072, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 943904, "time": 29909.85570001602, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 943952, "time": 29911.36726140976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 944040, "time": 29913.83713030815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 944040, "time": 29913.84556555748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 944184, "time": 29918.290143966675, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 944240, "time": 29920.21413373947, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 944480, "time": 29927.65331339836, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 944584, "time": 29930.604169130325, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 944688, "time": 29934.01765680313, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 944840, "time": 29938.462341070175, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 944856, "time": 29938.953006505966, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 944992, "time": 29943.328082561493, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 945136, "time": 29947.724647521973, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 945256, "time": 29951.185361146927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 945272, "time": 29951.679387807846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 945336, "time": 29953.693633556366, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 945472, "time": 29958.127363204956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 945528, "time": 29959.622963428497, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 945664, "time": 29964.011531591415, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 945816, "time": 29968.436349630356, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 945944, "time": 29972.36225295067, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 946176, "time": 29979.702241182327, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 946464, "time": 29988.600026607513, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 946568, "time": 29991.591512441635, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 946888, "time": 30001.356617689133, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 946912, "time": 30002.311010599136, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 946968, "time": 30003.817445278168, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 947152, "time": 30009.74206018448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 947384, "time": 30016.70685148239, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 947512, "time": 30020.601365804672, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 947552, "time": 30022.03945493698, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 947568, "time": 30022.528158903122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 947648, "time": 30024.97569990158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 947744, "time": 30027.886410951614, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 947784, "time": 30028.883954763412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 947904, "time": 30032.747358560562, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 947984, "time": 30035.190052986145, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 947984, "time": 30035.19962143898, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 948160, "time": 30040.584812164307, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 948608, "time": 30054.377529621124, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 948696, "time": 30056.836234092712, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 948704, "time": 30057.312878608704, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 948776, "time": 30059.308379411697, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 948784, "time": 30059.777696609497, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 948808, "time": 30060.2893345356, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 949008, "time": 30066.583652496338, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 949072, "time": 30068.557296276093, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 949264, "time": 30074.517174720764, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 949280, "time": 30075.011795520782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 949392, "time": 30078.41355228424, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 949560, "time": 30083.29712986946, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 949760, "time": 30089.68858551979, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 949776, "time": 30090.184267282486, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 949776, "time": 30090.193244457245, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 949824, "time": 30091.663264751434, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 949928, "time": 30094.610467910767, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 950040, "time": 30098.20334815979, "eval_episode/length": 8.0, "eval_episode/score": 0.9750000238418579, "eval_episode/reward_rate": 0.1111111111111111}
{"step": 950040, "time": 30099.94530272484, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 950040, "time": 30099.952597141266, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 950040, "time": 30099.959015846252, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 950040, "time": 30100.027552127838, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 950040, "time": 30100.44744873047, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 950040, "time": 30101.534447431564, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 950040, "time": 30103.889266490936, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 950040, "time": 30103.897346496582, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 950040, "time": 30103.907047748566, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 950168, "time": 30107.796088933945, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 950352, "time": 30114.128359794617, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 950512, "time": 30119.017022371292, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 950728, "time": 30125.474656820297, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 950776, "time": 30126.954186201096, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 950816, "time": 30128.398030519485, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 950952, "time": 30132.32551908493, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 951040, "time": 30135.371169805527, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 951264, "time": 30142.192185640335, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 951264, "time": 30142.202252388, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 951280, "time": 30142.697707891464, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 951384, "time": 30145.650336503983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 951408, "time": 30146.60221338272, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 951704, "time": 30155.441021680832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 951712, "time": 30155.915442705154, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 951832, "time": 30159.361580133438, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 951864, "time": 30160.339306354523, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 951968, "time": 30163.846608638763, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 951976, "time": 30163.904760599136, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 952496, "time": 30180.0406332016, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 952512, "time": 30180.54414820671, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 952776, "time": 30188.431275367737, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 952840, "time": 30190.36812734604, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 953128, "time": 30199.30015397072, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 953256, "time": 30203.213156938553, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 953296, "time": 30204.644592285156, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 953528, "time": 30211.464443206787, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 953528, "time": 30211.475301265717, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 953616, "time": 30214.400300979614, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 953696, "time": 30216.84075498581, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 953720, "time": 30217.37282347679, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 953936, "time": 30224.33787059784, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 954080, "time": 30228.778420448303, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 954320, "time": 30236.102818250656, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 954464, "time": 30240.523267507553, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 954520, "time": 30242.03693342209, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 954592, "time": 30244.447788476944, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 954808, "time": 30250.79998731613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 954984, "time": 30256.301274061203, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 955064, "time": 30258.75743484497, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 955328, "time": 30267.00888156891, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 955336, "time": 30267.035742282867, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 955344, "time": 30267.504648685455, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 955360, "time": 30267.996601104736, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 955824, "time": 30282.132632493973, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 955912, "time": 30284.732846021652, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 955928, "time": 30285.23353457451, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 956008, "time": 30287.683684825897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 956169, "time": 30293.575600624084, "train_stats/mean_log_entropy": 0.08214831511889185, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.23801025390625, "train/action_min": 0.0, "train/action_std": 1.6757401543855668, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009058843621751293, "train/actor_opt_grad_steps": 58665.0, "train/actor_opt_loss": -9.941306104362011, "train/adv_mag": 0.9691735458374023, "train/adv_max": 0.23180503904819488, "train/adv_mean": 0.002282104503174196, "train/adv_min": -0.9364603930711746, "train/adv_std": 0.02622070557670668, "train/cont_avg": 0.994892578125, "train/cont_loss_mean": 0.01909545760601759, "train/cont_loss_std": 0.25098247243091465, "train/cont_neg_acc": 0.25374693918973207, "train/cont_neg_loss": 3.034890383183956, "train/cont_pos_acc": 0.9999067696928978, "train/cont_pos_loss": 0.0037347128958208488, "train/cont_pred": 0.9949961081147194, "train/cont_rate": 0.994892578125, "train/dyn_loss_mean": 1.0001729232072831, "train/dyn_loss_std": 0.0006663289483185509, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.17683686763979495, "train/extr_critic_critic_opt_grad_steps": 58665.0, "train/extr_critic_critic_opt_loss": 13249.987163085938, "train/extr_critic_mag": 1.453747911453247, "train/extr_critic_max": 1.453747911453247, "train/extr_critic_mean": 1.3708899825811387, "train/extr_critic_min": 1.2461193901300431, "train/extr_critic_std": 0.019500090195797383, "train/extr_return_normed_mag": 0.9772263920307159, "train/extr_return_normed_max": 0.27293739676475526, "train/extr_return_normed_mean": 0.04125676506664604, "train/extr_return_normed_min": -0.923292161822319, "train/extr_return_normed_std": 0.033490069871768356, "train/extr_return_rate": 0.9995843467116355, "train/extr_return_raw_mag": 1.6048526114225388, "train/extr_return_raw_max": 1.6048526114225388, "train/extr_return_raw_mean": 1.3731720435619355, "train/extr_return_raw_min": 0.40862305283546446, "train/extr_return_raw_std": 0.03349007001146674, "train/extr_reward_mag": 0.2893629783391953, "train/extr_reward_max": 0.2893629783391953, "train/extr_reward_mean": 0.002512985012144782, "train/extr_reward_min": 2.3066997528076173e-07, "train/extr_reward_std": 0.008548193236347288, "train/image_loss_mean": 0.08930579153820872, "train/image_loss_std": 0.10211817122995853, "train/model_loss_mean": 0.7220946562290191, "train/model_loss_std": 0.4612110594660044, "train/model_opt_grad_norm": 17.525405707359315, "train/model_opt_grad_steps": 58611.795, "train/model_opt_loss": 3845.9142517089845, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5325.0, "train/policy_entropy_mag": 1.2760395693778992, "train/policy_entropy_max": 1.2760395693778992, "train/policy_entropy_mean": 0.09676854364573956, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12228211745619774, "train/policy_logprob_mag": 6.551080274581909, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09679992064833641, "train/policy_logprob_min": -6.551080274581909, "train/policy_logprob_std": 0.6348367965221405, "train/policy_randomness_mag": 0.6557546585798264, "train/policy_randomness_max": 0.6557546585798264, "train/policy_randomness_mean": 0.049729196541011336, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06284058084711433, "train/post_ent_mag": 61.460493106842044, "train/post_ent_max": 61.460493106842044, "train/post_ent_mean": 52.56181159973144, "train/post_ent_min": 46.32076808929443, "train/post_ent_std": 3.2606143450736997, "train/prior_ent_mag": 63.21223726272583, "train/prior_ent_max": 63.21223726272583, "train/prior_ent_mean": 54.39796960830689, "train/prior_ent_min": 48.06618278503418, "train/prior_ent_std": 3.2270852184295653, "train/rep_loss_mean": 1.0001729232072831, "train/rep_loss_std": 0.0006663289483185509, "train/reward_avg": 0.0017871246275899466, "train/reward_loss_mean": 0.013589628715999424, "train/reward_loss_std": 0.21736513669369742, "train/reward_max_data": 0.7559687496721744, "train/reward_max_pred": 0.17511701583862305, "train/reward_neg_acc": 0.9997698676586151, "train/reward_neg_loss": 0.0022034987664665095, "train/reward_pos_acc": 0.12255154757462826, "train/reward_pos_loss": 4.322094006943948, "train/reward_pred": 0.0012866057344945148, "train/reward_rate": 0.0026220703125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.025044361129403114, "report/cont_loss_std": 0.3301355838775635, "report/cont_neg_acc": 0.375, "report/cont_neg_loss": 2.864529609680176, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0026862085796892643, "report/cont_pred": 0.9944078326225281, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08469679951667786, "report/image_loss_std": 0.10951689630746841, "report/model_loss_mean": 0.7342192530632019, "report/model_loss_std": 0.7281513214111328, "report/post_ent_mag": 61.9092903137207, "report/post_ent_max": 61.9092903137207, "report/post_ent_mean": 54.48420333862305, "report/post_ent_min": 49.79664993286133, "report/post_ent_std": 2.5601301193237305, "report/prior_ent_mag": 64.25360107421875, "report/prior_ent_max": 64.25360107421875, "report/prior_ent_mean": 58.171241760253906, "report/prior_ent_min": 53.55369567871094, "report/prior_ent_std": 2.1854960918426514, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0026397705078125, "report/reward_loss_mean": 0.024478094652295113, "report/reward_loss_std": 0.3790305554866791, "report/reward_max_data": 0.862500011920929, "report/reward_max_pred": 0.08081412315368652, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0016805313061922789, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.837856292724609, "report/reward_pred": 0.0009449131321161985, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.023941535502672195, "eval/cont_loss_std": 0.36035317182540894, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.389836311340332, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0028988125268369913, "eval/cont_pred": 0.9970784187316895, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.127527117729187, "eval/image_loss_std": 0.11757206171751022, "eval/model_loss_mean": 0.7695959806442261, "eval/model_loss_std": 0.6749948263168335, "eval/post_ent_mag": 61.928070068359375, "eval/post_ent_max": 61.928070068359375, "eval/post_ent_mean": 54.85227584838867, "eval/post_ent_min": 49.74858856201172, "eval/post_ent_std": 2.8605141639709473, "eval/prior_ent_mag": 64.626953125, "eval/prior_ent_max": 64.626953125, "eval/prior_ent_mean": 58.64155578613281, "eval/prior_ent_min": 54.08171844482422, "eval/prior_ent_std": 2.669511556625366, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0021697997581213713, "eval/reward_loss_mean": 0.018127311021089554, "eval/reward_loss_std": 0.3277527689933777, "eval/reward_max_data": 0.7593749761581421, "eval/reward_max_pred": 0.03290355205535889, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0015881105791777372, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.646968364715576, "eval/reward_pred": 0.0008973425719887018, "eval/reward_rate": 0.0029296875, "replay/size": 955665.0, "replay/inserts": 32000.0, "replay/samples": 32000.0, "replay/insert_wait_avg": 1.358628273010254e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0559335350990295e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4880.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1638051173726066e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3560056686401367e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0925943851471, "timer/env.step_count": 4000.0, "timer/env.step_total": 39.86706352233887, "timer/env.step_frac": 0.0398633723978818, "timer/env.step_avg": 0.009966765880584717, "timer/env.step_min": 0.007925987243652344, "timer/env.step_max": 0.03551292419433594, "timer/replay._sample_count": 32000.0, "timer/replay._sample_total": 17.729363918304443, "timer/replay._sample_frac": 0.01772772243074591, "timer/replay._sample_avg": 0.0005540426224470139, "timer/replay._sample_min": 0.0004303455352783203, "timer/replay._sample_max": 0.034494638442993164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4610.0, "timer/agent.policy_total": 50.26602268218994, "timer/agent.policy_frac": 0.050261368761652804, "timer/agent.policy_avg": 0.010903692555789575, "timer/agent.policy_min": 0.009136438369750977, "timer/agent.policy_max": 0.08053827285766602, "timer/dataset_train_count": 2000.0, "timer/dataset_train_total": 0.23492002487182617, "timer/dataset_train_frac": 0.0002348982746105165, "timer/dataset_train_avg": 0.00011746001243591309, "timer/dataset_train_min": 0.0001010894775390625, "timer/dataset_train_max": 0.0010848045349121094, "timer/agent.train_count": 2000.0, "timer/agent.train_total": 897.3863010406494, "timer/agent.train_frac": 0.8973032158010918, "timer/agent.train_avg": 0.4486931505203247, "timer/agent.train_min": 0.43581295013427734, "timer/agent.train_max": 2.746924638748169, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5149691104888916, "timer/agent.report_frac": 0.0005149214316555284, "timer/agent.report_avg": 0.2574845552444458, "timer/agent.report_min": 0.25223207473754883, "timer/agent.report_max": 0.2627370357513428, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9561166610547217e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 31.99643948312316}
{"step": 956304, "time": 30297.756460666656, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 956456, "time": 30302.170789003372, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 956760, "time": 30311.47786784172, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 956880, "time": 30315.512330532074, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 956888, "time": 30315.540397644043, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 956920, "time": 30316.54945588112, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 957024, "time": 30319.940066337585, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 957120, "time": 30322.898151397705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 957592, "time": 30337.12142777443, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 957640, "time": 30338.59107017517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 957672, "time": 30339.56931090355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 957768, "time": 30342.511212825775, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 957824, "time": 30344.57761669159, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 957880, "time": 30346.094490289688, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 957952, "time": 30348.522399663925, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 958184, "time": 30355.40629673004, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 958240, "time": 30357.347657442093, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 958320, "time": 30359.787336587906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 958576, "time": 30368.20172572136, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 958600, "time": 30368.717777252197, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 958608, "time": 30369.193572044373, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 958904, "time": 30378.13503432274, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 958928, "time": 30379.08964896202, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 959040, "time": 30382.507220983505, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 959336, "time": 30391.323167085648, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 959496, "time": 30396.212030649185, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 959584, "time": 30399.107350111008, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 959728, "time": 30403.5078561306, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 959808, "time": 30406.095557689667, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 959888, "time": 30408.538338422775, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 959984, "time": 30411.50124526024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 959984, "time": 30411.509889125824, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 959992, "time": 30411.542119026184, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 960024, "time": 30413.71266269684, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 960024, "time": 30413.737618923187, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 960024, "time": 30414.40336084366, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 960024, "time": 30415.22886300087, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 960024, "time": 30415.37833094597, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 960024, "time": 30415.86469054222, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 960024, "time": 30416.581362724304, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 960024, "time": 30418.03978085518, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 960112, "time": 30420.964210748672, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 960552, "time": 30434.25925040245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 960608, "time": 30436.205095529556, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 960624, "time": 30436.696190834045, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 960744, "time": 30440.134133815765, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 960768, "time": 30441.112726449966, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 960880, "time": 30444.511642217636, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 961168, "time": 30453.26139855385, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 961240, "time": 30455.262610435486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 961368, "time": 30459.155508756638, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 961448, "time": 30461.615127325058, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 961464, "time": 30462.10753440857, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 961776, "time": 30471.948976755142, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 961896, "time": 30475.402401208878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 961912, "time": 30475.89474248886, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 962176, "time": 30484.16155910492, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 962296, "time": 30487.60267519951, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 962400, "time": 30490.988656759262, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 962448, "time": 30492.455803871155, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 962720, "time": 30500.944279193878, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 963008, "time": 30509.74873661995, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 963160, "time": 30514.1966714859, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 963192, "time": 30515.182450056076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 963248, "time": 30517.10902786255, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 963400, "time": 30521.53147816658, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 963480, "time": 30524.113474845886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 963776, "time": 30533.336277246475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 963840, "time": 30535.309324502945, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 963928, "time": 30537.761038541794, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 963960, "time": 30538.754700899124, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 964088, "time": 30542.645055532455, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 964128, "time": 30544.110632181168, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 964216, "time": 30546.56904053688, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 964328, "time": 30550.01539850235, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 964472, "time": 30554.584615707397, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 964568, "time": 30557.52135157585, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 964584, "time": 30558.01870393753, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 964712, "time": 30561.993544101715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 964808, "time": 30564.987139940262, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 965032, "time": 30571.888119459152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 965072, "time": 30573.352545261383, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 965344, "time": 30581.640258073807, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 965400, "time": 30583.147855997086, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 965408, "time": 30583.62465238571, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 965448, "time": 30584.71843647957, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 965608, "time": 30589.60661625862, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 965824, "time": 30596.43806576729, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 965944, "time": 30599.886538028717, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 965992, "time": 30601.36208796501, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 966136, "time": 30605.759211063385, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 966176, "time": 30607.197027683258, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 966240, "time": 30609.192901849747, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 966432, "time": 30615.20359301567, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 966496, "time": 30617.15293622017, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 966640, "time": 30621.565959215164, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 966784, "time": 30626.486243724823, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 966880, "time": 30629.433341503143, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 966896, "time": 30629.928933382034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 966968, "time": 30631.901802778244, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 967040, "time": 30634.34024167061, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 967368, "time": 30644.240389108658, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 967384, "time": 30644.73132634163, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 967424, "time": 30646.17978644371, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 967520, "time": 30649.134657382965, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 967704, "time": 30654.536458015442, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 967768, "time": 30656.49776506424, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 967880, "time": 30659.955162525177, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 967920, "time": 30661.404827594757, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 968168, "time": 30668.762094020844, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 968376, "time": 30675.20092868805, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 968400, "time": 30676.159245967865, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 968776, "time": 30687.351837158203, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 969208, "time": 30700.507670640945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 969280, "time": 30702.952114343643, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 969680, "time": 30715.250967502594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 969832, "time": 30719.663474798203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 969840, "time": 30720.135534524918, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 969864, "time": 30720.64986348152, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 970008, "time": 30725.41369318962, "eval_episode/length": 15.0, "eval_episode/score": 0.953125, "eval_episode/reward_rate": 0.0625}
{"step": 970008, "time": 30725.9413022995, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 970008, "time": 30726.187875509262, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 970008, "time": 30726.233976602554, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 970008, "time": 30726.48692059517, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 970008, "time": 30726.994746685028, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 970008, "time": 30727.832601070404, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 970008, "time": 30728.605370759964, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 970072, "time": 30730.574306488037, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 970080, "time": 30731.0485496521, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 970232, "time": 30735.62467932701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 970232, "time": 30735.631004333496, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 970480, "time": 30743.474962711334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 970560, "time": 30745.967106342316, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 970688, "time": 30749.89720392227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 970856, "time": 30754.816657543182, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 971104, "time": 30762.629388332367, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 971168, "time": 30764.722017526627, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 971168, "time": 30764.730525255203, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 971256, "time": 30767.18504166603, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 971432, "time": 30772.60972929001, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 971616, "time": 30778.49553346634, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 971848, "time": 30785.38875746727, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 972144, "time": 30794.79588508606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 972176, "time": 30795.77896809578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 972240, "time": 30797.733869314194, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 972544, "time": 30807.049254179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 972880, "time": 30817.416345357895, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 973072, "time": 30823.406232357025, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 973312, "time": 30830.941747426987, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 973328, "time": 30831.43720793724, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 973480, "time": 30835.896582603455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 973480, "time": 30835.904122829437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 973480, "time": 30835.910996437073, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 973568, "time": 30838.873460769653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 973744, "time": 30844.307387828827, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 973960, "time": 30850.711893558502, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 974056, "time": 30853.761966228485, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 974104, "time": 30855.32160615921, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 974208, "time": 30858.722902536392, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 974216, "time": 30858.752435684204, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 974488, "time": 30867.081322431564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 974520, "time": 30868.084864377975, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 974560, "time": 30869.538460969925, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 974840, "time": 30877.908037424088, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 974856, "time": 30878.647782087326, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 974928, "time": 30881.39105987549, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 974960, "time": 30882.377403259277, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 975272, "time": 30891.977804660797, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 975288, "time": 30892.48263168335, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 975328, "time": 30893.969917058945, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 975496, "time": 30898.92093229294, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 975568, "time": 30901.38470172882, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 975576, "time": 30901.41294312477, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 975576, "time": 30901.421233415604, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 975792, "time": 30908.393640756607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 976056, "time": 30916.44235444069, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 976056, "time": 30916.450655937195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 976248, "time": 30922.396208286285, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 976464, "time": 30929.331608057022, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 976576, "time": 30932.808475971222, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 976608, "time": 30933.80866098404, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 976608, "time": 30933.815876960754, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 976648, "time": 30934.82030057907, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 976672, "time": 30935.782406568527, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 976912, "time": 30943.18472313881, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 977048, "time": 30947.25719809532, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 977168, "time": 30951.179736852646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 977256, "time": 30953.674070119858, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 977624, "time": 30964.974417448044, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 977656, "time": 30965.95626783371, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 977760, "time": 30969.361163139343, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 977976, "time": 30975.87363243103, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 978112, "time": 30980.250009536743, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 978424, "time": 30989.523213624954, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 978920, "time": 31004.774769067764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 978920, "time": 31004.783491373062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 978960, "time": 31006.230553627014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 979120, "time": 31011.137321949005, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 979152, "time": 31012.13817024231, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 979160, "time": 31012.16787481308, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 979224, "time": 31014.12219595909, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 979312, "time": 31017.04220890999, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 979520, "time": 31023.406283140182, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 979776, "time": 31031.294230222702, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 979928, "time": 31035.870513677597, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 980072, "time": 31040.297649145126, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 980096, "time": 31042.33321094513, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 980096, "time": 31042.46048593521, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 980096, "time": 31043.04312801361, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 980096, "time": 31043.069472312927, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 980096, "time": 31043.50807571411, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 980096, "time": 31044.022476673126, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 980096, "time": 31044.234279870987, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 980096, "time": 31044.62727332115, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 980288, "time": 31050.5015335083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 980360, "time": 31052.45851945877, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 980792, "time": 31065.7285926342, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 980848, "time": 31067.64867758751, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 981184, "time": 31077.93561410904, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 981232, "time": 31079.43204522133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 981272, "time": 31080.438530683517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 981472, "time": 31086.75978422165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 981504, "time": 31087.731622457504, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 981528, "time": 31088.242414712906, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 981536, "time": 31088.709790468216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 981832, "time": 31097.631767749786, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 981872, "time": 31099.092841148376, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 981920, "time": 31100.55908703804, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 982144, "time": 31107.3853225708, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 982256, "time": 31110.8293633461, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 982264, "time": 31110.85839509964, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 982272, "time": 31111.332403182983, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 982344, "time": 31113.315618276596, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 982600, "time": 31121.137244939804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 982800, "time": 31127.575281381607, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 982824, "time": 31128.089226961136, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 983048, "time": 31135.190027713776, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 983320, "time": 31143.83844256401, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 983392, "time": 31146.27807354927, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 983432, "time": 31147.275695562363, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 983840, "time": 31160.098035812378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 984136, "time": 31169.003681898117, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 984176, "time": 31170.460508584976, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 984232, "time": 31171.954036712646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 984480, "time": 31179.867705345154, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 984576, "time": 31182.80550479889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 984592, "time": 31183.317549943924, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 984600, "time": 31183.344089746475, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 984704, "time": 31186.856522083282, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 984784, "time": 31189.324635505676, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 985040, "time": 31197.134582281113, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 985184, "time": 31201.517995595932, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 985200, "time": 31202.008620500565, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 985232, "time": 31203.00076675415, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 985360, "time": 31206.879895687103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 985528, "time": 31211.814386844635, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 985744, "time": 31218.782695531845, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 985848, "time": 31221.717893600464, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 986000, "time": 31226.595559597015, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 986216, "time": 31232.944927453995, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 986312, "time": 31235.860273599625, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 986472, "time": 31240.756182909012, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 986632, "time": 31245.7615339756, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 986768, "time": 31250.132174253464, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 986912, "time": 31254.544601917267, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 987096, "time": 31259.961759090424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 987216, "time": 31263.86923098564, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 987352, "time": 31267.809653520584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 987608, "time": 31275.805634975433, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 987752, "time": 31280.220967292786, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 987888, "time": 31284.607168197632, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 987944, "time": 31286.094300031662, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 987992, "time": 31287.572664260864, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 988169, "time": 31293.979955673218, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2716656494140626, "train/action_min": 0.0, "train/action_std": 1.6688495510816574, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00845272054313682, "train/actor_opt_grad_steps": 60665.0, "train/actor_opt_loss": -11.876252158880234, "train/adv_mag": 0.9349866300821305, "train/adv_max": 0.27531670808792114, "train/adv_mean": 0.0022941736996290275, "train/adv_min": -0.8750781089067459, "train/adv_std": 0.026815909431315958, "train/cont_avg": 0.9946826171875, "train/cont_loss_mean": 0.01944205804495141, "train/cont_loss_std": 0.2548468078346923, "train/cont_neg_acc": 0.26914809335023165, "train/cont_neg_loss": 2.933453367701732, "train/cont_pos_acc": 0.9998674139380455, "train/cont_pos_loss": 0.00387426721106749, "train/cont_pred": 0.9948242431879044, "train/cont_rate": 0.9946826171875, "train/dyn_loss_mean": 1.0000007486343383, "train/dyn_loss_std": 2.3929440631036413e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14242798909544946, "train/extr_critic_critic_opt_grad_steps": 60665.0, "train/extr_critic_critic_opt_loss": 10920.223608398437, "train/extr_critic_mag": 1.5500613582134246, "train/extr_critic_max": 1.5500613582134246, "train/extr_critic_mean": 1.469656457901001, "train/extr_critic_min": 1.32378691136837, "train/extr_critic_std": 0.021928386902436613, "train/extr_return_normed_mag": 0.9567530179023742, "train/extr_return_normed_max": 0.32349037647247314, "train/extr_return_normed_mean": 0.04689579048193991, "train/extr_return_normed_min": -0.8609276807308197, "train/extr_return_normed_std": 0.03580051386728883, "train/extr_return_rate": 0.9997038108110428, "train/extr_return_raw_mag": 1.7485451591014862, "train/extr_return_raw_max": 1.7485451591014862, "train/extr_return_raw_mean": 1.4719506406784058, "train/extr_return_raw_min": 0.5641271018981934, "train/extr_return_raw_std": 0.035800513625144956, "train/extr_reward_mag": 0.3309112161397934, "train/extr_reward_max": 0.3309112161397934, "train/extr_reward_mean": 0.0025859426578972488, "train/extr_reward_min": 1.8715858459472657e-07, "train/extr_reward_std": 0.009623332598712295, "train/image_loss_mean": 0.08751354157924653, "train/image_loss_std": 0.1010300087183714, "train/model_loss_mean": 0.7205156928300858, "train/model_loss_std": 0.4613420370593667, "train/model_opt_grad_norm": 16.842008521556853, "train/model_opt_grad_steps": 60609.88, "train/model_opt_loss": 3656.406370849609, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5075.0, "train/policy_entropy_mag": 1.2822780406475067, "train/policy_entropy_max": 1.2822780406475067, "train/policy_entropy_mean": 0.0960591633617878, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12110981676727534, "train/policy_logprob_mag": 6.551080248355865, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09657880444079638, "train/policy_logprob_min": -6.551080248355865, "train/policy_logprob_std": 0.6367323502898217, "train/policy_randomness_mag": 0.6589605993032456, "train/policy_randomness_max": 0.6589605993032456, "train/policy_randomness_mean": 0.04936464613303542, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06223813820630312, "train/post_ent_mag": 62.17339572906494, "train/post_ent_max": 62.17339572906494, "train/post_ent_mean": 54.48123199462891, "train/post_ent_min": 48.723964290618895, "train/post_ent_std": 2.9118952631950377, "train/prior_ent_mag": 63.97091663360596, "train/prior_ent_max": 63.97091663360596, "train/prior_ent_mean": 57.438963737487796, "train/prior_ent_min": 52.070758476257325, "train/prior_ent_std": 2.65140602350235, "train/rep_loss_mean": 1.0000007486343383, "train/rep_loss_std": 2.3929440631036413e-05, "train/reward_avg": 0.00187162779722712, "train/reward_loss_mean": 0.013559620095184072, "train/reward_loss_std": 0.21516630617436022, "train/reward_max_data": 0.7498593752086162, "train/reward_max_pred": 0.2157972276210785, "train/reward_neg_acc": 0.9997649750113488, "train/reward_neg_loss": 0.0023354908131295814, "train/reward_pos_acc": 0.14223443384353932, "train/reward_pos_loss": 4.137346765933892, "train/reward_pred": 0.0014000383723760024, "train/reward_rate": 0.0027197265625, "train_stats/mean_log_entropy": 0.08126212599646135, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.01689191535115242, "report/cont_loss_std": 0.2190159112215042, "report/cont_neg_acc": 0.4285714626312256, "report/cont_neg_loss": 1.9928315877914429, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0032915447372943163, "report/cont_pred": 0.993714451789856, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10328903794288635, "report/image_loss_std": 0.10804994404315948, "report/model_loss_mean": 0.7346616983413696, "report/model_loss_std": 0.4682919979095459, "report/post_ent_mag": 64.97357940673828, "report/post_ent_max": 64.97357940673828, "report/post_ent_mean": 55.5185661315918, "report/post_ent_min": 47.62090301513672, "report/post_ent_std": 3.873260259628296, "report/prior_ent_mag": 63.63410568237305, "report/prior_ent_max": 63.63410568237305, "report/prior_ent_mean": 56.794654846191406, "report/prior_ent_min": 50.67144012451172, "report/prior_ent_std": 3.179727554321289, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0018737793434411287, "report/reward_loss_mean": 0.014480721205472946, "report/reward_loss_std": 0.2383749634027481, "report/reward_max_data": 0.7437499761581421, "report/reward_max_pred": 0.04410982131958008, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0016274064546450973, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.388892650604248, "report/reward_pred": 0.0009051183005794883, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.02256961539387703, "eval/cont_loss_std": 0.4301191568374634, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.517878532409668, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003987797535955906, "eval/cont_pred": 0.9960678815841675, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1076800748705864, "eval/image_loss_std": 0.12634916603565216, "eval/model_loss_mean": 0.7567660808563232, "eval/model_loss_std": 1.011004090309143, "eval/post_ent_mag": 65.02294921875, "eval/post_ent_max": 65.02294921875, "eval/post_ent_mean": 55.58628845214844, "eval/post_ent_min": 48.303428649902344, "eval/post_ent_std": 3.88631010055542, "eval/prior_ent_mag": 63.63410568237305, "eval/prior_ent_max": 63.63410568237305, "eval/prior_ent_mean": 56.720985412597656, "eval/prior_ent_min": 50.259559631347656, "eval/prior_ent_std": 2.9096245765686035, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0012023926246911287, "eval/reward_loss_mean": 0.026516368612647057, "eval/reward_loss_std": 0.5608367919921875, "eval/reward_max_data": 0.7593749761581421, "eval/reward_max_pred": 0.028920412063598633, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0023093654308468103, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 12.396295547485352, "eval/reward_pred": 0.0011887374566867948, "eval/reward_rate": 0.001953125, "replay/size": 987665.0, "replay/inserts": 32000.0, "replay/samples": 32000.0, "replay/insert_wait_avg": 1.3626590371131897e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.503141045570374e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4632.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1747468114928671e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2814998626708984e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3902101516724, "timer/env.step_count": 4000.0, "timer/env.step_total": 40.115668296813965, "timer/env.step_frac": 0.0401000208615915, "timer/env.step_avg": 0.01002891707420349, "timer/env.step_min": 0.007935762405395508, "timer/env.step_max": 0.05197405815124512, "timer/replay._sample_count": 32000.0, "timer/replay._sample_total": 17.844300985336304, "timer/replay._sample_frac": 0.017837340673926498, "timer/replay._sample_avg": 0.0005576344057917595, "timer/replay._sample_min": 0.0004069805145263672, "timer/replay._sample_max": 0.03541421890258789, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4579.0, "timer/agent.policy_total": 50.7415087223053, "timer/agent.policy_frac": 0.050721716593580234, "timer/agent.policy_avg": 0.011081351544508691, "timer/agent.policy_min": 0.008827924728393555, "timer/agent.policy_max": 0.08666515350341797, "timer/dataset_train_count": 2000.0, "timer/dataset_train_total": 0.23624038696289062, "timer/dataset_train_frac": 0.00023614823952252938, "timer/dataset_train_avg": 0.00011812019348144532, "timer/dataset_train_min": 0.00010228157043457031, "timer/dataset_train_max": 0.0005688667297363281, "timer/agent.train_count": 2000.0, "timer/agent.train_total": 897.0273675918579, "timer/agent.train_frac": 0.896677474938361, "timer/agent.train_avg": 0.44851368379592893, "timer/agent.train_min": 0.43643927574157715, "timer/agent.train_max": 0.7178788185119629, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5169732570648193, "timer/agent.report_frac": 0.0005167716075374621, "timer/agent.report_avg": 0.25848662853240967, "timer/agent.report_min": 0.25309324264526367, "timer/agent.report_max": 0.26388001441955566, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.7407441934605434e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 31.986949019992565}
{"step": 988240, "time": 31296.20110630989, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 988448, "time": 31302.58757710457, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 988472, "time": 31303.101432323456, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 988528, "time": 31305.175398111343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 988568, "time": 31306.182999134064, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 988624, "time": 31308.15103340149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 988784, "time": 31313.076200962067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 988848, "time": 31315.029039382935, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 989200, "time": 31325.879042625427, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 989280, "time": 31328.335325956345, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 989472, "time": 31334.295253753662, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 989528, "time": 31335.78057551384, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 989528, "time": 31335.789404392242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 989584, "time": 31337.752404928207, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 989904, "time": 31347.558974981308, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 989904, "time": 31347.566994428635, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 989968, "time": 31349.517699480057, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 990080, "time": 31354.27557492256, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 990080, "time": 31354.441858291626, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 990080, "time": 31355.08684849739, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 990080, "time": 31355.229791641235, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 990080, "time": 31355.660559654236, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 990080, "time": 31355.685272693634, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 990080, "time": 31356.175586223602, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 990080, "time": 31356.819840669632, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 990112, "time": 31357.798305749893, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 990200, "time": 31360.293083667755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 990496, "time": 31369.69747877121, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 990584, "time": 31372.173523187637, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 990656, "time": 31374.588536977768, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 990704, "time": 31376.06776189804, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 990824, "time": 31379.496369600296, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 990864, "time": 31380.95879650116, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 991024, "time": 31385.85580253601, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 991136, "time": 31389.29217171669, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 991480, "time": 31400.18407559395, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 991504, "time": 31401.13781619072, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 991792, "time": 31410.016761302948, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 991840, "time": 31411.50080513954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 992128, "time": 31420.329546689987, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 992496, "time": 31431.713158607483, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 992512, "time": 31432.210332393646, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 992704, "time": 31438.08362841606, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 992968, "time": 31445.984283447266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 992984, "time": 31446.48187470436, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 993016, "time": 31447.468485593796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 993096, "time": 31449.9343149662, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 993176, "time": 31452.423503398895, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 993240, "time": 31454.539662361145, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 993336, "time": 31457.481647729874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 993448, "time": 31460.922479629517, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 993456, "time": 31461.397547721863, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 993768, "time": 31470.761937618256, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 993800, "time": 31471.75796175003, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 993896, "time": 31474.735644340515, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 993976, "time": 31477.2001683712, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 993976, "time": 31477.208812713623, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 994208, "time": 31484.699464559555, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 994376, "time": 31489.62358236313, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 994408, "time": 31490.61839079857, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 994440, "time": 31491.601912498474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 994696, "time": 31499.457273721695, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 994728, "time": 31500.437536239624, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 994792, "time": 31502.410621643066, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 995096, "time": 31511.72177386284, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 995256, "time": 31516.78191256523, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 995288, "time": 31517.761650323868, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 995296, "time": 31518.2381670475, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 995448, "time": 31522.67809033394, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 995616, "time": 31528.051292657852, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 995656, "time": 31529.069535255432, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 995800, "time": 31533.488886594772, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 995944, "time": 31537.883749485016, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 996168, "time": 31544.935492515564, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 996472, "time": 31554.249918222427, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 996552, "time": 31556.695237398148, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 996720, "time": 31562.11458826065, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 996752, "time": 31563.118221998215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 996760, "time": 31563.14563846588, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 996776, "time": 31563.639137268066, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 996832, "time": 31565.579108715057, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 997008, "time": 31570.969690322876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 997008, "time": 31570.975849866867, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 997104, "time": 31574.080481290817, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 997272, "time": 31579.01414680481, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 997272, "time": 31579.023255825043, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 997472, "time": 31585.392481803894, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 997704, "time": 31592.3021774292, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 997752, "time": 31593.7920897007, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 997832, "time": 31596.244525432587, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 997840, "time": 31596.716994524002, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 998104, "time": 31604.7154173851, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 998408, "time": 31614.057303905487, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 998536, "time": 31617.989358901978, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 998904, "time": 31629.26189184189, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 998952, "time": 31630.738508462906, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 999072, "time": 31634.78346014023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 999112, "time": 31635.802849769592, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 999256, "time": 31640.194744586945, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 999320, "time": 31642.167183160782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 999352, "time": 31643.145891427994, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 999784, "time": 31656.856701612473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 999848, "time": 31658.85573554039, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 999888, "time": 31660.299558877945, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1000040, "time": 31664.870843172073, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1000064, "time": 31666.49067568779, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 1000064, "time": 31666.64003610611, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 1000064, "time": 31667.398894548416, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 1000064, "time": 31667.88534283638, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 1000064, "time": 31668.307706832886, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 1000064, "time": 31668.476679325104, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1000064, "time": 31668.77327132225, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 1000064, "time": 31670.503302812576, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1000144, "time": 31672.99113869667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1000152, "time": 31673.023128271103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1000232, "time": 31675.489550352097, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1000344, "time": 31678.924103975296, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1000416, "time": 31681.351182460785, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1000744, "time": 31691.16425180435, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1001248, "time": 31706.927983283997, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1001352, "time": 31709.891069173813, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1001392, "time": 31711.397171735764, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1001464, "time": 31713.387355804443, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1001480, "time": 31713.879720926285, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1001496, "time": 31714.37450528145, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1001840, "time": 31725.227644205093, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1002096, "time": 31733.11714577675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1002136, "time": 31734.119950532913, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1002160, "time": 31735.08515405655, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1002296, "time": 31739.05293917656, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1002464, "time": 31744.464948654175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1002656, "time": 31750.363208293915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1002696, "time": 31751.391243696213, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1002776, "time": 31753.995141983032, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1002776, "time": 31754.00332570076, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1002848, "time": 31756.450432300568, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1003256, "time": 31768.730775356293, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1003464, "time": 31775.111603736877, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1003640, "time": 31780.54954957962, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1003784, "time": 31785.10663843155, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1003832, "time": 31786.59899997711, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1003992, "time": 31791.524886846542, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1004192, "time": 31797.89536333084, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1004256, "time": 31799.849187850952, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1004408, "time": 31804.30328989029, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1004504, "time": 31807.270738601685, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1004520, "time": 31807.770422697067, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1004608, "time": 31810.70476770401, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1004832, "time": 31817.65602684021, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1004840, "time": 31817.683537721634, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1004968, "time": 31821.613223552704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1004984, "time": 31822.111778736115, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1005040, "time": 31824.05085992813, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1005224, "time": 31829.509369134903, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1005368, "time": 31833.94390273094, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1005384, "time": 31834.43679332733, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1005520, "time": 31838.823259830475, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1005776, "time": 31846.835139274597, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1006040, "time": 31854.737568616867, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 1006104, "time": 31856.69575858116, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1006136, "time": 31857.67342853546, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1006344, "time": 31864.077579975128, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1006448, "time": 31867.515514612198, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1006456, "time": 31867.54559993744, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1006624, "time": 31872.935757875443, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1006632, "time": 31872.963516950607, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1006696, "time": 31875.08491396904, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1006728, "time": 31876.064933538437, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1006792, "time": 31878.019269943237, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1007024, "time": 31885.3629219532, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1007136, "time": 31888.77476119995, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1007256, "time": 31892.242344141006, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1007640, "time": 31904.695996284485, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1007656, "time": 31905.187925577164, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1007944, "time": 31914.01728796959, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1008208, "time": 31922.31340765953, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1008376, "time": 31927.265533208847, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1008416, "time": 31928.720455408096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1008488, "time": 31930.7149207592, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1008568, "time": 31933.186172008514, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1008744, "time": 31938.672435998917, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1008760, "time": 31939.183432102203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1008768, "time": 31939.65500664711, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1008944, "time": 31945.053442001343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1008968, "time": 31945.568133831024, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1009168, "time": 31951.897921562195, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1009272, "time": 31954.87069630623, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1009344, "time": 31957.291956186295, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1009568, "time": 31964.361783981323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1009752, "time": 31969.781178236008, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1009816, "time": 31971.74963450432, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1009968, "time": 31976.647269248962, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1009984, "time": 31977.138154268265, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1009984, "time": 31977.145340681076, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1010048, "time": 31980.17851305008, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 1010048, "time": 31980.362584590912, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1010048, "time": 31980.60661458969, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1010048, "time": 31980.756701231003, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1010048, "time": 31981.293742895126, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 1010048, "time": 31981.72667980194, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1010048, "time": 31981.978565216064, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 1010048, "time": 31982.02485394478, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1010072, "time": 31982.538276910782, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1010232, "time": 31987.445345163345, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1010464, "time": 31994.901253700256, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1010472, "time": 31994.92973971367, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1010544, "time": 31997.39923453331, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1010560, "time": 31997.899015188217, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1010688, "time": 32001.837146759033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1010760, "time": 32003.81789445877, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1011144, "time": 32015.571017980576, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1011344, "time": 32021.944955825806, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1011384, "time": 32022.956449747086, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1011512, "time": 32027.05622124672, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1011624, "time": 32030.48527431488, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1011784, "time": 32035.37696003914, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1011824, "time": 32036.84993839264, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1011872, "time": 32038.316655397415, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1012112, "time": 32045.665533065796, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1012568, "time": 32059.560597658157, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1012784, "time": 32066.448035478592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1012856, "time": 32068.425785541534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1012896, "time": 32069.88486289978, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1012976, "time": 32072.3638112545, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1013072, "time": 32075.32126235962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1013160, "time": 32077.794862747192, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1013568, "time": 32090.641887664795, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1013824, "time": 32098.49449491501, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1013856, "time": 32099.47156715393, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1013904, "time": 32100.964505910873, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1014096, "time": 32106.885229587555, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1014240, "time": 32111.3206179142, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1014424, "time": 32116.857441663742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1014520, "time": 32119.810765028, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1014808, "time": 32128.684292793274, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1014888, "time": 32131.155539512634, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 1014912, "time": 32132.116044282913, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1015216, "time": 32141.42739534378, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1015352, "time": 32145.52930378914, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1015472, "time": 32149.440042495728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1015544, "time": 32151.42360019684, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1015560, "time": 32151.919315338135, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1015632, "time": 32154.369882822037, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1015816, "time": 32159.974373817444, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1015824, "time": 32160.743820667267, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1015824, "time": 32160.75100159645, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1016136, "time": 32170.13521552086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1016168, "time": 32171.120631694794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1016256, "time": 32174.177238702774, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1016288, "time": 32175.17715358734, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1016344, "time": 32176.666632652283, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1016568, "time": 32183.509532928467, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1016600, "time": 32184.51626253128, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1016672, "time": 32186.951192378998, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1016752, "time": 32189.426266908646, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1016776, "time": 32189.94568514824, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1017104, "time": 32200.2472717762, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1017216, "time": 32203.70648264885, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1017272, "time": 32205.32023358345, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1017416, "time": 32209.788086652756, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1017488, "time": 32212.229751825333, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1018088, "time": 32230.397491931915, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1018128, "time": 32231.84654688835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1018288, "time": 32236.883608579636, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 1018432, "time": 32241.311462402344, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1018480, "time": 32242.776528835297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1018528, "time": 32244.267330169678, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1018720, "time": 32250.15288376808, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1018960, "time": 32257.523464918137, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1019096, "time": 32261.508989095688, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1019176, "time": 32264.123015403748, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1019360, "time": 32270.01175260544, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1019416, "time": 32271.512010335922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1019528, "time": 32274.990233898163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1019576, "time": 32276.46573281288, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1019656, "time": 32278.95044374466, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1019728, "time": 32281.38587498665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1019760, "time": 32282.362768650055, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1019984, "time": 32289.227777004242, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1020032, "time": 32290.99053668976, "eval_episode/length": 13.0, "eval_episode/score": 0.9593750238418579, "eval_episode/reward_rate": 0.07142857142857142}
{"step": 1020032, "time": 32293.23854804039, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1020032, "time": 32293.385553836823, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1020032, "time": 32293.413571834564, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1020032, "time": 32293.66266989708, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1020032, "time": 32294.300485372543, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 1020032, "time": 32294.935726881027, "eval_episode/length": 168.0, "eval_episode/score": 0.4749999940395355, "eval_episode/reward_rate": 0.005917159763313609}
{"step": 1020032, "time": 32295.68419766426, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1020033, "time": 32296.301468133926, "train_stats/mean_log_entropy": 0.07850663848951751, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2700462149615266, "train/action_min": 0.0, "train/action_std": 1.6757474275090587, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011504826015423067, "train/actor_opt_grad_steps": 62660.0, "train/actor_opt_loss": -12.306765345323026, "train/adv_mag": 1.0285403821336565, "train/adv_max": 0.40402246420107896, "train/adv_mean": 0.002589463888484007, "train/adv_min": -0.9575427039783804, "train/adv_std": 0.03311046117907343, "train/cont_avg": 0.9949895964195979, "train/cont_loss_mean": 0.018159959672355848, "train/cont_loss_std": 0.23905433603941495, "train/cont_neg_acc": 0.2718852257459008, "train/cont_neg_loss": 2.8727228564336595, "train/cont_pos_acc": 0.999866851610155, "train/cont_pos_loss": 0.003922816327932155, "train/cont_pred": 0.9948230203072629, "train/cont_rate": 0.9949895964195979, "train/dyn_loss_mean": 1.000000534944199, "train/dyn_loss_std": 1.5214431830178394e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1438129358461604, "train/extr_critic_critic_opt_grad_steps": 62660.0, "train/extr_critic_critic_opt_loss": 7643.536154895572, "train/extr_critic_mag": 1.6012368549653633, "train/extr_critic_max": 1.6012368549653633, "train/extr_critic_mean": 1.5182316285281925, "train/extr_critic_min": 1.3119715380309216, "train/extr_critic_std": 0.02293482893637976, "train/extr_return_normed_mag": 1.039380554577813, "train/extr_return_normed_max": 0.43191483931325786, "train/extr_return_normed_mean": 0.04819808514723227, "train/extr_return_normed_min": -0.943126537092966, "train/extr_return_normed_std": 0.041596675338457574, "train/extr_return_rate": 0.9996964341432006, "train/extr_return_raw_mag": 1.9045377933799321, "train/extr_return_raw_max": 1.9045377933799321, "train/extr_return_raw_mean": 1.5208211280592723, "train/extr_return_raw_min": 0.5294964169737083, "train/extr_return_raw_std": 0.041596675329097554, "train/extr_reward_mag": 0.43493642998700166, "train/extr_reward_max": 0.43493642998700166, "train/extr_reward_mean": 0.002680346635919083, "train/extr_reward_min": 1.2759587273525833e-07, "train/extr_reward_std": 0.011535641875342657, "train/image_loss_mean": 0.08544299538111567, "train/image_loss_std": 0.09970388619519359, "train/model_loss_mean": 0.7167958479430807, "train/model_loss_std": 0.44284996285510425, "train/model_opt_grad_norm": 16.728767188949202, "train/model_opt_grad_steps": 62603.05527638191, "train/model_opt_loss": 3996.386242737123, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5577.889447236181, "train/policy_entropy_mag": 1.3041529691399043, "train/policy_entropy_max": 1.3041529691399043, "train/policy_entropy_mean": 0.09785247478053798, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12486163377013039, "train/policy_logprob_mag": 6.551080267633026, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09792240989867167, "train/policy_logprob_min": -6.551080267633026, "train/policy_logprob_std": 0.6364627522439813, "train/policy_randomness_mag": 0.6702020896140055, "train/policy_randomness_max": 0.6702020896140055, "train/policy_randomness_mean": 0.05028622694800248, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06416619009333639, "train/post_ent_mag": 63.75159753387298, "train/post_ent_max": 63.75159753387298, "train/post_ent_mean": 53.798583677665675, "train/post_ent_min": 46.15124780089412, "train/post_ent_std": 3.809786861266323, "train/prior_ent_mag": 62.938394287722794, "train/prior_ent_max": 62.938394287722794, "train/prior_ent_mean": 54.55031119878568, "train/prior_ent_min": 48.022164253733266, "train/prior_ent_std": 3.1661823730372904, "train/rep_loss_mean": 1.000000534944199, "train/rep_loss_std": 1.5214431830178394e-05, "train/reward_avg": 0.001845608063477405, "train/reward_loss_mean": 0.013192549931709116, "train/reward_loss_std": 0.20726258724450541, "train/reward_max_data": 0.7544440941594953, "train/reward_max_pred": 0.21020581854048687, "train/reward_neg_acc": 0.9997342756046123, "train/reward_neg_loss": 0.002409975302707516, "train/reward_pos_acc": 0.15484916641137986, "train/reward_pos_loss": 4.0747662642239275, "train/reward_pred": 0.0014437854807149975, "train/reward_rate": 0.002645061243718593, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.029585957527160645, "report/cont_loss_std": 0.3137943148612976, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.7705576419830322, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0038368895184248686, "report/cont_pred": 0.9960660338401794, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07112692296504974, "report/image_loss_std": 0.08689180761575699, "report/model_loss_mean": 0.7298591136932373, "report/model_loss_std": 0.6801413297653198, "report/post_ent_mag": 60.839046478271484, "report/post_ent_max": 60.839046478271484, "report/post_ent_mean": 53.35075378417969, "report/post_ent_min": 47.69103240966797, "report/post_ent_std": 2.8333585262298584, "report/prior_ent_mag": 60.7119140625, "report/prior_ent_max": 60.7119140625, "report/prior_ent_mean": 52.26054000854492, "report/prior_ent_min": 46.71320343017578, "report/prior_ent_std": 2.8221442699432373, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0041656494140625, "report/reward_loss_mean": 0.029146211221814156, "report/reward_loss_std": 0.35406750440597534, "report/reward_max_data": 0.859375, "report/reward_max_pred": 0.04234147071838379, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002136755036190152, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.611750602722168, "report/reward_pred": 0.0012055416591465473, "report/reward_rate": 0.005859375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.04070394113659859, "eval/cont_loss_std": 0.6380001902580261, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.579399108886719, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0032972984481602907, "eval/cont_pred": 0.9967623353004456, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.15032346546649933, "eval/image_loss_std": 0.15003275871276855, "eval/model_loss_mean": 0.7974616885185242, "eval/model_loss_std": 0.6977174282073975, "eval/post_ent_mag": 61.148406982421875, "eval/post_ent_max": 61.148406982421875, "eval/post_ent_mean": 53.15418243408203, "eval/post_ent_min": 46.72749710083008, "eval/post_ent_std": 3.1073696613311768, "eval/prior_ent_mag": 60.7119140625, "eval/prior_ent_max": 60.7119140625, "eval/prior_ent_mean": 51.89635467529297, "eval/prior_ent_min": 45.73497772216797, "eval/prior_ent_std": 3.093271493911743, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007873534923419356, "eval/reward_loss_mean": 0.006434280425310135, "eval/reward_loss_std": 0.1545054018497467, "eval/reward_max_data": 0.8062499761581421, "eval/reward_max_pred": 0.07478761672973633, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0016098502092063427, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.941826343536377, "eval/reward_pred": 0.0008529837941750884, "eval/reward_rate": 0.0009765625, "replay/size": 1000000.0, "replay/inserts": 31864.0, "replay/samples": 31856.0, "replay/insert_wait_avg": 1.3271124555093094e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.623485734748937e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6208.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1544559419769603e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2814998626708984e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1002.2677929401398, "timer/env.step_count": 3983.0, "timer/env.step_total": 39.97998356819153, "timer/env.step_frac": 0.039889522390927835, "timer/env.step_avg": 0.010037655929749317, "timer/env.step_min": 0.00794363021850586, "timer/env.step_max": 0.052510738372802734, "timer/replay._sample_count": 31856.0, "timer/replay._sample_total": 17.64354133605957, "timer/replay._sample_frac": 0.017603619970968504, "timer/replay._sample_avg": 0.0005538530052756018, "timer/replay._sample_min": 0.0004286766052246094, "timer/replay._sample_max": 0.012305498123168945, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4759.0, "timer/agent.policy_total": 52.19002318382263, "timer/agent.policy_frac": 0.052071934817663715, "timer/agent.policy_avg": 0.010966594491242411, "timer/agent.policy_min": 0.008908271789550781, "timer/agent.policy_max": 0.11671566963195801, "timer/dataset_train_count": 1991.0, "timer/dataset_train_total": 0.23410582542419434, "timer/dataset_train_frac": 0.0002335761231411496, "timer/dataset_train_avg": 0.00011758203185544668, "timer/dataset_train_min": 0.00010275840759277344, "timer/dataset_train_max": 0.00036454200744628906, "timer/agent.train_count": 1991.0, "timer/agent.train_total": 895.5144345760345, "timer/agent.train_frac": 0.89348818837035, "timer/agent.train_avg": 0.44978123283577826, "timer/agent.train_min": 0.4380018711090088, "timer/agent.train_max": 0.6818759441375732, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.49995946884155273, "timer/agent.report_frac": 0.0004988282297038878, "timer/agent.report_avg": 0.24997973442077637, "timer/agent.report_min": 0.22843647003173828, "timer/agent.report_max": 0.27152299880981445, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.00010919570922851562, "timer/dataset_eval_frac": 1.0894863628032126e-07, "timer/dataset_eval_avg": 0.00010919570922851562, "timer/dataset_eval_min": 0.00010919570922851562, "timer/dataset_eval_max": 0.00010919570922851562, "fps": 31.791383222983917}
{"step": 1020120, "time": 32299.03007364273, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1020200, "time": 32301.4737098217, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1020272, "time": 32303.922382116318, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1020456, "time": 32309.34813952446, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1020640, "time": 32315.23858332634, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1020744, "time": 32318.198646068573, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1020840, "time": 32321.185594558716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1020928, "time": 32324.26261997223, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1021400, "time": 32338.503150701523, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1021640, "time": 32345.863209486008, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1021736, "time": 32348.81531214714, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1021768, "time": 32349.79542541504, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 1021816, "time": 32351.261969804764, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1021888, "time": 32353.743327856064, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1021920, "time": 32354.81200861931, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 1021960, "time": 32355.817025899887, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1022056, "time": 32358.77956700325, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1022312, "time": 32366.631729841232, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1022376, "time": 32368.599984169006, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1022408, "time": 32369.591222286224, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1022432, "time": 32370.555668115616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1022544, "time": 32373.990596294403, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1022616, "time": 32375.971734523773, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1022784, "time": 32381.348841190338, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1022856, "time": 32383.362856388092, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1022864, "time": 32383.99392437935, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1022960, "time": 32386.942581176758, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1022976, "time": 32387.43926501274, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1023392, "time": 32400.266800642014, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1023472, "time": 32402.728860139847, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1023696, "time": 32409.591552734375, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1023736, "time": 32410.60333585739, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1023744, "time": 32411.078577280045, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1024128, "time": 32423.46934223175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1024184, "time": 32424.96875977516, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1024344, "time": 32429.87752556801, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1024472, "time": 32433.830425977707, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1024816, "time": 32444.76021504402, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1024840, "time": 32445.28080892563, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1025080, "time": 32452.694453954697, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1025272, "time": 32458.640189170837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1025352, "time": 32461.10255408287, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1025408, "time": 32463.059458494186, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1025520, "time": 32466.486747980118, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1025552, "time": 32467.4952917099, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1025704, "time": 32471.927223682404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1025968, "time": 32480.44944381714, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1025976, "time": 32480.478783369064, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1026128, "time": 32485.398619174957, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1026248, "time": 32488.853326797485, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1026464, "time": 32495.681971549988, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1026496, "time": 32496.668033123016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1026736, "time": 32504.17819404602, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1026872, "time": 32508.12738609314, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1026872, "time": 32508.14057302475, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1026984, "time": 32511.57047367096, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1027008, "time": 32512.55338692665, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1027320, "time": 32521.880992650986, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1027544, "time": 32528.736068725586, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1027664, "time": 32532.658289432526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1027712, "time": 32534.22886323929, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1027928, "time": 32540.614655017853, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1028256, "time": 32550.874783992767, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1028504, "time": 32558.276422023773, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1028616, "time": 32561.728070497513, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1028808, "time": 32567.739854097366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1028816, "time": 32568.214458227158, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1028824, "time": 32568.243215084076, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1029048, "time": 32575.18026828766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1029344, "time": 32584.60760831833, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1029368, "time": 32585.128868103027, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1029384, "time": 32585.62778878212, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1029712, "time": 32596.07255768776, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1029824, "time": 32599.506742477417, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1030016, "time": 32606.442618131638, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1030016, "time": 32606.45011305809, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1030016, "time": 32606.66681289673, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1030016, "time": 32606.789453029633, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1030016, "time": 32606.98487997055, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1030016, "time": 32607.09536576271, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1030016, "time": 32607.50791811943, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 1030016, "time": 32608.528676986694, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 1030016, "time": 32608.53812098503, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1030024, "time": 32608.5688495636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1030056, "time": 32609.575377464294, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1030176, "time": 32613.473162174225, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1030240, "time": 32615.45386648178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1030416, "time": 32620.840271234512, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1030512, "time": 32623.93015575409, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1030816, "time": 32633.282593488693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1030904, "time": 32635.778670072556, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1030928, "time": 32636.743945121765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1031016, "time": 32639.228791713715, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1031096, "time": 32641.691809415817, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1031112, "time": 32642.193464279175, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1031184, "time": 32644.66205382347, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1031224, "time": 32645.672245502472, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1031256, "time": 32646.65433740616, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1031280, "time": 32647.61918282509, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1031896, "time": 32666.421885490417, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1031912, "time": 32666.9141125679, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1032032, "time": 32670.812271356583, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1032080, "time": 32672.276522874832, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1032352, "time": 32681.12682747841, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1032472, "time": 32684.754992485046, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1032488, "time": 32685.250820159912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1032608, "time": 32689.15590929985, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1032896, "time": 32697.9762570858, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1033136, "time": 32705.35489296913, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1033176, "time": 32706.359364748, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1033248, "time": 32708.81495285034, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1033328, "time": 32711.261909246445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1033408, "time": 32713.811909675598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1033528, "time": 32717.302243947983, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1033544, "time": 32717.79744696617, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1033600, "time": 32719.753074407578, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1033648, "time": 32721.226211071014, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1033696, "time": 32722.684565782547, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1033736, "time": 32723.709884881973, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1034024, "time": 32732.520394802094, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1034064, "time": 32733.982486486435, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1034072, "time": 32734.010967493057, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1034120, "time": 32735.483905792236, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1034208, "time": 32738.41476392746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1034376, "time": 32743.334984779358, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1034440, "time": 32745.430173158646, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1034872, "time": 32758.652829647064, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1034960, "time": 32761.59660744667, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1035016, "time": 32763.111513853073, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1035128, "time": 32766.52555346489, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1035256, "time": 32770.45877337456, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1035376, "time": 32774.54092669487, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1035416, "time": 32775.54890823364, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1035448, "time": 32776.52839565277, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1035656, "time": 32782.955610990524, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1035744, "time": 32785.87907266617, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1035840, "time": 32788.86655449867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1035912, "time": 32790.863164424896, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1035944, "time": 32791.86410164833, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1036048, "time": 32795.319261312485, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1036224, "time": 32800.79180264473, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1036248, "time": 32801.31650185585, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1036384, "time": 32805.8736178875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1036424, "time": 32806.87842988968, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1036432, "time": 32807.374628305435, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1036648, "time": 32813.7792737484, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1036904, "time": 32821.641431331635, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1036960, "time": 32823.61285376549, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1037080, "time": 32827.0938911438, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1037168, "time": 32830.00141906738, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1037376, "time": 32836.49952197075, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1037424, "time": 32837.98405599594, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1037440, "time": 32838.47802448273, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1037712, "time": 32846.84384226799, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1037928, "time": 32853.21670079231, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1038192, "time": 32861.50837445259, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1038504, "time": 32870.97418951988, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1038512, "time": 32871.464007377625, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1038520, "time": 32871.49077439308, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1038696, "time": 32876.923696279526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1038736, "time": 32878.3742518425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1038752, "time": 32878.86540198326, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1038936, "time": 32884.296018600464, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1038992, "time": 32886.26098203659, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1039272, "time": 32894.72237086296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1039488, "time": 32901.582406282425, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1039552, "time": 32903.556537628174, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1039584, "time": 32904.54198265076, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1039664, "time": 32906.99898099899, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1039688, "time": 32907.52354097366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1040000, "time": 32918.47637915611, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 1040000, "time": 32918.98393726349, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1040000, "time": 32919.075592041016, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1040000, "time": 32919.48389983177, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1040000, "time": 32919.87429499626, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1040000, "time": 32920.1982524395, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 1040000, "time": 32920.28235030174, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 1040000, "time": 32920.78540921211, "eval_episode/length": 171.0, "eval_episode/score": 0.46562498807907104, "eval_episode/reward_rate": 0.005813953488372093}
{"step": 1040152, "time": 32925.33265900612, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1040232, "time": 32927.79225111008, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1040304, "time": 32930.23934173584, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1040408, "time": 32933.729244709015, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1040768, "time": 32945.05110669136, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1040776, "time": 32945.08090543747, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1040832, "time": 32947.0165207386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1040944, "time": 32950.47317504883, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1041008, "time": 32952.43461704254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1041208, "time": 32958.49616599083, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1041360, "time": 32963.41675782204, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1041464, "time": 32966.41243505478, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1041480, "time": 32966.91008114815, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1041536, "time": 32968.86737823486, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1041576, "time": 32969.89294576645, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1041672, "time": 32972.847005844116, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1041736, "time": 32974.83801841736, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1041920, "time": 32980.74582743645, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1041928, "time": 32980.77377128601, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1041936, "time": 32981.24515891075, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1042152, "time": 32987.76270198822, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1042240, "time": 32990.69036054611, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1042368, "time": 32994.62284755707, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1042416, "time": 32996.08862042427, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1042632, "time": 33002.49777507782, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1042760, "time": 33006.429503917694, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1043320, "time": 33023.69030213356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1043352, "time": 33024.67849564552, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1043360, "time": 33025.152681827545, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1043512, "time": 33029.579310655594, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1043760, "time": 33037.41804647446, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1044096, "time": 33047.84651994705, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1044192, "time": 33050.800060510635, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1044240, "time": 33052.27172660828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1044360, "time": 33055.74030685425, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1044464, "time": 33059.17654132843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1044552, "time": 33061.6386756897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1044864, "time": 33071.42925906181, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1044936, "time": 33073.43708539009, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1044968, "time": 33074.55986762047, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1044976, "time": 33075.031559467316, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1045040, "time": 33076.97374510765, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1045120, "time": 33079.42121076584, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1045672, "time": 33096.02006030083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1045744, "time": 33098.47897911072, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1045808, "time": 33100.45416498184, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1045920, "time": 33104.06636452675, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1045960, "time": 33105.079184770584, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1046032, "time": 33107.521057128906, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1046072, "time": 33108.52505302429, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1046072, "time": 33108.53217601776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1046464, "time": 33120.78701210022, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1046912, "time": 33134.63334441185, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1046976, "time": 33136.5916492939, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1047008, "time": 33137.59114933014, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1047016, "time": 33137.619257450104, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1047176, "time": 33142.50870537758, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1047664, "time": 33157.658037900925, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1047720, "time": 33159.147146224976, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1047920, "time": 33165.603167295456, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1047984, "time": 33167.572879076004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1047992, "time": 33167.60209298134, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1048008, "time": 33168.09216952324, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1048248, "time": 33175.42411351204, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1048344, "time": 33178.38580989838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1048384, "time": 33179.8363699913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1048520, "time": 33183.80038833618, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1048688, "time": 33189.68504071236, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1048704, "time": 33190.181017160416, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1048856, "time": 33194.729983091354, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1049056, "time": 33201.10548400879, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1049104, "time": 33202.60610342026, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1049128, "time": 33203.12855362892, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1049216, "time": 33206.05563092232, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1049264, "time": 33207.5663087368, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1049320, "time": 33209.07602119446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1049448, "time": 33213.04298186302, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1049640, "time": 33218.91495323181, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1049864, "time": 33225.92019748688, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1049928, "time": 33227.907571315765, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1050088, "time": 33234.27536773682, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1050088, "time": 33234.71192622185, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1050088, "time": 33234.74127078056, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1050088, "time": 33234.87632608414, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1050088, "time": 33235.18624186516, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1050088, "time": 33235.470261096954, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 1050088, "time": 33236.23115444183, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1050088, "time": 33236.51226902008, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1050232, "time": 33240.949338912964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1050416, "time": 33246.81333208084, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1050416, "time": 33246.82107877731, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1050528, "time": 33250.25910282135, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1050568, "time": 33251.26530623436, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1050816, "time": 33259.16996598244, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1051080, "time": 33267.035027980804, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1051224, "time": 33271.44748902321, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1051224, "time": 33271.45516991615, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1051368, "time": 33275.86067008972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1051472, "time": 33279.283193826675, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1051472, "time": 33279.291982889175, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1051576, "time": 33282.25090622902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1051888, "time": 33292.16510844231, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1052009, "time": 33296.76019144058, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.294039001464844, "train/action_min": 0.0, "train/action_std": 1.733516247868538, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013467733206925913, "train/actor_opt_grad_steps": 64655.0, "train/actor_opt_loss": -14.420263043642045, "train/adv_mag": 1.0879231482744216, "train/adv_max": 0.4330329769849777, "train/adv_mean": 0.0011312387129055424, "train/adv_min": -1.0110413295030594, "train/adv_std": 0.03965943090151995, "train/cont_avg": 0.9946435546875, "train/cont_loss_mean": 0.01977072167675942, "train/cont_loss_std": 0.2547622614633292, "train/cont_neg_acc": 0.24905592076480387, "train/cont_neg_loss": 3.010872455080971, "train/cont_pos_acc": 0.9999067708849907, "train/cont_pos_loss": 0.003928482015035115, "train/cont_pred": 0.9947694399952889, "train/cont_rate": 0.9946435546875, "train/dyn_loss_mean": 1.0000005745887757, "train/dyn_loss_std": 1.340438921488385e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2210767250880599, "train/extr_critic_critic_opt_grad_steps": 64655.0, "train/extr_critic_critic_opt_loss": 4383.234979248047, "train/extr_critic_mag": 1.6647435772418975, "train/extr_critic_max": 1.6647435772418975, "train/extr_critic_mean": 1.5702731335163116, "train/extr_critic_min": 1.3424523782730102, "train/extr_critic_std": 0.02610925312153995, "train/extr_return_normed_mag": 1.1137064462900161, "train/extr_return_normed_max": 0.48162834227085116, "train/extr_return_normed_mean": 0.05245664080604911, "train/extr_return_normed_min": -0.998229444026947, "train/extr_return_normed_std": 0.049703088626265525, "train/extr_return_rate": 0.999593134522438, "train/extr_return_raw_mag": 2.0005760312080385, "train/extr_return_raw_max": 2.0005760312080385, "train/extr_return_raw_mean": 1.5714043974876404, "train/extr_return_raw_min": 0.5207182449102402, "train/extr_return_raw_std": 0.04970308868214488, "train/extr_reward_mag": 0.4737731873989105, "train/extr_reward_max": 0.4737731873989105, "train/extr_reward_mean": 0.002720026636379771, "train/extr_reward_min": 1.6927719116210937e-07, "train/extr_reward_std": 0.013373896984849126, "train/image_loss_mean": 0.08508722310885787, "train/image_loss_std": 0.10001941036432982, "train/model_loss_mean": 0.7195112878084182, "train/model_loss_std": 0.4710524487495422, "train/model_opt_grad_norm": 16.65041586637497, "train/model_opt_grad_steps": 64596.19, "train/model_opt_loss": 3723.9629711914063, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5200.0, "train/policy_entropy_mag": 1.2977314376831055, "train/policy_entropy_max": 1.2977314376831055, "train/policy_entropy_mean": 0.09229726988822222, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11317975174635649, "train/policy_logprob_mag": 6.551080257892608, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0917618153616786, "train/policy_logprob_min": -6.551080257892608, "train/policy_logprob_std": 0.6278348681330681, "train/policy_randomness_mag": 0.6669020730257035, "train/policy_randomness_max": 0.6669020730257035, "train/policy_randomness_mean": 0.04743141582235694, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05816289037466049, "train/post_ent_mag": 63.62262729644775, "train/post_ent_max": 63.62262729644775, "train/post_ent_mean": 53.09544927597046, "train/post_ent_min": 44.875531311035154, "train/post_ent_std": 4.153182743787766, "train/prior_ent_mag": 63.24077127456665, "train/prior_ent_max": 63.24077127456665, "train/prior_ent_mean": 52.921204776763915, "train/prior_ent_min": 45.34772411346435, "train/prior_ent_std": 3.7072034847736357, "train/rep_loss_mean": 1.0000005745887757, "train/rep_loss_std": 1.340438921488385e-05, "train/reward_avg": 0.001987731933768373, "train/reward_loss_mean": 0.014652976379729808, "train/reward_loss_std": 0.22215166711248457, "train/reward_max_data": 0.7502500005811453, "train/reward_max_pred": 0.2089923018217087, "train/reward_neg_acc": 0.9998188999295234, "train/reward_neg_loss": 0.0025210654840338974, "train/reward_pos_acc": 0.11803166427849475, "train/reward_pos_loss": 4.234004380815316, "train/reward_pred": 0.0015037694509373977, "train/reward_rate": 0.0028857421875, "train_stats/mean_log_entropy": 0.0767325125050311, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.01848253794014454, "report/cont_loss_std": 0.23757606744766235, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 3.0436713695526123, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00363862793892622, "report/cont_pred": 0.9953811168670654, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08304749429225922, "report/image_loss_std": 0.10028113424777985, "report/model_loss_mean": 0.7238055467605591, "report/model_loss_std": 0.5853889584541321, "report/post_ent_mag": 66.22201538085938, "report/post_ent_max": 66.22201538085938, "report/post_ent_mean": 54.02954864501953, "report/post_ent_min": 43.715858459472656, "report/post_ent_std": 5.408712387084961, "report/prior_ent_mag": 66.5855484008789, "report/prior_ent_max": 66.5855484008789, "report/prior_ent_mean": 53.951812744140625, "report/prior_ent_min": 44.761070251464844, "report/prior_ent_std": 4.879500389099121, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0023559569381177425, "report/reward_loss_mean": 0.02227550558745861, "report/reward_loss_std": 0.31676340103149414, "report/reward_max_data": 0.7749999761581421, "report/reward_max_pred": 0.05711197853088379, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.002528073266148567, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.057870864868164, "report/reward_pred": 0.0013406978687271476, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.011517628096044064, "eval/cont_loss_std": 0.16256076097488403, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.588301420211792, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004518050700426102, "eval/cont_pred": 0.995468020439148, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1171032041311264, "eval/image_loss_std": 0.13158363103866577, "eval/model_loss_mean": 0.7351456880569458, "eval/model_loss_std": 0.28865084052085876, "eval/post_ent_mag": 65.49213409423828, "eval/post_ent_max": 65.49213409423828, "eval/post_ent_mean": 54.869998931884766, "eval/post_ent_min": 44.665374755859375, "eval/post_ent_std": 4.815515995025635, "eval/prior_ent_mag": 64.91658020019531, "eval/prior_ent_max": 64.91658020019531, "eval/prior_ent_mean": 54.706321716308594, "eval/prior_ent_min": 44.949310302734375, "eval/prior_ent_std": 4.412691116333008, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0006530761602334678, "eval/reward_loss_mean": 0.0065248021855950356, "eval/reward_loss_std": 0.1155717521905899, "eval/reward_max_data": 0.668749988079071, "eval/reward_max_pred": 0.04564809799194336, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0029206383042037487, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 3.69358491897583, "eval/reward_pred": 0.0015073647955432534, "eval/reward_rate": 0.0009765625, "replay/size": 1000000.0, "replay/inserts": 31976.0, "replay/samples": 31984.0, "replay/insert_wait_avg": 1.3082451542407415e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.57461104743656e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3952.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.238123608021601e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2069940567016602e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3607470989227, "timer/env.step_count": 3997.0, "timer/env.step_total": 40.33428907394409, "timer/env.step_frac": 0.040319743843323305, "timer/env.step_avg": 0.010091140623953988, "timer/env.step_min": 0.008079290390014648, "timer/env.step_max": 0.03956747055053711, "timer/replay._sample_count": 31984.0, "timer/replay._sample_total": 17.687906742095947, "timer/replay._sample_frac": 0.017681528182099733, "timer/replay._sample_avg": 0.000553023597489243, "timer/replay._sample_min": 0.00044608116149902344, "timer/replay._sample_max": 0.011762380599975586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4491.0, "timer/agent.policy_total": 48.9880895614624, "timer/agent.policy_frac": 0.04897042362320731, "timer/agent.policy_avg": 0.010908058241251926, "timer/agent.policy_min": 0.009202718734741211, "timer/agent.policy_max": 0.08506226539611816, "timer/dataset_train_count": 1999.0, "timer/dataset_train_total": 0.24033761024475098, "timer/dataset_train_frac": 0.00024025094041498282, "timer/dataset_train_avg": 0.00012022891958216657, "timer/dataset_train_min": 0.00010585784912109375, "timer/dataset_train_max": 0.0003750324249267578, "timer/agent.train_count": 1999.0, "timer/agent.train_total": 899.3688495159149, "timer/agent.train_frac": 0.8990445218128685, "timer/agent.train_avg": 0.4499093794476813, "timer/agent.train_min": 0.43973731994628906, "timer/agent.train_max": 0.6854453086853027, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47430992126464844, "timer/agent.report_frac": 0.00047413887704026965, "timer/agent.report_avg": 0.23715496063232422, "timer/agent.report_min": 0.23070812225341797, "timer/agent.report_max": 0.24360179901123047, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4809112548828125e-05, "timer/dataset_eval_frac": 3.479655979083109e-08, "timer/dataset_eval_avg": 3.4809112548828125e-05, "timer/dataset_eval_min": 3.4809112548828125e-05, "timer/dataset_eval_max": 3.4809112548828125e-05, "fps": 31.96390393384376}
{"step": 1052224, "time": 33303.34303474426, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1052256, "time": 33304.321330070496, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1052328, "time": 33306.30743932724, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1052424, "time": 33309.24261713028, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1052504, "time": 33311.72589159012, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1052536, "time": 33312.711148262024, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1052544, "time": 33313.1846883297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1052840, "time": 33322.09102058411, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1053008, "time": 33327.43227171898, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1053232, "time": 33334.33777785301, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1053320, "time": 33336.80199098587, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1053584, "time": 33345.21406507492, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1053592, "time": 33345.24266076088, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1053784, "time": 33351.10825419426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1053928, "time": 33355.50181269646, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1054144, "time": 33362.34294509888, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1054256, "time": 33365.78292679787, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1054256, "time": 33365.790551662445, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1054384, "time": 33369.73241686821, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1054568, "time": 33375.26752996445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1054672, "time": 33378.68936038017, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1054736, "time": 33380.63588762283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1054832, "time": 33383.57845425606, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1054856, "time": 33384.09826231003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1055096, "time": 33391.412009477615, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1055232, "time": 33395.797320365906, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1055256, "time": 33396.31807017326, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1055272, "time": 33396.81756067276, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1055544, "time": 33405.287031412125, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1055664, "time": 33409.17931509018, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1055824, "time": 33414.10687303543, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1055880, "time": 33415.60140442848, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1055944, "time": 33417.55565428734, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1056032, "time": 33420.48216819763, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1056144, "time": 33423.909875154495, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1056160, "time": 33424.404430150986, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1056840, "time": 33445.57881116867, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1056872, "time": 33446.565802812576, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1056968, "time": 33449.53582262993, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1056984, "time": 33450.03726005554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1057144, "time": 33454.999641656876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1057184, "time": 33456.44963812828, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1057360, "time": 33461.83180856705, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1057400, "time": 33462.85272669792, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1057576, "time": 33468.39517450333, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1057704, "time": 33472.29144668579, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1057888, "time": 33478.15019392967, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1057992, "time": 33481.08712506294, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1058192, "time": 33487.46539926529, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1058376, "time": 33492.91052031517, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1058568, "time": 33498.96229720116, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1058616, "time": 33500.42781019211, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1058904, "time": 33509.2059173584, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1058992, "time": 33512.126071453094, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1059152, "time": 33516.97643876076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1059304, "time": 33521.3809773922, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1059536, "time": 33528.83600401878, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1059672, "time": 33532.76572537422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1059712, "time": 33534.20772433281, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1059760, "time": 33535.66663336754, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1059816, "time": 33537.1718146801, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1060016, "time": 33543.52580690384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1060072, "time": 33546.016608953476, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 1060072, "time": 33546.31724333763, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1060072, "time": 33547.15788626671, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1060072, "time": 33547.239896297455, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1060072, "time": 33547.58835840225, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 1060072, "time": 33548.711317777634, "eval_episode/length": 182.0, "eval_episode/score": 0.4312500059604645, "eval_episode/reward_rate": 0.00546448087431694}
{"step": 1060072, "time": 33549.61754870415, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1060072, "time": 33550.271883010864, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1060120, "time": 33551.7711956501, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1060168, "time": 33553.256915807724, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1060232, "time": 33555.356987953186, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1060600, "time": 33566.667285203934, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1060680, "time": 33569.08614087105, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1060688, "time": 33569.55441856384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1060744, "time": 33571.04333329201, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1060920, "time": 33576.43706321716, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1060952, "time": 33577.41864681244, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1061008, "time": 33579.36660003662, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1061160, "time": 33583.935475587845, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1061624, "time": 33598.13407611847, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1061776, "time": 33603.00469851494, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1061776, "time": 33603.01285529137, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1061984, "time": 33609.37364721298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1062120, "time": 33613.32489013672, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1062248, "time": 33617.3661339283, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1062328, "time": 33619.8039560318, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1062520, "time": 33625.728595256805, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1062544, "time": 33626.68393230438, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1062784, "time": 33633.95101118088, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1062912, "time": 33637.855182647705, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1062912, "time": 33637.86274957657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1063160, "time": 33645.31385803223, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1063232, "time": 33647.72288894653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1063264, "time": 33648.70060682297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1063432, "time": 33653.633533000946, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1063544, "time": 33657.0694334507, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1063768, "time": 33663.87704205513, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1063888, "time": 33667.748721838, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1063944, "time": 33669.21867275238, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1063960, "time": 33669.727767944336, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1064264, "time": 33679.09322118759, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1064560, "time": 33688.37711548805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1064568, "time": 33688.40544915199, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1064608, "time": 33689.877974033356, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1064664, "time": 33691.373161792755, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1064720, "time": 33693.30924201012, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1064784, "time": 33695.28878593445, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1065032, "time": 33703.19204735756, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 1065128, "time": 33706.25573039055, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1065224, "time": 33709.20028471947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1065360, "time": 33713.64535212517, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1065440, "time": 33716.14837241173, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1065472, "time": 33717.145990133286, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1065864, "time": 33728.95721697807, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1065928, "time": 33730.9262740612, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1066136, "time": 33737.444256067276, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1066264, "time": 33741.364560604095, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1066328, "time": 33743.31817150116, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1066736, "time": 33756.02463054657, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1066880, "time": 33760.449586868286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1066920, "time": 33761.4509165287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1067096, "time": 33766.95191144943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1067104, "time": 33767.418098688126, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1067216, "time": 33770.84904026985, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1067440, "time": 33777.66800069809, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1067528, "time": 33780.128283023834, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1067544, "time": 33780.61802148819, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1067744, "time": 33786.99264883995, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1067952, "time": 33793.38748717308, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1067968, "time": 33794.02785515785, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1068224, "time": 33801.797483205795, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1068224, "time": 33801.805378198624, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1068408, "time": 33807.183579444885, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1068568, "time": 33812.08921909332, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1068624, "time": 33814.040691137314, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1068728, "time": 33816.99498772621, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1069144, "time": 33829.93290066719, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1069256, "time": 33833.39511847496, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1069344, "time": 33836.31684041023, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1069408, "time": 33838.29692387581, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1069664, "time": 33846.1227684021, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1069752, "time": 33848.60020685196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1070056, "time": 33858.01811480522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1070056, "time": 33859.22083282471, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1070056, "time": 33859.457594394684, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1070056, "time": 33859.69410467148, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1070056, "time": 33859.75966119766, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1070056, "time": 33859.92528963089, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1070056, "time": 33859.989991903305, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1070056, "time": 33860.217562913895, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1070056, "time": 33861.001616477966, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 1070112, "time": 33862.94510912895, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1070152, "time": 33863.96322917938, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1070296, "time": 33868.429480314255, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1070416, "time": 33872.33186984062, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1070440, "time": 33872.85295176506, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1070544, "time": 33876.27435874939, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1070744, "time": 33882.20967459679, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1071024, "time": 33891.140166044235, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1071032, "time": 33891.1684820652, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1071184, "time": 33896.03477573395, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1071272, "time": 33898.49404978752, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1071400, "time": 33902.42818903923, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1071456, "time": 33904.36214542389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1071568, "time": 33907.82236146927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1071616, "time": 33909.28756690025, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1071624, "time": 33909.31534576416, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1072056, "time": 33922.61621117592, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1072136, "time": 33925.06452250481, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1072144, "time": 33925.5342438221, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1072240, "time": 33928.47755789757, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1072376, "time": 33932.421597480774, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1072552, "time": 33937.80125117302, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1072832, "time": 33946.76954483986, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1072904, "time": 33948.73898553848, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1073056, "time": 33953.61638402939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1073056, "time": 33953.62539577484, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1073136, "time": 33956.07211589813, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1073552, "time": 33969.19796705246, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1073584, "time": 33970.17311358452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1073608, "time": 33970.68567800522, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1073800, "time": 33976.67931127548, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1074008, "time": 33983.00095582008, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1074024, "time": 33983.48994755745, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1074128, "time": 33986.88265323639, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1074352, "time": 33993.69362306595, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1074552, "time": 33999.53267478943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1074864, "time": 34009.45297169685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1074880, "time": 34009.94813990593, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1074992, "time": 34013.38864278793, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1075008, "time": 34013.88474535942, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1075072, "time": 34015.87386536598, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1075144, "time": 34017.83943772316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1075216, "time": 34020.25540137291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1075376, "time": 34025.11221456528, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1075384, "time": 34025.14069223404, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1075464, "time": 34027.55055427551, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1075576, "time": 34030.95670723915, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1075576, "time": 34030.96456718445, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1075832, "time": 34038.898260354996, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1076232, "time": 34051.00342750549, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1076248, "time": 34051.4949529171, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1076512, "time": 34059.70559620857, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1076664, "time": 34064.22039222717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1076824, "time": 34069.11823678017, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1076888, "time": 34071.06528568268, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1076928, "time": 34072.54100108147, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1076960, "time": 34073.52385687828, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1077288, "time": 34083.364842414856, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1077296, "time": 34083.83648490906, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1077336, "time": 34084.838785648346, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1077384, "time": 34086.3040766716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1077680, "time": 34095.711517095566, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1077688, "time": 34095.74138879776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1077904, "time": 34102.57228422165, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1078008, "time": 34105.51242852211, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1078280, "time": 34113.939767837524, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1078616, "time": 34124.38305020332, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1078824, "time": 34130.75308728218, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1078984, "time": 34135.65513372421, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1079088, "time": 34139.06540632248, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 1079160, "time": 34141.09888505936, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1079200, "time": 34142.55824327469, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1079896, "time": 34163.730461120605, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1080000, "time": 34167.145538806915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1080040, "time": 34169.594760894775, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 1080040, "time": 34170.28899908066, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1080040, "time": 34170.39811062813, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1080040, "time": 34170.99625277519, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1080040, "time": 34171.62699484825, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 1080040, "time": 34171.91692686081, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 1080040, "time": 34172.15191578865, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 1080040, "time": 34172.69898557663, "eval_episode/length": 187.0, "eval_episode/score": 0.4156250059604645, "eval_episode/reward_rate": 0.005319148936170213}
{"step": 1080056, "time": 34173.19105195999, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1080128, "time": 34175.62559700012, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1080216, "time": 34178.09287428856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1080592, "time": 34190.13372302055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1080696, "time": 34193.07831072807, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1081152, "time": 34207.349789619446, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1081296, "time": 34211.78903198242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1081400, "time": 34215.46504187584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1081664, "time": 34223.71401166916, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1081680, "time": 34224.20932126045, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1081744, "time": 34226.180592775345, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1081896, "time": 34230.591576337814, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1082208, "time": 34240.27914214134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1082224, "time": 34240.76879405975, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1082304, "time": 34243.20101523399, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1082312, "time": 34243.2302274704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1082368, "time": 34245.27243185043, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1082368, "time": 34245.279336452484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1082480, "time": 34248.6776907444, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1082648, "time": 34253.59404850006, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1082744, "time": 34256.55239510536, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1082816, "time": 34258.94993686676, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1082960, "time": 34263.34129476547, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1083224, "time": 34271.20872402191, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1083336, "time": 34274.788075208664, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1083616, "time": 34283.520565748215, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1083816, "time": 34289.375564575195, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1083928, "time": 34292.77875876427, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1084000, "time": 34295.20446443558, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1084025, "time": 34296.7711148262, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2441146850585936, "train/action_min": 0.0, "train/action_std": 1.720276756286621, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011529881216119975, "train/actor_opt_grad_steps": 66655.0, "train/actor_opt_loss": -15.314438374042512, "train/adv_mag": 1.1406139826774597, "train/adv_max": 0.33997807204723357, "train/adv_mean": 0.0005949604781562811, "train/adv_min": -1.0849278539419174, "train/adv_std": 0.03408815523609519, "train/cont_avg": 0.9943701171875, "train/cont_loss_mean": 0.02126227532280609, "train/cont_loss_std": 0.2621807871386409, "train/cont_neg_acc": 0.220084780305624, "train/cont_neg_loss": 3.0513352140784264, "train/cont_pos_acc": 0.9999018058180809, "train/cont_pos_loss": 0.00415065813518595, "train/cont_pred": 0.9946461617946625, "train/cont_rate": 0.9943701171875, "train/dyn_loss_mean": 1.0000015527009964, "train/dyn_loss_std": 4.965877858921885e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.18157396571710704, "train/extr_critic_critic_opt_grad_steps": 66655.0, "train/extr_critic_critic_opt_loss": 4245.865397949219, "train/extr_critic_mag": 1.664432601928711, "train/extr_critic_max": 1.664432601928711, "train/extr_critic_mean": 1.562303152680397, "train/extr_critic_min": 1.34382417678833, "train/extr_critic_std": 0.025510461498051883, "train/extr_return_normed_mag": 1.165970265865326, "train/extr_return_normed_max": 0.3936725574731827, "train/extr_return_normed_mean": 0.050199545016512276, "train/extr_return_normed_min": -1.0783508294820785, "train/extr_return_normed_std": 0.04385857059620321, "train/extr_return_rate": 0.9996725672483444, "train/extr_return_raw_mag": 1.9063710564374923, "train/extr_return_raw_max": 1.9063710564374923, "train/extr_return_raw_mean": 1.5628981292247772, "train/extr_return_raw_min": 0.43434766948223114, "train/extr_return_raw_std": 0.043858570670709016, "train/extr_reward_mag": 0.3971169835329056, "train/extr_reward_max": 0.3971169835329056, "train/extr_reward_mean": 0.0027043040667194874, "train/extr_reward_min": 1.4007091522216797e-07, "train/extr_reward_std": 0.011236306799110024, "train/image_loss_mean": 0.08585994943976402, "train/image_loss_std": 0.10086295843124389, "train/model_loss_mean": 0.7234141579270363, "train/model_loss_std": 0.4957995708286762, "train/model_opt_grad_norm": 15.932745661735535, "train/model_opt_grad_steps": 66594.295, "train/model_opt_loss": 3795.3525573730467, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5250.0, "train/policy_entropy_mag": 1.2934350901842118, "train/policy_entropy_max": 1.2934350901842118, "train/policy_entropy_mean": 0.0934456430003047, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11576325602829457, "train/policy_logprob_mag": 6.551080253124237, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09357786040753126, "train/policy_logprob_min": -6.551080253124237, "train/policy_logprob_std": 0.6321123757958412, "train/policy_randomness_mag": 0.664694187939167, "train/policy_randomness_max": 0.664694187939167, "train/policy_randomness_mean": 0.048021562825888396, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05949054822325706, "train/post_ent_mag": 66.4412020111084, "train/post_ent_max": 66.4412020111084, "train/post_ent_mean": 53.330913105010985, "train/post_ent_min": 43.016497974395755, "train/post_ent_std": 5.157724816799163, "train/prior_ent_mag": 67.14859849929809, "train/prior_ent_max": 67.14859849929809, "train/prior_ent_mean": 53.64228891372681, "train/prior_ent_min": 43.69460180282593, "train/prior_ent_std": 5.032106535434723, "train/rep_loss_mean": 1.0000015527009964, "train/rep_loss_std": 4.965877858921885e-05, "train/reward_avg": 0.0022517395071918146, "train/reward_loss_mean": 0.01629097623284906, "train/reward_loss_std": 0.23757492132717745, "train/reward_max_data": 0.7866874995827675, "train/reward_max_pred": 0.20811086416244506, "train/reward_neg_acc": 0.9997109282016754, "train/reward_neg_loss": 0.0027471270246314816, "train/reward_pos_acc": 0.1052442016509863, "train/reward_pos_loss": 4.181220775078504, "train/reward_pred": 0.0016200337611371651, "train/reward_rate": 0.0032373046875, "train_stats/mean_log_entropy": 0.07843437783109646, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.014993015676736832, "report/cont_loss_std": 0.1907377988100052, "report/cont_neg_acc": 0.625, "report/cont_neg_loss": 1.3247079849243164, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004680299665778875, "report/cont_pred": 0.9904900789260864, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10210327059030533, "report/image_loss_std": 0.10883966833353043, "report/model_loss_mean": 0.7355995178222656, "report/model_loss_std": 0.46804025769233704, "report/post_ent_mag": 64.3091812133789, "report/post_ent_max": 64.3091812133789, "report/post_ent_mean": 52.44544982910156, "report/post_ent_min": 43.256011962890625, "report/post_ent_std": 4.438780784606934, "report/prior_ent_mag": 67.420654296875, "report/prior_ent_max": 67.420654296875, "report/prior_ent_mean": 53.274314880371094, "report/prior_ent_min": 43.994720458984375, "report/prior_ent_std": 4.772724628448486, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0034332275390625, "report/reward_loss_mean": 0.018503230065107346, "report/reward_loss_std": 0.24891893565654755, "report/reward_max_data": 0.8374999761581421, "report/reward_max_pred": 0.5944533348083496, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002862484659999609, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.6722164154052734, "report/reward_pred": 0.002864910289645195, "report/reward_rate": 0.005859375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.016892746090888977, "eval/cont_loss_std": 0.2934750020503998, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.564762115478516, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004078911151736975, "eval/cont_pred": 0.9959697723388672, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11498026549816132, "eval/image_loss_std": 0.12452028691768646, "eval/model_loss_mean": 0.7491238117218018, "eval/model_loss_std": 0.6611248850822449, "eval/post_ent_mag": 64.54932403564453, "eval/post_ent_max": 64.54932403564453, "eval/post_ent_mean": 52.002174377441406, "eval/post_ent_min": 41.81427764892578, "eval/post_ent_std": 4.9245147705078125, "eval/prior_ent_mag": 67.57759094238281, "eval/prior_ent_max": 67.57759094238281, "eval/prior_ent_mean": 52.819828033447266, "eval/prior_ent_min": 42.53961181640625, "eval/prior_ent_std": 5.107719898223877, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0011199951404705644, "eval/reward_loss_mean": 0.01725071482360363, "eval/reward_loss_std": 0.34348800778388977, "eval/reward_max_data": 0.65625, "eval/reward_max_pred": 0.03589355945587158, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002130619715899229, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.743618965148926, "eval/reward_pred": 0.001031121239066124, "eval/reward_rate": 0.001953125, "replay/size": 1000000.0, "replay/inserts": 32016.0, "replay/samples": 32016.0, "replay/insert_wait_avg": 1.3193075565145589e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.431221197987127e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4776.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.188498645571608e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.519918441772461e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0549695491791, "timer/env.step_count": 4002.0, "timer/env.step_total": 40.36276459693909, "timer/env.step_frac": 0.04036054599592107, "timer/env.step_avg": 0.010085648325072236, "timer/env.step_min": 0.00811147689819336, "timer/env.step_max": 0.03695869445800781, "timer/replay._sample_count": 32016.0, "timer/replay._sample_total": 17.745854139328003, "timer/replay._sample_frac": 0.017744878711345002, "timer/replay._sample_avg": 0.0005542808014532734, "timer/replay._sample_min": 0.00042510032653808594, "timer/replay._sample_max": 0.012420892715454102, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4599.0, "timer/agent.policy_total": 50.81414222717285, "timer/agent.policy_frac": 0.050811349150216886, "timer/agent.policy_avg": 0.011048954604734257, "timer/agent.policy_min": 0.009080171585083008, "timer/agent.policy_max": 0.134232759475708, "timer/dataset_train_count": 2001.0, "timer/dataset_train_total": 0.24276304244995117, "timer/dataset_train_frac": 0.0002427496986084553, "timer/dataset_train_avg": 0.0001213208607945783, "timer/dataset_train_min": 0.00010514259338378906, "timer/dataset_train_max": 0.0004608631134033203, "timer/agent.train_count": 2001.0, "timer/agent.train_total": 895.9886131286621, "timer/agent.train_frac": 0.8959393637457452, "timer/agent.train_avg": 0.44777042135365425, "timer/agent.train_min": 0.4357888698577881, "timer/agent.train_max": 0.8114302158355713, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4789259433746338, "timer/agent.report_frac": 0.000478899618478504, "timer/agent.report_avg": 0.2394629716873169, "timer/agent.report_min": 0.23113369941711426, "timer/agent.report_max": 0.24779224395751953, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.17079280499975e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 32.01365554751119}
{"step": 1084368, "time": 34307.33151888847, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1084536, "time": 34312.23435115814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1084680, "time": 34316.643568992615, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1084680, "time": 34316.6539645195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1084768, "time": 34319.58442759514, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1084792, "time": 34320.09958958626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1084832, "time": 34321.54008221626, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1084896, "time": 34323.48679065704, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1085056, "time": 34328.358718156815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1085120, "time": 34330.33365726471, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1085160, "time": 34331.34237527847, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1085520, "time": 34342.71994948387, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1085568, "time": 34344.192259311676, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1085816, "time": 34351.487840652466, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1085952, "time": 34355.83726143837, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1086328, "time": 34367.16925263405, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1086760, "time": 34380.330869197845, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1086760, "time": 34380.336647987366, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1086992, "time": 34387.62383365631, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1087104, "time": 34391.00458359718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1087144, "time": 34392.00312542915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1087472, "time": 34402.384286642075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1087664, "time": 34408.24643135071, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1087880, "time": 34414.61862564087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1088104, "time": 34421.431864738464, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1088512, "time": 34434.219361782074, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1088640, "time": 34438.10661315918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1088720, "time": 34440.52987766266, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1088976, "time": 34448.3302397728, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1089072, "time": 34451.27162671089, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1089072, "time": 34451.278649806976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1089240, "time": 34456.32519698143, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1089304, "time": 34458.27486991882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1089416, "time": 34461.70316839218, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1089488, "time": 34464.15824222565, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1089504, "time": 34464.65008711815, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1089544, "time": 34465.8472135067, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1089784, "time": 34473.48883032799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1090024, "time": 34481.29241466522, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 1090024, "time": 34482.19122123718, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1090024, "time": 34482.830991983414, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1090024, "time": 34483.23122930527, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1090024, "time": 34483.42320179939, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 1090024, "time": 34484.58263587952, "eval_episode/length": 166.0, "eval_episode/score": 0.48124998807907104, "eval_episode/reward_rate": 0.005988023952095809}
{"step": 1090024, "time": 34484.99486064911, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1090024, "time": 34485.622249126434, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 1090088, "time": 34487.58735370636, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1090240, "time": 34492.45369410515, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1090584, "time": 34502.72201871872, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1090824, "time": 34510.05480647087, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 1090832, "time": 34510.55100560188, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1090952, "time": 34514.164937734604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1091000, "time": 34515.66208577156, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1091176, "time": 34521.04936289787, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1091200, "time": 34522.013931035995, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1091200, "time": 34522.020114421844, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1091232, "time": 34523.00698542595, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1091376, "time": 34527.44787859917, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1091424, "time": 34528.91655445099, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1091816, "time": 34540.72349333763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1091952, "time": 34545.234815359116, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1092096, "time": 34549.61659550667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1092240, "time": 34554.01852154732, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1092336, "time": 34556.95559334755, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1092792, "time": 34570.672815322876, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1093264, "time": 34585.39995217323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1093288, "time": 34585.910954236984, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1093512, "time": 34592.74130606651, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1093512, "time": 34592.748889923096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1093560, "time": 34594.23013877869, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1093688, "time": 34598.13351416588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1093888, "time": 34604.674639225006, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1093968, "time": 34607.10898709297, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1094128, "time": 34612.05723309517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1094240, "time": 34615.46919465065, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1094264, "time": 34615.980550050735, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 1094424, "time": 34620.83958697319, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1094512, "time": 34623.76244020462, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1094736, "time": 34630.57108807564, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1094808, "time": 34632.548531770706, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1094904, "time": 34635.647250175476, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1094928, "time": 34636.60365462303, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1095008, "time": 34639.05508542061, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1095200, "time": 34644.89285683632, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1095304, "time": 34647.85051202774, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1095376, "time": 34650.31659078598, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1095824, "time": 34664.0936832428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1095832, "time": 34664.1222679615, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1095944, "time": 34667.55021953583, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1096072, "time": 34671.491248607635, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1096232, "time": 34676.38064074516, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1096312, "time": 34678.839700460434, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1096312, "time": 34678.845839977264, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1096608, "time": 34688.16155385971, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1096680, "time": 34690.13873553276, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1096720, "time": 34691.57241511345, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1096824, "time": 34694.6672873497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1096936, "time": 34698.08275294304, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1097048, "time": 34701.4898724556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1097048, "time": 34701.49793744087, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1097176, "time": 34705.419313669205, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1097296, "time": 34709.32443237305, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1097576, "time": 34717.65287041664, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1097624, "time": 34719.10898208618, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1097784, "time": 34724.62051296234, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1097800, "time": 34725.115100860596, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1097920, "time": 34729.03620839119, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1097960, "time": 34730.04536819458, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1098280, "time": 34739.827471256256, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1098384, "time": 34743.22856283188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1098728, "time": 34753.588675022125, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1098776, "time": 34755.1749958992, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1098784, "time": 34755.64481592178, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1098904, "time": 34759.072477817535, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1098920, "time": 34759.56039786339, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1099040, "time": 34763.44451332092, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1099400, "time": 34774.29935145378, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1099576, "time": 34779.64403915405, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1099640, "time": 34781.613473176956, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1099880, "time": 34789.04960370064, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1099936, "time": 34790.985003471375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1100008, "time": 34793.94609498978, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 1100008, "time": 34794.22874045372, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 1100008, "time": 34794.61333346367, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1100008, "time": 34794.83021688461, "eval_episode/length": 9.0, "eval_episode/score": 0.971875011920929, "eval_episode/reward_rate": 0.1}
{"step": 1100008, "time": 34794.9001955986, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 1100008, "time": 34795.8531897068, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 1100008, "time": 34796.08744454384, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 1100008, "time": 34796.244245290756, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1100160, "time": 34801.106734752655, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1100336, "time": 34806.478949546814, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1100480, "time": 34810.87854909897, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1100592, "time": 34814.43857908249, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1100984, "time": 34826.14836859703, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1101088, "time": 34829.5495929718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1101096, "time": 34829.578968048096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1101264, "time": 34834.91341280937, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1101352, "time": 34837.357902765274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1101800, "time": 34851.182446956635, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1101808, "time": 34851.65366625786, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1101824, "time": 34852.145206689835, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1102008, "time": 34857.55144190788, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1102104, "time": 34860.5289311409, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1102248, "time": 34864.960417985916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1102344, "time": 34867.88145494461, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1102400, "time": 34869.83382034302, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1102472, "time": 34871.824694633484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1102544, "time": 34874.38909840584, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1102672, "time": 34878.28992128372, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1102904, "time": 34885.11471962929, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1103200, "time": 34894.37123250961, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1103216, "time": 34894.8628320694, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1103232, "time": 34895.351375579834, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1103384, "time": 34899.75390911102, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1103536, "time": 34904.74120807648, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1103640, "time": 34907.70574784279, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1104120, "time": 34922.3736243248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1104376, "time": 34930.200845479965, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 1104408, "time": 34931.171553850174, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1104416, "time": 34931.63889169693, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1104480, "time": 34933.6204931736, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1104512, "time": 34934.68830919266, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1104560, "time": 34936.155000686646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1104640, "time": 34938.58814525604, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1104680, "time": 34939.58622598648, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1104984, "time": 34948.846088171005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1105192, "time": 34955.22066283226, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1105200, "time": 34955.69317007065, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1105216, "time": 34956.183324575424, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1105360, "time": 34960.573132276535, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1105544, "time": 34966.08906126022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1105648, "time": 34969.507041692734, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1105800, "time": 34973.96260070801, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1105880, "time": 34976.41362166405, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1105912, "time": 34977.39721870422, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1106088, "time": 34983.28331685066, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1106160, "time": 34985.71534705162, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1106224, "time": 34987.67873597145, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1106680, "time": 35001.558080911636, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1106712, "time": 35002.547364234924, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1106928, "time": 35009.41664028168, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1107000, "time": 35011.424986600876, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1107296, "time": 35020.70345520973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1107304, "time": 35020.73264288902, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1107384, "time": 35023.21020627022, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1107504, "time": 35027.25378847122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1107688, "time": 35032.64510679245, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1107856, "time": 35037.981659173965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1107872, "time": 35038.47519874573, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1108096, "time": 35045.31974506378, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1108136, "time": 35046.336755275726, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1108328, "time": 35052.22237443924, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1108632, "time": 35061.67466878891, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1108664, "time": 35062.65884947777, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1108800, "time": 35067.03852200508, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1108992, "time": 35072.914137125015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1109040, "time": 35074.384029626846, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1109240, "time": 35080.30106139183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1109368, "time": 35084.29605174065, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1109408, "time": 35085.755123615265, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1109648, "time": 35093.043149232864, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1109696, "time": 35094.50569438934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1109744, "time": 35095.98358511925, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1109872, "time": 35099.91332101822, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1109952, "time": 35102.37552309036, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1110096, "time": 35108.316210746765, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1110096, "time": 35108.75913691521, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1110096, "time": 35109.10796523094, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1110096, "time": 35109.623036623, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 1110096, "time": 35109.65123915672, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1110096, "time": 35109.720611810684, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 1110096, "time": 35110.35234475136, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1110096, "time": 35111.112447977066, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1110184, "time": 35113.65158677101, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1110272, "time": 35116.709109544754, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1110312, "time": 35117.71372675896, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1110400, "time": 35120.66143965721, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1110656, "time": 35128.495341300964, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1110992, "time": 35138.84552717209, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1111112, "time": 35142.333173274994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1111408, "time": 35151.75026130676, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1111664, "time": 35159.621443510056, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1111720, "time": 35161.113283872604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1112184, "time": 35175.39990448952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1112464, "time": 35184.187588214874, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1112496, "time": 35185.16782307625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1112584, "time": 35187.67272019386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1112928, "time": 35198.369159698486, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1113304, "time": 35209.63920068741, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1113400, "time": 35212.579291820526, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1113424, "time": 35213.53468513489, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1113488, "time": 35215.46422624588, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1113624, "time": 35219.36309313774, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1113720, "time": 35222.27991747856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1114032, "time": 35231.908601522446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1114320, "time": 35241.2506673336, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1114344, "time": 35241.76611638069, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1114480, "time": 35246.11211395264, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1114496, "time": 35246.60010623932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1114664, "time": 35251.53932452202, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1114776, "time": 35254.9724752903, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1114808, "time": 35255.96685242653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1114992, "time": 35261.7938041687, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1115192, "time": 35267.74025416374, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1115256, "time": 35269.68978738785, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1115296, "time": 35271.12219333649, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1115560, "time": 35278.9621694088, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1115808, "time": 35286.737674474716, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1115824, "time": 35287.23084330559, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1115896, "time": 35289.188134908676, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1115936, "time": 35290.63808441162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1116121, "time": 35297.30211138725, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1991000199199315, "train/action_min": 0.0, "train/action_std": 1.6803981575799818, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010902339862474235, "train/actor_opt_grad_steps": 68660.0, "train/actor_opt_loss": -16.268436107469434, "train/adv_mag": 0.9993200121234306, "train/adv_max": 0.3005380731316941, "train/adv_mean": -0.00038134817625394866, "train/adv_min": -0.9574362694920592, "train/adv_std": 0.030712625739252687, "train/cont_avg": 0.9944272776741293, "train/cont_loss_mean": 0.02163667014257899, "train/cont_loss_std": 0.2632302819236891, "train/cont_neg_acc": 0.21159283412777963, "train/cont_neg_loss": 3.077121301373439, "train/cont_pos_acc": 0.9998925331220105, "train/cont_pos_loss": 0.0044275648655620085, "train/cont_pred": 0.9944487996955416, "train/cont_rate": 0.9944272776741293, "train/dyn_loss_mean": 1.0000068109426925, "train/dyn_loss_std": 0.00018930448849328714, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15029926661086912, "train/extr_critic_critic_opt_grad_steps": 68660.0, "train/extr_critic_critic_opt_loss": 4932.95457648282, "train/extr_critic_mag": 1.6605349452934455, "train/extr_critic_max": 1.6605349452934455, "train/extr_critic_mean": 1.5525586462732572, "train/extr_critic_min": 1.3068277497789753, "train/extr_critic_std": 0.023665901115951845, "train/extr_return_normed_mag": 1.0255744623307566, "train/extr_return_normed_max": 0.33222086809167817, "train/extr_return_normed_mean": 0.045099513364297836, "train/extr_return_normed_min": -0.9476485359134958, "train/extr_return_normed_std": 0.040195783711413836, "train/extr_return_rate": 0.9996822864855107, "train/extr_return_raw_mag": 1.8392985928711014, "train/extr_return_raw_max": 1.8392985928711014, "train/extr_return_raw_mean": 1.552177324223874, "train/extr_return_raw_min": 0.5594291888659273, "train/extr_return_raw_std": 0.04019578377628208, "train/extr_reward_mag": 0.32134575155837025, "train/extr_reward_max": 0.32134575155837025, "train/extr_reward_mean": 0.002575610069886999, "train/extr_reward_min": 1.3344323457177004e-07, "train/extr_reward_std": 0.0097071602291877, "train/image_loss_mean": 0.08605459970028247, "train/image_loss_std": 0.10203198417650526, "train/model_loss_mean": 0.7244237240274154, "train/model_loss_std": 0.4989309402099296, "train/model_opt_grad_norm": 15.310544082774452, "train/model_opt_grad_steps": 68597.30845771145, "train/model_opt_loss": 3622.1186244072605, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5024.875621890547, "train/policy_entropy_mag": 1.2675456419513, "train/policy_entropy_max": 1.2675456419513, "train/policy_entropy_mean": 0.0933338010414916, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11510096579345304, "train/policy_logprob_mag": 6.551080283833973, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09308059502448608, "train/policy_logprob_min": -6.551080283833973, "train/policy_logprob_std": 0.6290141355932055, "train/policy_randomness_mag": 0.6513896427344327, "train/policy_randomness_max": 0.6513896427344327, "train/policy_randomness_mean": 0.04796408800714051, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05915019885446895, "train/post_ent_mag": 65.63024171667905, "train/post_ent_max": 65.63024171667905, "train/post_ent_mean": 52.67729114893064, "train/post_ent_min": 42.35336745912163, "train/post_ent_std": 5.226735170800888, "train/prior_ent_mag": 65.61871810457599, "train/prior_ent_max": 65.61871810457599, "train/prior_ent_mean": 52.62548266358637, "train/prior_ent_min": 42.97549880677788, "train/prior_ent_std": 4.970164629950452, "train/rep_loss_mean": 1.0000068109426925, "train/rep_loss_std": 0.00018930448849328714, "train/reward_avg": 0.002220556163330405, "train/reward_loss_mean": 0.01672834477535639, "train/reward_loss_std": 0.24026401616883145, "train/reward_max_data": 0.7693252496013594, "train/reward_max_pred": 0.204057243332934, "train/reward_neg_acc": 0.9997220605760071, "train/reward_neg_loss": 0.0029810743773615554, "train/reward_pos_acc": 0.12227106369458712, "train/reward_pos_loss": 4.1659366543476395, "train/reward_pred": 0.0017162954327024852, "train/reward_rate": 0.0032649253731343282, "train_stats/mean_log_entropy": 0.07788387042704133, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.023302976042032242, "report/cont_loss_std": 0.2924042344093323, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.093122959136963, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003333302214741707, "report/cont_pred": 0.9966076612472534, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08588465303182602, "report/image_loss_std": 0.11146588623523712, "report/model_loss_mean": 0.735785722732544, "report/model_loss_std": 0.6807067394256592, "report/post_ent_mag": 67.48489379882812, "report/post_ent_max": 67.48489379882812, "report/post_ent_mean": 52.882118225097656, "report/post_ent_min": 40.34735107421875, "report/post_ent_std": 6.159284591674805, "report/prior_ent_mag": 67.2022933959961, "report/prior_ent_max": 67.2022933959961, "report/prior_ent_mean": 51.014373779296875, "report/prior_ent_min": 38.235687255859375, "report/prior_ent_std": 6.032609462738037, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.003396606305614114, "report/reward_loss_mean": 0.026598023250699043, "report/reward_loss_std": 0.35390034317970276, "report/reward_max_data": 0.8656250238418579, "report/reward_max_pred": 0.055354952812194824, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0023998913820832968, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.95817756652832, "report/reward_pred": 0.0012672035954892635, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020462488755583763, "eval/cont_loss_std": 0.34427765011787415, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.8677825927734375, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003281332552433014, "eval/cont_pred": 0.9967234134674072, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10621660947799683, "eval/image_loss_std": 0.11294671148061752, "eval/model_loss_mean": 0.7395033836364746, "eval/model_loss_std": 0.5486477017402649, "eval/post_ent_mag": 68.7550048828125, "eval/post_ent_max": 68.7550048828125, "eval/post_ent_mean": 55.04369354248047, "eval/post_ent_min": 41.12724304199219, "eval/post_ent_std": 6.604213237762451, "eval/prior_ent_mag": 67.98797607421875, "eval/prior_ent_max": 67.98797607421875, "eval/prior_ent_mean": 53.234214782714844, "eval/prior_ent_min": 40.107398986816406, "eval/prior_ent_std": 6.7732062339782715, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0017730712424963713, "eval/reward_loss_mean": 0.012824255041778088, "eval/reward_loss_std": 0.2502521574497223, "eval/reward_max_data": 0.9750000238418579, "eval/reward_max_pred": 0.021759867668151855, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0018566905055195093, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.617249965667725, "eval/reward_pred": 0.000972102046944201, "eval/reward_rate": 0.001953125, "replay/size": 1000000.0, "replay/inserts": 32096.0, "replay/samples": 32096.0, "replay/insert_wait_avg": 1.3405028154937957e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.486899299849779e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4560.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2195424029701634e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.437319278717, "timer/env.step_count": 4012.0, "timer/env.step_total": 40.85357093811035, "timer/env.step_frac": 0.04083571269368925, "timer/env.step_avg": 0.010182844201921823, "timer/env.step_min": 0.00791621208190918, "timer/env.step_max": 0.04893994331359863, "timer/replay._sample_count": 32096.0, "timer/replay._sample_total": 17.807294368743896, "timer/replay._sample_frac": 0.0177995102997381, "timer/replay._sample_avg": 0.0005548135084977535, "timer/replay._sample_min": 0.00039458274841308594, "timer/replay._sample_max": 0.012512445449829102, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4582.0, "timer/agent.policy_total": 50.86053919792175, "timer/agent.policy_frac": 0.050838306626336725, "timer/agent.policy_avg": 0.011100074028354813, "timer/agent.policy_min": 0.009527206420898438, "timer/agent.policy_max": 0.08511042594909668, "timer/dataset_train_count": 2006.0, "timer/dataset_train_total": 0.24532318115234375, "timer/dataset_train_frac": 0.00024521594349280555, "timer/dataset_train_avg": 0.00012229470645680148, "timer/dataset_train_min": 0.00010442733764648438, "timer/dataset_train_max": 0.00037932395935058594, "timer/agent.train_count": 2006.0, "timer/agent.train_total": 895.8542740345001, "timer/agent.train_frac": 0.8954626709451243, "timer/agent.train_avg": 0.44658737489257233, "timer/agent.train_min": 0.43521714210510254, "timer/agent.train_max": 0.6873762607574463, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4780595302581787, "timer/agent.report_frac": 0.00047785055699725815, "timer/agent.report_avg": 0.23902976512908936, "timer/agent.report_min": 0.23160171508789062, "timer/agent.report_max": 0.24645781517028809, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.504753112792969e-05, "timer/dataset_eval_frac": 3.5032210866741584e-08, "timer/dataset_eval_avg": 3.504753112792969e-05, "timer/dataset_eval_min": 3.504753112792969e-05, "timer/dataset_eval_max": 3.504753112792969e-05, "fps": 32.0813121379083}
{"step": 1116152, "time": 35297.984156131744, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1116656, "time": 35313.73412108421, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1116696, "time": 35314.75238728523, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1116808, "time": 35318.20618748665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1117192, "time": 35330.01884388924, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1117304, "time": 35333.48659324646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1117464, "time": 35338.35777640343, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1117680, "time": 35345.18088054657, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1118120, "time": 35358.4431643486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1118128, "time": 35358.91320204735, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 1118136, "time": 35358.941967487335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1118136, "time": 35358.94938111305, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1118248, "time": 35362.37491083145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1118440, "time": 35368.21654009819, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1118736, "time": 35377.488324165344, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1118912, "time": 35382.91058421135, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1118920, "time": 35382.94227409363, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1118952, "time": 35384.05116271973, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1118968, "time": 35384.54470396042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1118976, "time": 35385.017035245895, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1119264, "time": 35393.771589040756, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1119616, "time": 35404.49490857124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1119656, "time": 35405.51045250893, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1120080, "time": 35419.2235019207, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 1120080, "time": 35419.81190395355, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1120080, "time": 35423.69602584839, "eval_episode/length": 249.0, "eval_episode/score": 0.22187499701976776, "eval_episode/reward_rate": 0.004}
{"step": 1120080, "time": 35425.077100515366, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1120080, "time": 35425.084859371185, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1120080, "time": 35425.09314966202, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1120080, "time": 35425.10269117355, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1120080, "time": 35425.11029744148, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1120440, "time": 35435.83748626709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1120912, "time": 35450.58432817459, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 1121224, "time": 35459.83029079437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1121280, "time": 35461.78817677498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1121288, "time": 35461.81762313843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1121576, "time": 35470.56944537163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1121856, "time": 35479.400725364685, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1121928, "time": 35481.38368153572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1121968, "time": 35482.820548295975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1122216, "time": 35490.159896850586, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1122552, "time": 35500.867872953415, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1122704, "time": 35505.856087207794, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1122752, "time": 35507.32108044624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1123240, "time": 35521.95504760742, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1123536, "time": 35531.219876766205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1123592, "time": 35532.70728516579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1123600, "time": 35533.18229627609, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1123888, "time": 35542.07621097565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1124016, "time": 35545.97175741196, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1124032, "time": 35546.46314096451, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1124112, "time": 35548.922827005386, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1124864, "time": 35571.961587667465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1125016, "time": 35576.377304792404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1125064, "time": 35577.831293821335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1125552, "time": 35592.97123813629, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1126000, "time": 35606.70395278931, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 1126288, "time": 35615.50044775009, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1126328, "time": 35616.504514694214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1126344, "time": 35616.99361181259, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1126424, "time": 35619.43659281731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1126752, "time": 35629.78054380417, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1126992, "time": 35637.10379743576, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1127176, "time": 35642.50903558731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1127304, "time": 35646.38797521591, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1127328, "time": 35647.36100578308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1127376, "time": 35648.812957286835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1127544, "time": 35653.762397289276, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1127664, "time": 35657.7014837265, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1127768, "time": 35660.63423895836, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1127856, "time": 35663.53418445587, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1128296, "time": 35676.63409471512, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1128336, "time": 35678.06607055664, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1128536, "time": 35684.0495531559, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1128600, "time": 35686.014496803284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1128856, "time": 35693.790625572205, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1128952, "time": 35696.72152471542, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1129336, "time": 35708.43801903725, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1129368, "time": 35709.41258430481, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1129616, "time": 35717.316740989685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1129640, "time": 35717.82964658737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1129688, "time": 35719.28682398796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1129912, "time": 35726.09792923927, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1129968, "time": 35728.00945043564, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1130016, "time": 35729.474090099335, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1130016, "time": 35729.48198246956, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1130064, "time": 35731.60046982765, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 1130064, "time": 35732.609001636505, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1130064, "time": 35732.734225034714, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1130064, "time": 35733.020364284515, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1130064, "time": 35733.10402274132, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1130064, "time": 35733.228596925735, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 1130064, "time": 35734.05755472183, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 1130064, "time": 35734.39688372612, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1130168, "time": 35737.343894958496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1130432, "time": 35745.69547390938, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1130464, "time": 35746.667025089264, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1130520, "time": 35748.66564631462, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1130648, "time": 35752.555278778076, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1130800, "time": 35757.40990948677, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1130864, "time": 35759.360575675964, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1130920, "time": 35760.83306956291, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1130928, "time": 35761.3040766716, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1131136, "time": 35767.624032497406, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1131184, "time": 35769.110302209854, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1131208, "time": 35769.62012267113, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 1131296, "time": 35772.51994395256, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1131672, "time": 35783.88519072533, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1131672, "time": 35783.9004278183, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1131680, "time": 35784.3697514534, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1132280, "time": 35802.38260912895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1132344, "time": 35804.47688627243, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1132424, "time": 35806.915531635284, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1132856, "time": 35820.11483478546, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1132960, "time": 35823.51073932648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1132968, "time": 35823.53837490082, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1132992, "time": 35824.49686932564, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1133048, "time": 35825.98200964928, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1133048, "time": 35825.989221572876, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1133176, "time": 35829.885662317276, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1133368, "time": 35835.831448316574, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1133544, "time": 35841.18713927269, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1133560, "time": 35841.69791960716, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1133792, "time": 35848.967856884, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1133856, "time": 35850.9066901207, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1133992, "time": 35854.85218310356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1134000, "time": 35855.325753211975, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1134056, "time": 35856.84766840935, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1134152, "time": 35859.77817058563, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1134664, "time": 35875.4317843914, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1134768, "time": 35878.811779260635, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1134784, "time": 35879.304894685745, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1134960, "time": 35884.652348041534, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1135232, "time": 35892.94490671158, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1135288, "time": 35894.53794121742, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1135376, "time": 35897.45781517029, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1135680, "time": 35906.7268550396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1135744, "time": 35908.66610574722, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1135792, "time": 35910.20059347153, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1135872, "time": 35912.63443803787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1136096, "time": 35919.45197224617, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1136168, "time": 35921.43286180496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1136304, "time": 35925.993812799454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1136680, "time": 35937.303915023804, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1136680, "time": 35937.31105875969, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1136704, "time": 35938.26542425156, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1137072, "time": 35949.519728899, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1137168, "time": 35952.43413352966, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1137192, "time": 35952.945363521576, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 1137248, "time": 35955.04478049278, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1137600, "time": 35965.837507247925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1137680, "time": 35968.26459646225, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1137792, "time": 35971.67482876778, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1137904, "time": 35975.12482404709, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1138024, "time": 35978.56065607071, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1138056, "time": 35979.56499290466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1138104, "time": 35981.02705049515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1138304, "time": 35987.50102138519, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1138472, "time": 35992.38508057594, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1138544, "time": 35994.795763492584, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1138624, "time": 35997.21393108368, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1138760, "time": 36001.661769628525, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1138768, "time": 36002.13316035271, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1138840, "time": 36004.11237168312, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1138960, "time": 36007.978600502014, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1139088, "time": 36011.870950460434, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1139248, "time": 36016.8616669178, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1139352, "time": 36019.82329535484, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1139480, "time": 36023.71656179428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1139488, "time": 36024.186135053635, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1139632, "time": 36028.584911346436, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1139664, "time": 36029.558354616165, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1139864, "time": 36035.46506905556, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1140000, "time": 36039.82987999916, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1140048, "time": 36041.87428355217, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 1140048, "time": 36041.92685890198, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 1140048, "time": 36041.937509059906, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 1140048, "time": 36042.66804051399, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1140048, "time": 36043.19917464256, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1140048, "time": 36043.35886621475, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1140048, "time": 36043.503821372986, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 1140048, "time": 36043.54859519005, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1140064, "time": 36044.168296813965, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1140104, "time": 36045.156316280365, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1140104, "time": 36045.16424536705, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1140256, "time": 36050.00701665878, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1140344, "time": 36052.48358464241, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1140552, "time": 36058.81930923462, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1140920, "time": 36070.032544374466, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1141000, "time": 36072.46319913864, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1141152, "time": 36077.431315898895, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1141160, "time": 36077.45929288864, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1141400, "time": 36084.770080566406, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1141480, "time": 36087.18743634224, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1141560, "time": 36089.625106573105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1141952, "time": 36101.743339300156, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1142104, "time": 36106.2623333931, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1142120, "time": 36106.75416612625, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1142312, "time": 36112.60692691803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1142312, "time": 36112.6137983799, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1142416, "time": 36116.01174616814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1142568, "time": 36120.40787196159, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1142728, "time": 36125.27894425392, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1142744, "time": 36125.76890349388, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1142920, "time": 36131.12181210518, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1142920, "time": 36131.12856698036, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1142952, "time": 36132.109912872314, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1143192, "time": 36139.549516916275, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1143304, "time": 36142.973024606705, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1143352, "time": 36144.451365470886, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1143472, "time": 36148.3567609787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1143480, "time": 36148.385050058365, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1143592, "time": 36151.76843714714, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1143904, "time": 36161.55878138542, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1144072, "time": 36166.60689496994, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1144144, "time": 36169.02933192253, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1144264, "time": 36172.45307278633, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1144384, "time": 36176.33929014206, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1144384, "time": 36176.34609603882, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1144624, "time": 36183.64641189575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1144888, "time": 36191.4284157753, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1145152, "time": 36199.840819597244, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1145400, "time": 36207.164847135544, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1145504, "time": 36210.546100854874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1145808, "time": 36219.794303655624, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1145832, "time": 36220.308153152466, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.0}
{"step": 1145992, "time": 36225.282200574875, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 1146208, "time": 36232.06406092644, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1146216, "time": 36232.0915453434, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1146328, "time": 36235.472692251205, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1146384, "time": 36237.401470184326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1146432, "time": 36238.85146665573, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1146696, "time": 36246.66808438301, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1146864, "time": 36251.986490011215, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1146936, "time": 36254.57222533226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1146968, "time": 36255.54989242554, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1147304, "time": 36265.78833460808, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1147360, "time": 36267.72147488594, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1147376, "time": 36268.21088385582, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1147608, "time": 36275.096091508865, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1147824, "time": 36281.921226263046, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1147832, "time": 36281.94952082634, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1147984, "time": 36286.95010781288, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1148096, "time": 36290.3669154644, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1148120, "time": 36290.902269124985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1148176, "time": 36292.826305389404, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1148297, "time": 36297.34415626526, "train_stats/mean_log_entropy": 0.07396034577542597, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1760402698421952, "train/action_min": 0.0, "train/action_std": 1.693286948536166, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009746090834496996, "train/actor_opt_grad_steps": 70670.0, "train/actor_opt_loss": -16.115786133713982, "train/adv_mag": 1.0188657350801116, "train/adv_max": 0.3310767370669996, "train/adv_mean": -0.00017190621310783625, "train/adv_min": -0.9702455371766541, "train/adv_std": 0.02986286824745177, "train/cont_avg": 0.994072605721393, "train/cont_loss_mean": 0.022977331006871677, "train/cont_loss_std": 0.27040701531411254, "train/cont_neg_acc": 0.21953373476862909, "train/cont_neg_loss": 3.022271936805919, "train/cont_pos_acc": 0.9998485908579471, "train/cont_pos_loss": 0.00475555550728679, "train/cont_pred": 0.9941504823034676, "train/cont_rate": 0.994072605721393, "train/dyn_loss_mean": 1.0000010260302037, "train/dyn_loss_std": 3.283689915207191e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10661467695747738, "train/extr_critic_critic_opt_grad_steps": 70670.0, "train/extr_critic_critic_opt_loss": 7199.093145114272, "train/extr_critic_mag": 1.669050778915633, "train/extr_critic_max": 1.669050778915633, "train/extr_critic_mean": 1.5243409700061552, "train/extr_critic_min": 1.2568502449870702, "train/extr_critic_std": 0.02434258234330374, "train/extr_return_normed_mag": 1.0535764353192267, "train/extr_return_normed_max": 0.35644629345604434, "train/extr_return_normed_mean": 0.044387882885833584, "train/extr_return_normed_min": -0.9681185148841706, "train/extr_return_normed_std": 0.03940702417856129, "train/extr_return_rate": 0.9996809938653785, "train/extr_return_raw_mag": 1.8362273618356506, "train/extr_return_raw_max": 1.8362273618356506, "train/extr_return_raw_mean": 1.5241690215779775, "train/extr_return_raw_min": 0.5116625534954355, "train/extr_return_raw_std": 0.03940702426196331, "train/extr_reward_mag": 0.35399257365743914, "train/extr_reward_max": 0.35399257365743914, "train/extr_reward_mean": 0.0025409220420148466, "train/extr_reward_min": 1.2869858623144046e-07, "train/extr_reward_std": 0.010236514375466316, "train/image_loss_mean": 0.0849895983637862, "train/image_loss_std": 0.1011955604995068, "train/model_loss_mean": 0.7249031876450154, "train/model_loss_std": 0.4963591501339158, "train/model_opt_grad_norm": 16.132283742155007, "train/model_opt_grad_steps": 70605.41293532339, "train/model_opt_loss": 3823.320829932369, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5273.63184079602, "train/policy_entropy_mag": 1.295401679342659, "train/policy_entropy_max": 1.295401679342659, "train/policy_entropy_mean": 0.09133300982156203, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11155034483072176, "train/policy_logprob_mag": 6.551080267227705, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09107410881798066, "train/policy_logprob_min": -6.551080267227705, "train/policy_logprob_std": 0.628297278537086, "train/policy_randomness_mag": 0.6657048164315484, "train/policy_randomness_max": 0.6657048164315484, "train/policy_randomness_mean": 0.04693588488434085, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05732554036067493, "train/post_ent_mag": 66.21879940127852, "train/post_ent_max": 66.21879940127852, "train/post_ent_mean": 53.12026415772699, "train/post_ent_min": 41.77306031943554, "train/post_ent_std": 5.703720669248211, "train/prior_ent_mag": 66.63540653209782, "train/prior_ent_max": 66.63540653209782, "train/prior_ent_mean": 53.41034668120579, "train/prior_ent_min": 42.393609573592, "train/prior_ent_std": 5.65558148616582, "train/rep_loss_mean": 1.0000010260302037, "train/rep_loss_std": 3.283689915207191e-05, "train/reward_avg": 0.002446052221296383, "train/reward_loss_mean": 0.016935616095703262, "train/reward_loss_std": 0.23539629943010892, "train/reward_max_data": 0.7899720146881407, "train/reward_max_pred": 0.2623014153532721, "train/reward_neg_acc": 0.9996392602351174, "train/reward_neg_loss": 0.0031522219712192667, "train/reward_pos_acc": 0.14160220956590575, "train/reward_pos_loss": 3.958046308628799, "train/reward_pred": 0.0018888631712793563, "train/reward_rate": 0.0034738417288557215, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.019742514938116074, "report/cont_loss_std": 0.24439619481563568, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.580359935760498, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004650467541068792, "report/cont_pred": 0.9938054084777832, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07864443957805634, "report/image_loss_std": 0.09564413130283356, "report/model_loss_mean": 0.7095569372177124, "report/model_loss_std": 0.3712637722492218, "report/post_ent_mag": 65.43697357177734, "report/post_ent_max": 65.43697357177734, "report/post_ent_mean": 51.808570861816406, "report/post_ent_min": 40.91010665893555, "report/post_ent_std": 5.864272117614746, "report/prior_ent_mag": 65.81632995605469, "report/prior_ent_max": 65.81632995605469, "report/prior_ent_mean": 51.95227813720703, "report/prior_ent_min": 42.02256774902344, "report/prior_ent_std": 5.465635776519775, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0020599365234375, "report/reward_loss_mean": 0.01116996817290783, "report/reward_loss_std": 0.15722566843032837, "report/reward_max_data": 0.846875011920929, "report/reward_max_pred": 0.5831271409988403, "report/reward_neg_acc": 0.999020516872406, "report/reward_neg_loss": 0.003875019494444132, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 2.4938840866088867, "report/reward_pred": 0.0026136082597076893, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.025707699358463287, "eval/cont_loss_std": 0.37081626057624817, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.187326431274414, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.007603040896356106, "eval/cont_pred": 0.993802547454834, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09317167848348618, "eval/image_loss_std": 0.1021619364619255, "eval/model_loss_mean": 0.7356675863265991, "eval/model_loss_std": 0.5918059349060059, "eval/post_ent_mag": 65.85113525390625, "eval/post_ent_max": 65.85113525390625, "eval/post_ent_mean": 52.5233154296875, "eval/post_ent_min": 40.75350570678711, "eval/post_ent_std": 6.195084571838379, "eval/prior_ent_mag": 65.23049926757812, "eval/prior_ent_max": 65.23049926757812, "eval/prior_ent_mean": 52.82477569580078, "eval/prior_ent_min": 41.912071228027344, "eval/prior_ent_std": 5.718821048736572, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0013702393043786287, "eval/reward_loss_mean": 0.01678820140659809, "eval/reward_loss_std": 0.2706943154335022, "eval/reward_max_data": 0.8656250238418579, "eval/reward_max_pred": 0.4773319959640503, "eval/reward_neg_acc": 0.9960861206054688, "eval/reward_neg_loss": 0.005356891080737114, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.858186721801758, "eval/reward_pred": 0.0024584028869867325, "eval/reward_rate": 0.001953125, "replay/size": 1000000.0, "replay/inserts": 32176.0, "replay/samples": 32176.0, "replay/insert_wait_avg": 1.30521871746031e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.470869806025053e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4560.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.188903524164568e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.6242265701293945e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0979731082916, "timer/env.step_count": 4022.0, "timer/env.step_total": 40.295382499694824, "timer/env.step_frac": 0.040291435022568135, "timer/env.step_avg": 0.01001874254094849, "timer/env.step_min": 0.008010625839233398, "timer/env.step_max": 0.03594541549682617, "timer/replay._sample_count": 32176.0, "timer/replay._sample_total": 17.849292755126953, "timer/replay._sample_frac": 0.017847544175748683, "timer/replay._sample_avg": 0.000554739332270231, "timer/replay._sample_min": 0.00042319297790527344, "timer/replay._sample_max": 0.012254476547241211, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4592.0, "timer/agent.policy_total": 50.379759550094604, "timer/agent.policy_frac": 0.05037482417199083, "timer/agent.policy_avg": 0.010971201992616421, "timer/agent.policy_min": 0.008557558059692383, "timer/agent.policy_max": 0.08923673629760742, "timer/dataset_train_count": 2011.0, "timer/dataset_train_total": 0.24125909805297852, "timer/dataset_train_frac": 0.0002412354634647927, "timer/dataset_train_avg": 0.00011996971559074019, "timer/dataset_train_min": 0.00010466575622558594, "timer/dataset_train_max": 0.0003685951232910156, "timer/agent.train_count": 2011.0, "timer/agent.train_total": 896.7634313106537, "timer/agent.train_frac": 0.8966755812168327, "timer/agent.train_avg": 0.4459291055746662, "timer/agent.train_min": 0.43295788764953613, "timer/agent.train_max": 0.7011206150054932, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4934420585632324, "timer/agent.report_frac": 0.0004933937192469462, "timer/agent.report_avg": 0.2467210292816162, "timer/agent.report_min": 0.22916722297668457, "timer/agent.report_max": 0.26427483558654785, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.528594970703125e-05, "timer/dataset_eval_frac": 3.528249297152655e-08, "timer/dataset_eval_avg": 3.528594970703125e-05, "timer/dataset_eval_min": 3.528594970703125e-05, "timer/dataset_eval_max": 3.528594970703125e-05, "fps": 32.17224208044713}
{"step": 1148368, "time": 36299.50431013107, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1148432, "time": 36301.46809339523, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1148448, "time": 36301.96293067932, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1148456, "time": 36301.989644527435, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1148552, "time": 36304.9202477932, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1148752, "time": 36311.225809812546, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1148792, "time": 36312.22387647629, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1148880, "time": 36315.248911857605, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1148976, "time": 36318.17623567581, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1149088, "time": 36321.6047873497, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1149128, "time": 36322.60585188866, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1149280, "time": 36327.4659178257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1149352, "time": 36329.44039607048, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1149480, "time": 36333.34507346153, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1149616, "time": 36337.71225523949, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1149680, "time": 36339.65482091904, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1149832, "time": 36344.204619407654, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1149944, "time": 36347.645065546036, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1149992, "time": 36349.09839582443, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1150008, "time": 36349.589207172394, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1150032, "time": 36351.47425413132, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 1150032, "time": 36351.85008764267, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 1150032, "time": 36351.940960645676, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1150032, "time": 36352.42712497711, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1150032, "time": 36352.453796863556, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1150032, "time": 36352.661900520325, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1150032, "time": 36352.94040799141, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 1150032, "time": 36353.27462029457, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1150080, "time": 36354.75458097458, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1150256, "time": 36360.12506508827, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1150496, "time": 36367.445781469345, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1150576, "time": 36369.895332574844, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1150632, "time": 36371.37431168556, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1150720, "time": 36374.418620824814, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1150968, "time": 36381.79009270668, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1150984, "time": 36382.28481411934, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1151168, "time": 36388.20555782318, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1151344, "time": 36393.66690278053, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1151360, "time": 36394.16706752777, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1151592, "time": 36401.078795194626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1151632, "time": 36402.541935920715, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1151832, "time": 36408.57797002792, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1152064, "time": 36415.92841362953, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1152096, "time": 36416.905222415924, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1152272, "time": 36422.28114080429, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1152392, "time": 36425.72080016136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1152552, "time": 36430.594779491425, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1152888, "time": 36441.026616334915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1152944, "time": 36442.97744369507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1153032, "time": 36445.45201706886, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1153176, "time": 36449.87581014633, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1153296, "time": 36453.7776093483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1153328, "time": 36454.75678277016, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1153328, "time": 36454.76401376724, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1153392, "time": 36456.728805065155, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1153480, "time": 36459.1773416996, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1153776, "time": 36468.570476055145, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1153880, "time": 36471.53647828102, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1154032, "time": 36476.40431237221, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1154136, "time": 36479.358781814575, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1154168, "time": 36480.341750860214, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1154176, "time": 36480.81137704849, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1154328, "time": 36485.25987529755, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1154512, "time": 36491.14144730568, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1154576, "time": 36493.092599868774, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1154584, "time": 36493.121385097504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1154640, "time": 36495.17940211296, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1154920, "time": 36503.51080870628, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1155024, "time": 36506.900795936584, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1155040, "time": 36507.39320373535, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1155160, "time": 36511.35794019699, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1155176, "time": 36511.85965228081, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1155256, "time": 36514.33343219757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1155584, "time": 36524.69968867302, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1155648, "time": 36526.67621541023, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1155704, "time": 36528.15949964523, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1155816, "time": 36531.62940645218, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1155880, "time": 36533.62168812752, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1155992, "time": 36537.0647854805, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1156072, "time": 36539.50254821777, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1156192, "time": 36543.3939166069, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1156240, "time": 36544.859760046005, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1156264, "time": 36545.37326049805, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1156480, "time": 36552.25586891174, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1156560, "time": 36554.830828905106, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1156600, "time": 36555.856298446655, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1156640, "time": 36557.310219049454, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1156704, "time": 36559.25322461128, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1156808, "time": 36562.22206377983, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1157104, "time": 36571.45630311966, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1157384, "time": 36579.761642217636, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1157488, "time": 36583.1692006588, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1157624, "time": 36587.209787130356, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1157776, "time": 36592.07745885849, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1157960, "time": 36597.46016287804, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1158232, "time": 36605.77610063553, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1158352, "time": 36609.67287111282, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1158504, "time": 36614.229357004166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1158520, "time": 36614.751037836075, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1158640, "time": 36618.632324934006, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1158904, "time": 36626.45989322662, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1158912, "time": 36626.92977690697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1159016, "time": 36629.88876795769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1159296, "time": 36638.599336862564, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1159416, "time": 36642.07907104492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1159672, "time": 36650.04673862457, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1159760, "time": 36652.960600852966, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1159800, "time": 36653.98337101936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1159832, "time": 36654.969079494476, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1159880, "time": 36656.43587779999, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1160016, "time": 36661.11404514313, "eval_episode/length": 11.0, "eval_episode/score": 0.965624988079071, "eval_episode/reward_rate": 0.08333333333333333}
{"step": 1160016, "time": 36661.36864256859, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 1160016, "time": 36662.440474033356, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1160016, "time": 36662.48750448227, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1160016, "time": 36662.592766046524, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1160016, "time": 36662.699996471405, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1160016, "time": 36662.9052901268, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 1160016, "time": 36662.93036389351, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1160056, "time": 36663.933213710785, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1160120, "time": 36665.90869164467, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1160224, "time": 36669.289806604385, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1160272, "time": 36670.76734948158, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1160696, "time": 36683.60409235954, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1160832, "time": 36688.01080274582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1160912, "time": 36690.465961933136, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1160952, "time": 36691.46748828888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1161072, "time": 36695.37152051926, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1161192, "time": 36698.79413533211, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1161256, "time": 36700.75607275963, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1161312, "time": 36702.67958045006, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1161392, "time": 36705.23615145683, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1161816, "time": 36717.91914629936, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1161840, "time": 36718.87488746643, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1161880, "time": 36719.89321947098, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1162112, "time": 36727.17560958862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1162320, "time": 36733.53797864914, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1162568, "time": 36741.056471824646, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1162576, "time": 36741.52841210365, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1162584, "time": 36741.5602209568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1162824, "time": 36748.91665768623, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1162904, "time": 36751.38611769676, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1163008, "time": 36754.79472756386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1163200, "time": 36760.62510204315, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1163296, "time": 36764.18694400787, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1163456, "time": 36769.09824228287, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1163560, "time": 36772.06277489662, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1163600, "time": 36773.51292061806, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1163704, "time": 36776.478375434875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1164048, "time": 36787.25576043129, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1164128, "time": 36789.72473049164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1164752, "time": 36808.93916153908, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1164928, "time": 36814.34544467926, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1165136, "time": 36820.683913230896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1165216, "time": 36823.12023687363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1165232, "time": 36823.67314887047, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1165440, "time": 36830.10075688362, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1165512, "time": 36832.07218384743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1165720, "time": 36838.426708459854, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1165744, "time": 36839.382808446884, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1165752, "time": 36839.41141939163, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 1165768, "time": 36839.90462398529, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1165784, "time": 36840.39751124382, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1166016, "time": 36847.710770606995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1166344, "time": 36857.592240810394, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1166496, "time": 36862.44778752327, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1166632, "time": 36866.37196660042, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1166728, "time": 36869.312869787216, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1166896, "time": 36874.678550720215, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1166944, "time": 36876.14940452576, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1167048, "time": 36879.124119758606, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1167360, "time": 36889.050741910934, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1167376, "time": 36889.54200720787, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1167512, "time": 36893.51180624962, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1167544, "time": 36894.51603317261, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1167616, "time": 36896.92452788353, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1167624, "time": 36896.951270103455, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1168056, "time": 36910.14820790291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1168080, "time": 36911.10439014435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1168096, "time": 36911.600068092346, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1168168, "time": 36913.649916410446, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1168784, "time": 36932.782214164734, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1168896, "time": 36936.190350055695, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1169152, "time": 36944.1805999279, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1169600, "time": 36957.82855796814, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1169632, "time": 36958.80487179756, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1169672, "time": 36959.80648088455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1169824, "time": 36964.6692507267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1169936, "time": 36968.10151171684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1169960, "time": 36968.61544704437, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1170000, "time": 36970.377764463425, "eval_episode/length": 15.0, "eval_episode/score": 0.953125, "eval_episode/reward_rate": 0.0625}
{"step": 1170000, "time": 36970.392683029175, "eval_episode/length": 15.0, "eval_episode/score": 0.953125, "eval_episode/reward_rate": 0.0625}
{"step": 1170000, "time": 36971.33081316948, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 1170000, "time": 36971.599358320236, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1170000, "time": 36972.560455560684, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1170000, "time": 36973.11255097389, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1170000, "time": 36973.15903258324, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 1170000, "time": 36973.33198618889, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 1170336, "time": 36983.722934007645, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1170336, "time": 36983.73214149475, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1170368, "time": 36984.74719071388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1170448, "time": 36987.232439517975, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1170480, "time": 36988.238629341125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1170632, "time": 36992.703050374985, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1170912, "time": 37001.45501637459, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1170952, "time": 37002.49488449097, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1170976, "time": 37003.458084106445, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1171552, "time": 37021.761043310165, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1171592, "time": 37022.75977063179, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1171624, "time": 37023.74560832977, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1172080, "time": 37038.12244987488, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1172168, "time": 37040.600930690765, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1172224, "time": 37042.52124643326, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1172248, "time": 37043.03763842583, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1172496, "time": 37050.87899804115, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1172512, "time": 37051.37288546562, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1172632, "time": 37054.85318279266, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1172648, "time": 37055.35474252701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1172680, "time": 37056.34806728363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1172968, "time": 37065.30566620827, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1172968, "time": 37065.31226372719, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1173160, "time": 37071.19320845604, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1173160, "time": 37071.19943523407, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1173304, "time": 37075.62225270271, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1173400, "time": 37078.57981967926, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1173496, "time": 37081.4963889122, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1173544, "time": 37082.96131801605, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1173584, "time": 37084.43064427376, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1173872, "time": 37093.21688365936, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1173928, "time": 37094.836577653885, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1174112, "time": 37100.662703990936, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1174200, "time": 37103.13902878761, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1174248, "time": 37104.61052823067, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1174296, "time": 37106.070382356644, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1174480, "time": 37111.96231818199, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1174504, "time": 37112.47662091255, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1174640, "time": 37116.865379333496, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1174680, "time": 37117.88036251068, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1174840, "time": 37122.78258752823, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1174880, "time": 37124.354497909546, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1175000, "time": 37127.80407500267, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1175216, "time": 37134.648315668106, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1175232, "time": 37135.14502644539, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1175344, "time": 37138.58902192116, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 1175472, "time": 37142.518070697784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1175472, "time": 37142.52707862854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1175856, "time": 37154.308811903, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1175864, "time": 37154.33713555336, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1175872, "time": 37154.80721449852, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1176000, "time": 37158.71840143204, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 1176224, "time": 37165.53285622597, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1176272, "time": 37167.016449928284, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1176352, "time": 37169.45434880257, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1176632, "time": 37177.791335105896, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1176792, "time": 37182.69635677338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1176816, "time": 37183.67219090462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1176904, "time": 37186.21291875839, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1176944, "time": 37187.67360019684, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1177096, "time": 37192.14250993729, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1177152, "time": 37194.08628296852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1177240, "time": 37196.5560567379, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1177392, "time": 37201.442833423615, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1177512, "time": 37204.88791680336, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1177792, "time": 37213.702867269516, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1177896, "time": 37216.74416279793, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1178208, "time": 37226.48658490181, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1178320, "time": 37229.88924241066, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1178536, "time": 37236.27326965332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1178664, "time": 37240.172562122345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1178896, "time": 37247.60886335373, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1179096, "time": 37253.48341536522, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1179104, "time": 37253.96167731285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1179256, "time": 37258.382982730865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1179336, "time": 37260.83510637283, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1179368, "time": 37261.83643293381, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1179456, "time": 37264.751749038696, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1179536, "time": 37267.21619558334, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1179552, "time": 37267.71553707123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1179688, "time": 37272.15642571449, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1180088, "time": 37285.52253174782, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1180088, "time": 37285.53112602234, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1180088, "time": 37285.96508717537, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1180088, "time": 37286.04865002632, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1180088, "time": 37286.58325839043, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 1180088, "time": 37287.27856993675, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 1180088, "time": 37288.45128297806, "eval_episode/length": 197.0, "eval_episode/score": 0.3843750059604645, "eval_episode/reward_rate": 0.005050505050505051}
{"step": 1180088, "time": 37288.48229765892, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 1180160, "time": 37290.91444015503, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1180264, "time": 37293.8506398201, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1180345, "time": 37297.42816233635, "train_stats/mean_log_entropy": 0.07393955084262416, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.227239074707031, "train/action_min": 0.0, "train/action_std": 1.7542986154556275, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00988564737373963, "train/actor_opt_grad_steps": 72675.0, "train/actor_opt_loss": -18.86975895166397, "train/adv_mag": 0.9019596990942955, "train/adv_max": 0.3221077734231949, "train/adv_mean": 0.0005221978484405554, "train/adv_min": -0.8401069250702858, "train/adv_std": 0.028683070936240257, "train/cont_avg": 0.9940869140625, "train/cont_loss_mean": 0.023829631060361862, "train/cont_loss_std": 0.2773037143796682, "train/cont_neg_acc": 0.18193903665989639, "train/cont_neg_loss": 3.193270919919014, "train/cont_pos_acc": 0.9999017253518104, "train/cont_pos_loss": 0.004962951828492806, "train/cont_pred": 0.9940373668074608, "train/cont_rate": 0.9940869140625, "train/dyn_loss_mean": 1.0000070059299468, "train/dyn_loss_std": 9.03616932919249e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12300549630075693, "train/extr_critic_critic_opt_grad_steps": 72675.0, "train/extr_critic_critic_opt_loss": 7486.816433105469, "train/extr_critic_mag": 1.6666801118850707, "train/extr_critic_max": 1.6666801118850707, "train/extr_critic_mean": 1.519482716321945, "train/extr_critic_min": 1.272232636809349, "train/extr_critic_std": 0.027727229911834003, "train/extr_return_normed_mag": 0.9398838740587234, "train/extr_return_normed_max": 0.36155600130558013, "train/extr_return_normed_mean": 0.056463154796510935, "train/extr_return_normed_min": -0.8251759362220764, "train/extr_return_normed_std": 0.041135197523981336, "train/extr_return_rate": 0.9997236660122871, "train/extr_return_raw_mag": 1.8250977385044098, "train/extr_return_raw_max": 1.8250977385044098, "train/extr_return_raw_mean": 1.520004974603653, "train/extr_return_raw_min": 0.6383658009767532, "train/extr_return_raw_std": 0.041135197514668105, "train/extr_reward_mag": 0.3446907812356949, "train/extr_reward_max": 0.3446907812356949, "train/extr_reward_mean": 0.0026200689643155785, "train/extr_reward_min": 2.41398811340332e-07, "train/extr_reward_std": 0.00980633283033967, "train/image_loss_mean": 0.08546553341671824, "train/image_loss_std": 0.10092990733683109, "train/model_loss_mean": 0.7278456351161003, "train/model_loss_std": 0.5194061706587673, "train/model_opt_grad_norm": 15.837598402500152, "train/model_opt_grad_steps": 72608.55, "train/model_opt_loss": 3982.0654138183595, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5475.0, "train/policy_entropy_mag": 1.2948669266700745, "train/policy_entropy_max": 1.2948669266700745, "train/policy_entropy_mean": 0.08984238971024752, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10951864395290613, "train/policy_logprob_mag": 6.551080245971679, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09016208942979574, "train/policy_logprob_min": -6.551080245971679, "train/policy_logprob_std": 0.6289714676141739, "train/policy_randomness_mag": 0.6654300081729889, "train/policy_randomness_max": 0.6654300081729889, "train/policy_randomness_mean": 0.04616985771805048, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05628145242109895, "train/post_ent_mag": 64.50811840057374, "train/post_ent_max": 64.50811840057374, "train/post_ent_mean": 53.007964553833006, "train/post_ent_min": 42.223204078674314, "train/post_ent_std": 5.21160658955574, "train/prior_ent_mag": 65.2948302078247, "train/prior_ent_max": 65.2948302078247, "train/prior_ent_mean": 53.25029756546021, "train/prior_ent_min": 42.69319295883179, "train/prior_ent_std": 5.259261823892594, "train/rep_loss_mean": 1.0000070059299468, "train/rep_loss_std": 9.03616932919249e-05, "train/reward_avg": 0.0025697784396470523, "train/reward_loss_mean": 0.018546245372854174, "train/reward_loss_std": 0.24911447382066398, "train/reward_max_data": 0.7840468738973141, "train/reward_max_pred": 0.26135308504104615, "train/reward_neg_acc": 0.9996667030453682, "train/reward_neg_loss": 0.0033988735935417936, "train/reward_pos_acc": 0.13100732794174783, "train/reward_pos_loss": 4.020139627578931, "train/reward_pred": 0.0020212543569505213, "train/reward_rate": 0.0037451171875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.011816284619271755, "report/cont_loss_std": 0.15736036002635956, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 1.671907663345337, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003670596517622471, "report/cont_pred": 0.9942648410797119, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0772862359881401, "report/image_loss_std": 0.09061548858880997, "report/model_loss_mean": 0.7004818320274353, "report/model_loss_std": 0.3780365288257599, "report/post_ent_mag": 69.57904052734375, "report/post_ent_max": 69.57904052734375, "report/post_ent_mean": 53.71710205078125, "report/post_ent_min": 39.799102783203125, "report/post_ent_std": 7.208915710449219, "report/prior_ent_mag": 68.53915405273438, "report/prior_ent_max": 68.53915405273438, "report/prior_ent_mean": 54.212005615234375, "report/prior_ent_min": 42.46223068237305, "report/prior_ent_std": 6.728163719177246, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0011260986793786287, "report/reward_loss_mean": 0.011379284784197807, "report/reward_loss_std": 0.20210415124893188, "report/reward_max_data": 0.6187499761581421, "report/reward_max_pred": 0.03015124797821045, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002485092729330063, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.556311130523682, "report/reward_pred": 0.00134412688203156, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.018667420372366905, "eval/cont_loss_std": 0.2833731472492218, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.764325141906738, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004723274614661932, "eval/cont_pred": 0.9952592253684998, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10688760131597519, "eval/image_loss_std": 0.11714164167642593, "eval/model_loss_mean": 0.7389837503433228, "eval/model_loss_std": 0.4764848053455353, "eval/post_ent_mag": 69.32829284667969, "eval/post_ent_max": 69.32829284667969, "eval/post_ent_mean": 55.96706771850586, "eval/post_ent_min": 42.188446044921875, "eval/post_ent_std": 6.437845230102539, "eval/prior_ent_mag": 68.17544555664062, "eval/prior_ent_max": 68.17544555664062, "eval/prior_ent_mean": 56.38743591308594, "eval/prior_ent_min": 42.79473114013672, "eval/prior_ent_std": 5.907179832458496, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0010772704845294356, "eval/reward_loss_mean": 0.013428749516606331, "eval/reward_loss_std": 0.23127999901771545, "eval/reward_max_data": 0.606249988079071, "eval/reward_max_pred": 0.08140826225280762, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.003365029115229845, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.155989646911621, "eval/reward_pred": 0.00180901272688061, "eval/reward_rate": 0.001953125, "replay/size": 1000000.0, "replay/inserts": 32048.0, "replay/samples": 32048.0, "replay/insert_wait_avg": 1.3274457296370507e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.453198461013619e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4672.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2116379117312496e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1473894119262695e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9922382831573, "timer/env.step_count": 4006.0, "timer/env.step_total": 40.48356318473816, "timer/env.step_frac": 0.0404838774091313, "timer/env.step_avg": 0.010105732197887709, "timer/env.step_min": 0.008027791976928711, "timer/env.step_max": 0.0382227897644043, "timer/replay._sample_count": 32048.0, "timer/replay._sample_total": 17.74769949913025, "timer/replay._sample_frac": 0.017747837252817575, "timer/replay._sample_avg": 0.0005537849319498955, "timer/replay._sample_min": 0.0004417896270751953, "timer/replay._sample_max": 0.02814650535583496, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4590.0, "timer/agent.policy_total": 50.132450103759766, "timer/agent.policy_frac": 0.05013283922066231, "timer/agent.policy_avg": 0.010922102419119775, "timer/agent.policy_min": 0.00906229019165039, "timer/agent.policy_max": 0.09079146385192871, "timer/dataset_train_count": 2003.0, "timer/dataset_train_total": 0.2399458885192871, "timer/dataset_train_frac": 0.00023994775092578681, "timer/dataset_train_avg": 0.00011979325437807643, "timer/dataset_train_min": 0.00010442733764648438, "timer/dataset_train_max": 0.0010657310485839844, "timer/agent.train_count": 2003.0, "timer/agent.train_total": 896.5656623840332, "timer/agent.train_frac": 0.8965726213268488, "timer/agent.train_avg": 0.44761141407091026, "timer/agent.train_min": 0.43527817726135254, "timer/agent.train_max": 0.7284331321716309, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4789915084838867, "timer/agent.report_frac": 0.0004789952263092023, "timer/agent.report_avg": 0.23949575424194336, "timer/agent.report_min": 0.23198366165161133, "timer/agent.report_max": 0.2470078468322754, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.5762786865234375e-05, "timer/dataset_eval_frac": 3.5763064448014044e-08, "timer/dataset_eval_avg": 3.5762786865234375e-05, "timer/dataset_eval_min": 3.5762786865234375e-05, "timer/dataset_eval_max": 3.5762786865234375e-05, "fps": 32.04755577544088}
{"step": 1180400, "time": 37299.07916498184, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1180520, "time": 37302.51929616928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1180616, "time": 37305.58561062813, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1181400, "time": 37329.52053451538, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1181552, "time": 37334.530106306076, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1181648, "time": 37337.431874513626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1181680, "time": 37338.41334795952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1181768, "time": 37340.88079357147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1181864, "time": 37343.79396247864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1182152, "time": 37352.56468987465, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1182232, "time": 37355.022542476654, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1182472, "time": 37362.32750368118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1182496, "time": 37363.28088593483, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1182688, "time": 37369.280159950256, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1182712, "time": 37369.79487681389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1182736, "time": 37370.7542347908, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1182896, "time": 37375.65780830383, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1182920, "time": 37376.171573638916, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1183224, "time": 37385.44231343269, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1183432, "time": 37391.78555417061, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1183600, "time": 37397.2641825676, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1183616, "time": 37397.7596578598, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1183712, "time": 37400.685576200485, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1183992, "time": 37408.994119644165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1184040, "time": 37410.44882917404, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1184216, "time": 37415.812900066376, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1184336, "time": 37419.71346116066, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1184408, "time": 37421.674946546555, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1184432, "time": 37422.65439128876, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1184632, "time": 37428.64527344704, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1184688, "time": 37430.57290816307, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1184784, "time": 37433.52514529228, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1185000, "time": 37439.893183231354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1185152, "time": 37444.76083636284, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1185368, "time": 37451.10474538803, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1185480, "time": 37454.67751288414, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1185512, "time": 37455.652522563934, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1185576, "time": 37457.6204791069, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1185880, "time": 37466.97901391983, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1185944, "time": 37468.935660362244, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1186184, "time": 37476.24496102333, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1186232, "time": 37477.71866393089, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1186288, "time": 37479.63213920593, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1186312, "time": 37480.14504766464, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 1186432, "time": 37484.15203142166, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1186720, "time": 37492.922122478485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1186920, "time": 37498.792862176895, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1186936, "time": 37499.28707122803, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1187088, "time": 37504.130635261536, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1187208, "time": 37507.57276749611, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1187248, "time": 37509.012674331665, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1187576, "time": 37518.96751642227, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1187640, "time": 37520.944757938385, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1187680, "time": 37522.39069700241, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1187736, "time": 37523.882507801056, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1187856, "time": 37528.28957223892, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1188000, "time": 37532.702946186066, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1188168, "time": 37537.60794663429, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1188216, "time": 37539.07497382164, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1188408, "time": 37545.01869177818, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1188424, "time": 37545.511770009995, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1188448, "time": 37546.49677872658, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1188544, "time": 37549.409346818924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1189072, "time": 37565.54764819145, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1189288, "time": 37571.90209937096, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1189352, "time": 37574.00177550316, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1189392, "time": 37575.46692323685, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1189616, "time": 37582.29263615608, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1189744, "time": 37586.195425748825, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1189856, "time": 37589.60316443443, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1189952, "time": 37592.56903910637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1190048, "time": 37595.549632787704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1190072, "time": 37597.14824461937, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1190072, "time": 37597.75597667694, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1190072, "time": 37598.2124581337, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1190072, "time": 37599.1367828846, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 1190072, "time": 37599.64287018776, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1190072, "time": 37599.9991645813, "eval_episode/length": 162.0, "eval_episode/score": 0.4937500059604645, "eval_episode/reward_rate": 0.006134969325153374}
{"step": 1190072, "time": 37600.51410317421, "eval_episode/length": 188.0, "eval_episode/score": 0.4124999940395355, "eval_episode/reward_rate": 0.005291005291005291}
{"step": 1190072, "time": 37600.63322305679, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 1190136, "time": 37602.57339000702, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1190136, "time": 37602.58237481117, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1190432, "time": 37612.02586364746, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1190512, "time": 37614.489468336105, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1190552, "time": 37615.488327264786, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1190584, "time": 37616.45480966568, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1190736, "time": 37621.340599536896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1191040, "time": 37630.64887213707, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1191056, "time": 37631.14218831062, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1191096, "time": 37632.15500617027, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1191120, "time": 37633.13786315918, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1191128, "time": 37633.16754817963, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1191600, "time": 37647.956979990005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1191608, "time": 37647.98548030853, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1191896, "time": 37656.77921462059, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1191912, "time": 37657.271087408066, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1191920, "time": 37657.73853111267, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1192008, "time": 37660.20187282562, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1192496, "time": 37675.455172777176, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1192960, "time": 37689.601994752884, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1193000, "time": 37690.60060381889, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1193048, "time": 37692.06965112686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1193432, "time": 37703.95399475098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1193440, "time": 37704.425765275955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1193920, "time": 37719.28790926933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1194016, "time": 37722.228801488876, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1194104, "time": 37724.82457661629, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1194136, "time": 37725.80523991585, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1194208, "time": 37728.24824094772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1194224, "time": 37728.74823689461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1194448, "time": 37735.654982328415, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1194480, "time": 37736.63724112511, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1194576, "time": 37739.57303190231, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1194712, "time": 37743.512286901474, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1195112, "time": 37755.795931100845, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1195360, "time": 37763.631205797195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1195568, "time": 37770.00087213516, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1195608, "time": 37770.99974370003, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1195632, "time": 37771.97391986847, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1195640, "time": 37772.000848054886, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1195752, "time": 37775.44763755798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1195904, "time": 37780.32551884651, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1196672, "time": 37804.53179240227, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1196712, "time": 37805.53364753723, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1196760, "time": 37807.01850318909, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1196792, "time": 37808.0011510849, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1196792, "time": 37808.00926399231, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1196816, "time": 37808.97346115112, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1196888, "time": 37810.95749568939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1197152, "time": 37819.393822431564, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1197232, "time": 37821.855523347855, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1197512, "time": 37830.226516485214, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1197520, "time": 37830.699657678604, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1197560, "time": 37831.71877169609, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1197752, "time": 37837.58940434456, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1197760, "time": 37838.06290912628, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1197856, "time": 37841.06721162796, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1198064, "time": 37847.63555431366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1198064, "time": 37847.652594566345, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1198112, "time": 37849.166305065155, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1198304, "time": 37855.096766233444, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1198464, "time": 37860.03267765045, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1198496, "time": 37861.008449316025, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1198728, "time": 37867.89944076538, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1198856, "time": 37871.81188702583, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1198912, "time": 37873.83488988876, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1198936, "time": 37874.40257668495, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1199088, "time": 37879.268367528915, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1199144, "time": 37880.746794223785, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1199160, "time": 37881.263102054596, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1199248, "time": 37884.1635658741, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1199384, "time": 37888.090410232544, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1199736, "time": 37898.83654856682, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1199944, "time": 37905.27786397934, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1200040, "time": 37908.21352696419, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1200056, "time": 37909.22062301636, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 1200056, "time": 37909.489106178284, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 1200056, "time": 37909.49620914459, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 1200056, "time": 37909.58445596695, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 1200056, "time": 37909.96838259697, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1200056, "time": 37910.32998633385, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1200056, "time": 37910.60496091843, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 1200056, "time": 37910.90674352646, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1200168, "time": 37914.34338116646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1200512, "time": 37925.1405043602, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1200592, "time": 37927.59928011894, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1200760, "time": 37932.50885510445, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1201144, "time": 37944.44679260254, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1201224, "time": 37946.88647031784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1201344, "time": 37950.79023170471, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1201400, "time": 37952.30874085426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1201456, "time": 37954.252234220505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1201560, "time": 37957.23102235794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1201752, "time": 37963.10654044151, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1201856, "time": 37966.61253452301, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1202040, "time": 37972.04390048981, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1202112, "time": 37974.466485500336, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1202160, "time": 37975.93658423424, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1202448, "time": 37984.78483724594, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1202544, "time": 37987.73943257332, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1202568, "time": 37988.25809764862, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1202824, "time": 37996.18820619583, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1202824, "time": 37996.196798563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1202904, "time": 37998.653507471085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1203000, "time": 38001.59318637848, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1203160, "time": 38006.49382376671, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1203240, "time": 38008.92566847801, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1203304, "time": 38010.88534474373, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1203584, "time": 38019.66829967499, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1203640, "time": 38021.18052005768, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1203656, "time": 38021.67760157585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1203792, "time": 38026.185654878616, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1204048, "time": 38034.03378033638, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1204200, "time": 38038.45185089111, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1204240, "time": 38040.432716846466, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1204296, "time": 38041.95148444176, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1204360, "time": 38043.90503311157, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1204448, "time": 38046.836218595505, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1204472, "time": 38047.35907411575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1204616, "time": 38051.775265455246, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1204824, "time": 38058.28436779976, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1204976, "time": 38063.15838479996, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1205256, "time": 38071.50648212433, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1205616, "time": 38082.753410577774, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1205736, "time": 38086.29566717148, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1205896, "time": 38091.1993598938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1206352, "time": 38105.39258122444, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1206360, "time": 38105.421822071075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1206376, "time": 38105.920233249664, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1206672, "time": 38115.31573796272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1206784, "time": 38118.75175189972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1206928, "time": 38123.22142934799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1207056, "time": 38127.13395547867, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1207208, "time": 38131.55691385269, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1207320, "time": 38134.98682117462, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1207760, "time": 38148.774112463, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 1207960, "time": 38154.71936964989, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1208048, "time": 38157.64642381668, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1208064, "time": 38158.139456510544, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1208208, "time": 38162.54170489311, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1208232, "time": 38163.0613617897, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1208456, "time": 38169.90574336052, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1208512, "time": 38171.83263039589, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1208568, "time": 38173.32559800148, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1208840, "time": 38181.83093905449, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1208984, "time": 38186.27469301224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1209096, "time": 38189.72540974617, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1209184, "time": 38192.61927628517, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1209240, "time": 38194.12149620056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1209880, "time": 38213.854466199875, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1209936, "time": 38215.79791474342, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1210040, "time": 38220.352021455765, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1210040, "time": 38220.49542403221, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1210040, "time": 38220.62126278877, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1210040, "time": 38221.14299726486, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 1210040, "time": 38221.23236322403, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 1210040, "time": 38221.8506257534, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 1210040, "time": 38222.085768699646, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 1210040, "time": 38222.48193335533, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1210144, "time": 38225.89108586311, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1210360, "time": 38232.30426740646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1210496, "time": 38236.8091981411, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1210624, "time": 38240.740426301956, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1210672, "time": 38242.21567583084, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1210768, "time": 38245.18104100227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1210880, "time": 38248.67498469353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1211024, "time": 38253.10393714905, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1211184, "time": 38258.00648832321, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1211256, "time": 38259.98502397537, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1211296, "time": 38261.42418551445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1211408, "time": 38264.99510025978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1211440, "time": 38265.971999168396, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1211440, "time": 38265.981086969376, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1211584, "time": 38270.37686800957, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1211664, "time": 38272.874742269516, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1211872, "time": 38279.230373859406, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1211896, "time": 38279.7630648613, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1212160, "time": 38288.043676137924, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1212208, "time": 38289.519273757935, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1212384, "time": 38295.00745677948, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1212392, "time": 38295.03615236282, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1212425, "time": 38297.64021849632, "train_stats/mean_log_entropy": 0.08564699576373845, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.264782957769745, "train/action_min": 0.0, "train/action_std": 1.7724928434808456, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010535455910044152, "train/actor_opt_grad_steps": 74680.0, "train/actor_opt_loss": -20.99221386601083, "train/adv_mag": 0.8815141252024257, "train/adv_max": 0.3061000844139365, "train/adv_mean": 0.0006704327731869798, "train/adv_min": -0.8317080931877022, "train/adv_std": 0.02911625213142651, "train/cont_avg": 0.9941697761194029, "train/cont_loss_mean": 0.024062717596384054, "train/cont_loss_std": 0.27655380208100844, "train/cont_neg_acc": 0.17617073714436582, "train/cont_neg_loss": 3.2268938523397517, "train/cont_pos_acc": 0.9998533764288793, "train/cont_pos_loss": 0.005067108320628307, "train/cont_pred": 0.9940376625725286, "train/cont_rate": 0.9941697761194029, "train/dyn_loss_mean": 1.000001254959486, "train/dyn_loss_std": 4.013452941866879e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12878887877053585, "train/extr_critic_critic_opt_grad_steps": 74680.0, "train/extr_critic_critic_opt_loss": 6319.206665646378, "train/extr_critic_mag": 1.6850277487911396, "train/extr_critic_max": 1.6850277487911396, "train/extr_critic_mean": 1.5324824336749405, "train/extr_critic_min": 1.2854271468831533, "train/extr_critic_std": 0.028421563193646828, "train/extr_return_normed_mag": 0.9411057613382292, "train/extr_return_normed_max": 0.3859003728895045, "train/extr_return_normed_mean": 0.05741227145737676, "train/extr_return_normed_min": -0.8043814535757795, "train/extr_return_normed_std": 0.0422237750550556, "train/extr_return_rate": 0.9997324896095997, "train/extr_return_raw_mag": 1.8616409034871344, "train/extr_return_raw_max": 1.8616409034871344, "train/extr_return_raw_mean": 1.5331528696847792, "train/extr_return_raw_min": 0.6713590770218503, "train/extr_return_raw_std": 0.042223774888251554, "train/extr_reward_mag": 0.36658094949390163, "train/extr_reward_max": 0.36658094949390163, "train/extr_reward_mean": 0.0027903145484959903, "train/extr_reward_min": 2.2892928242090329e-07, "train/extr_reward_std": 0.010439630120584917, "train/image_loss_mean": 0.08535298690273987, "train/image_loss_std": 0.10184355283999325, "train/model_loss_mean": 0.7278795971799252, "train/model_loss_std": 0.5185766998511642, "train/model_opt_grad_norm": 15.045985096129613, "train/model_opt_grad_steps": 74611.60696517413, "train/model_opt_loss": 3674.7669659514927, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5049.751243781095, "train/policy_entropy_mag": 1.2993542359242984, "train/policy_entropy_max": 1.2993542359242984, "train/policy_entropy_mean": 0.09773693422772992, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1239159570923492, "train/policy_logprob_mag": 6.551080255366084, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09812943466860263, "train/policy_logprob_min": -6.551080255366084, "train/policy_logprob_std": 0.6367589309440916, "train/policy_randomness_mag": 0.6677360276677715, "train/policy_randomness_max": 0.6677360276677715, "train/policy_randomness_mean": 0.05022685081508029, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06368020908971925, "train/post_ent_mag": 66.3533721278556, "train/post_ent_max": 66.3533721278556, "train/post_ent_mean": 53.597833775762304, "train/post_ent_min": 41.83955073949709, "train/post_ent_std": 5.768556231883035, "train/prior_ent_mag": 65.39950912627415, "train/prior_ent_max": 65.39950912627415, "train/prior_ent_mean": 53.47675122313238, "train/prior_ent_min": 42.344713657056516, "train/prior_ent_std": 5.469479968891808, "train/rep_loss_mean": 1.000001254959486, "train/rep_loss_std": 4.013452941866879e-05, "train/reward_avg": 0.0025136311853012597, "train/reward_loss_mean": 0.018463118859006103, "train/reward_loss_std": 0.24887972499072478, "train/reward_max_data": 0.7874533596323497, "train/reward_max_pred": 0.2385246866378025, "train/reward_neg_acc": 0.9995806273536303, "train/reward_neg_loss": 0.0034810870651859993, "train/reward_pos_acc": 0.12561346179976754, "train/reward_pos_loss": 4.077912954043369, "train/reward_pred": 0.0020353950806823906, "train/reward_rate": 0.0036438899253731344, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.020506031811237335, "report/cont_loss_std": 0.26020026206970215, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.4660186767578125, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0035996895749121904, "report/cont_pred": 0.9961941838264465, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0634913221001625, "report/image_loss_std": 0.08856086432933807, "report/model_loss_mean": 0.7007254362106323, "report/model_loss_std": 0.49483922123908997, "report/post_ent_mag": 69.50768280029297, "report/post_ent_max": 69.50768280029297, "report/post_ent_mean": 53.4075927734375, "report/post_ent_min": 42.9403190612793, "report/post_ent_std": 5.868675708770752, "report/prior_ent_mag": 63.845603942871094, "report/prior_ent_max": 63.845603942871094, "report/prior_ent_mean": 51.535972595214844, "report/prior_ent_min": 42.03127670288086, "report/prior_ent_std": 5.052316188812256, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0028839111328125, "report/reward_loss_mean": 0.01672801375389099, "report/reward_loss_std": 0.23987944424152374, "report/reward_max_data": 0.8218749761581421, "report/reward_max_pred": 0.1653209924697876, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.002447816077619791, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.6581783294677734, "report/reward_pred": 0.0015258393250405788, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.98828125, "eval/cont_loss_mean": 0.07285060733556747, "eval/cont_loss_std": 0.6775082349777222, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.835593223571777, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004517688881605864, "eval/cont_pred": 0.9955254197120667, "eval/cont_rate": 0.98828125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12758180499076843, "eval/image_loss_std": 0.12502428889274597, "eval/model_loss_mean": 0.8741010427474976, "eval/model_loss_std": 1.4192806482315063, "eval/post_ent_mag": 68.05537414550781, "eval/post_ent_max": 68.05537414550781, "eval/post_ent_mean": 56.313079833984375, "eval/post_ent_min": 44.54290008544922, "eval/post_ent_std": 6.586249351501465, "eval/prior_ent_mag": 63.63859176635742, "eval/prior_ent_max": 63.63859176635742, "eval/prior_ent_mean": 54.04854202270508, "eval/prior_ent_min": 43.7939453125, "eval/prior_ent_std": 5.2358551025390625, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.008389282040297985, "eval/reward_loss_mean": 0.07366861402988434, "eval/reward_loss_std": 0.7111860513687134, "eval/reward_max_data": 0.9281250238418579, "eval/reward_max_pred": 0.04955017566680908, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002477140398696065, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.629756927490234, "eval/reward_pred": 0.0012871406506747007, "eval/reward_rate": 0.0107421875, "replay/size": 1000000.0, "replay/inserts": 32080.0, "replay/samples": 32080.0, "replay/insert_wait_avg": 1.3213205218612404e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0411415314139273e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3904.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.169374731720471e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2530181407928, "timer/env.step_count": 4010.0, "timer/env.step_total": 40.389445066452026, "timer/env.step_frac": 0.040379228389158354, "timer/env.step_avg": 0.010072180814576566, "timer/env.step_min": 0.008058309555053711, "timer/env.step_max": 0.03780031204223633, "timer/replay._sample_count": 32080.0, "timer/replay._sample_total": 17.753560543060303, "timer/replay._sample_frac": 0.017749069706442376, "timer/replay._sample_avg": 0.0005534152288983884, "timer/replay._sample_min": 0.0004451274871826172, "timer/replay._sample_max": 0.011918783187866211, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4498.0, "timer/agent.policy_total": 49.71230220794678, "timer/agent.policy_frac": 0.049699727275353656, "timer/agent.policy_avg": 0.011052090308569759, "timer/agent.policy_min": 0.009167194366455078, "timer/agent.policy_max": 0.09483528137207031, "timer/dataset_train_count": 2005.0, "timer/dataset_train_total": 0.23987984657287598, "timer/dataset_train_frac": 0.000239819167972869, "timer/dataset_train_avg": 0.00011964082123335461, "timer/dataset_train_min": 0.00010037422180175781, "timer/dataset_train_max": 0.0003497600555419922, "timer/agent.train_count": 2005.0, "timer/agent.train_total": 898.3441035747528, "timer/agent.train_frac": 0.8981168637156808, "timer/agent.train_avg": 0.44805192198242033, "timer/agent.train_min": 0.4353759288787842, "timer/agent.train_max": 0.7275912761688232, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48101043701171875, "timer/agent.report_frac": 0.0004808887634308673, "timer/agent.report_avg": 0.24050521850585938, "timer/agent.report_min": 0.23186063766479492, "timer/agent.report_max": 0.24914979934692383, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4332275390625e-05, "timer/dataset_eval_frac": 3.432359089947028e-08, "timer/dataset_eval_avg": 3.4332275390625e-05, "timer/dataset_eval_min": 3.4332275390625e-05, "timer/dataset_eval_max": 3.4332275390625e-05, "fps": 32.07106147803272}
{"step": 1212608, "time": 38303.2534763813, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1212672, "time": 38305.22109913826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1212736, "time": 38307.17443943024, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1212984, "time": 38314.58153247833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1213104, "time": 38318.49222326279, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1213184, "time": 38320.94408559799, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1213184, "time": 38320.954327344894, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1213200, "time": 38321.45336270332, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1213408, "time": 38327.96308732033, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1213464, "time": 38329.4481151104, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1213632, "time": 38334.825359106064, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1213816, "time": 38340.23380756378, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1213912, "time": 38343.1910674572, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1214144, "time": 38350.548708200455, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1214184, "time": 38351.54658174515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1214288, "time": 38355.07173085213, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1214496, "time": 38361.467351436615, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1214720, "time": 38368.32947731018, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1214736, "time": 38368.82392525673, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1214752, "time": 38369.319771528244, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1215032, "time": 38377.707658052444, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1215104, "time": 38380.124672174454, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1215496, "time": 38392.01131629944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1215576, "time": 38394.4502158165, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1215664, "time": 38397.35962343216, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1215720, "time": 38398.838183641434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1215848, "time": 38402.73655247688, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1216208, "time": 38414.09362864494, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1216320, "time": 38417.51636481285, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1216464, "time": 38421.90564417839, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1216600, "time": 38425.85259222984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1216672, "time": 38428.26890707016, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1216736, "time": 38430.21456503868, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1217016, "time": 38438.551053762436, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1217048, "time": 38439.549072265625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1217232, "time": 38445.59468793869, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1217328, "time": 38448.50628376007, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1217344, "time": 38449.000408649445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1217504, "time": 38453.89047217369, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1217720, "time": 38460.24890637398, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1217864, "time": 38464.62710571289, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1218104, "time": 38471.97036409378, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1218264, "time": 38476.990340709686, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1218528, "time": 38485.29635453224, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1218768, "time": 38492.67248058319, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1218776, "time": 38492.701730012894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1218912, "time": 38497.08396100998, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1219048, "time": 38501.02089095116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1219216, "time": 38506.560587882996, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1219496, "time": 38514.92740225792, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1219504, "time": 38515.40057730675, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1219544, "time": 38516.400079250336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1219640, "time": 38519.33521223068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1219672, "time": 38520.32268214226, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1219696, "time": 38521.28279590607, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1220024, "time": 38531.72399544716, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 1220024, "time": 38532.10373830795, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 1220024, "time": 38532.617086172104, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1220024, "time": 38533.130108356476, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1220024, "time": 38533.38337779045, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 1220024, "time": 38534.0809776783, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1220024, "time": 38534.267263650894, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 1220024, "time": 38534.843277692795, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 1220384, "time": 38546.069563388824, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1220416, "time": 38547.04629945755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1220736, "time": 38557.374352931976, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1220984, "time": 38564.799907684326, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1221528, "time": 38581.33387541771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1221808, "time": 38590.10981440544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1221816, "time": 38590.14078307152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1221856, "time": 38591.600412368774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1222008, "time": 38596.19554758072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1222032, "time": 38597.16865563393, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1222232, "time": 38603.050167798996, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1222456, "time": 38609.92715358734, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1222632, "time": 38615.32622003555, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1222648, "time": 38615.81832957268, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1222688, "time": 38617.28064537048, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1222728, "time": 38618.27906489372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1222784, "time": 38620.21932029724, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1222992, "time": 38626.75601887703, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1223048, "time": 38628.24985766411, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1223216, "time": 38633.61992096901, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1223416, "time": 38639.521767139435, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1223416, "time": 38639.528584718704, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1223648, "time": 38646.896228313446, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1223664, "time": 38647.399639606476, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1223680, "time": 38647.899856090546, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1223728, "time": 38649.3811275959, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1223792, "time": 38651.37310266495, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1223840, "time": 38652.84273767471, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1224200, "time": 38663.74112534523, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1224304, "time": 38667.142946243286, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1224312, "time": 38667.170679569244, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1224352, "time": 38668.60901236534, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1224424, "time": 38670.593123197556, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1224496, "time": 38673.03382110596, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1224784, "time": 38681.82676267624, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1224960, "time": 38687.284723997116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1224992, "time": 38688.26299524307, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1225520, "time": 38704.51201605797, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1225560, "time": 38705.54081606865, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1225696, "time": 38709.90644621849, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1225728, "time": 38710.90294933319, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1226176, "time": 38724.73017048836, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1226504, "time": 38734.48024773598, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1226624, "time": 38738.356694698334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1226688, "time": 38740.35289144516, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1226808, "time": 38743.90418243408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1227096, "time": 38752.70315647125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1227176, "time": 38755.16093826294, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1227272, "time": 38758.08844542503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1227400, "time": 38761.99434065819, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1227568, "time": 38767.33520436287, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1227592, "time": 38767.8464846611, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1227624, "time": 38768.81764602661, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1227672, "time": 38770.2940325737, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1227872, "time": 38776.75144195557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1228208, "time": 38787.022959947586, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1228224, "time": 38787.50794887543, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1228296, "time": 38789.47662425041, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1228512, "time": 38796.28097820282, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1228560, "time": 38797.74232816696, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1228688, "time": 38801.67876672745, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1228816, "time": 38806.2580037117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1228888, "time": 38808.24266076088, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1228984, "time": 38811.214079380035, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1229144, "time": 38816.12102293968, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1229304, "time": 38821.00431013107, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1229384, "time": 38823.46235370636, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1229520, "time": 38827.8478205204, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1229528, "time": 38827.874873161316, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1229576, "time": 38829.356815099716, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1229864, "time": 38838.29873895645, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1229896, "time": 38839.30988097191, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1229984, "time": 38842.28398323059, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1230008, "time": 38844.02914023399, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1230008, "time": 38844.076679468155, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1230008, "time": 38844.32551908493, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1230008, "time": 38844.43440914154, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1230008, "time": 38845.14895606041, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 1230008, "time": 38845.32775759697, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1230008, "time": 38845.66878890991, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 1230008, "time": 38845.67699384689, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1230016, "time": 38846.14765691757, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1230104, "time": 38848.631798267365, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1230192, "time": 38851.56550168991, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1230480, "time": 38860.354432582855, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1230528, "time": 38861.82869386673, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1230720, "time": 38867.78921031952, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1230744, "time": 38868.303683280945, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1230816, "time": 38870.7156560421, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1230824, "time": 38870.74456834793, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1230864, "time": 38872.20311379433, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1230976, "time": 38875.61425757408, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1231128, "time": 38880.02198600769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1231128, "time": 38880.028867959976, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1231296, "time": 38885.380299568176, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1231320, "time": 38885.925236940384, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1231384, "time": 38887.87390136719, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1231768, "time": 38899.75467991829, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1231832, "time": 38901.722840070724, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1231832, "time": 38901.73086333275, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1231840, "time": 38902.20480966568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1231920, "time": 38904.636454582214, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1232144, "time": 38911.48951673508, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1232488, "time": 38921.76552963257, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1232624, "time": 38926.239966630936, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1232688, "time": 38928.182664871216, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1232824, "time": 38932.10826134682, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1232872, "time": 38933.5601747036, "episode/length": 5.0, "episode/score": 0.984375, "episode/reward_rate": 0.16666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1233048, "time": 38938.88924598694, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1233088, "time": 38940.34462809563, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1233136, "time": 38941.805361270905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1233440, "time": 38951.034571409225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1233576, "time": 38955.082134485245, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1233632, "time": 38957.01364541054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1233656, "time": 38957.52902173996, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1233760, "time": 38960.941460847855, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1233776, "time": 38961.4384996891, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1234152, "time": 38972.649705410004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1234224, "time": 38975.0885322094, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1234280, "time": 38976.56509757042, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1234320, "time": 38978.00560212135, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1234360, "time": 38979.03125524521, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1234392, "time": 38980.01398086548, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1234432, "time": 38981.45519113541, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1234496, "time": 38983.40063405037, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1234664, "time": 38988.489520311356, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1234696, "time": 38989.490751981735, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1235184, "time": 39004.68590593338, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1235496, "time": 39014.13528108597, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1235584, "time": 39017.05733370781, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1235600, "time": 39017.54788684845, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1235672, "time": 39019.532052755356, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1235768, "time": 39022.4512386322, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1235968, "time": 39028.78481674194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1235976, "time": 39028.812012434006, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1236336, "time": 39039.99133205414, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1236376, "time": 39040.99709439278, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1236584, "time": 39047.48153376579, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1236632, "time": 39048.972304582596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1236752, "time": 39052.909646987915, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1237008, "time": 39061.26306462288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1237088, "time": 39063.72350811958, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1237160, "time": 39065.69518709183, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1237808, "time": 39085.84824490547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1237808, "time": 39085.85606122017, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1237816, "time": 39085.88447380066, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1237984, "time": 39091.23396587372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1238072, "time": 39093.7194340229, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1238456, "time": 39105.55481481552, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1238584, "time": 39109.48004412651, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1238648, "time": 39111.41994214058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1238688, "time": 39112.894433259964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1238696, "time": 39112.92428779602, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1238912, "time": 39119.802917957306, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1239064, "time": 39124.25280332565, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1239328, "time": 39132.528613328934, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1239400, "time": 39134.66268515587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1239656, "time": 39142.47074985504, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1239792, "time": 39146.81615996361, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1239904, "time": 39150.218703985214, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1240096, "time": 39156.73110961914, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 1240096, "time": 39157.672677993774, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1240096, "time": 39157.78441596031, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1240096, "time": 39157.81263065338, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1240096, "time": 39158.14554595947, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1240096, "time": 39158.174564123154, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1240096, "time": 39159.03509473801, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 1240096, "time": 39159.16809153557, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 1240336, "time": 39166.64306354523, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1240376, "time": 39167.6632642746, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1240384, "time": 39168.14169430733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1240480, "time": 39171.1097972393, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1240576, "time": 39174.036163806915, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1240632, "time": 39175.53975892067, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1240768, "time": 39179.89395928383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1241008, "time": 39187.16165351868, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1241008, "time": 39187.169129133224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1241024, "time": 39187.65839600563, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1241200, "time": 39193.0172522068, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1241208, "time": 39193.04699468613, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1241256, "time": 39194.701915979385, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1241384, "time": 39198.610951423645, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1241480, "time": 39201.55501127243, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1241600, "time": 39205.451763391495, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1241848, "time": 39212.78872489929, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1242016, "time": 39218.12461709976, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1242080, "time": 39220.07325768471, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1242536, "time": 39233.90673613548, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1242568, "time": 39234.88917851448, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1242688, "time": 39238.77523636818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1242792, "time": 39241.70326066017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1242880, "time": 39244.59806919098, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1242992, "time": 39247.99878692627, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1243256, "time": 39255.90087604523, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1243520, "time": 39264.189031124115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1243720, "time": 39270.082879543304, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1243736, "time": 39270.57295179367, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1243984, "time": 39278.34255361557, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1244200, "time": 39284.867508649826, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1244240, "time": 39286.312323093414, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1244240, "time": 39286.3221282959, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1244328, "time": 39288.793264865875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1244392, "time": 39290.74634361267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1244480, "time": 39293.641369342804, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1244585, "time": 39300.093306303024, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2031101207828048, "train/action_min": 0.0, "train/action_std": 1.8310414689097239, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01179149471552329, "train/actor_opt_grad_steps": 76690.0, "train/actor_opt_loss": -20.936743513268617, "train/adv_mag": 1.017129546374231, "train/adv_max": 0.3758888392899167, "train/adv_mean": 0.0008912910651729792, "train/adv_min": -0.9697620302290466, "train/adv_std": 0.03352543940091163, "train/cont_avg": 0.9938831234452736, "train/cont_loss_mean": 0.02528394753604534, "train/cont_loss_std": 0.28450169136275105, "train/cont_neg_acc": 0.15153274336709313, "train/cont_neg_loss": 3.299172504031243, "train/cont_pos_acc": 0.9998874910435274, "train/cont_pos_loss": 0.00522801548877351, "train/cont_pred": 0.9939612455628998, "train/cont_rate": 0.9938831234452736, "train/dyn_loss_mean": 1.0000007265242772, "train/dyn_loss_std": 1.795813111143548e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1693710799871096, "train/extr_critic_critic_opt_grad_steps": 76690.0, "train/extr_critic_critic_opt_loss": 4310.4460169853855, "train/extr_critic_mag": 1.7031883778263681, "train/extr_critic_max": 1.7031883778263681, "train/extr_critic_mean": 1.5600762794266885, "train/extr_critic_min": 1.2206741375709647, "train/extr_critic_std": 0.027647640157620706, "train/extr_return_normed_mag": 1.0753177226479373, "train/extr_return_normed_max": 0.4058129686621291, "train/extr_return_normed_mean": 0.056925427706087404, "train/extr_return_normed_min": -0.9924911385151878, "train/extr_return_normed_std": 0.045063326848828376, "train/extr_return_rate": 0.999633057497034, "train/extr_return_raw_mag": 1.9098550271038985, "train/extr_return_raw_max": 1.9098550271038985, "train/extr_return_raw_mean": 1.560967568734392, "train/extr_return_raw_min": 0.5115509199265816, "train/extr_return_raw_std": 0.04506332694149729, "train/extr_reward_mag": 0.4040193836487348, "train/extr_reward_max": 0.4040193836487348, "train/extr_reward_mean": 0.003022141038759876, "train/extr_reward_min": 2.342670118037741e-07, "train/extr_reward_std": 0.011217362018051878, "train/image_loss_mean": 0.08604674537976582, "train/image_loss_std": 0.10240317065620896, "train/model_loss_mean": 0.7315668176062664, "train/model_loss_std": 0.5410229476974971, "train/model_opt_grad_norm": 15.045716469287873, "train/model_opt_grad_steps": 76619.815920398, "train/model_opt_loss": 4146.473522281172, "train/model_opt_model_opt_grad_overflow": 0.004975124378109453, "train/model_opt_model_opt_grad_scale": 5646.766169154229, "train/policy_entropy_mag": 1.3073054747794992, "train/policy_entropy_max": 1.3073054747794992, "train/policy_entropy_mean": 0.09276482069966804, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11614733819493014, "train/policy_logprob_mag": 6.551080238759814, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0927002532268638, "train/policy_logprob_min": -6.551080238759814, "train/policy_logprob_std": 0.6308701705576768, "train/policy_randomness_mag": 0.6718221552929475, "train/policy_randomness_max": 0.6718221552929475, "train/policy_randomness_mean": 0.047671689916012894, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.059687927643309775, "train/post_ent_mag": 65.8901733284566, "train/post_ent_max": 65.8901733284566, "train/post_ent_mean": 54.07946010608578, "train/post_ent_min": 42.77578636662877, "train/post_ent_std": 5.426250626198688, "train/prior_ent_mag": 65.52793071993548, "train/prior_ent_max": 65.52793071993548, "train/prior_ent_mean": 54.207195433811165, "train/prior_ent_min": 42.941484024275596, "train/prior_ent_std": 5.290364709066514, "train/rep_loss_mean": 1.0000007265242772, "train/rep_loss_std": 1.795813111143548e-05, "train/reward_avg": 0.002841201711930242, "train/reward_loss_mean": 0.020235664405818306, "train/reward_loss_std": 0.2639607365998389, "train/reward_max_data": 0.8213463950513015, "train/reward_max_pred": 0.2506082354493402, "train/reward_neg_acc": 0.9995560518544705, "train/reward_neg_loss": 0.0036712178163489893, "train/reward_pos_acc": 0.11397681213054225, "train/reward_pos_loss": 4.173985604065747, "train/reward_pred": 0.002167207344703895, "train/reward_rate": 0.004027712997512438, "train_stats/mean_log_entropy": 0.0824309371319818, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.028694892302155495, "report/cont_loss_std": 0.31626832485198975, "report/cont_neg_acc": 0.125, "report/cont_neg_loss": 3.217841148376465, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0035835052840411663, "report/cont_pred": 0.9952362775802612, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09584684669971466, "report/image_loss_std": 0.1112329512834549, "report/model_loss_mean": 0.75132817029953, "report/model_loss_std": 0.6428918242454529, "report/post_ent_mag": 65.41084289550781, "report/post_ent_max": 65.41084289550781, "report/post_ent_mean": 52.96377944946289, "report/post_ent_min": 40.34687042236328, "report/post_ent_std": 6.095211505889893, "report/prior_ent_mag": 65.57270050048828, "report/prior_ent_max": 65.57270050048828, "report/prior_ent_mean": 53.965911865234375, "report/prior_ent_min": 41.993080139160156, "report/prior_ent_std": 5.8777618408203125, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0045837401412427425, "report/reward_loss_mean": 0.026786401867866516, "report/reward_loss_std": 0.32207387685775757, "report/reward_max_data": 0.909375011920929, "report/reward_max_pred": 0.06994128227233887, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0023573392536491156, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.171584129333496, "report/reward_pred": 0.0013395168352872133, "report/reward_rate": 0.005859375, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.03534569963812828, "eval/cont_loss_std": 0.3565583825111389, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.058930397033691, "eval/cont_pos_acc": 0.998033344745636, "eval/cont_pos_loss": 0.007651406805962324, "eval/cont_pred": 0.9946681261062622, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13522839546203613, "eval/image_loss_std": 0.1201963946223259, "eval/model_loss_mean": 0.8022557497024536, "eval/model_loss_std": 0.7394722104072571, "eval/post_ent_mag": 65.05120849609375, "eval/post_ent_max": 65.05120849609375, "eval/post_ent_mean": 53.448760986328125, "eval/post_ent_min": 42.90161895751953, "eval/post_ent_std": 5.548367023468018, "eval/prior_ent_mag": 65.47671508789062, "eval/prior_ent_max": 65.47671508789062, "eval/prior_ent_mean": 54.471405029296875, "eval/prior_ent_min": 43.67593765258789, "eval/prior_ent_std": 5.300912857055664, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.004574584774672985, "eval/reward_loss_mean": 0.0316816121339798, "eval/reward_loss_std": 0.3859972059726715, "eval/reward_max_data": 0.9750000238418579, "eval/reward_max_pred": 0.04789578914642334, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002511802362278104, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.980825901031494, "eval/reward_pred": 0.00138757040258497, "eval/reward_rate": 0.005859375, "replay/size": 1000000.0, "replay/inserts": 32160.0, "replay/samples": 32160.0, "replay/insert_wait_avg": 1.3318450296696146e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.773753175688026e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3616.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2385106719700636e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2516975402832031e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9670479297638, "timer/env.step_count": 4020.0, "timer/env.step_total": 40.19587802886963, "timer/env.step_frac": 0.04019720260991333, "timer/env.step_avg": 0.009998974634047171, "timer/env.step_min": 0.00806427001953125, "timer/env.step_max": 0.03968977928161621, "timer/replay._sample_count": 32160.0, "timer/replay._sample_total": 17.743512392044067, "timer/replay._sample_frac": 0.017744097096777878, "timer/replay._sample_avg": 0.0005517261315934101, "timer/replay._sample_min": 0.00039386749267578125, "timer/replay._sample_max": 0.025360822677612305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4472.0, "timer/agent.policy_total": 48.82822251319885, "timer/agent.policy_frac": 0.04882983155723795, "timer/agent.policy_avg": 0.010918654408139277, "timer/agent.policy_min": 0.009205818176269531, "timer/agent.policy_max": 0.08611488342285156, "timer/dataset_train_count": 2010.0, "timer/dataset_train_total": 0.2413346767425537, "timer/dataset_train_frac": 0.0002413426294818314, "timer/dataset_train_avg": 0.00012006700335450434, "timer/dataset_train_min": 0.00010442733764648438, "timer/dataset_train_max": 0.0005350112915039062, "timer/agent.train_count": 2010.0, "timer/agent.train_total": 899.599846124649, "timer/agent.train_frac": 0.8996294907788157, "timer/agent.train_avg": 0.4475621124998254, "timer/agent.train_min": 0.4360768795013428, "timer/agent.train_max": 0.7006981372833252, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4722280502319336, "timer/agent.report_frac": 0.00047224361163659284, "timer/agent.report_avg": 0.2361140251159668, "timer/agent.report_min": 0.22931838035583496, "timer/agent.report_max": 0.24290966987609863, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.2187568825739616e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 32.160371082620365}
{"step": 1244760, "time": 39305.18331480026, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1244880, "time": 39309.05585241318, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1244904, "time": 39309.56955695152, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1244920, "time": 39310.08213686943, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1244936, "time": 39310.5718126297, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1245376, "time": 39324.81444430351, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1245552, "time": 39330.17876577377, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1245672, "time": 39333.587361335754, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1245704, "time": 39334.56342768669, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1246032, "time": 39344.88842868805, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1246168, "time": 39348.806554079056, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1246424, "time": 39356.633982896805, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1246512, "time": 39359.55535554886, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1246552, "time": 39360.54793524742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1246552, "time": 39360.56488656998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1246712, "time": 39365.49836611748, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1246776, "time": 39367.44669055939, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1247056, "time": 39376.290332078934, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1247072, "time": 39376.78341817856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1247072, "time": 39376.790971040726, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1247232, "time": 39381.65540623665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1247424, "time": 39387.51686620712, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1247544, "time": 39390.958928108215, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1247616, "time": 39393.37033033371, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1247848, "time": 39400.21382045746, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1248016, "time": 39405.69506931305, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1248016, "time": 39405.703483343124, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1248080, "time": 39407.65740466118, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1248288, "time": 39413.98456954956, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1248304, "time": 39414.47668123245, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1248536, "time": 39421.2968518734, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1248552, "time": 39421.78952550888, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1248584, "time": 39422.76336812973, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1249024, "time": 39436.5187792778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1249032, "time": 39436.547093868256, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1249048, "time": 39437.037405490875, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1249224, "time": 39442.3755941391, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1249320, "time": 39445.314697265625, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1249384, "time": 39447.27001810074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1249664, "time": 39456.02997159958, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1249704, "time": 39457.02416038513, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1249864, "time": 39461.900826931, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1249984, "time": 39465.92868447304, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1250080, "time": 39469.73074889183, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 1250080, "time": 39470.44060301781, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1250080, "time": 39470.54595708847, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1250080, "time": 39470.708699941635, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1250080, "time": 39470.96291971207, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1250080, "time": 39471.38520073891, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1250080, "time": 39471.53332209587, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 1250080, "time": 39471.78961229324, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 1250176, "time": 39474.743980407715, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1250328, "time": 39479.17857718468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1250352, "time": 39480.15569162369, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1250856, "time": 39495.39909338951, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1250864, "time": 39495.8745777607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1250896, "time": 39496.85528969765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1250936, "time": 39497.85411095619, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1251280, "time": 39508.60351514816, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1251360, "time": 39511.08910489082, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1251448, "time": 39513.5372235775, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1251520, "time": 39515.966999053955, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1251672, "time": 39520.37854886055, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 1251864, "time": 39526.35809421539, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1251960, "time": 39529.30252933502, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1252016, "time": 39531.22660756111, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1252016, "time": 39531.23530483246, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1252096, "time": 39533.69935011864, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1252208, "time": 39537.11576986313, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1252568, "time": 39547.94767665863, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1252704, "time": 39552.36524581909, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1252704, "time": 39552.37099194527, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1252864, "time": 39557.44607377052, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1252880, "time": 39557.93918991089, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1252928, "time": 39559.42377400398, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1252960, "time": 39560.40252995491, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1253048, "time": 39562.8469376564, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1253208, "time": 39567.744666576385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1253336, "time": 39571.665455818176, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1253376, "time": 39573.245429039, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1253456, "time": 39576.06650567055, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1253480, "time": 39576.582057237625, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1253552, "time": 39579.00339269638, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1253592, "time": 39580.00217652321, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1253760, "time": 39585.507106781006, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1253760, "time": 39585.51454257965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1253872, "time": 39588.973747015, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1254056, "time": 39594.401799440384, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1254200, "time": 39598.78356194496, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1254448, "time": 39606.55199408531, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1254448, "time": 39606.558900117874, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1254456, "time": 39606.59018492699, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1254640, "time": 39612.491394519806, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1254880, "time": 39619.98301362991, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1254888, "time": 39620.01217699051, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1255048, "time": 39624.921634197235, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1255144, "time": 39627.85745334625, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1255208, "time": 39629.85314035416, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1255528, "time": 39639.67530488968, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1255600, "time": 39642.097877025604, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1255720, "time": 39645.68759083748, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1255728, "time": 39646.15969538689, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1255768, "time": 39647.15896868706, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1255792, "time": 39648.136389017105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1255904, "time": 39651.58278012276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1255928, "time": 39652.103044748306, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1256320, "time": 39664.35123586655, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1256432, "time": 39667.812173843384, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1256568, "time": 39671.72593283653, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1256576, "time": 39672.203139066696, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1256760, "time": 39677.75696015358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1256936, "time": 39683.12457990646, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1256968, "time": 39684.10996031761, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1257000, "time": 39685.09186077118, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1257224, "time": 39691.90686058998, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1257368, "time": 39696.321863889694, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1257520, "time": 39701.18736600876, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1257568, "time": 39702.68240356445, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1257720, "time": 39707.21478176117, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1257912, "time": 39713.146490335464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1257936, "time": 39714.10583996773, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1258080, "time": 39718.52914738655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1258360, "time": 39726.839326143265, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1258424, "time": 39728.77554774284, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1258592, "time": 39734.22877860069, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1258616, "time": 39734.74746131897, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1258704, "time": 39737.65284991264, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1258880, "time": 39743.0178527832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1258904, "time": 39743.532275915146, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1259016, "time": 39746.962255477905, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1259208, "time": 39752.83597898483, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1259504, "time": 39762.095185279846, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1259680, "time": 39767.588691711426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1259744, "time": 39769.55144429207, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1259760, "time": 39770.04305911064, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1260064, "time": 39779.95389342308, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 1260064, "time": 39780.33705449104, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 1260064, "time": 39780.57872414589, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1260064, "time": 39781.07812857628, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1260064, "time": 39781.72686576843, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 1260064, "time": 39782.44680929184, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 1260064, "time": 39783.12507772446, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1260064, "time": 39783.28714442253, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 1260296, "time": 39790.13792395592, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1260480, "time": 39796.103130340576, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1260672, "time": 39801.94868826866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1260904, "time": 39808.78397965431, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1261016, "time": 39812.215617895126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1261216, "time": 39818.55969119072, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1261520, "time": 39827.98439645767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1261736, "time": 39834.874648332596, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1261816, "time": 39837.30642223358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1261992, "time": 39842.671217918396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1262072, "time": 39845.12781333923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1262344, "time": 39853.44432806969, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1262368, "time": 39854.53392839432, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1262488, "time": 39857.977932453156, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1262544, "time": 39859.93742799759, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1262640, "time": 39862.8396999836, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1262752, "time": 39866.24340343475, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1262984, "time": 39873.10855221748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1263056, "time": 39875.56003570557, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1263144, "time": 39878.0265378952, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1263360, "time": 39885.02812004089, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1263384, "time": 39885.54163503647, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1263528, "time": 39889.93304395676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1263632, "time": 39893.345968961716, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1263976, "time": 39903.64654827118, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1264080, "time": 39907.02700591087, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1264144, "time": 39909.00560092926, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1264200, "time": 39910.48760795593, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1264296, "time": 39913.43282556534, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1264384, "time": 39916.47875261307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1264456, "time": 39918.478588581085, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1264488, "time": 39919.45885658264, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1264488, "time": 39919.466727018356, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1264864, "time": 39931.13300657272, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1264904, "time": 39932.12984061241, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1265208, "time": 39941.43322944641, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1265448, "time": 39948.91559505463, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1265464, "time": 39949.40872812271, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1265584, "time": 39953.30797624588, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1265696, "time": 39956.70536017418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1265704, "time": 39956.7330698967, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1265896, "time": 39962.61035990715, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1266096, "time": 39968.939041137695, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1266608, "time": 39984.798441171646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1266624, "time": 39985.29661989212, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1266656, "time": 39986.29874110222, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1266768, "time": 39989.78762626648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1266800, "time": 39990.77298974991, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1267136, "time": 40001.10433721542, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1267192, "time": 40002.60555934906, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1267208, "time": 40003.09759426117, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1267464, "time": 40011.075597286224, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1267480, "time": 40011.59955859184, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1267616, "time": 40015.95002031326, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1267968, "time": 40026.72125482559, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1268008, "time": 40027.72187232971, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1268136, "time": 40031.64023542404, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1268192, "time": 40033.59182691574, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1268192, "time": 40033.606291770935, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1268208, "time": 40034.20177149773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1268240, "time": 40035.181805849075, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1268408, "time": 40040.08565449715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1268696, "time": 40048.86529827118, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1268816, "time": 40052.783868312836, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1268968, "time": 40057.205971479416, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1268976, "time": 40057.67354297638, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1269112, "time": 40061.603100538254, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1269192, "time": 40064.1491215229, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1269496, "time": 40073.40121006966, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1269600, "time": 40076.81644320488, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1269768, "time": 40081.926028966904, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1269904, "time": 40086.61462974548, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 1270048, "time": 40091.98765873909, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 1270048, "time": 40092.0154569149, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 1270048, "time": 40092.968490600586, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1270048, "time": 40093.05274128914, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1270048, "time": 40093.45128273964, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 1270048, "time": 40093.7572953701, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 1270048, "time": 40094.00067424774, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 1270048, "time": 40094.365126132965, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 1270056, "time": 40094.39241361618, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1270280, "time": 40101.21247792244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1270320, "time": 40102.652131319046, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1270664, "time": 40112.96882176399, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1270688, "time": 40113.94798851013, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1271136, "time": 40127.719373226166, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1271184, "time": 40129.20437121391, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1271288, "time": 40132.14515256882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1271424, "time": 40136.526649713516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1271504, "time": 40138.96551632881, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1271600, "time": 40141.882860422134, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1271824, "time": 40148.71436572075, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1271888, "time": 40150.69551324844, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1271912, "time": 40151.212010622025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1272064, "time": 40156.194407224655, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1272080, "time": 40156.68968963623, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1272216, "time": 40160.64114999771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1272232, "time": 40161.13201880455, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1272280, "time": 40162.61227941513, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1272592, "time": 40172.36544442177, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1272608, "time": 40172.85803151131, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1272792, "time": 40178.2891228199, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1272848, "time": 40180.22275304794, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1273248, "time": 40192.534198999405, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1273296, "time": 40194.005615234375, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1273312, "time": 40194.501237392426, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1273400, "time": 40196.99448800087, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1273448, "time": 40198.46179819107, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1273736, "time": 40207.308044433594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1274192, "time": 40221.56231379509, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1274376, "time": 40227.02633881569, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1274376, "time": 40227.03426194191, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1274464, "time": 40229.93835711479, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1274864, "time": 40242.12812614441, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1274976, "time": 40245.64613509178, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1274984, "time": 40245.674832582474, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1275096, "time": 40249.09722805023, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1275104, "time": 40249.56556224823, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1275104, "time": 40249.57417488098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1275608, "time": 40264.72662329674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1275696, "time": 40267.66243648529, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1275712, "time": 40268.159116983414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1275744, "time": 40269.15677571297, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1275784, "time": 40270.16229891777, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1275904, "time": 40274.194090127945, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1276048, "time": 40278.58504033089, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1276528, "time": 40293.19331240654, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1276576, "time": 40294.66439580917, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1276640, "time": 40296.644297361374, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1276649, "time": 40297.75696849823, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.194063720703125, "train/action_min": 0.0, "train/action_std": 1.8237398809194565, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01028653395944275, "train/actor_opt_grad_steps": 78695.0, "train/actor_opt_loss": -21.501482605934143, "train/adv_mag": 0.8845863151550293, "train/adv_max": 0.32515283226966857, "train/adv_mean": 0.0015332270538868898, "train/adv_min": -0.8225218397378922, "train/adv_std": 0.03030896685551852, "train/cont_avg": 0.99375, "train/cont_loss_mean": 0.02598538709571585, "train/cont_loss_std": 0.29101417631842197, "train/cont_neg_acc": 0.16032305534929037, "train/cont_neg_loss": 3.292181900292635, "train/cont_pos_acc": 0.9998820385336876, "train/cont_pos_loss": 0.0053307892300654205, "train/cont_pred": 0.9937818604707718, "train/cont_rate": 0.99375, "train/dyn_loss_mean": 1.0000020772218705, "train/dyn_loss_std": 6.041355431079864e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.19100178067572415, "train/extr_critic_critic_opt_grad_steps": 78695.0, "train/extr_critic_critic_opt_loss": 4751.066225585938, "train/extr_critic_mag": 1.733791216611862, "train/extr_critic_max": 1.733791216611862, "train/extr_critic_mean": 1.5807664221525193, "train/extr_critic_min": 1.285210382938385, "train/extr_critic_std": 0.03034030258655548, "train/extr_return_normed_mag": 0.9117275005578995, "train/extr_return_normed_max": 0.3762770438194275, "train/extr_return_normed_mean": 0.0635771532729268, "train/extr_return_normed_min": -0.7891999393701553, "train/extr_return_normed_std": 0.04403978389687836, "train/extr_return_rate": 0.9997471007704735, "train/extr_return_raw_mag": 1.8949995082616806, "train/extr_return_raw_max": 1.8949995082616806, "train/extr_return_raw_mean": 1.5822996932268143, "train/extr_return_raw_min": 0.7295225250720978, "train/extr_return_raw_std": 0.0440397837664932, "train/extr_reward_mag": 0.34743984758853913, "train/extr_reward_max": 0.34743984758853913, "train/extr_reward_mean": 0.0030394036445068194, "train/extr_reward_min": 2.2292137145996095e-07, "train/extr_reward_std": 0.010582358888350428, "train/image_loss_mean": 0.08506602101027966, "train/image_loss_std": 0.10169018894433975, "train/model_loss_mean": 0.7317944130301476, "train/model_loss_std": 0.5493956249579788, "train/model_opt_grad_norm": 14.29695072889328, "train/model_opt_grad_steps": 78622.995, "train/model_opt_loss": 4028.076174316406, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5500.0, "train/policy_entropy_mag": 1.299266060590744, "train/policy_entropy_max": 1.299266060590744, "train/policy_entropy_mean": 0.09165235508233309, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11267023745924235, "train/policy_logprob_mag": 6.55108026266098, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09150600723922253, "train/policy_logprob_min": -6.55108026266098, "train/policy_logprob_std": 0.6288071700930595, "train/policy_randomness_mag": 0.667690714597702, "train/policy_randomness_max": 0.667690714597702, "train/policy_randomness_mean": 0.04709999606013298, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.057901051826775074, "train/post_ent_mag": 65.23138746261597, "train/post_ent_max": 65.23138746261597, "train/post_ent_mean": 54.63522224426269, "train/post_ent_min": 44.38492258071899, "train/post_ent_std": 4.744393014907837, "train/prior_ent_mag": 63.30570541381836, "train/prior_ent_max": 63.30570541381836, "train/prior_ent_mean": 54.86607553482056, "train/prior_ent_min": 46.544854946136475, "train/prior_ent_std": 3.7531373393535614, "train/rep_loss_mean": 1.0000020772218705, "train/rep_loss_std": 6.041355431079864e-05, "train/reward_avg": 0.002927963242545957, "train/reward_loss_mean": 0.020741735638584943, "train/reward_loss_std": 0.26631724182516336, "train/reward_max_data": 0.8182031248509883, "train/reward_max_pred": 0.2913535010814667, "train/reward_neg_acc": 0.9996274498105049, "train/reward_neg_loss": 0.003767156465910375, "train/reward_pos_acc": 0.14842857353389263, "train/reward_pos_loss": 3.989869213104248, "train/reward_pred": 0.0022860340861370785, "train/reward_rate": 0.004208984375, "train_stats/mean_log_entropy": 0.08060482237488031, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 0.03224889561533928, "report/cont_loss_std": 0.3142600357532501, "report/cont_neg_acc": 0.1111111119389534, "report/cont_neg_loss": 3.103795289993286, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0050135087221860886, "report/cont_pred": 0.9938443899154663, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10935381054878235, "report/image_loss_std": 0.11206337809562683, "report/model_loss_mean": 0.7678827047348022, "report/model_loss_std": 0.6438787579536438, "report/post_ent_mag": 65.74200439453125, "report/post_ent_max": 65.74200439453125, "report/post_ent_mean": 55.86003494262695, "report/post_ent_min": 44.164154052734375, "report/post_ent_std": 5.130802631378174, "report/prior_ent_mag": 63.19612121582031, "report/prior_ent_max": 63.19612121582031, "report/prior_ent_mean": 55.94132614135742, "report/prior_ent_min": 47.859519958496094, "report/prior_ent_std": 3.4637844562530518, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0041564940474927425, "report/reward_loss_mean": 0.026279989629983902, "report/reward_loss_std": 0.330912321805954, "report/reward_max_data": 0.8656250238418579, "report/reward_max_pred": 0.7108637094497681, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0027201541233807802, "report/reward_pos_acc": 0.1666666716337204, "report/reward_pos_loss": 4.023599147796631, "report/reward_pred": 0.002215755172073841, "report/reward_rate": 0.005859375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.030809517949819565, "eval/cont_loss_std": 0.41473981738090515, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.164608955383301, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0056191375479102135, "eval/cont_pred": 0.9945369362831116, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11411720514297485, "eval/image_loss_std": 0.11407624185085297, "eval/model_loss_mean": 0.7810797691345215, "eval/model_loss_std": 0.9513822793960571, "eval/post_ent_mag": 66.6480941772461, "eval/post_ent_max": 66.6480941772461, "eval/post_ent_mean": 55.08660888671875, "eval/post_ent_min": 44.56609344482422, "eval/post_ent_std": 4.624737739562988, "eval/prior_ent_mag": 62.89408874511719, "eval/prior_ent_max": 62.89408874511719, "eval/prior_ent_mean": 55.25060272216797, "eval/prior_ent_min": 47.97283172607422, "eval/prior_ent_std": 3.0420618057250977, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0035858156625181437, "eval/reward_loss_mean": 0.03615300729870796, "eval/reward_loss_std": 0.5120079517364502, "eval/reward_max_data": 0.8843749761581421, "eval/reward_max_pred": 0.23308587074279785, "eval/reward_neg_acc": 0.999018669128418, "eval/reward_neg_loss": 0.0034814770333468914, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.694611549377441, "eval/reward_pred": 0.0019061296479776502, "eval/reward_rate": 0.0048828125, "replay/size": 1000000.0, "replay/inserts": 32064.0, "replay/samples": 32064.0, "replay/insert_wait_avg": 1.308327901387167e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.687985488754547e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3744.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1536300691783938e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2069940567016602e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0821492671967, "timer/env.step_count": 4008.0, "timer/env.step_total": 40.18872952461243, "timer/env.step_frac": 0.040185428321123866, "timer/env.step_avg": 0.0100271281249033, "timer/env.step_min": 0.007990121841430664, "timer/env.step_max": 0.05279731750488281, "timer/replay._sample_count": 32064.0, "timer/replay._sample_total": 17.832767009735107, "timer/replay._sample_frac": 0.017831302181327748, "timer/replay._sample_avg": 0.0005561616457626967, "timer/replay._sample_min": 0.0004296302795410156, "timer/replay._sample_max": 0.028185606002807617, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4476.0, "timer/agent.policy_total": 49.29977893829346, "timer/agent.policy_frac": 0.04929572933025305, "timer/agent.policy_avg": 0.01101424909255886, "timer/agent.policy_min": 0.009236335754394531, "timer/agent.policy_max": 0.0961904525756836, "timer/dataset_train_count": 2004.0, "timer/dataset_train_total": 0.24154329299926758, "timer/dataset_train_frac": 0.00024152345202467295, "timer/dataset_train_avg": 0.00012053058532897584, "timer/dataset_train_min": 0.000102996826171875, "timer/dataset_train_max": 0.0008764266967773438, "timer/agent.train_count": 2004.0, "timer/agent.train_total": 896.473641872406, "timer/agent.train_frac": 0.8964000032690224, "timer/agent.train_avg": 0.44734213666287725, "timer/agent.train_min": 0.4356868267059326, "timer/agent.train_max": 0.6967489719390869, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.476482629776001, "timer/agent.report_frac": 0.00047644349029241285, "timer/agent.report_avg": 0.2382413148880005, "timer/agent.report_min": 0.22992920875549316, "timer/agent.report_max": 0.2465534210205078, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.1230268318647953e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 32.06061318771616}
{"step": 1276752, "time": 40300.8967423439, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1276824, "time": 40302.87521696091, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1276976, "time": 40307.86322903633, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1277296, "time": 40317.68250584602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1277408, "time": 40321.119377851486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1277496, "time": 40323.581508398056, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1277616, "time": 40327.46395277977, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1277712, "time": 40330.41294121742, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1277832, "time": 40333.96339273453, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 1277848, "time": 40334.45688223839, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1278032, "time": 40340.777978897095, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1278088, "time": 40342.274185180664, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1278104, "time": 40342.77488851547, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1278288, "time": 40348.60870194435, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1278560, "time": 40356.8869869709, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1278728, "time": 40361.75992631912, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1278776, "time": 40363.22168326378, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1278800, "time": 40364.28075480461, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1278808, "time": 40364.3103556633, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1278888, "time": 40366.75824165344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1278904, "time": 40367.25068974495, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1278952, "time": 40368.71335196495, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1279000, "time": 40370.204604148865, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1279200, "time": 40376.521058797836, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1279520, "time": 40386.306762456894, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1279776, "time": 40394.2386071682, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1279784, "time": 40394.269443035126, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1279864, "time": 40396.71561193466, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1279888, "time": 40397.665304899216, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1279992, "time": 40400.627912044525, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1280032, "time": 40402.07020640373, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1280032, "time": 40403.18913817406, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1280032, "time": 40403.216071367264, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 1280032, "time": 40403.24336051941, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1280032, "time": 40403.58481049538, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1280032, "time": 40403.62928915024, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1280032, "time": 40403.67281126976, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1280032, "time": 40403.85507631302, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1280032, "time": 40404.81493830681, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1280096, "time": 40406.75554728508, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1280104, "time": 40406.78262400627, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1280224, "time": 40410.707879304886, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1280584, "time": 40421.440927267075, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1280768, "time": 40427.42343044281, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1280768, "time": 40427.433557510376, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1280776, "time": 40427.46614217758, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1280888, "time": 40430.8649995327, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1281264, "time": 40442.59094929695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1281360, "time": 40445.49902153015, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1281376, "time": 40445.990369558334, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1281400, "time": 40446.52715468407, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1281560, "time": 40451.41701006889, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1281568, "time": 40451.886796712875, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1281616, "time": 40453.36768937111, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1281888, "time": 40461.876079797745, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1281952, "time": 40463.834038734436, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1282088, "time": 40467.76006102562, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1282384, "time": 40476.97582268715, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1282496, "time": 40480.38804626465, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1282656, "time": 40485.426924943924, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1282896, "time": 40492.75486111641, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1283120, "time": 40499.56575226784, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1283384, "time": 40507.41655540466, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1283552, "time": 40512.78785777092, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1283648, "time": 40515.85883927345, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1283672, "time": 40516.373498916626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1283672, "time": 40516.382378816605, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 1283984, "time": 40526.11336350441, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1284104, "time": 40529.534638404846, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1284400, "time": 40538.799877643585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1284536, "time": 40542.79958367348, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1284560, "time": 40543.87290549278, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1284704, "time": 40548.33493757248, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1284968, "time": 40556.192135095596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1284976, "time": 40556.66114330292, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1285208, "time": 40563.48500108719, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1285208, "time": 40563.49438929558, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1285224, "time": 40563.98389983177, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1285312, "time": 40566.88331079483, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1285352, "time": 40567.90624833107, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1285696, "time": 40578.78560233116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1285760, "time": 40580.74443602562, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1285800, "time": 40581.744356155396, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1285808, "time": 40582.21249175072, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1285864, "time": 40583.71694231033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1286032, "time": 40589.09149599075, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1286288, "time": 40597.43734073639, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1286344, "time": 40598.913425922394, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1286464, "time": 40602.80502033234, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1286680, "time": 40609.368485450745, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1286720, "time": 40610.822806835175, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1286760, "time": 40611.83973670006, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1286920, "time": 40616.73480343819, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1287240, "time": 40626.49189329147, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1287304, "time": 40628.44506549835, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1287328, "time": 40629.424813747406, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1287536, "time": 40635.88264155388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1287568, "time": 40636.857273578644, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1287616, "time": 40638.32439947128, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1287696, "time": 40640.774238586426, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1287880, "time": 40646.169723033905, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1287896, "time": 40646.659482479095, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1288120, "time": 40653.4869890213, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1288144, "time": 40654.44380927086, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1288368, "time": 40661.28030180931, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1288600, "time": 40668.233281850815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1288672, "time": 40670.649844408035, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1288768, "time": 40673.588500738144, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1288888, "time": 40677.01954340935, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1289248, "time": 40688.25992107391, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1289248, "time": 40688.271250486374, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1289272, "time": 40688.78890180588, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1289552, "time": 40697.69547486305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1289632, "time": 40700.16291308403, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1289960, "time": 40709.98001790047, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1290016, "time": 40712.27747988701, "eval_episode/length": 16.0, "eval_episode/score": 0.949999988079071, "eval_episode/reward_rate": 0.058823529411764705}
{"step": 1290016, "time": 40712.285551309586, "eval_episode/length": 16.0, "eval_episode/score": 0.949999988079071, "eval_episode/reward_rate": 0.058823529411764705}
{"step": 1290016, "time": 40712.87353205681, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 1290016, "time": 40713.44294333458, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1290016, "time": 40713.72533988953, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1290016, "time": 40714.06917977333, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 1290016, "time": 40714.35835647583, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 1290016, "time": 40714.508726119995, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1290088, "time": 40716.50204229355, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1290176, "time": 40719.40738654137, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1290192, "time": 40719.91735339165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1290456, "time": 40727.86987280846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1290560, "time": 40731.29777932167, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1290792, "time": 40738.15312170982, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1290912, "time": 40742.041533231735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1290960, "time": 40743.50284600258, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1290992, "time": 40744.50048804283, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1291304, "time": 40753.959657907486, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1291496, "time": 40759.83309984207, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1291560, "time": 40761.79153633118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1291856, "time": 40771.06998181343, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1291904, "time": 40772.534081697464, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1291944, "time": 40773.5307533741, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1292024, "time": 40776.00006222725, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1292272, "time": 40783.97784113884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1292480, "time": 40790.3764898777, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1292488, "time": 40790.40504002571, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1292512, "time": 40791.36096787453, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1292704, "time": 40797.19800114632, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1292744, "time": 40798.19642210007, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1293104, "time": 40809.455017089844, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1293104, "time": 40809.46369814873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1293192, "time": 40811.93202447891, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1293296, "time": 40815.50532126427, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1293360, "time": 40817.46224141121, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1293376, "time": 40817.95495772362, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1293432, "time": 40819.47651338577, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1293872, "time": 40833.14782500267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1293968, "time": 40836.08003997803, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1294040, "time": 40838.06988239288, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1294080, "time": 40839.51521039009, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1294176, "time": 40842.46530508995, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1294488, "time": 40852.44729590416, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1294584, "time": 40855.42852115631, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1294712, "time": 40859.335608005524, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1294792, "time": 40861.77139353752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1294912, "time": 40865.66478276253, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1294936, "time": 40866.17786574364, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1295040, "time": 40869.63350749016, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1295248, "time": 40876.17744112015, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1295424, "time": 40881.5594727993, "episode/length": 265.0, "episode/score": 0.171875, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.0}
{"step": 1295504, "time": 40884.00484800339, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1295688, "time": 40889.386310100555, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1295840, "time": 40894.21266889572, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1295856, "time": 40894.70556306839, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1296104, "time": 40902.08349394798, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1296128, "time": 40903.0709400177, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1296320, "time": 40909.061171770096, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1296392, "time": 40911.04583525658, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1296576, "time": 40916.94421291351, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1296744, "time": 40921.84892129898, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1296864, "time": 40925.76772737503, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1296896, "time": 40926.74489283562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1296984, "time": 40929.21618127823, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1297144, "time": 40934.234521627426, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1297224, "time": 40936.68326020241, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1297248, "time": 40937.6573908329, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1297272, "time": 40938.173130989075, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1297816, "time": 40954.83972167969, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1297840, "time": 40955.79048371315, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1297936, "time": 40958.75167322159, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1298000, "time": 40960.71075630188, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1298000, "time": 40960.72055864334, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1298008, "time": 40960.75342321396, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1298080, "time": 40963.21079134941, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1298312, "time": 40970.21233820915, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1298680, "time": 40981.53458118439, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1298712, "time": 40982.51521372795, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1298760, "time": 40983.9911544323, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1298928, "time": 40989.37314748764, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1298968, "time": 40990.37560582161, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1298992, "time": 40991.352335214615, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1299056, "time": 40993.31824398041, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1299472, "time": 41006.14402103424, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1299496, "time": 41006.657356500626, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1299584, "time": 41009.58660912514, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1299776, "time": 41015.45689058304, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1299864, "time": 41017.92450404167, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1300000, "time": 41023.15209746361, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 1300000, "time": 41023.23341631889, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 1300000, "time": 41023.59619688988, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1300000, "time": 41023.825377464294, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1300000, "time": 41024.17674422264, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1300000, "time": 41024.27544283867, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1300000, "time": 41025.14650988579, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1300000, "time": 41025.56819939613, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1300128, "time": 41029.485201597214, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1300152, "time": 41030.00062417984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1300352, "time": 41036.32607936859, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1300408, "time": 41037.80970668793, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1300448, "time": 41039.27676129341, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1300904, "time": 41052.985577344894, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1300992, "time": 41056.03564929962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1301024, "time": 41057.01702308655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1301032, "time": 41057.04759955406, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1301184, "time": 41061.91383719444, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1301264, "time": 41064.36368346214, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1301296, "time": 41065.33529090881, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1301416, "time": 41068.78081393242, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1301440, "time": 41069.746173620224, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1301936, "time": 41084.99389600754, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1301960, "time": 41085.508737802505, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1302272, "time": 41095.22629356384, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1302368, "time": 41098.17531085014, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1302464, "time": 41101.11001729965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1302536, "time": 41103.34681534767, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1303072, "time": 41120.39000701904, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1303088, "time": 41120.88522195816, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1303104, "time": 41121.37633252144, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1303216, "time": 41124.83137178421, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1303496, "time": 41133.16405296326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1303760, "time": 41141.459213256836, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1303768, "time": 41141.48850607872, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1304008, "time": 41148.959678411484, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1304208, "time": 41155.30503988266, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1304216, "time": 41155.33453297615, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1304248, "time": 41156.31285238266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1304272, "time": 41157.28714752197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1304360, "time": 41159.724459171295, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1304432, "time": 41162.1476662159, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1304584, "time": 41166.54749131203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1304960, "time": 41178.425240039825, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1304984, "time": 41178.94327998161, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1305024, "time": 41180.38735103607, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1305032, "time": 41180.41533923149, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1305384, "time": 41191.124762535095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1305480, "time": 41194.057968854904, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1305624, "time": 41198.46440029144, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1305640, "time": 41198.95484209061, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1305704, "time": 41200.90885806084, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1305720, "time": 41201.419811964035, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1305888, "time": 41206.92483448982, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1306040, "time": 41211.37664461136, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1306136, "time": 41214.30435657501, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1306320, "time": 41220.11552143097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1306664, "time": 41230.334064006805, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1306696, "time": 41231.33192753792, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1306712, "time": 41231.82113075256, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1307152, "time": 41245.57746100426, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1307256, "time": 41248.514100790024, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1307296, "time": 41249.95721697807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1307400, "time": 41252.91335058212, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1307568, "time": 41258.269614458084, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1307736, "time": 41263.189506053925, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1307936, "time": 41269.631470918655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1307968, "time": 41270.62030363083, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1308256, "time": 41279.38817715645, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1308448, "time": 41285.24374675751, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1308736, "time": 41294.07858943939, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1308816, "time": 41296.52710533142, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1308840, "time": 41297.03632068634, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1308841, "time": 41298.0956864357, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2217923444301926, "train/action_min": 0.0, "train/action_std": 1.8336139941096898, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010504437193496903, "train/actor_opt_grad_steps": 80700.0, "train/actor_opt_loss": -21.422726446123267, "train/adv_mag": 0.8987160743172489, "train/adv_max": 0.37333869103768574, "train/adv_mean": 0.0006782056048516223, "train/adv_min": -0.8256773527581893, "train/adv_std": 0.030776348363478385, "train/cont_avg": 0.9933486862562189, "train/cont_loss_mean": 0.027599377386197818, "train/cont_loss_std": 0.2983832721927421, "train/cont_neg_acc": 0.12622372398329018, "train/cont_neg_loss": 3.3568798552698165, "train/cont_pos_acc": 0.999882495521906, "train/cont_pos_loss": 0.005473476458127745, "train/cont_pred": 0.9936897315789218, "train/cont_rate": 0.9933486862562189, "train/dyn_loss_mean": 1.0000001897859336, "train/dyn_loss_std": 6.07361104825873e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.18064575236457497, "train/extr_critic_critic_opt_grad_steps": 80700.0, "train/extr_critic_critic_opt_loss": 5463.185238358987, "train/extr_critic_mag": 1.7693398378381682, "train/extr_critic_max": 1.7693398378381682, "train/extr_critic_mean": 1.5992367018514604, "train/extr_critic_min": 1.2964781415996267, "train/extr_critic_std": 0.02896490815415311, "train/extr_return_normed_mag": 0.9260427963674365, "train/extr_return_normed_max": 0.39829898948100073, "train/extr_return_normed_mean": 0.05803127501586183, "train/extr_return_normed_min": -0.7961597282495072, "train/extr_return_normed_std": 0.04312116882546031, "train/extr_return_rate": 0.9997635815867144, "train/extr_return_raw_mag": 1.940182551222654, "train/extr_return_raw_max": 1.940182551222654, "train/extr_return_raw_mean": 1.5999149095952807, "train/extr_return_raw_min": 0.7457238334921462, "train/extr_return_raw_std": 0.043121168936663005, "train/extr_reward_mag": 0.3785386091441064, "train/extr_reward_max": 0.3785386091441064, "train/extr_reward_mean": 0.003182819187849649, "train/extr_reward_min": 2.283362013783621e-07, "train/extr_reward_std": 0.011404528081027874, "train/image_loss_mean": 0.08697880361581323, "train/image_loss_std": 0.1027555905319565, "train/model_loss_mean": 0.7369834060099587, "train/model_loss_std": 0.5710515501487314, "train/model_opt_grad_norm": 14.776816272735596, "train/model_opt_grad_steps": 80626.07462686567, "train/model_opt_loss": 3721.5845929046177, "train/model_opt_model_opt_grad_overflow": 0.004975124378109453, "train/model_opt_model_opt_grad_scale": 5024.875621890547, "train/policy_entropy_mag": 1.2832191079410153, "train/policy_entropy_max": 1.2832191079410153, "train/policy_entropy_mean": 0.09136838462222274, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11206489942263607, "train/policy_logprob_mag": 6.551080252993759, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09196322819041969, "train/policy_logprob_min": -6.551080252993759, "train/policy_logprob_std": 0.6316326337667247, "train/policy_randomness_mag": 0.6594442096515675, "train/policy_randomness_max": 0.6594442096515675, "train/policy_randomness_mean": 0.046954063559646035, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.057589969491187616, "train/post_ent_mag": 66.51652238380849, "train/post_ent_max": 66.51652238380849, "train/post_ent_mean": 55.999363154321166, "train/post_ent_min": 45.35862547841238, "train/post_ent_std": 4.836616728436295, "train/prior_ent_mag": 64.38048636972607, "train/prior_ent_max": 64.38048636972607, "train/prior_ent_mean": 56.024705839394336, "train/prior_ent_min": 47.76700931757837, "train/prior_ent_std": 3.6194579221715975, "train/rep_loss_mean": 1.0000001897859336, "train/rep_loss_std": 6.07361104825873e-06, "train/reward_avg": 0.003186900589142495, "train/reward_loss_mean": 0.02240508963210295, "train/reward_loss_std": 0.2800414282087218, "train/reward_max_data": 0.830363803538517, "train/reward_max_pred": 0.2785866367283152, "train/reward_neg_acc": 0.9996583847264152, "train/reward_neg_loss": 0.0039335190960257055, "train/reward_pos_acc": 0.1292525278031826, "train/reward_pos_loss": 4.062946435958147, "train/reward_pred": 0.002382578587724795, "train/reward_rate": 0.0045378575870646766, "train_stats/mean_log_entropy": 0.08477177868582426, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.030021414160728455, "report/cont_loss_std": 0.32911112904548645, "report/cont_neg_acc": 0.125, "report/cont_neg_loss": 3.490385055541992, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002774452557787299, "report/cont_pred": 0.9961708188056946, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11818428337574005, "report/image_loss_std": 0.1135813295841217, "report/model_loss_mean": 0.787352442741394, "report/model_loss_std": 0.8174745440483093, "report/post_ent_mag": 67.7606201171875, "report/post_ent_max": 67.7606201171875, "report/post_ent_mean": 56.72892761230469, "report/post_ent_min": 44.85169219970703, "report/post_ent_std": 6.049152374267578, "report/prior_ent_mag": 65.02084350585938, "report/prior_ent_max": 65.02084350585938, "report/prior_ent_mean": 56.25093078613281, "report/prior_ent_min": 46.8865852355957, "report/prior_ent_std": 4.522260665893555, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.004177856259047985, "report/reward_loss_mean": 0.03914668783545494, "report/reward_loss_std": 0.45845961570739746, "report/reward_max_data": 0.893750011920929, "report/reward_max_pred": 0.03180968761444092, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.001884978380985558, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.4527411460876465, "report/reward_pred": 0.001070199185051024, "report/reward_rate": 0.0068359375, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.004263310693204403, "eval/cont_loss_std": 0.011256350204348564, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004263310693204403, "eval/cont_pred": 0.9958070516586304, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10529550909996033, "eval/image_loss_std": 0.11141519248485565, "eval/model_loss_mean": 0.7126484513282776, "eval/model_loss_std": 0.11197585612535477, "eval/post_ent_mag": 67.81199645996094, "eval/post_ent_max": 67.81199645996094, "eval/post_ent_mean": 56.90968322753906, "eval/post_ent_min": 44.44375228881836, "eval/post_ent_std": 5.486199855804443, "eval/prior_ent_mag": 64.92648315429688, "eval/prior_ent_max": 64.92648315429688, "eval/prior_ent_mean": 56.55522918701172, "eval/prior_ent_min": 46.63067626953125, "eval/prior_ent_std": 3.954072952270508, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0030896200332790613, "eval/reward_loss_std": 0.011015644297003746, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.13286828994750977, "eval/reward_neg_acc": 0.9990234375, "eval/reward_neg_loss": 0.0030896200332790613, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0016456183511763811, "eval/reward_rate": 0.0, "replay/size": 1000000.0, "replay/inserts": 32192.0, "replay/samples": 32192.0, "replay/insert_wait_avg": 1.3174863150769151e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.618506990891564e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3232.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1919453592583684e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3432133197784, "timer/env.step_count": 4024.0, "timer/env.step_total": 40.32583951950073, "timer/env.step_frac": 0.04031200390281433, "timer/env.step_avg": 0.01002133188854392, "timer/env.step_min": 0.00795435905456543, "timer/env.step_max": 0.04026389122009277, "timer/replay._sample_count": 32192.0, "timer/replay._sample_total": 17.94892144203186, "timer/replay._sample_frac": 0.017942763246691966, "timer/replay._sample_avg": 0.000557558444397113, "timer/replay._sample_min": 0.0004444122314453125, "timer/replay._sample_max": 0.01192784309387207, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4428.0, "timer/agent.policy_total": 48.534350633621216, "timer/agent.policy_frac": 0.048517698713177855, "timer/agent.policy_avg": 0.010960783792597384, "timer/agent.policy_min": 0.009391069412231445, "timer/agent.policy_max": 0.08456635475158691, "timer/dataset_train_count": 2012.0, "timer/dataset_train_total": 0.24304604530334473, "timer/dataset_train_frac": 0.0002429626572831564, "timer/dataset_train_avg": 0.00012079823325215941, "timer/dataset_train_min": 0.0001010894775390625, "timer/dataset_train_max": 0.0010390281677246094, "timer/agent.train_count": 2012.0, "timer/agent.train_total": 900.4371793270111, "timer/agent.train_frac": 0.9001282433243935, "timer/agent.train_avg": 0.44753338932754033, "timer/agent.train_min": 0.4330728054046631, "timer/agent.train_max": 0.6836225986480713, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47385215759277344, "timer/agent.report_frac": 0.0004736895810191274, "timer/agent.report_avg": 0.23692607879638672, "timer/agent.report_min": 0.22981810569763184, "timer/agent.report_max": 0.2440340518951416, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.241380190925259e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 32.18023012447239}
{"step": 1308976, "time": 41302.21920180321, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1309112, "time": 41306.162293195724, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1309496, "time": 41318.015268325806, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1309568, "time": 41320.457038640976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1309712, "time": 41325.02663230896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1309880, "time": 41329.950404167175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1310088, "time": 41336.28538990021, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1310088, "time": 41336.995241642, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 1310088, "time": 41337.160420656204, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1310088, "time": 41337.564844846725, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1310088, "time": 41338.213463544846, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1310088, "time": 41338.25979590416, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1310088, "time": 41338.82165789604, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 1310088, "time": 41339.555253982544, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 1310088, "time": 41339.8445520401, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 1310592, "time": 41355.58389186859, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1310864, "time": 41364.388830423355, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1311048, "time": 41369.812262773514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1311128, "time": 41372.27092933655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1311288, "time": 41377.16003203392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1311368, "time": 41379.60147070885, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1311424, "time": 41381.528757572174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1311520, "time": 41384.574148893356, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1311624, "time": 41387.503062963486, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1311712, "time": 41390.41309070587, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1311808, "time": 41393.354691028595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1311880, "time": 41395.31847238541, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1311960, "time": 41397.75090575218, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1312072, "time": 41401.14487409592, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1312200, "time": 41405.042550325394, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1312320, "time": 41408.92506527901, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1312472, "time": 41413.335074424744, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1312480, "time": 41413.906770944595, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1312560, "time": 41416.34860134125, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1312712, "time": 41420.76973438263, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1312888, "time": 41426.124445438385, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1312952, "time": 41428.0940823555, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1312960, "time": 41428.56495833397, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1313136, "time": 41433.93312048912, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 1313136, "time": 41433.94287967682, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1313800, "time": 41454.204795360565, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1313864, "time": 41456.14596390724, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1314272, "time": 41468.84333229065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1314288, "time": 41469.336936712265, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1314432, "time": 41473.758179187775, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1314640, "time": 41480.14762711525, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1314792, "time": 41484.55571889877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1315064, "time": 41492.82869100571, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1315264, "time": 41499.190553188324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1315448, "time": 41504.713386297226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1315448, "time": 41504.72031402588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1315712, "time": 41512.98770403862, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1315824, "time": 41516.44055056572, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1316040, "time": 41522.81421470642, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1316072, "time": 41523.79039859772, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1316256, "time": 41529.60639667511, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1316280, "time": 41530.15287876129, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1316328, "time": 41531.641303539276, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1316456, "time": 41535.7201795578, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1316544, "time": 41538.60266494751, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1316552, "time": 41538.63036084175, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1316600, "time": 41540.1131734848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1316720, "time": 41543.97977614403, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1316744, "time": 41544.49614238739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1316792, "time": 41545.974653959274, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1317000, "time": 41552.29145884514, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1317088, "time": 41555.1957013607, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1317184, "time": 41558.095007419586, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1317280, "time": 41561.0264108181, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1317472, "time": 41566.979731321335, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1317576, "time": 41569.93958735466, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1318112, "time": 41586.51272177696, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1318400, "time": 41595.39528179169, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1318888, "time": 41610.069843530655, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1318912, "time": 41611.200422525406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1319032, "time": 41615.024493694305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1319056, "time": 41615.980999946594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1319112, "time": 41617.45647954941, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1319312, "time": 41623.85659599304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1319384, "time": 41625.837374448776, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1319496, "time": 41629.279262304306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1319496, "time": 41629.28867650032, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1319760, "time": 41637.59422540665, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1319784, "time": 41638.118822813034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1320072, "time": 41647.70020508766, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 1320072, "time": 41648.89817523956, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1320072, "time": 41648.984268665314, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1320072, "time": 41649.2530002594, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1320072, "time": 41649.41884326935, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 1320072, "time": 41649.57280755043, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 1320072, "time": 41649.941259384155, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 1320072, "time": 41650.524914741516, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 1320080, "time": 41650.99966883659, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1320288, "time": 41657.49662423134, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1320384, "time": 41660.41011476517, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1320568, "time": 41665.78258872032, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1320584, "time": 41666.27335643768, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1320704, "time": 41670.150309324265, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1320952, "time": 41677.49597978592, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1321096, "time": 41681.87262749672, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1321144, "time": 41683.32207775116, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1321224, "time": 41685.85531401634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1321360, "time": 41690.22328519821, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1321392, "time": 41691.22596716881, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1321536, "time": 41695.60111737251, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1321752, "time": 41701.98742890358, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1321808, "time": 41703.92465162277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1322040, "time": 41710.78965592384, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1322160, "time": 41714.78004574776, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1322192, "time": 41715.77378964424, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1322264, "time": 41717.74340891838, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1322392, "time": 41721.62295913696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1322768, "time": 41733.25076675415, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1322864, "time": 41736.171581983566, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1322896, "time": 41737.14777135849, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1322904, "time": 41737.17651462555, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1322920, "time": 41737.667174339294, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1323232, "time": 41747.47819876671, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1323288, "time": 41748.96096086502, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1323520, "time": 41756.27291083336, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1323704, "time": 41761.67614221573, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1324336, "time": 41781.351333379745, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1324352, "time": 41781.844108104706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1324384, "time": 41782.827572107315, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1324472, "time": 41785.29580926895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1324472, "time": 41785.30297040939, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1324536, "time": 41787.245887994766, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1324704, "time": 41792.5588388443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1324960, "time": 41800.339485406876, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1325112, "time": 41804.88007926941, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1325120, "time": 41805.35405373573, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1325232, "time": 41808.76600027084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1325512, "time": 41817.09895968437, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1325728, "time": 41823.91231060028, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1325768, "time": 41824.91460967064, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1325864, "time": 41827.8202559948, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1325928, "time": 41829.786762952805, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1325928, "time": 41829.79765701294, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1326232, "time": 41839.13855600357, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1326256, "time": 41840.08956503868, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1326480, "time": 41846.9177942276, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1326608, "time": 41850.84050321579, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1326664, "time": 41852.348039627075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1326872, "time": 41858.73469853401, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1327328, "time": 41873.48667860031, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1327448, "time": 41876.91810750961, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1327896, "time": 41890.605883836746, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1327896, "time": 41890.61951947212, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1328040, "time": 41895.1515917778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1328176, "time": 41899.50027704239, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1328240, "time": 41901.43863916397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1328504, "time": 41909.3179833889, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1328544, "time": 41910.778485774994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1328992, "time": 41924.62850809097, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1329024, "time": 41925.61487364769, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1329184, "time": 41930.591757297516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1329568, "time": 41942.3749089241, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1329728, "time": 41947.27070116997, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1329752, "time": 41947.78097343445, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1329760, "time": 41948.25687122345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1329968, "time": 41954.71233010292, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 1330056, "time": 41958.57003688812, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 1330056, "time": 41958.61848473549, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 1330056, "time": 41959.95431852341, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1330056, "time": 41960.186002492905, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 1330056, "time": 41960.516105890274, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 1330056, "time": 41960.85691714287, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1330056, "time": 41960.86561393738, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 1330056, "time": 41961.84799027443, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 1330224, "time": 41967.1894493103, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1330488, "time": 41974.97196984291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1330560, "time": 41977.399399995804, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1330560, "time": 41977.40838909149, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1330592, "time": 41978.39335989952, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1330872, "time": 41986.7980298996, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1330896, "time": 41987.750546216965, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1331248, "time": 41998.43494749069, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1331288, "time": 41999.43229174614, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1331336, "time": 42000.91178703308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1331592, "time": 42008.70563220978, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1331832, "time": 42016.15458011627, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1332064, "time": 42023.470029354095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1332104, "time": 42024.47221469879, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1332280, "time": 42029.91721653938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1332400, "time": 42033.78441476822, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1332488, "time": 42036.27195191383, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1332720, "time": 42043.52616214752, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1332760, "time": 42044.66144323349, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1332904, "time": 42049.01565527916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1333328, "time": 42062.165704488754, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1333368, "time": 42063.1761341095, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1333528, "time": 42068.072905778885, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1333560, "time": 42069.06918549538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1333648, "time": 42071.98888754845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1333744, "time": 42075.07790470123, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1333856, "time": 42078.481315374374, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1333904, "time": 42079.9548933506, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1334040, "time": 42083.88748669624, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1334192, "time": 42088.74225974083, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1334392, "time": 42094.5905046463, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1334400, "time": 42095.06199097633, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1334488, "time": 42097.50496339798, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1334592, "time": 42100.9050719738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1334648, "time": 42102.386402606964, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1334840, "time": 42108.336540937424, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1335064, "time": 42115.14944815636, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1335256, "time": 42120.965883255005, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1335384, "time": 42125.32531833649, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1335544, "time": 42130.17890906334, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1335784, "time": 42137.630940675735, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1335840, "time": 42139.58879852295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1335872, "time": 42140.56860637665, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1336072, "time": 42146.43001508713, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1336504, "time": 42159.59482431412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1336528, "time": 42160.54333257675, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1336704, "time": 42166.038241147995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1336712, "time": 42166.0685813427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1336864, "time": 42170.9244055748, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1336920, "time": 42172.435368299484, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1336936, "time": 42172.92639708519, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1337480, "time": 42189.44223570824, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1337696, "time": 42196.32387018204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1337728, "time": 42197.3227455616, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1337856, "time": 42201.19389009476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1337960, "time": 42204.153493881226, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1338184, "time": 42211.001435518265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1338248, "time": 42212.98844099045, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1338464, "time": 42219.840557813644, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1338632, "time": 42224.87153291702, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1338736, "time": 42228.27323794365, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1338840, "time": 42231.22245550156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1338856, "time": 42231.71502876282, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1339368, "time": 42247.37208247185, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1339448, "time": 42249.804799079895, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1339464, "time": 42250.298073768616, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1339792, "time": 42260.60397911072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1339944, "time": 42265.002202034, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1340024, "time": 42267.43833231926, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1340040, "time": 42267.93157124519, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1340040, "time": 42269.520389556885, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1340040, "time": 42269.72352361679, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1340040, "time": 42270.47603726387, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 1340040, "time": 42270.5657248497, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 1340040, "time": 42271.00619864464, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 1340040, "time": 42271.131365060806, "eval_episode/length": 155.0, "eval_episode/score": 0.515625, "eval_episode/reward_rate": 0.00641025641025641}
{"step": 1340040, "time": 42272.3078584671, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1340040, "time": 42272.37255334854, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 1340056, "time": 42272.863301754, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1340168, "time": 42276.285517692566, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1340248, "time": 42278.73498797417, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1340536, "time": 42287.67890357971, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1340776, "time": 42295.03260946274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1340808, "time": 42296.01423072815, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1340857, "time": 42298.68544006348, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.261197814941406, "train/action_min": 0.0, "train/action_std": 1.8397185319662095, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01092126518022269, "train/actor_opt_grad_steps": 82705.0, "train/actor_opt_loss": -21.758105173110962, "train/adv_mag": 0.8629790115356445, "train/adv_max": 0.349055147767067, "train/adv_mean": -0.0006171565094155085, "train/adv_min": -0.7844891458749771, "train/adv_std": 0.031220145407132804, "train/cont_avg": 0.9935888671875, "train/cont_loss_mean": 0.02797651176340878, "train/cont_loss_std": 0.30117480296641586, "train/cont_neg_acc": 0.11048052176833152, "train/cont_neg_loss": 3.450529162287712, "train/cont_pos_acc": 0.9998378795385361, "train/cont_pos_loss": 0.00580823568161577, "train/cont_pred": 0.9935900303721428, "train/cont_rate": 0.9935888671875, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.160500902030617, "train/extr_critic_critic_opt_grad_steps": 82705.0, "train/extr_critic_critic_opt_loss": 4634.066236572266, "train/extr_critic_mag": 1.735734543800354, "train/extr_critic_max": 1.735734543800354, "train/extr_critic_mean": 1.5807568395137788, "train/extr_critic_min": 1.3151574110984803, "train/extr_critic_std": 0.026832659980282187, "train/extr_return_normed_mag": 0.9030431288480759, "train/extr_return_normed_max": 0.3924925094842911, "train/extr_return_normed_mean": 0.053587780091911556, "train/extr_return_normed_min": -0.7618175780773163, "train/extr_return_normed_std": 0.04249691925942898, "train/extr_return_rate": 0.9996995717287064, "train/extr_return_raw_mag": 1.9190443801879882, "train/extr_return_raw_max": 1.9190443801879882, "train/extr_return_raw_mean": 1.580139718055725, "train/extr_return_raw_min": 0.7647342926263809, "train/extr_return_raw_std": 0.042496919250115756, "train/extr_reward_mag": 0.38085689723491667, "train/extr_reward_max": 0.38085689723491667, "train/extr_reward_mean": 0.0031264306756202133, "train/extr_reward_min": 3.4451484680175783e-07, "train/extr_reward_std": 0.011131435316056013, "train/image_loss_mean": 0.08647025376558304, "train/image_loss_std": 0.10229548461735248, "train/model_loss_mean": 0.7362943544983864, "train/model_loss_std": 0.5644376324117184, "train/model_opt_grad_norm": 14.120971276760102, "train/model_opt_grad_steps": 82629.135, "train/model_opt_loss": 3790.8356079101563, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5150.0, "train/policy_entropy_mag": 1.271147962808609, "train/policy_entropy_max": 1.271147962808609, "train/policy_entropy_mean": 0.09071721877902746, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11018896944820882, "train/policy_logprob_mag": 6.55108026266098, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09041058205068112, "train/policy_logprob_min": -6.55108026266098, "train/policy_logprob_std": 0.6267033916711807, "train/policy_randomness_mag": 0.653240869641304, "train/policy_randomness_max": 0.653240869641304, "train/policy_randomness_mean": 0.046619431246072054, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.056625932324677705, "train/post_ent_mag": 68.13990509033204, "train/post_ent_max": 68.13990509033204, "train/post_ent_mean": 57.0135534286499, "train/post_ent_min": 44.92697734832764, "train/post_ent_std": 5.255347232818604, "train/prior_ent_mag": 68.56675243377686, "train/prior_ent_max": 68.56675243377686, "train/prior_ent_mean": 57.38174039840698, "train/prior_ent_min": 46.158518657684326, "train/prior_ent_std": 4.866127663850785, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0030153350828913974, "train/reward_loss_mean": 0.021847566657233985, "train/reward_loss_std": 0.27420621619559826, "train/reward_max_data": 0.8136875014007091, "train/reward_max_pred": 0.256303146481514, "train/reward_neg_acc": 0.9995240437984466, "train/reward_neg_loss": 0.004125699290307238, "train/reward_pos_acc": 0.11721799759702249, "train/reward_pos_loss": 4.091376190233713, "train/reward_pred": 0.0024226869200356304, "train/reward_rate": 0.0043310546875, "train_stats/mean_log_entropy": 0.08263156286596712, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9892578125, "report/cont_loss_mean": 0.03905615210533142, "report/cont_loss_std": 0.3412666916847229, "report/cont_neg_acc": 0.09090909361839294, "report/cont_neg_loss": 3.180407762527466, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004944732878357172, "report/cont_pred": 0.9942457675933838, "report/cont_rate": 0.9892578125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10827077925205231, "report/image_loss_std": 0.1209220364689827, "report/model_loss_mean": 0.7927072048187256, "report/model_loss_std": 0.8036792278289795, "report/post_ent_mag": 67.5447998046875, "report/post_ent_max": 67.5447998046875, "report/post_ent_mean": 57.202484130859375, "report/post_ent_min": 45.64391326904297, "report/post_ent_std": 5.082276821136475, "report/prior_ent_mag": 68.73966217041016, "report/prior_ent_max": 68.73966217041016, "report/prior_ent_mean": 57.08991622924805, "report/prior_ent_min": 46.89110565185547, "report/prior_ent_std": 4.8084940910339355, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00744018517434597, "report/reward_loss_mean": 0.04538024589419365, "report/reward_loss_std": 0.4179411232471466, "report/reward_max_data": 0.90625, "report/reward_max_pred": 0.13776767253875732, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0039613922126591206, "report/reward_pos_acc": 0.1818181872367859, "report/reward_pos_loss": 3.85968017578125, "report/reward_pred": 0.0024797830265015364, "report/reward_rate": 0.0107421875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.018975507467985153, "eval/cont_loss_std": 0.2466968446969986, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.352754592895508, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.006241583731025457, "eval/cont_pred": 0.9938114881515503, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10172819346189499, "eval/image_loss_std": 0.11686117947101593, "eval/model_loss_mean": 0.7421531677246094, "eval/model_loss_std": 0.6051017642021179, "eval/post_ent_mag": 67.75791931152344, "eval/post_ent_max": 67.75791931152344, "eval/post_ent_mean": 57.294464111328125, "eval/post_ent_min": 45.13239669799805, "eval/post_ent_std": 4.820544242858887, "eval/prior_ent_mag": 68.70585632324219, "eval/prior_ent_max": 68.70585632324219, "eval/prior_ent_mean": 57.19537353515625, "eval/prior_ent_min": 45.426734924316406, "eval/prior_ent_std": 4.591262340545654, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0022094727028161287, "eval/reward_loss_mean": 0.02144942805171013, "eval/reward_loss_std": 0.3237684369087219, "eval/reward_max_data": 0.796875, "eval/reward_max_pred": 0.20740747451782227, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.004868623800575733, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.664449691772461, "eval/reward_pred": 0.00261567160487175, "eval/reward_rate": 0.0029296875, "replay/size": 1000000.0, "replay/inserts": 32016.0, "replay/samples": 32016.0, "replay/insert_wait_avg": 1.3309767816973472e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0542366756075087e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6064.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2000742562528022e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2069940567016602e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.437260389328, "timer/env.step_count": 4002.0, "timer/env.step_total": 40.46444582939148, "timer/env.step_frac": 0.04044676006333913, "timer/env.step_avg": 0.010111055929383179, "timer/env.step_min": 0.008068561553955078, "timer/env.step_max": 0.05046868324279785, "timer/replay._sample_count": 32016.0, "timer/replay._sample_total": 17.907898426055908, "timer/replay._sample_frac": 0.017900071433851743, "timer/replay._sample_avg": 0.0005593421547368787, "timer/replay._sample_min": 0.0004467964172363281, "timer/replay._sample_max": 0.013414144515991211, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4760.0, "timer/agent.policy_total": 52.75929617881775, "timer/agent.policy_frac": 0.05273623671142162, "timer/agent.policy_avg": 0.011083885751852469, "timer/agent.policy_min": 0.009437322616577148, "timer/agent.policy_max": 0.08996152877807617, "timer/dataset_train_count": 2001.0, "timer/dataset_train_total": 0.2459723949432373, "timer/dataset_train_frac": 0.00024586488796660296, "timer/dataset_train_avg": 0.00012292473510406663, "timer/dataset_train_min": 0.00010418891906738281, "timer/dataset_train_max": 0.0010578632354736328, "timer/agent.train_count": 2001.0, "timer/agent.train_total": 892.506551027298, "timer/agent.train_frac": 0.8921164638349955, "timer/agent.train_avg": 0.4460302603834573, "timer/agent.train_min": 0.4339118003845215, "timer/agent.train_max": 0.6902897357940674, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4802098274230957, "timer/agent.report_frac": 0.0004799999424613776, "timer/agent.report_avg": 0.24010491371154785, "timer/agent.report_min": 0.23177886009216309, "timer/agent.report_max": 0.24843096733093262, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.1457497323879126e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 32.00131606939515}
{"step": 1340936, "time": 42300.90941429138, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1340944, "time": 42301.38351583481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1341200, "time": 42309.207182884216, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1341304, "time": 42312.17800831795, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1341344, "time": 42313.65883684158, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1341368, "time": 42314.27615070343, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1341712, "time": 42325.092542648315, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1341760, "time": 42326.55766701698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1341784, "time": 42327.072222948074, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1341896, "time": 42330.50482869148, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1341912, "time": 42330.99860167503, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1342184, "time": 42339.28061771393, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1342352, "time": 42344.78535437584, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1342368, "time": 42345.274983644485, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1342632, "time": 42353.11936402321, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1342824, "time": 42358.983858823776, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1342832, "time": 42359.471987724304, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1342848, "time": 42359.96458411217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1343184, "time": 42370.22415089607, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1343208, "time": 42370.738089084625, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1343480, "time": 42379.17430257797, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1343512, "time": 42380.67604589462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1343648, "time": 42385.032375097275, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1343664, "time": 42385.5215215683, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1343688, "time": 42386.03514814377, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1343936, "time": 42393.81285071373, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1344072, "time": 42397.74351143837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1344128, "time": 42399.69382476807, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1344168, "time": 42400.69882488251, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1344216, "time": 42402.16143941879, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 1344224, "time": 42402.631452560425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1344360, "time": 42406.6853852272, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1344520, "time": 42411.5942504406, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1344688, "time": 42416.9956703186, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1344728, "time": 42418.00156545639, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1344824, "time": 42420.921424627304, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1344992, "time": 42426.3135766983, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1345024, "time": 42427.289935112, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1345184, "time": 42432.18584537506, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1345384, "time": 42438.216346263885, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1345440, "time": 42440.15891075134, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1345584, "time": 42444.567923069, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1345696, "time": 42447.961893081665, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1345824, "time": 42451.87940955162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1346088, "time": 42459.75786066055, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1346168, "time": 42462.20294904709, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1346216, "time": 42463.700779914856, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1346248, "time": 42464.75083947182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1346696, "time": 42478.426344156265, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1346816, "time": 42482.29443025589, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1347000, "time": 42487.71651172638, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1347176, "time": 42493.10427570343, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1347336, "time": 42498.10114192963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1347376, "time": 42499.537247896194, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1347512, "time": 42503.45339846611, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1347696, "time": 42509.26573872566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1347840, "time": 42513.68452620506, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1347856, "time": 42514.17723941803, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1348024, "time": 42519.0533759594, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1348032, "time": 42519.522267341614, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1348240, "time": 42525.97054696083, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1348256, "time": 42526.45993852615, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1348264, "time": 42526.4876229763, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1348376, "time": 42529.89342737198, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1348400, "time": 42530.84539818764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1348584, "time": 42536.2305893898, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1348664, "time": 42538.69227433205, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1348992, "time": 42548.967542886734, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1349104, "time": 42552.421387434006, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1349168, "time": 42554.52098321915, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1349456, "time": 42563.33545804024, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1349512, "time": 42564.81900024414, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1349552, "time": 42566.281041145325, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1349688, "time": 42570.195496320724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1349704, "time": 42570.69143533707, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1349720, "time": 42571.20530080795, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1349728, "time": 42571.6739192009, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1350024, "time": 42581.709886312485, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1350024, "time": 42581.95813989639, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1350024, "time": 42582.71474528313, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1350024, "time": 42582.889021873474, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1350024, "time": 42582.96537065506, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 1350024, "time": 42583.164689064026, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 1350024, "time": 42583.79325962067, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 1350024, "time": 42584.23044013977, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1350176, "time": 42589.127313137054, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1350312, "time": 42593.058950185776, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1350344, "time": 42594.03836560249, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1350536, "time": 42599.92395091057, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1350584, "time": 42601.39451789856, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1350688, "time": 42604.80034708977, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1350752, "time": 42606.770131111145, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1350840, "time": 42609.26404714584, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1351056, "time": 42616.28674650192, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1351632, "time": 42633.87246441841, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1351696, "time": 42636.29250884056, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1351760, "time": 42638.23166799545, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1351768, "time": 42638.26223754883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1351784, "time": 42638.756345272064, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1351824, "time": 42640.23656153679, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1352000, "time": 42645.7333009243, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1352032, "time": 42646.712154626846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1352064, "time": 42647.687425136566, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1352136, "time": 42649.67835211754, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 1352496, "time": 42660.91516137123, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1352544, "time": 42662.38895654678, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1352736, "time": 42668.293452739716, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1352848, "time": 42671.73142170906, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1352888, "time": 42672.73822140694, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1352928, "time": 42674.35602283478, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1353048, "time": 42677.80094742775, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1353264, "time": 42684.653220653534, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1353424, "time": 42689.569050073624, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1353808, "time": 42701.297538518906, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1353888, "time": 42703.858708143234, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1353920, "time": 42704.86946153641, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1354104, "time": 42710.29433989525, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1354128, "time": 42711.256833314896, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1354344, "time": 42717.6406481266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1354528, "time": 42723.494579553604, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1354552, "time": 42724.00658965111, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1354760, "time": 42730.41663479805, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1354816, "time": 42732.35582137108, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 1355248, "time": 42745.82606673241, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1355352, "time": 42748.83981657028, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1355440, "time": 42751.74894142151, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1355576, "time": 42755.721996068954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1355744, "time": 42761.102643013, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1356296, "time": 42778.21907067299, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1356416, "time": 42782.10457968712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1356440, "time": 42782.63956570625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1356656, "time": 42789.50248336792, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1356656, "time": 42789.51264858246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1357056, "time": 42801.964012384415, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1357096, "time": 42802.99523139, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1357128, "time": 42803.98134160042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1357184, "time": 42805.93153214455, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1357360, "time": 42811.36341357231, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1357496, "time": 42815.348167181015, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1357664, "time": 42820.76834106445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1357888, "time": 42827.81982541084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1358080, "time": 42833.82142281532, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1358136, "time": 42835.34762763977, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1358184, "time": 42836.82858109474, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1358408, "time": 42843.772438287735, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1358752, "time": 42854.78218102455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1358768, "time": 42855.28300738335, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1359152, "time": 42867.1503071785, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1359496, "time": 42877.53963017464, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1359608, "time": 42880.96271896362, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1359808, "time": 42887.50506687164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1360000, "time": 42894.00658893585, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1360008, "time": 42895.129257917404, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 1360008, "time": 42895.41427755356, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1360008, "time": 42895.79372406006, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1360008, "time": 42895.80042409897, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1360008, "time": 42895.91403388977, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1360008, "time": 42896.31392288208, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 1360008, "time": 42896.50824570656, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 1360008, "time": 42897.21736764908, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 1360200, "time": 42903.10289025307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1360448, "time": 42910.96674180031, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1360592, "time": 42915.5108191967, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1360720, "time": 42919.39142155647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1360728, "time": 42919.42053627968, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1360832, "time": 42922.82689881325, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1361064, "time": 42929.70444011688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1361440, "time": 42941.46317911148, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1361464, "time": 42941.983296871185, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1361464, "time": 42941.99034023285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1361688, "time": 42948.95631766319, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1361712, "time": 42949.92579674721, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1361728, "time": 42950.416086912155, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1361960, "time": 42957.27600169182, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1362088, "time": 42961.19811964035, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1362472, "time": 42972.928389549255, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1362656, "time": 42978.889222860336, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1362760, "time": 42981.868080616, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1362816, "time": 42983.81876587868, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1363032, "time": 42990.27155613899, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1363192, "time": 42995.21054816246, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1363240, "time": 42996.69183135033, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1363272, "time": 42997.68491101265, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1363360, "time": 43000.6458261013, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1363632, "time": 43009.117592573166, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1363712, "time": 43011.55125427246, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1363776, "time": 43013.51222872734, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1363776, "time": 43013.52197408676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1363904, "time": 43017.48107767105, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1364040, "time": 43021.443600177765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1364216, "time": 43026.853657245636, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1364224, "time": 43027.328264951706, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1364272, "time": 43028.829855680466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1364304, "time": 43029.823863744736, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1364344, "time": 43030.83559823036, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1364392, "time": 43032.31795859337, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1364672, "time": 43041.26261425018, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1364680, "time": 43041.294478178024, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1364768, "time": 43044.237674474716, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1364928, "time": 43049.14189743996, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1364936, "time": 43049.17040801048, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1365024, "time": 43052.08030653, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1365160, "time": 43055.99616765976, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1365432, "time": 43064.42099714279, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1365592, "time": 43069.36327409744, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1365632, "time": 43070.81347846985, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1365680, "time": 43072.28940367699, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1366120, "time": 43085.55432391167, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1366160, "time": 43087.00248670578, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1366336, "time": 43092.3919365406, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1366568, "time": 43099.4449903965, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1366656, "time": 43102.36508965492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1366704, "time": 43103.86538720131, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1367184, "time": 43118.74429297447, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1367248, "time": 43120.70991516113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1367360, "time": 43124.274701833725, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1367744, "time": 43136.14665579796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1367904, "time": 43141.069761514664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1367920, "time": 43141.56633377075, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1368032, "time": 43145.0280816555, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 1368056, "time": 43145.54408288002, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1368432, "time": 43157.992797613144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1368696, "time": 43165.84654688835, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1368752, "time": 43167.81179976463, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1368880, "time": 43171.72941470146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1369016, "time": 43175.6613407135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1369040, "time": 43176.62660741806, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1369064, "time": 43177.14910507202, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1369368, "time": 43186.651388168335, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1369632, "time": 43195.00656938553, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1369672, "time": 43196.019313812256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1369712, "time": 43197.49983239174, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1370048, "time": 43207.81876587868, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1370096, "time": 43210.60779833794, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1370096, "time": 43210.76327610016, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1370096, "time": 43210.87565946579, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1370096, "time": 43211.26550769806, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1370096, "time": 43211.402273893356, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 1370096, "time": 43211.43152427673, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1370096, "time": 43212.15393972397, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 1370096, "time": 43212.82176923752, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1370344, "time": 43220.31733417511, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1370424, "time": 43222.78917551041, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1370472, "time": 43224.270107746124, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1370552, "time": 43226.74459004402, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1370680, "time": 43230.651386260986, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1370744, "time": 43232.58679676056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1371160, "time": 43245.438525915146, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1371352, "time": 43251.308832883835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1371432, "time": 43253.77513718605, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1371944, "time": 43269.41050744057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1372400, "time": 43283.631654024124, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1372656, "time": 43291.43277812004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1372784, "time": 43295.34266209602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1372816, "time": 43296.31946802139, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1372864, "time": 43297.79053068161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1372873, "time": 43298.88429379463, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2753695678710937, "train/action_min": 0.0, "train/action_std": 1.8357470828294753, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010791850836249069, "train/actor_opt_grad_steps": 84705.0, "train/actor_opt_loss": -22.32047552585602, "train/adv_mag": 0.8198702543973923, "train/adv_max": 0.32124684810638426, "train/adv_mean": -0.00046215440491977235, "train/adv_min": -0.7653167396783829, "train/adv_std": 0.02920889058616012, "train/cont_avg": 0.9933740234375, "train/cont_loss_mean": 0.028799353833310306, "train/cont_loss_std": 0.30133252680301664, "train/cont_neg_acc": 0.0993475852534175, "train/cont_neg_loss": 3.415928555727005, "train/cont_pos_acc": 0.9997936022281647, "train/cont_pos_loss": 0.006144427534891293, "train/cont_pred": 0.9933455699682235, "train/cont_rate": 0.9933740234375, "train/dyn_loss_mean": 1.0000080078840257, "train/dyn_loss_std": 0.00016013552762160542, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11981423827819526, "train/extr_critic_critic_opt_grad_steps": 84705.0, "train/extr_critic_critic_opt_loss": 4933.94168334961, "train/extr_critic_mag": 1.7010459578037262, "train/extr_critic_max": 1.7010459578037262, "train/extr_critic_mean": 1.5481601840257644, "train/extr_critic_min": 1.2797170293331146, "train/extr_critic_std": 0.02729134723544121, "train/extr_return_normed_mag": 0.866118625998497, "train/extr_return_normed_max": 0.3497500032186508, "train/extr_return_normed_mean": 0.056019773073494435, "train/extr_return_normed_min": -0.7428155225515366, "train/extr_return_normed_std": 0.04095521504059434, "train/extr_return_rate": 0.99971226811409, "train/extr_return_raw_mag": 1.8414281904697418, "train/extr_return_raw_max": 1.8414281904697418, "train/extr_return_raw_mean": 1.5476980471611024, "train/extr_return_raw_min": 0.7488626646995544, "train/extr_return_raw_std": 0.04095521525479853, "train/extr_reward_mag": 0.3280085611343384, "train/extr_reward_max": 0.3280085611343384, "train/extr_reward_mean": 0.003107017377042212, "train/extr_reward_min": 2.9683113098144534e-07, "train/extr_reward_std": 0.010138810041826218, "train/image_loss_mean": 0.08795011157169938, "train/image_loss_std": 0.10293075662106276, "train/model_loss_mean": 0.7401596531271935, "train/model_loss_std": 0.5794197858870029, "train/model_opt_grad_norm": 14.482000303268432, "train/model_opt_grad_steps": 84627.205, "train/model_opt_loss": 3883.4502001953124, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5250.0, "train/policy_entropy_mag": 1.24566459774971, "train/policy_entropy_max": 1.24566459774971, "train/policy_entropy_mean": 0.09021501027047635, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10914002604782581, "train/policy_logprob_mag": 6.551080250740052, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09021395649760962, "train/policy_logprob_min": -6.551080250740052, "train/policy_logprob_std": 0.6274781113862992, "train/policy_randomness_mag": 0.6401450082659721, "train/policy_randomness_max": 0.6401450082659721, "train/policy_randomness_mean": 0.046361347790807486, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05608688194304705, "train/post_ent_mag": 69.04572978973388, "train/post_ent_max": 69.04572978973388, "train/post_ent_mean": 57.0830157661438, "train/post_ent_min": 44.03842754364014, "train/post_ent_std": 5.566237156391144, "train/prior_ent_mag": 69.6787194442749, "train/prior_ent_max": 69.6787194442749, "train/prior_ent_mean": 57.81361326217652, "train/prior_ent_min": 45.08057525634766, "train/prior_ent_std": 5.374824500083923, "train/rep_loss_mean": 1.0000080078840257, "train/rep_loss_std": 0.00016013552762160542, "train/reward_avg": 0.0033089447018573993, "train/reward_loss_mean": 0.02340535995317623, "train/reward_loss_std": 0.2847609965130687, "train/reward_max_data": 0.8378749999403954, "train/reward_max_pred": 0.3119779133796692, "train/reward_neg_acc": 0.9994407787919044, "train/reward_neg_loss": 0.004461688548326492, "train/reward_pos_acc": 0.1291198079010949, "train/reward_pos_loss": 4.036211582883518, "train/reward_pred": 0.0026083746447693556, "train/reward_rate": 0.004697265625, "train_stats/mean_log_entropy": 0.08309095481346393, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.013436935842037201, "report/cont_loss_std": 0.1791476309299469, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.048396110534668, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005540733225643635, "report/cont_pred": 0.9945101141929626, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06809934228658676, "report/image_loss_std": 0.08486223220825195, "report/model_loss_mean": 0.6898027658462524, "report/model_loss_std": 0.3162001371383667, "report/post_ent_mag": 67.23462677001953, "report/post_ent_max": 67.23462677001953, "report/post_ent_mean": 55.45412063598633, "report/post_ent_min": 44.051639556884766, "report/post_ent_std": 5.424509525299072, "report/prior_ent_mag": 71.88307189941406, "report/prior_ent_max": 71.88307189941406, "report/prior_ent_mean": 58.609275817871094, "report/prior_ent_min": 45.80316925048828, "report/prior_ent_std": 5.792600154876709, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006347656017169356, "report/reward_loss_mean": 0.008266511373221874, "report/reward_loss_std": 0.14543645083904266, "report/reward_max_data": 0.6499999761581421, "report/reward_max_pred": 0.04406857490539551, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0037289082538336515, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.650234222412109, "report/reward_pred": 0.001993706449866295, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02012847736477852, "eval/cont_loss_std": 0.2650854289531708, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.6726861000061035, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0064578852616250515, "eval/cont_pred": 0.9936648011207581, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09435667097568512, "eval/image_loss_std": 0.11286530643701553, "eval/model_loss_mean": 0.7360096573829651, "eval/model_loss_std": 0.6376955509185791, "eval/post_ent_mag": 67.56742858886719, "eval/post_ent_max": 67.56742858886719, "eval/post_ent_mean": 55.40508270263672, "eval/post_ent_min": 42.677490234375, "eval/post_ent_std": 5.502509593963623, "eval/prior_ent_mag": 71.36776733398438, "eval/prior_ent_max": 71.36776733398438, "eval/prior_ent_mean": 58.55598449707031, "eval/prior_ent_min": 45.21171188354492, "eval/prior_ent_std": 5.773318290710449, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0024505616165697575, "eval/reward_loss_mean": 0.021524501964449883, "eval/reward_loss_std": 0.33656784892082214, "eval/reward_max_data": 0.965624988079071, "eval/reward_max_pred": 0.06080472469329834, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.003756122197955847, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.068696975708008, "eval/reward_pred": 0.0019077000906690955, "eval/reward_rate": 0.0029296875, "replay/size": 1000000.0, "replay/inserts": 32016.0, "replay/samples": 32016.0, "replay/insert_wait_avg": 1.3498471177619198e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.819723736459407e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3728.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2664068410324947e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.4901161193847656e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3059282302856, "timer/env.step_count": 4002.0, "timer/env.step_total": 40.9504656791687, "timer/env.step_frac": 0.040937941607141294, "timer/env.step_avg": 0.010232500169707321, "timer/env.step_min": 0.008226871490478516, "timer/env.step_max": 0.03843998908996582, "timer/replay._sample_count": 32016.0, "timer/replay._sample_total": 18.04603099822998, "timer/replay._sample_frac": 0.01804051189635208, "timer/replay._sample_avg": 0.0005636566403744997, "timer/replay._sample_min": 0.00044417381286621094, "timer/replay._sample_max": 0.012206077575683594, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4468.0, "timer/agent.policy_total": 50.09751749038696, "timer/agent.policy_frac": 0.05008219593281642, "timer/agent.policy_avg": 0.011212515105279087, "timer/agent.policy_min": 0.009541749954223633, "timer/agent.policy_max": 0.08907675743103027, "timer/dataset_train_count": 2001.0, "timer/dataset_train_total": 0.24768781661987305, "timer/dataset_train_frac": 0.00024761206509899995, "timer/dataset_train_avg": 0.00012378201730128588, "timer/dataset_train_min": 0.00010704994201660156, "timer/dataset_train_max": 0.0005168914794921875, "timer/agent.train_count": 2001.0, "timer/agent.train_total": 897.0445330142975, "timer/agent.train_frac": 0.8967701856984138, "timer/agent.train_avg": 0.4482981174484245, "timer/agent.train_min": 0.43566083908081055, "timer/agent.train_max": 0.7295877933502197, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4806835651397705, "timer/agent.report_frac": 0.00048053655544177666, "timer/agent.report_avg": 0.24034178256988525, "timer/agent.report_min": 0.2329120635986328, "timer/agent.report_max": 0.2477715015411377, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.217666442870577e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 32.00552812899868}
{"step": 1372952, "time": 43301.09119462967, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1373056, "time": 43304.629762887955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1373128, "time": 43306.62966299057, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1373160, "time": 43307.60718536377, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1373328, "time": 43313.02998113632, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1373472, "time": 43317.53254413605, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1373544, "time": 43319.54110956192, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1373592, "time": 43321.03397798538, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1373664, "time": 43323.4648706913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1373680, "time": 43323.96404647827, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1373936, "time": 43331.81360530853, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1374080, "time": 43336.35333967209, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1374240, "time": 43341.24604177475, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1374392, "time": 43345.737035512924, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1374584, "time": 43351.612181186676, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1374600, "time": 43352.10930895805, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1374648, "time": 43353.57079744339, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1374776, "time": 43357.491137981415, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1375000, "time": 43364.529906988144, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1375104, "time": 43367.942621946335, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1375208, "time": 43370.94662451744, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1375440, "time": 43378.279644966125, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1375784, "time": 43388.70140457153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1375840, "time": 43390.69648742676, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1375904, "time": 43392.692343473434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1376048, "time": 43397.21668124199, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1376200, "time": 43401.62926697731, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1376512, "time": 43411.91502356529, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1376528, "time": 43412.40789484978, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1376552, "time": 43412.93016052246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1376792, "time": 43420.314234018326, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 1377416, "time": 43439.6087334156, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1377424, "time": 43440.08805990219, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1377448, "time": 43440.60999393463, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1377488, "time": 43442.08293914795, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1377520, "time": 43443.07825422287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1378064, "time": 43459.975282907486, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1378096, "time": 43460.95793056488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1378144, "time": 43462.42962169647, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1378152, "time": 43462.46058988571, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1378264, "time": 43465.89938402176, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1378272, "time": 43466.3715133667, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1378440, "time": 43471.27200102806, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1378512, "time": 43473.74437379837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1378768, "time": 43481.54280114174, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1378896, "time": 43485.568122148514, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1378896, "time": 43485.57591342926, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1379024, "time": 43489.48194003105, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1379184, "time": 43494.37237453461, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1379376, "time": 43500.27183461189, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1379384, "time": 43500.30051469803, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1379384, "time": 43500.31021237373, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1379576, "time": 43506.19759440422, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1379688, "time": 43509.65800857544, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1379696, "time": 43510.13170027733, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1379728, "time": 43511.11381602287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1379744, "time": 43511.61495733261, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1379976, "time": 43518.67421579361, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1380080, "time": 43523.05377078056, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 1380080, "time": 43523.28904628754, "eval_episode/length": 11.0, "eval_episode/score": 0.965624988079071, "eval_episode/reward_rate": 0.08333333333333333}
{"step": 1380080, "time": 43523.82121157646, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1380080, "time": 43524.14924573898, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1380080, "time": 43524.232820510864, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1380080, "time": 43524.8683757782, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 1380080, "time": 43525.320548295975, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 1380080, "time": 43525.765610694885, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 1380200, "time": 43529.61374473572, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1380456, "time": 43537.4442179203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1380488, "time": 43538.42123866081, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1380632, "time": 43542.83006596565, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1380696, "time": 43544.89796042442, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1380880, "time": 43550.74205875397, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1380936, "time": 43552.24875497818, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1381208, "time": 43560.578161001205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1381320, "time": 43564.035214185715, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1381520, "time": 43570.37321853638, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1381576, "time": 43571.888874292374, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1381688, "time": 43575.50597167015, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1381760, "time": 43577.9611620903, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1381880, "time": 43581.49224805832, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1382000, "time": 43585.44800043106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1382144, "time": 43589.964089393616, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1382360, "time": 43596.50572562218, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1382512, "time": 43601.484296798706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1383032, "time": 43617.21604561806, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1383224, "time": 43623.069321632385, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1383248, "time": 43624.03143143654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1383560, "time": 43633.47792625427, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1383784, "time": 43640.48100686073, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1383832, "time": 43641.96810603142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1384064, "time": 43649.31002283096, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1384072, "time": 43649.33954119682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1384192, "time": 43653.25941157341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1384312, "time": 43656.72068333626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1384456, "time": 43661.36620879173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1384504, "time": 43663.1054186821, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1384632, "time": 43667.144223213196, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1384832, "time": 43673.47656536102, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1384864, "time": 43674.45778250694, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1385168, "time": 43683.73396372795, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1385168, "time": 43683.74280548096, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1385280, "time": 43687.174191236496, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1385320, "time": 43688.17345452309, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1385408, "time": 43691.10447025299, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1385528, "time": 43694.68549776077, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1385536, "time": 43695.15957069397, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1385608, "time": 43697.16015148163, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1385928, "time": 43706.94405770302, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1386144, "time": 43713.7925889492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1386248, "time": 43716.75806307793, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1386544, "time": 43726.185012578964, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1386680, "time": 43730.14443230629, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1386704, "time": 43731.0993540287, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1386976, "time": 43739.4159154892, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1387248, "time": 43747.782601356506, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1387296, "time": 43749.25211024284, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1387368, "time": 43751.269287109375, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1387552, "time": 43757.27127957344, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1387688, "time": 43761.263391017914, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1387840, "time": 43766.14160013199, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1388016, "time": 43771.59588956833, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1388032, "time": 43772.09477210045, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1388144, "time": 43775.55399084091, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1388456, "time": 43785.07830810547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1388792, "time": 43795.40126848221, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1389192, "time": 43807.60802745819, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1389288, "time": 43810.57311677933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1389680, "time": 43822.95877075195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1389696, "time": 43823.45626974106, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1389864, "time": 43828.40755319595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1389888, "time": 43829.38946843147, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 1390064, "time": 43835.91894340515, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1390064, "time": 43836.10765886307, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1390064, "time": 43836.42446184158, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1390064, "time": 43836.511137485504, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1390064, "time": 43836.52149772644, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1390064, "time": 43836.657603263855, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 1390064, "time": 43837.37541270256, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 1390064, "time": 43837.70860981941, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 1390176, "time": 43841.16574501991, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1390280, "time": 43844.269778966904, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1390328, "time": 43845.76647520065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1390480, "time": 43850.670902729034, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1390512, "time": 43851.67263484001, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1390640, "time": 43855.59913468361, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1390728, "time": 43858.08701086044, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1390792, "time": 43860.05232310295, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1390888, "time": 43863.019867658615, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1391112, "time": 43869.87751913071, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1391296, "time": 43875.866641283035, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1391816, "time": 43891.62742614746, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1391936, "time": 43895.534848451614, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1391960, "time": 43896.07185745239, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1391992, "time": 43897.05705523491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1392200, "time": 43903.48727798462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1392368, "time": 43909.00468873978, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1392496, "time": 43912.932961940765, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 1392552, "time": 43914.43732213974, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1392584, "time": 43915.427754879, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1392616, "time": 43916.43869328499, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1392752, "time": 43921.41724395752, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1392776, "time": 43921.942348480225, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1392792, "time": 43922.441264629364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1392912, "time": 43926.37906169891, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1392936, "time": 43926.89450836182, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1393128, "time": 43932.82051181793, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1393264, "time": 43937.320930957794, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1393296, "time": 43938.30160307884, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1393320, "time": 43938.81876921654, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1393464, "time": 43943.23442530632, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1393712, "time": 43951.05551028252, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1393736, "time": 43951.57270359993, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1393736, "time": 43951.580800294876, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1393864, "time": 43955.50736570358, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1394112, "time": 43963.33082103729, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1394168, "time": 43964.945576906204, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1394216, "time": 43966.42639565468, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1394224, "time": 43966.8959736824, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1394368, "time": 43971.288078546524, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1394872, "time": 43986.46880984306, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1394976, "time": 43989.84627914429, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1395072, "time": 43992.78322601318, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1395160, "time": 43995.393354177475, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1395224, "time": 43997.36892461777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1395536, "time": 44007.13329267502, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1395704, "time": 44012.1289396286, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1395752, "time": 44013.61200070381, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1395936, "time": 44019.493564128876, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1395960, "time": 44020.028245449066, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1396048, "time": 44022.93985080719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1396176, "time": 44026.98026871681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1396352, "time": 44032.365263938904, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1396456, "time": 44035.35584068298, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1396552, "time": 44038.29014611244, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1396656, "time": 44041.71516776085, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1396680, "time": 44042.243082761765, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1396688, "time": 44042.715136528015, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1396720, "time": 44043.70394849777, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1396784, "time": 44045.686113119125, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1396992, "time": 44052.027725696564, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1397056, "time": 44054.118488550186, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 1397152, "time": 44057.075677633286, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1397352, "time": 44062.96441030502, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1397368, "time": 44063.45487523079, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1397448, "time": 44065.926695108414, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1397576, "time": 44069.83084344864, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1397752, "time": 44075.1751832962, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1397864, "time": 44078.57909321785, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1397976, "time": 44081.99827623367, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1398120, "time": 44086.56832051277, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1398224, "time": 44090.02017498016, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1398272, "time": 44091.49775695801, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1398392, "time": 44095.00128817558, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1398528, "time": 44099.3872487545, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 1398728, "time": 44105.37681388855, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1398944, "time": 44112.20590925217, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1399072, "time": 44116.25128388405, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1399120, "time": 44117.71873354912, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1399328, "time": 44124.072679042816, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1399416, "time": 44126.52970743179, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1399616, "time": 44132.820823431015, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1399728, "time": 44136.244124889374, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1399888, "time": 44141.15892267227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1400048, "time": 44147.28464818001, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1400048, "time": 44147.37254476547, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 1400048, "time": 44147.7465364933, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1400048, "time": 44148.656682252884, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 1400048, "time": 44148.952724695206, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 1400048, "time": 44149.31376123428, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 1400048, "time": 44149.759420871735, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 1400048, "time": 44149.84411025047, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1400064, "time": 44150.34156036377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1400232, "time": 44155.297285079956, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1400496, "time": 44163.648923158646, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1400584, "time": 44166.13185405731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1400600, "time": 44166.65297913551, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1400976, "time": 44179.19756960869, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1401048, "time": 44181.18293714523, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1401256, "time": 44187.55701303482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1401384, "time": 44191.46213078499, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1401552, "time": 44196.847476005554, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1401904, "time": 44207.78180885315, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1401928, "time": 44208.2972240448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1401984, "time": 44210.22157788277, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1402264, "time": 44218.60020184517, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1402280, "time": 44219.093964099884, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1402712, "time": 44232.291700839996, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1402768, "time": 44234.33704638481, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 1402776, "time": 44234.36597967148, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1402816, "time": 44235.81623315811, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1402912, "time": 44238.75478053093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1403112, "time": 44244.58532452583, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 1403144, "time": 44245.55716538429, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1403152, "time": 44246.04377269745, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1403208, "time": 44247.52357196808, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1403264, "time": 44249.44333195686, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1403376, "time": 44252.855340242386, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1403408, "time": 44253.83645105362, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1403576, "time": 44258.718978881836, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1403768, "time": 44264.688864946365, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1403840, "time": 44267.10300087929, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1403888, "time": 44268.56590771675, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1404008, "time": 44272.006212472916, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1404248, "time": 44279.32281923294, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1404792, "time": 44296.032824754715, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1404857, "time": 44299.180336236954, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2348638916015626, "train/action_min": 0.0, "train/action_std": 1.8084068715572357, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011391116841696202, "train/actor_opt_grad_steps": 86705.0, "train/actor_opt_loss": -21.96863609790802, "train/adv_mag": 0.7641171771287918, "train/adv_max": 0.33671246469020844, "train/adv_mean": 0.0007354626195228775, "train/adv_min": -0.6921917831897736, "train/adv_std": 0.03321582649834454, "train/cont_avg": 0.99328125, "train/cont_loss_mean": 0.029364336566068232, "train/cont_loss_std": 0.3071697498112917, "train/cont_neg_acc": 0.1009341650083661, "train/cont_neg_loss": 3.4647370290756228, "train/cont_pos_acc": 0.9998769980669021, "train/cont_pos_loss": 0.006044682250358164, "train/cont_pred": 0.9933762595057487, "train/cont_rate": 0.99328125, "train/dyn_loss_mean": 1.0000001329183579, "train/dyn_loss_std": 4.250676720403135e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13146237010136247, "train/extr_critic_critic_opt_grad_steps": 86705.0, "train/extr_critic_critic_opt_loss": 6608.645837402344, "train/extr_critic_mag": 1.703105765581131, "train/extr_critic_max": 1.703105765581131, "train/extr_critic_mean": 1.5332705199718475, "train/extr_critic_min": 1.2603430318832398, "train/extr_critic_std": 0.02904847661033273, "train/extr_return_normed_mag": 0.7829370650649071, "train/extr_return_normed_max": 0.38942363440990446, "train/extr_return_normed_mean": 0.05781965620815754, "train/extr_return_normed_min": -0.6251662331819534, "train/extr_return_normed_std": 0.04551818320527673, "train/extr_return_rate": 0.9996152552962303, "train/extr_return_raw_mag": 1.8656099188327788, "train/extr_return_raw_max": 1.8656099188327788, "train/extr_return_raw_mean": 1.5340060299634934, "train/extr_return_raw_min": 0.8510200512409211, "train/extr_return_raw_std": 0.045518183186650275, "train/extr_reward_mag": 0.3545974457263947, "train/extr_reward_max": 0.3545974457263947, "train/extr_reward_mean": 0.003133237441070378, "train/extr_reward_min": 3.659725189208984e-07, "train/extr_reward_std": 0.011473813694901764, "train/image_loss_mean": 0.08824761800467967, "train/image_loss_std": 0.10394967505708337, "train/model_loss_mean": 0.7415815857052803, "train/model_loss_std": 0.5878501407057047, "train/model_opt_grad_norm": 13.967303054332733, "train/model_opt_grad_steps": 86625.36, "train/model_opt_loss": 4120.008349609375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5550.0, "train/policy_entropy_mag": 1.2811299151182174, "train/policy_entropy_max": 1.2811299151182174, "train/policy_entropy_mean": 0.09193260468542576, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11337312296032906, "train/policy_logprob_mag": 6.551080260276795, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09170557036995888, "train/policy_logprob_min": -6.551080260276795, "train/policy_logprob_std": 0.6285183992981911, "train/policy_randomness_mag": 0.6583705779910087, "train/policy_randomness_max": 0.6583705779910087, "train/policy_randomness_mean": 0.047244016341865064, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0582622635550797, "train/post_ent_mag": 69.68738029479981, "train/post_ent_max": 69.68738029479981, "train/post_ent_mean": 56.86602416992187, "train/post_ent_min": 43.68986848831177, "train/post_ent_std": 5.715829625129699, "train/prior_ent_mag": 69.6554550933838, "train/prior_ent_max": 69.6554550933838, "train/prior_ent_mean": 57.147516384124756, "train/prior_ent_min": 44.44948932647705, "train/prior_ent_std": 5.6046618509292605, "train/rep_loss_mean": 1.0000001329183579, "train/rep_loss_std": 4.250676720403135e-06, "train/reward_avg": 0.0033597106716479175, "train/reward_loss_mean": 0.0239695262350142, "train/reward_loss_std": 0.2896664828341454, "train/reward_max_data": 0.8351562511920929, "train/reward_max_pred": 0.2848199099302292, "train/reward_neg_acc": 0.9995092737674713, "train/reward_neg_loss": 0.004442485109902919, "train/reward_pos_acc": 0.14375793889164926, "train/reward_pos_loss": 4.073300341963768, "train/reward_pred": 0.002648952926392667, "train/reward_rate": 0.0047509765625, "train_stats/mean_log_entropy": 0.08398593010002152, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9892578125, "report/cont_loss_mean": 0.05111333355307579, "report/cont_loss_std": 0.4325624406337738, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.047059059143066, "report/cont_pos_acc": 0.9990128874778748, "report/cont_pos_loss": 0.007722020614892244, "report/cont_pred": 0.9930011034011841, "report/cont_rate": 0.9892578125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10520869493484497, "report/image_loss_std": 0.11396097391843796, "report/model_loss_mean": 0.7870082259178162, "report/model_loss_std": 0.7379655241966248, "report/post_ent_mag": 70.03130340576172, "report/post_ent_max": 70.03130340576172, "report/post_ent_mean": 56.53990936279297, "report/post_ent_min": 43.038795471191406, "report/post_ent_std": 5.87026309967041, "report/prior_ent_mag": 71.23033142089844, "report/prior_ent_max": 71.23033142089844, "report/prior_ent_mean": 58.20874786376953, "report/prior_ent_min": 43.88182067871094, "report/prior_ent_std": 6.118082046508789, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0037902831099927425, "report/reward_loss_mean": 0.030686182901263237, "report/reward_loss_std": 0.35240986943244934, "report/reward_max_data": 0.871874988079071, "report/reward_max_pred": 0.09726440906524658, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00391570245847106, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.572745323181152, "report/reward_pred": 0.0021139318123459816, "report/reward_rate": 0.005859375, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.036355964839458466, "eval/cont_loss_std": 0.32954707741737366, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.7212274074554443, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.007341229822486639, "eval/cont_pred": 0.992612898349762, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10073474794626236, "eval/image_loss_std": 0.11412017792463303, "eval/model_loss_mean": 0.7782843112945557, "eval/model_loss_std": 0.7697315812110901, "eval/post_ent_mag": 70.37614440917969, "eval/post_ent_max": 70.37614440917969, "eval/post_ent_mean": 57.57421112060547, "eval/post_ent_min": 44.11021423339844, "eval/post_ent_std": 5.593487739562988, "eval/prior_ent_mag": 71.82447052001953, "eval/prior_ent_max": 71.82447052001953, "eval/prior_ent_mean": 59.39073944091797, "eval/prior_ent_min": 44.50245666503906, "eval/prior_ent_std": 5.848125457763672, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.005703735630959272, "eval/reward_loss_mean": 0.04119356349110603, "eval/reward_loss_std": 0.40659719705581665, "eval/reward_max_data": 0.8843749761581421, "eval/reward_max_pred": 0.050153136253356934, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00525411544367671, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.605503082275391, "eval/reward_pred": 0.0028251400217413902, "eval/reward_rate": 0.0078125, "replay/size": 1000000.0, "replay/inserts": 31984.0, "replay/samples": 31984.0, "replay/insert_wait_avg": 1.311294730750843e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.722355427057402e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3928.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1798320622648096e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1473894119262695e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1563308238983, "timer/env.step_count": 3998.0, "timer/env.step_total": 40.27644491195679, "timer/env.step_frac": 0.04027014944631534, "timer/env.step_avg": 0.010074148302140267, "timer/env.step_min": 0.008224964141845703, "timer/env.step_max": 0.03648185729980469, "timer/replay._sample_count": 31984.0, "timer/replay._sample_total": 17.994476556777954, "timer/replay._sample_frac": 0.017991663905136363, "timer/replay._sample_avg": 0.0005626086967476849, "timer/replay._sample_min": 0.00044846534729003906, "timer/replay._sample_max": 0.028424978256225586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4489.0, "timer/agent.policy_total": 49.488399267196655, "timer/agent.policy_frac": 0.04948066391423991, "timer/agent.policy_avg": 0.011024370520649734, "timer/agent.policy_min": 0.009495973587036133, "timer/agent.policy_max": 0.09415292739868164, "timer/dataset_train_count": 1999.0, "timer/dataset_train_total": 0.24585914611816406, "timer/dataset_train_frac": 0.0002458207167629812, "timer/dataset_train_avg": 0.00012299106859337873, "timer/dataset_train_min": 0.00010514259338378906, "timer/dataset_train_max": 0.0005059242248535156, "timer/agent.train_count": 1999.0, "timer/agent.train_total": 898.3536849021912, "timer/agent.train_frac": 0.8982132664822056, "timer/agent.train_avg": 0.4494015432227069, "timer/agent.train_min": 0.43479156494140625, "timer/agent.train_max": 0.69724440574646, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5044214725494385, "timer/agent.report_frac": 0.000504342628250837, "timer/agent.report_avg": 0.25221073627471924, "timer/agent.report_min": 0.23037052154541016, "timer/agent.report_max": 0.2740509510040283, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.313500247288073e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 31.978362502850263}
{"step": 1404864, "time": 44299.20214390755, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1405000, "time": 44303.584510564804, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1405128, "time": 44307.50270175934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1405424, "time": 44316.85404634476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1405432, "time": 44316.884697675705, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1405520, "time": 44319.79320311546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1405552, "time": 44320.79536151886, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 1405624, "time": 44322.78337454796, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1405664, "time": 44324.343428611755, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1406064, "time": 44336.60334300995, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1406120, "time": 44338.08417606354, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1406208, "time": 44340.98918390274, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1406504, "time": 44349.7822933197, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1406560, "time": 44351.74594473839, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1406760, "time": 44357.73786330223, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1406768, "time": 44358.21229481697, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1407056, "time": 44367.067969322205, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1407176, "time": 44370.51944065094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1407312, "time": 44374.91538667679, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1407504, "time": 44380.77705836296, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1407600, "time": 44383.72284555435, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1407864, "time": 44391.654344558716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1408368, "time": 44407.27356147766, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1408520, "time": 44411.70721125603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1408816, "time": 44421.0879843235, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1408872, "time": 44422.606086969376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1409048, "time": 44428.52202177048, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1409072, "time": 44429.505758047104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1409096, "time": 44430.028285741806, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1409128, "time": 44431.00875258446, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1409488, "time": 44442.240564107895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1409624, "time": 44446.324001550674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1409744, "time": 44450.20460820198, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1409976, "time": 44457.05077624321, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1410032, "time": 44459.25730967522, "eval_episode/length": 12.0, "eval_episode/score": 0.9624999761581421, "eval_episode/reward_rate": 0.07692307692307693}
{"step": 1410032, "time": 44459.975506305695, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 1410032, "time": 44460.33568882942, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1410032, "time": 44460.44680070877, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1410032, "time": 44460.625624895096, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1410032, "time": 44460.87161517143, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1410032, "time": 44461.9435300827, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 1410032, "time": 44463.65004873276, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 1410040, "time": 44463.6790099144, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1410104, "time": 44465.64636135101, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1410528, "time": 44478.96634435654, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1410560, "time": 44479.94476222992, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1410576, "time": 44480.44053149223, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1410656, "time": 44482.88114762306, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1411024, "time": 44494.123055934906, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1411128, "time": 44497.081206321716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1411192, "time": 44499.0460062027, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1411224, "time": 44500.02185988426, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1411408, "time": 44506.01585102081, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1411736, "time": 44515.803001880646, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1411920, "time": 44521.674570560455, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1411936, "time": 44522.17175459862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1412104, "time": 44527.084292411804, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1412120, "time": 44527.59417438507, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1412552, "time": 44540.90827250481, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1412584, "time": 44541.88661670685, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1412608, "time": 44542.86118221283, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1412872, "time": 44550.70327591896, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1412888, "time": 44551.19821214676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1412968, "time": 44553.64513731003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1413064, "time": 44556.59261393547, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1413096, "time": 44557.5973610878, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1413336, "time": 44565.071434020996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1413432, "time": 44568.056527137756, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1413528, "time": 44570.99856901169, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1413648, "time": 44574.93027353287, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1413672, "time": 44575.450577259064, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1413800, "time": 44579.365844249725, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1413816, "time": 44579.85822749138, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1414040, "time": 44586.80691552162, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1414072, "time": 44587.80303764343, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1414152, "time": 44590.27764415741, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1414152, "time": 44590.28469634056, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1414264, "time": 44593.77160310745, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1414336, "time": 44596.23610877991, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1414448, "time": 44599.6751806736, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1414504, "time": 44601.15954589844, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1414656, "time": 44606.01550245285, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1414664, "time": 44606.04280805588, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1414704, "time": 44607.50128650665, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1414984, "time": 44615.86032485962, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1415032, "time": 44617.3375313282, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1415040, "time": 44617.808242082596, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1415096, "time": 44619.28751564026, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1415480, "time": 44631.119027137756, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1415568, "time": 44634.049015283585, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1415608, "time": 44635.058077573776, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1415648, "time": 44636.53042459488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1415664, "time": 44637.021463394165, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1415680, "time": 44637.51140499115, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1415720, "time": 44638.507232666016, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1415880, "time": 44643.407817840576, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1416136, "time": 44651.22451400757, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1416184, "time": 44652.693408727646, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1416184, "time": 44652.70221185684, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1416624, "time": 44666.46220588684, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1416648, "time": 44666.97427821159, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1416696, "time": 44668.43695449829, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1416728, "time": 44669.414971113205, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1416832, "time": 44672.828251600266, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1416912, "time": 44675.29120182991, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1416992, "time": 44677.73108482361, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1417280, "time": 44687.2029106617, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1417288, "time": 44687.230528116226, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1417352, "time": 44689.1732711792, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1417464, "time": 44692.61723995209, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1417616, "time": 44697.50242328644, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1417752, "time": 44701.43907213211, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 1417752, "time": 44701.448204278946, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1417840, "time": 44704.348221063614, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1417944, "time": 44707.32056641579, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1417976, "time": 44708.32594752312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1418224, "time": 44716.234488248825, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1418336, "time": 44719.64096522331, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1418560, "time": 44726.497789382935, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1418760, "time": 44732.394073963165, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 1418864, "time": 44735.80013537407, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1418928, "time": 44737.74608159065, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1418992, "time": 44739.70494890213, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1418992, "time": 44739.71318483353, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1419080, "time": 44742.16728067398, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1419224, "time": 44746.67083263397, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1419496, "time": 44754.979809999466, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1419552, "time": 44756.9332947731, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1419624, "time": 44758.90001440048, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1419824, "time": 44765.26974439621, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1419992, "time": 44770.18350625038, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1420016, "time": 44772.08041715622, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 1420016, "time": 44772.560465574265, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1420016, "time": 44773.19866394997, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1420016, "time": 44773.26126718521, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1420016, "time": 44773.38408946991, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 1420016, "time": 44773.44825172424, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 1420016, "time": 44774.2361266613, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 1420016, "time": 44774.66787958145, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 1420080, "time": 44776.631685733795, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1420144, "time": 44778.595740795135, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1420424, "time": 44786.94930315018, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1421096, "time": 44807.59861469269, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1421176, "time": 44810.0505502224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1421184, "time": 44810.52918958664, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1421240, "time": 44812.04260969162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1421632, "time": 44824.253036260605, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1421704, "time": 44826.23758935928, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 1421736, "time": 44827.2369761467, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1421808, "time": 44829.6476123333, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1421864, "time": 44831.133534669876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1421912, "time": 44832.618304014206, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1421936, "time": 44833.59639763832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1422136, "time": 44839.57206892967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1422312, "time": 44844.928767204285, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1422416, "time": 44848.32522583008, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1422712, "time": 44857.153769016266, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1422848, "time": 44861.53224015236, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1423224, "time": 44872.95053434372, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1423224, "time": 44872.96910357475, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1423352, "time": 44876.88199543953, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1423424, "time": 44879.31154561043, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1423680, "time": 44887.107087135315, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1423768, "time": 44889.56080245972, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1423904, "time": 44894.04573583603, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1423944, "time": 44895.04357457161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1424032, "time": 44897.99287056923, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1424048, "time": 44898.49807500839, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1424536, "time": 44913.34793782234, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1424576, "time": 44914.80975937843, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1424808, "time": 44921.752531051636, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1424952, "time": 44926.32700800896, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1425024, "time": 44928.7588865757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1425168, "time": 44933.19381213188, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1425480, "time": 44943.12978601456, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1425536, "time": 44945.06476664543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1425536, "time": 44945.07232737541, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1425616, "time": 44947.53493452072, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1425664, "time": 44949.0023522377, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1425808, "time": 44953.43145751953, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1425928, "time": 44957.02348327637, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1425992, "time": 44958.99069929123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1426168, "time": 44964.37862110138, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1426200, "time": 44965.38674783707, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1426360, "time": 44970.28105711937, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1426528, "time": 44975.64445018768, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1426584, "time": 44977.13802075386, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1426848, "time": 44985.57170009613, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1427072, "time": 44992.41939020157, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1427400, "time": 45002.233199596405, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1427472, "time": 45004.67472624779, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1427752, "time": 45013.026872873306, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1427848, "time": 45016.10121202469, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1428032, "time": 45021.96712017059, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1428040, "time": 45021.99655175209, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1428240, "time": 45028.3295507431, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1428256, "time": 45028.82168054581, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1428304, "time": 45030.31341791153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1428384, "time": 45032.748121738434, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1428480, "time": 45035.72760057449, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1428512, "time": 45036.70639181137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1428832, "time": 45046.57585191727, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1428960, "time": 45050.49364614487, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1429072, "time": 45053.92640924454, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1429120, "time": 45055.39151382446, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1429152, "time": 45056.367973566055, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1429464, "time": 45065.69401550293, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1429592, "time": 45069.592255592346, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1429640, "time": 45071.06082558632, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1429680, "time": 45072.50635313988, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1430000, "time": 45083.88123035431, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1430000, "time": 45084.4938120842, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1430000, "time": 45084.620106220245, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1430000, "time": 45084.707037210464, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 1430000, "time": 45085.5407640934, "eval_episode/length": 155.0, "eval_episode/score": 0.515625, "eval_episode/reward_rate": 0.00641025641025641}
{"step": 1430000, "time": 45085.588515520096, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 1430000, "time": 45085.63474678993, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1430000, "time": 45086.107944726944, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1430128, "time": 45090.011657714844, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1430256, "time": 45093.90685200691, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1430360, "time": 45096.87612581253, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1430600, "time": 45104.30503511429, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1430608, "time": 45104.77720165253, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1430792, "time": 45110.190615177155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1430792, "time": 45110.20094919205, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1430824, "time": 45111.18328118324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1431144, "time": 45120.97936105728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1431272, "time": 45124.90352678299, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1431416, "time": 45129.30893659592, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1431464, "time": 45130.77006530762, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1431496, "time": 45131.76647615433, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1431552, "time": 45133.717816114426, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1431856, "time": 45143.15580368042, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1431896, "time": 45144.15007638931, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1432032, "time": 45148.51367521286, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1432088, "time": 45150.011623859406, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1432344, "time": 45157.80239892006, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1432536, "time": 45163.80543255806, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1432560, "time": 45164.80056190491, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1432584, "time": 45165.31403493881, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1432768, "time": 45171.17475605011, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1432936, "time": 45176.0832324028, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1433512, "time": 45193.699912548065, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1433568, "time": 45195.72195196152, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1433584, "time": 45196.21427702904, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1433608, "time": 45196.937064409256, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1433856, "time": 45205.04223561287, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1433864, "time": 45205.07085585594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1434008, "time": 45209.49292778969, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1434168, "time": 45214.463349342346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1434248, "time": 45216.928882837296, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1434280, "time": 45217.908596515656, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1434400, "time": 45221.80336380005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1434712, "time": 45231.21112179756, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1435040, "time": 45241.48499059677, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1435216, "time": 45246.89261031151, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1435240, "time": 45247.40953540802, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1435240, "time": 45247.41761922836, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1435432, "time": 45253.306166648865, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1435688, "time": 45261.285375118256, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1435792, "time": 45264.70156311989, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1435896, "time": 45267.64883637428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1436136, "time": 45275.02809858322, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1436168, "time": 45276.019672870636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1436176, "time": 45276.497794151306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1436232, "time": 45277.99391412735, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1436248, "time": 45278.486236572266, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1436288, "time": 45279.94810175896, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1436712, "time": 45292.83792471886, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1436712, "time": 45292.84704399109, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1436792, "time": 45295.311781167984, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1436848, "time": 45297.240820646286, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1436889, "time": 45299.306379795074, "train_stats/mean_log_entropy": 0.08006848866540578, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1342279052734376, "train/action_min": 0.0, "train/action_std": 1.7719661974906922, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011863622609525918, "train/actor_opt_grad_steps": 88705.0, "train/actor_opt_loss": -25.215643248558045, "train/adv_mag": 0.7977470123767852, "train/adv_max": 0.3419202107191086, "train/adv_mean": 0.0014754999911019695, "train/adv_min": -0.7237434750795364, "train/adv_std": 0.034623463074676696, "train/cont_avg": 0.9930908203125, "train/cont_loss_mean": 0.030161679703742266, "train/cont_loss_std": 0.3076724071055651, "train/cont_neg_acc": 0.0795102135464549, "train/cont_neg_loss": 3.4793807208538055, "train/cont_pos_acc": 0.9998278921842575, "train/cont_pos_loss": 0.0062484853155910965, "train/cont_pred": 0.9932943400740624, "train/cont_rate": 0.9930908203125, "train/dyn_loss_mean": 1.0000237315893172, "train/dyn_loss_std": 0.00032300705526722596, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1910935427993536, "train/extr_critic_critic_opt_grad_steps": 88705.0, "train/extr_critic_critic_opt_loss": 4766.742993164063, "train/extr_critic_mag": 1.7365478706359863, "train/extr_critic_max": 1.7365478706359863, "train/extr_critic_mean": 1.5822128027677536, "train/extr_critic_min": 1.316147605776787, "train/extr_critic_std": 0.0307854285184294, "train/extr_return_normed_mag": 0.8160721218585968, "train/extr_return_normed_max": 0.3931488662958145, "train/extr_return_normed_mean": 0.06454202085733414, "train/extr_return_normed_min": -0.6645265895128251, "train/extr_return_normed_std": 0.04761937763541937, "train/extr_return_rate": 0.999721703529358, "train/extr_return_raw_mag": 1.9122950917482375, "train/extr_return_raw_max": 1.9122950917482375, "train/extr_return_raw_mean": 1.5836883229017258, "train/extr_return_raw_min": 0.8546196359395981, "train/extr_return_raw_std": 0.04761937761679292, "train/extr_reward_mag": 0.3656067091226578, "train/extr_reward_max": 0.3656067091226578, "train/extr_reward_mean": 0.003103614480351098, "train/extr_reward_min": 3.218650817871094e-07, "train/extr_reward_std": 0.012426967911887915, "train/image_loss_mean": 0.08952471766620874, "train/image_loss_std": 0.10443113408982754, "train/model_loss_mean": 0.7451825809478759, "train/model_loss_std": 0.5987674290686846, "train/model_opt_grad_norm": 13.724681308269501, "train/model_opt_grad_steps": 88623.5, "train/model_opt_loss": 3800.1045690917967, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5100.0, "train/policy_entropy_mag": 1.2576585042476653, "train/policy_entropy_max": 1.2576585042476653, "train/policy_entropy_mean": 0.08797951903194189, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1035584269836545, "train/policy_logprob_mag": 6.551080241203308, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08821938037872315, "train/policy_logprob_min": -6.551080241203308, "train/policy_logprob_std": 0.6270747271180153, "train/policy_randomness_mag": 0.646308659017086, "train/policy_randomness_max": 0.646308659017086, "train/policy_randomness_mean": 0.04521253257989884, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05321850687265396, "train/post_ent_mag": 71.63028518676758, "train/post_ent_max": 71.63028518676758, "train/post_ent_mean": 57.15523014068604, "train/post_ent_min": 42.17293529510498, "train/post_ent_std": 6.59903903722763, "train/prior_ent_mag": 70.75596660614013, "train/prior_ent_max": 70.75596660614013, "train/prior_ent_mean": 57.61011138916015, "train/prior_ent_min": 43.2779762840271, "train/prior_ent_std": 6.345779151916504, "train/rep_loss_mean": 1.0000237315893172, "train/rep_loss_std": 0.00032300705526722596, "train/reward_avg": 0.003597427375498228, "train/reward_loss_mean": 0.02548192332498729, "train/reward_loss_std": 0.29689021363854406, "train/reward_max_data": 0.8335156252980233, "train/reward_max_pred": 0.2621901768445969, "train/reward_neg_acc": 0.999391413629055, "train/reward_neg_loss": 0.00460814421530813, "train/reward_pos_acc": 0.10270274341106415, "train/reward_pos_loss": 4.116509677171707, "train/reward_pred": 0.002655184231698513, "train/reward_rate": 0.0051171875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.024900022894144058, "report/cont_loss_std": 0.2783997356891632, "report/cont_neg_acc": 0.1666666716337204, "report/cont_neg_loss": 3.2415130138397217, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005941599141806364, "report/cont_pred": 0.993211030960083, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08938362449407578, "report/image_loss_std": 0.1041209027171135, "report/model_loss_mean": 0.7356816530227661, "report/model_loss_std": 0.5486649870872498, "report/post_ent_mag": 71.28488159179688, "report/post_ent_max": 71.28488159179688, "report/post_ent_mean": 59.1019172668457, "report/post_ent_min": 47.54987335205078, "report/post_ent_std": 5.339328289031982, "report/prior_ent_mag": 70.36540985107422, "report/prior_ent_max": 70.36540985107422, "report/prior_ent_mean": 57.251922607421875, "report/prior_ent_min": 44.51192855834961, "report/prior_ent_std": 5.695023059844971, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0029235840775072575, "report/reward_loss_mean": 0.02139800786972046, "report/reward_loss_std": 0.2726143002510071, "report/reward_max_data": 0.8999999761581421, "report/reward_max_pred": 0.09020888805389404, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.004386452492326498, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.359344482421875, "report/reward_pred": 0.0024118642322719097, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.05178394168615341, "eval/cont_loss_std": 0.5952760577201843, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.961509704589844, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.005250665359199047, "eval/cont_pred": 0.9947855472564697, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10551784932613373, "eval/image_loss_std": 0.1206522211432457, "eval/model_loss_mean": 0.8023853898048401, "eval/model_loss_std": 1.0903500318527222, "eval/post_ent_mag": 71.066162109375, "eval/post_ent_max": 71.066162109375, "eval/post_ent_mean": 59.041786193847656, "eval/post_ent_min": 47.774681091308594, "eval/post_ent_std": 5.515540599822998, "eval/prior_ent_mag": 69.53227233886719, "eval/prior_ent_max": 69.53227233886719, "eval/prior_ent_mean": 57.259639739990234, "eval/prior_ent_min": 45.02933120727539, "eval/prior_ent_std": 5.768194198608398, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0051513672806322575, "eval/reward_loss_mean": 0.04508357122540474, "eval/reward_loss_std": 0.5281743407249451, "eval/reward_max_data": 0.921875, "eval/reward_max_pred": 0.09714651107788086, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.004497113171964884, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.941717147827148, "eval/reward_pred": 0.0023084257263690233, "eval/reward_rate": 0.0068359375, "replay/size": 1000000.0, "replay/inserts": 32032.0, "replay/samples": 32032.0, "replay/insert_wait_avg": 1.30176752597302e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.783706464967527e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4560.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1949162734182257e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3262033462524414e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2222073078156, "timer/env.step_count": 4004.0, "timer/env.step_total": 40.26015305519104, "timer/env.step_frac": 0.04025120894241562, "timer/env.step_avg": 0.010054983280517243, "timer/env.step_min": 0.007930278778076172, "timer/env.step_max": 0.05343914031982422, "timer/replay._sample_count": 32032.0, "timer/replay._sample_total": 17.982945680618286, "timer/replay._sample_frac": 0.017978950626402243, "timer/replay._sample_avg": 0.000561405646872449, "timer/replay._sample_min": 0.0004165172576904297, "timer/replay._sample_max": 0.02832484245300293, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4574.0, "timer/agent.policy_total": 50.20917105674744, "timer/agent.policy_frac": 0.050198016690600936, "timer/agent.policy_avg": 0.010977081560285842, "timer/agent.policy_min": 0.00935816764831543, "timer/agent.policy_max": 0.08239197731018066, "timer/dataset_train_count": 2002.0, "timer/dataset_train_total": 0.2441883087158203, "timer/dataset_train_frac": 0.0002441340603435253, "timer/dataset_train_avg": 0.00012197218217573442, "timer/dataset_train_min": 0.00010395050048828125, "timer/dataset_train_max": 0.00042819976806640625, "timer/agent.train_count": 2002.0, "timer/agent.train_total": 896.6793189048767, "timer/agent.train_frac": 0.8964801144721297, "timer/agent.train_avg": 0.4478917676847536, "timer/agent.train_min": 0.4373633861541748, "timer/agent.train_max": 0.7454984188079834, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48050498962402344, "timer/agent.report_frac": 0.00048039824162407285, "timer/agent.report_avg": 0.24025249481201172, "timer/agent.report_min": 0.23225784301757812, "timer/agent.report_max": 0.2482471466064453, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.2656088915312405e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 32.02420567172452}
{"step": 1437016, "time": 45302.95487165451, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1437160, "time": 45307.345821380615, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1437416, "time": 45315.34011387825, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1437456, "time": 45316.78486132622, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1437456, "time": 45316.79410457611, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1437504, "time": 45318.26745414734, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1437552, "time": 45319.75366353989, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1437824, "time": 45328.04672288895, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1437880, "time": 45329.556447029114, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1438080, "time": 45335.902812719345, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1438080, "time": 45335.9107530117, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1438176, "time": 45338.85636305809, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1438320, "time": 45343.27544236183, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1438392, "time": 45345.398404598236, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1438736, "time": 45356.1347784996, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1438808, "time": 45358.11229777336, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1438840, "time": 45359.11349129677, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1439016, "time": 45364.487080574036, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1439024, "time": 45364.962038993835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1439024, "time": 45364.97158932686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1439368, "time": 45375.431013822556, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1439400, "time": 45376.41185617447, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1439464, "time": 45378.37177658081, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1439664, "time": 45384.73668050766, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1439848, "time": 45390.11010789871, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1440032, "time": 45395.97798657417, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1440088, "time": 45397.47610425949, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1440088, "time": 45398.03678941727, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 1440088, "time": 45398.085034132004, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 1440088, "time": 45398.69114112854, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1440088, "time": 45398.77636241913, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1440088, "time": 45399.49113535881, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1440088, "time": 45399.61718463898, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1440088, "time": 45399.64405608177, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 1440088, "time": 45399.651215553284, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1440296, "time": 45406.10310769081, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1440392, "time": 45409.04548192024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1440488, "time": 45412.0020635128, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1440664, "time": 45417.38837766647, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1440704, "time": 45418.835062503815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1440784, "time": 45421.285506248474, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1440824, "time": 45422.290638923645, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1441192, "time": 45433.49500417709, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1441376, "time": 45439.46000313759, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1441424, "time": 45440.947874069214, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1441600, "time": 45446.35302090645, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1441680, "time": 45448.80077433586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1442112, "time": 45462.57496166229, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1442128, "time": 45463.071264505386, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1442424, "time": 45472.08295631409, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1442624, "time": 45478.467494249344, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1442656, "time": 45479.46198916435, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1442704, "time": 45480.94834494591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1443096, "time": 45492.7554705143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1443120, "time": 45493.76165151596, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1443184, "time": 45495.80391359329, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1443336, "time": 45500.22748851776, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1443392, "time": 45502.16447234154, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1443432, "time": 45503.16830635071, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1443680, "time": 45510.99204993248, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 1443736, "time": 45512.4941368103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1443888, "time": 45517.387699604034, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1444008, "time": 45520.86032962799, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1444304, "time": 45530.25534534454, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1444424, "time": 45533.74278879166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1444520, "time": 45536.69968342781, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1444968, "time": 45550.45902681351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1445064, "time": 45553.40087747574, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1445280, "time": 45560.40160942078, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1445704, "time": 45573.19602203369, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1445744, "time": 45574.66903758049, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1446096, "time": 45585.60148477554, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1446200, "time": 45588.610520362854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1446240, "time": 45590.07164335251, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1446256, "time": 45590.56391644478, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1446472, "time": 45596.9680685997, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1446616, "time": 45601.394562244415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1446728, "time": 45604.84203648567, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1446736, "time": 45605.31599807739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1446888, "time": 45609.77309536934, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1447136, "time": 45617.71272921562, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1447192, "time": 45619.22076392174, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1447480, "time": 45628.02898311615, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1447688, "time": 45634.39618015289, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1448056, "time": 45645.81448340416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1448104, "time": 45647.28268003464, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1448408, "time": 45656.57776474953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1448512, "time": 45659.98973560333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1448808, "time": 45668.85905838013, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1448896, "time": 45671.7874917984, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1449008, "time": 45675.35151672363, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1449080, "time": 45677.3567943573, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1449448, "time": 45688.64120221138, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1449504, "time": 45690.57890701294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1449552, "time": 45692.07484269142, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1449792, "time": 45699.43001461029, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1450000, "time": 45706.429636240005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1450008, "time": 45706.45867013931, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1450072, "time": 45708.841472148895, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 1450072, "time": 45709.83786916733, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 1450072, "time": 45710.197674036026, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1450072, "time": 45710.306447029114, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1450072, "time": 45710.35683512688, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1450072, "time": 45711.038136959076, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1450072, "time": 45711.20403814316, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 1450072, "time": 45711.41032791138, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1450168, "time": 45714.33554935455, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1450456, "time": 45723.147315979004, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1450456, "time": 45723.15549612045, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1450512, "time": 45725.10994935036, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1450720, "time": 45731.5008149147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1451096, "time": 45742.95580482483, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1451320, "time": 45750.01056957245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1451360, "time": 45751.4730424881, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1451400, "time": 45752.48282909393, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1451552, "time": 45757.35043334961, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1451744, "time": 45763.23693203926, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1452144, "time": 45775.676241636276, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1452312, "time": 45780.60970711708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1452400, "time": 45783.53311920166, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1452480, "time": 45786.01253271103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1452624, "time": 45790.44942045212, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1452768, "time": 45795.02117443085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1452768, "time": 45795.02999830246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1452936, "time": 45799.96416926384, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1453088, "time": 45804.865115880966, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 1453248, "time": 45809.76847076416, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1453384, "time": 45813.71635866165, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1453528, "time": 45818.11405682564, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1454032, "time": 45833.85405874252, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1454456, "time": 45846.60526609421, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1454568, "time": 45850.04143881798, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1454624, "time": 45851.98085141182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1454712, "time": 45854.59347319603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1454792, "time": 45857.03970575333, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1454936, "time": 45861.486048936844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1455256, "time": 45871.29941034317, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1455400, "time": 45875.75622487068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1455456, "time": 45877.69743347168, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1455560, "time": 45880.687281131744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1455664, "time": 45884.2312169075, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1455696, "time": 45885.22617006302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1455728, "time": 45886.209102630615, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1455968, "time": 45893.578280210495, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1456264, "time": 45902.40877366066, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1456264, "time": 45902.42623257637, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1456440, "time": 45907.84992814064, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1456496, "time": 45909.78381609917, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1457032, "time": 45926.14079117775, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1457496, "time": 45940.435338020325, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1457680, "time": 45946.489958286285, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1457712, "time": 45947.48749732971, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1457712, "time": 45947.49613022804, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1457768, "time": 45948.9841170311, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1458008, "time": 45956.32345318794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1458040, "time": 45957.3257894516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1458152, "time": 45960.74453043938, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1458192, "time": 45962.785981178284, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1458280, "time": 45965.26060295105, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1458576, "time": 45974.707043647766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1458672, "time": 45977.673005104065, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1458832, "time": 45982.58263683319, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1458904, "time": 45984.578401088715, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1458976, "time": 45987.02000951767, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1459160, "time": 45992.46756982803, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1459288, "time": 45996.37696957588, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1459360, "time": 45998.8260307312, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1459376, "time": 45999.31985831261, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1459440, "time": 46001.26803469658, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1459496, "time": 46002.79148721695, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1459720, "time": 46009.735416173935, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1459888, "time": 46015.12108325958, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1460024, "time": 46019.06411075592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1460056, "time": 46020.41291618347, "eval_episode/length": 17.0, "eval_episode/score": 0.9468749761581421, "eval_episode/reward_rate": 0.05555555555555555}
{"step": 1460056, "time": 46021.483046770096, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1460056, "time": 46021.508069992065, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1460056, "time": 46021.80797290802, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1460056, "time": 46021.87490129471, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1460056, "time": 46021.90138792992, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1460056, "time": 46022.580953359604, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 1460056, "time": 46022.64853620529, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 1460056, "time": 46022.65592122078, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 1460104, "time": 46024.13049888611, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1460264, "time": 46029.034198760986, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1460352, "time": 46031.94395637512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1460448, "time": 46035.051187992096, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1460648, "time": 46040.93863463402, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1460672, "time": 46041.895204782486, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1460832, "time": 46046.80322551727, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1461000, "time": 46051.75801253319, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1461008, "time": 46052.230880498886, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1461040, "time": 46053.2146692276, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1461520, "time": 46068.188745975494, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 1461752, "time": 46075.122821092606, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1461752, "time": 46075.13009047508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1461848, "time": 46078.07564997673, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 1462176, "time": 46088.340158224106, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1462360, "time": 46093.87679362297, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1462376, "time": 46094.3965947628, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1462456, "time": 46096.830161333084, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1462472, "time": 46097.32597732544, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1462528, "time": 46099.286172151566, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1462960, "time": 46112.5134036541, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1463016, "time": 46114.02195739746, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1463032, "time": 46114.52527475357, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1463320, "time": 46123.41596388817, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1463336, "time": 46124.06617426872, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1463352, "time": 46124.570544958115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1463672, "time": 46134.35344672203, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1463704, "time": 46135.34709715843, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1463760, "time": 46137.2776184082, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1463784, "time": 46137.78817844391, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1464136, "time": 46148.559473991394, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 1464136, "time": 46148.56693506241, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1464328, "time": 46154.57524752617, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1464336, "time": 46155.047231435776, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1464344, "time": 46155.076301813126, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1464496, "time": 46159.96715736389, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1464552, "time": 46161.453808784485, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1464776, "time": 46168.321256399155, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1464816, "time": 46169.767342329025, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1464968, "time": 46174.19595980644, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1465312, "time": 46185.13251757622, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1465344, "time": 46186.13322401047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1465480, "time": 46190.105979681015, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1465480, "time": 46190.112219810486, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1465520, "time": 46191.57592511177, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1465608, "time": 46194.05010032654, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1465720, "time": 46197.49512243271, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1466096, "time": 46209.22148227692, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1466312, "time": 46215.757653713226, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1466448, "time": 46220.64604854584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1466496, "time": 46222.11124801636, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 1466608, "time": 46225.56095409393, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1466904, "time": 46234.39567518234, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1466968, "time": 46236.34836888313, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1466976, "time": 46236.81939291954, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1467016, "time": 46237.839527606964, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1467480, "time": 46252.162254333496, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1467616, "time": 46256.511949300766, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1467680, "time": 46258.488605976105, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1467792, "time": 46261.9582529068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1468000, "time": 46268.329647541046, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1468104, "time": 46271.31120753288, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1468136, "time": 46272.30979561806, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 1468208, "time": 46274.863963365555, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1468312, "time": 46277.845264196396, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1468744, "time": 46291.11902832985, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1468944, "time": 46297.4912815094, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1468985, "time": 46299.68403673172, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.214872901119403, "train/action_min": 0.0, "train/action_std": 1.8301031453099417, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011744199448093698, "train/actor_opt_grad_steps": 90710.0, "train/actor_opt_loss": -26.774646872904764, "train/adv_mag": 0.8782683468576687, "train/adv_max": 0.3529282707480056, "train/adv_mean": 0.001291361105689415, "train/adv_min": -0.819117058568926, "train/adv_std": 0.03628995022110974, "train/cont_avg": 0.9934167055348259, "train/cont_loss_mean": 0.02877332943848413, "train/cont_loss_std": 0.299011982236039, "train/cont_neg_acc": 0.0979378021771635, "train/cont_neg_loss": 3.4219368773313303, "train/cont_pos_acc": 0.9998435475933019, "train/cont_pos_loss": 0.0062873046103846374, "train/cont_pred": 0.9931680109370408, "train/cont_rate": 0.9934167055348259, "train/dyn_loss_mean": 1.0000034374977225, "train/dyn_loss_std": 0.00010765151109717861, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2010815568194164, "train/extr_critic_critic_opt_grad_steps": 90710.0, "train/extr_critic_critic_opt_loss": 5967.844543153374, "train/extr_critic_mag": 1.7602970303587653, "train/extr_critic_max": 1.7602970303587653, "train/extr_critic_mean": 1.602764130231753, "train/extr_critic_min": 1.3379938946434515, "train/extr_critic_std": 0.029477894917797686, "train/extr_return_normed_mag": 0.8902697824127045, "train/extr_return_normed_max": 0.4035287116890523, "train/extr_return_normed_mean": 0.06440451681910463, "train/extr_return_normed_min": -0.7641718974753992, "train/extr_return_normed_std": 0.04827629962926777, "train/extr_return_rate": 0.9996618756014316, "train/extr_return_raw_mag": 1.9431796690717857, "train/extr_return_raw_max": 1.9431796690717857, "train/extr_return_raw_mean": 1.6040555659811295, "train/extr_return_raw_min": 0.7754790599073343, "train/extr_return_raw_std": 0.04827629986094005, "train/extr_reward_mag": 0.37634204691322287, "train/extr_reward_max": 0.37634204691322287, "train/extr_reward_mean": 0.003308358759762932, "train/extr_reward_min": 3.3153230278053095e-07, "train/extr_reward_std": 0.012276726452846876, "train/image_loss_mean": 0.0868778822026146, "train/image_loss_std": 0.10230225009556433, "train/model_loss_mean": 0.7404231206694646, "train/model_loss_std": 0.5895280239000842, "train/model_opt_grad_norm": 13.868884418010712, "train/model_opt_grad_steps": 90626.79104477612, "train/model_opt_loss": 4370.2415583216725, "train/model_opt_model_opt_grad_overflow": 0.004975124378109453, "train/model_opt_model_opt_grad_scale": 5870.646766169154, "train/policy_entropy_mag": 1.2437443751007764, "train/policy_entropy_max": 1.2437443751007764, "train/policy_entropy_mean": 0.08671002905463698, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10084409967287263, "train/policy_logprob_mag": 6.551080269600028, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08678418716684502, "train/policy_logprob_min": -6.551080269600028, "train/policy_logprob_std": 0.6247887801175094, "train/policy_randomness_mag": 0.6391582118338021, "train/policy_randomness_max": 0.6391582118338021, "train/policy_randomness_mean": 0.04456014375188457, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05182361823335216, "train/post_ent_mag": 72.89198094458129, "train/post_ent_max": 72.89198094458129, "train/post_ent_mean": 59.340442145048684, "train/post_ent_min": 43.57377749770435, "train/post_ent_std": 6.589803083619075, "train/prior_ent_mag": 72.63159426409214, "train/prior_ent_max": 72.63159426409214, "train/prior_ent_mean": 59.89423398829218, "train/prior_ent_min": 44.99214779678269, "train/prior_ent_std": 6.395028211584139, "train/rep_loss_mean": 1.0000034374977225, "train/rep_loss_std": 0.00010765151109717861, "train/reward_avg": 0.003478138483145659, "train/reward_loss_mean": 0.024769821700023776, "train/reward_loss_std": 0.2941419392527632, "train/reward_max_data": 0.8367226366973042, "train/reward_max_pred": 0.3178507890274276, "train/reward_neg_acc": 0.9993603205799464, "train/reward_neg_loss": 0.004707622210916818, "train/reward_pos_acc": 0.12523296453169921, "train/reward_pos_loss": 4.059703217216986, "train/reward_pred": 0.002784216795603175, "train/reward_rate": 0.0049654073383084574, "train_stats/mean_log_entropy": 0.07870548215162541, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.026770848780870438, "report/cont_loss_std": 0.29923015832901, "report/cont_neg_acc": 0.2857142984867096, "report/cont_neg_loss": 2.9682366847991943, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.006524770986288786, "report/cont_pred": 0.99165940284729, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1332281529903412, "report/image_loss_std": 0.12292496114969254, "report/model_loss_mean": 0.7841662168502808, "report/model_loss_std": 0.5780381560325623, "report/post_ent_mag": 72.68826293945312, "report/post_ent_max": 72.68826293945312, "report/post_ent_mean": 61.26642608642578, "report/post_ent_min": 47.496543884277344, "report/post_ent_std": 6.3973283767700195, "report/prior_ent_mag": 73.3283462524414, "report/prior_ent_max": 73.3283462524414, "report/prior_ent_mean": 60.96360778808594, "report/prior_ent_min": 47.43041229248047, "report/prior_ent_std": 6.536787509918213, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0042572021484375, "report/reward_loss_mean": 0.02416720800101757, "report/reward_loss_std": 0.29318714141845703, "report/reward_max_data": 0.918749988079071, "report/reward_max_pred": 0.7914813756942749, "report/reward_neg_acc": 0.9990177154541016, "report/reward_neg_loss": 0.004817684646695852, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.3071365356445312, "report/reward_pred": 0.003755278419703245, "report/reward_rate": 0.005859375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.020473700016736984, "eval/cont_loss_std": 0.2819264233112335, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.850854396820068, "eval/cont_pos_acc": 0.9980430603027344, "eval/cont_pos_loss": 0.009063951671123505, "eval/cont_pred": 0.9922271966934204, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.092437244951725, "eval/image_loss_std": 0.10862031579017639, "eval/model_loss_mean": 0.7342662215232849, "eval/model_loss_std": 0.6401466131210327, "eval/post_ent_mag": 72.20225524902344, "eval/post_ent_max": 72.20225524902344, "eval/post_ent_mean": 58.737876892089844, "eval/post_ent_min": 43.12909698486328, "eval/post_ent_std": 6.235560417175293, "eval/prior_ent_mag": 72.44515228271484, "eval/prior_ent_max": 72.44515228271484, "eval/prior_ent_mean": 58.585723876953125, "eval/prior_ent_min": 44.48442077636719, "eval/prior_ent_std": 6.2212605476379395, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0014770508278161287, "eval/reward_loss_mean": 0.02135523408651352, "eval/reward_loss_std": 0.32990244030952454, "eval/reward_max_data": 0.800000011920929, "eval/reward_max_pred": 0.6551618576049805, "eval/reward_neg_acc": 0.9970645904541016, "eval/reward_neg_loss": 0.007887370884418488, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.903433322906494, "eval/reward_pred": 0.003775459248572588, "eval/reward_rate": 0.001953125, "replay/size": 1000000.0, "replay/inserts": 32096.0, "replay/samples": 32096.0, "replay/insert_wait_avg": 1.3245319797177377e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.63353385716112e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2760.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2243139571037846e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.5348196029663086e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2359130382538, "timer/env.step_count": 4012.0, "timer/env.step_total": 40.60552406311035, "timer/env.step_frac": 0.040595946949924605, "timer/env.step_avg": 0.010121017961891913, "timer/env.step_min": 0.008470296859741211, "timer/env.step_max": 0.037509918212890625, "timer/replay._sample_count": 32096.0, "timer/replay._sample_total": 18.103063821792603, "timer/replay._sample_frac": 0.018098794080292392, "timer/replay._sample_avg": 0.0005640286584556518, "timer/replay._sample_min": 0.00040793418884277344, "timer/replay._sample_max": 0.0316464900970459, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4357.0, "timer/agent.policy_total": 48.647212743759155, "timer/agent.policy_frac": 0.04863573893881838, "timer/agent.policy_avg": 0.011165300147752848, "timer/agent.policy_min": 0.009152412414550781, "timer/agent.policy_max": 0.09734654426574707, "timer/dataset_train_count": 2006.0, "timer/dataset_train_total": 0.27225375175476074, "timer/dataset_train_frac": 0.0002721895386937066, "timer/dataset_train_avg": 0.00013571971672719877, "timer/dataset_train_min": 0.0001068115234375, "timer/dataset_train_max": 0.022989988327026367, "timer/agent.train_count": 2006.0, "timer/agent.train_total": 900.3662006855011, "timer/agent.train_frac": 0.9001538426575839, "timer/agent.train_avg": 0.4488365905710374, "timer/agent.train_min": 0.4360668659210205, "timer/agent.train_max": 0.7421479225158691, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48598742485046387, "timer/agent.report_frac": 0.00048587280112174635, "timer/agent.report_avg": 0.24299371242523193, "timer/agent.report_min": 0.23496103286743164, "timer/agent.report_max": 0.2510263919830322, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.600120544433594e-05, "timer/dataset_eval_frac": 3.59927142937519e-08, "timer/dataset_eval_avg": 3.600120544433594e-05, "timer/dataset_eval_min": 3.600120544433594e-05, "timer/dataset_eval_max": 3.600120544433594e-05, "fps": 32.08771845717554}
{"step": 1469096, "time": 46302.843801021576, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1469184, "time": 46305.84837889671, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1469216, "time": 46306.84057021141, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1469536, "time": 46316.75992035866, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1469840, "time": 46326.10824394226, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1469880, "time": 46327.126870155334, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1469928, "time": 46328.59079837799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1469944, "time": 46329.08518528938, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1470040, "time": 46333.32659769058, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1470040, "time": 46334.013288497925, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1470040, "time": 46334.08126115799, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 1470040, "time": 46334.10813164711, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1470040, "time": 46334.37729167938, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 1470040, "time": 46334.976320028305, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 1470040, "time": 46335.833794116974, "eval_episode/length": 174.0, "eval_episode/score": 0.45625001192092896, "eval_episode/reward_rate": 0.005714285714285714}
{"step": 1470040, "time": 46335.840958595276, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1470104, "time": 46337.8002884388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1470104, "time": 46337.812463760376, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1470296, "time": 46343.70409631729, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1470632, "time": 46353.98436379433, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1470704, "time": 46356.4490942955, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1470832, "time": 46360.366911649704, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1471216, "time": 46372.33142733574, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1471336, "time": 46375.806441783905, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1471768, "time": 46389.055151462555, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1471848, "time": 46391.52130818367, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1472152, "time": 46400.98131990433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1472240, "time": 46403.90733838081, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1472312, "time": 46405.94809007645, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1472376, "time": 46407.94108223915, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1472416, "time": 46409.40314745903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1472576, "time": 46414.39012980461, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1472608, "time": 46415.39437484741, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1472792, "time": 46420.82151865959, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1472896, "time": 46424.34625911713, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1472976, "time": 46426.832706689835, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1473088, "time": 46430.30932068825, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1473328, "time": 46437.67864537239, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1473376, "time": 46439.18307232857, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1473392, "time": 46439.70633673668, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1473448, "time": 46441.20749998093, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1473672, "time": 46448.03114891052, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1473856, "time": 46454.03154230118, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1474416, "time": 46471.0764336586, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1474616, "time": 46477.43124508858, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1474624, "time": 46477.8990213871, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1474784, "time": 46482.77313423157, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1474952, "time": 46487.85397338867, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 1475104, "time": 46492.750238657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1475152, "time": 46494.251057863235, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1475216, "time": 46496.220626831055, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1475232, "time": 46496.71642613411, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1475288, "time": 46498.22096276283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1475344, "time": 46500.16882801056, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1475456, "time": 46503.59061861038, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 1475568, "time": 46507.033672094345, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1475640, "time": 46509.06818437576, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1475728, "time": 46511.999337911606, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1475896, "time": 46517.11529755592, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1476096, "time": 46523.49975824356, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1476392, "time": 46532.41851019859, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1476584, "time": 46538.31805610657, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1476624, "time": 46539.787460803986, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1476800, "time": 46545.34138035774, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1477288, "time": 46560.07074427605, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1477416, "time": 46564.03740954399, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1477520, "time": 46567.45481944084, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1477528, "time": 46567.4850692749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1477576, "time": 46568.968945264816, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1477712, "time": 46573.41654729843, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1477768, "time": 46575.06430006027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1478032, "time": 46583.494492292404, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1478048, "time": 46583.986377477646, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1478112, "time": 46585.96460938454, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1478208, "time": 46588.92522358894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1478328, "time": 46592.3667280674, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1478672, "time": 46603.07599449158, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1478888, "time": 46609.57885956764, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1478976, "time": 46612.47658777237, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1478976, "time": 46612.4844455719, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1479176, "time": 46618.39215493202, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1479312, "time": 46622.78197169304, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1479472, "time": 46627.643552064896, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1479880, "time": 46640.001141786575, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1480024, "time": 46644.409125328064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1480024, "time": 46645.58933234215, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 1480024, "time": 46645.94182872772, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1480024, "time": 46646.33333039284, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1480024, "time": 46646.38222742081, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1480024, "time": 46646.78693151474, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 1480024, "time": 46647.33020210266, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 1480024, "time": 46647.661967754364, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1480024, "time": 46647.67022061348, "eval_episode/length": 155.0, "eval_episode/score": 0.515625, "eval_episode/reward_rate": 0.00641025641025641}
{"step": 1480032, "time": 46648.142597436905, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1480152, "time": 46651.58962035179, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1480344, "time": 46657.43863487244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1480360, "time": 46657.93255352974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1480480, "time": 46661.81205677986, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1480672, "time": 46667.793326854706, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1480680, "time": 46667.8217086792, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1480752, "time": 46670.26683950424, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1480952, "time": 46676.17716193199, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1480976, "time": 46677.1441783905, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1481136, "time": 46682.07765221596, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1481248, "time": 46685.52129864693, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 1481400, "time": 46689.983555316925, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1481472, "time": 46692.41504383087, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1481472, "time": 46692.447998046875, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1481592, "time": 46696.04640460014, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1481696, "time": 46699.442773103714, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1481888, "time": 46705.404597997665, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1482264, "time": 46716.87123441696, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1482424, "time": 46721.782794713974, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1482440, "time": 46722.292096138, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1482704, "time": 46730.887595653534, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1482888, "time": 46736.8740568161, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1482992, "time": 46740.28963017464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1483032, "time": 46741.30364203453, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1483120, "time": 46744.21319818497, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1483128, "time": 46744.24147748947, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1483544, "time": 46757.1585149765, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1483624, "time": 46759.60422992706, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1483720, "time": 46762.560326099396, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1483784, "time": 46764.524134635925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1483824, "time": 46766.01686859131, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1483920, "time": 46769.009195804596, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1484080, "time": 46773.967567682266, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1484304, "time": 46780.86185693741, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1484416, "time": 46784.39661383629, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1484424, "time": 46784.42449951172, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1484648, "time": 46791.30337882042, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1484704, "time": 46793.246589660645, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1485056, "time": 46804.05724430084, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1485088, "time": 46805.057451963425, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1485208, "time": 46808.51923203468, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1485352, "time": 46812.99130964279, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1485432, "time": 46815.60003185272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1485752, "time": 46825.55049824715, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1485960, "time": 46832.12862253189, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1486032, "time": 46834.62054538727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1486216, "time": 46840.116543293, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1486232, "time": 46840.60979580879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1486408, "time": 46846.20730614662, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1486424, "time": 46846.708309412, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1486664, "time": 46854.118453502655, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1486800, "time": 46858.54398870468, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1486856, "time": 46860.05107021332, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 1487176, "time": 46869.91630029678, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1487384, "time": 46876.45180249214, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1487688, "time": 46885.823647260666, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1487744, "time": 46887.77910757065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1488064, "time": 46897.635191202164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1488280, "time": 46904.2018032074, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1488528, "time": 46912.065891981125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1488632, "time": 46915.05462026596, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1488648, "time": 46915.54725193977, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1488720, "time": 46917.975640535355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1488856, "time": 46921.973991155624, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1488984, "time": 46925.92557811737, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1489088, "time": 46929.371337890625, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1489168, "time": 46931.822818279266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1489304, "time": 46935.91184711456, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1489376, "time": 46938.34091114998, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1489488, "time": 46941.81488156319, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1489648, "time": 46946.73010969162, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1489720, "time": 46948.73122239113, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1489744, "time": 46949.69166493416, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1489776, "time": 46950.66887116432, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1490008, "time": 46958.02481460571, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 1490008, "time": 46958.61195254326, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1490008, "time": 46959.044231414795, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1490008, "time": 46959.13328266144, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1490008, "time": 46959.38491868973, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1490008, "time": 46959.775993824005, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 1490008, "time": 46959.86585474014, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1490008, "time": 46959.95203733444, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1490040, "time": 46960.95127034187, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1490456, "time": 46973.905495882034, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1490528, "time": 46976.37825393677, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1490728, "time": 46982.28675246239, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1490856, "time": 46986.23158669472, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1490928, "time": 46988.66735768318, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1490960, "time": 46990.14979100227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1491016, "time": 46991.65111756325, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1491088, "time": 46994.20014953613, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1491184, "time": 46997.16879487038, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1491480, "time": 47006.042882204056, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1491496, "time": 47006.55200743675, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1491616, "time": 47010.53304553032, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1491640, "time": 47011.06548500061, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1491664, "time": 47012.02688908577, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 1491792, "time": 47015.99588608742, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1491976, "time": 47021.414618730545, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1492184, "time": 47027.94869971275, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1492192, "time": 47028.42328572273, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1492248, "time": 47029.91482424736, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1492368, "time": 47033.8676803112, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1492456, "time": 47036.35788989067, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1492520, "time": 47038.33301305771, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1492576, "time": 47040.28524899483, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1492720, "time": 47044.72915768623, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1492816, "time": 47047.707163095474, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1492888, "time": 47049.69952702522, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1492920, "time": 47050.69772982597, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1493224, "time": 47060.10980939865, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1493672, "time": 47073.8334980011, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1493696, "time": 47074.79439210892, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1493816, "time": 47078.25898480415, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1493824, "time": 47078.73372268677, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1493912, "time": 47081.21805882454, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1494072, "time": 47086.235973358154, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1494104, "time": 47087.224239349365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1494536, "time": 47100.45281481743, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1494648, "time": 47103.865488767624, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1494752, "time": 47107.29204750061, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1494792, "time": 47108.30561757088, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1495096, "time": 47117.79032373428, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1495128, "time": 47118.76789045334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1495224, "time": 47121.70719766617, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1495232, "time": 47122.17922067642, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1495304, "time": 47124.151624679565, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1495376, "time": 47126.58945894241, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1495536, "time": 47131.47496628761, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1495576, "time": 47132.47015404701, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1495784, "time": 47138.85931944847, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1495832, "time": 47140.35176324844, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1496272, "time": 47154.2769343853, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1496288, "time": 47154.77299499512, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1496360, "time": 47156.7499396801, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1496392, "time": 47157.73263454437, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1496416, "time": 47158.69573020935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1496496, "time": 47161.151952028275, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1496568, "time": 47163.13493680954, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1496896, "time": 47173.43750452995, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1497152, "time": 47181.430305719376, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1497176, "time": 47181.95151424408, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1497200, "time": 47182.91961193085, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1497312, "time": 47186.39661836624, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1497376, "time": 47188.38889312744, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1497472, "time": 47191.409551382065, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1498016, "time": 47208.46488690376, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1498056, "time": 47209.513667583466, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1498408, "time": 47220.367594242096, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 1498440, "time": 47221.35500574112, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1498576, "time": 47225.76637673378, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1498688, "time": 47229.227336883545, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1498704, "time": 47229.72665309906, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1498728, "time": 47230.245855093, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1498792, "time": 47232.22634220123, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1498848, "time": 47234.35491728783, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1498872, "time": 47234.875921964645, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 1499048, "time": 47240.381487846375, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1499072, "time": 47241.3623445034, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1499296, "time": 47248.88681769371, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1499320, "time": 47249.42795610428, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1499344, "time": 47250.395679712296, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1499480, "time": 47254.387241363525, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1499672, "time": 47260.28882646561, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1499768, "time": 47263.25675868988, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1499992, "time": 47270.27589440346, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1500008, "time": 47270.77035117149, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1500072, "time": 47272.73044013977, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1500096, "time": 47274.584409713745, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 1500096, "time": 47274.5926425457, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 1500096, "time": 47274.68484735489, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 1500096, "time": 47275.33686876297, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1500096, "time": 47275.36285877228, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1500096, "time": 47275.51013636589, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1500096, "time": 47276.29829263687, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 1500096, "time": 47276.67460560799, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1500144, "time": 47278.16665673256, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1500160, "time": 47278.65966081619, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1500200, "time": 47279.65910696983, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1500560, "time": 47290.96479654312, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1500760, "time": 47297.03826999664, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1500800, "time": 47298.47822475433, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1500809, "time": 47299.56961154938, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2341630638544285, "train/action_min": 0.0, "train/action_std": 1.8254654293683306, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00959539315639878, "train/actor_opt_grad_steps": 92710.0, "train/actor_opt_loss": -22.974268199211387, "train/adv_mag": 0.7971643802508637, "train/adv_max": 0.30883508711004976, "train/adv_mean": 0.0007994409581725956, "train/adv_min": -0.7335159041773733, "train/adv_std": 0.029317394989406942, "train/cont_avg": 0.9932474874371859, "train/cont_loss_mean": 0.029221337630259032, "train/cont_loss_std": 0.3035042735949234, "train/cont_neg_acc": 0.09922429784458486, "train/cont_neg_loss": 3.424901637599696, "train/cont_pos_acc": 0.9998665413065772, "train/cont_pos_loss": 0.006256679873258324, "train/cont_pred": 0.9931129828170316, "train/cont_rate": 0.9932474874371859, "train/dyn_loss_mean": 1.0000057496018147, "train/dyn_loss_std": 0.00010957133174691368, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1740641152795086, "train/extr_critic_critic_opt_grad_steps": 92710.0, "train/extr_critic_critic_opt_loss": 5938.400488771985, "train/extr_critic_mag": 1.759347965968913, "train/extr_critic_max": 1.759347965968913, "train/extr_critic_mean": 1.60563739340509, "train/extr_critic_min": 1.387451650509283, "train/extr_critic_std": 0.028743334479592552, "train/extr_return_normed_mag": 0.8207373774830421, "train/extr_return_normed_max": 0.34591085886835454, "train/extr_return_normed_mean": 0.06011532507275217, "train/extr_return_normed_min": -0.6872151473059727, "train/extr_return_normed_std": 0.04174124381163312, "train/extr_return_rate": 0.9997929334640503, "train/extr_return_raw_mag": 1.8922322790826385, "train/extr_return_raw_max": 1.8922322790826385, "train/extr_return_raw_mean": 1.606436808504651, "train/extr_return_raw_min": 0.8591062729083114, "train/extr_return_raw_std": 0.041741243914593405, "train/extr_reward_mag": 0.3304521348608199, "train/extr_reward_max": 0.3304521348608199, "train/extr_reward_mean": 0.0030919267379458824, "train/extr_reward_min": 3.2168536929029916e-07, "train/extr_reward_std": 0.010208301098745822, "train/image_loss_mean": 0.08789349935162606, "train/image_loss_std": 0.10255255464033865, "train/model_loss_mean": 0.7414809693044154, "train/model_loss_std": 0.5834370447163606, "train/model_opt_grad_norm": 13.412001046267422, "train/model_opt_grad_steps": 92625.21105527638, "train/model_opt_loss": 4544.688108511306, "train/model_opt_model_opt_grad_overflow": 0.005025125628140704, "train/model_opt_model_opt_grad_scale": 6105.527638190954, "train/policy_entropy_mag": 1.2511253249106096, "train/policy_entropy_max": 1.2511253249106096, "train/policy_entropy_mean": 0.08982767056130883, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1074930556380569, "train/policy_logprob_mag": 6.551080270029193, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08977294803114992, "train/policy_logprob_min": -6.551080270029193, "train/policy_logprob_std": 0.6270388098218334, "train/policy_randomness_mag": 0.6429512698446685, "train/policy_randomness_max": 0.6429512698446685, "train/policy_randomness_mean": 0.0461622944017451, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05524050614717019, "train/post_ent_mag": 72.95239656534626, "train/post_ent_max": 72.95239656534626, "train/post_ent_mean": 59.956897448055706, "train/post_ent_min": 44.3518705511812, "train/post_ent_std": 6.333307752657176, "train/prior_ent_mag": 72.33599964697757, "train/prior_ent_max": 72.33599964697757, "train/prior_ent_mean": 59.5649880068985, "train/prior_ent_min": 45.66610104354782, "train/prior_ent_std": 6.016730473868212, "train/rep_loss_mean": 1.0000057496018147, "train/rep_loss_std": 0.00010957133174691368, "train/reward_avg": 0.003472747029643038, "train/reward_loss_mean": 0.024362660850861563, "train/reward_loss_std": 0.28628158966201034, "train/reward_max_data": 0.8285175891377818, "train/reward_max_pred": 0.3261172861310106, "train/reward_neg_acc": 0.999329257550551, "train/reward_neg_loss": 0.004681805551201854, "train/reward_pos_acc": 0.13007624964019163, "train/reward_pos_loss": 3.949366945717203, "train/reward_pred": 0.0028081758751594766, "train/reward_rate": 0.004995681532663316, "train_stats/mean_log_entropy": 0.08239913948613112, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.0167971383780241, "report/cont_loss_std": 0.1769169569015503, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.6590555906295776, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.007117815315723419, "report/cont_pred": 0.9901988506317139, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06552687287330627, "report/image_loss_std": 0.07920819520950317, "report/model_loss_mean": 0.6971559524536133, "report/model_loss_std": 0.3549599349498749, "report/post_ent_mag": 72.76490783691406, "report/post_ent_max": 72.76490783691406, "report/post_ent_mean": 57.49473571777344, "report/post_ent_min": 41.91896438598633, "report/post_ent_std": 7.079845428466797, "report/prior_ent_mag": 72.69908142089844, "report/prior_ent_max": 72.69908142089844, "report/prior_ent_mean": 58.70825958251953, "report/prior_ent_min": 45.43291473388672, "report/prior_ent_std": 6.194395542144775, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0030548095237463713, "report/reward_loss_mean": 0.014831927604973316, "report/reward_loss_std": 0.17412500083446503, "report/reward_max_data": 0.8125, "report/reward_max_pred": 0.702666163444519, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0055739302188158035, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.3756213188171387, "report/reward_pred": 0.004245442803949118, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.03941790759563446, "eval/cont_loss_std": 0.39720746874809265, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.322055339813232, "eval/cont_pos_acc": 0.998033344745636, "eval/cont_pos_loss": 0.00994055811315775, "eval/cont_pred": 0.9923142194747925, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13837526738643646, "eval/image_loss_std": 0.13966861367225647, "eval/model_loss_mean": 0.814777672290802, "eval/model_loss_std": 0.8132390975952148, "eval/post_ent_mag": 72.50135803222656, "eval/post_ent_max": 72.50135803222656, "eval/post_ent_mean": 56.56511688232422, "eval/post_ent_min": 42.104881286621094, "eval/post_ent_std": 7.578956127166748, "eval/prior_ent_mag": 71.8968276977539, "eval/prior_ent_max": 71.8968276977539, "eval/prior_ent_mean": 58.04718780517578, "eval/prior_ent_min": 45.442955017089844, "eval/prior_ent_std": 6.543148994445801, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0045227049849927425, "eval/reward_loss_mean": 0.03698445484042168, "eval/reward_loss_std": 0.40594246983528137, "eval/reward_max_data": 0.921875, "eval/reward_max_pred": 0.6357872486114502, "eval/reward_neg_acc": 0.9970530867576599, "eval/reward_neg_loss": 0.008295875042676926, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.90447998046875, "eval/reward_pred": 0.003678838489577174, "eval/reward_rate": 0.005859375, "replay/size": 1000000.0, "replay/inserts": 31824.0, "replay/samples": 31824.0, "replay/insert_wait_avg": 1.3478620978921668e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.645898477584049e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4720.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1880519026416843e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3113021850585938e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9818334579468, "timer/env.step_count": 3978.0, "timer/env.step_total": 40.86850142478943, "timer/env.step_frac": 0.04086924387762701, "timer/env.step_avg": 0.010273630322973713, "timer/env.step_min": 0.00835561752319336, "timer/env.step_max": 0.05666375160217285, "timer/replay._sample_count": 31824.0, "timer/replay._sample_total": 18.079880237579346, "timer/replay._sample_frac": 0.01808020869245089, "timer/replay._sample_avg": 0.0005681209224980941, "timer/replay._sample_min": 0.00041484832763671875, "timer/replay._sample_max": 0.027309656143188477, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4568.0, "timer/agent.policy_total": 51.0411958694458, "timer/agent.policy_frac": 0.0510421231283221, "timer/agent.policy_avg": 0.011173641827812128, "timer/agent.policy_min": 0.009311199188232422, "timer/agent.policy_max": 0.0840456485748291, "timer/dataset_train_count": 1989.0, "timer/dataset_train_total": 0.25429463386535645, "timer/dataset_train_frac": 0.00025429925360344113, "timer/dataset_train_avg": 0.00012785049465327121, "timer/dataset_train_min": 0.00010919570922851562, "timer/dataset_train_max": 0.0008997917175292969, "timer/agent.train_count": 1989.0, "timer/agent.train_total": 894.8573546409607, "timer/agent.train_frac": 0.8948736114000545, "timer/agent.train_avg": 0.4499031446158676, "timer/agent.train_min": 0.43672633171081543, "timer/agent.train_max": 0.7307369709014893, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4778404235839844, "timer/agent.report_frac": 0.00047784910444983547, "timer/agent.report_avg": 0.2389202117919922, "timer/agent.report_min": 0.23179316520690918, "timer/agent.report_max": 0.2460472583770752, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.790855407714844e-05, "timer/dataset_eval_frac": 3.790924275700119e-08, "timer/dataset_eval_avg": 3.790855407714844e-05, "timer/dataset_eval_min": 3.790855407714844e-05, "timer/dataset_eval_max": 3.790855407714844e-05, "fps": 31.823892744410553}
{"step": 1500976, "time": 47304.68800663948, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1501040, "time": 47306.656443595886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1501232, "time": 47312.61606621742, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1501472, "time": 47319.96832871437, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1501600, "time": 47324.05633354187, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1501648, "time": 47325.54858851433, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1501680, "time": 47326.54081106186, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1502072, "time": 47338.36038565636, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1502136, "time": 47340.31215715408, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1502312, "time": 47345.73066520691, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1502472, "time": 47350.642433166504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1502648, "time": 47356.184268951416, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1502752, "time": 47359.686790943146, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 1502936, "time": 47365.127496004105, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1502992, "time": 47367.08919095993, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1503112, "time": 47370.587035894394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1503128, "time": 47371.08802008629, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 1503184, "time": 47373.04008746147, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1503192, "time": 47373.07243347168, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1503496, "time": 47382.42632985115, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1503584, "time": 47385.50621318817, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1503680, "time": 47388.45775580406, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 1503840, "time": 47393.39135622978, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1503912, "time": 47395.38163495064, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1504080, "time": 47400.799417972565, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1504240, "time": 47405.72569704056, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1504296, "time": 47407.23614573479, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1504400, "time": 47410.62491440773, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1504488, "time": 47413.12430715561, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1504504, "time": 47413.67537546158, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1504536, "time": 47414.69360637665, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1504840, "time": 47424.05896806717, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1505152, "time": 47433.901629924774, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 1505176, "time": 47434.42342567444, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1505248, "time": 47436.87485861778, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1505336, "time": 47439.36224293709, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1505592, "time": 47447.3625869751, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1505608, "time": 47447.857411146164, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1505824, "time": 47454.730388879776, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1505904, "time": 47457.195668935776, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1506024, "time": 47460.63240432739, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1506128, "time": 47464.04027104378, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1506144, "time": 47464.53499865532, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1506312, "time": 47469.45918297768, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1506448, "time": 47474.00743460655, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1506456, "time": 47474.03578209877, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1506472, "time": 47474.53243994713, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1506552, "time": 47477.025309085846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1506848, "time": 47486.36344242096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1506872, "time": 47486.87485051155, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1506888, "time": 47487.36543703079, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1507024, "time": 47491.76735377312, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1507944, "time": 47520.36283612251, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1508024, "time": 47522.83704280853, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1508216, "time": 47528.71444964409, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1508416, "time": 47535.19146704674, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1508440, "time": 47535.73244047165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1508760, "time": 47545.57565331459, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1508784, "time": 47546.53465414047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1508840, "time": 47548.03619813919, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1508912, "time": 47550.51404237747, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 1508928, "time": 47551.01457905769, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1508928, "time": 47551.0258140564, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1508992, "time": 47552.9941174984, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1509208, "time": 47559.40838909149, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1509472, "time": 47567.90823197365, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1509640, "time": 47572.916462659836, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1509760, "time": 47576.90377616882, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1509872, "time": 47580.35093283653, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1509952, "time": 47582.80908727646, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1509960, "time": 47582.83933854103, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1510040, "time": 47585.32680487633, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1510080, "time": 47587.76648592949, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 1510080, "time": 47588.103237867355, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 1510080, "time": 47588.55295395851, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1510080, "time": 47588.59905219078, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1510080, "time": 47589.03689265251, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1510080, "time": 47589.235651254654, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1510080, "time": 47589.85354733467, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1510080, "time": 47590.336017370224, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1510096, "time": 47590.82899713516, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1510248, "time": 47595.38664841652, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1510568, "time": 47605.22096538544, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1510608, "time": 47606.674384355545, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1510872, "time": 47614.58508658409, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1511096, "time": 47621.517446517944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1511264, "time": 47627.05199766159, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1511536, "time": 47635.395250082016, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1511600, "time": 47637.35749363899, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1511640, "time": 47638.385536432266, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1511656, "time": 47638.879821777344, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1511672, "time": 47639.368918418884, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 1511904, "time": 47646.69528222084, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1512072, "time": 47651.62257170677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1512184, "time": 47655.19059896469, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1512320, "time": 47659.58531045914, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1512352, "time": 47660.57282805443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1512408, "time": 47662.070390462875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1512616, "time": 47668.48654007912, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1512672, "time": 47670.43534517288, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1512736, "time": 47672.40430378914, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1512744, "time": 47672.43182730675, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 1512920, "time": 47677.89169931412, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1513208, "time": 47686.94750952721, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1513480, "time": 47695.36195755005, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1513768, "time": 47704.18515443802, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1513944, "time": 47709.58821463585, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 1514248, "time": 47719.07582569122, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1514248, "time": 47719.087487220764, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1514368, "time": 47723.006700992584, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1514616, "time": 47730.32757854462, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1514616, "time": 47730.342475652695, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1514664, "time": 47731.81930422783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1514760, "time": 47734.791046857834, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1514928, "time": 47740.208054065704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1515168, "time": 47747.75506615639, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1515240, "time": 47749.74894094467, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1515248, "time": 47750.22658395767, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1515448, "time": 47756.15258526802, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1515464, "time": 47756.65151953697, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1516208, "time": 47780.63094043732, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1516208, "time": 47780.6396355629, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1516256, "time": 47782.13217163086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1516272, "time": 47782.655272483826, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1516456, "time": 47788.160430431366, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1516624, "time": 47793.645725250244, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1516680, "time": 47795.163758039474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1516944, "time": 47803.78721666336, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1517112, "time": 47808.86736321449, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1517256, "time": 47813.40496778488, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1517376, "time": 47817.384969711304, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1517520, "time": 47821.94001078606, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1517632, "time": 47825.43183207512, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1517688, "time": 47826.95463132858, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1517816, "time": 47830.99028611183, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1517968, "time": 47836.06163954735, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1517992, "time": 47836.58361530304, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1518552, "time": 47854.02186369896, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1518568, "time": 47854.524055957794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1518728, "time": 47859.45284867287, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1518968, "time": 47867.01732468605, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1518992, "time": 47868.00212550163, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1518992, "time": 47868.01031064987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1519160, "time": 47872.951649188995, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1519256, "time": 47875.91429781914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1519456, "time": 47882.28423810005, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1519520, "time": 47884.27269268036, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1519624, "time": 47887.23691248894, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1519672, "time": 47888.72879743576, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1519768, "time": 47891.665060043335, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1520016, "time": 47899.631630182266, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1520032, "time": 47900.1261677742, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1520064, "time": 47903.29350757599, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1520064, "time": 47903.466098070145, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1520064, "time": 47904.15947508812, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 1520064, "time": 47904.402009010315, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 1520064, "time": 47904.74753189087, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 1520064, "time": 47905.52535581589, "eval_episode/length": 173.0, "eval_episode/score": 0.4593749940395355, "eval_episode/reward_rate": 0.005747126436781609}
{"step": 1520064, "time": 47906.10588288307, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1520064, "time": 47906.33641958237, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1520104, "time": 47907.36019396782, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1520280, "time": 47912.84273791313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1520328, "time": 47914.31801152229, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1520416, "time": 47917.24100327492, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1520912, "time": 47932.66063928604, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1520920, "time": 47932.689908504486, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1520928, "time": 47933.16313433647, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1521088, "time": 47938.060130119324, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 1521512, "time": 47950.90046477318, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1521512, "time": 47950.91815042496, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1521600, "time": 47954.03985095024, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1521984, "time": 47965.81389307976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1522024, "time": 47966.835829257965, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1522256, "time": 47974.23751950264, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1522336, "time": 47976.682949543, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1522640, "time": 47986.14003992081, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1522728, "time": 47988.630240917206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1522824, "time": 47991.567689180374, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1522880, "time": 47993.520102500916, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1523032, "time": 47997.9512360096, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1523136, "time": 48001.35063409805, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1523240, "time": 48004.32982635498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1523704, "time": 48018.74829816818, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1523744, "time": 48020.70283293724, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1523808, "time": 48022.67559981346, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1523816, "time": 48022.70584988594, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1523912, "time": 48025.63866233826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1524048, "time": 48030.02093958855, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1524112, "time": 48031.992871046066, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1524168, "time": 48033.48397016525, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1524216, "time": 48034.974615335464, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1524360, "time": 48039.406577825546, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1524568, "time": 48045.915800094604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1524696, "time": 48049.82996702194, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1524752, "time": 48051.79013776779, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1524864, "time": 48055.196662425995, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1524896, "time": 48056.17626237869, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1524976, "time": 48058.62701916695, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1525056, "time": 48061.05594730377, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1525136, "time": 48063.51999568939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1525408, "time": 48071.8454785347, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1525656, "time": 48079.32765388489, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1526000, "time": 48090.10433292389, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1526072, "time": 48092.09746217728, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 1526264, "time": 48097.963967084885, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1526344, "time": 48100.415595293045, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1526464, "time": 48104.48098611832, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1527008, "time": 48121.15151262283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1527088, "time": 48123.59964966774, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 1527208, "time": 48127.05403780937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1527240, "time": 48128.03684139252, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1527296, "time": 48129.965695858, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1527400, "time": 48132.93059492111, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1527448, "time": 48134.55481123924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1527472, "time": 48135.5365254879, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1527760, "time": 48144.34056472778, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1528000, "time": 48151.719675540924, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1528280, "time": 48160.08333516121, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1528384, "time": 48163.52283382416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1528536, "time": 48168.107177734375, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1528616, "time": 48170.58775758743, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1528704, "time": 48173.50076627731, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1528752, "time": 48175.008261442184, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1528936, "time": 48180.40398645401, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1529136, "time": 48186.75174498558, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1529432, "time": 48195.7045071125, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1529496, "time": 48197.65706849098, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1529552, "time": 48199.60957074165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1529576, "time": 48200.131843328476, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1529624, "time": 48201.613679885864, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1529712, "time": 48204.55796575546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1529720, "time": 48204.587154626846, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1529824, "time": 48207.99957370758, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1530048, "time": 48215.94328045845, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 1530048, "time": 48216.5263197422, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1530048, "time": 48216.800955057144, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1530048, "time": 48216.92530918121, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 1530048, "time": 48217.03888487816, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1530048, "time": 48217.33832216263, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 1530048, "time": 48217.34662985802, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1530048, "time": 48217.41438937187, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 1530328, "time": 48225.87897443771, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1530328, "time": 48225.89945268631, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1530640, "time": 48235.689426898956, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1530688, "time": 48237.176745176315, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1530752, "time": 48239.130620718, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1530968, "time": 48245.50277709961, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1531032, "time": 48247.48504781723, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1531200, "time": 48252.85632300377, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1531248, "time": 48254.47130060196, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1531312, "time": 48256.45116734505, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1531448, "time": 48260.37692785263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1531520, "time": 48262.81214570999, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 1531840, "time": 48272.59492993355, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1531864, "time": 48273.108276605606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1531888, "time": 48274.06158494949, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1532016, "time": 48278.51158642769, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1532088, "time": 48280.49221587181, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1532216, "time": 48284.539154052734, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1532352, "time": 48288.984503507614, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1532400, "time": 48290.4773273468, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1532472, "time": 48292.48325395584, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1532672, "time": 48298.821003198624, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1532680, "time": 48298.84859275818, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1532680, "time": 48298.8577978611, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1532681, "time": 48300.06248474121, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1262108884265074, "train/action_min": 0.0, "train/action_std": 1.7832412414215317, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01112544713027064, "train/actor_opt_grad_steps": 94700.0, "train/actor_opt_loss": -27.6494778292862, "train/adv_mag": 0.8083592284863917, "train/adv_max": 0.3152965325206967, "train/adv_mean": 0.0008797859957543843, "train/adv_min": -0.7307144322587018, "train/adv_std": 0.034037598001597516, "train/cont_avg": 0.9933505417713567, "train/cont_loss_mean": 0.02911745658584276, "train/cont_loss_std": 0.3025360650677777, "train/cont_neg_acc": 0.0961881937393591, "train/cont_neg_loss": 3.425947207901346, "train/cont_pos_acc": 0.999812308867373, "train/cont_pos_loss": 0.006284501890291521, "train/cont_pred": 0.9931594250190198, "train/cont_rate": 0.9933505417713567, "train/dyn_loss_mean": 1.0000009488819832, "train/dyn_loss_std": 2.850856908115011e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16289224182653367, "train/extr_critic_critic_opt_grad_steps": 94700.0, "train/extr_critic_critic_opt_loss": 7222.397117423053, "train/extr_critic_mag": 1.7640232920047625, "train/extr_critic_max": 1.7640232920047625, "train/extr_critic_mean": 1.6203854030101144, "train/extr_critic_min": 1.349512653135175, "train/extr_critic_std": 0.032115224299568625, "train/extr_return_normed_mag": 0.8119237369029366, "train/extr_return_normed_max": 0.3283165980823076, "train/extr_return_normed_mean": 0.06859542049430123, "train/extr_return_normed_min": -0.6791089641388937, "train/extr_return_normed_std": 0.04813119622143968, "train/extr_return_rate": 0.9996535652246906, "train/extr_return_raw_mag": 1.8809862855690807, "train/extr_return_raw_max": 1.8809862855690807, "train/extr_return_raw_mean": 1.6212651879344153, "train/extr_return_raw_min": 0.8735607233478795, "train/extr_return_raw_std": 0.048131196202719634, "train/extr_reward_mag": 0.30380146347697656, "train/extr_reward_max": 0.30380146347697656, "train/extr_reward_mean": 0.003066594187104747, "train/extr_reward_min": 3.9776365960662686e-07, "train/extr_reward_std": 0.010866531610825852, "train/image_loss_mean": 0.08897188962928614, "train/image_loss_std": 0.10407075723960771, "train/model_loss_mean": 0.7426716948873434, "train/model_loss_std": 0.5897605405680498, "train/model_opt_grad_norm": 13.612143171492534, "train/model_opt_grad_steps": 94613.51256281407, "train/model_opt_loss": 4110.54462988772, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5527.638190954774, "train/policy_entropy_mag": 1.24217859045345, "train/policy_entropy_max": 1.24217859045345, "train/policy_entropy_mean": 0.08730992101993992, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10240199199723239, "train/policy_logprob_mag": 6.551080270029193, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08773847265009904, "train/policy_logprob_min": -6.551080270029193, "train/policy_logprob_std": 0.6275301354015292, "train/policy_randomness_mag": 0.6383535577424208, "train/policy_randomness_max": 0.6383535577424208, "train/policy_randomness_mean": 0.04486842734280543, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05262421711755158, "train/post_ent_mag": 74.44948945932053, "train/post_ent_max": 74.44948945932053, "train/post_ent_mean": 59.97033963610779, "train/post_ent_min": 42.72384570711222, "train/post_ent_std": 7.063284972205234, "train/prior_ent_mag": 74.03438096549642, "train/prior_ent_max": 74.03438096549642, "train/prior_ent_mean": 60.18256786480621, "train/prior_ent_min": 43.91908668633082, "train/prior_ent_std": 6.971144156240339, "train/rep_loss_mean": 1.0000009488819832, "train/rep_loss_std": 2.850856908115011e-05, "train/reward_avg": 0.0034808901766895423, "train/reward_loss_mean": 0.024581758122909907, "train/reward_loss_std": 0.29217764413236974, "train/reward_max_data": 0.8377041454291224, "train/reward_max_pred": 0.3133887124421009, "train/reward_neg_acc": 0.9993984998770096, "train/reward_neg_loss": 0.004697124787311458, "train/reward_pos_acc": 0.13888725971606508, "train/reward_pos_loss": 4.023312973616711, "train/reward_pred": 0.002782295205883083, "train/reward_rate": 0.004946608040201005, "train_stats/mean_log_entropy": 0.08318802565954533, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 0.04423223435878754, "report/cont_loss_std": 0.41119372844696045, "report/cont_neg_acc": 0.10000000149011612, "report/cont_neg_loss": 3.874575138092041, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.006457650568336248, "report/cont_pred": 0.9929553270339966, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10853519290685654, "report/image_loss_std": 0.11992684751749039, "report/model_loss_mean": 0.7856454849243164, "report/model_loss_std": 0.7225433588027954, "report/post_ent_mag": 74.15702819824219, "report/post_ent_max": 74.15702819824219, "report/post_ent_mean": 60.94834518432617, "report/post_ent_min": 45.79358673095703, "report/post_ent_std": 6.41739559173584, "report/prior_ent_mag": 75.3067398071289, "report/prior_ent_max": 75.3067398071289, "report/prior_ent_mean": 62.47638702392578, "report/prior_ent_min": 45.62071990966797, "report/prior_ent_std": 6.683554649353027, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.004638671875, "report/reward_loss_mean": 0.03287805989384651, "report/reward_loss_std": 0.3434247672557831, "report/reward_max_data": 0.7875000238418579, "report/reward_max_pred": 0.31046295166015625, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0054184626787900925, "report/reward_pos_acc": 0.1428571492433548, "report/reward_pos_loss": 4.022365093231201, "report/reward_pred": 0.0032467367127537727, "report/reward_rate": 0.0068359375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.013846229761838913, "eval/cont_loss_std": 0.1516890674829483, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.322003126144409, "eval/cont_pos_acc": 0.9990215301513672, "eval/cont_pos_loss": 0.007372342050075531, "eval/cont_pred": 0.9931661486625671, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10768525302410126, "eval/image_loss_std": 0.12270504236221313, "eval/model_loss_mean": 0.7351177930831909, "eval/model_loss_std": 0.36535751819610596, "eval/post_ent_mag": 74.19103240966797, "eval/post_ent_max": 74.19103240966797, "eval/post_ent_mean": 59.553958892822266, "eval/post_ent_min": 43.93462371826172, "eval/post_ent_std": 7.220160007476807, "eval/prior_ent_mag": 75.28346252441406, "eval/prior_ent_max": 75.28346252441406, "eval/prior_ent_mean": 60.88232421875, "eval/prior_ent_min": 44.10655975341797, "eval/prior_ent_std": 7.576511383056641, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0014587402110919356, "eval/reward_loss_mean": 0.013586269691586494, "eval/reward_loss_std": 0.17793606221675873, "eval/reward_max_data": 0.875, "eval/reward_max_pred": 0.38837647438049316, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.005872042383998632, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 3.9555561542510986, "eval/reward_pred": 0.0029550460167229176, "eval/reward_rate": 0.001953125, "replay/size": 1000000.0, "replay/inserts": 31872.0, "replay/samples": 31872.0, "replay/insert_wait_avg": 1.3476574277303305e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.709991604448801e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3968.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2427448265014157e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2665987014770508e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3437278270721, "timer/env.step_count": 3984.0, "timer/env.step_total": 40.88438582420349, "timer/env.step_frac": 0.04087033755188508, "timer/env.step_avg": 0.010262145036195656, "timer/env.step_min": 0.008370399475097656, "timer/env.step_max": 0.039679527282714844, "timer/replay._sample_count": 31872.0, "timer/replay._sample_total": 18.071701049804688, "timer/replay._sample_frac": 0.01806549143768782, "timer/replay._sample_avg": 0.0005670086925767033, "timer/replay._sample_min": 0.0004420280456542969, "timer/replay._sample_max": 0.012131452560424805, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4480.0, "timer/agent.policy_total": 50.74841094017029, "timer/agent.policy_frac": 0.05073097329295505, "timer/agent.policy_avg": 0.011327770299145154, "timer/agent.policy_min": 0.00950312614440918, "timer/agent.policy_max": 0.11245083808898926, "timer/dataset_train_count": 1992.0, "timer/dataset_train_total": 0.254284143447876, "timer/dataset_train_frac": 0.0002541967689448378, "timer/dataset_train_avg": 0.000127652682453753, "timer/dataset_train_min": 0.00010895729064941406, "timer/dataset_train_max": 0.0010709762573242188, "timer/agent.train_count": 1992.0, "timer/agent.train_total": 896.202691078186, "timer/agent.train_frac": 0.895894747123472, "timer/agent.train_avg": 0.44990094933643876, "timer/agent.train_min": 0.43770718574523926, "timer/agent.train_max": 0.7160558700561523, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4762227535247803, "timer/agent.report_frac": 0.0004760591187583316, "timer/agent.report_avg": 0.23811137676239014, "timer/agent.report_min": 0.22954106330871582, "timer/agent.report_max": 0.24668169021606445, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.1961669921875e-05, "timer/dataset_eval_frac": 4.194725148427066e-08, "timer/dataset_eval_avg": 4.1961669921875e-05, "timer/dataset_eval_min": 4.1961669921875e-05, "timer/dataset_eval_max": 4.1961669921875e-05, "fps": 31.860250815442257}
{"step": 1532696, "time": 48300.11445379257, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1532696, "time": 48300.49935674667, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1532944, "time": 48308.31944203377, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1533048, "time": 48311.26959872246, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1533160, "time": 48314.83294463158, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1533472, "time": 48324.59268331528, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1533472, "time": 48324.59879422188, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1533520, "time": 48326.06518435478, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1533968, "time": 48339.723646879196, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1533968, "time": 48339.7324860096, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1534056, "time": 48342.22554254532, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1534064, "time": 48342.69735264778, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1534184, "time": 48346.2879486084, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1534520, "time": 48356.64204788208, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1534848, "time": 48366.90125155449, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1534928, "time": 48369.36682367325, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1534984, "time": 48370.84384512901, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1534992, "time": 48371.33462190628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1535080, "time": 48373.896570682526, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1535232, "time": 48378.77613210678, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1535256, "time": 48379.29519677162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1535320, "time": 48381.26893353462, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1535336, "time": 48381.76589155197, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1535832, "time": 48396.99034571648, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1536016, "time": 48402.86673974991, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1536152, "time": 48406.98732972145, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1536376, "time": 48413.87326359749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1536720, "time": 48424.66174054146, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1536720, "time": 48424.67948794365, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1536832, "time": 48428.11130619049, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1537128, "time": 48437.07133245468, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1537136, "time": 48437.546075344086, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1537176, "time": 48438.54561376572, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1537240, "time": 48440.516068935394, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1537296, "time": 48442.452139139175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1537480, "time": 48447.87912631035, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1537568, "time": 48450.82209777832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1537584, "time": 48451.316761016846, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1537648, "time": 48453.268862485886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1537656, "time": 48453.296288728714, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1537992, "time": 48463.62868332863, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1538016, "time": 48464.66664528847, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1538080, "time": 48466.65166902542, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1538152, "time": 48468.63980555534, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1538392, "time": 48476.01717233658, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1538768, "time": 48487.764229774475, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1538808, "time": 48488.768738269806, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1538912, "time": 48492.192076683044, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1538984, "time": 48494.3078660965, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1539032, "time": 48495.80184292793, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1539136, "time": 48499.20004439354, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1539160, "time": 48499.76299786568, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1539344, "time": 48505.633454322815, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1539728, "time": 48517.54519557953, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1539792, "time": 48519.55425572395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1539792, "time": 48519.56217265129, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1539960, "time": 48524.69211101532, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1540032, "time": 48527.90884256363, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 1540032, "time": 48527.91780543327, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 1540032, "time": 48528.73117733002, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1540032, "time": 48528.86775755882, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1540032, "time": 48529.19821310043, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1540032, "time": 48530.09944105148, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1540032, "time": 48530.38421869278, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 1540032, "time": 48530.582168102264, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1540032, "time": 48530.589854717255, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1540368, "time": 48541.59001541138, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1540496, "time": 48545.56349444389, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1540688, "time": 48551.4765894413, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1540752, "time": 48553.460878133774, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1540840, "time": 48556.07838463783, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1540856, "time": 48556.57924222946, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1541120, "time": 48564.971360206604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1541136, "time": 48565.46938061714, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1541200, "time": 48567.44335913658, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1541552, "time": 48578.32229876518, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1541776, "time": 48585.35936141014, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1541824, "time": 48586.8712117672, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1541896, "time": 48588.907423734665, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1541992, "time": 48591.88259983063, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1542088, "time": 48594.87982726097, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1542272, "time": 48600.830889463425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1542496, "time": 48607.73476481438, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1542600, "time": 48610.754834890366, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1542680, "time": 48613.24471974373, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 1542840, "time": 48618.2694978714, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1542952, "time": 48621.7085878849, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1542992, "time": 48623.18412590027, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1543064, "time": 48625.16840338707, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1543072, "time": 48625.63939785957, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 1543112, "time": 48626.63665676117, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1543672, "time": 48644.06273770332, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 1543696, "time": 48645.02418279648, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1543816, "time": 48648.49099397659, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1543856, "time": 48649.94634890556, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1543864, "time": 48649.975281476974, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1544040, "time": 48655.39782619476, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1544064, "time": 48656.360481500626, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1544160, "time": 48659.32430553436, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1544224, "time": 48661.30681824684, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1544408, "time": 48666.81380224228, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1544672, "time": 48675.269619226456, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1544744, "time": 48677.271330833435, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1544752, "time": 48677.77056336403, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1544800, "time": 48679.26208567619, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1545264, "time": 48693.50388073921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1545472, "time": 48699.850021362305, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1545592, "time": 48703.29851102829, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1545632, "time": 48704.861169338226, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1545680, "time": 48706.33263349533, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1545856, "time": 48711.714274168015, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 1545912, "time": 48713.22133398056, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1546112, "time": 48719.54559326172, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1546144, "time": 48720.52127838135, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1546352, "time": 48726.91535663605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1546440, "time": 48729.36763596535, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1546664, "time": 48736.337299108505, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1546808, "time": 48740.77286911011, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1546984, "time": 48746.17159366608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1547056, "time": 48748.61470413208, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1547096, "time": 48749.619109392166, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1547288, "time": 48755.48895907402, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1547304, "time": 48755.98049116135, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1547504, "time": 48762.33226656914, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1547712, "time": 48768.86021780968, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1547784, "time": 48770.88780498505, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1547824, "time": 48772.38815498352, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1548168, "time": 48782.76650214195, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1548480, "time": 48793.092294216156, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1548504, "time": 48793.68463945389, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1548552, "time": 48795.21409225464, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1549072, "time": 48811.460097789764, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1549096, "time": 48811.9776968956, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1549368, "time": 48820.31892967224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1549408, "time": 48821.79012656212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1549616, "time": 48828.29340839386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1549816, "time": 48834.20166397095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1549936, "time": 48838.15824961662, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1550016, "time": 48841.01623558998, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 1550016, "time": 48841.81881260872, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1550016, "time": 48842.34725213051, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1550016, "time": 48843.728828668594, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 1550016, "time": 48844.28546023369, "eval_episode/length": 177.0, "eval_episode/score": 0.4468750059604645, "eval_episode/reward_rate": 0.0056179775280898875}
{"step": 1550016, "time": 48844.338542699814, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1550016, "time": 48845.00077557564, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 1550016, "time": 48845.47232460976, "eval_episode/length": 174.0, "eval_episode/score": 0.45625001192092896, "eval_episode/reward_rate": 0.005714285714285714}
{"step": 1550240, "time": 48852.37316966057, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1550744, "time": 48867.752135276794, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1550792, "time": 48869.21823954582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1550864, "time": 48871.65728998184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1551040, "time": 48877.15227723122, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1551048, "time": 48877.179857730865, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1551408, "time": 48888.56531262398, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1551656, "time": 48895.9588227272, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1551680, "time": 48896.92164993286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1551712, "time": 48897.90692305565, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1551720, "time": 48897.93685746193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1552080, "time": 48909.17716550827, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1552328, "time": 48916.69209384918, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1552400, "time": 48919.10429811478, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1552848, "time": 48932.80636763573, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1552920, "time": 48934.80113697052, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1553056, "time": 48939.17266917229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1553056, "time": 48939.17950963974, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1553176, "time": 48942.629944086075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1553344, "time": 48948.13122391701, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1553360, "time": 48948.62522768974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1553424, "time": 48950.60419034958, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1553672, "time": 48958.00249385834, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1553720, "time": 48959.49351024628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1553768, "time": 48960.96324467659, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1553856, "time": 48963.892522096634, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1553880, "time": 48964.43700957298, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1554024, "time": 48968.85612201691, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1554568, "time": 48985.630368709564, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1554800, "time": 48992.94372558594, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1554824, "time": 48993.46511173248, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1554840, "time": 48993.981288433075, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1554976, "time": 48998.364334106445, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1555072, "time": 49001.319836854935, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1555248, "time": 49006.83372068405, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1555368, "time": 49010.28883600235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1555400, "time": 49011.27585911751, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1555456, "time": 49013.217499017715, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1555592, "time": 49017.15798330307, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1555672, "time": 49019.605113983154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1555864, "time": 49025.46262526512, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1556304, "time": 49039.23638391495, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1556384, "time": 49041.6698114872, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1556440, "time": 49043.16990303993, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1556456, "time": 49043.66128993034, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1557024, "time": 49061.705046892166, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1557072, "time": 49063.191438913345, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1557488, "time": 49076.00722384453, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1557536, "time": 49077.472536325455, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1557720, "time": 49082.88499689102, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1557768, "time": 49084.35655736923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1557904, "time": 49088.75234270096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1558040, "time": 49092.70877170563, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1558112, "time": 49095.257707595825, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1558176, "time": 49097.21892738342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1558304, "time": 49101.12403225899, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1558328, "time": 49101.63961029053, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1558632, "time": 49110.981001615524, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1558640, "time": 49111.454850673676, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1558696, "time": 49112.97496366501, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1558936, "time": 49120.31187939644, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1559288, "time": 49131.21053504944, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1559400, "time": 49134.644015073776, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1559480, "time": 49137.104576826096, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1559648, "time": 49142.47105026245, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1559672, "time": 49142.99050331116, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1559832, "time": 49147.897092580795, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1560000, "time": 49154.686564683914, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1560000, "time": 49154.921651124954, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1560000, "time": 49155.265045404434, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1560000, "time": 49155.48307824135, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1560000, "time": 49155.81981754303, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1560000, "time": 49155.92953419685, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 1560000, "time": 49156.176933288574, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1560000, "time": 49156.22487902641, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 1560128, "time": 49160.13921022415, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1560176, "time": 49161.60465860367, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1560488, "time": 49170.913527965546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1560784, "time": 49180.192172288895, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1560872, "time": 49182.67531991005, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1560952, "time": 49185.27941942215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1561048, "time": 49188.21005439758, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1561160, "time": 49191.63182806969, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1561248, "time": 49194.55359387398, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1561280, "time": 49195.5286128521, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1561464, "time": 49200.939863204956, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1561608, "time": 49205.372044086456, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1561936, "time": 49215.795766592026, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1561944, "time": 49215.8256790638, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1561968, "time": 49216.789175748825, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1562072, "time": 49219.76436495781, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1562144, "time": 49222.18006205559, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1562312, "time": 49227.12093257904, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1562320, "time": 49227.59338641167, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1562592, "time": 49235.97801613808, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1562632, "time": 49236.99668073654, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1562792, "time": 49241.90400958061, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1562864, "time": 49244.52552485466, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1562960, "time": 49247.50593996048, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1563232, "time": 49255.82979488373, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1563360, "time": 49259.80858540535, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1563576, "time": 49266.23478150368, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1563592, "time": 49266.72553253174, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1563744, "time": 49271.60612678528, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1563760, "time": 49272.09804534912, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1563832, "time": 49274.2263982296, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1564200, "time": 49285.60967159271, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1564280, "time": 49288.08253502846, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 1564384, "time": 49291.49274969101, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1564456, "time": 49293.49132966995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1564633, "time": 49299.96064925194, "train_stats/mean_log_entropy": 0.08210699776292363, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.206832275390625, "train/action_min": 0.0, "train/action_std": 1.8388824743032455, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010200128182768822, "train/actor_opt_grad_steps": 96695.0, "train/actor_opt_loss": -27.41524024963379, "train/adv_mag": 0.752288735806942, "train/adv_max": 0.33072036266326904, "train/adv_mean": 0.0020625468559319414, "train/adv_min": -0.6555996134877204, "train/adv_std": 0.030024260859936477, "train/cont_avg": 0.9928564453125, "train/cont_loss_mean": 0.030900836200453342, "train/cont_loss_std": 0.3099376420676708, "train/cont_neg_acc": 0.07844964947551489, "train/cont_neg_loss": 3.448199574947357, "train/cont_pos_acc": 0.999901551604271, "train/cont_pos_loss": 0.006409414483932778, "train/cont_pred": 0.9930566132068634, "train/cont_rate": 0.9928564453125, "train/dyn_loss_mean": 1.0000046533346176, "train/dyn_loss_std": 0.00012821639771573245, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12288055552635342, "train/extr_critic_critic_opt_grad_steps": 96695.0, "train/extr_critic_critic_opt_loss": 10798.785173339844, "train/extr_critic_mag": 1.8225641214847565, "train/extr_critic_max": 1.8225641214847565, "train/extr_critic_mean": 1.6804960668087006, "train/extr_critic_min": 1.3755552595853806, "train/extr_critic_std": 0.03258977330289781, "train/extr_return_normed_mag": 0.7492227578163146, "train/extr_return_normed_max": 0.3349414306879044, "train/extr_return_normed_mean": 0.07113552207127213, "train/extr_return_normed_min": -0.5943831092119217, "train/extr_return_normed_std": 0.04470784854143858, "train/extr_return_rate": 0.9997825717926025, "train/extr_return_raw_mag": 1.9463644063472747, "train/extr_return_raw_max": 1.9463644063472747, "train/extr_return_raw_mean": 1.6825585913658143, "train/extr_return_raw_min": 1.0170398664474487, "train/extr_return_raw_std": 0.04470784852281213, "train/extr_reward_mag": 0.28648203909397124, "train/extr_reward_max": 0.28648203909397124, "train/extr_reward_mean": 0.0029488722153473645, "train/extr_reward_min": 2.9027462005615235e-07, "train/extr_reward_std": 0.009633433276321738, "train/image_loss_mean": 0.0905359655804932, "train/image_loss_std": 0.10552344433963298, "train/model_loss_mean": 0.7486534881591796, "train/model_loss_std": 0.61391388759017, "train/model_opt_grad_norm": 13.162976632118225, "train/model_opt_grad_steps": 96606.895, "train/model_opt_loss": 4511.471942138672, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6050.0, "train/policy_entropy_mag": 1.223883728981018, "train/policy_entropy_max": 1.223883728981018, "train/policy_entropy_mean": 0.08556857768446208, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09808049336075783, "train/policy_logprob_mag": 6.551080253124237, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08569056950509549, "train/policy_logprob_min": -6.551080253124237, "train/policy_logprob_std": 0.6238807463645935, "train/policy_randomness_mag": 0.6289518544077873, "train/policy_randomness_max": 0.6289518544077873, "train/policy_randomness_mean": 0.04397355455905199, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.050403405837714674, "train/post_ent_mag": 74.40375640869141, "train/post_ent_max": 74.40375640869141, "train/post_ent_mean": 59.2676145362854, "train/post_ent_min": 41.570272026062014, "train/post_ent_std": 7.227728998661041, "train/prior_ent_mag": 73.98358707427978, "train/prior_ent_max": 73.98358707427978, "train/prior_ent_mean": 59.64810956954956, "train/prior_ent_min": 42.57680395126343, "train/prior_ent_std": 7.226396610736847, "train/rep_loss_mean": 1.0000046533346176, "train/rep_loss_std": 0.00012821639771573245, "train/reward_avg": 0.003888137821631972, "train/reward_loss_mean": 0.027213872913271188, "train/reward_loss_std": 0.3061532401666045, "train/reward_max_data": 0.8395312491059304, "train/reward_max_pred": 0.28829472184181215, "train/reward_neg_acc": 0.9993614959716797, "train/reward_neg_loss": 0.004842962109250948, "train/reward_pos_acc": 0.11968073781579733, "train/reward_pos_loss": 4.016761307120323, "train/reward_pred": 0.0028682214731816204, "train/reward_rate": 0.005556640625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.030981160700321198, "report/cont_loss_std": 0.3179655969142914, "report/cont_neg_acc": 0.125, "report/cont_neg_loss": 3.2838025093078613, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005368391517549753, "report/cont_pred": 0.9935944080352783, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09739059209823608, "report/image_loss_std": 0.10983583331108093, "report/model_loss_mean": 0.757888913154602, "report/model_loss_std": 0.6560785174369812, "report/post_ent_mag": 74.63082885742188, "report/post_ent_max": 74.63082885742188, "report/post_ent_mean": 58.98869705200195, "report/post_ent_min": 42.96723175048828, "report/post_ent_std": 7.5202226638793945, "report/prior_ent_mag": 71.85348510742188, "report/prior_ent_max": 71.85348510742188, "report/prior_ent_mean": 57.783084869384766, "report/prior_ent_min": 42.65533447265625, "report/prior_ent_std": 7.033773422241211, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0045074461959302425, "report/reward_loss_mean": 0.02951715886592865, "report/reward_loss_std": 0.3308086097240448, "report/reward_max_data": 0.7875000238418579, "report/reward_max_pred": 0.625035285949707, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0036921752616763115, "report/reward_pos_acc": 0.1428571492433548, "report/reward_pos_loss": 3.7815182209014893, "report/reward_pred": 0.0026523484848439693, "report/reward_rate": 0.0068359375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.02175876684486866, "eval/cont_loss_std": 0.26129961013793945, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.9173312187194824, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0064820111729204655, "eval/cont_pred": 0.993520975112915, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.07934856414794922, "eval/image_loss_std": 0.09315058588981628, "eval/model_loss_mean": 0.7171597480773926, "eval/model_loss_std": 0.4553936719894409, "eval/post_ent_mag": 75.34900665283203, "eval/post_ent_max": 75.34900665283203, "eval/post_ent_mean": 60.308502197265625, "eval/post_ent_min": 44.616294860839844, "eval/post_ent_std": 6.626382350921631, "eval/prior_ent_mag": 71.88904571533203, "eval/prior_ent_max": 71.88904571533203, "eval/prior_ent_mean": 59.104522705078125, "eval/prior_ent_min": 45.561805725097656, "eval/prior_ent_std": 6.078096389770508, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0021820068359375, "eval/reward_loss_mean": 0.01605238951742649, "eval/reward_loss_std": 0.21425658464431763, "eval/reward_max_data": 0.800000011920929, "eval/reward_max_pred": 0.09605693817138672, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.004471175372600555, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 3.9575252532958984, "eval/reward_pred": 0.0024157646112143993, "eval/reward_rate": 0.0029296875, "replay/size": 1000000.0, "replay/inserts": 31952.0, "replay/samples": 31952.0, "replay/insert_wait_avg": 1.3630645061410781e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.680083828325802e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4152.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.27076183899749e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1175870895385742e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0019776821136, "timer/env.step_count": 3994.0, "timer/env.step_total": 40.58304953575134, "timer/env.step_frac": 0.04058296927553889, "timer/env.step_avg": 0.010161003889772494, "timer/env.step_min": 0.008130311965942383, "timer/env.step_max": 0.03615546226501465, "timer/replay._sample_count": 31952.0, "timer/replay._sample_total": 17.96210479736328, "timer/replay._sample_frac": 0.017962069274100153, "timer/replay._sample_avg": 0.0005621590134377592, "timer/replay._sample_min": 0.00042057037353515625, "timer/replay._sample_max": 0.011722564697265625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4513.0, "timer/agent.policy_total": 50.453821659088135, "timer/agent.policy_frac": 0.05045372187766481, "timer/agent.policy_avg": 0.011179663562838053, "timer/agent.policy_min": 0.008426904678344727, "timer/agent.policy_max": 0.0821220874786377, "timer/dataset_train_count": 1997.0, "timer/dataset_train_total": 0.2501034736633301, "timer/dataset_train_frac": 0.00025010297903914184, "timer/dataset_train_avg": 0.00012523959622600403, "timer/dataset_train_min": 0.00010943412780761719, "timer/dataset_train_max": 0.0003707408905029297, "timer/agent.train_count": 1997.0, "timer/agent.train_total": 896.1042790412903, "timer/agent.train_frac": 0.8961025068353905, "timer/agent.train_avg": 0.4487252273616877, "timer/agent.train_min": 0.4373643398284912, "timer/agent.train_max": 0.709963321685791, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48169898986816406, "timer/agent.report_frac": 0.00048169803722257167, "timer/agent.report_avg": 0.24084949493408203, "timer/agent.report_min": 0.23375463485717773, "timer/agent.report_max": 0.24794435501098633, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.21864445241553e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 31.951218783047523}
{"step": 1564672, "time": 49301.32532119751, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1564744, "time": 49303.71048474312, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1564832, "time": 49306.69800448418, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1564928, "time": 49309.655524492264, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1565176, "time": 49317.01188778877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1565304, "time": 49320.94961833954, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1565416, "time": 49324.38395023346, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1565432, "time": 49324.882013082504, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1565616, "time": 49330.73454809189, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1565672, "time": 49332.22931408882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1565776, "time": 49335.78086709976, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1565888, "time": 49339.22704195976, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1565904, "time": 49339.71971964836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1566032, "time": 49343.61537575722, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1566080, "time": 49345.07667970657, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1566096, "time": 49345.56750583649, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1566296, "time": 49351.46697092056, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1566408, "time": 49354.896141052246, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1566424, "time": 49355.385090112686, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1566552, "time": 49359.295377254486, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1566672, "time": 49363.18115758896, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1566688, "time": 49363.70518541336, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1566952, "time": 49371.63776135445, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1566976, "time": 49372.58953690529, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1567000, "time": 49373.12121629715, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1567296, "time": 49382.36627244949, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1567408, "time": 49385.828800439835, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1567520, "time": 49389.28885269165, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1567528, "time": 49389.31703853607, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1567848, "time": 49399.23016500473, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1567864, "time": 49399.72635436058, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1568144, "time": 49408.54451203346, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1568216, "time": 49410.55417633057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1568304, "time": 49413.490275382996, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1568744, "time": 49426.83313918114, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1568896, "time": 49431.74077248573, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1568904, "time": 49431.76847362518, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1569032, "time": 49435.70375943184, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1569080, "time": 49437.198071718216, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1569264, "time": 49443.06923723221, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1569288, "time": 49443.58958053589, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1569392, "time": 49446.99118852615, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1569576, "time": 49452.410054683685, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1569592, "time": 49452.902081012726, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1569664, "time": 49455.4840965271, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1569680, "time": 49455.978909254074, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1569864, "time": 49461.386143922806, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1569960, "time": 49464.328830480576, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1570088, "time": 49469.31428837776, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 1570088, "time": 49469.32100343704, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 1570088, "time": 49469.51304268837, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1570088, "time": 49469.56055498123, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 1570088, "time": 49470.29153585434, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 1570088, "time": 49470.527237176895, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1570088, "time": 49470.72719955444, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1570088, "time": 49470.92224216461, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 1570288, "time": 49477.318006277084, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1570456, "time": 49482.241555690765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1571016, "time": 49499.47321343422, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1571032, "time": 49499.965562820435, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1571192, "time": 49504.86942577362, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1571208, "time": 49505.370611190796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1571392, "time": 49511.24122262001, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1571392, "time": 49511.25311374664, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1571880, "time": 49526.12121415138, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1571888, "time": 49526.60101270676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1571904, "time": 49527.101991176605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1571968, "time": 49529.08556866646, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1572024, "time": 49530.579721450806, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1572184, "time": 49535.531447649, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1572256, "time": 49537.96857595444, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1572336, "time": 49540.42802858353, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1572424, "time": 49542.88758111, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1572448, "time": 49544.006808042526, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1572624, "time": 49549.395668029785, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1572816, "time": 49555.24371981621, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1572832, "time": 49555.73470687866, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1572888, "time": 49557.75588321686, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1572952, "time": 49559.757430553436, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1572984, "time": 49560.7555103302, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1572984, "time": 49560.76298928261, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1573024, "time": 49562.21996688843, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1573032, "time": 49562.24819111824, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1573120, "time": 49565.175419569016, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1573344, "time": 49572.01596355438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1573352, "time": 49572.04378771782, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1573368, "time": 49572.53351902962, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1573544, "time": 49578.07658147812, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1573568, "time": 49579.06268286705, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1573640, "time": 49581.03830242157, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1573656, "time": 49581.531145095825, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1573744, "time": 49584.457563877106, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1573992, "time": 49591.834552288055, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1574000, "time": 49592.3062582016, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1574168, "time": 49597.24614691734, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1574184, "time": 49597.751744270325, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1574336, "time": 49602.64595866203, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1574440, "time": 49605.71806335449, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1574616, "time": 49611.15782952309, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1574816, "time": 49617.6188018322, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1575048, "time": 49624.506622076035, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1575104, "time": 49626.43379712105, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1575192, "time": 49628.91533660889, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1575296, "time": 49632.301916599274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1575304, "time": 49632.331122636795, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1575624, "time": 49642.27553129196, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1576176, "time": 49659.45465230942, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1576472, "time": 49668.58749103546, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1576480, "time": 49669.059846401215, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 1576616, "time": 49673.01588010788, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 1576648, "time": 49673.99167108536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1576720, "time": 49676.41059875488, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1577000, "time": 49684.76894116402, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1577360, "time": 49696.143062114716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1577400, "time": 49697.17086148262, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 1577408, "time": 49697.64454340935, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1577800, "time": 49709.40886092186, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1577936, "time": 49713.79817152023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1578224, "time": 49722.68240690231, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1578336, "time": 49726.22361135483, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1578344, "time": 49726.251623630524, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1578488, "time": 49730.66080713272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1578600, "time": 49734.14658999443, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1578904, "time": 49743.468782663345, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1578928, "time": 49744.43248295784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1579096, "time": 49749.35506749153, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1579224, "time": 49753.29462528229, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1579336, "time": 49756.86467933655, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1579440, "time": 49760.266219615936, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1579440, "time": 49760.2757062912, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1579488, "time": 49761.76114296913, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1579672, "time": 49767.184664964676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1579896, "time": 49774.04850244522, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1580024, "time": 49777.97814631462, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1580072, "time": 49779.449261665344, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1580072, "time": 49779.45932197571, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1580072, "time": 49780.798604011536, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 1580072, "time": 49781.294196367264, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1580072, "time": 49781.40707397461, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1580072, "time": 49781.59186863899, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1580072, "time": 49782.43063831329, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 1580072, "time": 49782.65377664566, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1580072, "time": 49782.69642329216, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 1580072, "time": 49783.233805179596, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1580248, "time": 49788.72303414345, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1580584, "time": 49798.978511571884, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1580584, "time": 49798.987498521805, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1580600, "time": 49799.5014667511, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1580688, "time": 49802.4458425045, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1580720, "time": 49803.448677539825, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1580960, "time": 49810.84034490585, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1581128, "time": 49816.35236907005, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1581248, "time": 49820.25299811363, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1581368, "time": 49823.68769645691, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1581512, "time": 49828.1085164547, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1581536, "time": 49829.06455874443, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1581552, "time": 49829.57904744148, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1581696, "time": 49833.962419748306, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1581696, "time": 49833.96857357025, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1581840, "time": 49838.442798137665, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1582072, "time": 49845.472254276276, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1582192, "time": 49849.37268829346, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1582448, "time": 49857.21935415268, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1582480, "time": 49858.19862794876, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1582824, "time": 49868.56403374672, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1582832, "time": 49869.05525255203, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1583000, "time": 49874.10485172272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1583024, "time": 49875.06896686554, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1583040, "time": 49875.56991147995, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1583080, "time": 49876.58036828041, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1583120, "time": 49878.050515413284, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1583440, "time": 49887.88945531845, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1583496, "time": 49889.42320942879, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 1583584, "time": 49892.33011984825, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1583640, "time": 49893.8435254097, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1583648, "time": 49894.31237959862, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1583696, "time": 49895.77335071564, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1583920, "time": 49902.62078022957, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1584176, "time": 49910.622938632965, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1584248, "time": 49912.59977936745, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1584272, "time": 49913.57515978813, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1584288, "time": 49914.06484699249, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1584288, "time": 49914.07445144653, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1584528, "time": 49921.40836143494, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1584736, "time": 49927.747655153275, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1584896, "time": 49932.67713212967, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1585008, "time": 49936.238423109055, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1585096, "time": 49938.72135806084, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1585328, "time": 49946.07387161255, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1585496, "time": 49951.04611492157, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1585688, "time": 49956.98737311363, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1585800, "time": 49960.463825941086, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1585904, "time": 49964.040786743164, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1586232, "time": 49973.92222189903, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1586280, "time": 49975.392357349396, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1586424, "time": 49979.81546473503, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1586504, "time": 49982.27367711067, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 1586560, "time": 49984.24975609779, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1586840, "time": 49992.664072752, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 1586904, "time": 49994.74197411537, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1587000, "time": 49997.71207237244, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1587120, "time": 50001.6186208725, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1587256, "time": 50005.5949447155, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1587336, "time": 50008.06538796425, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1587408, "time": 50010.50705432892, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1587440, "time": 50011.50337076187, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1587592, "time": 50015.973452568054, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1587784, "time": 50021.91082048416, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1587848, "time": 50024.02922081947, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1588064, "time": 50030.897943258286, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1588072, "time": 50030.92770719528, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1588256, "time": 50036.84453678131, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1588448, "time": 50042.77312207222, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1588592, "time": 50047.22846078873, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1588592, "time": 50047.23654985428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1588616, "time": 50047.7600338459, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1589088, "time": 50062.587883234024, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1589104, "time": 50063.08452248573, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1589288, "time": 50069.04097819328, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1589464, "time": 50074.452164411545, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1589504, "time": 50075.91335773468, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1589568, "time": 50077.90757274628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1589656, "time": 50080.38324403763, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1590048, "time": 50092.841052532196, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1590056, "time": 50093.91732788086, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 1590056, "time": 50094.092341423035, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1590056, "time": 50094.66735005379, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1590056, "time": 50095.392067193985, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1590056, "time": 50095.62738633156, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 1590056, "time": 50095.92000079155, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 1590056, "time": 50096.26063680649, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 1590056, "time": 50096.539969205856, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1590056, "time": 50096.54836988449, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1590104, "time": 50098.03021359444, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1590144, "time": 50099.482927799225, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1590376, "time": 50106.44853782654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1590744, "time": 50117.90733170509, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1590776, "time": 50118.89012789726, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1590920, "time": 50123.32099914551, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1590928, "time": 50123.79499721527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1591216, "time": 50132.68077850342, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1591328, "time": 50136.147189855576, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1591344, "time": 50136.64533162117, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1591400, "time": 50138.157683610916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1591432, "time": 50139.14402294159, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1591552, "time": 50143.087243795395, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1591888, "time": 50153.58457875252, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1592088, "time": 50159.52510023117, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1592120, "time": 50160.530490636826, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1592184, "time": 50162.48611831665, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1592456, "time": 50170.88687372208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1592456, "time": 50170.8957529068, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1592464, "time": 50171.37123346329, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1592624, "time": 50176.415784835815, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1592672, "time": 50177.8972094059, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1592672, "time": 50177.90559339523, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1592688, "time": 50178.401406764984, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1592712, "time": 50178.91807723045, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1592936, "time": 50185.80098795891, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1593224, "time": 50194.646290540695, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1593376, "time": 50199.58336400986, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1593392, "time": 50200.10644221306, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1593408, "time": 50200.604930877686, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1593456, "time": 50202.07816886902, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1593656, "time": 50208.16413021088, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1593696, "time": 50209.62191438675, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1593784, "time": 50212.165798425674, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1593904, "time": 50216.130539894104, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1593920, "time": 50216.63403749466, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1594184, "time": 50224.59038424492, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1594224, "time": 50226.06473278999, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1594336, "time": 50229.49542045593, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1594688, "time": 50240.45074677467, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1594760, "time": 50242.441479206085, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1594768, "time": 50242.918179512024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1595264, "time": 50258.19104027748, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1595288, "time": 50258.71414065361, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1595352, "time": 50260.71954393387, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1595600, "time": 50268.68938446045, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 1595720, "time": 50272.15405488014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1596016, "time": 50281.52781510353, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1596056, "time": 50282.53686475754, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1596136, "time": 50285.003019571304, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1596320, "time": 50290.864307403564, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1596601, "time": 50300.52552342415, "train_stats/mean_log_entropy": 0.08011888334362204, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2308819580078123, "train/action_min": 0.0, "train/action_std": 1.828323814868927, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009119643229059875, "train/actor_opt_grad_steps": 98695.0, "train/actor_opt_loss": -28.88944736480713, "train/adv_mag": 0.6964009752869607, "train/adv_max": 0.300385183095932, "train/adv_mean": 0.0003854115908711719, "train/adv_min": -0.6249896058440209, "train/adv_std": 0.030236003706231713, "train/cont_avg": 0.99296875, "train/cont_loss_mean": 0.029767334195785224, "train/cont_loss_std": 0.29732970349490645, "train/cont_neg_acc": 0.09011784233152867, "train/cont_neg_loss": 3.303330859541893, "train/cont_pos_acc": 0.9998230564594269, "train/cont_pos_loss": 0.006610544768627733, "train/cont_pred": 0.9928216311335564, "train/cont_rate": 0.99296875, "train/dyn_loss_mean": 1.000002521276474, "train/dyn_loss_std": 6.739534441294382e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11661982654593885, "train/extr_critic_critic_opt_grad_steps": 98695.0, "train/extr_critic_critic_opt_loss": 11262.174838867188, "train/extr_critic_mag": 1.8432801342010499, "train/extr_critic_max": 1.8432801342010499, "train/extr_critic_mean": 1.687677910923958, "train/extr_critic_min": 1.4118444430828094, "train/extr_critic_std": 0.03091260022483766, "train/extr_return_normed_mag": 0.719748685657978, "train/extr_return_normed_max": 0.3328516012430191, "train/extr_return_normed_mean": 0.06564214617013932, "train/extr_return_normed_min": -0.5704887422919274, "train/extr_return_normed_std": 0.04391784526407719, "train/extr_return_rate": 0.9998056811094284, "train/extr_return_raw_mag": 1.9552728271484374, "train/extr_return_raw_max": 1.9552728271484374, "train/extr_return_raw_mean": 1.6880634546279907, "train/extr_return_raw_min": 1.0519324836134911, "train/extr_return_raw_std": 0.043917845217511055, "train/extr_reward_mag": 0.2911416047811508, "train/extr_reward_max": 0.2911416047811508, "train/extr_reward_mean": 0.003150851189275272, "train/extr_reward_min": 2.5391578674316405e-07, "train/extr_reward_std": 0.010281860590912401, "train/image_loss_mean": 0.085063799880445, "train/image_loss_std": 0.10260443463921547, "train/model_loss_mean": 0.7424205058813095, "train/model_loss_std": 0.6074653193354607, "train/model_opt_grad_norm": 13.50098215341568, "train/model_opt_grad_steps": 98605.045, "train/model_opt_loss": 3952.1283630371095, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5350.0, "train/policy_entropy_mag": 1.2221089377999306, "train/policy_entropy_max": 1.2221089377999306, "train/policy_entropy_mean": 0.08706786107271909, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10184999853372574, "train/policy_logprob_mag": 6.551080257892608, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08744397144764662, "train/policy_logprob_min": -6.551080257892608, "train/policy_logprob_std": 0.6264593178033828, "train/policy_randomness_mag": 0.6280397945642471, "train/policy_randomness_max": 0.6280397945642471, "train/policy_randomness_mean": 0.04474403312429786, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05234054822474718, "train/post_ent_mag": 74.43750881195068, "train/post_ent_max": 74.43750881195068, "train/post_ent_mean": 59.47601633071899, "train/post_ent_min": 42.62221101760864, "train/post_ent_std": 6.846556041240692, "train/prior_ent_mag": 73.79199089050293, "train/prior_ent_max": 73.79199089050293, "train/prior_ent_mean": 59.79727239608765, "train/prior_ent_min": 43.42187450408935, "train/prior_ent_std": 6.864546334743499, "train/rep_loss_mean": 1.000002521276474, "train/rep_loss_std": 6.739534441294382e-05, "train/reward_avg": 0.003968658449302893, "train/reward_loss_mean": 0.027587835183367132, "train/reward_loss_std": 0.30669049236923457, "train/reward_max_data": 0.8394374993443489, "train/reward_max_pred": 0.33849352300167085, "train/reward_neg_acc": 0.9993175294995308, "train/reward_neg_loss": 0.005221072161803022, "train/reward_pos_acc": 0.122995132394135, "train/reward_pos_loss": 3.9649350130558014, "train/reward_pred": 0.0030717183562228457, "train/reward_rate": 0.00564453125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.02895205281674862, "report/cont_loss_std": 0.29266586899757385, "report/cont_neg_acc": 0.1428571492433548, "report/cont_neg_loss": 2.9498674869537354, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.008847424760460854, "report/cont_pred": 0.9902313947677612, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07726004719734192, "report/image_loss_std": 0.09680655598640442, "report/model_loss_mean": 0.7272564172744751, "report/model_loss_std": 0.4799675941467285, "report/post_ent_mag": 77.0956802368164, "report/post_ent_max": 77.0956802368164, "report/post_ent_mean": 59.70933532714844, "report/post_ent_min": 41.6212158203125, "report/post_ent_std": 7.750198841094971, "report/prior_ent_mag": 74.88433837890625, "report/prior_ent_max": 74.88433837890625, "report/prior_ent_mean": 58.98017883300781, "report/prior_ent_min": 41.97352981567383, "report/prior_ent_std": 7.825323581695557, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0032562254928052425, "report/reward_loss_mean": 0.021044351160526276, "report/reward_loss_std": 0.2202812135219574, "report/reward_max_data": 0.8031250238418579, "report/reward_max_pred": 0.4912300109863281, "report/reward_neg_acc": 0.9970559477806091, "report/reward_neg_loss": 0.007340435869991779, "report/reward_pos_acc": 0.4000000059604645, "report/reward_pos_loss": 2.8139026165008545, "report/reward_pred": 0.004652944393455982, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.01826327107846737, "eval/cont_loss_std": 0.23079803586006165, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.160312652587891, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.006092703435570002, "eval/cont_pred": 0.9939607381820679, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10072295367717743, "eval/image_loss_std": 0.10309173166751862, "eval/model_loss_mean": 0.7385700941085815, "eval/model_loss_std": 0.530548095703125, "eval/post_ent_mag": 77.53807067871094, "eval/post_ent_max": 77.53807067871094, "eval/post_ent_mean": 60.4221076965332, "eval/post_ent_min": 41.165462493896484, "eval/post_ent_std": 7.74638557434082, "eval/prior_ent_mag": 74.90829467773438, "eval/prior_ent_max": 74.90829467773438, "eval/prior_ent_mean": 59.5556755065918, "eval/prior_ent_min": 40.8157844543457, "eval/prior_ent_std": 7.942683219909668, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0024047852493822575, "eval/reward_loss_mean": 0.01958386041224003, "eval/reward_loss_std": 0.2730327248573303, "eval/reward_max_data": 0.909375011920929, "eval/reward_max_pred": 0.05713629722595215, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.005122215952724218, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.941363334655762, "eval/reward_pred": 0.0028432602994143963, "eval/reward_rate": 0.0029296875, "replay/size": 1000000.0, "replay/inserts": 31968.0, "replay/samples": 31968.0, "replay/insert_wait_avg": 1.3600330095033388e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.77980064319538e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3616.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2348842831839502e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4333217144012, "timer/env.step_count": 3996.0, "timer/env.step_total": 40.88922357559204, "timer/env.step_frac": 0.04087151306148207, "timer/env.step_avg": 0.010232538432330341, "timer/env.step_min": 0.00804591178894043, "timer/env.step_max": 0.03665471076965332, "timer/replay._sample_count": 31968.0, "timer/replay._sample_total": 18.058344841003418, "timer/replay._sample_frac": 0.01805052315736303, "timer/replay._sample_avg": 0.0005648881644458026, "timer/replay._sample_min": 0.00040650367736816406, "timer/replay._sample_max": 0.02470684051513672, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4448.0, "timer/agent.policy_total": 50.18683314323425, "timer/agent.policy_frac": 0.050165095518041276, "timer/agent.policy_avg": 0.011283011048388995, "timer/agent.policy_min": 0.009097814559936523, "timer/agent.policy_max": 0.09348487854003906, "timer/dataset_train_count": 1998.0, "timer/dataset_train_total": 0.25562572479248047, "timer/dataset_train_frac": 0.00025551500459263513, "timer/dataset_train_avg": 0.00012794080319943968, "timer/dataset_train_min": 0.00010848045349121094, "timer/dataset_train_max": 0.0010781288146972656, "timer/agent.train_count": 1998.0, "timer/agent.train_total": 897.2200820446014, "timer/agent.train_frac": 0.8968314654964435, "timer/agent.train_avg": 0.4490591001224231, "timer/agent.train_min": 0.4355330467224121, "timer/agent.train_max": 0.698383092880249, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47997212409973145, "timer/agent.report_frac": 0.00047976423184028204, "timer/agent.report_avg": 0.23998606204986572, "timer/agent.report_min": 0.23335695266723633, "timer/agent.report_max": 0.24661517143249512, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.145762117106942e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 31.95346167256627}
{"step": 1596648, "time": 50301.765209674835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1597008, "time": 50313.144787073135, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1597032, "time": 50313.66627717018, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1597072, "time": 50315.14620923996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1597280, "time": 50321.55080270767, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1597432, "time": 50326.149951696396, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1597600, "time": 50332.07057452202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1597808, "time": 50338.47162938118, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1597920, "time": 50341.92478966713, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1598056, "time": 50345.91972875595, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1598632, "time": 50363.75667929649, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1598744, "time": 50367.212436676025, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1598808, "time": 50369.17779278755, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1599136, "time": 50379.46006155014, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1599344, "time": 50386.054480075836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1599384, "time": 50387.06853437424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1599792, "time": 50399.89511203766, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1599912, "time": 50403.37374329567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1600040, "time": 50408.463039159775, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1600040, "time": 50408.9831404686, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1600040, "time": 50409.376453876495, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1600040, "time": 50411.15637564659, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 1600040, "time": 50411.51687216759, "eval_episode/length": 193.0, "eval_episode/score": 0.3968749940395355, "eval_episode/reward_rate": 0.005154639175257732}
{"step": 1600040, "time": 50411.60826206207, "eval_episode/length": 197.0, "eval_episode/score": 0.3843750059604645, "eval_episode/reward_rate": 0.005050505050505051}
{"step": 1600040, "time": 50411.616819143295, "eval_episode/length": 197.0, "eval_episode/score": 0.3843750059604645, "eval_episode/reward_rate": 0.005050505050505051}
{"step": 1600040, "time": 50412.52118611336, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1600208, "time": 50418.054929971695, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1600232, "time": 50418.57564377785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1600368, "time": 50422.994128227234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1600368, "time": 50423.002177000046, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1600568, "time": 50428.92180490494, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1600792, "time": 50435.85374426842, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1600896, "time": 50439.280091524124, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1600928, "time": 50440.28228712082, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1601120, "time": 50446.272824287415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1601208, "time": 50448.73641324043, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1601304, "time": 50451.71736550331, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1601448, "time": 50456.14617943764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1601536, "time": 50459.08398985863, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1601616, "time": 50461.5915825367, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1601776, "time": 50466.571184396744, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1601944, "time": 50471.604377985, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1602024, "time": 50474.18788433075, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1602040, "time": 50474.71061420441, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1602208, "time": 50480.12410211563, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1602272, "time": 50482.11422276497, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1602552, "time": 50490.58877372742, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1602952, "time": 50502.97478246689, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1603104, "time": 50508.059843063354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1603120, "time": 50508.56276035309, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1603240, "time": 50512.11410188675, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1603240, "time": 50512.12376356125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1603536, "time": 50521.47574687004, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1603696, "time": 50526.428322315216, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1603696, "time": 50526.4453663826, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1603848, "time": 50530.90611410141, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1604040, "time": 50537.02174162865, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1604112, "time": 50539.475192546844, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1604280, "time": 50544.45506596565, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1604384, "time": 50547.8714029789, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1604584, "time": 50553.857120752335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1604744, "time": 50558.78411769867, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1604928, "time": 50564.83303070068, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1605072, "time": 50569.296835422516, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1605224, "time": 50573.75579047203, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1605240, "time": 50574.27649998665, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1605360, "time": 50578.20589542389, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1605552, "time": 50584.148117780685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1605680, "time": 50588.60750460625, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1605728, "time": 50590.11401391029, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1605920, "time": 50596.16073346138, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1605944, "time": 50596.6798017025, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1606152, "time": 50603.08005642891, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 1606480, "time": 50613.40316534042, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1606616, "time": 50617.41234970093, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1606656, "time": 50618.87483549118, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1606720, "time": 50620.8701236248, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1606864, "time": 50625.44279909134, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 1606960, "time": 50628.41780900955, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1607144, "time": 50633.880876779556, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1607152, "time": 50634.3776204586, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1607240, "time": 50636.85570526123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1607304, "time": 50638.81799221039, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1607384, "time": 50641.28901267052, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1607736, "time": 50652.05484580994, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1607904, "time": 50657.52829170227, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1607936, "time": 50658.51180076599, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1607992, "time": 50660.019829034805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1608264, "time": 50668.32365465164, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1608424, "time": 50673.227833509445, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1608464, "time": 50674.691595077515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1608520, "time": 50676.19572043419, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1608536, "time": 50676.69400835037, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1608768, "time": 50684.18775367737, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1608928, "time": 50689.105330228806, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1609008, "time": 50691.5556409359, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 1609168, "time": 50696.46675348282, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1609192, "time": 50696.98043704033, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1609208, "time": 50697.48244142532, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1609224, "time": 50697.9857339859, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1609264, "time": 50699.47552847862, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1609448, "time": 50704.99799346924, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1609832, "time": 50716.94368767738, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1609840, "time": 50717.41476726532, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1609864, "time": 50717.931262254715, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1609928, "time": 50719.90350317955, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1610024, "time": 50724.16031360626, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1610024, "time": 50724.20818781853, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1610024, "time": 50724.2164413929, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1610024, "time": 50724.50712990761, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1610024, "time": 50724.83736371994, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1610024, "time": 50725.331431388855, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1610024, "time": 50725.33932995796, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1610024, "time": 50725.56886076927, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 1610184, "time": 50730.486626148224, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1610464, "time": 50739.3215508461, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1610544, "time": 50741.78944301605, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1610592, "time": 50743.27285575867, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1610824, "time": 50750.25189900398, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1610992, "time": 50755.62364983559, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1611056, "time": 50757.575449466705, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1611240, "time": 50762.974759340286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1611312, "time": 50765.420154333115, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1611520, "time": 50771.88875627518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1611576, "time": 50773.3902015686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1611624, "time": 50775.01463198662, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1611904, "time": 50783.87053990364, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1611968, "time": 50785.85546660423, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1611968, "time": 50785.86458826065, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1612048, "time": 50788.34464406967, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1612136, "time": 50790.86803269386, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1612184, "time": 50792.353529930115, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1612520, "time": 50802.8085103035, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1612608, "time": 50805.87000846863, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1612624, "time": 50806.3657476902, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1612720, "time": 50809.30054521561, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1612776, "time": 50810.82752466202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1612872, "time": 50813.763565301895, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1613120, "time": 50821.579007864, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1613152, "time": 50822.557959795, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1613232, "time": 50825.03819799423, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1613320, "time": 50827.5153670311, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1613448, "time": 50831.469262599945, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1613536, "time": 50834.51410651207, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1613576, "time": 50835.53345370293, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1613632, "time": 50837.46190404892, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1613768, "time": 50841.40354037285, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1614024, "time": 50849.894481658936, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1614248, "time": 50856.76752924919, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1614256, "time": 50857.24456524849, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1614336, "time": 50859.70673942566, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1614448, "time": 50863.13845396042, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1614480, "time": 50864.24058294296, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1614704, "time": 50871.084121227264, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1614744, "time": 50872.09005022049, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1615024, "time": 50880.92652511597, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 1615072, "time": 50882.391523361206, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1615144, "time": 50884.38521981239, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1615312, "time": 50889.779394865036, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1615520, "time": 50896.254816532135, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1615624, "time": 50899.20755267143, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1615712, "time": 50902.124802827835, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1615784, "time": 50904.12031292915, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1615888, "time": 50907.57044816017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1615944, "time": 50909.06435251236, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1616216, "time": 50917.44580197334, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 1616240, "time": 50918.4028532505, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1616352, "time": 50921.83932685852, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1616424, "time": 50923.93195796013, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1616544, "time": 50927.84157037735, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1616560, "time": 50928.33431506157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1616576, "time": 50928.82893490791, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1616608, "time": 50929.839015483856, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1616752, "time": 50934.2454533577, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1616776, "time": 50934.76283478737, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1617152, "time": 50946.614659786224, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1617200, "time": 50948.09002280235, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1617240, "time": 50949.10890126228, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1617296, "time": 50951.04470515251, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1617464, "time": 50956.08767437935, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1617496, "time": 50957.07612633705, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1617832, "time": 50967.35169124603, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1617848, "time": 50967.84860563278, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1618048, "time": 50974.219313144684, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1618128, "time": 50976.66231536865, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1618472, "time": 50987.1316614151, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1618504, "time": 50988.11321926117, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1618768, "time": 50996.396204948425, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1618880, "time": 50999.84752321243, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1619064, "time": 51005.259069919586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1619176, "time": 51008.71934890747, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1619360, "time": 51014.73564171791, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1619448, "time": 51017.2288775444, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1619464, "time": 51017.725306510925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1619608, "time": 51022.13087797165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1619632, "time": 51023.111057043076, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1619640, "time": 51023.13988161087, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1619784, "time": 51027.54269504547, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1620008, "time": 51035.90575146675, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1620008, "time": 51036.34715151787, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1620008, "time": 51036.436838150024, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1620008, "time": 51036.56861162186, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1620008, "time": 51036.659927845, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1620008, "time": 51036.83243608475, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 1620008, "time": 51037.110934495926, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 1620008, "time": 51037.37267994881, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1620080, "time": 51039.794484853745, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1620096, "time": 51040.287148714066, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1620240, "time": 51044.78655338287, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1620296, "time": 51046.305274009705, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1620432, "time": 51050.69385385513, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1620448, "time": 51051.18941402435, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1620528, "time": 51053.635883808136, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1620632, "time": 51056.6194756031, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1620664, "time": 51057.60112762451, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1620792, "time": 51061.51994729042, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1620824, "time": 51062.49552321434, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1620848, "time": 51063.450316905975, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1620984, "time": 51067.37874794006, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1621184, "time": 51073.76541876793, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1621328, "time": 51078.28204751015, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1621520, "time": 51084.1460313797, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1621600, "time": 51086.61715912819, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1621632, "time": 51087.60259437561, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1621984, "time": 51098.401317834854, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1622224, "time": 51106.36289668083, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1622392, "time": 51111.283311128616, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1622528, "time": 51115.65762400627, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1622672, "time": 51120.080777168274, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1622760, "time": 51122.543241262436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1622872, "time": 51125.985431194305, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1623056, "time": 51131.85372543335, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1623104, "time": 51133.32163834572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1623136, "time": 51134.4084956646, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1623160, "time": 51134.94744896889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1623296, "time": 51139.3053381443, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1623360, "time": 51141.283031225204, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1623640, "time": 51149.65844106674, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1623664, "time": 51150.61648130417, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1623912, "time": 51158.01794099808, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1623928, "time": 51158.51344180107, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1624304, "time": 51170.383957862854, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1624360, "time": 51171.87272977829, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1624448, "time": 51174.81010556221, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1624520, "time": 51176.79183888435, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1624776, "time": 51184.6197078228, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1625040, "time": 51192.90647268295, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1625048, "time": 51192.93456840515, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1625184, "time": 51197.493516922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1625232, "time": 51198.986453294754, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1625312, "time": 51201.43145918846, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1625336, "time": 51201.949347019196, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1625576, "time": 51209.36449313164, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1625784, "time": 51215.78717780113, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1625888, "time": 51219.19077658653, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1625952, "time": 51221.14447236061, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1626064, "time": 51224.708340168, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1626096, "time": 51225.68885755539, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1626224, "time": 51229.64558792114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1626288, "time": 51231.59293317795, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1626600, "time": 51240.941247463226, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1626712, "time": 51244.37431263924, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1627000, "time": 51253.158319711685, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1627192, "time": 51259.099618673325, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1627488, "time": 51268.33886098862, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1627624, "time": 51272.29102396965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1627672, "time": 51273.78699302673, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1627856, "time": 51279.72245526314, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 1627912, "time": 51281.21705055237, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 1627928, "time": 51281.710530519485, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1627960, "time": 51282.71454024315, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1628096, "time": 51287.22995352745, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 1628400, "time": 51296.58167719841, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1628408, "time": 51296.60944414139, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1628464, "time": 51298.590351343155, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1628464, "time": 51298.59942650795, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1628505, "time": 51300.686974048615, "train_stats/mean_log_entropy": 0.08328741144329782, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.153031699022456, "train/action_min": 0.0, "train/action_std": 1.792442105523306, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00990917317653496, "train/actor_opt_grad_steps": 100690.0, "train/actor_opt_loss": -29.43590690382761, "train/adv_mag": 0.6992238071096603, "train/adv_max": 0.2890177959173768, "train/adv_mean": 0.0013957242161967628, "train/adv_min": -0.6328236008409279, "train/adv_std": 0.02948228140647088, "train/cont_avg": 0.9925997173366834, "train/cont_loss_mean": 0.03170982839998288, "train/cont_loss_std": 0.31525547645199836, "train/cont_neg_acc": 0.08411905098350803, "train/cont_neg_loss": 3.4272104759312154, "train/cont_pos_acc": 0.9998369270832694, "train/cont_pos_loss": 0.006604492116775645, "train/cont_pred": 0.9928207777852389, "train/cont_rate": 0.9925997173366834, "train/dyn_loss_mean": 1.0000021709269615, "train/dyn_loss_std": 6.626062177065478e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11108671840813816, "train/extr_critic_critic_opt_grad_steps": 100690.0, "train/extr_critic_critic_opt_loss": 12351.537482333542, "train/extr_critic_mag": 1.8573038290493453, "train/extr_critic_max": 1.8573038290493453, "train/extr_critic_mean": 1.718038508640462, "train/extr_critic_min": 1.4345421383728334, "train/extr_critic_std": 0.030948408593858907, "train/extr_return_normed_mag": 0.7099765682939309, "train/extr_return_normed_max": 0.30795370334356875, "train/extr_return_normed_mean": 0.06665962606893112, "train/extr_return_normed_min": -0.5763470976795982, "train/extr_return_normed_std": 0.04348000035101744, "train/extr_return_rate": 0.9998066691897023, "train/extr_return_raw_mag": 1.9607282032319648, "train/extr_return_raw_max": 1.9607282032319648, "train/extr_return_raw_mean": 1.7194342127996474, "train/extr_return_raw_min": 1.0764274022087978, "train/extr_return_raw_std": 0.04348000036037747, "train/extr_reward_mag": 0.2667637416465798, "train/extr_reward_max": 0.2667637416465798, "train/extr_reward_mean": 0.003128160931984309, "train/extr_reward_min": 3.28274827506674e-07, "train/extr_reward_std": 0.00965410400996331, "train/image_loss_mean": 0.08534443853937801, "train/image_loss_std": 0.10223561296960217, "train/model_loss_mean": 0.7457374232498246, "train/model_loss_std": 0.6292190017113134, "train/model_opt_grad_norm": 12.78181654244811, "train/model_opt_grad_steps": 100598.21608040201, "train/model_opt_loss": 4028.975058397456, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5402.010050251256, "train/policy_entropy_mag": 1.2109758554391525, "train/policy_entropy_max": 1.2109758554391525, "train/policy_entropy_mean": 0.08717573452834508, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10200944756293416, "train/policy_logprob_mag": 6.551080262840693, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08696794442495509, "train/policy_logprob_min": -6.551080262840693, "train/policy_logprob_std": 0.6240435554154554, "train/policy_randomness_mag": 0.622318520468084, "train/policy_randomness_max": 0.622318520468084, "train/policy_randomness_mean": 0.04479946956113355, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0524224892595605, "train/post_ent_mag": 75.76157716530652, "train/post_ent_max": 75.76157716530652, "train/post_ent_mean": 59.53587132362864, "train/post_ent_min": 41.221552805684915, "train/post_ent_std": 7.587137926763027, "train/prior_ent_mag": 75.7733828290623, "train/prior_ent_max": 75.7733828290623, "train/prior_ent_mean": 59.926951441932566, "train/prior_ent_min": 42.24897436400754, "train/prior_ent_std": 7.683087574177651, "train/rep_loss_mean": 1.0000021709269615, "train/rep_loss_std": 6.626062177065478e-05, "train/reward_avg": 0.004166692235605352, "train/reward_loss_mean": 0.02868182956236391, "train/reward_loss_std": 0.3153190658469895, "train/reward_max_data": 0.849434674385205, "train/reward_max_pred": 0.35507303446381533, "train/reward_neg_acc": 0.9993434713114446, "train/reward_neg_loss": 0.005207670823291843, "train/reward_pos_acc": 0.12319864909253528, "train/reward_pos_loss": 4.005087272605705, "train/reward_pred": 0.003123371541294171, "train/reward_rate": 0.0059035411432160805, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.01742437668144703, "report/cont_loss_std": 0.2099050134420395, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.0992960929870605, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.005338604096323252, "report/cont_pred": 0.9942774772644043, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06476031243801117, "report/image_loss_std": 0.08493964374065399, "report/model_loss_mean": 0.7029446363449097, "report/model_loss_std": 0.5072840452194214, "report/post_ent_mag": 76.34441375732422, "report/post_ent_max": 76.34441375732422, "report/post_ent_mean": 59.36109924316406, "report/post_ent_min": 40.418846130371094, "report/post_ent_std": 8.190071105957031, "report/prior_ent_mag": 75.08448791503906, "report/prior_ent_max": 75.08448791503906, "report/prior_ent_mean": 59.47545623779297, "report/prior_ent_min": 41.562828063964844, "report/prior_ent_std": 7.709778308868408, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002593994140625, "report/reward_loss_mean": 0.020759880542755127, "report/reward_loss_std": 0.26946645975112915, "report/reward_max_data": 0.762499988079071, "report/reward_max_pred": 0.16319513320922852, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.004376118537038565, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 4.198619365692139, "report/reward_pred": 0.0024869050830602646, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.025108739733695984, "eval/cont_loss_std": 0.34764567017555237, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.978158473968506, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.007616918999701738, "eval/cont_pred": 0.9936510324478149, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10869558155536652, "eval/image_loss_std": 0.1288638710975647, "eval/model_loss_mean": 0.758307933807373, "eval/model_loss_std": 0.7613398432731628, "eval/post_ent_mag": 75.33280944824219, "eval/post_ent_max": 75.33280944824219, "eval/post_ent_mean": 59.71126174926758, "eval/post_ent_min": 41.157432556152344, "eval/post_ent_std": 7.740848064422607, "eval/prior_ent_mag": 74.49430847167969, "eval/prior_ent_max": 74.49430847167969, "eval/prior_ent_mean": 59.71014404296875, "eval/prior_ent_min": 42.110939025878906, "eval/prior_ent_std": 7.242599010467529, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0020812987349927425, "eval/reward_loss_mean": 0.024503592401742935, "eval/reward_loss_std": 0.3874230682849884, "eval/reward_max_data": 0.8531249761581421, "eval/reward_max_pred": 0.10985267162322998, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.004203779622912407, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.933206081390381, "eval/reward_pred": 0.00223681447096169, "eval/reward_rate": 0.0029296875, "replay/size": 1000000.0, "replay/inserts": 31904.0, "replay/samples": 31904.0, "replay/insert_wait_avg": 1.340484248479845e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.759662742002559e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4056.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2175453720243256e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.4007091522216797e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2518219947815, "timer/env.step_count": 3988.0, "timer/env.step_total": 40.79373049736023, "timer/env.step_frac": 0.04078346032502709, "timer/env.step_avg": 0.010229119984292935, "timer/env.step_min": 0.008427858352661133, "timer/env.step_max": 0.04904985427856445, "timer/replay._sample_count": 31904.0, "timer/replay._sample_total": 18.1661114692688, "timer/replay._sample_frac": 0.018161537994542714, "timer/replay._sample_avg": 0.0005693991809575226, "timer/replay._sample_min": 0.000446319580078125, "timer/replay._sample_max": 0.030673742294311523, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4495.0, "timer/agent.policy_total": 50.57756209373474, "timer/agent.policy_frac": 0.050564828757691194, "timer/agent.policy_avg": 0.011251960421298052, "timer/agent.policy_min": 0.009623289108276367, "timer/agent.policy_max": 0.0941004753112793, "timer/dataset_train_count": 1994.0, "timer/dataset_train_total": 0.2520277500152588, "timer/dataset_train_frac": 0.00025196429986265367, "timer/dataset_train_avg": 0.00012639305417013982, "timer/dataset_train_min": 0.00011014938354492188, "timer/dataset_train_max": 0.0005273818969726562, "timer/agent.train_count": 1994.0, "timer/agent.train_total": 896.3013000488281, "timer/agent.train_frac": 0.8960756484915499, "timer/agent.train_avg": 0.4494991474668145, "timer/agent.train_min": 0.43712544441223145, "timer/agent.train_max": 0.7509400844573975, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47892332077026367, "timer/agent.report_frac": 0.00047880274770722915, "timer/agent.report_avg": 0.23946166038513184, "timer/agent.report_min": 0.23208117485046387, "timer/agent.report_max": 0.2468421459197998, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.098661217271427e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 31.89530244532079}
{"step": 1628776, "time": 51308.7438583374, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1628944, "time": 51314.204575777054, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1629216, "time": 51322.488189935684, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1629824, "time": 51341.08279824257, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1629904, "time": 51343.54428434372, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1629984, "time": 51346.12936592102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1630096, "time": 51351.22723340988, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1630096, "time": 51351.23421359062, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1630096, "time": 51351.60625910759, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1630096, "time": 51351.809965610504, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 1630096, "time": 51352.05694413185, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1630096, "time": 51352.38380026817, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1630096, "time": 51352.49666810036, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 1630096, "time": 51352.81683039665, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1630152, "time": 51354.313125133514, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1630224, "time": 51357.24982905388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1630288, "time": 51359.19237828255, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1630800, "time": 51374.99592065811, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1630864, "time": 51376.964539051056, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1630968, "time": 51379.93624305725, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1631088, "time": 51383.856097221375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1631344, "time": 51391.69601106644, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1631472, "time": 51395.62787461281, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1631528, "time": 51397.116122722626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1631784, "time": 51405.08191537857, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1631840, "time": 51407.04438686371, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1632040, "time": 51413.00096797943, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1632344, "time": 51422.3344502449, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1632384, "time": 51423.79219245911, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1632408, "time": 51424.31917262077, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1632576, "time": 51429.70847463608, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 1632672, "time": 51432.665615558624, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1632696, "time": 51433.18102169037, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1632912, "time": 51440.17257499695, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1632944, "time": 51441.1535615921, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 1633056, "time": 51444.577061891556, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1633200, "time": 51449.005125284195, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1633224, "time": 51449.531527519226, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 1633416, "time": 51455.4468960762, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1633464, "time": 51456.91586995125, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1633512, "time": 51458.38875961304, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1633584, "time": 51460.864115953445, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1633720, "time": 51464.98112154007, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1634056, "time": 51475.323389053345, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1634072, "time": 51475.818742990494, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1634152, "time": 51478.26420521736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1634168, "time": 51478.75401926041, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1634344, "time": 51484.17372369766, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1634472, "time": 51488.0909781456, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1634512, "time": 51489.57698512077, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1634592, "time": 51492.020067214966, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1634744, "time": 51496.597324848175, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1635000, "time": 51504.48717260361, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1635144, "time": 51508.88720202446, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1635480, "time": 51519.22828769684, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1635616, "time": 51523.64094352722, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1635656, "time": 51524.76429629326, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1635792, "time": 51529.17285346985, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1636144, "time": 51539.96754026413, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1636192, "time": 51541.44367003441, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1636224, "time": 51542.42886567116, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1636240, "time": 51542.92592215538, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1636400, "time": 51547.84403538704, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 1636480, "time": 51550.31796312332, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1636520, "time": 51551.31951093674, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1636576, "time": 51553.25386238098, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1636656, "time": 51555.82552790642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1637176, "time": 51571.5678460598, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1637192, "time": 51572.066460847855, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1637344, "time": 51576.95256304741, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1637424, "time": 51579.418545246124, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1637568, "time": 51583.96458220482, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1637664, "time": 51586.90928387642, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1638072, "time": 51599.27391958237, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1638072, "time": 51599.28334546089, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 1638168, "time": 51602.23202967644, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1638376, "time": 51608.656903743744, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1638440, "time": 51611.130123376846, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1638464, "time": 51612.085889816284, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1638536, "time": 51614.190783023834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1638848, "time": 51623.94290971756, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1638968, "time": 51627.393642663956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1639104, "time": 51631.83657336235, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1639144, "time": 51632.836681842804, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1639192, "time": 51634.33564043045, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1639376, "time": 51640.237385988235, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1639544, "time": 51645.28135704994, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1639592, "time": 51646.76511311531, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1639656, "time": 51648.74321746826, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1639664, "time": 51649.21565055847, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1639664, "time": 51649.223670482635, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1639736, "time": 51651.20943689346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1640080, "time": 51662.53342962265, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 1640080, "time": 51662.87758874893, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 1640080, "time": 51663.31602358818, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1640080, "time": 51663.572087049484, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1640080, "time": 51664.3368332386, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 1640080, "time": 51664.46937084198, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1640080, "time": 51664.678043842316, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 1640080, "time": 51666.1914293766, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1640272, "time": 51672.09466481209, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1640416, "time": 51676.61999773979, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1640416, "time": 51676.628539562225, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1640656, "time": 51684.03213119507, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1640696, "time": 51685.048681259155, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1640704, "time": 51685.52941799164, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1641104, "time": 51697.841639995575, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1641136, "time": 51698.82889962196, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1641144, "time": 51698.858191013336, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1641184, "time": 51700.306649923325, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1641424, "time": 51707.7625977993, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 1641544, "time": 51711.20015716553, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1641736, "time": 51717.09231328964, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1641792, "time": 51719.024340867996, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1641856, "time": 51720.97692871094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1641992, "time": 51724.92361211777, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1642000, "time": 51725.3981423378, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1642200, "time": 51731.31373000145, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1642288, "time": 51734.374522686005, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1642416, "time": 51738.31792855263, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1642616, "time": 51744.246342897415, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1642680, "time": 51746.23466014862, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1642680, "time": 51746.244876384735, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1642728, "time": 51747.73444390297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1642888, "time": 51752.67240715027, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1643000, "time": 51756.129858255386, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1643040, "time": 51757.579708337784, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1643320, "time": 51766.17683339119, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1643552, "time": 51773.52230763435, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1643832, "time": 51781.89369368553, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1644112, "time": 51790.718552827835, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1644136, "time": 51791.23494744301, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1644248, "time": 51794.798424482346, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1644480, "time": 51802.15110230446, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1644504, "time": 51802.668261528015, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1644512, "time": 51803.14259672165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1644608, "time": 51806.09962296486, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 1644744, "time": 51810.04692339897, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1644928, "time": 51815.95219326019, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1644992, "time": 51817.9205801487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1645176, "time": 51823.35778570175, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1645352, "time": 51828.89967799187, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1645480, "time": 51832.840017557144, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1645528, "time": 51834.31593108177, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1645576, "time": 51835.809517383575, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1645584, "time": 51836.28583550453, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1645632, "time": 51837.758194208145, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1645792, "time": 51842.66195344925, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1645848, "time": 51844.15615582466, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1646152, "time": 51853.4827580452, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1646320, "time": 51858.95873308182, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1646344, "time": 51859.4740653038, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1646352, "time": 51859.96691393852, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1646464, "time": 51863.38200497627, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1646912, "time": 51877.64872956276, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1646992, "time": 51880.11964893341, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1647008, "time": 51880.61444211006, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1647120, "time": 51884.172753572464, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1647192, "time": 51886.18537402153, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1647512, "time": 51896.06706118584, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1647528, "time": 51896.57496261597, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1647696, "time": 51902.0137488842, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1647776, "time": 51904.480298519135, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 1647888, "time": 51907.96627283096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1647896, "time": 51907.995660066605, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1648104, "time": 51914.57362818718, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1648144, "time": 51916.06330537796, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1648184, "time": 51917.070271492004, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1648184, "time": 51917.079521894455, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1648224, "time": 51918.548245191574, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1648360, "time": 51922.506954193115, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1648432, "time": 51924.95175552368, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1648776, "time": 51935.32577443123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1648912, "time": 51939.71670770645, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1649144, "time": 51946.734088897705, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1649144, "time": 51946.74269127846, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1649152, "time": 51947.21831178665, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1649272, "time": 51950.70535445213, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1649600, "time": 51961.03296279907, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1649656, "time": 51962.534004211426, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1649784, "time": 51966.46592211723, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1649792, "time": 51966.94213676453, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1649888, "time": 51969.91147542, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1650016, "time": 51973.92534661293, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1650064, "time": 51976.66741704941, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1650064, "time": 51976.69374990463, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1650064, "time": 51977.02953624725, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1650064, "time": 51977.42036938667, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1650064, "time": 51977.54598379135, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 1650064, "time": 51977.65509939194, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 1650064, "time": 51977.78752541542, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1650064, "time": 51978.6091735363, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 1650184, "time": 51982.038219213486, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1650384, "time": 51988.408396959305, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1650664, "time": 51996.773943185806, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1650808, "time": 52001.19763684273, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1650816, "time": 52001.67619538307, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1650912, "time": 52004.72175741196, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1650920, "time": 52004.75051903725, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1650968, "time": 52006.2196791172, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1651168, "time": 52012.63140964508, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1651456, "time": 52021.430362939835, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1651608, "time": 52025.877383708954, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1651904, "time": 52035.27221417427, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1652040, "time": 52039.24336743355, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1652248, "time": 52045.649522066116, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1652288, "time": 52047.11319231987, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1652576, "time": 52055.952152490616, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1652584, "time": 52055.98144555092, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1652648, "time": 52057.96849703789, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 1652808, "time": 52062.90096139908, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1652952, "time": 52067.484669446945, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1653232, "time": 52076.3746342659, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1653432, "time": 52082.331817388535, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1653440, "time": 52082.80400490761, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1653512, "time": 52084.784017801285, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1653728, "time": 52091.63287591934, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1653784, "time": 52093.12582230568, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1653912, "time": 52097.203276872635, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1654136, "time": 52104.064439058304, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1654184, "time": 52105.538917541504, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1654208, "time": 52106.52179646492, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1654336, "time": 52110.47541499138, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1654416, "time": 52112.956839084625, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1654528, "time": 52116.45128893852, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1654536, "time": 52116.481556892395, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1654672, "time": 52120.908531188965, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1654720, "time": 52122.393152713776, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1654880, "time": 52127.95882797241, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1654912, "time": 52128.94503378868, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1655128, "time": 52135.34999656677, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1655384, "time": 52143.23549795151, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1655440, "time": 52145.190116882324, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1655624, "time": 52150.62750554085, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1655632, "time": 52151.11944770813, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1655856, "time": 52158.12298512459, "episode/length": 265.0, "episode/score": 0.171875, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.0}
{"step": 1656120, "time": 52166.05035972595, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1656128, "time": 52166.526636362076, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1656256, "time": 52170.46390128136, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1656288, "time": 52171.47328066826, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1656344, "time": 52172.96894431114, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1656640, "time": 52182.448154211044, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1656840, "time": 52188.52782654762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1656880, "time": 52189.97640299797, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1656976, "time": 52192.931047439575, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1657016, "time": 52193.94419980049, "episode/length": 286.0, "episode/score": 0.10625000298023224, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.0}
{"step": 1657384, "time": 52205.28731560707, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1657456, "time": 52207.74202823639, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 1657512, "time": 52209.23256969452, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1657936, "time": 52222.629336833954, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1658024, "time": 52225.11006975174, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1658208, "time": 52231.02037549019, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1658248, "time": 52232.03983068466, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1658344, "time": 52235.01447725296, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1658432, "time": 52237.96720957756, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1658472, "time": 52238.98717498779, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1658568, "time": 52241.97770857811, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1658600, "time": 52242.967067956924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1658872, "time": 52251.44800782204, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1659064, "time": 52257.33251929283, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1659080, "time": 52257.82486176491, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1659112, "time": 52258.81165719032, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1659216, "time": 52262.25238800049, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1659328, "time": 52265.732119083405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1659400, "time": 52267.71570158005, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1659560, "time": 52272.632997751236, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1659600, "time": 52274.19859075546, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1659680, "time": 52276.67076086998, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1659712, "time": 52277.65057182312, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1659872, "time": 52282.56668829918, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1660048, "time": 52289.04424023628, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 1660048, "time": 52289.28725552559, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1660048, "time": 52289.983093738556, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1660048, "time": 52290.03041744232, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 1660048, "time": 52290.14124202728, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1660048, "time": 52291.683933734894, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1660048, "time": 52291.712277173996, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1660048, "time": 52291.94772696495, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 1660104, "time": 52293.44209718704, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1660256, "time": 52298.35825252533, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1660313, "time": 52301.08442187309, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1400051404483356, "train/action_min": 0.0, "train/action_std": 1.710299715324862, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010505861970104615, "train/actor_opt_grad_steps": 102680.0, "train/actor_opt_loss": -33.230686015220144, "train/adv_mag": 0.8144024101334002, "train/adv_max": 0.3196249589249117, "train/adv_mean": 0.0017411985824568473, "train/adv_min": -0.7614219823674341, "train/adv_std": 0.03528914802787292, "train/cont_avg": 0.9925310144472361, "train/cont_loss_mean": 0.03214974078962851, "train/cont_loss_std": 0.3145891765329107, "train/cont_neg_acc": 0.08466628463424031, "train/cont_neg_loss": 3.383264212153066, "train/cont_pos_acc": 0.9998269539382589, "train/cont_pos_loss": 0.006799849648796134, "train/cont_pred": 0.9926548067049764, "train/cont_rate": 0.9925310144472361, "train/dyn_loss_mean": 1.0000044047532968, "train/dyn_loss_std": 0.00013746414275081763, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12219670851101827, "train/extr_critic_critic_opt_grad_steps": 102680.0, "train/extr_critic_critic_opt_loss": 13041.08229624686, "train/extr_critic_mag": 1.9102367408311547, "train/extr_critic_max": 1.9102367408311547, "train/extr_critic_mean": 1.7597012831338088, "train/extr_critic_min": 1.4617927332020284, "train/extr_critic_std": 0.03514252706950334, "train/extr_return_normed_mag": 0.8524140383130941, "train/extr_return_normed_max": 0.3393610889588169, "train/extr_return_normed_mean": 0.07773308294951617, "train/extr_return_normed_min": -0.7202592057798376, "train/extr_return_normed_std": 0.05039675441107259, "train/extr_return_rate": 0.9997664339578332, "train/extr_return_raw_mag": 2.0230703982875573, "train/extr_return_raw_max": 2.0230703982875573, "train/extr_return_raw_mean": 1.7614424665968622, "train/extr_return_raw_min": 0.9634501035489029, "train/extr_return_raw_std": 0.05039675460763313, "train/extr_reward_mag": 0.2830913659915253, "train/extr_reward_max": 0.2830913659915253, "train/extr_reward_mean": 0.0032437698981120956, "train/extr_reward_min": 2.336262458532899e-07, "train/extr_reward_std": 0.0108763683334592, "train/image_loss_mean": 0.0853849581662734, "train/image_loss_std": 0.10237669780026729, "train/model_loss_mean": 0.7464135957123647, "train/model_loss_std": 0.6264910554167015, "train/model_opt_grad_norm": 13.24355541401772, "train/model_opt_grad_steps": 102586.63819095478, "train/model_opt_loss": 4686.962525027481, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6281.407035175879, "train/policy_entropy_mag": 1.2136943825525255, "train/policy_entropy_max": 1.2136943825525255, "train/policy_entropy_mean": 0.0867482705331927, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10150839174961925, "train/policy_logprob_mag": 6.5510802556521925, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08692006283818778, "train/policy_logprob_min": -6.5510802556521925, "train/policy_logprob_std": 0.625118003718218, "train/policy_randomness_mag": 0.6237155690265062, "train/policy_randomness_max": 0.6237155690265062, "train/policy_randomness_mean": 0.04457979688617452, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.052164997269011026, "train/post_ent_mag": 75.79287194486838, "train/post_ent_max": 75.79287194486838, "train/post_ent_mean": 59.77106891804604, "train/post_ent_min": 41.4733545696316, "train/post_ent_std": 7.4781025857781644, "train/prior_ent_mag": 75.57896204809448, "train/prior_ent_max": 75.57896204809448, "train/prior_ent_mean": 60.04047188686965, "train/prior_ent_min": 42.02823554570951, "train/prior_ent_std": 7.386766747613648, "train/rep_loss_mean": 1.0000044047532968, "train/rep_loss_std": 0.00013746414275081763, "train/reward_avg": 0.00406734907008642, "train/reward_loss_mean": 0.028876229900698266, "train/reward_loss_std": 0.31532678910386025, "train/reward_max_data": 0.8437500020966457, "train/reward_max_pred": 0.32296355285836226, "train/reward_neg_acc": 0.9992843255325777, "train/reward_neg_loss": 0.005488239924877358, "train/reward_pos_acc": 0.11293263093161224, "train/reward_pos_loss": 4.019680921755843, "train/reward_pred": 0.0031508373192525537, "train/reward_rate": 0.005820116206030151, "train_stats/mean_log_entropy": 0.08185992753433605, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 0.0354556106030941, "report/cont_loss_std": 0.35330039262771606, "report/cont_neg_acc": 0.30000001192092896, "report/cont_neg_loss": 3.014713764190674, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.006074365694075823, "report/cont_pred": 0.9918989539146423, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10070770233869553, "report/image_loss_std": 0.11875217407941818, "report/model_loss_mean": 0.7719264030456543, "report/model_loss_std": 0.7239440679550171, "report/post_ent_mag": 78.435791015625, "report/post_ent_max": 78.435791015625, "report/post_ent_mean": 64.62466430664062, "report/post_ent_min": 43.96966552734375, "report/post_ent_std": 7.380485534667969, "report/prior_ent_mag": 78.67521667480469, "report/prior_ent_max": 78.67521667480469, "report/prior_ent_mean": 63.87166976928711, "report/prior_ent_min": 41.56612014770508, "report/prior_ent_std": 7.755971908569336, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0057617188431322575, "report/reward_loss_mean": 0.03576305881142616, "report/reward_loss_std": 0.3694440722465515, "report/reward_max_data": 0.824999988079071, "report/reward_max_pred": 0.5239648818969727, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.004897535778582096, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.5167078971862793, "report/reward_pred": 0.0037820101715624332, "report/reward_rate": 0.0087890625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.04374789074063301, "eval/cont_loss_std": 0.5078285932540894, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.30322790145874, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0068550813011825085, "eval/cont_pred": 0.9932319521903992, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09540437161922455, "eval/image_loss_std": 0.11316859722137451, "eval/model_loss_mean": 0.7911030054092407, "eval/model_loss_std": 1.1832796335220337, "eval/post_ent_mag": 79.27132415771484, "eval/post_ent_max": 79.27132415771484, "eval/post_ent_mean": 62.66376495361328, "eval/post_ent_min": 42.71099853515625, "eval/post_ent_std": 8.528402328491211, "eval/prior_ent_mag": 78.47244262695312, "eval/prior_ent_max": 78.47244262695312, "eval/prior_ent_mean": 62.10270690917969, "eval/prior_ent_min": 42.19277572631836, "eval/prior_ent_std": 8.84482479095459, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0037078857421875, "eval/reward_loss_mean": 0.05195073038339615, "eval/reward_loss_std": 0.6456367373466492, "eval/reward_max_data": 0.731249988079071, "eval/reward_max_pred": 0.05658459663391113, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.005514871794730425, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.930568695068359, "eval/reward_pred": 0.0029151923954486847, "eval/reward_rate": 0.005859375, "replay/size": 1000000.0, "replay/inserts": 31808.0, "replay/samples": 31808.0, "replay/insert_wait_avg": 1.3391256812112912e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.635234742577168e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5232.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2427659574269519e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2378299236298, "timer/env.step_count": 3976.0, "timer/env.step_total": 40.566479444503784, "timer/env.step_frac": 0.0405568338158147, "timer/env.step_avg": 0.010202836882420468, "timer/env.step_min": 0.008330821990966797, "timer/env.step_max": 0.042681217193603516, "timer/replay._sample_count": 31808.0, "timer/replay._sample_total": 18.144350290298462, "timer/replay._sample_frac": 0.018140036046910783, "timer/replay._sample_avg": 0.0005704335478589808, "timer/replay._sample_min": 0.00044226646423339844, "timer/replay._sample_max": 0.012643575668334961, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4630.0, "timer/agent.policy_total": 52.35046148300171, "timer/agent.policy_frac": 0.05233801393714411, "timer/agent.policy_avg": 0.011306795136717432, "timer/agent.policy_min": 0.0094757080078125, "timer/agent.policy_max": 0.10477471351623535, "timer/dataset_train_count": 1988.0, "timer/dataset_train_total": 0.25011730194091797, "timer/dataset_train_frac": 0.0002500578307061381, "timer/dataset_train_avg": 0.00012581353216343963, "timer/dataset_train_min": 0.00010824203491210938, "timer/dataset_train_max": 0.0010769367218017578, "timer/agent.train_count": 1988.0, "timer/agent.train_total": 893.2762379646301, "timer/agent.train_frac": 0.8930638406596095, "timer/agent.train_avg": 0.449334123724663, "timer/agent.train_min": 0.4381091594696045, "timer/agent.train_max": 0.7176632881164551, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48102784156799316, "timer/agent.report_frac": 0.0004809134659551125, "timer/agent.report_avg": 0.24051392078399658, "timer/agent.report_min": 0.23207759857177734, "timer/agent.report_max": 0.24895024299621582, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.384738831064489e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 31.79968184710976}
{"step": 1660344, "time": 52301.77982330322, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1660368, "time": 52302.82553911209, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1660464, "time": 52305.92584180832, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1660496, "time": 52306.92116141319, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1660896, "time": 52319.238684892654, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1661040, "time": 52323.687829732895, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1661072, "time": 52324.68931031227, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1661200, "time": 52328.63238334656, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1661280, "time": 52331.13202738762, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1661656, "time": 52342.61039304733, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1661680, "time": 52343.58554601669, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1661696, "time": 52344.077486753464, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1661712, "time": 52344.59453701973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1662024, "time": 52353.937849760056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1662152, "time": 52357.880984544754, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1662184, "time": 52358.865220069885, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1662720, "time": 52375.75317287445, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1662800, "time": 52378.2273337841, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1663096, "time": 52387.71762728691, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 1663200, "time": 52391.17398738861, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 1663256, "time": 52392.67656207085, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1663296, "time": 52394.24484848976, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 1663296, "time": 52394.25443935394, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1663512, "time": 52400.73228263855, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1663792, "time": 52409.66638827324, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1663864, "time": 52411.69334626198, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1663912, "time": 52413.188908576965, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1664128, "time": 52420.11060500145, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1664128, "time": 52420.1190571785, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1664336, "time": 52426.68997478485, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1664592, "time": 52434.623208761215, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1664704, "time": 52438.06274271011, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1664712, "time": 52438.092564344406, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 1665032, "time": 52447.933471918106, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1665040, "time": 52448.40802168846, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1665048, "time": 52448.43795275688, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1665608, "time": 52465.747965574265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1665776, "time": 52471.12195920944, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1665784, "time": 52471.15048980713, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1666152, "time": 52482.49843811989, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1666208, "time": 52484.59751152992, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1666224, "time": 52485.089684963226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1666488, "time": 52492.96141886711, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 1666576, "time": 52495.89454007149, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1666648, "time": 52497.870337724686, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1666696, "time": 52499.35505104065, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1666720, "time": 52500.318878889084, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1666960, "time": 52507.674443006516, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1667064, "time": 52510.6463406086, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1667088, "time": 52511.608033657074, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1667376, "time": 52520.58080339432, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1667528, "time": 52525.00925779343, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1667592, "time": 52526.96082115173, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1667600, "time": 52527.43577504158, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1667800, "time": 52533.348064899445, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1667856, "time": 52535.30015230179, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1668072, "time": 52541.74800491333, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1668128, "time": 52543.72614145279, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1668168, "time": 52544.80846786499, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1668232, "time": 52546.769936323166, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 1668304, "time": 52549.24243402481, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1668448, "time": 52553.68482375145, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 1669064, "time": 52572.320935726166, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1669136, "time": 52574.83963918686, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1669200, "time": 52576.7872068882, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1669208, "time": 52576.81526994705, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1669224, "time": 52577.309208631516, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1669288, "time": 52579.28614139557, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1669360, "time": 52581.697038412094, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1669440, "time": 52584.15327692032, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1669592, "time": 52588.59438538551, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1669784, "time": 52594.502026081085, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 1669808, "time": 52595.45755982399, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1669840, "time": 52596.43835926056, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1669912, "time": 52598.445987701416, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1670032, "time": 52602.65336751938, "eval_episode/length": 13.0, "eval_episode/score": 0.9593750238418579, "eval_episode/reward_rate": 0.07142857142857142}
{"step": 1670032, "time": 52603.177929639816, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 1670032, "time": 52604.11252570152, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1670032, "time": 52604.23430228233, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1670032, "time": 52604.3241789341, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1670032, "time": 52604.408172130585, "eval_episode/length": 13.0, "eval_episode/score": 0.9593750238418579, "eval_episode/reward_rate": 0.07142857142857142}
{"step": 1670032, "time": 52604.41434407234, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 1670032, "time": 52604.58382940292, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1670168, "time": 52608.5378715992, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1670368, "time": 52614.90115571022, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1670408, "time": 52615.908421278, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1670480, "time": 52618.338039159775, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1670824, "time": 52628.65652680397, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1670968, "time": 52633.103451013565, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1671032, "time": 52635.19863009453, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1671424, "time": 52647.88535094261, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1671432, "time": 52647.9143345356, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1671448, "time": 52648.409524440765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1671504, "time": 52650.374068021774, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1671816, "time": 52659.73838376999, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1671824, "time": 52660.21641421318, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1671904, "time": 52662.66140913963, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1671936, "time": 52663.666991472244, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1671992, "time": 52665.26443052292, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1672120, "time": 52669.20211434364, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1672152, "time": 52670.18199419975, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1672344, "time": 52676.109807252884, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1672448, "time": 52679.55270862579, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1672848, "time": 52691.779616355896, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1673072, "time": 52698.818477869034, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1673104, "time": 52699.800837278366, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1673136, "time": 52700.78454566002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1673312, "time": 52706.19255757332, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1673392, "time": 52708.68987441063, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1673432, "time": 52709.71789813042, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1673480, "time": 52711.20825099945, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1673816, "time": 52721.544343709946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1673872, "time": 52723.498987197876, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1673880, "time": 52723.52692270279, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1673976, "time": 52726.58404350281, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1674032, "time": 52728.54603052139, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1674072, "time": 52729.547985076904, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1674328, "time": 52737.40929412842, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1674552, "time": 52744.272582530975, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1674656, "time": 52747.67663860321, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1674856, "time": 52753.65559053421, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1674920, "time": 52755.69815349579, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1674984, "time": 52757.66043591499, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1675040, "time": 52759.617441654205, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1675112, "time": 52761.6038172245, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1675224, "time": 52765.04520392418, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1675400, "time": 52770.42780303955, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1675744, "time": 52781.289657354355, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1675952, "time": 52787.82002091408, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1676040, "time": 52790.28306412697, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1676064, "time": 52791.25055551529, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1676240, "time": 52796.6499171257, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1676312, "time": 52798.64561963081, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1676416, "time": 52802.046686172485, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1676464, "time": 52803.53627157211, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1676632, "time": 52808.483135700226, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1676752, "time": 52812.39997649193, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1676944, "time": 52818.45696377754, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1676952, "time": 52818.48611330986, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1676976, "time": 52819.46215629578, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1677184, "time": 52825.84031915665, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1677232, "time": 52827.332909822464, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1677344, "time": 52830.75237631798, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1677384, "time": 52831.762558460236, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1677400, "time": 52832.27894830704, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1677448, "time": 52833.75117945671, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1677664, "time": 52840.60847878456, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1677688, "time": 52841.12603330612, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1677792, "time": 52844.65420436859, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1677808, "time": 52845.1491625309, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1678048, "time": 52852.51563644409, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1678232, "time": 52857.96493721008, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1678288, "time": 52859.90644288063, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1678312, "time": 52860.428634643555, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1678336, "time": 52861.39213657379, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1678496, "time": 52866.31384420395, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1678592, "time": 52869.268768787384, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1678776, "time": 52874.791293382645, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1679128, "time": 52885.58657121658, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1679160, "time": 52886.583684682846, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1679176, "time": 52887.08102941513, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1679400, "time": 52894.47925853729, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1679432, "time": 52895.46845602989, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1679480, "time": 52896.97729444504, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1679656, "time": 52902.385628700256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1679760, "time": 52905.934458732605, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1680016, "time": 52914.38683581352, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 1680016, "time": 52915.06804037094, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1680016, "time": 52915.546701192856, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1680016, "time": 52915.656277894974, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1680016, "time": 52915.87864995003, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1680016, "time": 52915.94666099548, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1680016, "time": 52916.01335644722, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1680016, "time": 52916.42910552025, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 1680080, "time": 52918.38302922249, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1680080, "time": 52918.39163327217, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1680120, "time": 52919.41970229149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1680144, "time": 52920.37517738342, "episode/length": 7.0, "episode/score": 0.9781249761581421, "episode/reward_rate": 0.125, "episode/intrinsic_return": 0.0}
{"step": 1680192, "time": 52921.841148376465, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1680384, "time": 52927.715364933014, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1680760, "time": 52939.10655593872, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1680928, "time": 52944.46393561363, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1680936, "time": 52944.50193071365, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1681152, "time": 52951.32227349281, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1681528, "time": 52962.61747074127, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1681584, "time": 52964.69389843941, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1681712, "time": 52968.64563322067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1681736, "time": 52969.162964344025, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1681776, "time": 52970.617691516876, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1681944, "time": 52975.59928679466, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1681968, "time": 52976.559004068375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1682072, "time": 52979.53119468689, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 1682216, "time": 52983.95237374306, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1682512, "time": 52993.230503082275, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1682568, "time": 52994.829315423965, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1682600, "time": 52995.809158325195, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1682624, "time": 52996.76493000984, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1682648, "time": 52997.27885699272, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1682656, "time": 52997.7501475811, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1683112, "time": 53011.512733221054, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1683176, "time": 53013.50800180435, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1683312, "time": 53017.91073036194, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1683376, "time": 53019.86050105095, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1683512, "time": 53023.913450956345, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1683616, "time": 53027.327474594116, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1683832, "time": 53033.76131224632, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1683896, "time": 53035.72009778023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1684024, "time": 53039.65641260147, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1684360, "time": 53049.97559118271, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1684424, "time": 53051.93059301376, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1684424, "time": 53051.939464092255, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1684440, "time": 53052.46395969391, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1684776, "time": 53062.884894132614, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1684816, "time": 53064.34171962738, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1684936, "time": 53067.800043821335, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1684960, "time": 53068.772075653076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1685128, "time": 53073.70872807503, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1685464, "time": 53084.1206138134, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1685544, "time": 53086.571635723114, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1685560, "time": 53087.08817863464, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1685648, "time": 53090.02798867226, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1685824, "time": 53095.44396209717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1685832, "time": 53095.47603845596, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1686096, "time": 53103.801762104034, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1686328, "time": 53110.67663383484, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1686736, "time": 53123.5200510025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1686752, "time": 53124.014969825745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1686768, "time": 53124.50866603851, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1686768, "time": 53124.518780231476, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1686984, "time": 53130.913089990616, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1686984, "time": 53130.923194646835, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1687104, "time": 53134.83797764778, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1687272, "time": 53139.80107450485, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1687304, "time": 53140.78839182854, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1687344, "time": 53142.26077914238, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1687576, "time": 53149.82531809807, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1687960, "time": 53161.62610077858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1688112, "time": 53166.51829099655, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1688216, "time": 53169.48219895363, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1688384, "time": 53175.01051950455, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1688744, "time": 53185.858889102936, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1689032, "time": 53194.69077682495, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1689064, "time": 53195.68408989906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1689296, "time": 53203.11030578613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1689304, "time": 53203.13824748993, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1689304, "time": 53203.14874982834, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1689392, "time": 53206.21816897392, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 1689416, "time": 53206.73886013031, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1689928, "time": 53222.44142699242, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1689968, "time": 53223.88854265213, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1690000, "time": 53226.15458607674, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1690000, "time": 53226.36755871773, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1690000, "time": 53226.88553214073, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1690000, "time": 53227.90068221092, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 1690000, "time": 53228.098086833954, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1690000, "time": 53228.25019574165, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1690000, "time": 53228.52535653114, "eval_episode/length": 171.0, "eval_episode/score": 0.46562498807907104, "eval_episode/reward_rate": 0.005813953488372093}
{"step": 1690000, "time": 53228.789496183395, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1690040, "time": 53229.815229177475, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1690304, "time": 53238.28357958794, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1690344, "time": 53239.29317522049, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1690488, "time": 53243.721269607544, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1690528, "time": 53245.20966172218, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1690648, "time": 53248.65197443962, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1690696, "time": 53250.14947152138, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1690720, "time": 53251.112191200256, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1690832, "time": 53254.56835269928, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 1691000, "time": 53259.48861575127, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1691096, "time": 53262.440927267075, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1691376, "time": 53271.37828493118, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1691376, "time": 53271.3883459568, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1691376, "time": 53271.3972363472, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1691432, "time": 53272.91473650932, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1691448, "time": 53273.41536617279, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1691680, "time": 53280.8402364254, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1691728, "time": 53282.318732738495, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1691888, "time": 53287.228914022446, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1691896, "time": 53287.25774312019, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1691896, "time": 53287.26691031456, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1691952, "time": 53289.21834778786, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1692120, "time": 53294.24338197708, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1692120, "time": 53294.2507622242, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1692160, "time": 53295.709261894226, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1692208, "time": 53297.18719911575, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1692313, "time": 53301.21617460251, "train_stats/mean_log_entropy": 0.0806319557560178, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1661495971679687, "train/action_min": 0.0, "train/action_std": 1.7594868868589402, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012276318750809877, "train/actor_opt_grad_steps": 104675.0, "train/actor_opt_loss": -32.48236393928528, "train/adv_mag": 0.8566895282268524, "train/adv_max": 0.312456693649292, "train/adv_mean": 0.0015186038034539706, "train/adv_min": -0.7984472119808197, "train/adv_std": 0.03520493782125413, "train/cont_avg": 0.9927587890625, "train/cont_loss_mean": 0.030542158326134085, "train/cont_loss_std": 0.30591926746070386, "train/cont_neg_acc": 0.1002130114659667, "train/cont_neg_loss": 3.2972256791591645, "train/cont_pos_acc": 0.9998525288701058, "train/cont_pos_loss": 0.00668582963058725, "train/cont_pred": 0.992629346549511, "train/cont_rate": 0.9927587890625, "train/dyn_loss_mean": 1.000001944899559, "train/dyn_loss_std": 6.220417461008765e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11925868879072368, "train/extr_critic_critic_opt_grad_steps": 104675.0, "train/extr_critic_critic_opt_loss": 13092.2159375, "train/extr_critic_mag": 1.9540973234176635, "train/extr_critic_max": 1.9540973234176635, "train/extr_critic_mean": 1.8090248113870622, "train/extr_critic_min": 1.5396600371599198, "train/extr_critic_std": 0.034252270814031364, "train/extr_return_normed_mag": 0.877959498167038, "train/extr_return_normed_max": 0.3349820399284363, "train/extr_return_normed_mean": 0.07534545168280601, "train/extr_return_normed_min": -0.745623254776001, "train/extr_return_normed_std": 0.0498206455539912, "train/extr_return_rate": 0.9997874584794044, "train/extr_return_raw_mag": 2.0701799046993257, "train/extr_return_raw_max": 2.0701799046993257, "train/extr_return_raw_mean": 1.8105433958768844, "train/extr_return_raw_min": 0.9895746099948883, "train/extr_return_raw_std": 0.049820645647123456, "train/extr_reward_mag": 0.27767381370067595, "train/extr_reward_max": 0.27767381370067595, "train/extr_reward_mean": 0.0032138498540734872, "train/extr_reward_min": 2.2292137145996095e-07, "train/extr_reward_std": 0.010560282738879323, "train/image_loss_mean": 0.08537363972514868, "train/image_loss_std": 0.10246250523254276, "train/model_loss_mean": 0.74410087287426, "train/model_loss_std": 0.6152537514269352, "train/model_opt_grad_norm": 13.173194952011109, "train/model_opt_grad_steps": 104580.03, "train/model_opt_loss": 4278.374549560547, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5775.0, "train/policy_entropy_mag": 1.1976925784349441, "train/policy_entropy_max": 1.1976925784349441, "train/policy_entropy_mean": 0.08611973576247692, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.0991801579296589, "train/policy_logprob_mag": 6.551080272197724, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08629470895975828, "train/policy_logprob_min": -6.551080272197724, "train/policy_logprob_std": 0.6250162109732628, "train/policy_randomness_mag": 0.6154922649264336, "train/policy_randomness_max": 0.6154922649264336, "train/policy_randomness_mean": 0.04425679441541433, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05096852188929915, "train/post_ent_mag": 75.57285663604736, "train/post_ent_max": 75.57285663604736, "train/post_ent_mean": 59.95046453475952, "train/post_ent_min": 41.734312267303466, "train/post_ent_std": 7.631447887420654, "train/prior_ent_mag": 75.80578254699707, "train/prior_ent_max": 75.80578254699707, "train/prior_ent_mean": 60.04679521560669, "train/prior_ent_min": 42.5208268737793, "train/prior_ent_std": 7.557002658843994, "train/rep_loss_mean": 1.000001944899559, "train/rep_loss_std": 6.220417461008765e-05, "train/reward_avg": 0.004044372560456395, "train/reward_loss_mean": 0.028183887149207294, "train/reward_loss_std": 0.31000180035829544, "train/reward_max_data": 0.8469843766093255, "train/reward_max_pred": 0.3498289126157761, "train/reward_neg_acc": 0.9993517145514488, "train/reward_neg_loss": 0.0053619519434869286, "train/reward_pos_acc": 0.1409022256731987, "train/reward_pos_loss": 3.9479041969776154, "train/reward_pred": 0.0032128633151296527, "train/reward_rate": 0.00580078125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.98828125, "report/cont_loss_mean": 0.045192766934633255, "report/cont_loss_std": 0.38853588700294495, "report/cont_neg_acc": 0.1666666716337204, "report/cont_neg_loss": 3.1947789192199707, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.007845893502235413, "report/cont_pred": 0.9904402494430542, "report/cont_rate": 0.98828125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08551008999347687, "report/image_loss_std": 0.10279642045497894, "report/model_loss_mean": 0.7716720104217529, "report/model_loss_std": 0.7421512007713318, "report/post_ent_mag": 72.23626708984375, "report/post_ent_max": 72.23626708984375, "report/post_ent_mean": 58.190704345703125, "report/post_ent_min": 41.963294982910156, "report/post_ent_std": 6.619965553283691, "report/prior_ent_mag": 74.82319641113281, "report/prior_ent_max": 74.82319641113281, "report/prior_ent_mean": 58.93254089355469, "report/prior_ent_min": 42.54617691040039, "report/prior_ent_std": 7.313874244689941, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0069976807571947575, "report/reward_loss_mean": 0.04096917808055878, "report/reward_loss_std": 0.36862078309059143, "report/reward_max_data": 0.981249988079071, "report/reward_max_pred": 0.7914787530899048, "report/reward_neg_acc": 0.9990147948265076, "report/reward_neg_loss": 0.008285276591777802, "report/reward_pos_acc": 0.1111111119389534, "report/reward_pos_loss": 3.726986885070801, "report/reward_pred": 0.005111480597406626, "report/reward_rate": 0.0087890625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.033933404833078384, "eval/cont_loss_std": 0.3592269718647003, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.406616687774658, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.008161205798387527, "eval/cont_pred": 0.9918770790100098, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1247442290186882, "eval/image_loss_std": 0.12770675122737885, "eval/model_loss_mean": 0.795577883720398, "eval/model_loss_std": 0.7889395952224731, "eval/post_ent_mag": 71.34635925292969, "eval/post_ent_max": 71.34635925292969, "eval/post_ent_mean": 60.14081573486328, "eval/post_ent_min": 42.66859817504883, "eval/post_ent_std": 5.599232196807861, "eval/prior_ent_mag": 73.47750854492188, "eval/prior_ent_max": 73.47750854492188, "eval/prior_ent_mean": 61.04029846191406, "eval/prior_ent_min": 41.17556381225586, "eval/prior_ent_std": 6.39677619934082, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.00439453125, "eval/reward_loss_mean": 0.03690022602677345, "eval/reward_loss_std": 0.3987451195716858, "eval/reward_max_data": 0.903124988079071, "eval/reward_max_pred": 0.07083892822265625, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00744371535256505, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.0346879959106445, "eval/reward_pred": 0.003996746614575386, "eval/reward_rate": 0.005859375, "replay/size": 1000000.0, "replay/inserts": 32000.0, "replay/samples": 32000.0, "replay/insert_wait_avg": 1.3372674584388734e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0491162538528443e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3280.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2069940567016602e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2464668750763, "timer/env.step_count": 4000.0, "timer/env.step_total": 40.82112455368042, "timer/env.step_frac": 0.04081106597778034, "timer/env.step_avg": 0.010205281138420105, "timer/env.step_min": 0.008159160614013672, "timer/env.step_max": 0.05006980895996094, "timer/replay._sample_count": 32000.0, "timer/replay._sample_total": 18.25586700439453, "timer/replay._sample_frac": 0.018251368646598338, "timer/replay._sample_avg": 0.0005704958438873291, "timer/replay._sample_min": 0.00043487548828125, "timer/replay._sample_max": 0.03410196304321289, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4410.0, "timer/agent.policy_total": 49.375139236450195, "timer/agent.policy_frac": 0.04936297289877536, "timer/agent.policy_avg": 0.011196176697607753, "timer/agent.policy_min": 0.009072065353393555, "timer/agent.policy_max": 0.09319090843200684, "timer/dataset_train_count": 2000.0, "timer/dataset_train_total": 0.2496027946472168, "timer/dataset_train_frac": 0.00024954129098502523, "timer/dataset_train_avg": 0.0001248013973236084, "timer/dataset_train_min": 0.0001087188720703125, "timer/dataset_train_max": 0.0004532337188720703, "timer/agent.train_count": 2000.0, "timer/agent.train_total": 898.4570498466492, "timer/agent.train_frac": 0.8982356645093355, "timer/agent.train_avg": 0.4492285249233246, "timer/agent.train_min": 0.4392108917236328, "timer/agent.train_max": 0.7030954360961914, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4752218723297119, "timer/agent.report_frac": 0.00047510477474054777, "timer/agent.report_avg": 0.23761093616485596, "timer/agent.report_min": 0.2301957607269287, "timer/agent.report_max": 0.2450261116027832, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.3847096044429395e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 31.991385689018777}
{"step": 1692320, "time": 53301.25417160988, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1692368, "time": 53303.13708972931, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1692616, "time": 53310.53285050392, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1692808, "time": 53316.44640994072, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1692936, "time": 53320.38353586197, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1692984, "time": 53321.864476919174, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1693016, "time": 53322.8494579792, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1693272, "time": 53330.850501298904, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1693456, "time": 53336.72531032562, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1693512, "time": 53338.22214436531, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1693872, "time": 53349.51047587395, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1693896, "time": 53350.04130601883, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1694072, "time": 53355.59421157837, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 1694176, "time": 53358.999874830246, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1694200, "time": 53359.53543186188, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1694472, "time": 53367.8524518013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1694592, "time": 53371.76344418526, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1694624, "time": 53372.766302108765, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1694696, "time": 53374.781351327896, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1694864, "time": 53380.19063425064, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1695120, "time": 53388.177032232285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1695192, "time": 53390.17447972298, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1695216, "time": 53391.13288187981, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1695288, "time": 53393.13611268997, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1695328, "time": 53394.61919379234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1695480, "time": 53399.09420919418, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1695552, "time": 53401.53277468681, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1695824, "time": 53410.4445168972, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1695976, "time": 53415.04587364197, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1696048, "time": 53417.46995806694, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1696144, "time": 53420.42575144768, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1696192, "time": 53421.89199256897, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1696704, "time": 53437.67454123497, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1696856, "time": 53442.198311805725, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1696888, "time": 53443.18106341362, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1697008, "time": 53447.19592547417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1697336, "time": 53457.05069613457, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 1697368, "time": 53458.03509616852, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1697560, "time": 53463.93861961365, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1697648, "time": 53466.86487746239, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1697728, "time": 53469.32316875458, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1697864, "time": 53473.25572133064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1697968, "time": 53476.78708410263, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1698040, "time": 53478.786757707596, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1698288, "time": 53486.60349011421, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1698592, "time": 53495.92636728287, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1698600, "time": 53495.95598053932, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1698752, "time": 53500.85500597954, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1699040, "time": 53509.82927966118, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1699080, "time": 53510.83815598488, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1699128, "time": 53512.31398558617, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1699160, "time": 53513.325593709946, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1699200, "time": 53514.78973484039, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1699320, "time": 53518.26160573959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1699384, "time": 53520.21449923515, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1699520, "time": 53524.62405657768, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1699736, "time": 53531.021664619446, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1699832, "time": 53534.10581731796, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1699832, "time": 53534.1248486042, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1700040, "time": 53540.50379037857, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1700056, "time": 53540.99689459801, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1700088, "time": 53542.92319345474, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 1700088, "time": 53542.97112083435, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 1700088, "time": 53543.62832283974, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1700088, "time": 53543.952358961105, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1700088, "time": 53544.019738435745, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1700088, "time": 53544.75594544411, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1700088, "time": 53544.82268571854, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 1700088, "time": 53546.391167879105, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 1700112, "time": 53547.38016080856, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1700192, "time": 53549.837194919586, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1700328, "time": 53553.791120290756, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1700680, "time": 53564.69505429268, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1700752, "time": 53567.135677576065, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1701064, "time": 53576.46895122528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1701160, "time": 53579.462890625, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 1701272, "time": 53582.99390769005, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1701344, "time": 53585.4270157814, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1701488, "time": 53589.84075188637, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1701656, "time": 53594.9030418396, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1702088, "time": 53608.21291875839, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1702424, "time": 53618.56726670265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1702480, "time": 53620.51446008682, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1702768, "time": 53629.49800157547, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 1702768, "time": 53629.50621056557, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1702920, "time": 53633.980281591415, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1703296, "time": 53645.78413248062, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1703320, "time": 53646.32348060608, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 1703344, "time": 53647.28416824341, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1703368, "time": 53647.797392606735, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1703376, "time": 53648.26909041405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1703424, "time": 53649.73755025864, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1703576, "time": 53654.317705631256, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1703576, "time": 53654.32790899277, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1703888, "time": 53664.13665056229, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1703896, "time": 53664.16483569145, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1703912, "time": 53664.66190648079, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1703952, "time": 53666.62751913071, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1704024, "time": 53668.60875439644, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1704496, "time": 53683.31639146805, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1704504, "time": 53683.34531664848, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1704608, "time": 53686.879843473434, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1704672, "time": 53688.858758211136, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1704896, "time": 53695.738518476486, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1705080, "time": 53701.20377159119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1705120, "time": 53702.650873184204, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1705208, "time": 53705.124626636505, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1705344, "time": 53709.53095769882, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1705520, "time": 53715.05061340332, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1705704, "time": 53720.47053647041, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1706080, "time": 53732.230508089066, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1706136, "time": 53733.721527814865, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 1706232, "time": 53736.67576766014, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1706328, "time": 53739.61781978607, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1706408, "time": 53742.09711742401, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1706456, "time": 53743.59247779846, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1706640, "time": 53749.5487074852, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1706784, "time": 53753.97906064987, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1706824, "time": 53754.998010635376, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1706832, "time": 53755.49792075157, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1706984, "time": 53759.94980120659, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1707120, "time": 53764.34825134277, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1707272, "time": 53768.820692777634, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1707336, "time": 53770.803611040115, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1707440, "time": 53774.34804081917, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1707576, "time": 53778.306034088135, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1707640, "time": 53780.28861308098, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1707712, "time": 53782.70902752876, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1707880, "time": 53787.65118980408, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1707936, "time": 53789.586884498596, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1708048, "time": 53793.03129839897, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1708136, "time": 53795.53185772896, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1708136, "time": 53795.541219711304, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1708512, "time": 53807.50935149193, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1708552, "time": 53808.512442827225, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1708552, "time": 53808.52149391174, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1708616, "time": 53810.51743745804, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1708912, "time": 53819.871514081955, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1709008, "time": 53822.82189846039, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1709032, "time": 53823.34091711044, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1709216, "time": 53829.220618247986, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 1709272, "time": 53830.74146795273, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1709704, "time": 53844.08280873299, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1709720, "time": 53844.59585261345, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1709792, "time": 53847.01993513107, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1709904, "time": 53850.48299026489, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1710024, "time": 53853.946913957596, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1710072, "time": 53855.45204639435, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1710072, "time": 53856.582000494, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 1710072, "time": 53856.61091828346, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 1710072, "time": 53857.397520303726, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1710072, "time": 53858.19365787506, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1710072, "time": 53858.22008562088, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1710072, "time": 53858.32836198807, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1710072, "time": 53858.697404146194, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 1710072, "time": 53858.74502205849, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 1710192, "time": 53862.661328315735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1710376, "time": 53868.21512532234, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1710648, "time": 53876.61612224579, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1710712, "time": 53878.61443948746, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1710864, "time": 53883.59191274643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1710888, "time": 53884.12608861923, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1710952, "time": 53886.12049174309, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1711008, "time": 53888.08435702324, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1711048, "time": 53889.09155893326, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1711184, "time": 53893.52450656891, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1711224, "time": 53894.663858652115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1711488, "time": 53903.032703876495, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1711816, "time": 53912.977783203125, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1711856, "time": 53914.44380927086, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1712072, "time": 53920.89341020584, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1712192, "time": 53925.47528362274, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1712208, "time": 53925.97066950798, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1712368, "time": 53930.9361436367, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1712488, "time": 53934.40482592583, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1712536, "time": 53935.90304660797, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1712656, "time": 53939.84643793106, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1712664, "time": 53939.875623464584, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1712672, "time": 53940.35216522217, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1712688, "time": 53940.848027706146, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1712976, "time": 53949.69548392296, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1713008, "time": 53950.668679237366, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1713496, "time": 53965.552855968475, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1713536, "time": 53967.00141763687, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1713584, "time": 53968.50197458267, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1713688, "time": 53971.45887422562, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1713736, "time": 53972.94644856453, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1713800, "time": 53974.89405441284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1713888, "time": 53977.83254933357, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1713952, "time": 53979.79170250893, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1714408, "time": 53993.73787689209, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1714456, "time": 53995.2091755867, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1714704, "time": 54003.07007551193, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1714800, "time": 54006.02859520912, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1714848, "time": 54007.52377676964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1714896, "time": 54009.00161862373, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1714976, "time": 54011.45701789856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1715272, "time": 54020.40804672241, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1715400, "time": 54024.34252047539, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1715584, "time": 54030.22495818138, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1715896, "time": 54039.61624503136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1715912, "time": 54040.11660671234, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1716200, "time": 54049.10356783867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1716240, "time": 54050.55592870712, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1716312, "time": 54052.55460476875, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1716488, "time": 54057.979986190796, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1716496, "time": 54058.45590376854, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1716752, "time": 54066.36757183075, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1716768, "time": 54066.864542245865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1717000, "time": 54073.899774074554, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1717032, "time": 54074.88750529289, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1717176, "time": 54079.30354475975, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1717392, "time": 54086.16061258316, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1717416, "time": 54086.67738366127, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1717704, "time": 54095.518059015274, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1717712, "time": 54096.01857972145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1717752, "time": 54097.03523015976, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1717976, "time": 54104.07820105553, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1718416, "time": 54117.80969667435, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1718416, "time": 54117.81833219528, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1718480, "time": 54119.78033351898, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1718504, "time": 54120.2961294651, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1718728, "time": 54127.20379257202, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1718928, "time": 54133.54847383499, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1718992, "time": 54135.63785767555, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1719152, "time": 54140.54137134552, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1719296, "time": 54144.94423699379, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1719344, "time": 54146.430857658386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1719624, "time": 54154.77920770645, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1719704, "time": 54157.23583006859, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1719720, "time": 54157.730033159256, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1719952, "time": 54165.22029018402, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1720056, "time": 54169.33315706253, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1720056, "time": 54169.5829846859, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 1720056, "time": 54169.7686817646, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1720056, "time": 54170.19765043259, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 1720056, "time": 54170.409605264664, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1720056, "time": 54170.53645300865, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 1720056, "time": 54171.4042198658, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1720056, "time": 54171.701184511185, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1720136, "time": 54174.17555141449, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1720200, "time": 54176.13833618164, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1720272, "time": 54178.59469413757, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1720520, "time": 54186.46249675751, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1720536, "time": 54186.96554040909, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 1720552, "time": 54187.46206355095, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1720616, "time": 54189.44150209427, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1720656, "time": 54190.88939189911, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1720688, "time": 54191.86786174774, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1721016, "time": 54201.80090332031, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1721192, "time": 54207.20894551277, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1721304, "time": 54210.669475317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1721376, "time": 54213.093494176865, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1721664, "time": 54221.94031524658, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1721896, "time": 54228.98919463158, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1721920, "time": 54229.95593523979, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1722008, "time": 54232.42532134056, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1722040, "time": 54233.431452035904, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1722072, "time": 54234.41552376747, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1722328, "time": 54242.30769634247, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1722360, "time": 54243.30658316612, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1722400, "time": 54244.750148534775, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1722464, "time": 54246.724588871, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1722728, "time": 54254.719744205475, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1722800, "time": 54257.13856172562, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1722864, "time": 54259.119124889374, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 1722896, "time": 54260.102913856506, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1723256, "time": 54270.91298341751, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1723408, "time": 54275.8325586319, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1723432, "time": 54276.350373506546, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1723496, "time": 54278.34999489784, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1723512, "time": 54278.84837412834, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1723616, "time": 54282.266743183136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1723664, "time": 54283.865393161774, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1724072, "time": 54296.18127274513, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1724088, "time": 54296.67285990715, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1724208, "time": 54300.582864284515, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1724217, "time": 54304.35795998573, "train_stats/mean_log_entropy": 0.07823051468067961, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.176191933790044, "train/action_min": 0.0, "train/action_std": 1.7989122496178402, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00987174920620743, "train/actor_opt_grad_steps": 106670.0, "train/actor_opt_loss": -33.67790556672829, "train/adv_mag": 0.7935716674555486, "train/adv_max": 0.2903359667140635, "train/adv_mean": 0.000219634431355806, "train/adv_min": -0.7400711936567297, "train/adv_std": 0.03163715608268228, "train/cont_avg": 0.9925555511934674, "train/cont_loss_mean": 0.03183832129547794, "train/cont_loss_std": 0.31369254779276534, "train/cont_neg_acc": 0.08861126484882892, "train/cont_neg_loss": 3.3812934453762957, "train/cont_pos_acc": 0.999836788405126, "train/cont_pos_loss": 0.006792081339780859, "train/cont_pred": 0.992655014871952, "train/cont_rate": 0.9925555511934674, "train/dyn_loss_mean": 1.0000093797942502, "train/dyn_loss_std": 9.802599880234783e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09119945641925287, "train/extr_critic_critic_opt_grad_steps": 106670.0, "train/extr_critic_critic_opt_loss": 12517.132915554334, "train/extr_critic_mag": 1.9776611771415826, "train/extr_critic_max": 1.9776611771415826, "train/extr_critic_mean": 1.845175433398491, "train/extr_critic_min": 1.5861909605150846, "train/extr_critic_std": 0.03208088206511047, "train/extr_return_normed_mag": 0.820809837561756, "train/extr_return_normed_max": 0.31798867783953794, "train/extr_return_normed_mean": 0.06998781631490093, "train/extr_return_normed_min": -0.686162595772863, "train/extr_return_normed_std": 0.045896927484465604, "train/extr_return_rate": 0.999808634345855, "train/extr_return_raw_mag": 2.0933959346320763, "train/extr_return_raw_max": 2.0933959346320763, "train/extr_return_raw_mean": 1.8453951684673826, "train/extr_return_raw_min": 1.089244661019675, "train/extr_return_raw_std": 0.04589692750318566, "train/extr_reward_mag": 0.27123051612221416, "train/extr_reward_max": 0.27123051612221416, "train/extr_reward_mean": 0.0031796035721860638, "train/extr_reward_min": 2.0067895477141568e-07, "train/extr_reward_std": 0.009575237840619968, "train/image_loss_mean": 0.08714390637811704, "train/image_loss_std": 0.10417629059535174, "train/model_loss_mean": 0.7485409897176465, "train/model_loss_std": 0.6297870567396059, "train/model_opt_grad_norm": 12.438395346828441, "train/model_opt_grad_steps": 106573.50753768845, "train/model_opt_loss": 4531.183521366599, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6055.276381909548, "train/policy_entropy_mag": 1.181264168653057, "train/policy_entropy_max": 1.181264168653057, "train/policy_entropy_mean": 0.08452471154718542, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09514932031158227, "train/policy_logprob_mag": 6.551080272425359, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08457761871904584, "train/policy_logprob_min": -6.551080272425359, "train/policy_logprob_std": 0.6220323760904859, "train/policy_randomness_mag": 0.6070497341491469, "train/policy_randomness_max": 0.6070497341491469, "train/policy_randomness_mean": 0.043437113826298834, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.04889708074118624, "train/post_ent_mag": 75.00665448059388, "train/post_ent_max": 75.00665448059388, "train/post_ent_mean": 61.3360291869197, "train/post_ent_min": 45.50745531781834, "train/post_ent_std": 6.444749103718666, "train/prior_ent_mag": 74.89134883401383, "train/prior_ent_max": 74.89134883401383, "train/prior_ent_mean": 61.68441887476936, "train/prior_ent_min": 46.381904544542785, "train/prior_ent_std": 6.198336174739665, "train/rep_loss_mean": 1.0000093797942502, "train/rep_loss_std": 9.802599880234783e-05, "train/reward_avg": 0.004188161871300065, "train/reward_loss_mean": 0.029553111637919093, "train/reward_loss_std": 0.3177142852739473, "train/reward_max_data": 0.843451633824775, "train/reward_max_pred": 0.32203689112735157, "train/reward_neg_acc": 0.9992692479536162, "train/reward_neg_loss": 0.005448428793440587, "train/reward_pos_acc": 0.1230854180140711, "train/reward_pos_loss": 3.9834488222946476, "train/reward_pred": 0.003208752757233179, "train/reward_rate": 0.006006595477386935, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.02853231504559517, "report/cont_loss_std": 0.2644127309322357, "report/cont_neg_acc": 0.125, "report/cont_neg_loss": 2.739001750946045, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.007190037053078413, "report/cont_pred": 0.9918508529663086, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07686048746109009, "report/image_loss_std": 0.10025268793106079, "report/model_loss_mean": 0.7333277463912964, "report/model_loss_std": 0.5726962685585022, "report/post_ent_mag": 75.1539077758789, "report/post_ent_max": 75.1539077758789, "report/post_ent_mean": 59.25877380371094, "report/post_ent_min": 42.209808349609375, "report/post_ent_std": 7.041523456573486, "report/prior_ent_mag": 74.86654663085938, "report/prior_ent_max": 74.86654663085938, "report/prior_ent_mean": 60.089263916015625, "report/prior_ent_min": 44.731449127197266, "report/prior_ent_std": 6.504910945892334, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0038238526321947575, "report/reward_loss_mean": 0.027934905141592026, "report/reward_loss_std": 0.29747140407562256, "report/reward_max_data": 0.949999988079071, "report/reward_max_pred": 0.07572221755981445, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.005614176858216524, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.81501841545105, "report/reward_pred": 0.0030938484705984592, "report/reward_rate": 0.005859375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.03490808606147766, "eval/cont_loss_std": 0.42055636644363403, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.144149303436279, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.009838211350142956, "eval/cont_pred": 0.9903392195701599, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10374648869037628, "eval/image_loss_std": 0.12037388980388641, "eval/model_loss_mean": 0.7643179893493652, "eval/model_loss_std": 0.6520064473152161, "eval/post_ent_mag": 75.16370391845703, "eval/post_ent_max": 75.16370391845703, "eval/post_ent_mean": 60.949501037597656, "eval/post_ent_min": 45.211185455322266, "eval/post_ent_std": 6.575279235839844, "eval/prior_ent_mag": 75.17581176757812, "eval/prior_ent_max": 75.17581176757812, "eval/prior_ent_mean": 61.746124267578125, "eval/prior_ent_min": 47.27643966674805, "eval/prior_ent_std": 5.961399555206299, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0029663085006177425, "eval/reward_loss_mean": 0.02566344663500786, "eval/reward_loss_std": 0.28506025671958923, "eval/reward_max_data": 0.8374999761581421, "eval/reward_max_pred": 0.12872040271759033, "eval/reward_neg_acc": 0.9980391263961792, "eval/reward_neg_loss": 0.008185244165360928, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.48260498046875, "eval/reward_pred": 0.004263072274625301, "eval/reward_rate": 0.00390625, "replay/size": 1000000.0, "replay/inserts": 31904.0, "replay/samples": 31904.0, "replay/insert_wait_avg": 1.367940048994487e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.655788047622175e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4072.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2352447847017838e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.296401023864746e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.455970287323, "timer/env.step_count": 3988.0, "timer/env.step_total": 40.85574126243591, "timer/env.step_frac": 0.04083712074875466, "timer/env.step_avg": 0.010244669323579718, "timer/env.step_min": 0.008291959762573242, "timer/env.step_max": 0.03619194030761719, "timer/replay._sample_count": 31904.0, "timer/replay._sample_total": 18.2961745262146, "timer/replay._sample_frac": 0.01828783581646285, "timer/replay._sample_avg": 0.0005734758815889732, "timer/replay._sample_min": 0.0004379749298095703, "timer/replay._sample_max": 0.013196945190429688, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4497.0, "timer/agent.policy_total": 50.376131772994995, "timer/agent.policy_frac": 0.05035317222258904, "timer/agent.policy_avg": 0.011202164058927062, "timer/agent.policy_min": 0.00909423828125, "timer/agent.policy_max": 0.09992051124572754, "timer/dataset_train_count": 1994.0, "timer/dataset_train_total": 0.28770971298217773, "timer/dataset_train_frac": 0.00028757858569183187, "timer/dataset_train_avg": 0.000144287719650039, "timer/dataset_train_min": 0.00010919570922851562, "timer/dataset_train_max": 0.0350034236907959, "timer/agent.train_count": 1994.0, "timer/agent.train_total": 896.3358273506165, "timer/agent.train_frac": 0.8959273111171459, "timer/agent.train_avg": 0.4495164630645017, "timer/agent.train_min": 0.43936991691589355, "timer/agent.train_max": 0.8047490119934082, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4834127426147461, "timer/agent.report_frac": 0.00048319242122760663, "timer/agent.report_avg": 0.24170637130737305, "timer/agent.report_min": 0.23405838012695312, "timer/agent.report_max": 0.24935436248779297, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.220008850097656e-05, "timer/dataset_eval_frac": 4.218085528427306e-08, "timer/dataset_eval_avg": 4.220008850097656e-05, "timer/dataset_eval_min": 4.220008850097656e-05, "timer/dataset_eval_max": 4.220008850097656e-05, "fps": 31.888641501234055}
{"step": 1724288, "time": 54306.58957409859, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1724496, "time": 54312.98374557495, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1724688, "time": 54318.990648031235, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1724744, "time": 54320.48270368576, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1724824, "time": 54322.944927453995, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1724928, "time": 54326.35505819321, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1724992, "time": 54328.31194138527, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1725040, "time": 54329.799144506454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1725312, "time": 54338.31762480736, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1725464, "time": 54342.773607969284, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1725488, "time": 54343.789690732956, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1725592, "time": 54346.8291182518, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1725632, "time": 54348.27458524704, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1725744, "time": 54351.72507596016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1725824, "time": 54354.17723727226, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1725840, "time": 54354.68066596985, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1725944, "time": 54357.66356277466, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1726008, "time": 54359.62418317795, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1726328, "time": 54369.522849321365, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1726472, "time": 54374.07733750343, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1726584, "time": 54377.56703329086, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1726992, "time": 54390.46357488632, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1727080, "time": 54393.00248193741, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1727088, "time": 54393.4805791378, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1727328, "time": 54400.94792962074, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1727392, "time": 54402.95581436157, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1727640, "time": 54410.55553030968, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1727688, "time": 54412.0459151268, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1727904, "time": 54418.91356801987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1727920, "time": 54419.41291975975, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1727944, "time": 54419.935431718826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1728040, "time": 54422.934309244156, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1728072, "time": 54423.93011498451, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1728200, "time": 54427.88509893417, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1728248, "time": 54429.36793375015, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1728424, "time": 54434.91147208214, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1728744, "time": 54445.27793216705, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1728768, "time": 54446.2618329525, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1728944, "time": 54451.677595853806, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1729144, "time": 54457.60304522514, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1729280, "time": 54462.014659166336, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1729400, "time": 54465.61993265152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1729632, "time": 54472.97115063667, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1729720, "time": 54475.48027396202, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1729736, "time": 54475.97607755661, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1730040, "time": 54486.59091758728, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 1730040, "time": 54487.0126683712, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1730040, "time": 54487.47826933861, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 1730040, "time": 54487.74290919304, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1730040, "time": 54487.81452536583, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1730040, "time": 54488.274193286896, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 1730040, "time": 54488.53713321686, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 1730040, "time": 54488.89774847031, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1730104, "time": 54490.85347342491, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1730256, "time": 54495.884732961655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1730256, "time": 54495.892391204834, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1730376, "time": 54499.35288357735, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1730568, "time": 54505.22027158737, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1730592, "time": 54506.180949926376, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1730608, "time": 54506.67459201813, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1730736, "time": 54510.604009866714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1730896, "time": 54515.519735336304, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1731032, "time": 54519.47881650925, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1731088, "time": 54521.43544793129, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1731304, "time": 54528.0027244091, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1731368, "time": 54529.98359632492, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1731528, "time": 54534.936470746994, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1731592, "time": 54536.89074802399, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1731912, "time": 54546.70394062996, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1731944, "time": 54547.682720422745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1731952, "time": 54548.17563915253, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1732368, "time": 54561.10788965225, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1732616, "time": 54568.51783442497, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1732616, "time": 54568.527082681656, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1732960, "time": 54579.30621480942, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1732992, "time": 54580.29074573517, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1733048, "time": 54581.775624752045, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 1733344, "time": 54591.18067741394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1733400, "time": 54592.69229722023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1733488, "time": 54595.59650206566, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1733576, "time": 54598.08868432045, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1733712, "time": 54602.47731757164, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1733840, "time": 54606.42018342018, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1734400, "time": 54623.71574091911, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1734544, "time": 54628.14265489578, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1734768, "time": 54635.026354551315, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1734928, "time": 54639.92130899429, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1735000, "time": 54641.916422367096, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1735152, "time": 54646.97161030769, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1735304, "time": 54651.391406059265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1735360, "time": 54653.361941576004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1735384, "time": 54653.88172006607, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1735560, "time": 54659.281672000885, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 1735592, "time": 54660.26629495621, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1735656, "time": 54662.27000927925, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1735712, "time": 54664.22488617897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1735776, "time": 54666.18878078461, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1735808, "time": 54667.186539411545, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1736000, "time": 54673.094887018204, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1736248, "time": 54680.62101459503, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1736400, "time": 54685.509806632996, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1736440, "time": 54686.54027581215, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1736488, "time": 54688.01838135719, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1736488, "time": 54688.02747321129, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1736576, "time": 54690.9412586689, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1736784, "time": 54697.863916397095, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1736880, "time": 54700.80861926079, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1736992, "time": 54704.35162830353, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 1737056, "time": 54706.307631254196, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1737208, "time": 54710.76519703865, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1737496, "time": 54719.61172294617, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1737544, "time": 54721.084513902664, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1737584, "time": 54722.56211519241, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1737640, "time": 54724.05940198898, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1737664, "time": 54725.02637839317, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1737672, "time": 54725.05577015877, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1737968, "time": 54734.49048829079, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1738056, "time": 54736.98464131355, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1738104, "time": 54738.4580347538, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1738176, "time": 54740.87393426895, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1738256, "time": 54743.3276925087, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1738296, "time": 54744.33158135414, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1738560, "time": 54752.63174891472, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1738800, "time": 54759.97990655899, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1738856, "time": 54761.48880934715, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1738912, "time": 54763.433183670044, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1739024, "time": 54767.011472940445, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1739120, "time": 54769.97336602211, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1739192, "time": 54771.9687461853, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1739192, "time": 54771.97873663902, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1739208, "time": 54772.47881102562, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1739544, "time": 54782.80290198326, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1739624, "time": 54785.27969098091, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1739904, "time": 54794.20268559456, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1740024, "time": 54798.10591554642, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 1740024, "time": 54798.23645734787, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 1740024, "time": 54798.24492287636, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 1740024, "time": 54800.22356247902, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 1740024, "time": 54800.35706090927, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 1740024, "time": 54800.94284391403, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 1740024, "time": 54801.38167834282, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 1740024, "time": 54801.98009133339, "eval_episode/length": 204.0, "eval_episode/score": 0.36250001192092896, "eval_episode/reward_rate": 0.004878048780487805}
{"step": 1740032, "time": 54802.45172762871, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1740120, "time": 54804.9476146698, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1740336, "time": 54811.81978392601, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1740528, "time": 54817.713416814804, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1740608, "time": 54820.171117305756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1741056, "time": 54834.02830314636, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1741104, "time": 54835.5107254982, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1741336, "time": 54842.402515888214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1741384, "time": 54843.87623500824, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1741520, "time": 54848.26935791969, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1741656, "time": 54852.24949002266, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1741832, "time": 54857.749237537384, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1742072, "time": 54865.084199905396, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1742120, "time": 54866.559388160706, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1742360, "time": 54873.92729640007, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1742392, "time": 54874.91450667381, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1742424, "time": 54875.91139912605, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1742608, "time": 54881.80148410797, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1742664, "time": 54883.31448316574, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 1742720, "time": 54885.39886832237, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1742840, "time": 54888.87637376785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1742960, "time": 54892.76207923889, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1743072, "time": 54896.20790672302, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1743208, "time": 54900.17937731743, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1743320, "time": 54903.61819601059, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1743616, "time": 54912.935923576355, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1743640, "time": 54913.46474981308, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1743728, "time": 54916.516342163086, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1743784, "time": 54918.007199048996, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1743840, "time": 54919.96391201019, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1743984, "time": 54924.367446660995, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1744216, "time": 54931.23931980133, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1744264, "time": 54932.71524429321, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1744384, "time": 54936.659507513046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1744664, "time": 54945.17926859856, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1744728, "time": 54947.164063453674, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1745072, "time": 54958.625245809555, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1745080, "time": 54958.65660595894, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1745112, "time": 54959.66278910637, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1745296, "time": 54965.56921482086, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1745320, "time": 54966.08506512642, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1745400, "time": 54968.54262590408, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1745592, "time": 54974.55460810661, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1745928, "time": 54984.846648693085, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1745952, "time": 54985.81075048447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1746008, "time": 54987.291974782944, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1746072, "time": 54989.27077913284, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1746096, "time": 54990.237845659256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1746360, "time": 54998.133439302444, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1746584, "time": 55005.145941734314, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1746960, "time": 55016.96123576164, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1747048, "time": 55019.45993185043, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1747056, "time": 55019.93539762497, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1747392, "time": 55030.27819943428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1747544, "time": 55034.831525325775, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1747632, "time": 55037.78119778633, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1747664, "time": 55038.76779341698, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 1747704, "time": 55039.7725584507, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1747896, "time": 55045.679527282715, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1747904, "time": 55046.152640104294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1748000, "time": 55049.10778474808, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1748488, "time": 55064.029309511185, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1748728, "time": 55071.388852119446, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1748744, "time": 55071.89088869095, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 1748816, "time": 55074.3771314621, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1748824, "time": 55074.40577840805, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1748928, "time": 55077.85089087486, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1748936, "time": 55077.880083322525, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1749000, "time": 55079.8532500267, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1749064, "time": 55081.80865716934, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1749248, "time": 55087.68867397308, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1749296, "time": 55089.1629216671, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1749496, "time": 55095.20662021637, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1749712, "time": 55102.06895637512, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1749840, "time": 55105.979172706604, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1750008, "time": 55111.7120244503, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 1750008, "time": 55112.45207667351, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1750008, "time": 55112.668305397034, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1750008, "time": 55112.862964868546, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1750008, "time": 55113.6738986969, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1750008, "time": 55113.80758070946, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 1750008, "time": 55114.172974824905, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1750008, "time": 55114.26335692406, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 1750080, "time": 55116.708535432816, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1750208, "time": 55120.65923380852, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1750216, "time": 55120.68826317787, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1750304, "time": 55123.635028123856, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1750520, "time": 55130.1510579586, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1750752, "time": 55137.49826550484, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1750800, "time": 55138.97256016731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1750912, "time": 55142.43834900856, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 1750968, "time": 55143.94168424606, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1751032, "time": 55145.9495010376, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1751104, "time": 55148.38010382652, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1751344, "time": 55155.87069487572, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1751368, "time": 55156.38792324066, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 1751400, "time": 55157.368178367615, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1751688, "time": 55166.17992448807, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1751696, "time": 55166.65527844429, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1751808, "time": 55170.10376596451, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1751976, "time": 55175.15091562271, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1752080, "time": 55178.56200480461, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1752360, "time": 55187.11066484451, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1752400, "time": 55188.55883765221, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1752480, "time": 55191.03928041458, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1752504, "time": 55191.55494308472, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1752592, "time": 55194.48594760895, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1752600, "time": 55194.51313853264, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1752688, "time": 55197.42506480217, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1752712, "time": 55197.9406247139, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1753040, "time": 55208.24925684929, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1753056, "time": 55208.74795174599, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1753088, "time": 55209.900289058685, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1753216, "time": 55214.28750562668, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1753280, "time": 55216.26547217369, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1753368, "time": 55218.747381687164, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1753368, "time": 55218.75656270981, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1753432, "time": 55220.75001549721, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1753504, "time": 55223.17417740822, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1753832, "time": 55232.98349404335, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1754136, "time": 55242.321380615234, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1754440, "time": 55251.76562285423, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1754472, "time": 55252.7421476841, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1754528, "time": 55254.714812994, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1754672, "time": 55259.16958737373, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1755000, "time": 55269.00894236565, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1755000, "time": 55269.0282728672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1755064, "time": 55270.99727344513, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1755096, "time": 55271.97962641716, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1755216, "time": 55276.026332616806, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1755328, "time": 55279.45333981514, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1755496, "time": 55284.36947989464, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1755552, "time": 55286.310353040695, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1755592, "time": 55287.33216404915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1755704, "time": 55290.77085042, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1755808, "time": 55294.26582098007, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1755904, "time": 55297.206530332565, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1756025, "time": 55301.763080358505, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.14950270149576, "train/action_min": 0.0, "train/action_std": 1.7749632297448776, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010505530875569312, "train/actor_opt_grad_steps": 108660.0, "train/actor_opt_loss": -37.50999205316131, "train/adv_mag": 0.7662557579165128, "train/adv_max": 0.31738856329989795, "train/adv_mean": 0.000509037433983568, "train/adv_min": -0.7016732141600183, "train/adv_std": 0.03242577755608451, "train/cont_avg": 0.9926880496231156, "train/cont_loss_mean": 0.031154112768682404, "train/cont_loss_std": 0.30679056317961995, "train/cont_neg_acc": 0.09515670196494865, "train/cont_neg_loss": 3.320967540669082, "train/cont_pos_acc": 0.9998319643226701, "train/cont_pos_loss": 0.006997129786291614, "train/cont_pred": 0.9924136696748398, "train/cont_rate": 0.9926880496231156, "train/dyn_loss_mean": 1.0000017557910938, "train/dyn_loss_std": 5.618131520044077e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10204220909494252, "train/extr_critic_critic_opt_grad_steps": 108660.0, "train/extr_critic_critic_opt_loss": 12220.246756242148, "train/extr_critic_mag": 1.9965822217452467, "train/extr_critic_max": 1.9965822217452467, "train/extr_critic_mean": 1.8545706062460665, "train/extr_critic_min": 1.5494683471756365, "train/extr_critic_std": 0.0356264490278522, "train/extr_return_normed_mag": 0.771016539940283, "train/extr_return_normed_max": 0.31283160789528086, "train/extr_return_normed_mean": 0.07856125259144821, "train/extr_return_normed_min": -0.6354430084252477, "train/extr_return_normed_std": 0.048777305881431955, "train/extr_return_rate": 0.9998119036156927, "train/extr_return_raw_mag": 2.0893499401945563, "train/extr_return_raw_max": 2.0893499401945563, "train/extr_return_raw_mean": 1.8550796856233223, "train/extr_return_raw_min": 1.1410753238740279, "train/extr_return_raw_std": 0.048777305853351875, "train/extr_reward_mag": 0.24684990890062036, "train/extr_reward_max": 0.24684990890062036, "train/extr_reward_mean": 0.0033257438803569006, "train/extr_reward_min": 1.7851441349815484e-07, "train/extr_reward_std": 0.009885038969916615, "train/image_loss_mean": 0.08494957798539694, "train/image_loss_std": 0.10237683209791855, "train/model_loss_mean": 0.7447222486213224, "train/model_loss_std": 0.6168141962595322, "train/model_opt_grad_norm": 12.670291831145933, "train/model_opt_grad_steps": 108561.88442211055, "train/model_opt_loss": 4641.240545991677, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6256.281407035176, "train/policy_entropy_mag": 1.180120357316942, "train/policy_entropy_max": 1.180120357316942, "train/policy_entropy_mean": 0.0845818646514236, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09560059613768179, "train/policy_logprob_mag": 6.551080262840693, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08445072847994128, "train/policy_logprob_min": -6.551080262840693, "train/policy_logprob_std": 0.6211207101692506, "train/policy_randomness_mag": 0.6064619332102675, "train/policy_randomness_max": 0.6064619332102675, "train/policy_randomness_mean": 0.04346648472637387, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.04912899073269499, "train/post_ent_mag": 76.23471613744995, "train/post_ent_max": 76.23471613744995, "train/post_ent_mean": 61.102139573600425, "train/post_ent_min": 44.17751783821451, "train/post_ent_std": 6.914813372358005, "train/prior_ent_mag": 76.08507511004731, "train/prior_ent_max": 76.08507511004731, "train/prior_ent_mean": 61.48973489885953, "train/prior_ent_min": 45.14419969721655, "train/prior_ent_std": 6.711850099228135, "train/rep_loss_mean": 1.0000017557910938, "train/rep_loss_std": 5.618131520044077e-05, "train/reward_avg": 0.004039024479626374, "train/reward_loss_mean": 0.02861748184147642, "train/reward_loss_std": 0.31137602815601095, "train/reward_max_data": 0.8459013799327103, "train/reward_max_pred": 0.3553021487279154, "train/reward_neg_acc": 0.9992991679876893, "train/reward_neg_loss": 0.0057441243602327965, "train/reward_pos_acc": 0.1479993793907477, "train/reward_pos_loss": 3.939609000431233, "train/reward_pred": 0.003370382883305189, "train/reward_rate": 0.005825023555276382, "train_stats/mean_log_entropy": 0.07853620681984752, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.03275267779827118, "report/cont_loss_std": 0.35994112491607666, "report/cont_neg_acc": 0.1428571492433548, "report/cont_neg_loss": 3.9034500122070312, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0061107114888727665, "report/cont_pred": 0.9929860830307007, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0824398398399353, "report/image_loss_std": 0.09942242503166199, "report/model_loss_mean": 0.7472641468048096, "report/model_loss_std": 0.756959080696106, "report/post_ent_mag": 75.96282958984375, "report/post_ent_max": 75.96282958984375, "report/post_ent_mean": 59.876121520996094, "report/post_ent_min": 42.15948486328125, "report/post_ent_std": 6.848657131195068, "report/prior_ent_mag": 77.84197998046875, "report/prior_ent_max": 77.84197998046875, "report/prior_ent_mean": 61.540382385253906, "report/prior_ent_min": 43.31737518310547, "report/prior_ent_std": 7.210871696472168, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0030395505018532276, "report/reward_loss_mean": 0.03207159414887428, "report/reward_loss_std": 0.4005714952945709, "report/reward_max_data": 0.831250011920929, "report/reward_max_pred": 0.2485562562942505, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.004907932132482529, "report/reward_pos_acc": 0.1666666716337204, "report/reward_pos_loss": 4.640839576721191, "report/reward_pred": 0.00285888509824872, "report/reward_rate": 0.005859375, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.04469006881117821, "eval/cont_loss_std": 0.5337646007537842, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.182014465332031, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004238692577928305, "eval/cont_pred": 0.995632529258728, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12616950273513794, "eval/image_loss_std": 0.130559504032135, "eval/model_loss_mean": 0.8180491924285889, "eval/model_loss_std": 1.1042100191116333, "eval/post_ent_mag": 75.60555267333984, "eval/post_ent_max": 75.60555267333984, "eval/post_ent_mean": 59.512351989746094, "eval/post_ent_min": 43.897789001464844, "eval/post_ent_std": 7.066188335418701, "eval/prior_ent_mag": 77.4893569946289, "eval/prior_ent_max": 77.4893569946289, "eval/prior_ent_mean": 61.12841796875, "eval/prior_ent_min": 45.23744201660156, "eval/prior_ent_std": 7.355199337005615, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.005749511998146772, "eval/reward_loss_mean": 0.047189608216285706, "eval/reward_loss_std": 0.5379247665405273, "eval/reward_max_data": 0.840624988079071, "eval/reward_max_pred": 0.037283897399902344, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0036397071089595556, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.578027725219727, "eval/reward_pred": 0.002026202157139778, "eval/reward_rate": 0.0078125, "replay/size": 1000000.0, "replay/inserts": 31808.0, "replay/samples": 31808.0, "replay/insert_wait_avg": 1.341876549500095e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.557355937343728e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4208.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2253513807579591e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3262033462524414e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0602421760559, "timer/env.step_count": 3976.0, "timer/env.step_total": 40.45155119895935, "timer/env.step_frac": 0.04044911445628497, "timer/env.step_avg": 0.010173931388068247, "timer/env.step_min": 0.008350610733032227, "timer/env.step_max": 0.03587055206298828, "timer/replay._sample_count": 31808.0, "timer/replay._sample_total": 18.21998953819275, "timer/replay._sample_frac": 0.018218891992493793, "timer/replay._sample_avg": 0.0005728115423224581, "timer/replay._sample_min": 0.0004413127899169922, "timer/replay._sample_max": 0.012974262237548828, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4502.0, "timer/agent.policy_total": 50.40602517127991, "timer/agent.policy_frac": 0.05040298878555574, "timer/agent.policy_avg": 0.011196362765721881, "timer/agent.policy_min": 0.009280681610107422, "timer/agent.policy_max": 0.08777523040771484, "timer/dataset_train_count": 1988.0, "timer/dataset_train_total": 0.2549474239349365, "timer/dataset_train_frac": 0.00025493206627251783, "timer/dataset_train_avg": 0.00012824317099342883, "timer/dataset_train_min": 0.00010848045349121094, "timer/dataset_train_max": 0.004049062728881836, "timer/agent.train_count": 1988.0, "timer/agent.train_total": 893.9596834182739, "timer/agent.train_frac": 0.8939058325857299, "timer/agent.train_avg": 0.4496779091641217, "timer/agent.train_min": 0.4370274543762207, "timer/agent.train_max": 0.7318823337554932, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5322117805480957, "timer/agent.report_frac": 0.0005321797208836568, "timer/agent.report_avg": 0.26610589027404785, "timer/agent.report_min": 0.2596461772918701, "timer/agent.report_max": 0.2725656032562256, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.7416484967965414e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 31.805406614050387}
{"step": 1756040, "time": 55301.81757950783, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1756160, "time": 55306.27090096474, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1756184, "time": 55306.78836274147, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1756272, "time": 55309.75414657593, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1756440, "time": 55314.69248795509, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1756456, "time": 55315.18510603905, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1756768, "time": 55325.05066370964, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1757048, "time": 55333.40352892876, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1757136, "time": 55336.47603273392, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1757272, "time": 55340.42678022385, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1757376, "time": 55343.81845617294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1757448, "time": 55345.822957754135, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1757568, "time": 55349.71605634689, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1757632, "time": 55351.681809425354, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1757640, "time": 55351.71132230759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1757904, "time": 55360.033015728, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1757912, "time": 55360.063271045685, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1758056, "time": 55364.606090307236, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1758496, "time": 55378.333874464035, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1758768, "time": 55386.67998456955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1758856, "time": 55389.16896915436, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1758952, "time": 55392.09599375725, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1759056, "time": 55395.66785502434, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1759312, "time": 55403.522085905075, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1759384, "time": 55405.51128196716, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1759568, "time": 55411.38564133644, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1759880, "time": 55420.71401190758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1759888, "time": 55421.18383193016, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1759912, "time": 55421.70169186592, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1760096, "time": 55429.03325819969, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1760096, "time": 55429.37469267845, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1760096, "time": 55429.47150230408, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1760096, "time": 55429.49936962128, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1760096, "time": 55430.15830516815, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1760096, "time": 55430.30309700966, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 1760096, "time": 55431.1506960392, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1760096, "time": 55431.71319484711, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1760216, "time": 55435.17936205864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1760368, "time": 55440.04452419281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1760424, "time": 55441.53003191948, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1760488, "time": 55443.504286527634, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1760688, "time": 55449.83771777153, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1760856, "time": 55454.84758806229, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1760856, "time": 55454.85758519173, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1760952, "time": 55457.8445019722, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1760992, "time": 55459.28857111931, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1761152, "time": 55464.18869829178, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1761168, "time": 55464.68775010109, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1761168, "time": 55464.69682741165, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1761376, "time": 55471.562364816666, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1761664, "time": 55480.427820920944, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1761800, "time": 55484.52910614014, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1761936, "time": 55488.9234457016, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1762200, "time": 55496.837960481644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1762352, "time": 55501.71891832352, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1762392, "time": 55502.72668814659, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1762616, "time": 55509.6020219326, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1763024, "time": 55522.383759737015, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1763168, "time": 55526.826998233795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1763264, "time": 55529.795570611954, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1763480, "time": 55536.23599362373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1763480, "time": 55536.2455394268, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1763608, "time": 55540.17018175125, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1763664, "time": 55542.14062213898, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1763720, "time": 55543.661747694016, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1764096, "time": 55555.52508807182, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1764128, "time": 55556.521708488464, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1764248, "time": 55559.96180295944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1764344, "time": 55562.917875766754, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1764360, "time": 55563.41431450844, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1764472, "time": 55566.87359762192, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1764512, "time": 55568.32361483574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1764664, "time": 55572.76968336105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1764816, "time": 55577.80180025101, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1764920, "time": 55580.7601685524, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1764936, "time": 55581.26762628555, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1765368, "time": 55594.5715546608, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1765440, "time": 55597.05064702034, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1765560, "time": 55600.53757739067, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1765584, "time": 55601.50605845451, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1765992, "time": 55613.977077007294, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1766112, "time": 55617.89807796478, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1766120, "time": 55617.926366090775, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1766296, "time": 55623.35249090195, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1766328, "time": 55624.35299253464, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1766440, "time": 55627.805960178375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1766488, "time": 55629.28580904007, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1766552, "time": 55631.266177654266, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1767896, "time": 55672.70907473564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1767928, "time": 55673.70019316673, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1768104, "time": 55679.09302186966, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1768120, "time": 55679.61735749245, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 1768304, "time": 55685.52741217613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1768360, "time": 55687.017947912216, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 1768376, "time": 55687.5111951828, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1768424, "time": 55688.981860637665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1768464, "time": 55690.45569872856, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1768744, "time": 55698.9224190712, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1768800, "time": 55700.87723493576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1768992, "time": 55706.727353811264, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1768992, "time": 55706.73629951477, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1769000, "time": 55706.76865696907, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1769048, "time": 55708.23855757713, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1769112, "time": 55710.26685118675, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1769536, "time": 55724.184671640396, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1769744, "time": 55730.60477733612, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1769904, "time": 55735.531103372574, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1769928, "time": 55736.04466557503, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1770032, "time": 55739.46563887596, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1770080, "time": 55741.764389276505, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 1770080, "time": 55741.998232126236, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 1770080, "time": 55742.08965754509, "eval_episode/length": 14.0, "eval_episode/score": 0.956250011920929, "eval_episode/reward_rate": 0.06666666666666667}
{"step": 1770080, "time": 55742.138620615005, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1770080, "time": 55743.18601679802, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1770080, "time": 55743.8108253479, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1770080, "time": 55744.364721775055, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1770080, "time": 55745.02793598175, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 1770096, "time": 55745.528180122375, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1770192, "time": 55748.492465019226, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1770272, "time": 55750.94477343559, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1770464, "time": 55756.968514204025, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1770480, "time": 55757.45898246765, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1770672, "time": 55763.35955309868, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1770808, "time": 55767.31108093262, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1770880, "time": 55769.78076148033, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1771104, "time": 55776.649091243744, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1771304, "time": 55782.54242515564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1771496, "time": 55788.5510392189, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1771520, "time": 55789.513190984726, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1771680, "time": 55794.429493904114, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1771808, "time": 55798.381157159805, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1772144, "time": 55808.6961107254, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1772208, "time": 55810.63891649246, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1772328, "time": 55814.203803777695, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1772584, "time": 55822.042331933975, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 1772720, "time": 55826.42637205124, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1772760, "time": 55827.447085380554, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1772776, "time": 55827.94031381607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1772816, "time": 55829.39360880852, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1772992, "time": 55834.78750371933, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1773352, "time": 55845.6910200119, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1773408, "time": 55847.640159368515, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1773576, "time": 55852.556577682495, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1773656, "time": 55854.985659360886, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1773680, "time": 55855.94065594673, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1773832, "time": 55860.37566232681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1773936, "time": 55863.79036068916, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1773960, "time": 55864.310363054276, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1774120, "time": 55869.196558475494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1774272, "time": 55874.20465707779, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1774304, "time": 55875.18657040596, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1774472, "time": 55880.068565130234, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1774656, "time": 55885.91247868538, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1775024, "time": 55897.18932771683, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1775136, "time": 55900.61680817604, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1775472, "time": 55911.065579652786, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1775528, "time": 55912.55603766441, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1775576, "time": 55914.01969456673, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1775704, "time": 55917.94742465019, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1775720, "time": 55918.44423747063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1775760, "time": 55919.88650536537, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1776144, "time": 55931.74528670311, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1776272, "time": 55935.790143013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1776448, "time": 55941.16949415207, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1776584, "time": 55945.10649347305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1776768, "time": 55950.9797065258, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1777016, "time": 55958.36484646797, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1777288, "time": 55966.83448767662, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1777304, "time": 55967.33744978905, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1777592, "time": 55976.22668480873, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 1777784, "time": 55982.62603235245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1777840, "time": 55984.57981157303, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1777896, "time": 55986.106759786606, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1777992, "time": 55989.06275200844, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1778016, "time": 55990.03388428688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1778072, "time": 55991.57490515709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1778248, "time": 55997.177018880844, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1778368, "time": 56001.131617069244, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1778560, "time": 56007.06482505798, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1778632, "time": 56009.05560660362, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 1778648, "time": 56009.55653977394, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1778768, "time": 56013.516563892365, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1778824, "time": 56015.03766655922, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1778896, "time": 56017.504078149796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1778952, "time": 56019.00504851341, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1778960, "time": 56019.48309803009, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1779280, "time": 56029.50753760338, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1779520, "time": 56036.92424368858, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1779648, "time": 56040.89099764824, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1779720, "time": 56042.89199304581, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1779920, "time": 56049.308232069016, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1780064, "time": 56054.998051166534, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1780064, "time": 56055.391239881516, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1780064, "time": 56055.45989060402, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1780064, "time": 56055.86512517929, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 1780064, "time": 56055.89182281494, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1780064, "time": 56056.39236044884, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1780064, "time": 56056.619901418686, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1780064, "time": 56056.736992836, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 1780208, "time": 56061.19721007347, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1780328, "time": 56064.707251787186, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1780624, "time": 56074.09422874451, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 1780680, "time": 56075.59192061424, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1781000, "time": 56085.56873464584, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1781016, "time": 56086.06438207626, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1781072, "time": 56088.019748449326, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 1781072, "time": 56088.02955174446, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1781104, "time": 56089.02900481224, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1781296, "time": 56094.930916786194, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1781312, "time": 56095.4247610569, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1781520, "time": 56101.81931066513, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1781880, "time": 56112.685551166534, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1781896, "time": 56113.18439221382, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1782032, "time": 56117.6871342659, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1782240, "time": 56124.1217045784, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1782568, "time": 56133.898372888565, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1782744, "time": 56139.274851322174, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1782936, "time": 56145.24864411354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1782976, "time": 56146.68133330345, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1783240, "time": 56154.526822805405, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1783312, "time": 56156.95909166336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1783392, "time": 56159.4022166729, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1783624, "time": 56166.263199329376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1783736, "time": 56169.68477153778, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1783776, "time": 56171.140033721924, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1783920, "time": 56175.681303977966, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1783944, "time": 56176.20152974129, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1784088, "time": 56180.64273071289, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1784208, "time": 56184.56299614906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1784664, "time": 56198.27751708031, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1784808, "time": 56202.67636013031, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1784816, "time": 56203.148255348206, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1785016, "time": 56209.16710829735, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 1785032, "time": 56209.66748523712, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1785248, "time": 56216.61439013481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1785392, "time": 56220.9930062294, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1785488, "time": 56223.92234826088, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1785608, "time": 56227.45896577835, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1785696, "time": 56230.42259430885, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1785720, "time": 56230.95560359955, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1786000, "time": 56240.345376968384, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1786104, "time": 56243.31075167656, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1786320, "time": 56250.13896250725, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1786352, "time": 56251.13846874237, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1786400, "time": 56252.60219454765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1786624, "time": 56259.44166755676, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1786728, "time": 56262.40531349182, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1786976, "time": 56270.37300944328, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1787080, "time": 56273.3432264328, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1787288, "time": 56279.69479894638, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1787664, "time": 56291.43925213814, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1787800, "time": 56295.53503704071, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1787840, "time": 56296.98249125481, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1787928, "time": 56299.44824910164, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1787968, "time": 56300.91345882416, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1787977, "time": 56302.13589978218, "train_stats/mean_log_entropy": 0.07896548387034115, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1642776489257813, "train/action_min": 0.0, "train/action_std": 1.7822497189044952, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01014767460525036, "train/actor_opt_grad_steps": 110655.0, "train/actor_opt_loss": -38.91063478469849, "train/adv_mag": 0.6998395943641662, "train/adv_max": 0.2899413019418716, "train/adv_mean": 0.0002091499115294937, "train/adv_min": -0.6417321807146072, "train/adv_std": 0.032928177500143645, "train/cont_avg": 0.992587890625, "train/cont_loss_mean": 0.03159207781311125, "train/cont_loss_std": 0.30745253708213566, "train/cont_neg_acc": 0.08686823073774576, "train/cont_neg_loss": 3.3328408801555636, "train/cont_pos_acc": 0.9998426511883736, "train/cont_pos_loss": 0.0069982940959744154, "train/cont_pred": 0.992436845600605, "train/cont_rate": 0.992587890625, "train/dyn_loss_mean": 1.0000004863739014, "train/dyn_loss_std": 1.2216042960062622e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09923766625113785, "train/extr_critic_critic_opt_grad_steps": 110655.0, "train/extr_critic_critic_opt_loss": 11714.213198242187, "train/extr_critic_mag": 2.0133294808864592, "train/extr_critic_max": 2.0133294808864592, "train/extr_critic_mean": 1.8697716301679612, "train/extr_critic_min": 1.5869198638200759, "train/extr_critic_std": 0.036033694688230755, "train/extr_return_normed_mag": 0.7260300678014755, "train/extr_return_normed_max": 0.3150984239578247, "train/extr_return_normed_mean": 0.08070758162066341, "train/extr_return_normed_min": -0.5689995354413986, "train/extr_return_normed_std": 0.04981251087039709, "train/extr_return_rate": 0.99978484749794, "train/extr_return_raw_mag": 2.10437160551548, "train/extr_return_raw_max": 2.10437160551548, "train/extr_return_raw_mean": 1.8699808353185654, "train/extr_return_raw_min": 1.2202736461162567, "train/extr_return_raw_std": 0.04981251107528806, "train/extr_reward_mag": 0.239430091381073, "train/extr_reward_max": 0.239430091381073, "train/extr_reward_mean": 0.0033322242286521944, "train/extr_reward_min": 2.0563602447509767e-07, "train/extr_reward_std": 0.0099397281720303, "train/image_loss_mean": 0.08553714375942946, "train/image_loss_std": 0.1028020248375833, "train/model_loss_mean": 0.7473149904608727, "train/model_loss_std": 0.632572772204876, "train/model_opt_grad_norm": 13.006110761165619, "train/model_opt_grad_steps": 110555.08, "train/model_opt_loss": 3867.7312060546874, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5200.0, "train/policy_entropy_mag": 1.171906259059906, "train/policy_entropy_max": 1.171906259059906, "train/policy_entropy_mean": 0.08283173169940711, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09130626622587443, "train/policy_logprob_mag": 6.551080272197724, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08309760987758637, "train/policy_logprob_min": -6.551080272197724, "train/policy_logprob_std": 0.6216426584124565, "train/policy_randomness_mag": 0.6022407197952271, "train/policy_randomness_max": 0.6022407197952271, "train/policy_randomness_mean": 0.042567093968391416, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.046922141276299956, "train/post_ent_mag": 76.52091331481934, "train/post_ent_max": 76.52091331481934, "train/post_ent_mean": 61.067960586547855, "train/post_ent_min": 43.50621822357178, "train/post_ent_std": 7.232807192802429, "train/prior_ent_mag": 76.95637283325195, "train/prior_ent_max": 76.95637283325195, "train/prior_ent_mean": 61.55435525894165, "train/prior_ent_min": 44.64916036605835, "train/prior_ent_std": 7.137027537822723, "train/rep_loss_mean": 1.0000004863739014, "train/rep_loss_std": 1.2216042960062622e-05, "train/reward_avg": 0.004190521229756996, "train/reward_loss_mean": 0.030185455619357527, "train/reward_loss_std": 0.3228684168681502, "train/reward_max_data": 0.8470312511920929, "train/reward_max_pred": 0.32302348971366884, "train/reward_neg_acc": 0.9992877635359764, "train/reward_neg_loss": 0.005710485996678472, "train/reward_pos_acc": 0.1131535017862916, "train/reward_pos_loss": 4.053046056032181, "train/reward_pred": 0.003309019756852649, "train/reward_rate": 0.0060302734375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.021266303956508636, "report/cont_loss_std": 0.23059247434139252, "report/cont_neg_acc": 0.1428571492433548, "report/cont_neg_loss": 2.2799572944641113, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00571975763887167, "report/cont_pred": 0.9927145838737488, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08733927458524704, "report/image_loss_std": 0.10904981940984726, "report/model_loss_mean": 0.7296242713928223, "report/model_loss_std": 0.5247734785079956, "report/post_ent_mag": 79.58528137207031, "report/post_ent_max": 79.58528137207031, "report/post_ent_mean": 62.644981384277344, "report/post_ent_min": 44.78437423706055, "report/post_ent_std": 8.228067398071289, "report/prior_ent_mag": 77.71196746826172, "report/prior_ent_max": 77.71196746826172, "report/prior_ent_mean": 61.27701187133789, "report/prior_ent_min": 44.85690689086914, "report/prior_ent_std": 7.972586154937744, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.003656005719676614, "report/reward_loss_mean": 0.021018730476498604, "report/reward_loss_std": 0.2697606384754181, "report/reward_max_data": 0.871874988079071, "report/reward_max_pred": 0.7656371593475342, "report/reward_neg_acc": 0.999018669128418, "report/reward_neg_loss": 0.005013759713619947, "report/reward_pos_acc": 0.4000000059604645, "report/reward_pos_loss": 3.282831907272339, "report/reward_pred": 0.0035484922118484974, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.03926348686218262, "eval/cont_loss_std": 0.4205172061920166, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.415727138519287, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00480314576998353, "eval/cont_pred": 0.9951424598693848, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1231519803404808, "eval/image_loss_std": 0.11750734597444534, "eval/model_loss_mean": 0.8082243204116821, "eval/model_loss_std": 0.9543764591217041, "eval/post_ent_mag": 79.46148681640625, "eval/post_ent_max": 79.46148681640625, "eval/post_ent_mean": 63.220985412597656, "eval/post_ent_min": 42.582969665527344, "eval/post_ent_std": 8.117247581481934, "eval/prior_ent_mag": 76.65878295898438, "eval/prior_ent_max": 76.65878295898438, "eval/prior_ent_mean": 61.842830657958984, "eval/prior_ent_min": 42.7850456237793, "eval/prior_ent_std": 7.698168754577637, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.005825805477797985, "eval/reward_loss_mean": 0.04580885171890259, "eval/reward_loss_std": 0.5033547282218933, "eval/reward_max_data": 0.893750011920929, "eval/reward_max_pred": 0.0880126953125, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.004044665023684502, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.349860191345215, "eval/reward_pred": 0.0022505978122353554, "eval/reward_rate": 0.0078125, "replay/size": 1000000.0, "replay/inserts": 31952.0, "replay/samples": 31952.0, "replay/insert_wait_avg": 2.091863361906874e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.580245302149696e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3808.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.278619806305701e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2814998626708984e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2292158603668, "timer/env.step_count": 3994.0, "timer/env.step_total": 40.49351143836975, "timer/env.step_frac": 0.04048423181034405, "timer/env.step_avg": 0.010138585738199738, "timer/env.step_min": 0.008346796035766602, "timer/env.step_max": 0.03843259811401367, "timer/replay._sample_count": 31952.0, "timer/replay._sample_total": 18.06891632080078, "timer/replay._sample_frac": 0.01806477558772211, "timer/replay._sample_avg": 0.0005655018878568096, "timer/replay._sample_min": 0.0004429817199707031, "timer/replay._sample_max": 0.01206517219543457, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4470.0, "timer/agent.policy_total": 50.62566637992859, "timer/agent.policy_frac": 0.050614064833511115, "timer/agent.policy_avg": 0.011325652433988498, "timer/agent.policy_min": 0.00873422622680664, "timer/agent.policy_max": 0.1000828742980957, "timer/dataset_train_count": 1997.0, "timer/dataset_train_total": 0.2538635730743408, "timer/dataset_train_frac": 0.00025380539685193566, "timer/dataset_train_avg": 0.00012712247024253422, "timer/dataset_train_min": 0.00010609626770019531, "timer/dataset_train_max": 0.0010521411895751953, "timer/agent.train_count": 1997.0, "timer/agent.train_total": 896.4379835128784, "timer/agent.train_frac": 0.8962325527972003, "timer/agent.train_avg": 0.4488923302518169, "timer/agent.train_min": 0.4349050521850586, "timer/agent.train_max": 0.6970674991607666, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5107569694519043, "timer/agent.report_frac": 0.000510639922682689, "timer/agent.report_avg": 0.25537848472595215, "timer/agent.report_min": 0.25325775146484375, "timer/agent.report_max": 0.25749921798706055, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.07489485574026e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 31.94403326029401}
{"step": 1788248, "time": 56310.33342027664, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 1788272, "time": 56311.32532787323, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1788320, "time": 56312.80170869827, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 1788392, "time": 56314.79132437706, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1788448, "time": 56316.75850057602, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1788520, "time": 56318.74297738075, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1788680, "time": 56323.69683814049, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1788832, "time": 56328.65174007416, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1788888, "time": 56330.146018743515, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1788952, "time": 56332.12153363228, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1788976, "time": 56333.07979750633, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1789064, "time": 56335.54665017128, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1789216, "time": 56340.421706438065, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1789336, "time": 56343.887102365494, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1789416, "time": 56346.38030576706, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1789472, "time": 56348.31957530975, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1789512, "time": 56349.32142186165, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1789824, "time": 56359.25399684906, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1789936, "time": 56362.68970298767, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1789960, "time": 56363.20923423767, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1790048, "time": 56367.18784093857, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 1790048, "time": 56367.547353982925, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1790048, "time": 56368.01682972908, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1790048, "time": 56368.35128426552, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 1790048, "time": 56368.39999914169, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1790048, "time": 56368.42752504349, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 1790048, "time": 56369.34396648407, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1790048, "time": 56369.96294546127, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1790280, "time": 56376.86584401131, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1790312, "time": 56377.8663790226, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1790368, "time": 56379.82149243355, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1790648, "time": 56388.27094697952, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1790824, "time": 56393.667555332184, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1790824, "time": 56393.6784427166, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1790840, "time": 56394.19441962242, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 1791000, "time": 56399.08618879318, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1791192, "time": 56404.94693374634, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1791224, "time": 56405.94235992432, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1791264, "time": 56407.390691280365, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1791344, "time": 56409.8588821888, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1791472, "time": 56413.91446065903, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1791536, "time": 56415.886533498764, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1791688, "time": 56420.34778380394, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1791728, "time": 56421.81418681145, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1791968, "time": 56429.204874038696, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1791984, "time": 56429.699556827545, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1792016, "time": 56430.69065499306, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1792024, "time": 56430.72019171715, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1792040, "time": 56431.21453166008, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1792056, "time": 56431.711926698685, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1792416, "time": 56442.976469516754, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1792488, "time": 56445.105016469955, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1792624, "time": 56449.50444817543, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1792768, "time": 56453.91398239136, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1792832, "time": 56455.87412405014, "episode/length": 7.0, "episode/score": 0.9781249761581421, "episode/reward_rate": 0.125, "episode/intrinsic_return": 0.0}
{"step": 1792848, "time": 56456.36663722992, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1792856, "time": 56456.39404821396, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1792872, "time": 56456.88625383377, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1792880, "time": 56457.36037445068, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1793064, "time": 56462.756232500076, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1793096, "time": 56463.75661492348, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1793776, "time": 56484.914065122604, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1793784, "time": 56484.94244194031, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1793832, "time": 56486.42117381096, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1793848, "time": 56486.91474342346, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1794040, "time": 56492.80086827278, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1794136, "time": 56496.28888010979, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1794280, "time": 56500.69357919693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1794336, "time": 56502.62699723244, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1794344, "time": 56502.655467271805, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1794616, "time": 56511.08589506149, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1794672, "time": 56513.040895462036, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1794752, "time": 56515.489924669266, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1794832, "time": 56517.96079874039, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1794928, "time": 56520.891954422, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1794928, "time": 56520.90067887306, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1794976, "time": 56522.375245809555, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1795096, "time": 56525.85727477074, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1795288, "time": 56531.74846339226, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1795424, "time": 56536.27073931694, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1795448, "time": 56536.78463578224, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1795488, "time": 56538.24161338806, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1795672, "time": 56543.63161587715, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1795880, "time": 56549.99593377113, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1796064, "time": 56555.86055636406, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1796104, "time": 56556.867168188095, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1796192, "time": 56559.80435705185, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1796272, "time": 56562.269862651825, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1796664, "time": 56574.208084106445, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1796776, "time": 56577.649864673615, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1796880, "time": 56581.05010390282, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1796896, "time": 56581.54573106766, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1796912, "time": 56582.06060504913, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1797152, "time": 56589.40347766876, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1797448, "time": 56598.36196422577, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 1797552, "time": 56601.7968351841, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1797600, "time": 56603.26543688774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1797616, "time": 56603.75876259804, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1797752, "time": 56607.725504398346, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1797856, "time": 56611.15985250473, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1798128, "time": 56619.530963897705, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1798344, "time": 56626.05150151253, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1798384, "time": 56627.5269677639, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1798744, "time": 56638.37873458862, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1798752, "time": 56638.85456395149, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 1798760, "time": 56638.882581710815, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1798808, "time": 56640.3442902565, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1798848, "time": 56641.81654572487, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1798976, "time": 56645.73330593109, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1799320, "time": 56656.173661231995, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1799352, "time": 56657.15403175354, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1799784, "time": 56670.389268398285, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1799840, "time": 56672.359407663345, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1799864, "time": 56672.87771773338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1800032, "time": 56679.27565717697, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 1800032, "time": 56679.806099653244, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1800032, "time": 56679.987060546875, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1800032, "time": 56680.013182640076, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1800032, "time": 56680.11775350571, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1800032, "time": 56680.74585056305, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 1800032, "time": 56680.894839048386, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1800032, "time": 56681.25091791153, "eval_episode/length": 16.0, "eval_episode/score": 0.949999988079071, "eval_episode/reward_rate": 0.058823529411764705}
{"step": 1800064, "time": 56682.24147415161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1800240, "time": 56687.734590530396, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1800264, "time": 56688.247916698456, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1800576, "time": 56698.04689908028, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1800592, "time": 56698.56302309036, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1800856, "time": 56706.437782764435, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1800904, "time": 56707.913898944855, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1800936, "time": 56708.91357278824, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1801064, "time": 56712.81707525253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1801240, "time": 56718.3338971138, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1801240, "time": 56718.34544467926, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1801288, "time": 56719.8199338913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1801544, "time": 56727.65777397156, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1801680, "time": 56732.077145814896, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1801712, "time": 56733.076620578766, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1801744, "time": 56734.05251002312, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1801752, "time": 56734.08091211319, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1801776, "time": 56735.04597568512, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1802152, "time": 56746.53897023201, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1802288, "time": 56751.48655104637, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1802296, "time": 56751.514336586, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1802312, "time": 56752.005141973495, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1802336, "time": 56752.96310687065, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1802336, "time": 56752.97234749794, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1802576, "time": 56760.351613759995, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1802744, "time": 56765.286165475845, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1802832, "time": 56768.218445301056, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1802984, "time": 56772.63474535942, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1803032, "time": 56774.2328953743, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1803056, "time": 56775.19208264351, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1803184, "time": 56779.12976241112, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1803272, "time": 56781.59245109558, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1803736, "time": 56795.89419198036, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1803776, "time": 56797.341918468475, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1803912, "time": 56801.30236816406, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1804168, "time": 56809.264960289, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1804480, "time": 56819.10319375992, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 1804760, "time": 56827.48144817352, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1804888, "time": 56831.39713096619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1804944, "time": 56833.38105082512, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1805368, "time": 56846.312057971954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1805424, "time": 56848.272434711456, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1805504, "time": 56850.71556472778, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1805816, "time": 56860.05138659477, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1806072, "time": 56868.03150558472, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 1806088, "time": 56868.5279841423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1806224, "time": 56872.94324350357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1806632, "time": 56885.32094192505, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1806792, "time": 56890.278138160706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1806880, "time": 56893.216181993484, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1806976, "time": 56896.26353955269, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1807256, "time": 56904.60863518715, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1807256, "time": 56904.61868572235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1807272, "time": 56905.11574602127, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1807448, "time": 56910.50608706474, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1807488, "time": 56911.985124349594, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1807544, "time": 56913.4752137661, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1807744, "time": 56919.82602548599, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1807792, "time": 56921.323782444, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1807816, "time": 56921.83966588974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1808160, "time": 56932.77938079834, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1808256, "time": 56935.72400307655, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1808400, "time": 56940.144896268845, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1808512, "time": 56943.59429526329, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1808568, "time": 56945.08495783806, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1809016, "time": 56958.94404506683, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1809104, "time": 56961.887044906616, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1809192, "time": 56964.37875843048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1809352, "time": 56969.26925635338, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1809456, "time": 56972.68017363548, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 1809536, "time": 56975.12515330315, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1810016, "time": 56990.52156949043, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 1810016, "time": 56991.4033768177, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1810016, "time": 56991.61564350128, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1810016, "time": 56991.974412202835, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1810016, "time": 56992.022501945496, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1810016, "time": 56992.070259809494, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1810016, "time": 56992.21364212036, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1810016, "time": 56992.25867152214, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1810104, "time": 56994.75564980507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1810224, "time": 56998.66639375687, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1810376, "time": 57003.11244177818, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1810576, "time": 57009.9449133873, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1810648, "time": 57011.92537069321, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1810712, "time": 57014.026749134064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1810840, "time": 57017.954674482346, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1810896, "time": 57019.885253190994, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 1811024, "time": 57023.83604192734, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1811144, "time": 57027.27649474144, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1811296, "time": 57032.17116332054, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1811552, "time": 57040.06848669052, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1811720, "time": 57045.14073610306, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1811880, "time": 57050.09630608559, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1811952, "time": 57052.555443525314, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1812320, "time": 57063.88057470322, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1812448, "time": 57067.82491803169, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1812456, "time": 57067.85375213623, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1812512, "time": 57069.787690877914, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1812536, "time": 57070.3031668663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1812568, "time": 57071.289858579636, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1812776, "time": 57077.860311985016, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1812888, "time": 57081.342141628265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1812928, "time": 57082.808884859085, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1813336, "time": 57095.06958723068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1813600, "time": 57103.44831609726, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1813600, "time": 57103.45772433281, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1813648, "time": 57105.04885530472, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1813904, "time": 57112.958914518356, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1814128, "time": 57119.85960006714, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1814256, "time": 57123.82056117058, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1814488, "time": 57130.74898457527, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1814664, "time": 57136.25063920021, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 1814696, "time": 57137.253450870514, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1814848, "time": 57142.19502902031, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1814880, "time": 57143.18482041359, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1814896, "time": 57143.678455114365, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1815072, "time": 57149.07664465904, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 1815376, "time": 57158.45011138916, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1815496, "time": 57161.928034067154, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1815568, "time": 57164.51662182808, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1815664, "time": 57167.51168513298, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1815720, "time": 57169.0114607811, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1816104, "time": 57181.02925777435, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1816120, "time": 57181.551518678665, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1816216, "time": 57184.52679634094, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 1816536, "time": 57194.55866217613, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1816624, "time": 57197.48262786865, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1816656, "time": 57198.46586871147, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1817008, "time": 57209.33413243294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1817152, "time": 57213.78757548332, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1817368, "time": 57220.20745587349, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1817392, "time": 57221.187133550644, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1817408, "time": 57221.68416428566, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 1817440, "time": 57222.66879582405, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1817640, "time": 57228.70015120506, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 1818048, "time": 57241.476798057556, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1818128, "time": 57243.928800821304, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1818152, "time": 57244.439606666565, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1818272, "time": 57248.37872672081, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1818680, "time": 57261.391217947006, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1819144, "time": 57275.691336393356, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1819224, "time": 57278.17704582214, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 1819280, "time": 57280.12934422493, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1819352, "time": 57282.14693570137, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1819440, "time": 57285.18620157242, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1819584, "time": 57289.6206703186, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1819768, "time": 57295.13809275627, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1819952, "time": 57301.055721998215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1819961, "time": 57302.18117403984, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.089892578125, "train/action_min": 0.0, "train/action_std": 1.7649763756990433, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011336749109905214, "train/actor_opt_grad_steps": 112655.0, "train/actor_opt_loss": -37.317749691009524, "train/adv_mag": 0.7106230056285858, "train/adv_max": 0.2904146033525467, "train/adv_mean": -0.00030786619938908186, "train/adv_min": -0.6601881343126297, "train/adv_std": 0.030734545718878507, "train/cont_avg": 0.99259765625, "train/cont_loss_mean": 0.0318453587917611, "train/cont_loss_std": 0.31292500495910647, "train/cont_neg_acc": 0.08501268357038498, "train/cont_neg_loss": 3.383504832983017, "train/cont_pos_acc": 0.9998770815134048, "train/cont_pos_loss": 0.0068410759489051995, "train/cont_pred": 0.9925680905580521, "train/cont_rate": 0.99259765625, "train/dyn_loss_mean": 1.0000005561113356, "train/dyn_loss_std": 1.5523923793807625e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10767142019700258, "train/extr_critic_critic_opt_grad_steps": 112655.0, "train/extr_critic_critic_opt_loss": 12616.184487304687, "train/extr_critic_mag": 1.991240350008011, "train/extr_critic_max": 1.991240350008011, "train/extr_critic_mean": 1.8389303588867187, "train/extr_critic_min": 1.5726961970329285, "train/extr_critic_std": 0.03497491357848048, "train/extr_return_normed_mag": 0.7344213581085205, "train/extr_return_normed_max": 0.31390175938606263, "train/extr_return_normed_mean": 0.07664056153967977, "train/extr_return_normed_min": -0.5851090049743652, "train/extr_return_normed_std": 0.04723231230862439, "train/extr_return_rate": 0.9998688319325447, "train/extr_return_raw_mag": 2.07588363468647, "train/extr_return_raw_max": 2.07588363468647, "train/extr_return_raw_mean": 1.8386225271224976, "train/extr_return_raw_min": 1.1768728703260423, "train/extr_return_raw_std": 0.047232312355190514, "train/extr_reward_mag": 0.22839025616645814, "train/extr_reward_max": 0.22839025616645814, "train/extr_reward_mean": 0.003291667267912999, "train/extr_reward_min": 1.531839370727539e-07, "train/extr_reward_std": 0.00954105508280918, "train/image_loss_mean": 0.08641045972704887, "train/image_loss_std": 0.10374996542930603, "train/model_loss_mean": 0.7479231756925583, "train/model_loss_std": 0.6307953287661076, "train/model_opt_grad_norm": 12.244691867828369, "train/model_opt_grad_steps": 112553.54, "train/model_opt_loss": 4613.535043945312, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6175.0, "train/policy_entropy_mag": 1.1719690877199174, "train/policy_entropy_max": 1.1719690877199174, "train/policy_entropy_mean": 0.08384623993188142, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09441929958760738, "train/policy_logprob_mag": 6.551080250740052, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08378981851041317, "train/policy_logprob_min": -6.551080250740052, "train/policy_logprob_std": 0.621709793806076, "train/policy_randomness_mag": 0.6022730073332787, "train/policy_randomness_max": 0.6022730073332787, "train/policy_randomness_mean": 0.04308844830840826, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.048521924521774056, "train/post_ent_mag": 76.4758818435669, "train/post_ent_max": 76.4758818435669, "train/post_ent_mean": 60.72308734893799, "train/post_ent_min": 43.44334909439087, "train/post_ent_std": 7.086675567626953, "train/prior_ent_mag": 75.63784633636475, "train/prior_ent_max": 75.63784633636475, "train/prior_ent_mean": 60.74255529403686, "train/prior_ent_min": 43.32847505569458, "train/prior_ent_std": 7.219086022377014, "train/rep_loss_mean": 1.0000005561113356, "train/rep_loss_std": 1.5523923793807625e-05, "train/reward_avg": 0.004183654783118982, "train/reward_loss_mean": 0.029667001338675617, "train/reward_loss_std": 0.31926327928900716, "train/reward_max_data": 0.8430625012516976, "train/reward_max_pred": 0.3279334062337875, "train/reward_neg_acc": 0.9994006669521331, "train/reward_neg_loss": 0.005594496013363823, "train/reward_pos_acc": 0.133106243647635, "train/reward_pos_loss": 3.9993206107616426, "train/reward_pred": 0.0033057438535615802, "train/reward_rate": 0.006015625, "train_stats/mean_log_entropy": 0.07902750213880365, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.025343026965856552, "report/cont_loss_std": 0.22171038389205933, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.169116735458374, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.009917248971760273, "report/cont_pred": 0.9901569485664368, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07361867278814316, "report/image_loss_std": 0.1015547588467598, "report/model_loss_mean": 0.7269940376281738, "report/model_loss_std": 0.5385896563529968, "report/post_ent_mag": 77.3106689453125, "report/post_ent_max": 77.3106689453125, "report/post_ent_mean": 62.67744445800781, "report/post_ent_min": 43.316383361816406, "report/post_ent_std": 6.869879722595215, "report/prior_ent_mag": 78.16145324707031, "report/prior_ent_max": 78.16145324707031, "report/prior_ent_mean": 62.78120422363281, "report/prior_ent_min": 43.19945526123047, "report/prior_ent_std": 7.3613600730896, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.003451538272202015, "report/reward_loss_mean": 0.028032278642058372, "report/reward_loss_std": 0.2817796468734741, "report/reward_max_data": 0.875, "report/reward_max_pred": 0.06666576862335205, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008384515531361103, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.0322465896606445, "report/reward_pred": 0.00439603952690959, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.027007728815078735, "eval/cont_loss_std": 0.30938518047332764, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.8742387294769287, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00813024677336216, "eval/cont_pred": 0.9919034242630005, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.08706352114677429, "eval/image_loss_std": 0.10113021731376648, "eval/model_loss_mean": 0.7431933879852295, "eval/model_loss_std": 0.6935520172119141, "eval/post_ent_mag": 77.47388458251953, "eval/post_ent_max": 77.47388458251953, "eval/post_ent_mean": 61.50220489501953, "eval/post_ent_min": 40.50316619873047, "eval/post_ent_std": 7.567614555358887, "eval/prior_ent_mag": 78.70452880859375, "eval/prior_ent_max": 78.70452880859375, "eval/prior_ent_mean": 61.472503662109375, "eval/prior_ent_min": 40.80937957763672, "eval/prior_ent_std": 8.0718994140625, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0033416748046875, "eval/reward_loss_mean": 0.029122093692421913, "eval/reward_loss_std": 0.35488462448120117, "eval/reward_max_data": 0.831250011920929, "eval/reward_max_pred": 0.2308558225631714, "eval/reward_neg_acc": 0.999018669128418, "eval/reward_neg_loss": 0.006641457322984934, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.610675811767578, "eval/reward_pred": 0.003538380842655897, "eval/reward_rate": 0.0048828125, "replay/size": 1000000.0, "replay/inserts": 31984.0, "replay/samples": 31984.0, "replay/insert_wait_avg": 1.301894848677085e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.395409489107346e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3448.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1952045068939989e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1473894119262695e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1284520626068, "timer/env.step_count": 3998.0, "timer/env.step_total": 40.69077944755554, "timer/env.step_frac": 0.0406855533043153, "timer/env.step_avg": 0.010177783753765768, "timer/env.step_min": 0.008049488067626953, "timer/env.step_max": 0.04043912887573242, "timer/replay._sample_count": 31984.0, "timer/replay._sample_total": 17.823236227035522, "timer/replay._sample_frac": 0.017820947089624253, "timer/replay._sample_avg": 0.0005572547594745973, "timer/replay._sample_min": 0.00043487548828125, "timer/replay._sample_max": 0.012004852294921875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4429.0, "timer/agent.policy_total": 49.38277983665466, "timer/agent.policy_frac": 0.04937643733143526, "timer/agent.policy_avg": 0.011149871265896288, "timer/agent.policy_min": 0.009440183639526367, "timer/agent.policy_max": 0.08496928215026855, "timer/dataset_train_count": 1999.0, "timer/dataset_train_total": 0.24150896072387695, "timer/dataset_train_frac": 0.00024147794238410367, "timer/dataset_train_avg": 0.0001208148878058414, "timer/dataset_train_min": 0.00010204315185546875, "timer/dataset_train_max": 0.0009217262268066406, "timer/agent.train_count": 1999.0, "timer/agent.train_total": 898.6741375923157, "timer/agent.train_frac": 0.8985587158718886, "timer/agent.train_avg": 0.44956184972101837, "timer/agent.train_min": 0.43755483627319336, "timer/agent.train_max": 0.7223641872406006, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5077369213104248, "timer/agent.report_frac": 0.0005076717098321697, "timer/agent.report_avg": 0.2538684606552124, "timer/agent.report_min": 0.23329639434814453, "timer/agent.report_max": 0.2744405269622803, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.886222839355469e-05, "timer/dataset_eval_frac": 3.8857237101301826e-08, "timer/dataset_eval_avg": 3.886222839355469e-05, "timer/dataset_eval_min": 3.886222839355469e-05, "timer/dataset_eval_max": 3.886222839355469e-05, "fps": 31.97916516777686}
{"step": 1820000, "time": 57304.5587644577, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 1820000, "time": 57304.631318330765, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1820000, "time": 57304.76567983627, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1820000, "time": 57305.31388568878, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1820000, "time": 57305.32236289978, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1820000, "time": 57306.23075008392, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1820000, "time": 57306.25839161873, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1820000, "time": 57306.370896577835, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1820200, "time": 57312.36906337738, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1820304, "time": 57315.952129125595, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 1820376, "time": 57317.938759326935, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1820440, "time": 57319.93642663956, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1820488, "time": 57321.40890741348, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1820504, "time": 57321.90142130852, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1820528, "time": 57322.859947919846, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1820768, "time": 57330.21620178223, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1820816, "time": 57331.697057724, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1820872, "time": 57333.2107064724, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1820920, "time": 57334.716343164444, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1821008, "time": 57337.65833759308, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1821072, "time": 57339.6498541832, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1821208, "time": 57343.68158173561, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1821592, "time": 57355.6580517292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1821672, "time": 57358.116812705994, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1821688, "time": 57358.61259865761, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1821848, "time": 57363.57552456856, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1821896, "time": 57365.08038806915, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1821936, "time": 57366.53653335571, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1822184, "time": 57374.10150003433, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1822304, "time": 57378.03032422066, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1822616, "time": 57387.4154856205, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1822680, "time": 57389.393367767334, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1822736, "time": 57391.33714079857, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1822752, "time": 57391.838510751724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1822936, "time": 57397.28769516945, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1823232, "time": 57406.703310489655, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1823240, "time": 57406.7365398407, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1823496, "time": 57414.59195423126, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1823528, "time": 57415.58299612999, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1823544, "time": 57416.07782077789, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1823848, "time": 57425.461770772934, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1823968, "time": 57429.393669843674, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1823984, "time": 57429.892983198166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1824072, "time": 57432.37679195404, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 1824312, "time": 57439.85453128815, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1824480, "time": 57445.298609018326, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1824696, "time": 57451.69602704048, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1824752, "time": 57453.65713238716, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1824800, "time": 57455.156955718994, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1824928, "time": 57459.13078856468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1825104, "time": 57464.73016190529, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1825248, "time": 57469.243434906006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1825544, "time": 57478.17465543747, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1825704, "time": 57483.12550711632, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1825816, "time": 57486.60802555084, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1825816, "time": 57486.61787033081, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1826000, "time": 57492.5282497406, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1826120, "time": 57496.12085771561, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1826192, "time": 57498.567032814026, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1826400, "time": 57504.943539619446, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1826576, "time": 57510.407604932785, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1826624, "time": 57511.89575171471, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1826776, "time": 57516.34300303459, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1827008, "time": 57524.36249232292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1827008, "time": 57524.36966943741, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1827080, "time": 57526.349365234375, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1827120, "time": 57527.80563163757, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1827328, "time": 57534.23719024658, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1827344, "time": 57534.73665142059, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1827536, "time": 57540.711527109146, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 1827672, "time": 57544.71332073212, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1827712, "time": 57546.17778110504, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1827760, "time": 57547.65013694763, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1827800, "time": 57548.67922306061, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1827960, "time": 57553.647955179214, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 1828224, "time": 57562.07616710663, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1828240, "time": 57562.57564496994, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1828384, "time": 57567.05964565277, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1828464, "time": 57569.54900097847, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1828568, "time": 57572.51196265221, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1828752, "time": 57578.431389570236, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1828992, "time": 57585.84588098526, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1829016, "time": 57586.35839557648, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1829048, "time": 57587.34563422203, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1829184, "time": 57591.75189399719, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1829216, "time": 57592.73016166687, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1829352, "time": 57596.69404911995, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1829352, "time": 57596.7032763958, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1829400, "time": 57598.20496630669, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1829648, "time": 57606.03629350662, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1829848, "time": 57611.97424221039, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1829968, "time": 57616.051681280136, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1830088, "time": 57620.09358024597, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 1830088, "time": 57620.92642879486, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1830088, "time": 57621.420738220215, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1830088, "time": 57622.606922626495, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 1830088, "time": 57622.76365399361, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 1830088, "time": 57622.81222772598, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 1830088, "time": 57623.453817367554, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 1830088, "time": 57623.86923265457, "eval_episode/length": 198.0, "eval_episode/score": 0.3812499940395355, "eval_episode/reward_rate": 0.005025125628140704}
{"step": 1830360, "time": 57632.28637886047, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1830392, "time": 57633.27441382408, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1830424, "time": 57634.26311469078, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1830472, "time": 57635.749336481094, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1830696, "time": 57642.683946847916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1830816, "time": 57646.730309963226, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1831136, "time": 57656.60036993027, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1831184, "time": 57658.103238105774, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1831368, "time": 57663.60488343239, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1831520, "time": 57668.555116176605, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1831664, "time": 57673.01099276543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1831784, "time": 57676.559497356415, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1831880, "time": 57679.50310301781, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1832280, "time": 57691.759197711945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1832384, "time": 57695.16970705986, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1832432, "time": 57696.66790866852, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1832720, "time": 57705.64273881912, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1832784, "time": 57707.620923519135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1832792, "time": 57707.64844870567, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1832792, "time": 57707.65874671936, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1832920, "time": 57711.621967077255, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1833168, "time": 57719.44588136673, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1833184, "time": 57719.943168878555, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1833296, "time": 57723.4302778244, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1833336, "time": 57724.44225907326, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1833472, "time": 57728.878215789795, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1833568, "time": 57731.82297062874, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1833640, "time": 57733.9088537693, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 1833760, "time": 57737.82472896576, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1834176, "time": 57750.72882127762, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1834184, "time": 57750.756524801254, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1834464, "time": 57759.633263111115, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1834520, "time": 57761.1453268528, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1834552, "time": 57762.135185956955, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1834856, "time": 57771.610072135925, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1834968, "time": 57775.04405093193, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1835264, "time": 57784.83334851265, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1835480, "time": 57791.24418449402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1835608, "time": 57795.277525663376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1835648, "time": 57796.735172986984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1835792, "time": 57801.121074676514, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1836160, "time": 57812.33155965805, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1836256, "time": 57815.25474071503, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1836272, "time": 57815.76837396622, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 1836552, "time": 57824.21017456055, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1836664, "time": 57827.66360259056, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1837000, "time": 57837.992115974426, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1837072, "time": 57840.41208267212, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1837160, "time": 57842.864735126495, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1837168, "time": 57843.34094142914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1837320, "time": 57847.75464844704, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1837440, "time": 57851.66496396065, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1837536, "time": 57854.747052907944, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1837728, "time": 57860.6697075367, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1837736, "time": 57860.6979162693, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1837912, "time": 57866.10852122307, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1837936, "time": 57867.072748184204, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1838264, "time": 57876.87180972099, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1838304, "time": 57878.31416654587, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1838440, "time": 57882.26163697243, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1838488, "time": 57883.75269937515, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1838608, "time": 57887.754418849945, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1838648, "time": 57888.75587415695, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1838792, "time": 57893.20630955696, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1838992, "time": 57899.63574171066, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1839048, "time": 57901.12827992439, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1839072, "time": 57902.09039211273, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1839336, "time": 57910.039061546326, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1839344, "time": 57910.51282501221, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1839512, "time": 57915.55983042717, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1839616, "time": 57918.96776223183, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 1839856, "time": 57926.31138777733, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1839984, "time": 57930.23228287697, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1840072, "time": 57933.596274375916, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 1840072, "time": 57934.50284051895, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 1840072, "time": 57935.48262286186, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1840072, "time": 57935.54775810242, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1840072, "time": 57935.65409779549, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1840072, "time": 57935.701038360596, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 1840072, "time": 57936.14262199402, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 1840072, "time": 57936.836373090744, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1840392, "time": 57946.714433670044, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1840408, "time": 57947.21199345589, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1840432, "time": 57948.20111823082, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1840728, "time": 57957.018404483795, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1840744, "time": 57957.51162672043, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1840800, "time": 57959.46982932091, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1840880, "time": 57961.91574931145, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1841104, "time": 57968.73787856102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1841160, "time": 57970.26298737526, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1841584, "time": 57983.604667663574, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1841704, "time": 57987.036125421524, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1841824, "time": 57990.95770573616, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1841832, "time": 57990.98955178261, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1842128, "time": 58000.41697597504, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1842296, "time": 58005.58247590065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1842344, "time": 58007.06598043442, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1842688, "time": 58017.84492397308, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1842704, "time": 58018.33845639229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1842704, "time": 58018.34726643562, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1843056, "time": 58029.043058633804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1843096, "time": 58030.032098293304, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1843248, "time": 58035.49895167351, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1843464, "time": 58041.82266306877, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1843464, "time": 58041.83273983002, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1843656, "time": 58047.69691514969, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1844112, "time": 58061.82625055313, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1844144, "time": 58062.79715180397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1844272, "time": 58066.812025785446, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1844640, "time": 58078.0825047493, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1844672, "time": 58079.06863760948, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1844680, "time": 58079.09619140625, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1844696, "time": 58079.60208320618, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 1844848, "time": 58084.49442386627, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1844904, "time": 58085.98450398445, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1845232, "time": 58096.40648603439, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1845400, "time": 58101.32399916649, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1845408, "time": 58101.79677915573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1845432, "time": 58102.3105533123, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1845488, "time": 58104.263622283936, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 1845576, "time": 58106.76415491104, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1845800, "time": 58113.621062517166, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1845952, "time": 58118.51840043068, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1846016, "time": 58120.479264736176, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1846256, "time": 58127.97572541237, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1846280, "time": 58128.496557474136, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1846304, "time": 58129.464935302734, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1846432, "time": 58133.41113567352, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1846560, "time": 58137.360347509384, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1846592, "time": 58138.34085035324, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 1846640, "time": 58139.81865668297, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1846656, "time": 58140.31512260437, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1846944, "time": 58149.19702291489, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1847056, "time": 58152.63491201401, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1847064, "time": 58152.666815280914, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1847208, "time": 58157.20152115822, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1847256, "time": 58158.684579372406, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1847336, "time": 58161.16930294037, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1847784, "time": 58174.93620467186, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1847904, "time": 58178.8211274147, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1847920, "time": 58179.313633441925, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1848160, "time": 58186.75625729561, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1848192, "time": 58187.73260998726, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1848280, "time": 58190.23358654976, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1848352, "time": 58192.643938302994, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1848448, "time": 58195.60973572731, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 1848648, "time": 58201.50532722473, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1848752, "time": 58204.90614938736, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1848752, "time": 58204.91501665115, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1849184, "time": 58218.256288051605, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1849272, "time": 58220.743596315384, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1849304, "time": 58221.72935414314, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1849400, "time": 58224.68158078194, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1849520, "time": 58228.5414648056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1849560, "time": 58229.563299655914, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1849720, "time": 58234.42944025993, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1849728, "time": 58234.90126657486, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1849976, "time": 58242.26891899109, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1850040, "time": 58244.3326215744, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1850056, "time": 58245.302842617035, "eval_episode/length": 22.0, "eval_episode/score": 0.9312499761581421, "eval_episode/reward_rate": 0.043478260869565216}
{"step": 1850056, "time": 58245.51269650459, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 1850056, "time": 58245.97763085365, "eval_episode/length": 22.0, "eval_episode/score": 0.9312499761581421, "eval_episode/reward_rate": 0.043478260869565216}
{"step": 1850056, "time": 58246.198813676834, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1850056, "time": 58246.528435468674, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1850056, "time": 58246.57474899292, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1850056, "time": 58247.2423312664, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1850056, "time": 58247.25124049187, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 1850136, "time": 58249.702761650085, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1850168, "time": 58250.68072271347, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1850272, "time": 58254.08300256729, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1850312, "time": 58255.10258769989, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1850760, "time": 58268.82348608971, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1850864, "time": 58272.268513679504, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1850920, "time": 58273.866799116135, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1851208, "time": 58282.78424358368, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1851336, "time": 58286.74248433113, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1851416, "time": 58289.66599941254, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1851496, "time": 58292.16010594368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1851712, "time": 58299.02320456505, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 1851760, "time": 58300.49422478676, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1851801, "time": 58302.688364982605, "eval_stats/mean_log_entropy": 0.0, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.17153639290201, "train/action_min": 0.0, "train/action_std": 1.7961569371534951, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011034619671540643, "train/actor_opt_grad_steps": 114650.0, "train/actor_opt_loss": -42.56862654757859, "train/adv_mag": 0.8107100701212284, "train/adv_max": 0.33868430727091264, "train/adv_mean": 0.0010070768132244045, "train/adv_min": -0.7314218929664573, "train/adv_std": 0.03688489330286656, "train/cont_avg": 0.992442682160804, "train/cont_loss_mean": 0.03252641105060302, "train/cont_loss_std": 0.3165191089238354, "train/cont_neg_acc": 0.0815145368477208, "train/cont_neg_loss": 3.391650681519628, "train/cont_pos_acc": 0.9997973846430754, "train/cont_pos_loss": 0.007011535146914835, "train/cont_pred": 0.9924974702111441, "train/cont_rate": 0.992442682160804, "train/dyn_loss_mean": 1.0000088532366345, "train/dyn_loss_std": 0.00018055306047893798, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10268107938332174, "train/extr_critic_critic_opt_grad_steps": 114650.0, "train/extr_critic_critic_opt_loss": 12442.416594692211, "train/extr_critic_mag": 2.0035041984002193, "train/extr_critic_max": 2.0035041984002193, "train/extr_critic_mean": 1.8440720352096174, "train/extr_critic_min": 1.4890567172112776, "train/extr_critic_std": 0.039019784239593465, "train/extr_return_normed_mag": 0.8062960077170751, "train/extr_return_normed_max": 0.322606405421118, "train/extr_return_normed_mean": 0.08976980658182547, "train/extr_return_normed_min": -0.6642120249906377, "train/extr_return_normed_std": 0.05454482941247111, "train/extr_return_rate": 0.999714739059084, "train/extr_return_raw_mag": 2.0779154971616354, "train/extr_return_raw_max": 2.0779154971616354, "train/extr_return_raw_mean": 1.8450789948803696, "train/extr_return_raw_min": 1.0910970667498794, "train/extr_return_raw_std": 0.054544829449911215, "train/extr_reward_mag": 0.2561780873255514, "train/extr_reward_max": 0.2561780873255514, "train/extr_reward_mean": 0.0033112983078925156, "train/extr_reward_min": 1.821086634343593e-07, "train/extr_reward_std": 0.01013861838540989, "train/image_loss_mean": 0.08707332279739069, "train/image_loss_std": 0.10361564443938097, "train/model_loss_mean": 0.7506612320641177, "train/model_loss_std": 0.6455577098244998, "train/model_opt_grad_norm": 12.43264756610046, "train/model_opt_grad_steps": 114546.93467336684, "train/model_opt_loss": 4737.838208375863, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6331.658291457286, "train/policy_entropy_mag": 1.1591528579218304, "train/policy_entropy_max": 1.1591528579218304, "train/policy_entropy_mean": 0.0834815052511105, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.0932971102807989, "train/policy_logprob_mag": 6.551080277217692, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08333108151078823, "train/policy_logprob_min": -6.551080277217692, "train/policy_logprob_std": 0.6203451006855797, "train/policy_randomness_mag": 0.5956867660709362, "train/policy_randomness_max": 0.5956867660709362, "train/policy_randomness_mean": 0.04290101151145882, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.04794523301510955, "train/post_ent_mag": 76.92261623976817, "train/post_ent_max": 76.92261623976817, "train/post_ent_mean": 60.44989418144801, "train/post_ent_min": 42.47213492081992, "train/post_ent_std": 7.58337192918787, "train/prior_ent_mag": 76.74786204429128, "train/prior_ent_max": 76.74786204429128, "train/prior_ent_mean": 60.599363662489694, "train/prior_ent_min": 43.10656811124716, "train/prior_ent_std": 7.558440026326395, "train/rep_loss_mean": 1.0000088532366345, "train/rep_loss_std": 0.00018055306047893798, "train/reward_avg": 0.004356330587065325, "train/reward_loss_mean": 0.031056158038689264, "train/reward_loss_std": 0.3280934885368874, "train/reward_max_data": 0.848555277639897, "train/reward_max_pred": 0.34261738475243647, "train/reward_neg_acc": 0.9992350094282447, "train/reward_neg_loss": 0.005830350984823913, "train/reward_pos_acc": 0.1119718390268896, "train/reward_pos_loss": 4.037164204084694, "train/reward_pred": 0.003371267639166072, "train/reward_rate": 0.0062617776381909546, "train_stats/mean_log_entropy": 0.0799553681525492, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 0.03503634035587311, "report/cont_loss_std": 0.3175332546234131, "report/cont_neg_acc": 0.10000000149011612, "report/cont_neg_loss": 3.0376479625701904, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005424786359071732, "report/cont_pred": 0.9934227466583252, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08691754937171936, "report/image_loss_std": 0.10612792521715164, "report/model_loss_mean": 0.7600173950195312, "report/model_loss_std": 0.721007227897644, "report/post_ent_mag": 77.93464660644531, "report/post_ent_max": 77.93464660644531, "report/post_ent_mean": 61.53746795654297, "report/post_ent_min": 39.745174407958984, "report/post_ent_std": 8.377592086791992, "report/prior_ent_mag": 77.2427978515625, "report/prior_ent_max": 77.2427978515625, "report/prior_ent_mean": 61.37312698364258, "report/prior_ent_min": 41.034454345703125, "report/prior_ent_std": 8.045039176940918, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.006854247767478228, "report/reward_loss_mean": 0.03806351125240326, "report/reward_loss_std": 0.37310853600502014, "report/reward_max_data": 0.878125011920929, "report/reward_max_pred": 0.7699261903762817, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.004601665306836367, "report/reward_pos_acc": 0.1111111119389534, "report/reward_pos_loss": 3.8118159770965576, "report/reward_pred": 0.0033535021357238293, "report/reward_rate": 0.0087890625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.027586910873651505, "eval/cont_loss_std": 0.25887468457221985, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.3759772777557373, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.007851801812648773, "eval/cont_pred": 0.9922440648078918, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.0873173400759697, "eval/image_loss_std": 0.10238264501094818, "eval/model_loss_mean": 0.7455692291259766, "eval/model_loss_std": 0.6093862652778625, "eval/post_ent_mag": 78.45057678222656, "eval/post_ent_max": 78.45057678222656, "eval/post_ent_mean": 62.27445983886719, "eval/post_ent_min": 44.202781677246094, "eval/post_ent_std": 7.67587947845459, "eval/prior_ent_mag": 77.55960845947266, "eval/prior_ent_max": 77.55960845947266, "eval/prior_ent_mean": 62.249671936035156, "eval/prior_ent_min": 43.350189208984375, "eval/prior_ent_std": 7.384943962097168, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.004492186941206455, "eval/reward_loss_mean": 0.030664972960948944, "eval/reward_loss_std": 0.31497278809547424, "eval/reward_max_data": 0.8062499761581421, "eval/reward_max_pred": 0.1845684051513672, "eval/reward_neg_acc": 0.9980353713035583, "eval/reward_neg_loss": 0.006553275510668755, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.121616363525391, "eval/reward_pred": 0.0035858829505741596, "eval/reward_rate": 0.005859375, "replay/size": 1000000.0, "replay/inserts": 31840.0, "replay/samples": 31840.0, "replay/insert_wait_avg": 1.302990482081121e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.37747296376444e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4912.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.241795791476868e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2069940567016602e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3769736289978, "timer/env.step_count": 3980.0, "timer/env.step_total": 40.7812225818634, "timer/env.step_frac": 0.040765854929591394, "timer/env.step_avg": 0.010246538337151608, "timer/env.step_min": 0.008462905883789062, "timer/env.step_max": 0.0365755558013916, "timer/replay._sample_count": 31840.0, "timer/replay._sample_total": 17.71317219734192, "timer/replay._sample_frac": 0.017706497314792322, "timer/replay._sample_avg": 0.0005563182222783266, "timer/replay._sample_min": 0.00041747093200683594, "timer/replay._sample_max": 0.01402735710144043, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4594.0, "timer/agent.policy_total": 52.25072979927063, "timer/agent.policy_frac": 0.052231040074547395, "timer/agent.policy_avg": 0.011373689551430264, "timer/agent.policy_min": 0.009351730346679688, "timer/agent.policy_max": 0.13579297065734863, "timer/dataset_train_count": 1990.0, "timer/dataset_train_total": 0.23921728134155273, "timer/dataset_train_frac": 0.00023912713671703266, "timer/dataset_train_avg": 0.00012020968911635816, "timer/dataset_train_min": 0.00010323524475097656, "timer/dataset_train_max": 0.0005421638488769531, "timer/agent.train_count": 1990.0, "timer/agent.train_total": 893.8061804771423, "timer/agent.train_frac": 0.8934693660878098, "timer/agent.train_avg": 0.4491488344106243, "timer/agent.train_min": 0.4360342025756836, "timer/agent.train_max": 0.7105846405029297, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48085737228393555, "timer/agent.report_frac": 0.0004806761700437414, "timer/agent.report_avg": 0.24042868614196777, "timer/agent.report_min": 0.23045563697814941, "timer/agent.report_max": 0.25040173530578613, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.1697721815284145e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 31.827355924685943}
{"step": 1851840, "time": 58304.07649230957, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1851872, "time": 58305.06459903717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1852000, "time": 58309.06806874275, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1852376, "time": 58320.550587654114, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1852408, "time": 58321.537353515625, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1852568, "time": 58326.46497654915, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1852608, "time": 58327.94109249115, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1852912, "time": 58337.47405743599, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1853368, "time": 58351.398458480835, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1853512, "time": 58355.84463310242, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1853552, "time": 58357.33318090439, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1853560, "time": 58357.36455988884, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 1853592, "time": 58358.35722279549, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1853728, "time": 58362.774935007095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1853808, "time": 58365.339772224426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1854072, "time": 58373.29233670235, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1854184, "time": 58376.73738861084, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1854544, "time": 58388.110446453094, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1854560, "time": 58388.60621404648, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1854688, "time": 58392.55123138428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1854712, "time": 58393.06815123558, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1854872, "time": 58398.11183261871, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1855024, "time": 58403.018538713455, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1855032, "time": 58403.046785354614, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1855184, "time": 58407.95880937576, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1855256, "time": 58409.97054338455, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1855608, "time": 58420.863829135895, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1855680, "time": 58423.33060383797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1855680, "time": 58423.34107494354, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1855792, "time": 58426.91884970665, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1855872, "time": 58429.37580060959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1855960, "time": 58431.88301157951, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1856120, "time": 58436.80455446243, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1856168, "time": 58438.27622103691, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1856344, "time": 58443.69887590408, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1856472, "time": 58447.66546034813, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1856560, "time": 58450.59368777275, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1856624, "time": 58452.57442355156, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1856808, "time": 58458.113587379456, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1856896, "time": 58461.03994989395, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1857328, "time": 58474.40645265579, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1857480, "time": 58478.887028217316, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1857504, "time": 58479.850209236145, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1857640, "time": 58483.937728881836, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1857912, "time": 58492.35331439972, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 1858008, "time": 58495.30703139305, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1858104, "time": 58498.27372598648, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1858264, "time": 58503.19812107086, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1858272, "time": 58503.67664480209, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1858320, "time": 58505.16783332825, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1858448, "time": 58509.130653619766, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 1858624, "time": 58514.668624162674, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1858656, "time": 58515.654678821564, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1858688, "time": 58516.66294693947, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1858792, "time": 58519.63111829758, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1859256, "time": 58534.03258538246, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1859416, "time": 58539.004405260086, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1859640, "time": 58546.57373571396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1859760, "time": 58550.5073120594, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1859784, "time": 58551.03066396713, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1859920, "time": 58555.46081852913, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1859952, "time": 58556.46826887131, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1860040, "time": 58559.634779930115, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 1860040, "time": 58559.880185842514, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 1860040, "time": 58560.124994277954, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1860040, "time": 58560.67443704605, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1860040, "time": 58560.720079660416, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1860040, "time": 58560.80795454979, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1860040, "time": 58561.59225273132, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1860040, "time": 58561.88095021248, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 1860208, "time": 58567.30660820007, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1860344, "time": 58571.284640073776, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1860352, "time": 58571.76033949852, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1860376, "time": 58572.279812812805, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1860480, "time": 58575.82188606262, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1860512, "time": 58576.80902719498, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1860672, "time": 58581.74524283409, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1860712, "time": 58582.76601457596, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1860728, "time": 58583.26292848587, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1861024, "time": 58592.64426803589, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1861152, "time": 58596.60301280022, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1861384, "time": 58603.53007698059, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1861544, "time": 58608.558336019516, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1861896, "time": 58619.460904836655, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1861960, "time": 58621.44105100632, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1862048, "time": 58624.383836984634, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1862432, "time": 58636.389379024506, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1862688, "time": 58644.272560834885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1862792, "time": 58647.24688386917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1862800, "time": 58647.7219722271, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 1862928, "time": 58651.67511844635, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1863024, "time": 58654.639086961746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1863072, "time": 58656.13363599777, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1863112, "time": 58657.1434469223, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1863152, "time": 58658.61394429207, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1863432, "time": 58667.14070034027, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1863672, "time": 58674.591776371, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1863744, "time": 58677.03166413307, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1863960, "time": 58683.470911026, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1863968, "time": 58683.952845573425, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1864064, "time": 58686.929946660995, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1864296, "time": 58693.98899102211, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1864336, "time": 58695.439571619034, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1864384, "time": 58696.91032958031, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1864472, "time": 58699.40079379082, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1864600, "time": 58703.353229761124, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1864744, "time": 58707.774059295654, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1864928, "time": 58713.80442523956, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1864968, "time": 58714.81312537193, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1865024, "time": 58716.75989317894, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1865088, "time": 58718.75225377083, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1865128, "time": 58719.764664173126, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
