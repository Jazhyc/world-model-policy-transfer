{"step": 1560, "time": 109.4569833278656, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 1560, "time": 138.45545530319214, "eval_episode/length": 255.0, "eval_episode/score": 0.203125, "eval_episode/reward_rate": 0.00390625}
{"step": 1560, "time": 139.2666618824005, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 139.2761926651001, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 139.28380846977234, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 139.29178524017334, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 139.29930090904236, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 139.30671525001526, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 139.31421756744385, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 261.072226524353, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.87249755859375, "train/action_min": 0.0, "train/action_std": 1.8552780151367188, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.000981956603936851, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.951793909072876, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.5947418808937073, "train/cont_loss_std": 0.24508675932884216, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.69140625, "train/cont_pos_loss": 0.5947418808937073, "train/cont_pred": 0.567509651184082, "train/cont_rate": 1.0, "train/dyn_loss_mean": 10.992332458496094, "train/dyn_loss_std": 0.3458620011806488, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 10.949646949768066, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 43548.00390625, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 5009.3203125, "train/image_loss_std": 41.007652282714844, "train/model_loss_mean": 5022.052734375, "train/model_loss_std": 40.994503021240234, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 50220528.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9287930727005005, "train/policy_entropy_max": 1.9287930727005005, "train/policy_entropy_mean": 1.6479904651641846, "train/policy_entropy_min": 0.6834920048713684, "train/policy_entropy_std": 0.14173689484596252, "train/policy_logprob_mag": 4.647947311401367, "train/policy_logprob_max": -0.16387534141540527, "train/policy_logprob_mean": -1.6558046340942383, "train/policy_logprob_min": -4.647947311401367, "train/policy_logprob_std": 0.7163146734237671, "train/policy_randomness_mag": 0.9912036061286926, "train/policy_randomness_max": 0.9912036061286926, "train/policy_randomness_mean": 0.8468995690345764, "train/policy_randomness_min": 0.3512454330921173, "train/policy_randomness_std": 0.07283835858106613, "train/post_ent_mag": 105.61427307128906, "train/post_ent_max": 105.61427307128906, "train/post_ent_mean": 105.30020141601562, "train/post_ent_min": 104.95169830322266, "train/post_ent_std": 0.11331532150506973, "train/prior_ent_mag": 106.34794616699219, "train/prior_ent_max": 106.34794616699219, "train/prior_ent_mean": 105.58576965332031, "train/prior_ent_min": 104.74143981933594, "train/prior_ent_std": 0.24860049784183502, "train/rep_loss_mean": 10.992332458496094, "train/rep_loss_std": 0.3458620011806488, "train/reward_avg": 0.0005807310808449984, "train/reward_loss_mean": 5.541263580322266, "train/reward_loss_std": 2.6488882554076554e-07, "train/reward_max_data": 0.0024999999441206455, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541263580322266, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.6190536022186279, "report/cont_loss_std": 0.2646026313304901, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.67578125, "report/cont_pos_loss": 0.6190536022186279, "report/cont_pred": 0.5562061667442322, "report/cont_rate": 1.0, "report/dyn_loss_mean": 10.974754333496094, "report/dyn_loss_std": 0.3687405586242676, "report/image_loss_mean": 5009.884765625, "report/image_loss_std": 40.79621124267578, "report/model_loss_mean": 5022.6298828125, "report/model_loss_std": 40.804649353027344, "report/post_ent_mag": 105.63218688964844, "report/post_ent_max": 105.63218688964844, "report/post_ent_mean": 105.317138671875, "report/post_ent_min": 104.9329833984375, "report/post_ent_std": 0.10178529471158981, "report/prior_ent_mag": 106.20365142822266, "report/prior_ent_max": 106.20365142822266, "report/prior_ent_mean": 105.567138671875, "report/prior_ent_min": 104.41767883300781, "report/prior_ent_std": 0.2834073603153229, "report/rep_loss_mean": 10.974754333496094, "report/rep_loss_std": 0.3687405586242676, "report/reward_avg": 0.0005807310808449984, "report/reward_loss_mean": 5.541263580322266, "report/reward_loss_std": 2.6488882554076554e-07, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541263580322266, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.6634638905525208, "eval/cont_loss_std": 0.2846289575099945, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 1.1052751541137695, "eval/cont_pos_acc": 0.5884652733802795, "eval/cont_pos_loss": 0.6630319952964783, "eval/cont_pred": 0.5352658033370972, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 10.998201370239258, "eval/dyn_loss_std": 0.3602330684661865, "eval/image_loss_mean": 5000.59228515625, "eval/image_loss_std": 39.32550811767578, "eval/model_loss_mean": 5013.396484375, "eval/model_loss_std": 39.318992614746094, "eval/post_ent_mag": 105.6291275024414, "eval/post_ent_max": 105.6291275024414, "eval/post_ent_mean": 105.29118347167969, "eval/post_ent_min": 104.930419921875, "eval/post_ent_std": 0.10654763132333755, "eval/prior_ent_mag": 106.47760772705078, "eval/prior_ent_max": 106.47760772705078, "eval/prior_ent_mean": 105.57597351074219, "eval/prior_ent_min": 104.819091796875, "eval/prior_ent_std": 0.26311466097831726, "eval/rep_loss_mean": 10.998201370239258, "eval/rep_loss_std": 0.3602330684661865, "eval/reward_avg": 0.0005371093866415322, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.550000011920929, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541263580322266, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0009765625, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.15627371825017e-05, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.770904268537249e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.7386575775871367e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 157.1893343925476, "timer/env.step_count": 196.0, "timer/env.step_total": 2.248851776123047, "timer/env.step_frac": 0.014306643544319668, "timer/env.step_avg": 0.0114737335516482, "timer/env.step_min": 0.009956836700439453, "timer/env.step_max": 0.02763843536376953, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.14591288566589355, "timer/replay._sample_frac": 0.0009282619983713814, "timer/replay._sample_avg": 0.0013027936220169067, "timer/replay._sample_min": 0.0005283355712890625, "timer/replay._sample_max": 0.02018570899963379, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.8697896003723145, "timer/agent.save_frac": 0.018256897718044996, "timer/agent.save_avg": 2.8697896003723145, "timer/agent.save_min": 2.8697896003723145, "timer/agent.save_max": 2.8697896003723145, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 27.66676902770996, "timer/agent.policy_frac": 0.17600920020831676, "timer/agent.policy_avg": 0.09540265181968952, "timer/agent.policy_min": 0.009282827377319336, "timer/agent.policy_max": 21.50069284439087, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 4.744529724121094e-05, "timer/dataset_train_frac": 3.018353466827857e-07, "timer/dataset_train_avg": 4.744529724121094e-05, "timer/dataset_train_min": 4.744529724121094e-05, "timer/dataset_train_max": 4.744529724121094e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 89.19405817985535, "timer/agent.train_frac": 0.5674307262928652, "timer/agent.train_avg": 89.19405817985535, "timer/agent.train_min": 89.19405817985535, "timer/agent.train_max": 89.19405817985535, "timer/agent.report_count": 2.0, "timer/agent.report_total": 29.489225149154663, "timer/agent.report_frac": 0.1876032191567875, "timer/agent.report_avg": 14.744612574577332, "timer/agent.report_min": 7.084526538848877, "timer/agent.report_max": 22.404698610305786, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 2.1234647505321608e-07, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05}
{"step": 2312, "time": 284.180823802948, "episode/length": 288.0, "episode/score": 0.14629848287654568, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14629848287654568}
{"step": 2312, "time": 284.1878454685211, "episode/length": 288.0, "episode/score": 0.16119965292773486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16119965292773486}
{"step": 2312, "time": 284.1942117214203, "episode/length": 288.0, "episode/score": 0.13766372353575207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13766372353575207}
{"step": 2312, "time": 284.19989037513733, "episode/length": 288.0, "episode/score": 0.1658446962301241, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1658446962301241}
{"step": 2312, "time": 284.20643067359924, "episode/length": 288.0, "episode/score": 0.17308541117745335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17308541117745335}
{"step": 2312, "time": 284.2123477458954, "episode/length": 288.0, "episode/score": 0.12666430952594965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12666430952594965}
{"step": 2312, "time": 284.2179160118103, "episode/length": 288.0, "episode/score": 0.1733796389210056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1733796389210056}
{"step": 2312, "time": 284.2247655391693, "episode/length": 288.0, "episode/score": 0.09474217910519656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09474217910519656}
{"step": 4624, "time": 356.29583168029785, "episode/length": 288.0, "episode/score": 0.13177866494402224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13177866494402224}
{"step": 4624, "time": 356.3034882545471, "episode/length": 288.0, "episode/score": 0.13499799080841512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13499799080841512}
{"step": 4624, "time": 356.3106164932251, "episode/length": 288.0, "episode/score": 0.0896376146994271, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0896376146994271}
{"step": 4624, "time": 356.3167636394501, "episode/length": 288.0, "episode/score": 0.07286995409856445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07286995409856445}
{"step": 4624, "time": 356.32292199134827, "episode/length": 288.0, "episode/score": 0.14385664094038475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14385664094038475}
{"step": 4624, "time": 356.3292124271393, "episode/length": 288.0, "episode/score": 0.13257736118623598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13257736118623598}
{"step": 4624, "time": 356.33581256866455, "episode/length": 288.0, "episode/score": 0.1061003041670574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1061003041670574}
{"step": 4624, "time": 356.3417613506317, "episode/length": 288.0, "episode/score": 0.11038738835509321, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11038738835509321}
{"step": 6936, "time": 428.0371060371399, "episode/length": 288.0, "episode/score": 0.10904066128262002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10904066128262002}
{"step": 6936, "time": 428.0448648929596, "episode/length": 288.0, "episode/score": 0.09303875005105056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09303875005105056}
{"step": 6936, "time": 428.05233669281006, "episode/length": 288.0, "episode/score": 0.10134238408716101, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10134238408716101}
{"step": 6936, "time": 428.05875873565674, "episode/length": 288.0, "episode/score": 0.09794026476754425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09794026476754425}
{"step": 6936, "time": 428.06517696380615, "episode/length": 288.0, "episode/score": 0.12754480419266656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12754480419266656}
{"step": 6936, "time": 428.0715148448944, "episode/length": 288.0, "episode/score": 0.08418170470542918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08418170470542918}
{"step": 6936, "time": 428.07796263694763, "episode/length": 288.0, "episode/score": 0.11101276973181484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11101276973181484}
{"step": 6936, "time": 428.0843460559845, "episode/length": 288.0, "episode/score": 0.09983429308579161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09983429308579161}
{"step": 9248, "time": 500.34440565109253, "episode/length": 288.0, "episode/score": 0.07388024253589265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07388024253589265}
{"step": 9248, "time": 500.3522448539734, "episode/length": 288.0, "episode/score": 0.13616914878957687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13616914878957687}
{"step": 9248, "time": 500.35977482795715, "episode/length": 288.0, "episode/score": 0.13411647632767654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13411647632767654}
{"step": 9248, "time": 500.3663845062256, "episode/length": 288.0, "episode/score": 0.12634028083186877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12634028083186877}
{"step": 9248, "time": 500.3729524612427, "episode/length": 288.0, "episode/score": 0.11083038160319347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11083038160319347}
{"step": 9248, "time": 500.379540681839, "episode/length": 288.0, "episode/score": 0.06324584164582348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06324584164582348}
{"step": 9248, "time": 500.3864629268646, "episode/length": 288.0, "episode/score": 0.04909150406041363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04909150406041363}
{"step": 9248, "time": 500.393257856369, "episode/length": 288.0, "episode/score": 0.08621453122339062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08621453122339062}
{"step": 10088, "time": 530.833957195282, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 530.8416323661804, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 530.8475029468536, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 530.8531119823456, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 530.8587698936462, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 530.8642470836639, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 530.8697819709778, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 530.8753952980042, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 11560, "time": 576.8442816734314, "episode/length": 288.0, "episode/score": 0.05622289527332214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05622289527332214}
{"step": 11560, "time": 576.8513152599335, "episode/length": 288.0, "episode/score": 0.12209426563447323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12209426563447323}
{"step": 11560, "time": 576.8585658073425, "episode/length": 288.0, "episode/score": 0.11317689357872496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11317689357872496}
{"step": 11560, "time": 576.8646328449249, "episode/length": 288.0, "episode/score": 0.18293939317868535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18293939317868535}
{"step": 11560, "time": 576.8706800937653, "episode/length": 288.0, "episode/score": 0.11214148660150158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11214148660150158}
{"step": 11560, "time": 576.8766851425171, "episode/length": 288.0, "episode/score": 0.13749389297709058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13749389297709058}
{"step": 11560, "time": 576.8825664520264, "episode/length": 288.0, "episode/score": 0.08744309950168372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08744309950168372}
{"step": 11560, "time": 576.8887298107147, "episode/length": 288.0, "episode/score": 0.1251841935135758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1251841935135758}
{"step": 13872, "time": 648.833244562149, "episode/length": 288.0, "episode/score": 0.11172746706063208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11172746706063208}
{"step": 13872, "time": 648.8404517173767, "episode/length": 288.0, "episode/score": 0.12640526740477753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12640526740477753}
{"step": 13872, "time": 648.8479778766632, "episode/length": 288.0, "episode/score": 0.13316384716580387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13316384716580387}
{"step": 13872, "time": 648.8543426990509, "episode/length": 288.0, "episode/score": 0.1421942855964744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1421942855964744}
{"step": 13872, "time": 648.8613245487213, "episode/length": 288.0, "episode/score": 0.13253906178573516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13253906178573516}
{"step": 13872, "time": 648.867437839508, "episode/length": 288.0, "episode/score": 0.10857592215973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10857592215973}
{"step": 13872, "time": 648.8736908435822, "episode/length": 288.0, "episode/score": 0.1301963268815598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1301963268815598}
{"step": 13872, "time": 648.8796422481537, "episode/length": 288.0, "episode/score": 0.09630026129235603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09630026129235603}
{"step": 16184, "time": 720.3227055072784, "episode/length": 288.0, "episode/score": 0.10166324886063194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10166324886063194}
{"step": 16184, "time": 720.3298575878143, "episode/length": 288.0, "episode/score": 0.09519801878082035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09519801878082035}
{"step": 16184, "time": 720.3368091583252, "episode/length": 288.0, "episode/score": 0.07635109103762261, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07635109103762261}
{"step": 16184, "time": 720.3429446220398, "episode/length": 288.0, "episode/score": 0.11279050326015749, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11279050326015749}
{"step": 16184, "time": 720.3488576412201, "episode/length": 288.0, "episode/score": 0.09747151278156707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09747151278156707}
{"step": 16184, "time": 720.3548889160156, "episode/length": 288.0, "episode/score": 0.11367904281314622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11367904281314622}
{"step": 16184, "time": 720.3607938289642, "episode/length": 288.0, "episode/score": 0.12439131927067137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12439131927067137}
{"step": 16184, "time": 720.3667271137238, "episode/length": 288.0, "episode/score": 0.11948444209974696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11948444209974696}
{"step": 17096, "time": 749.1843376159668, "episode/length": 113.0, "episode/score": 0.6956919006295266, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0488168791159751}
{"step": 18496, "time": 792.897075176239, "episode/length": 288.0, "episode/score": 0.14726174256020386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14726174256020386}
{"step": 18496, "time": 792.9042062759399, "episode/length": 288.0, "episode/score": 0.13179550510380977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13179550510380977}
{"step": 18496, "time": 792.9113771915436, "episode/length": 288.0, "episode/score": 0.12275926620623068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12275926620623068}
{"step": 18496, "time": 792.9175107479095, "episode/length": 288.0, "episode/score": 0.07872086433872028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07872086433872028}
{"step": 18496, "time": 792.9240748882294, "episode/length": 288.0, "episode/score": 0.19520477270066294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19520477270066294}
{"step": 18496, "time": 792.9300742149353, "episode/length": 288.0, "episode/score": 0.12802251762173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12802251762173}
{"step": 18496, "time": 792.9366199970245, "episode/length": 288.0, "episode/score": 0.1166137141285617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1166137141285617}
{"step": 19408, "time": 821.1942622661591, "episode/length": 288.0, "episode/score": 0.10710971109756429, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10710971109756429}
{"step": 20072, "time": 843.6684803962708, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 20072, "time": 844.220020532608, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 20072, "time": 847.0289671421051, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 847.0358529090881, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 847.041933298111, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 847.0476377010345, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 847.0535414218903, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 847.059398651123, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20808, "time": 869.9470705986023, "episode/length": 288.0, "episode/score": 0.13426643936168148, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13426643936168148}
{"step": 20808, "time": 869.9541370868683, "episode/length": 288.0, "episode/score": 0.12985097706155102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12985097706155102}
{"step": 20808, "time": 869.9623339176178, "episode/length": 288.0, "episode/score": 0.07714236942638308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07714236942638308}
{"step": 20808, "time": 869.9684872627258, "episode/length": 288.0, "episode/score": 0.11144681588734784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11144681588734784}
{"step": 20808, "time": 869.9751744270325, "episode/length": 288.0, "episode/score": 0.09575834704605768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09575834704605768}
{"step": 20808, "time": 869.9810495376587, "episode/length": 288.0, "episode/score": 0.12049129356591948, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12049129356591948}
{"step": 20808, "time": 869.9870896339417, "episode/length": 288.0, "episode/score": 0.09997865961940988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09997865961940988}
{"step": 21720, "time": 898.1785891056061, "episode/length": 288.0, "episode/score": 0.12238182943451648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12238182943451648}
{"step": 23120, "time": 941.839949131012, "episode/length": 288.0, "episode/score": 0.1179145708492797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1179145708492797}
{"step": 23120, "time": 941.8469867706299, "episode/length": 288.0, "episode/score": 0.15961417894891383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15961417894891383}
{"step": 23120, "time": 941.8542242050171, "episode/length": 288.0, "episode/score": 0.11782865650479835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11782865650479835}
{"step": 23120, "time": 941.860342502594, "episode/length": 288.0, "episode/score": 0.15507791671734594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15507791671734594}
{"step": 23120, "time": 941.8664388656616, "episode/length": 288.0, "episode/score": 0.12012284364527659, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12012284364527659}
{"step": 23120, "time": 941.8727490901947, "episode/length": 288.0, "episode/score": 0.13021291967061188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13021291967061188}
{"step": 23120, "time": 941.8788902759552, "episode/length": 288.0, "episode/score": 0.137019645262626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.137019645262626}
{"step": 24032, "time": 970.1227626800537, "episode/length": 288.0, "episode/score": 0.11479251944535918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11479251944535918}
{"step": 25432, "time": 1013.4591662883759, "episode/length": 288.0, "episode/score": 0.1380036895060357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1380036895060357}
{"step": 25432, "time": 1013.4661645889282, "episode/length": 288.0, "episode/score": 0.14145140727350736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14145140727350736}
{"step": 25432, "time": 1013.4740018844604, "episode/length": 288.0, "episode/score": 0.15195478165901477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15195478165901477}
{"step": 25432, "time": 1013.4800851345062, "episode/length": 288.0, "episode/score": 0.11968856631244762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11968856631244762}
{"step": 25432, "time": 1013.4858345985413, "episode/length": 288.0, "episode/score": 0.1519704332852143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1519704332852143}
{"step": 25432, "time": 1013.4922714233398, "episode/length": 288.0, "episode/score": 0.1286662461764081, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1286662461764081}
{"step": 25432, "time": 1013.4987542629242, "episode/length": 288.0, "episode/score": 0.10098680523765324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10098680523765324}
{"step": 26344, "time": 1041.7338893413544, "episode/length": 288.0, "episode/score": 0.11351944007083148, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11351944007083148}
{"step": 27744, "time": 1085.6937801837921, "episode/length": 288.0, "episode/score": 0.151200238494539, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.151200238494539}
{"step": 27744, "time": 1085.7008121013641, "episode/length": 288.0, "episode/score": 0.13150377878105246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13150377878105246}
{"step": 27744, "time": 1085.7085552215576, "episode/length": 288.0, "episode/score": 0.09785367005110857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09785367005110857}
{"step": 27744, "time": 1085.7146742343903, "episode/length": 288.0, "episode/score": 0.14728924496216678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14728924496216678}
{"step": 27744, "time": 1085.7206580638885, "episode/length": 288.0, "episode/score": 0.1609470504854471, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1609470504854471}
{"step": 27744, "time": 1085.7267129421234, "episode/length": 288.0, "episode/score": 0.1681622187429639, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1681622187429639}
{"step": 27744, "time": 1085.7334387302399, "episode/length": 288.0, "episode/score": 0.13724278055565264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13724278055565264}
{"step": 28656, "time": 1113.9442820549011, "episode/length": 288.0, "episode/score": 0.10682721070497792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10682721070497792}
{"step": 30056, "time": 1157.1314153671265, "episode/length": 288.0, "episode/score": 0.1776038766097372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1776038766097372}
{"step": 30056, "time": 1157.1386556625366, "episode/length": 288.0, "episode/score": 0.11335246838575586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11335246838575586}
{"step": 30056, "time": 1157.1464660167694, "episode/length": 288.0, "episode/score": 0.12512809884447051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12512809884447051}
{"step": 30056, "time": 1157.1527042388916, "episode/length": 288.0, "episode/score": 0.13850125338694852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13850125338694852}
{"step": 30056, "time": 1157.1589181423187, "episode/length": 288.0, "episode/score": 0.14832506352195196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14832506352195196}
{"step": 30056, "time": 1157.1650722026825, "episode/length": 288.0, "episode/score": 0.07824315886000477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07824315886000477}
{"step": 30056, "time": 1157.171450138092, "episode/length": 288.0, "episode/score": 0.11962842386355987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11962842386355987}
{"step": 30056, "time": 1160.8254520893097, "eval_episode/length": 229.0, "eval_episode/score": 0.28437501192092896, "eval_episode/reward_rate": 0.004347826086956522}
{"step": 30056, "time": 1161.790822505951, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1161.7973754405975, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1161.8030717372894, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1161.8086714744568, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1161.8142354488373, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1161.8204259872437, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1161.8261170387268, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30968, "time": 1190.5195622444153, "episode/length": 288.0, "episode/score": 0.120249451080781, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.120249451080781}
{"step": 31088, "time": 1194.4422833919525, "episode/length": 14.0, "episode/score": 0.9737179471658237, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.017467937573201198}
{"step": 32281, "time": 1232.2353038787842, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0038960774739585, "train/action_min": 0.0, "train/action_std": 1.9993799452980359, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0009822929285595212, "train/actor_opt_grad_steps": 965.0, "train/actor_opt_loss": 29.840069959250588, "train/adv_mag": 0.0031823903047817717, "train/adv_max": 0.0031823903047817717, "train/adv_mean": 0.0018632784156975095, "train/adv_min": 0.0002327856460818308, "train/adv_std": 0.0008658010973468707, "train/cont_avg": 0.9969991048177084, "train/cont_loss_mean": 0.023617524142727515, "train/cont_loss_std": 0.2978715581695878, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.795309895243725, "train/cont_pos_acc": 0.9982655746862292, "train/cont_pos_loss": 0.006275226392253271, "train/cont_pred": 0.9946273934716979, "train/cont_rate": 0.9969991048177084, "train/dyn_loss_mean": 1.0707091838121414, "train/dyn_loss_std": 0.004796882215108174, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.32058665548296, "train/extr_critic_critic_opt_grad_steps": 965.0, "train/extr_critic_critic_opt_loss": 14128.070096333822, "train/extr_critic_mag": 0.034198226407170296, "train/extr_critic_max": 0.03419822330276171, "train/extr_critic_mean": 0.034141085311558184, "train/extr_critic_min": 0.0340746957808733, "train/extr_critic_std": 1.4583346244971077e-05, "train/extr_return_normed_mag": 0.006111111929078428, "train/extr_return_normed_max": 0.00611111079064892, "train/extr_return_normed_mean": 0.004851116958469241, "train/extr_return_normed_min": 0.003250541288597253, "train/extr_return_normed_std": 0.0008654059307239467, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.03726437175229943, "train/extr_return_raw_max": 0.03726437051426501, "train/extr_return_raw_mean": 0.036004378351609696, "train/extr_return_raw_min": 0.03440380101719365, "train/extr_return_raw_std": 0.0008654059308755476, "train/extr_reward_mag": 0.0003973226994276047, "train/extr_reward_max": 0.0003973226994276047, "train/extr_reward_mean": 0.00039702873642847675, "train/extr_reward_min": 0.0003967111309369405, "train/extr_reward_std": 1.1565493525031445e-07, "train/image_loss_mean": 27.289474746833246, "train/image_loss_std": 0.3864381968354185, "train/model_loss_mean": 28.081243158628542, "train/model_loss_std": 0.6256065209163353, "train/model_opt_grad_norm": 99.75021649405595, "train/model_opt_grad_steps": 955.0, "train/model_opt_loss": 533.7157928496599, "train/model_opt_model_opt_grad_overflow": 0.005208333333333333, "train/model_opt_model_opt_grad_scale": 14.394124348958334, "train/policy_entropy_mag": 1.9457249672462542, "train/policy_entropy_max": 1.9457249672462542, "train/policy_entropy_mean": 1.9396944822122653, "train/policy_entropy_min": 1.8925888544569414, "train/policy_entropy_std": 0.0033931385833056993, "train/policy_logprob_mag": 2.3752294095853963, "train/policy_logprob_max": -1.5370560415710013, "train/policy_logprob_mean": -1.9397058878093958, "train/policy_logprob_min": -2.3752294095853963, "train/policy_logprob_std": 0.10038905204661812, "train/policy_randomness_mag": 0.9999048948908845, "train/policy_randomness_max": 0.9999048948908845, "train/policy_randomness_mean": 0.9968058367570242, "train/policy_randomness_min": 0.9725983322908481, "train/policy_randomness_std": 0.0017437284113839269, "train/post_ent_mag": 78.96463898817699, "train/post_ent_max": 78.96463898817699, "train/post_ent_mean": 78.93255740404129, "train/post_ent_min": 78.81180377801259, "train/post_ent_std": 0.024760891930782236, "train/prior_ent_mag": 84.48708057403564, "train/prior_ent_max": 84.48708057403564, "train/prior_ent_mean": 84.39258988698323, "train/prior_ent_min": 84.06798807779948, "train/prior_ent_std": 0.0608650409267284, "train/rep_loss_mean": 1.0707091838121414, "train/rep_loss_std": 0.004796882215108174, "train/reward_avg": 0.0004243725074957183, "train/reward_loss_mean": 0.12572538510236578, "train/reward_loss_std": 0.03541907838509273, "train/reward_max_data": 0.015976562892319635, "train/reward_max_pred": 0.00039707496762275696, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.12550049484707415, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 11.073474645614624, "train/reward_pred": 0.0003965554418149016, "train/reward_rate": 2.0345052083333332e-05, "train_stats/mean_log_entropy": 1.9251669836494159, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025577913969755173, "report/cont_loss_std": 0.3516060709953308, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.640276908874512, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0035594881046563387, "report/cont_pred": 0.9964469075202942, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.25376492738723755, "report/image_loss_std": 0.08385061472654343, "report/model_loss_mean": 0.8967092037200928, "report/model_loss_std": 0.3634282946586609, "report/post_ent_mag": 63.097328186035156, "report/post_ent_max": 63.097328186035156, "report/post_ent_mean": 63.029449462890625, "report/post_ent_min": 62.98369216918945, "report/post_ent_std": 0.013937166891992092, "report/prior_ent_mag": 71.50523376464844, "report/prior_ent_max": 71.50523376464844, "report/prior_ent_mean": 71.43608093261719, "report/prior_ent_min": 71.34776306152344, "report/prior_ent_std": 0.020318441092967987, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0003801933489739895, "report/reward_loss_mean": 0.01736639440059662, "report/reward_loss_std": 0.029164336621761322, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.0004036426544189453, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.017366396263241768, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0004022957291454077, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0035594699438661337, "eval/cont_loss_std": 3.994610779045615e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0035594699438661337, "eval/cont_pred": 0.996446967124939, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2516409158706665, "eval/image_loss_std": 0.08400678634643555, "eval/model_loss_mean": 0.8581072092056274, "eval/model_loss_std": 0.08400667458772659, "eval/post_ent_mag": 63.09650421142578, "eval/post_ent_max": 63.09650421142578, "eval/post_ent_mean": 63.029937744140625, "eval/post_ent_min": 62.96999740600586, "eval/post_ent_std": 0.01356478314846754, "eval/prior_ent_mag": 71.48709106445312, "eval/prior_ent_max": 71.48709106445312, "eval/prior_ent_mean": 71.4360580444336, "eval/prior_ent_min": 71.34906005859375, "eval/prior_ent_std": 0.018383421003818512, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0029068118892610073, "eval/reward_loss_std": 4.106135747861117e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0004036426544189453, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0029068118892610073, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0004023138899356127, "eval/reward_rate": 0.0, "replay/size": 31777.0, "replay/inserts": 30720.0, "replay/samples": 30720.0, "replay/insert_wait_avg": 1.1833462243278821e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.269360745946566e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10304.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.098870406101319e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 971.1518704891205, "timer/env.step_count": 3840.0, "timer/env.step_total": 34.53090786933899, "timer/env.step_frac": 0.03555665073470692, "timer/env.step_avg": 0.008992423924307028, "timer/env.step_min": 0.007517337799072266, "timer/env.step_max": 0.038657188415527344, "timer/replay._sample_count": 30720.0, "timer/replay._sample_total": 14.976539373397827, "timer/replay._sample_frac": 0.015421418450087416, "timer/replay._sample_avg": 0.00048751755772779383, "timer/replay._sample_min": 0.00032806396484375, "timer/replay._sample_max": 0.04403805732727051, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4707.0, "timer/agent.policy_total": 40.146079778671265, "timer/agent.policy_frac": 0.04133862169101492, "timer/agent.policy_avg": 0.00852901631159364, "timer/agent.policy_min": 0.00746464729309082, "timer/agent.policy_max": 0.08752942085266113, "timer/dataset_train_count": 1920.0, "timer/dataset_train_total": 0.19582462310791016, "timer/dataset_train_frac": 0.0002016416062806769, "timer/dataset_train_avg": 0.00010199199120203654, "timer/dataset_train_min": 8.058547973632812e-05, "timer/dataset_train_max": 0.00036144256591796875, "timer/agent.train_count": 1920.0, "timer/agent.train_total": 849.8056325912476, "timer/agent.train_frac": 0.8750491642087278, "timer/agent.train_avg": 0.4426071003079414, "timer/agent.train_min": 0.4315335750579834, "timer/agent.train_max": 0.8160355091094971, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.49094200134277344, "timer/agent.report_frac": 0.000505525465440859, "timer/agent.report_avg": 0.24547100067138672, "timer/agent.report_min": 0.24020624160766602, "timer/agent.report_max": 0.2507357597351074, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.384185791015625e-05, "timer/dataset_eval_frac": 2.455008185089352e-08, "timer/dataset_eval_avg": 2.384185791015625e-05, "timer/dataset_eval_min": 2.384185791015625e-05, "timer/dataset_eval_max": 2.384185791015625e-05, "fps": 31.63206419086881}
{"step": 32368, "time": 1235.1823427677155, "episode/length": 288.0, "episode/score": 0.11973739415464024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11973739415464024}
{"step": 32368, "time": 1235.1916329860687, "episode/length": 288.0, "episode/score": 0.09694159739024144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09694159739024144}
{"step": 32368, "time": 1235.1981449127197, "episode/length": 288.0, "episode/score": 0.09244628327292048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09244628327292048}
{"step": 32368, "time": 1235.2047398090363, "episode/length": 288.0, "episode/score": 0.1330547576757226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1330547576757226}
{"step": 32368, "time": 1235.211373090744, "episode/length": 288.0, "episode/score": 0.08981592469683619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08981592469683619}
{"step": 32368, "time": 1235.2173442840576, "episode/length": 288.0, "episode/score": 0.12567529672230648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12567529672230648}
{"step": 32368, "time": 1235.2262814044952, "episode/length": 288.0, "episode/score": 0.08395444914447125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08395444914447125}
{"step": 33400, "time": 1267.885445356369, "episode/length": 288.0, "episode/score": 0.1273034339988044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1273034339988044}
{"step": 34456, "time": 1300.5366156101227, "episode/length": 260.0, "episode/score": 0.29624431387401273, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.10874431620231917}
{"step": 34680, "time": 1307.4202163219452, "episode/length": 288.0, "episode/score": 0.1456665293653714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1456665293653714}
{"step": 34680, "time": 1307.4271590709686, "episode/length": 288.0, "episode/score": 0.09945760793470981, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09945760793470981}
{"step": 34680, "time": 1307.433337211609, "episode/length": 288.0, "episode/score": 0.11445403111974883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11445403111974883}
{"step": 34680, "time": 1307.439425945282, "episode/length": 288.0, "episode/score": 0.10044964502731091, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10044964502731091}
{"step": 34680, "time": 1307.4477951526642, "episode/length": 288.0, "episode/score": 0.07295724142477411, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07295724142477411}
{"step": 34680, "time": 1307.4520916938782, "episode/length": 288.0, "episode/score": 0.12663213159794395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12663213159794395}
{"step": 35568, "time": 1335.0254945755005, "episode/length": 270.0, "episode/score": 0.25439007637805844, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.09814007870636487}
{"step": 36768, "time": 1372.4140510559082, "episode/length": 288.0, "episode/score": 0.14119877903385714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14119877903385714}
{"step": 36992, "time": 1379.4210922718048, "episode/length": 288.0, "episode/score": 0.14046147244289386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14046147244289386}
{"step": 36992, "time": 1379.428147315979, "episode/length": 288.0, "episode/score": 0.08977668836860175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08977668836860175}
{"step": 36992, "time": 1379.4347507953644, "episode/length": 288.0, "episode/score": 0.09500082270233179, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09500082270233179}
{"step": 36992, "time": 1379.4409182071686, "episode/length": 288.0, "episode/score": 0.08658420664812638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08658420664812638}
{"step": 36992, "time": 1379.4471125602722, "episode/length": 288.0, "episode/score": 0.11027420201605764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11027420201605764}
{"step": 36992, "time": 1379.4540934562683, "episode/length": 288.0, "episode/score": 0.10649019086167755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10649019086167755}
{"step": 37880, "time": 1406.8922593593597, "episode/length": 288.0, "episode/score": 0.15414182494180295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15414182494180295}
{"step": 39080, "time": 1444.5498340129852, "episode/length": 288.0, "episode/score": 0.10062123655166033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10062123655166033}
{"step": 39304, "time": 1451.6731541156769, "episode/length": 288.0, "episode/score": 0.11453002303608173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11453002303608173}
{"step": 39304, "time": 1451.680635213852, "episode/length": 288.0, "episode/score": 0.13183310507633905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13183310507633905}
{"step": 39304, "time": 1451.6872293949127, "episode/length": 288.0, "episode/score": 0.11474225111157921, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11474225111157921}
{"step": 39304, "time": 1451.6933722496033, "episode/length": 288.0, "episode/score": 0.10286650544946951, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10286650544946951}
{"step": 39304, "time": 1451.7003796100616, "episode/length": 288.0, "episode/score": 0.04062632809950628, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04062632809950628}
{"step": 39304, "time": 1451.7069072723389, "episode/length": 288.0, "episode/score": 0.09315312294938849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09315312294938849}
{"step": 40040, "time": 1476.4474420547485, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 40040, "time": 1479.734046459198, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1479.7429683208466, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1479.7495193481445, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1479.7556848526, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1479.7614889144897, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1479.7672924995422, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1479.7732441425323, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40192, "time": 1484.7501049041748, "episode/length": 288.0, "episode/score": 0.06494796634774502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06494796634774502}
{"step": 41392, "time": 1522.8371212482452, "episode/length": 288.0, "episode/score": 0.10172076852722967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10172076852722967}
{"step": 41616, "time": 1529.839077949524, "episode/length": 288.0, "episode/score": 0.11329399898647807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11329399898647807}
{"step": 41616, "time": 1529.8465297222137, "episode/length": 288.0, "episode/score": 0.11056748270186745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11056748270186745}
{"step": 41616, "time": 1529.8526439666748, "episode/length": 288.0, "episode/score": 0.07964796477347136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07964796477347136}
{"step": 41616, "time": 1529.8599569797516, "episode/length": 288.0, "episode/score": 0.11030809578215894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11030809578215894}
{"step": 41616, "time": 1529.8663773536682, "episode/length": 288.0, "episode/score": 0.10353458096642498, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10353458096642498}
{"step": 41616, "time": 1529.873298883438, "episode/length": 288.0, "episode/score": 0.07346188633840711, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07346188633840711}
{"step": 42504, "time": 1557.2312133312225, "episode/length": 288.0, "episode/score": 0.058471717881786844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058471717881786844}
{"step": 43704, "time": 1594.3951907157898, "episode/length": 288.0, "episode/score": 0.0697159347146794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0697159347146794}
{"step": 43928, "time": 1601.4114363193512, "episode/length": 288.0, "episode/score": 0.07182104211676688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07182104211676688}
{"step": 43928, "time": 1601.4184637069702, "episode/length": 288.0, "episode/score": 0.07996352614759417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07996352614759417}
{"step": 43928, "time": 1601.4246468544006, "episode/length": 288.0, "episode/score": 0.06856477237812442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06856477237812442}
{"step": 43928, "time": 1601.4307599067688, "episode/length": 288.0, "episode/score": 0.10499150818657199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10499150818657199}
{"step": 43928, "time": 1601.4368925094604, "episode/length": 288.0, "episode/score": 0.07700785817633005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07700785817633005}
{"step": 43928, "time": 1601.4430508613586, "episode/length": 288.0, "episode/score": 0.06800300990653341, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06800300990653341}
{"step": 44816, "time": 1629.262447834015, "episode/length": 288.0, "episode/score": 0.06322888053534825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06322888053534825}
{"step": 46016, "time": 1666.405515909195, "episode/length": 288.0, "episode/score": 0.10328531444235978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10328531444235978}
{"step": 46240, "time": 1673.3385598659515, "episode/length": 288.0, "episode/score": 0.12900373573904744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12900373573904744}
{"step": 46240, "time": 1673.3455882072449, "episode/length": 288.0, "episode/score": 0.07725570433780149, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07725570433780149}
{"step": 46240, "time": 1673.3518042564392, "episode/length": 288.0, "episode/score": 0.07058406216896174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07058406216896174}
{"step": 46240, "time": 1673.3579535484314, "episode/length": 288.0, "episode/score": 0.09048440241389244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09048440241389244}
{"step": 46240, "time": 1673.3636636734009, "episode/length": 288.0, "episode/score": 0.07499862442858785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07499862442858785}
{"step": 46240, "time": 1673.3704783916473, "episode/length": 288.0, "episode/score": 0.1204692206092659, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1204692206092659}
{"step": 46528, "time": 1682.3130660057068, "episode/length": 35.0, "episode/score": 0.9134104247418122, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.022785426371626727}
{"step": 47128, "time": 1700.7821645736694, "episode/length": 288.0, "episode/score": 0.14270932548475912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14270932548475912}
{"step": 48328, "time": 1737.8724813461304, "episode/length": 288.0, "episode/score": 0.12336718488666065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12336718488666065}
{"step": 48552, "time": 1744.9008524417877, "episode/length": 288.0, "episode/score": 0.15860006660813042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15860006660813042}
{"step": 48552, "time": 1744.9128975868225, "episode/length": 288.0, "episode/score": 0.1383354478098795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1383354478098795}
{"step": 48552, "time": 1744.918864250183, "episode/length": 288.0, "episode/score": 0.1230511985242515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1230511985242515}
{"step": 48552, "time": 1744.944352388382, "episode/length": 288.0, "episode/score": 0.15939602015026821, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15939602015026821}
{"step": 48552, "time": 1744.9515829086304, "episode/length": 288.0, "episode/score": 0.1252662954784114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1252662954784114}
{"step": 48840, "time": 1753.9136035442352, "episode/length": 288.0, "episode/score": 0.10511099690802439, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10511099690802439}
{"step": 49440, "time": 1773.1782929897308, "episode/length": 288.0, "episode/score": 0.13356666341451273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13356666341451273}
{"step": 50024, "time": 1795.4931681156158, "eval_episode/length": 280.0, "eval_episode/score": 0.125, "eval_episode/reward_rate": 0.0035587188612099642}
{"step": 50024, "time": 1795.627296447754, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1795.6332943439484, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1795.638965845108, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1795.6445360183716, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1795.6499652862549, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1795.6554658412933, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1795.6614718437195, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50640, "time": 1815.052719116211, "episode/length": 288.0, "episode/score": 0.15135914207218093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15135914207218093}
{"step": 50864, "time": 1822.1168529987335, "episode/length": 288.0, "episode/score": 0.1559053144657696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1559053144657696}
{"step": 50864, "time": 1822.1237404346466, "episode/length": 288.0, "episode/score": 0.08343839296679789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08343839296679789}
{"step": 50864, "time": 1822.129870891571, "episode/length": 288.0, "episode/score": 0.11694166883046364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11694166883046364}
{"step": 50864, "time": 1822.136352777481, "episode/length": 288.0, "episode/score": 0.15541895511890402, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15541895511890402}
{"step": 50864, "time": 1822.1423826217651, "episode/length": 288.0, "episode/score": 0.09073439952268814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09073439952268814}
{"step": 51152, "time": 1831.0633614063263, "episode/length": 288.0, "episode/score": 0.11442857748423307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11442857748423307}
{"step": 51752, "time": 1849.4579973220825, "episode/length": 288.0, "episode/score": 0.08079367560193873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08079367560193873}
{"step": 52952, "time": 1886.5477702617645, "episode/length": 288.0, "episode/score": 0.14451881502137098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14451881502137098}
{"step": 53176, "time": 1893.4517550468445, "episode/length": 288.0, "episode/score": 0.1405284986929871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1405284986929871}
{"step": 53176, "time": 1893.4584457874298, "episode/length": 288.0, "episode/score": 0.07308043961265298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07308043961265298}
{"step": 53176, "time": 1893.473031282425, "episode/length": 288.0, "episode/score": 0.11727869928725454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11727869928725454}
{"step": 53176, "time": 1893.4792697429657, "episode/length": 288.0, "episode/score": 0.08408546193530242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08408546193530242}
{"step": 53176, "time": 1893.4852271080017, "episode/length": 288.0, "episode/score": 0.09008960250645259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09008960250645259}
{"step": 53464, "time": 1902.5604629516602, "episode/length": 288.0, "episode/score": 0.14428966589346714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14428966589346714}
{"step": 54064, "time": 1921.345918893814, "episode/length": 288.0, "episode/score": 0.08264108279897187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08264108279897187}
{"step": 55264, "time": 1958.6398615837097, "episode/length": 288.0, "episode/score": 0.09500106934723362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09500106934723362}
{"step": 55488, "time": 1965.5471651554108, "episode/length": 288.0, "episode/score": 0.1070639933869586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1070639933869586}
{"step": 55488, "time": 1965.5542759895325, "episode/length": 288.0, "episode/score": 0.09737245615724532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09737245615724532}
{"step": 55488, "time": 1965.5628728866577, "episode/length": 288.0, "episode/score": 0.15887546561410204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15887546561410204}
{"step": 55488, "time": 1965.5666997432709, "episode/length": 288.0, "episode/score": 0.06941900683850122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06941900683850122}
{"step": 55488, "time": 1965.5727915763855, "episode/length": 288.0, "episode/score": 0.09397052573814335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09397052573814335}
{"step": 55776, "time": 1974.4397201538086, "episode/length": 288.0, "episode/score": 0.1598051499368296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1598051499368296}
{"step": 56376, "time": 1992.7787766456604, "episode/length": 288.0, "episode/score": 0.14077679324239512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14077679324239512}
{"step": 57576, "time": 2030.3389637470245, "episode/length": 288.0, "episode/score": 0.10859884502875161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10859884502875161}
{"step": 57800, "time": 2037.3156485557556, "episode/length": 288.0, "episode/score": 0.11375727406993974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11375727406993974}
{"step": 57800, "time": 2037.3227744102478, "episode/length": 288.0, "episode/score": 0.11109971157912923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11109971157912923}
{"step": 57800, "time": 2037.3290479183197, "episode/length": 288.0, "episode/score": 0.1203369302677686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1203369302677686}
{"step": 57800, "time": 2037.335566997528, "episode/length": 288.0, "episode/score": 0.11972556523832623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11972556523832623}
{"step": 57800, "time": 2037.3417284488678, "episode/length": 288.0, "episode/score": 0.11165837941121026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11165837941121026}
{"step": 58088, "time": 2046.3307003974915, "episode/length": 288.0, "episode/score": 0.12722416901422662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12722416901422662}
{"step": 58688, "time": 2065.0849347114563, "episode/length": 288.0, "episode/score": 0.08320692593881063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08320692593881063}
{"step": 59888, "time": 2102.24911403656, "episode/length": 288.0, "episode/score": 0.08529251470446297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08529251470446297}
{"step": 59952, "time": 2104.238456249237, "episode/length": 268.0, "episode/score": 0.2671516573227848, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.1046516656115557}
{"step": 60008, "time": 2111.039351940155, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2111.0457031726837, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2111.0523846149445, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2111.0589060783386, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2111.069785118103, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2111.0765833854675, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2111.0830368995667, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2111.0905809402466, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60112, "time": 2114.5250079631805, "episode/length": 288.0, "episode/score": 0.11304335442210345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11304335442210345}
{"step": 60112, "time": 2114.5324108600616, "episode/length": 288.0, "episode/score": 0.1216294024880824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1216294024880824}
{"step": 60112, "time": 2114.538578271866, "episode/length": 288.0, "episode/score": 0.05599477311815804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05599477311815804}
{"step": 60112, "time": 2114.545266151428, "episode/length": 288.0, "episode/score": 0.09664134249305789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09664134249305789}
{"step": 60400, "time": 2123.534924030304, "episode/length": 288.0, "episode/score": 0.08764061109593513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08764061109593513}
{"step": 61000, "time": 2141.9170587062836, "episode/length": 288.0, "episode/score": 0.11882556504178865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11882556504178865}
{"step": 62200, "time": 2179.380566596985, "episode/length": 288.0, "episode/score": 0.11032808152847906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11032808152847906}
{"step": 62264, "time": 2181.3595678806305, "episode/length": 288.0, "episode/score": 0.10835810872359275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10835810872359275}
{"step": 62424, "time": 2186.3043162822723, "episode/length": 288.0, "episode/score": 0.10090922336206631, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10090922336206631}
{"step": 62424, "time": 2186.311244249344, "episode/length": 288.0, "episode/score": 0.06448700894108583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06448700894108583}
{"step": 62424, "time": 2186.3176131248474, "episode/length": 288.0, "episode/score": 0.1287199702105397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1287199702105397}
{"step": 62424, "time": 2186.3237545490265, "episode/length": 288.0, "episode/score": 0.11896140662469179, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11896140662469179}
{"step": 62712, "time": 2195.311342716217, "episode/length": 288.0, "episode/score": 0.18320224744059033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18320224744059033}
{"step": 63312, "time": 2213.96764421463, "episode/length": 288.0, "episode/score": 0.1398824633766651, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1398824633766651}
{"step": 63881, "time": 2232.493187189102, "train_stats/mean_log_entropy": 1.9373897535611042, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0001245488975252, "train/action_min": 0.0, "train/action_std": 1.9990647141703495, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00046327732662820414, "train/actor_opt_grad_steps": 2910.0, "train/actor_opt_loss": 14.048152858230669, "train/adv_mag": 0.0018452275071652409, "train/adv_max": 0.0018452275071652409, "train/adv_mean": 0.0010341984978616994, "train/adv_min": 5.287960701182409e-05, "train/adv_std": 0.0004830359870409546, "train/cont_avg": 0.9964903236040609, "train/cont_loss_mean": 0.023440668893609254, "train/cont_loss_std": 0.32328147031489374, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.712502628564835, "train/cont_pos_acc": 0.9999999851744792, "train/cont_pos_loss": 0.0033998758334732675, "train/cont_pred": 0.9966061959411893, "train/cont_rate": 0.9964903236040609, "train/dyn_loss_mean": 1.0000000066563564, "train/dyn_loss_std": 1.6416223783389935e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.07067140258924308, "train/extr_critic_critic_opt_grad_steps": 2910.0, "train/extr_critic_critic_opt_loss": 13302.760122541244, "train/extr_critic_mag": 0.08917506394652545, "train/extr_critic_max": 0.08917506394652545, "train/extr_critic_mean": 0.08907127664022639, "train/extr_critic_min": 0.08898126292349723, "train/extr_critic_std": 3.0039339563395202e-05, "train/extr_return_normed_mag": 0.0036948304717915915, "train/extr_return_normed_max": 0.0036948304717915915, "train/extr_return_normed_mean": 0.002966759873549383, "train/extr_return_normed_min": 0.0020393327559311376, "train/extr_return_normed_std": 0.0004816533488559485, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.09083358584170415, "train/extr_return_raw_max": 0.09083358584170415, "train/extr_return_raw_mean": 0.09010552021150056, "train/extr_return_raw_min": 0.08917808812584369, "train/extr_return_raw_std": 0.000481653349299154, "train/extr_reward_mag": 0.00043133733236245094, "train/extr_reward_max": 0.00043133733236245094, "train/extr_reward_mean": 0.0004310296196313244, "train/extr_reward_min": 0.00043062994322801, "train/extr_reward_std": 1.2131558976567905e-07, "train/image_loss_mean": 0.27315716558906633, "train/image_loss_std": 0.0860803672467089, "train/model_loss_mean": 0.9151716014455418, "train/model_loss_std": 0.3566289295626776, "train/model_opt_grad_norm": 79.22204831893069, "train/model_opt_grad_steps": 2900.0, "train/model_opt_loss": 50.778510844041854, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 55.619447969543145, "train/policy_entropy_mag": 1.945873193329361, "train/policy_entropy_max": 1.945873193329361, "train/policy_entropy_mean": 1.944561271498046, "train/policy_entropy_min": 1.9315123007382233, "train/policy_entropy_std": 0.0007792944387003288, "train/policy_logprob_mag": 2.179719780907413, "train/policy_logprob_max": -1.7169328522561165, "train/policy_logprob_mean": -1.9445863465972357, "train/policy_logprob_min": -2.179719780907413, "train/policy_logprob_std": 0.051063442536568276, "train/policy_randomness_mag": 0.999981068415085, "train/policy_randomness_max": 0.999981068415085, "train/policy_randomness_mean": 0.9993068705960578, "train/policy_randomness_min": 0.9926010261332323, "train/policy_randomness_std": 0.00040047815585742957, "train/post_ent_mag": 52.778463237781814, "train/post_ent_max": 52.778463237781814, "train/post_ent_mean": 52.6659615027723, "train/post_ent_min": 52.62542831111075, "train/post_ent_std": 0.017471929336070714, "train/prior_ent_mag": 61.084472520702384, "train/prior_ent_max": 61.084472520702384, "train/prior_ent_mean": 61.010693680816495, "train/prior_ent_min": 60.91147131363147, "train/prior_ent_std": 0.02244849385797675, "train/rep_loss_mean": 1.0000000066563564, "train/rep_loss_std": 1.6416223783389935e-07, "train/reward_avg": 0.0004342156273270319, "train/reward_loss_mean": 0.01857374331010931, "train/reward_loss_std": 0.04907821700317303, "train/reward_max_data": 0.03842533876183372, "train/reward_max_pred": 0.00043139784469217214, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.017833323804141602, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 7.934592050664565, "train/reward_pred": 0.00043089614311223707, "train/reward_rate": 9.4186230964467e-05, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.03087947703897953, "report/cont_loss_std": 0.37739431858062744, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.418506145477295, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004443624056875706, "report/cont_pred": 0.9955663084983826, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2920699715614319, "report/image_loss_std": 0.08098085969686508, "report/model_loss_mean": 0.9424359798431396, "report/model_loss_std": 0.3867335319519043, "report/post_ent_mag": 44.96814727783203, "report/post_ent_max": 44.96814727783203, "report/post_ent_mean": 44.8587646484375, "report/post_ent_min": 44.813472747802734, "report/post_ent_std": 0.018138224259018898, "report/prior_ent_mag": 54.46698760986328, "report/prior_ent_max": 54.46698760986328, "report/prior_ent_mean": 54.42171096801758, "report/prior_ent_min": 54.296897888183594, "report/prior_ent_std": 0.019137535244226456, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00044297994463704526, "report/reward_loss_mean": 0.01948649063706398, "report/reward_loss_std": 0.031218750402331352, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.00042641162872314453, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01948648877441883, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00042641162872314453, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.004443623591214418, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004443623591214418, "eval/cont_pred": 0.9955663084983826, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.270183265209198, "eval/image_loss_std": 0.0832282230257988, "eval/model_loss_mean": 0.8772438168525696, "eval/model_loss_std": 0.0832282230257988, "eval/post_ent_mag": 44.96845245361328, "eval/post_ent_max": 44.96845245361328, "eval/post_ent_mean": 44.858665466308594, "eval/post_ent_min": 44.817649841308594, "eval/post_ent_std": 0.015714948996901512, "eval/prior_ent_mag": 54.45549392700195, "eval/prior_ent_max": 54.45549392700195, "eval/prior_ent_mean": 54.422786712646484, "eval/prior_ent_min": 54.32884979248047, "eval/prior_ent_std": 0.01566116325557232, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00261688232421875, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00042641162872314453, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00261688232421875, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00042641162872314453, "eval/reward_rate": 0.0, "replay/size": 63377.0, "replay/inserts": 31600.0, "replay/samples": 31600.0, "replay/insert_wait_avg": 1.1909158923957922e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.624792147286331e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17240.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0721273763232029e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.241206407547, "timer/env.step_count": 3950.0, "timer/env.step_total": 35.31120705604553, "timer/env.step_frac": 0.03530269182057475, "timer/env.step_avg": 0.00893954609013811, "timer/env.step_min": 0.007456064224243164, "timer/env.step_max": 0.050635337829589844, "timer/replay._sample_count": 31600.0, "timer/replay._sample_total": 15.723902940750122, "timer/replay._sample_frac": 0.01572011114921358, "timer/replay._sample_avg": 0.0004975918652136115, "timer/replay._sample_min": 0.0003566741943359375, "timer/replay._sample_max": 0.035179853439331055, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4817.0, "timer/agent.policy_total": 41.72908353805542, "timer/agent.policy_frac": 0.04171902064295975, "timer/agent.policy_avg": 0.0086628780440223, "timer/agent.policy_min": 0.007523775100708008, "timer/agent.policy_max": 0.07837557792663574, "timer/dataset_train_count": 1975.0, "timer/dataset_train_total": 0.2070317268371582, "timer/dataset_train_frac": 0.00020698180150039068, "timer/dataset_train_avg": 0.00010482619080362441, "timer/dataset_train_min": 8.869171142578125e-05, "timer/dataset_train_max": 0.00023651123046875, "timer/agent.train_count": 1975.0, "timer/agent.train_total": 875.1250190734863, "timer/agent.train_frac": 0.8749139842144413, "timer/agent.train_avg": 0.44310127548024625, "timer/agent.train_min": 0.4324607849121094, "timer/agent.train_max": 0.5809612274169922, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48279595375061035, "timer/agent.report_frac": 0.00048267952835557925, "timer/agent.report_avg": 0.24139797687530518, "timer/agent.report_min": 0.23553991317749023, "timer/agent.report_max": 0.24725604057312012, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.4557113647460938e-05, "timer/dataset_eval_frac": 2.4551191742699684e-08, "timer/dataset_eval_avg": 2.4557113647460938e-05, "timer/dataset_eval_min": 2.4557113647460938e-05, "timer/dataset_eval_max": 2.4557113647460938e-05, "fps": 31.59185125643953}
{"step": 64512, "time": 2251.978758573532, "episode/length": 288.0, "episode/score": 0.11867074052111093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11867074052111093}
{"step": 64576, "time": 2253.9504199028015, "episode/length": 288.0, "episode/score": 0.11938909499326655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11938909499326655}
{"step": 64736, "time": 2258.9273748397827, "episode/length": 288.0, "episode/score": 0.08421551302353691, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08421551302353691}
{"step": 64736, "time": 2258.934193134308, "episode/length": 288.0, "episode/score": 0.12065290333543999, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12065290333543999}
{"step": 64736, "time": 2258.9426884651184, "episode/length": 288.0, "episode/score": 0.10835258499446354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10835258499446354}
{"step": 64736, "time": 2258.9488954544067, "episode/length": 288.0, "episode/score": 0.10267125500922702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10267125500922702}
{"step": 65024, "time": 2267.819581270218, "episode/length": 288.0, "episode/score": 0.10529711863591729, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10529711863591729}
{"step": 65624, "time": 2286.8528945446014, "episode/length": 288.0, "episode/score": 0.1394506828480644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1394506828480644}
{"step": 66824, "time": 2324.113762140274, "episode/length": 288.0, "episode/score": 0.18216920338375076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18216920338375076}
{"step": 66888, "time": 2326.114146709442, "episode/length": 288.0, "episode/score": 0.10020747100611516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10020747100611516}
{"step": 67048, "time": 2331.0941269397736, "episode/length": 288.0, "episode/score": 0.11336433427163684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11336433427163684}
{"step": 67048, "time": 2331.101417541504, "episode/length": 288.0, "episode/score": 0.11661298757451277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11661298757451277}
{"step": 67048, "time": 2331.107903242111, "episode/length": 288.0, "episode/score": 0.13842310709230787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13842310709230787}
{"step": 67048, "time": 2331.114216566086, "episode/length": 288.0, "episode/score": 0.13712787336328347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13712787336328347}
{"step": 67128, "time": 2333.592843770981, "episode/length": 37.0, "episode/score": 0.9140702112340477, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.029695237404212094}
{"step": 67336, "time": 2340.0588834285736, "episode/length": 288.0, "episode/score": 0.12138224588215962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12138224588215962}
{"step": 67936, "time": 2359.202544927597, "episode/length": 288.0, "episode/score": 0.12120595890201002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12120595890201002}
{"step": 68728, "time": 2383.6615467071533, "episode/length": 98.0, "episode/score": 0.7355706359844589, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.04182061377241553}
{"step": 69200, "time": 2398.6446781158447, "episode/length": 288.0, "episode/score": 0.11128256660913394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11128256660913394}
{"step": 69360, "time": 2403.55726647377, "episode/length": 288.0, "episode/score": 0.10738952298208915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10738952298208915}
{"step": 69360, "time": 2403.564960718155, "episode/length": 288.0, "episode/score": 0.11809108613488206, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11809108613488206}
{"step": 69360, "time": 2403.5713493824005, "episode/length": 288.0, "episode/score": 0.07777644942575535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07777644942575535}
{"step": 69360, "time": 2403.577628135681, "episode/length": 288.0, "episode/score": 0.08309959847213122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08309959847213122}
{"step": 69440, "time": 2406.156491994858, "episode/length": 288.0, "episode/score": 0.14220717246132608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14220717246132608}
{"step": 69648, "time": 2412.534039735794, "episode/length": 288.0, "episode/score": 0.1412352539546191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1412352539546191}
{"step": 70096, "time": 2426.9262058734894, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 70096, "time": 2430.8311293125153, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2430.837419986725, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2430.8428733348846, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2430.848329305649, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2430.853603363037, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2430.8588349819183, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2430.864117383957, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 71040, "time": 2459.9810721874237, "episode/length": 288.0, "episode/score": 0.09250822110914214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09250822110914214}
{"step": 71512, "time": 2474.336817264557, "episode/length": 288.0, "episode/score": 0.10257962764649164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10257962764649164}
{"step": 71672, "time": 2479.2679467201233, "episode/length": 288.0, "episode/score": 0.13242824710113155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13242824710113155}
{"step": 71672, "time": 2479.274922847748, "episode/length": 288.0, "episode/score": 0.10937315460023456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10937315460023456}
{"step": 71672, "time": 2479.281051635742, "episode/length": 288.0, "episode/score": 0.125054878153378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.125054878153378}
{"step": 71672, "time": 2479.2871878147125, "episode/length": 288.0, "episode/score": 0.08690341330901674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08690341330901674}
{"step": 71752, "time": 2481.7379581928253, "episode/length": 288.0, "episode/score": 0.08094043536550544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08094043536550544}
{"step": 71960, "time": 2488.1368322372437, "episode/length": 288.0, "episode/score": 0.13001316925272022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13001316925272022}
{"step": 73352, "time": 2531.117490530014, "episode/length": 288.0, "episode/score": 0.09502519057542713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09502519057542713}
{"step": 73824, "time": 2546.352021217346, "episode/length": 288.0, "episode/score": 0.08860577622584742, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08860577622584742}
{"step": 73984, "time": 2551.281234264374, "episode/length": 288.0, "episode/score": 0.12335639056993841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12335639056993841}
{"step": 73984, "time": 2551.2883973121643, "episode/length": 288.0, "episode/score": 0.1083848436467747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1083848436467747}
{"step": 73984, "time": 2551.358577489853, "episode/length": 288.0, "episode/score": 0.12427273729662147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12427273729662147}
{"step": 73984, "time": 2551.3644323349, "episode/length": 288.0, "episode/score": 0.12556592581199766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12556592581199766}
{"step": 74064, "time": 2553.8570291996, "episode/length": 288.0, "episode/score": 0.11998784333820822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11998784333820822}
{"step": 74272, "time": 2560.376662492752, "episode/length": 288.0, "episode/score": 0.10478310014076442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10478310014076442}
{"step": 74728, "time": 2574.244473695755, "episode/length": 92.0, "episode/score": 0.7598816055360658, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.04738163170623011}
{"step": 75472, "time": 2597.5498900413513, "episode/length": 175.0, "episode/score": 0.5167454200486645, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.06362042237697096}
{"step": 75664, "time": 2603.48912858963, "episode/length": 288.0, "episode/score": 0.13814123821953217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13814123821953217}
{"step": 76136, "time": 2617.944309949875, "episode/length": 288.0, "episode/score": 0.10479746733039974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10479746733039974}
{"step": 76296, "time": 2622.8792901039124, "episode/length": 288.0, "episode/score": 0.09731314100258714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09731314100258714}
{"step": 76296, "time": 2622.886234521866, "episode/length": 288.0, "episode/score": 0.10695365321089412, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10695365321089412}
{"step": 76296, "time": 2622.89239859581, "episode/length": 288.0, "episode/score": 0.1144081928439391, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1144081928439391}
{"step": 76584, "time": 2631.7530658245087, "episode/length": 288.0, "episode/score": 0.0654615099572311, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0654615099572311}
{"step": 77040, "time": 2646.150486469269, "episode/length": 288.0, "episode/score": 0.07359929201106752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07359929201106752}
{"step": 77784, "time": 2668.869159221649, "episode/length": 288.0, "episode/score": 0.107514731076094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.107514731076094}
{"step": 77976, "time": 2674.82323551178, "episode/length": 288.0, "episode/score": 0.11272549193961368, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11272549193961368}
{"step": 78448, "time": 2689.625770330429, "episode/length": 288.0, "episode/score": 0.12629655345426727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12629655345426727}
{"step": 78496, "time": 2691.102121114731, "episode/length": 181.0, "episode/score": 0.5530712358656729, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.11869624941641632}
{"step": 78608, "time": 2694.5576643943787, "episode/length": 288.0, "episode/score": 0.16862897237501784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16862897237501784}
{"step": 78608, "time": 2694.5645866394043, "episode/length": 288.0, "episode/score": 0.0854486956089886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0854486956089886}
{"step": 78608, "time": 2694.570293903351, "episode/length": 288.0, "episode/score": 0.08600819588764352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08600819588764352}
{"step": 78896, "time": 2703.4508435726166, "episode/length": 288.0, "episode/score": 0.13184188650075157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13184188650075157}
{"step": 79784, "time": 2730.6592676639557, "episode/length": 146.0, "episode/score": 0.5968769869884909, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.05312700123772629}
{"step": 80080, "time": 2745.0539135932922, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2745.060889005661, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2745.06884765625, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2745.0759665966034, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2745.082549571991, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2745.089807033539, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2745.0965337753296, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2745.1023218631744, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80096, "time": 2745.6074907779694, "episode/length": 288.0, "episode/score": 0.14246828187287974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14246828187287974}
{"step": 80288, "time": 2751.561713695526, "episode/length": 288.0, "episode/score": 0.1108117162907547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1108117162907547}
{"step": 80760, "time": 2766.003181695938, "episode/length": 288.0, "episode/score": 0.10980795714067426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10980795714067426}
{"step": 80808, "time": 2767.483443260193, "episode/length": 288.0, "episode/score": 0.1333713164162873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1333713164162873}
{"step": 80920, "time": 2770.952755689621, "episode/length": 288.0, "episode/score": 0.09872163513091436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09872163513091436}
{"step": 80920, "time": 2770.959864616394, "episode/length": 288.0, "episode/score": 0.06660347204524442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06660347204524442}
{"step": 81208, "time": 2779.8244075775146, "episode/length": 288.0, "episode/score": 0.0834619031791135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0834619031791135}
{"step": 82096, "time": 2808.012391805649, "episode/length": 288.0, "episode/score": 0.06558501322228949, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06558501322228949}
{"step": 82408, "time": 2817.450605392456, "episode/length": 288.0, "episode/score": 0.10221472559283029, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10221472559283029}
{"step": 82600, "time": 2823.390688896179, "episode/length": 288.0, "episode/score": 0.10158713854843882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10158713854843882}
{"step": 83072, "time": 2838.2451734542847, "episode/length": 288.0, "episode/score": 0.09539508913201189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09539508913201189}
{"step": 83120, "time": 2839.727506875992, "episode/length": 288.0, "episode/score": 0.08580271171240383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08580271171240383}
{"step": 83232, "time": 2843.1908206939697, "episode/length": 288.0, "episode/score": 0.11038680992828631, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11038680992828631}
{"step": 83232, "time": 2843.198065519333, "episode/length": 288.0, "episode/score": 0.10114516850421751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10114516850421751}
{"step": 83520, "time": 2852.090231180191, "episode/length": 288.0, "episode/score": 0.09191933806414454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09191933806414454}
{"step": 84408, "time": 2879.3456094264984, "episode/length": 288.0, "episode/score": 0.11015165144749517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11015165144749517}
{"step": 84720, "time": 2889.2999625205994, "episode/length": 288.0, "episode/score": 0.05010552935561918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05010552935561918}
{"step": 84912, "time": 2895.238636493683, "episode/length": 288.0, "episode/score": 0.18238851462660932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18238851462660932}
{"step": 85384, "time": 2909.564687728882, "episode/length": 288.0, "episode/score": 0.10727480227910746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10727480227910746}
{"step": 85432, "time": 2911.0631115436554, "episode/length": 288.0, "episode/score": 0.10965185528596066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10965185528596066}
{"step": 85544, "time": 2914.522503376007, "episode/length": 288.0, "episode/score": 0.12297987055103476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12297987055103476}
{"step": 85544, "time": 2914.5301480293274, "episode/length": 288.0, "episode/score": 0.09916985237816789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09916985237816789}
{"step": 85832, "time": 2923.557847261429, "episode/length": 288.0, "episode/score": 0.13321879431077832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13321879431077832}
{"step": 86720, "time": 2951.3694739341736, "episode/length": 288.0, "episode/score": 0.09222954277572626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09222954277572626}
{"step": 87032, "time": 2960.885493993759, "episode/length": 288.0, "episode/score": 0.17234991799784893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17234991799784893}
{"step": 87224, "time": 2966.812410593033, "episode/length": 288.0, "episode/score": 0.11064726164318017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11064726164318017}
{"step": 87696, "time": 2981.6941707134247, "episode/length": 288.0, "episode/score": 0.08575014738278242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08575014738278242}
{"step": 87744, "time": 2983.1992983818054, "episode/length": 288.0, "episode/score": 0.12262496261735123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12262496261735123}
{"step": 87856, "time": 2986.6922709941864, "episode/length": 288.0, "episode/score": 0.09072735238453333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09072735238453333}
{"step": 87856, "time": 2986.6993594169617, "episode/length": 288.0, "episode/score": 0.12773915170072314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12773915170072314}
{"step": 88144, "time": 2995.5337686538696, "episode/length": 288.0, "episode/score": 0.0929051851190934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0929051851190934}
{"step": 89032, "time": 3022.7673845291138, "episode/length": 288.0, "episode/score": 0.11245319231750273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11245319231750273}
{"step": 89344, "time": 3032.5798671245575, "episode/length": 288.0, "episode/score": 0.12314697342560521, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12314697342560521}
{"step": 89536, "time": 3038.601369380951, "episode/length": 288.0, "episode/score": 0.15925648209559995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15925648209559995}
{"step": 90008, "time": 3052.894521713257, "episode/length": 288.0, "episode/score": 0.08586861486088537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08586861486088537}
{"step": 90056, "time": 3054.382326364517, "episode/length": 288.0, "episode/score": 0.12000322810632724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12000322810632724}
{"step": 90064, "time": 3056.64284658432, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 90064, "time": 3059.9780740737915, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3059.9847359657288, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3059.990374803543, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3059.996063709259, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3060.001676797867, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3060.0080580711365, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3060.013705253601, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90168, "time": 3063.456095457077, "episode/length": 288.0, "episode/score": 0.06672013216859796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06672013216859796}
{"step": 90168, "time": 3063.4632523059845, "episode/length": 288.0, "episode/score": 0.14424810297947488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14424810297947488}
{"step": 90456, "time": 3072.404742717743, "episode/length": 288.0, "episode/score": 0.15259180007359419, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15259180007359419}
{"step": 91344, "time": 3100.015440940857, "episode/length": 288.0, "episode/score": 0.09246604947105652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09246604947105652}
{"step": 91656, "time": 3109.390244960785, "episode/length": 288.0, "episode/score": 0.0882341833951159, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0882341833951159}
{"step": 91848, "time": 3115.2736401557922, "episode/length": 288.0, "episode/score": 0.12271253750094502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12271253750094502}
{"step": 92320, "time": 3130.227377653122, "episode/length": 288.0, "episode/score": 0.09743654584747219, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09743654584747219}
{"step": 92368, "time": 3131.732208967209, "episode/length": 288.0, "episode/score": 0.10689660777933341, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10689660777933341}
{"step": 92480, "time": 3135.262789964676, "episode/length": 288.0, "episode/score": 0.12195082448607764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12195082448607764}
{"step": 92480, "time": 3135.2702713012695, "episode/length": 288.0, "episode/score": 0.14523329126410545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14523329126410545}
{"step": 92768, "time": 3144.334025621414, "episode/length": 288.0, "episode/score": 0.1509738495989268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1509738495989268}
{"step": 93656, "time": 3171.7845215797424, "episode/length": 288.0, "episode/score": 0.1529135797266008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1529135797266008}
{"step": 93968, "time": 3181.6513044834137, "episode/length": 288.0, "episode/score": 0.14546750552904086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14546750552904086}
{"step": 94160, "time": 3187.685210943222, "episode/length": 288.0, "episode/score": 0.1513644344653926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1513644344653926}
{"step": 94632, "time": 3202.0596055984497, "episode/length": 288.0, "episode/score": 0.13116054869340132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13116054869340132}
{"step": 94680, "time": 3203.5616023540497, "episode/length": 288.0, "episode/score": 0.1106725258225083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1106725258225083}
{"step": 94792, "time": 3207.0025565624237, "episode/length": 288.0, "episode/score": 0.09833419855954162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09833419855954162}
{"step": 94792, "time": 3207.009623527527, "episode/length": 288.0, "episode/score": 0.14727826991776283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14727826991776283}
{"step": 95080, "time": 3216.026857852936, "episode/length": 288.0, "episode/score": 0.08254772773892682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08254772773892682}
{"step": 95593, "time": 3232.8658821582794, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0007330383917297, "train/action_min": 0.0, "train/action_std": 2.0001806731175895, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0002249671458662076, "train/actor_opt_grad_steps": 4885.0, "train/actor_opt_loss": 4.490667689290612, "train/adv_mag": 0.000995173899814336, "train/adv_max": 0.000995173899814336, "train/adv_mean": 0.0005333713084617171, "train/adv_min": -2.4114857719402122e-05, "train/adv_std": 0.0002524192706106179, "train/cont_avg": 0.9966116240530303, "train/cont_loss_mean": 0.022705541339213726, "train/cont_loss_std": 0.3169599679014128, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.686123425478763, "train/cont_pos_acc": 0.9999999867545234, "train/cont_pos_loss": 0.003449797515070649, "train/cont_pred": 0.9965563172643835, "train/cont_rate": 0.9966116240530303, "train/dyn_loss_mean": 1.000000004816537, "train/dyn_loss_std": 8.546356349887158e-08, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.026985263367268173, "train/extr_critic_critic_opt_grad_steps": 4885.0, "train/extr_critic_critic_opt_loss": 11638.826985677084, "train/extr_critic_mag": 0.11903337998823686, "train/extr_critic_max": 0.11903337998823686, "train/extr_critic_mean": 0.11893309464659353, "train/extr_critic_min": 0.11885729763242933, "train/extr_critic_std": 3.003943881350932e-05, "train/extr_return_normed_mag": 0.0019344132807519701, "train/extr_return_normed_max": 0.0019344132807519701, "train/extr_return_normed_mean": 0.0015397020496576179, "train/extr_return_normed_min": 0.0010349245535002814, "train/extr_return_normed_std": 0.0002500648164953813, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.1198611491632582, "train/extr_return_raw_max": 0.1198611491632582, "train/extr_return_raw_mean": 0.1194664446091411, "train/extr_return_raw_min": 0.1189616604360065, "train/extr_return_raw_std": 0.00025006481748755734, "train/extr_reward_mag": 0.00044184622138437597, "train/extr_reward_max": 0.00044184622138437597, "train/extr_reward_mean": 0.00044161008569209675, "train/extr_reward_min": 0.00044134168913870144, "train/extr_reward_std": 9.733663948926126e-08, "train/image_loss_mean": 0.2618440505531099, "train/image_loss_std": 0.08486119315329224, "train/model_loss_mean": 0.9030193548009853, "train/model_loss_std": 0.35673597718429084, "train/model_opt_grad_norm": 66.11855937495376, "train/model_opt_grad_steps": 4875.0, "train/model_opt_loss": 197.93618146337644, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 219.38131313131314, "train/policy_entropy_mag": 1.945896200459413, "train/policy_entropy_max": 1.945896200459413, "train/policy_entropy_mean": 1.9452577450058677, "train/policy_entropy_min": 1.9368090942652538, "train/policy_entropy_std": 0.0004219321020751853, "train/policy_logprob_mag": 2.127288924323188, "train/policy_logprob_max": -1.7632260900555234, "train/policy_logprob_mean": -1.9452845917807684, "train/policy_logprob_min": -2.127288924323188, "train/policy_logprob_std": 0.03585659870595643, "train/policy_randomness_mag": 0.999992890490426, "train/policy_randomness_max": 0.999992890490426, "train/policy_randomness_mean": 0.9996647888963873, "train/policy_randomness_min": 0.9953230414727722, "train/policy_randomness_std": 0.00021683024364521237, "train/post_ent_mag": 41.16716864614776, "train/post_ent_max": 41.16716864614776, "train/post_ent_mean": 41.103618775955354, "train/post_ent_min": 41.03881404375789, "train/post_ent_std": 0.018053070684386927, "train/prior_ent_mag": 50.31617220483645, "train/prior_ent_max": 50.31617220483645, "train/prior_ent_mean": 50.27031836846862, "train/prior_ent_min": 50.17025126832904, "train/prior_ent_std": 0.018724953398258998, "train/rep_loss_mean": 1.000000004816537, "train/rep_loss_std": 8.546356349887158e-08, "train/reward_avg": 0.00044577700883206546, "train/reward_loss_mean": 0.018469741252824814, "train/reward_loss_std": 0.05711871436373754, "train/reward_max_data": 0.05834175100681758, "train/reward_max_pred": 0.000441963022405451, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.017491157383027704, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.036026824604381, "train/reward_pred": 0.0004415894044807764, "train/reward_rate": 0.00010850694444444444, "train_stats/mean_log_entropy": 1.937819452662217, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020060548558831215, "report/cont_loss_std": 0.3057047128677368, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.6597394943237305, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003489505499601364, "report/cont_pred": 0.9965164661407471, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.24592718482017517, "report/image_loss_std": 0.089949831366539, "report/model_loss_mean": 0.8803982138633728, "report/model_loss_std": 0.3165836036205292, "report/post_ent_mag": 38.7689323425293, "report/post_ent_max": 38.7689323425293, "report/post_ent_mean": 38.74480438232422, "report/post_ent_min": 38.63490295410156, "report/post_ent_std": 0.026525184512138367, "report/prior_ent_mag": 46.77404022216797, "report/prior_ent_max": 46.77404022216797, "report/prior_ent_mean": 46.73554992675781, "report/prior_ent_min": 46.65950012207031, "report/prior_ent_std": 0.013226622715592384, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00030987331410869956, "report/reward_loss_mean": 0.014410466887056828, "report/reward_loss_std": 0.02511671371757984, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.0004564523696899414, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.014410466887056828, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00045518483966588974, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003489505499601364, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003489505499601364, "eval/cont_pred": 0.9965164661407471, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24451690912246704, "eval/image_loss_std": 0.0896553173661232, "eval/model_loss_mean": 0.8507285118103027, "eval/model_loss_std": 0.08965523540973663, "eval/post_ent_mag": 38.767860412597656, "eval/post_ent_max": 38.767860412597656, "eval/post_ent_mean": 38.746337890625, "eval/post_ent_min": 38.63677215576172, "eval/post_ent_std": 0.025054482743144035, "eval/prior_ent_mag": 46.77404022216797, "eval/prior_ent_max": 46.77404022216797, "eval/prior_ent_mean": 46.736534118652344, "eval/prior_ent_min": 46.64379119873047, "eval/prior_ent_std": 0.013295453041791916, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0027220817282795906, "eval/reward_loss_std": 1.982440608117031e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0004564523696899414, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0027220817282795906, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0004551880992949009, "eval/reward_rate": 0.0, "replay/size": 95089.0, "replay/inserts": 31712.0, "replay/samples": 31712.0, "replay/insert_wait_avg": 1.2010471250647614e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.773639575985197e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24176.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0227662056787617e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3537998199463, "timer/env.step_count": 3964.0, "timer/env.step_total": 34.3155038356781, "timer/env.step_frac": 0.03430336731050009, "timer/env.step_avg": 0.008656787042300227, "timer/env.step_min": 0.007275819778442383, "timer/env.step_max": 0.03873872756958008, "timer/replay._sample_count": 31712.0, "timer/replay._sample_total": 16.096001148223877, "timer/replay._sample_frac": 0.016090308400009072, "timer/replay._sample_avg": 0.0005075681492250214, "timer/replay._sample_min": 0.00036454200744628906, "timer/replay._sample_max": 0.011105775833129883, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4831.0, "timer/agent.policy_total": 41.777740240097046, "timer/agent.policy_frac": 0.04176296451077271, "timer/agent.policy_avg": 0.00864784521633141, "timer/agent.policy_min": 0.007470846176147461, "timer/agent.policy_max": 0.500985860824585, "timer/dataset_train_count": 1982.0, "timer/dataset_train_total": 0.20675301551818848, "timer/dataset_train_frac": 0.00020667989220953822, "timer/dataset_train_avg": 0.00010431534587194172, "timer/dataset_train_min": 8.749961853027344e-05, "timer/dataset_train_max": 0.0003764629364013672, "timer/agent.train_count": 1982.0, "timer/agent.train_total": 877.0879793167114, "timer/agent.train_frac": 0.8767777754976075, "timer/agent.train_avg": 0.4425267302304296, "timer/agent.train_min": 0.4327998161315918, "timer/agent.train_max": 0.5833745002746582, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47617602348327637, "timer/agent.report_frac": 0.00047600761207583085, "timer/agent.report_avg": 0.23808801174163818, "timer/agent.report_min": 0.23265314102172852, "timer/agent.report_max": 0.24352288246154785, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.3603439331054688e-05, "timer/dataset_eval_frac": 2.3595091391968592e-08, "timer/dataset_eval_avg": 2.3603439331054688e-05, "timer/dataset_eval_min": 2.3603439331054688e-05, "timer/dataset_eval_max": 2.3603439331054688e-05, "fps": 31.700251025837556}
{"step": 95768, "time": 3238.052960395813, "episode/length": 135.0, "episode/score": 0.6469603312351637, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.06883533356347016}
{"step": 95968, "time": 3244.4758315086365, "episode/length": 288.0, "episode/score": 0.12182865911728413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12182865911728413}
{"step": 96280, "time": 3254.000241994858, "episode/length": 288.0, "episode/score": 0.10197858516755787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10197858516755787}
{"step": 96368, "time": 3256.911993741989, "episode/length": 160.0, "episode/score": 0.5609373225590844, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.06093729392091518}
{"step": 96408, "time": 3257.9262006282806, "episode/length": 221.0, "episode/score": 0.4364900142112731, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.12711502846050848}
{"step": 96472, "time": 3259.9139909744263, "episode/length": 288.0, "episode/score": 0.10735153331515335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10735153331515335}
{"step": 97104, "time": 3279.6636548042297, "episode/length": 288.0, "episode/score": 0.09865058419384809, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09865058419384809}
{"step": 97104, "time": 3279.670835494995, "episode/length": 288.0, "episode/score": 0.10833006214099328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10833006214099328}
{"step": 98080, "time": 3309.8517162799835, "episode/length": 288.0, "episode/score": 0.15423200489615851, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15423200489615851}
{"step": 98280, "time": 3315.8283126354218, "episode/length": 288.0, "episode/score": 0.09999754967435592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09999754967435592}
{"step": 98592, "time": 3326.377773284912, "episode/length": 288.0, "episode/score": 0.08867550571153515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08867550571153515}
{"step": 98680, "time": 3328.9015877246857, "episode/length": 288.0, "episode/score": 0.10182781098436067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10182781098436067}
{"step": 98720, "time": 3330.370103597641, "episode/length": 288.0, "episode/score": 0.09539951857979645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09539951857979645}
{"step": 98784, "time": 3332.350389957428, "episode/length": 288.0, "episode/score": 0.07509884077421702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07509884077421702}
{"step": 99416, "time": 3351.78653550148, "episode/length": 288.0, "episode/score": 0.14426129054263015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14426129054263015}
{"step": 99416, "time": 3351.793933868408, "episode/length": 288.0, "episode/score": 0.07247917026813866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07247917026813866}
{"step": 100048, "time": 3376.128540992737, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3376.1372439861298, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3376.14302110672, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3376.1487934589386, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3376.154322862625, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3376.159786939621, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3376.1651747226715, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3376.1705656051636, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100392, "time": 3386.6123416423798, "episode/length": 288.0, "episode/score": 0.10773842319019877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10773842319019877}
{"step": 100592, "time": 3393.052064180374, "episode/length": 288.0, "episode/score": 0.08470219359293196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08470219359293196}
{"step": 100704, "time": 3396.658095598221, "episode/length": 247.0, "episode/score": 0.3368719047988691, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.10874690046821911}
{"step": 100904, "time": 3402.6053512096405, "episode/length": 288.0, "episode/score": 0.08387832806056394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08387832806056394}
{"step": 100992, "time": 3405.584214448929, "episode/length": 288.0, "episode/score": 0.09889964251783567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09889964251783567}
{"step": 101096, "time": 3408.6020772457123, "episode/length": 288.0, "episode/score": 0.08103963484302312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08103963484302312}
{"step": 101728, "time": 3428.424464225769, "episode/length": 288.0, "episode/score": 0.08732501747385868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08732501747385868}
{"step": 101728, "time": 3428.431608438492, "episode/length": 288.0, "episode/score": 0.07962903982345892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07962903982345892}
{"step": 102704, "time": 3458.7717049121857, "episode/length": 288.0, "episode/score": 0.1048196900593723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1048196900593723}
{"step": 102904, "time": 3464.7444422245026, "episode/length": 288.0, "episode/score": 0.08033520636845992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08033520636845992}
{"step": 103016, "time": 3468.207898378372, "episode/length": 288.0, "episode/score": 0.1139476818164269, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1139476818164269}
{"step": 103216, "time": 3474.6236004829407, "episode/length": 288.0, "episode/score": 0.12626741519551388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12626741519551388}
{"step": 103304, "time": 3477.130102157593, "episode/length": 288.0, "episode/score": 0.12704680695404136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12704680695404136}
{"step": 103408, "time": 3480.5798482894897, "episode/length": 288.0, "episode/score": 0.08138212946980161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08138212946980161}
{"step": 104040, "time": 3500.0774805545807, "episode/length": 288.0, "episode/score": 0.14356891827196705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14356891827196705}
{"step": 104040, "time": 3500.0847063064575, "episode/length": 288.0, "episode/score": 0.1177643175568619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1177643175568619}
{"step": 105016, "time": 3530.250866174698, "episode/length": 288.0, "episode/score": 0.12688157385264276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12688157385264276}
{"step": 105216, "time": 3536.6436054706573, "episode/length": 288.0, "episode/score": 0.16175689161036644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16175689161036644}
{"step": 105328, "time": 3540.1229569911957, "episode/length": 288.0, "episode/score": 0.14507171459672463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14507171459672463}
{"step": 105528, "time": 3546.2195117473602, "episode/length": 288.0, "episode/score": 0.14164276679002796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14164276679002796}
{"step": 105616, "time": 3549.1689817905426, "episode/length": 288.0, "episode/score": 0.17849062188952303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17849062188952303}
{"step": 105720, "time": 3552.168023109436, "episode/length": 288.0, "episode/score": 0.160321634515185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.160321634515185}
{"step": 106248, "time": 3568.5074486732483, "episode/length": 89.0, "episode/score": 0.7689899156071078, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.047114906014485314}
{"step": 106352, "time": 3571.9532866477966, "episode/length": 288.0, "episode/score": 0.12752894872119214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12752894872119214}
{"step": 106352, "time": 3571.9609558582306, "episode/length": 288.0, "episode/score": 0.2013173137047488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2013173137047488}
{"step": 107328, "time": 3602.7048749923706, "episode/length": 288.0, "episode/score": 0.10999632155335348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10999632155335348}
{"step": 107528, "time": 3608.732825279236, "episode/length": 288.0, "episode/score": 0.14512273141372134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14512273141372134}
{"step": 107640, "time": 3612.190360546112, "episode/length": 288.0, "episode/score": 0.0887735571891426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0887735571891426}
{"step": 107928, "time": 3621.0219600200653, "episode/length": 288.0, "episode/score": 0.17123438270232327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17123438270232327}
{"step": 108032, "time": 3624.4399931430817, "episode/length": 288.0, "episode/score": 0.1075369863206106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1075369863206106}
{"step": 108560, "time": 3640.7808241844177, "episode/length": 288.0, "episode/score": 0.13158091046534537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13158091046534537}
{"step": 108664, "time": 3643.7709879875183, "episode/length": 288.0, "episode/score": 0.10716938462974213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10716938462974213}
{"step": 108664, "time": 3643.7778475284576, "episode/length": 288.0, "episode/score": 0.05211718112491326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05211718112491326}
{"step": 109640, "time": 3674.173110485077, "episode/length": 288.0, "episode/score": 0.12261348804543104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12261348804543104}
{"step": 109840, "time": 3680.580497741699, "episode/length": 288.0, "episode/score": 0.13144703918442247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13144703918442247}
{"step": 109952, "time": 3684.0748472213745, "episode/length": 288.0, "episode/score": 0.12173476803991434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12173476803991434}
{"step": 110032, "time": 3691.2233946323395, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3691.2300794124603, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3691.2356848716736, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3691.2412190437317, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3691.2466871738434, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3691.252253293991, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3691.2577381134033, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3691.2634556293488, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110240, "time": 3697.74928355217, "episode/length": 288.0, "episode/score": 0.07398461323293759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07398461323293759}
{"step": 110344, "time": 3700.724994659424, "episode/length": 288.0, "episode/score": 0.11239101387354822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11239101387354822}
{"step": 110872, "time": 3717.012020111084, "episode/length": 288.0, "episode/score": 0.11565179092713151, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11565179092713151}
{"step": 110976, "time": 3720.4339611530304, "episode/length": 288.0, "episode/score": 0.09563698844669943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09563698844669943}
{"step": 110976, "time": 3720.4410858154297, "episode/length": 288.0, "episode/score": 0.10181987104976997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10181987104976997}
{"step": 111248, "time": 3728.923629760742, "episode/length": 161.0, "episode/score": 0.5859465336613994, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.08907154791063476}
{"step": 111952, "time": 3750.796886920929, "episode/length": 288.0, "episode/score": 0.087010985173265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.087010985173265}
{"step": 112152, "time": 3756.972846031189, "episode/length": 288.0, "episode/score": 0.10236491571993156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10236491571993156}
{"step": 112552, "time": 3769.516350746155, "episode/length": 288.0, "episode/score": 0.11656967346050351, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11656967346050351}
{"step": 112656, "time": 3773.008369445801, "episode/length": 288.0, "episode/score": 0.0703814254561621, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0703814254561621}
{"step": 113184, "time": 3789.4141454696655, "episode/length": 288.0, "episode/score": 0.08222233990807126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08222233990807126}
{"step": 113288, "time": 3792.4180991649628, "episode/length": 288.0, "episode/score": 0.16304973775652343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16304973775652343}
{"step": 113288, "time": 3792.4251375198364, "episode/length": 288.0, "episode/score": 0.11191971669080658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11191971669080658}
{"step": 113560, "time": 3800.820702791214, "episode/length": 288.0, "episode/score": 0.10758462177273032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10758462177273032}
{"step": 114264, "time": 3822.692506313324, "episode/length": 288.0, "episode/score": 0.08831763756938926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08831763756938926}
{"step": 114464, "time": 3829.0853140354156, "episode/length": 288.0, "episode/score": 0.08854846034307684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08854846034307684}
{"step": 114864, "time": 3841.9111585617065, "episode/length": 288.0, "episode/score": 0.14641684910645836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14641684910645836}
{"step": 114968, "time": 3844.942302942276, "episode/length": 288.0, "episode/score": 0.09486161044981145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09486161044981145}
{"step": 115496, "time": 3861.460362434387, "episode/length": 288.0, "episode/score": 0.07937684513814247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07937684513814247}
{"step": 115600, "time": 3864.944043159485, "episode/length": 288.0, "episode/score": 0.09996844139362793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09996844139362793}
{"step": 115600, "time": 3864.9520082473755, "episode/length": 288.0, "episode/score": 0.09875621319650918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09875621319650918}
{"step": 115872, "time": 3873.489467382431, "episode/length": 288.0, "episode/score": 0.12712386043256174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12712386043256174}
{"step": 116576, "time": 3895.6329295635223, "episode/length": 288.0, "episode/score": 0.1095171373463586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1095171373463586}
{"step": 116776, "time": 3901.7451980113983, "episode/length": 288.0, "episode/score": 0.15666392844582333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15666392844582333}
{"step": 117176, "time": 3914.2227926254272, "episode/length": 288.0, "episode/score": 0.08788723419138478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08788723419138478}
{"step": 117280, "time": 3917.6405322551727, "episode/length": 288.0, "episode/score": 0.09978376859851323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09978376859851323}
{"step": 117488, "time": 3924.0172448158264, "episode/length": 201.0, "episode/score": 0.45737054389115883, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.08549555744190229}
{"step": 117808, "time": 3933.805761575699, "episode/length": 288.0, "episode/score": 0.1680897742166394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1680897742166394}
{"step": 117912, "time": 3936.9153554439545, "episode/length": 288.0, "episode/score": 0.08976533105214912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08976533105214912}
{"step": 117912, "time": 3936.9224824905396, "episode/length": 288.0, "episode/score": 0.13456050530629682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13456050530629682}
{"step": 118888, "time": 3966.964959383011, "episode/length": 288.0, "episode/score": 0.15616214314650279, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15616214314650279}
{"step": 119088, "time": 3973.4146208763123, "episode/length": 288.0, "episode/score": 0.09289538563638189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09289538563638189}
{"step": 119488, "time": 3985.74610042572, "episode/length": 288.0, "episode/score": 0.15125071486482966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15125071486482966}
{"step": 119592, "time": 3988.7274985313416, "episode/length": 288.0, "episode/score": 0.08876710660200615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08876710660200615}
{"step": 119800, "time": 3995.2652459144592, "episode/length": 288.0, "episode/score": 0.13860015303390583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13860015303390583}
{"step": 120016, "time": 4006.893052816391, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4006.897225856781, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4006.902956724167, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4006.9086997509003, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4006.914258003235, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4006.919906616211, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4006.925594329834, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4006.9313826560974, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120120, "time": 4009.9762196540833, "episode/length": 288.0, "episode/score": 0.16185409469454726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16185409469454726}
{"step": 120224, "time": 4013.441188097, "episode/length": 288.0, "episode/score": 0.13395619709342554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13395619709342554}
{"step": 120224, "time": 4013.4485545158386, "episode/length": 288.0, "episode/score": 0.11628404802513614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11628404802513614}
{"step": 121200, "time": 4043.857756614685, "episode/length": 288.0, "episode/score": 0.17644175081403546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17644175081403546}
{"step": 121400, "time": 4049.8845143318176, "episode/length": 288.0, "episode/score": 0.12183283587546612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12183283587546612}
{"step": 121800, "time": 4062.310087442398, "episode/length": 288.0, "episode/score": 0.1197164640830124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1197164640830124}
{"step": 121904, "time": 4065.73601269722, "episode/length": 288.0, "episode/score": 0.1540170757375563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1540170757375563}
{"step": 122112, "time": 4072.1392035484314, "episode/length": 288.0, "episode/score": 0.09535710666159503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09535710666159503}
{"step": 122432, "time": 4082.004464864731, "episode/length": 288.0, "episode/score": 0.09504265873670192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09504265873670192}
{"step": 122536, "time": 4085.158594608307, "episode/length": 288.0, "episode/score": 0.0905657710345622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0905657710345622}
{"step": 122536, "time": 4085.166025876999, "episode/length": 288.0, "episode/score": 0.1411169143996176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1411169143996176}
{"step": 123512, "time": 4115.924715518951, "episode/length": 288.0, "episode/score": 0.07333313217327486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07333313217327486}
{"step": 123712, "time": 4122.297071218491, "episode/length": 288.0, "episode/score": 0.09105534292700668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09105534292700668}
{"step": 124112, "time": 4134.71776676178, "episode/length": 288.0, "episode/score": 0.05217562813254517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05217562813254517}
{"step": 124216, "time": 4137.729022741318, "episode/length": 288.0, "episode/score": 0.08406947534547271, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08406947534547271}
{"step": 124424, "time": 4144.153851985931, "episode/length": 288.0, "episode/score": 0.10970114332928915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10970114332928915}
{"step": 124744, "time": 4154.13484454155, "episode/length": 288.0, "episode/score": 0.08333491431301354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08333491431301354}
{"step": 124848, "time": 4157.56457233429, "episode/length": 288.0, "episode/score": 0.1763827130531581, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1763827130531581}
{"step": 124848, "time": 4157.571745157242, "episode/length": 288.0, "episode/score": 0.15141728042556224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15141728042556224}
{"step": 125824, "time": 4187.755452632904, "episode/length": 288.0, "episode/score": 0.1293354139306757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1293354139306757}
{"step": 126024, "time": 4193.70140337944, "episode/length": 288.0, "episode/score": 0.0470771670737804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0470771670737804}
{"step": 126424, "time": 4206.107923030853, "episode/length": 288.0, "episode/score": 0.09565674304826643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09565674304826643}
{"step": 126528, "time": 4209.537252187729, "episode/length": 288.0, "episode/score": 0.11227532118630279, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11227532118630279}
{"step": 126736, "time": 4215.939991474152, "episode/length": 288.0, "episode/score": 0.12733418667812657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12733418667812657}
{"step": 127056, "time": 4225.798763751984, "episode/length": 288.0, "episode/score": 0.0944800613362986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0944800613362986}
{"step": 127160, "time": 4228.792001485825, "episode/length": 288.0, "episode/score": 0.123787227564776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.123787227564776}
{"step": 127160, "time": 4228.799097061157, "episode/length": 288.0, "episode/score": 0.040271677044643184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040271677044643184}
{"step": 127273, "time": 4233.243668079376, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.999365604285038, "train/action_min": 0.0, "train/action_std": 2.0002415198268313, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00013893874575392193, "train/actor_opt_grad_steps": 6865.0, "train/actor_opt_loss": 0.3296070406707286, "train/adv_mag": 0.0006330896056059635, "train/adv_max": 0.0006273570235329445, "train/adv_mean": 0.0003154900391059022, "train/adv_min": -4.525061207588273e-05, "train/adv_std": 0.00015532503956902391, "train/cont_avg": 0.9963403566919192, "train/cont_loss_mean": 0.024188142069944678, "train/cont_loss_std": 0.3290358342364374, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.657441976119061, "train/cont_pos_acc": 0.9999999876576241, "train/cont_pos_loss": 0.0035335215448279575, "train/cont_pred": 0.9964728442707447, "train/cont_rate": 0.9963403566919192, "train/dyn_loss_mean": 1.0134816434648302, "train/dyn_loss_std": 0.0003706520103444957, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.021556474802300635, "train/extr_critic_critic_opt_grad_steps": 6865.0, "train/extr_critic_critic_opt_loss": 9611.807686237375, "train/extr_critic_mag": 0.1352052092552185, "train/extr_critic_max": 0.1352052092552185, "train/extr_critic_mean": 0.13510676812041889, "train/extr_critic_min": 0.13503393741569134, "train/extr_critic_std": 2.2682437264651554e-05, "train/extr_return_normed_mag": 0.0011598621353958592, "train/extr_return_normed_max": 0.0011573842529094581, "train/extr_return_normed_mean": 0.0009074361353237011, "train/extr_return_normed_min": 0.0005952447953850332, "train/extr_return_normed_std": 0.00015222787866297601, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.1356722184202888, "train/extr_return_raw_max": 0.1356722184202888, "train/extr_return_raw_mean": 0.1354222773301481, "train/extr_return_raw_min": 0.13511007896276436, "train/extr_return_raw_std": 0.0001522278788513057, "train/extr_reward_mag": 0.0004559839614714035, "train/extr_reward_max": 0.0004559839614714035, "train/extr_reward_mean": 0.0004557300969897158, "train/extr_reward_min": 0.0004554938788365836, "train/extr_reward_std": 1.20640267021418e-07, "train/image_loss_mean": 0.2562187553355188, "train/image_loss_std": 0.08434953533037744, "train/model_loss_mean": 0.9075578138081715, "train/model_loss_std": 0.37934741295046276, "train/model_opt_grad_norm": 56.12154023334234, "train/model_opt_grad_steps": 6855.0, "train/model_opt_loss": 791.125165534742, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 868.0555555555555, "train/policy_entropy_mag": 1.9458959963586595, "train/policy_entropy_max": 1.9458959963586595, "train/policy_entropy_mean": 1.9452692023431413, "train/policy_entropy_min": 1.9355024839892532, "train/policy_entropy_std": 0.0004424270450589106, "train/policy_logprob_mag": 2.1329630805988504, "train/policy_logprob_max": -1.7588450667834041, "train/policy_logprob_mean": -1.945244510366459, "train/policy_logprob_min": -2.1329630805988504, "train/policy_logprob_std": 0.03503932614782543, "train/policy_randomness_mag": 0.9999927866338479, "train/policy_randomness_max": 0.9999927866338479, "train/policy_randomness_mean": 0.9996706725973071, "train/policy_randomness_min": 0.9946515749801289, "train/policy_randomness_std": 0.00022736251948935195, "train/post_ent_mag": 44.97112659492878, "train/post_ent_max": 44.97112659492878, "train/post_ent_mean": 44.93321021879562, "train/post_ent_min": 44.673302756415474, "train/post_ent_std": 0.057577141301913395, "train/prior_ent_mag": 49.67834534307923, "train/prior_ent_max": 49.67834534307923, "train/prior_ent_mean": 49.62986333442457, "train/prior_ent_min": 49.493467061206545, "train/prior_ent_std": 0.024513259807582757, "train/rep_loss_mean": 1.0134816434648302, "train/rep_loss_std": 0.0003706520103444957, "train/reward_avg": 0.0004688455742922602, "train/reward_loss_mean": 0.019061906220899386, "train/reward_loss_std": 0.07312269620785508, "train/reward_max_data": 0.08046085828670649, "train/reward_max_pred": 0.00045579972893300684, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.01750469421779718, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.045134235830869, "train/reward_pred": 0.0004555089605003219, "train/reward_rate": 0.00017262468434343434, "train_stats/mean_log_entropy": 1.9382393715674417, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.036440592259168625, "report/cont_loss_std": 0.4251372516155243, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.574114799499512, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0038020536303520203, "report/cont_pred": 0.9962052702903748, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2512738108634949, "report/image_loss_std": 0.08824241161346436, "report/model_loss_mean": 0.9064972400665283, "report/model_loss_std": 0.4363270401954651, "report/post_ent_mag": 59.00123596191406, "report/post_ent_max": 59.00123596191406, "report/post_ent_mean": 58.98936462402344, "report/post_ent_min": 58.94841384887695, "report/post_ent_std": 0.009679300710558891, "report/prior_ent_mag": 57.12660217285156, "report/prior_ent_max": 57.12660217285156, "report/prior_ent_mean": 57.094520568847656, "report/prior_ent_min": 56.861507415771484, "report/prior_ent_std": 0.04231913015246391, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00042568863136693835, "report/reward_loss_mean": 0.01878279447555542, "report/reward_loss_std": 0.030604423955082893, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.0004271268844604492, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01878279447555542, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0004271268844604492, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0038020533975213766, "eval/cont_loss_std": 6.984919309616089e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0038020533975213766, "eval/cont_pred": 0.9962052702903748, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24549272656440735, "eval/image_loss_std": 0.08309324830770493, "eval/model_loss_mean": 0.8518267869949341, "eval/model_loss_std": 0.08309324085712433, "eval/post_ent_mag": 59.000274658203125, "eval/post_ent_max": 59.000274658203125, "eval/post_ent_mean": 58.99028015136719, "eval/post_ent_min": 58.94823455810547, "eval/post_ent_std": 0.008538016118109226, "eval/prior_ent_mag": 57.12346267700195, "eval/prior_ent_max": 57.12346267700195, "eval/prior_ent_mean": 57.097999572753906, "eval/prior_ent_min": 56.861507415771484, "eval/prior_ent_std": 0.036504097282886505, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0025320053100585938, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0004271268844604492, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0025320053100585938, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0004271268844604492, "eval/reward_rate": 0.0, "replay/size": 126769.0, "replay/inserts": 31680.0, "replay/samples": 31680.0, "replay/insert_wait_avg": 1.1904372109307183e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.831689083214962e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31112.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0838489356475443e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3623852729797, "timer/env.step_count": 3960.0, "timer/env.step_total": 34.212289333343506, "timer/env.step_frac": 0.03419989579477004, "timer/env.step_avg": 0.008639467003369572, "timer/env.step_min": 0.007247209548950195, "timer/env.step_max": 0.0384221076965332, "timer/replay._sample_count": 31680.0, "timer/replay._sample_total": 16.1930251121521, "timer/replay._sample_frac": 0.016187159124074157, "timer/replay._sample_avg": 0.0005111434694492456, "timer/replay._sample_min": 0.00037407875061035156, "timer/replay._sample_max": 0.011646032333374023, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4827.0, "timer/agent.policy_total": 41.096094369888306, "timer/agent.policy_frac": 0.04108120714542257, "timer/agent.policy_avg": 0.008513796223303978, "timer/agent.policy_min": 0.007474184036254883, "timer/agent.policy_max": 0.07619881629943848, "timer/dataset_train_count": 1980.0, "timer/dataset_train_total": 0.21036863327026367, "timer/dataset_train_frac": 0.00021029242639192006, "timer/dataset_train_avg": 0.00010624678447993114, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.0003466606140136719, "timer/agent.train_count": 1980.0, "timer/agent.train_total": 878.038871049881, "timer/agent.train_frac": 0.8777207979589127, "timer/agent.train_avg": 0.4434539752777177, "timer/agent.train_min": 0.4327878952026367, "timer/agent.train_max": 0.5940213203430176, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47069311141967773, "timer/agent.report_frac": 0.0004705226009584863, "timer/agent.report_avg": 0.23534655570983887, "timer/agent.report_min": 0.22162365913391113, "timer/agent.report_max": 0.2490694522857666, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.955319416625839e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 31.667999173886557}
{"step": 128136, "time": 4259.689329624176, "episode/length": 288.0, "episode/score": 0.10698590285028331, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10698590285028331}
{"step": 128336, "time": 4266.184881448746, "episode/length": 288.0, "episode/score": 0.05538275145863736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05538275145863736}
{"step": 128736, "time": 4278.533970117569, "episode/length": 288.0, "episode/score": 0.09883307598965985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09883307598965985}
{"step": 128840, "time": 4281.543867588043, "episode/length": 288.0, "episode/score": 0.11471925407340677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11471925407340677}
{"step": 129048, "time": 4287.958742380142, "episode/length": 288.0, "episode/score": 0.09996032418303002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09996032418303002}
{"step": 129368, "time": 4297.896727323532, "episode/length": 288.0, "episode/score": 0.12044271028435105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12044271028435105}
{"step": 129472, "time": 4301.305611371994, "episode/length": 288.0, "episode/score": 0.10436023500369629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10436023500369629}
{"step": 129472, "time": 4301.312777996063, "episode/length": 288.0, "episode/score": 0.08905250806606091, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08905250806606091}
{"step": 130000, "time": 4322.5342173576355, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4322.540603399277, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4322.546123981476, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4322.551630973816, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4322.556822538376, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4322.562171936035, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4322.567325115204, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4322.57260966301, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130448, "time": 4336.450751543045, "episode/length": 288.0, "episode/score": 0.1450772815626351, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1450772815626351}
{"step": 130648, "time": 4342.369568824768, "episode/length": 288.0, "episode/score": 0.09614641011125968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09614641011125968}
{"step": 131048, "time": 4354.684954166412, "episode/length": 288.0, "episode/score": 0.08724317104872625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08724317104872625}
{"step": 131152, "time": 4358.711205482483, "episode/length": 288.0, "episode/score": 0.13758585714094806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13758585714094806}
{"step": 131360, "time": 4365.150362968445, "episode/length": 288.0, "episode/score": 0.12587552775812583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12587552775812583}
{"step": 131680, "time": 4375.161495923996, "episode/length": 288.0, "episode/score": 0.130867924118661, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.130867924118661}
{"step": 131784, "time": 4378.162328004837, "episode/length": 288.0, "episode/score": 0.10437210201985181, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10437210201985181}
{"step": 131784, "time": 4378.178054094315, "episode/length": 288.0, "episode/score": 0.11413836446479309, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11413836446479309}
{"step": 132760, "time": 4408.294085979462, "episode/length": 288.0, "episode/score": 0.14013229192448762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14013229192448762}
{"step": 132960, "time": 4414.659595489502, "episode/length": 288.0, "episode/score": 0.15999640200368503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15999640200368503}
{"step": 133200, "time": 4422.111665248871, "episode/length": 29.0, "episode/score": 0.9476416092259115, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.038266599633288934}
{"step": 133360, "time": 4427.0415279865265, "episode/length": 288.0, "episode/score": 0.12235953718425208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12235953718425208}
{"step": 133464, "time": 4430.041352510452, "episode/length": 288.0, "episode/score": 0.09124001160535045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09124001160535045}
{"step": 133672, "time": 4436.531750917435, "episode/length": 288.0, "episode/score": 0.12005791468538973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12005791468538973}
{"step": 133992, "time": 4446.537731170654, "episode/length": 288.0, "episode/score": 0.07402913198018268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07402913198018268}
{"step": 134096, "time": 4449.975003242493, "episode/length": 288.0, "episode/score": 0.13137086888741578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13137086888741578}
{"step": 134096, "time": 4449.98242354393, "episode/length": 288.0, "episode/score": 0.13536136645245733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13536136645245733}
{"step": 134248, "time": 4454.462464332581, "episode/length": 130.0, "episode/score": 0.6584041577767721, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.06465416010507852}
{"step": 135072, "time": 4480.322078466415, "episode/length": 288.0, "episode/score": 0.14088401610410983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14088401610410983}
{"step": 135672, "time": 4499.32618188858, "episode/length": 288.0, "episode/score": 0.08823618709038783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08823618709038783}
{"step": 135776, "time": 4502.756160020828, "episode/length": 288.0, "episode/score": 0.07012099830149054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07012099830149054}
{"step": 135984, "time": 4509.281893491745, "episode/length": 288.0, "episode/score": 0.12235163492948686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12235163492948686}
{"step": 136304, "time": 4519.483799934387, "episode/length": 288.0, "episode/score": 0.08188266597858274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08188266597858274}
{"step": 136408, "time": 4522.459495067596, "episode/length": 288.0, "episode/score": 0.0848095902329078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0848095902329078}
{"step": 136408, "time": 4522.466779708862, "episode/length": 288.0, "episode/score": 0.09207298914316198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09207298914316198}
{"step": 136560, "time": 4527.357044696808, "episode/length": 288.0, "episode/score": 0.11877322585178263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11877322585178263}
{"step": 137384, "time": 4552.702761411667, "episode/length": 288.0, "episode/score": 0.10218819337546847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10218819337546847}
{"step": 137984, "time": 4571.478268623352, "episode/length": 288.0, "episode/score": 0.11130029468904468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11130029468904468}
{"step": 138088, "time": 4574.53368473053, "episode/length": 288.0, "episode/score": 0.14068589238286222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14068589238286222}
{"step": 138296, "time": 4581.0564057827, "episode/length": 288.0, "episode/score": 0.11598096060765783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11598096060765783}
{"step": 138616, "time": 4590.942219495773, "episode/length": 288.0, "episode/score": 0.12873963957179058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12873963957179058}
{"step": 138720, "time": 4594.412262201309, "episode/length": 288.0, "episode/score": 0.13650391100452453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13650391100452453}
{"step": 138720, "time": 4594.418791294098, "episode/length": 288.0, "episode/score": 0.1197692315004133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1197692315004133}
{"step": 138872, "time": 4598.988870859146, "episode/length": 288.0, "episode/score": 0.07914746755443502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07914746755443502}
{"step": 139696, "time": 4625.314547777176, "episode/length": 288.0, "episode/score": 0.14681196250080575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14681196250080575}
{"step": 140088, "time": 4641.686891078949, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4641.693696260452, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4641.699183702469, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4641.704587697983, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4641.7099714279175, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4641.715296268463, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4641.72056388855, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4641.726083040237, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140296, "time": 4648.172299146652, "episode/length": 288.0, "episode/score": 0.15816054854792583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15816054854792583}
{"step": 140400, "time": 4651.593283176422, "episode/length": 288.0, "episode/score": 0.11197409678004533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11197409678004533}
{"step": 140608, "time": 4658.228069782257, "episode/length": 288.0, "episode/score": 0.11772803616008787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11772803616008787}
{"step": 140928, "time": 4668.060661315918, "episode/length": 288.0, "episode/score": 0.17001726163937292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17001726163937292}
{"step": 141032, "time": 4671.029884338379, "episode/length": 288.0, "episode/score": 0.16022303602278498, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16022303602278498}
{"step": 141032, "time": 4671.048065900803, "episode/length": 288.0, "episode/score": 0.1481891785906555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1481891785906555}
{"step": 141184, "time": 4675.961449146271, "episode/length": 288.0, "episode/score": 0.1542209986010903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1542209986010903}
{"step": 142008, "time": 4701.23108959198, "episode/length": 288.0, "episode/score": 0.07262377853146518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07262377853146518}
{"step": 142608, "time": 4720.18190908432, "episode/length": 288.0, "episode/score": 0.1282728378062643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1282728378062643}
{"step": 142712, "time": 4723.234848022461, "episode/length": 288.0, "episode/score": 0.14157633043316764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14157633043316764}
{"step": 142920, "time": 4729.7456822395325, "episode/length": 288.0, "episode/score": 0.09059588885338599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09059588885338599}
{"step": 143240, "time": 4739.634407997131, "episode/length": 288.0, "episode/score": 0.1307845175657576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1307845175657576}
{"step": 143344, "time": 4743.090276479721, "episode/length": 288.0, "episode/score": 0.17448141767789593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17448141767789593}
{"step": 143344, "time": 4743.097393035889, "episode/length": 288.0, "episode/score": 0.15787078920664044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15787078920664044}
{"step": 143496, "time": 4747.700252532959, "episode/length": 288.0, "episode/score": 0.10758926528177426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10758926528177426}
{"step": 144320, "time": 4773.281261444092, "episode/length": 288.0, "episode/score": 0.14061048061728343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14061048061728343}
{"step": 144440, "time": 4776.912340402603, "episode/length": 136.0, "episode/score": 0.6608020030712396, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.08580201732047499}
{"step": 144920, "time": 4791.774026632309, "episode/length": 288.0, "episode/score": 0.13776278527012664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13776278527012664}
{"step": 145024, "time": 4795.1975865364075, "episode/length": 288.0, "episode/score": 0.11716438604167934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11716438604167934}
{"step": 145232, "time": 4801.65035033226, "episode/length": 288.0, "episode/score": 0.11743329276669101, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11743329276669101}
{"step": 145424, "time": 4807.691231966019, "episode/length": 259.0, "episode/score": 0.30904705941929933, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.118422064727838}
{"step": 145552, "time": 4811.664492607117, "episode/length": 288.0, "episode/score": 0.12901595838684443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12901595838684443}
{"step": 145808, "time": 4819.606407403946, "episode/length": 288.0, "episode/score": 0.1335615338905427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1335615338905427}
{"step": 146632, "time": 4845.042636156082, "episode/length": 288.0, "episode/score": 0.16598525493031957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16598525493031957}
{"step": 146752, "time": 4848.983924865723, "episode/length": 288.0, "episode/score": 0.12681013640258243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12681013640258243}
{"step": 146960, "time": 4855.400663852692, "episode/length": 254.0, "episode/score": 0.3144245224093538, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.10817452701940056}
{"step": 147336, "time": 4866.914333820343, "episode/length": 288.0, "episode/score": 0.18446529338018536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18446529338018536}
{"step": 147544, "time": 4873.820148706436, "episode/length": 288.0, "episode/score": 0.16471674217484633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16471674217484633}
{"step": 147736, "time": 4879.790159225464, "episode/length": 288.0, "episode/score": 0.13568226646088988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13568226646088988}
{"step": 147864, "time": 4883.791611433029, "episode/length": 288.0, "episode/score": 0.18333053380047204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18333053380047204}
{"step": 148120, "time": 4891.750292778015, "episode/length": 288.0, "episode/score": 0.10366049678737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10366049678737}
{"step": 148200, "time": 4894.229967832565, "episode/length": 195.0, "episode/score": 0.468650142009551, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.07802514433785745}
{"step": 149064, "time": 4921.018972158432, "episode/length": 288.0, "episode/score": 0.15643256245789416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15643256245789416}
{"step": 149272, "time": 4927.554667472839, "episode/length": 288.0, "episode/score": 0.12895340439115444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12895340439115444}
{"step": 149648, "time": 4939.4972932338715, "episode/length": 288.0, "episode/score": 0.13771105603962042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13771105603962042}
{"step": 149856, "time": 4945.925177335739, "episode/length": 288.0, "episode/score": 0.1286931077125928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1286931077125928}
{"step": 150048, "time": 4951.860087394714, "episode/length": 288.0, "episode/score": 0.1015016688435253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1015016688435253}
{"step": 150072, "time": 4955.996054887772, "eval_episode/length": 222.0, "eval_episode/score": 0.3062500059604645, "eval_episode/reward_rate": 0.004484304932735426}
{"step": 150072, "time": 4957.036048173904, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4957.044506549835, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4957.050725698471, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4957.057248353958, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4957.062852144241, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4957.068303108215, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4957.07381772995, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150176, "time": 4960.502015113831, "episode/length": 288.0, "episode/score": 0.16236004872928333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16236004872928333}
{"step": 150432, "time": 4968.394886732101, "episode/length": 288.0, "episode/score": 0.1392917630695365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1392917630695365}
{"step": 150512, "time": 4970.875160694122, "episode/length": 288.0, "episode/score": 0.11859602831691518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11859602831691518}
{"step": 151000, "time": 4985.777890920639, "episode/length": 118.0, "episode/score": 0.6924796519091387, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.06122959942911166}
{"step": 151144, "time": 4990.204068183899, "episode/length": 17.0, "episode/score": 0.9663238673203978, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.019448892792070183}
{"step": 151376, "time": 4997.570518016815, "episode/length": 288.0, "episode/score": 0.09846162342500975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09846162342500975}
{"step": 151584, "time": 5003.949594974518, "episode/length": 288.0, "episode/score": 0.12647162603633433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12647162603633433}
{"step": 151960, "time": 5015.428641319275, "episode/length": 288.0, "episode/score": 0.1063226273185478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1063226273185478}
{"step": 152168, "time": 5021.800822496414, "episode/length": 288.0, "episode/score": 0.0491818309340033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0491818309340033}
{"step": 152424, "time": 5029.639620304108, "episode/length": 280.0, "episode/score": 0.2071411134084542, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.08214111503826871}
{"step": 152744, "time": 5039.459524393082, "episode/length": 288.0, "episode/score": 0.11931664935900699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11931664935900699}
{"step": 152824, "time": 5041.928633928299, "episode/length": 288.0, "episode/score": 0.106661885714459, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.106661885714459}
{"step": 153456, "time": 5061.753202676773, "episode/length": 288.0, "episode/score": 0.14853222269897515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14853222269897515}
{"step": 153688, "time": 5068.662930011749, "episode/length": 288.0, "episode/score": 0.0922831368225161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0922831368225161}
{"step": 153896, "time": 5075.224813938141, "episode/length": 288.0, "episode/score": 0.09459060306289757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09459060306289757}
{"step": 153992, "time": 5078.185410261154, "episode/length": 253.0, "episode/score": 0.32156364447041597, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.11218865275918688}
{"step": 154480, "time": 5093.4774515628815, "episode/length": 288.0, "episode/score": 0.1295520648303068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1295520648303068}
{"step": 154736, "time": 5101.397881269455, "episode/length": 288.0, "episode/score": 0.13011651092966758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13011651092966758}
{"step": 155056, "time": 5111.3932383060455, "episode/length": 288.0, "episode/score": 0.13713645425275445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13713645425275445}
{"step": 155136, "time": 5113.857015132904, "episode/length": 288.0, "episode/score": 0.09244850558820872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09244850558820872}
{"step": 155768, "time": 5133.624315738678, "episode/length": 288.0, "episode/score": 0.11220543382978576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11220543382978576}
{"step": 156000, "time": 5141.123642921448, "episode/length": 288.0, "episode/score": 0.11773049106932376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11773049106932376}
{"step": 156208, "time": 5147.5809054374695, "episode/length": 288.0, "episode/score": 0.1121425074641138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1121425074641138}
{"step": 156304, "time": 5150.610923290253, "episode/length": 288.0, "episode/score": 0.13229959830505322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13229959830505322}
{"step": 156792, "time": 5165.754503250122, "episode/length": 288.0, "episode/score": 0.13159600870767463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13159600870767463}
{"step": 157048, "time": 5173.71777844429, "episode/length": 288.0, "episode/score": 0.09340554426125891, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09340554426125891}
{"step": 157368, "time": 5183.599139451981, "episode/length": 288.0, "episode/score": 0.10663243523799792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10663243523799792}
{"step": 157448, "time": 5186.087825298309, "episode/length": 288.0, "episode/score": 0.15632695015483478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15632695015483478}
{"step": 158080, "time": 5205.819220542908, "episode/length": 288.0, "episode/score": 0.08998014882001826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08998014882001826}
{"step": 158312, "time": 5212.80939078331, "episode/length": 288.0, "episode/score": 0.1273080514006324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1273080514006324}
{"step": 158520, "time": 5219.289653778076, "episode/length": 288.0, "episode/score": 0.09572605176572324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09572605176572324}
{"step": 158616, "time": 5222.2715928554535, "episode/length": 288.0, "episode/score": 0.09673875904650231, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09673875904650231}
{"step": 158937, "time": 5233.420333623886, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.999386257595486, "train/action_min": 0.0, "train/action_std": 2.0001602678587944, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 8.324601985621466e-05, "train/actor_opt_grad_steps": 8845.0, "train/actor_opt_loss": -2.86881789931971, "train/adv_mag": 0.00042530066437191435, "train/adv_max": 0.0003901809604481013, "train/adv_mean": 0.00014798179792953968, "train/adv_min": -0.00011268303249821518, "train/adv_std": 9.755136980774378e-05, "train/cont_avg": 0.9966165561868687, "train/cont_loss_mean": 0.02265839711198527, "train/cont_loss_std": 0.3151927619791505, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.656097708588437, "train/cont_pos_acc": 0.9999999831421207, "train/cont_pos_loss": 0.003537381011428255, "train/cont_pred": 0.9964689832143109, "train/cont_rate": 0.9966165561868687, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.019375830421323015, "train/extr_critic_critic_opt_grad_steps": 8845.0, "train/extr_critic_critic_opt_loss": 8236.566716974432, "train/extr_critic_mag": 0.14337001665674073, "train/extr_critic_max": 0.14337001665674073, "train/extr_critic_mean": 0.14327557384967804, "train/extr_critic_min": 0.1431905199783017, "train/extr_critic_std": 2.536713452857407e-05, "train/extr_return_normed_mag": 0.000639626474091501, "train/extr_return_normed_max": 0.0006030396078572129, "train/extr_return_normed_mean": 0.0004384251143449666, "train/extr_return_normed_min": 0.00024281788353968148, "train/extr_return_normed_std": 9.022123393523626e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.14358816032457833, "train/extr_return_raw_max": 0.14358816032457833, "train/extr_return_raw_mean": 0.14342355269073237, "train/extr_return_raw_min": 0.1432279386002608, "train/extr_return_raw_std": 9.022123495037933e-05, "train/extr_reward_mag": 0.00045397968003244114, "train/extr_reward_max": 0.00045397968003244114, "train/extr_reward_mean": 0.0004536227828463201, "train/extr_reward_min": 0.0004531849514354359, "train/extr_reward_std": 1.76431183368912e-07, "train/image_loss_mean": 0.24977956825133527, "train/image_loss_std": 0.08351956176185849, "train/model_loss_mean": 0.8916322200587301, "train/model_loss_std": 0.3627004271580113, "train/model_opt_grad_norm": 49.08872903958716, "train/model_opt_grad_steps": 8834.671717171717, "train/model_opt_loss": 2329.569176259667, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2613.6363636363635, "train/policy_entropy_mag": 1.9458911539328219, "train/policy_entropy_max": 1.9458911539328219, "train/policy_entropy_mean": 1.9449658929699598, "train/policy_entropy_min": 1.933072592272903, "train/policy_entropy_std": 0.000630130741752289, "train/policy_logprob_mag": 2.1686339908175998, "train/policy_logprob_max": -1.7290730952012419, "train/policy_logprob_mean": -1.9449786501701432, "train/policy_logprob_min": -2.1686339908175998, "train/policy_logprob_std": 0.04342332905666395, "train/policy_randomness_mag": 0.9999902976883782, "train/policy_randomness_max": 0.9999902976883782, "train/policy_randomness_mean": 0.9995148091605215, "train/policy_randomness_min": 0.9934028591772522, "train/policy_randomness_std": 0.0003238231613361888, "train/post_ent_mag": 61.645619902947935, "train/post_ent_max": 61.645619902947935, "train/post_ent_mean": 61.624298423227636, "train/post_ent_min": 61.58504981223983, "train/post_ent_std": 0.010338921897169766, "train/prior_ent_mag": 57.7907438374529, "train/prior_ent_max": 57.7907438374529, "train/prior_ent_mean": 57.752757583001646, "train/prior_ent_min": 57.592937450216276, "train/prior_ent_std": 0.028831050552503026, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0004780601326145721, "train/reward_loss_mean": 0.01919423443067706, "train/reward_loss_std": 0.06806047232539365, "train/reward_max_data": 0.07716014263022578, "train/reward_max_pred": 0.0004539766696968464, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.017794392875988375, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.422383734158107, "train/reward_pred": 0.0004534324762797115, "train/reward_rate": 0.00014796401515151516, "train_stats/mean_log_entropy": 1.9364729630095618, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.03606497123837471, "report/cont_loss_std": 0.4069511294364929, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.336854457855225, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004822592716664076, "report/cont_pred": 0.9951887726783752, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.23039239645004272, "report/image_loss_std": 0.08856478333473206, "report/model_loss_mean": 0.8841375112533569, "report/model_loss_std": 0.418338418006897, "report/post_ent_mag": 63.703556060791016, "report/post_ent_max": 63.703556060791016, "report/post_ent_mean": 63.656517028808594, "report/post_ent_min": 63.61286163330078, "report/post_ent_std": 0.017555592581629753, "report/prior_ent_mag": 59.65211486816406, "report/prior_ent_max": 59.65211486816406, "report/prior_ent_mean": 59.597286224365234, "report/prior_ent_min": 59.43395233154297, "report/prior_ent_std": 0.03161740303039551, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00039558118442073464, "report/reward_loss_mean": 0.01768009550869465, "report/reward_loss_std": 0.02999049983918667, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.0004851818084716797, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.017680097371339798, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0004807625664398074, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0048225922510027885, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0048225922510027885, "eval/cont_pred": 0.9951887726783752, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21894510090351105, "eval/image_loss_std": 0.08867323398590088, "eval/model_loss_mean": 0.8265092372894287, "eval/model_loss_std": 0.08867330104112625, "eval/post_ent_mag": 63.70253372192383, "eval/post_ent_max": 63.70253372192383, "eval/post_ent_mean": 63.65859603881836, "eval/post_ent_min": 63.61097717285156, "eval/post_ent_std": 0.017652178183197975, "eval/prior_ent_mag": 59.64399719238281, "eval/prior_ent_max": 59.64399719238281, "eval/prior_ent_mean": 59.60057067871094, "eval/prior_ent_min": 59.43395233154297, "eval/prior_ent_std": 0.027980182319879532, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0027414653450250626, "eval/reward_loss_std": 2.535370640543988e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0004851818084716797, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0027414653450250626, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0004807586083188653, "eval/reward_rate": 0.0, "replay/size": 158433.0, "replay/inserts": 31664.0, "replay/samples": 31664.0, "replay/insert_wait_avg": 1.1875525214805814e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.558630957273355e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38048.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.019569416772123e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1612207889557, "timer/env.step_count": 3958.0, "timer/env.step_total": 34.08030581474304, "timer/env.step_frac": 0.03407481224662912, "timer/env.step_avg": 0.008610486562592987, "timer/env.step_min": 0.0071659088134765625, "timer/env.step_max": 0.04754519462585449, "timer/replay._sample_count": 31664.0, "timer/replay._sample_total": 16.246795177459717, "timer/replay._sample_frac": 0.016244176278544156, "timer/replay._sample_avg": 0.0005130998982269997, "timer/replay._sample_min": 0.0003666877746582031, "timer/replay._sample_max": 0.03263664245605469, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4825.0, "timer/agent.policy_total": 41.33158230781555, "timer/agent.policy_frac": 0.04132491987163032, "timer/agent.policy_avg": 0.008566131048251928, "timer/agent.policy_min": 0.007447481155395508, "timer/agent.policy_max": 0.07427668571472168, "timer/dataset_train_count": 1979.0, "timer/dataset_train_total": 0.20749473571777344, "timer/dataset_train_frac": 0.0002074612886451403, "timer/dataset_train_avg": 0.00010484827474369552, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.00036716461181640625, "timer/agent.train_count": 1979.0, "timer/agent.train_total": 878.09357380867, "timer/agent.train_frac": 0.8779520296897783, "timer/agent.train_avg": 0.4437056967198939, "timer/agent.train_min": 0.43305087089538574, "timer/agent.train_max": 1.0843355655670166, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47432684898376465, "timer/agent.report_frac": 0.00047425038996173246, "timer/agent.report_avg": 0.23716342449188232, "timer/agent.report_min": 0.23685312271118164, "timer/agent.report_max": 0.237473726272583, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.4318695068359375e-05, "timer/dataset_eval_frac": 2.4314775021147184e-08, "timer/dataset_eval_avg": 2.4318695068359375e-05, "timer/dataset_eval_min": 2.4318695068359375e-05, "timer/dataset_eval_max": 2.4318695068359375e-05, "fps": 31.658341508028105}
{"step": 159104, "time": 5238.55678653717, "episode/length": 288.0, "episode/score": 0.11099118335653202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11099118335653202}
{"step": 159360, "time": 5246.441225528717, "episode/length": 288.0, "episode/score": 0.09808692005822195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09808692005822195}
{"step": 159680, "time": 5256.430568695068, "episode/length": 288.0, "episode/score": 0.12444018331086681, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12444018331086681}
{"step": 159760, "time": 5258.899475812912, "episode/length": 288.0, "episode/score": 0.1517549602932604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1517549602932604}
{"step": 160056, "time": 5268.174572467804, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 160056, "time": 5272.346181869507, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5272.354467868805, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5272.360292673111, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5272.366069555283, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5272.3717885017395, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5272.377993822098, "eval_episode/length": 288.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.0034602076124567475}
{"step": 160056, "time": 5272.383665084839, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160392, "time": 5282.742384433746, "episode/length": 288.0, "episode/score": 0.09571448698523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09571448698523}
{"step": 160480, "time": 5285.7682383060455, "episode/length": 270.0, "episode/score": 0.2900822068937714, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.13383220922207784}
{"step": 160832, "time": 5296.604314565659, "episode/length": 288.0, "episode/score": 0.07754020923994176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07754020923994176}
{"step": 160928, "time": 5299.586970567703, "episode/length": 288.0, "episode/score": 0.08106315149166221, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08106315149166221}
{"step": 161416, "time": 5314.39591217041, "episode/length": 288.0, "episode/score": 0.12568434546460594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12568434546460594}
{"step": 161672, "time": 5322.367681980133, "episode/length": 288.0, "episode/score": 0.07951592971448918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07951592971448918}
{"step": 161992, "time": 5332.371750116348, "episode/length": 288.0, "episode/score": 0.06934102205713089, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06934102205713089}
{"step": 162072, "time": 5334.8998436927795, "episode/length": 288.0, "episode/score": 0.10443740338592988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10443740338592988}
{"step": 162704, "time": 5354.779858112335, "episode/length": 288.0, "episode/score": 0.08525039152283398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08525039152283398}
{"step": 162792, "time": 5357.263822317123, "episode/length": 288.0, "episode/score": 0.09593143876054455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09593143876054455}
{"step": 163144, "time": 5368.14217710495, "episode/length": 288.0, "episode/score": 0.05619204574213654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05619204574213654}
{"step": 163240, "time": 5371.126412630081, "episode/length": 288.0, "episode/score": 0.05533808718968203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05533808718968203}
{"step": 163728, "time": 5386.726145982742, "episode/length": 288.0, "episode/score": 0.07091277225481463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07091277225481463}
{"step": 163984, "time": 5395.241971492767, "episode/length": 288.0, "episode/score": 0.08787332326392061, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08787332326392061}
{"step": 164304, "time": 5405.264688253403, "episode/length": 288.0, "episode/score": 0.09205570452434131, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09205570452434131}
{"step": 164384, "time": 5407.72661948204, "episode/length": 288.0, "episode/score": 0.11706234391010639, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11706234391010639}
{"step": 165016, "time": 5427.054610013962, "episode/length": 288.0, "episode/score": 0.07865368780284143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07865368780284143}
{"step": 165104, "time": 5430.04065489769, "episode/length": 288.0, "episode/score": 0.1132927819944598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1132927819944598}
{"step": 165456, "time": 5441.236351728439, "episode/length": 288.0, "episode/score": 0.10838964508911886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10838964508911886}
{"step": 165552, "time": 5444.259276390076, "episode/length": 288.0, "episode/score": 0.1114154208832474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1114154208832474}
{"step": 166040, "time": 5459.1024668216705, "episode/length": 288.0, "episode/score": 0.12118728819962143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12118728819962143}
{"step": 166296, "time": 5467.109532117844, "episode/length": 288.0, "episode/score": 0.09907419361945813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09907419361945813}
{"step": 166616, "time": 5476.959821939468, "episode/length": 288.0, "episode/score": 0.11961709135152887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11961709135152887}
{"step": 166696, "time": 5479.442865610123, "episode/length": 288.0, "episode/score": 0.07582079659346164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07582079659346164}
{"step": 167328, "time": 5499.187611579895, "episode/length": 288.0, "episode/score": 0.08982185959348499, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08982185959348499}
{"step": 167416, "time": 5501.674463272095, "episode/length": 288.0, "episode/score": 0.07791739034701095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07791739034701095}
{"step": 167768, "time": 5512.530292272568, "episode/length": 288.0, "episode/score": 0.12029731754091699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12029731754091699}
{"step": 167864, "time": 5515.510777950287, "episode/length": 288.0, "episode/score": 0.06438999835665982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06438999835665982}
{"step": 168352, "time": 5530.910899400711, "episode/length": 288.0, "episode/score": 0.12134109895850997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12134109895850997}
{"step": 168608, "time": 5538.840951681137, "episode/length": 288.0, "episode/score": 0.025469138033940908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025469138033940908}
{"step": 168808, "time": 5544.775733709335, "episode/length": 56.0, "episode/score": 0.8520343092429812, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.027034323492216572}
{"step": 168928, "time": 5548.711217164993, "episode/length": 288.0, "episode/score": 0.060019733272383746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060019733272383746}
{"step": 169008, "time": 5551.170076370239, "episode/length": 288.0, "episode/score": 0.11692260553513734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11692260553513734}
{"step": 169640, "time": 5570.610524654388, "episode/length": 288.0, "episode/score": 0.08886102221288184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08886102221288184}
{"step": 169728, "time": 5573.594713449478, "episode/length": 288.0, "episode/score": 0.061080158882191427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061080158882191427}
{"step": 170040, "time": 5588.1785390377045, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5588.184677600861, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5588.192352771759, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5588.197850704193, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5588.20295548439, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5588.208032369614, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5588.213233709335, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5588.2184891700745, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170080, "time": 5589.668337106705, "episode/length": 288.0, "episode/score": 0.083095482839326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.083095482839326}
{"step": 170176, "time": 5592.609561920166, "episode/length": 288.0, "episode/score": 0.11621222766734718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11621222766734718}
{"step": 170920, "time": 5615.506288528442, "episode/length": 288.0, "episode/score": 0.11982111035206344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11982111035206344}
{"step": 171120, "time": 5621.905544996262, "episode/length": 288.0, "episode/score": 0.07625274598103715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07625274598103715}
{"step": 171240, "time": 5625.391397476196, "episode/length": 288.0, "episode/score": 0.09435311161962545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09435311161962545}
{"step": 171320, "time": 5627.892393350601, "episode/length": 288.0, "episode/score": 0.11128510328978791, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11128510328978791}
{"step": 171952, "time": 5647.6694004535675, "episode/length": 288.0, "episode/score": 0.06330132847551795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06330132847551795}
{"step": 172040, "time": 5650.423987865448, "episode/length": 288.0, "episode/score": 0.08695765200070582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08695765200070582}
{"step": 172392, "time": 5661.598279237747, "episode/length": 288.0, "episode/score": 0.0769314377110959, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0769314377110959}
{"step": 172488, "time": 5664.629044294357, "episode/length": 288.0, "episode/score": 0.07971710012532185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07971710012532185}
{"step": 173232, "time": 5687.959014892578, "episode/length": 288.0, "episode/score": 0.1145696621172192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1145696621172192}
{"step": 173432, "time": 5693.920319318771, "episode/length": 288.0, "episode/score": 0.07558072992651432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07558072992651432}
{"step": 173552, "time": 5697.91206407547, "episode/length": 288.0, "episode/score": 0.06731382047405532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06731382047405532}
{"step": 173632, "time": 5700.392158031464, "episode/length": 288.0, "episode/score": 0.0626423539189318, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0626423539189318}
{"step": 174264, "time": 5719.788242101669, "episode/length": 288.0, "episode/score": 0.08781834237140629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08781834237140629}
{"step": 174352, "time": 5722.745317459106, "episode/length": 288.0, "episode/score": 0.11111616195523766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11111616195523766}
{"step": 174704, "time": 5733.621621847153, "episode/length": 288.0, "episode/score": 0.10840978492399245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10840978492399245}
{"step": 174800, "time": 5736.696015357971, "episode/length": 288.0, "episode/score": 0.14215985480495874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14215985480495874}
{"step": 175544, "time": 5759.427400827408, "episode/length": 288.0, "episode/score": 0.1641498632617413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1641498632617413}
{"step": 175744, "time": 5765.89705324173, "episode/length": 288.0, "episode/score": 0.14086012929203662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14086012929203662}
{"step": 175864, "time": 5769.396760940552, "episode/length": 288.0, "episode/score": 0.12281090876820144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12281090876820144}
{"step": 175944, "time": 5771.86977481842, "episode/length": 288.0, "episode/score": 0.10783784702107369, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10783784702107369}
{"step": 176576, "time": 5791.811961889267, "episode/length": 288.0, "episode/score": 0.1065911042087464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1065911042087464}
{"step": 176664, "time": 5794.326359272003, "episode/length": 288.0, "episode/score": 0.1391117576039278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1391117576039278}
{"step": 177016, "time": 5805.307342767715, "episode/length": 288.0, "episode/score": 0.12226508813171222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12226508813171222}
{"step": 177112, "time": 5808.300537109375, "episode/length": 288.0, "episode/score": 0.10441811079351737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10441811079351737}
{"step": 177856, "time": 5831.643068552017, "episode/length": 288.0, "episode/score": 0.14163520514364336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14163520514364336}
{"step": 178056, "time": 5837.594735383987, "episode/length": 288.0, "episode/score": 0.12201568143598251, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12201568143598251}
{"step": 178176, "time": 5841.525977134705, "episode/length": 288.0, "episode/score": 0.1334539016789904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1334539016789904}
{"step": 178256, "time": 5844.005635261536, "episode/length": 288.0, "episode/score": 0.11504673022557199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11504673022557199}
{"step": 178888, "time": 5863.349464416504, "episode/length": 288.0, "episode/score": 0.09461092069966526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09461092069966526}
{"step": 178976, "time": 5866.273593187332, "episode/length": 288.0, "episode/score": 0.1393839961281742, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1393839961281742}
{"step": 179328, "time": 5877.179250717163, "episode/length": 288.0, "episode/score": 0.11883662498911463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11883662498911463}
{"step": 179424, "time": 5880.137683391571, "episode/length": 288.0, "episode/score": 0.12227413055353509, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12227413055353509}
{"step": 180024, "time": 5903.059264183044, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5903.065870285034, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5903.071570396423, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5903.077350854874, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5903.082852602005, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5903.088457584381, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5903.093896389008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5903.099997282028, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180168, "time": 5907.592931509018, "episode/length": 288.0, "episode/score": 0.09943928198890717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09943928198890717}
{"step": 180368, "time": 5914.438105344772, "episode/length": 288.0, "episode/score": 0.08867339305879796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08867339305879796}
{"step": 180488, "time": 5917.9798974990845, "episode/length": 288.0, "episode/score": 0.12085944805278359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12085944805278359}
{"step": 180568, "time": 5920.434015512466, "episode/length": 288.0, "episode/score": 0.09009067240970126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09009067240970126}
{"step": 181200, "time": 5940.113021373749, "episode/length": 288.0, "episode/score": 0.1591667563695296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1591667563695296}
{"step": 181288, "time": 5942.636043071747, "episode/length": 288.0, "episode/score": 0.18137110760216046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18137110760216046}
{"step": 181640, "time": 5953.580350399017, "episode/length": 288.0, "episode/score": 0.15387066987892695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15387066987892695}
{"step": 181736, "time": 5956.552763223648, "episode/length": 288.0, "episode/score": 0.09811921072463292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09811921072463292}
{"step": 182480, "time": 5979.818570137024, "episode/length": 288.0, "episode/score": 0.08262957308363639, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08262957308363639}
{"step": 182680, "time": 5985.766581058502, "episode/length": 288.0, "episode/score": 0.08052284760458406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08052284760458406}
{"step": 182800, "time": 5989.671534776688, "episode/length": 288.0, "episode/score": 0.10159848845324859, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10159848845324859}
{"step": 182880, "time": 5992.188147783279, "episode/length": 288.0, "episode/score": 0.15213221523805487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15213221523805487}
{"step": 183512, "time": 6011.6234431266785, "episode/length": 288.0, "episode/score": 0.10780271161428345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10780271161428345}
{"step": 183600, "time": 6014.553562879562, "episode/length": 288.0, "episode/score": 0.11391518922607702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11391518922607702}
{"step": 183952, "time": 6025.401473283768, "episode/length": 288.0, "episode/score": 0.13976409762597086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13976409762597086}
{"step": 184048, "time": 6028.349798202515, "episode/length": 288.0, "episode/score": 0.11937964329803208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11937964329803208}
{"step": 184792, "time": 6051.237319469452, "episode/length": 288.0, "episode/score": 0.07993003604445903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07993003604445903}
{"step": 184992, "time": 6057.603112697601, "episode/length": 288.0, "episode/score": 0.13705597120724633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13705597120724633}
{"step": 185112, "time": 6061.083571195602, "episode/length": 288.0, "episode/score": 0.17306645551593647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17306645551593647}
{"step": 185192, "time": 6063.539123296738, "episode/length": 288.0, "episode/score": 0.10018236942784142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10018236942784142}
{"step": 185824, "time": 6083.304755449295, "episode/length": 288.0, "episode/score": 0.08788521728456544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08788521728456544}
{"step": 185912, "time": 6085.806191682816, "episode/length": 288.0, "episode/score": 0.11614959456767338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11614959456767338}
{"step": 186264, "time": 6096.723037958145, "episode/length": 288.0, "episode/score": 0.1329883723969374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1329883723969374}
{"step": 186360, "time": 6099.707529783249, "episode/length": 288.0, "episode/score": 0.08762567119168807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08762567119168807}
{"step": 187104, "time": 6123.192551136017, "episode/length": 288.0, "episode/score": 0.24411472615065577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24411472615065577}
{"step": 187304, "time": 6129.2392683029175, "episode/length": 288.0, "episode/score": 0.18087019309677999, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18087019309677999}
{"step": 187424, "time": 6133.141035079956, "episode/length": 288.0, "episode/score": 0.21458007155501946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21458007155501946}
{"step": 187504, "time": 6135.621753692627, "episode/length": 288.0, "episode/score": 0.18596904423520755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18596904423520755}
{"step": 188136, "time": 6154.887896776199, "episode/length": 288.0, "episode/score": 0.21569722223739518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21569722223739518}
{"step": 188224, "time": 6157.850239992142, "episode/length": 288.0, "episode/score": 0.2092812339676584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2092812339676584}
{"step": 188576, "time": 6169.136011123657, "episode/length": 288.0, "episode/score": 0.1876901488085423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1876901488085423}
{"step": 188672, "time": 6172.097890377045, "episode/length": 288.0, "episode/score": 0.23012151840430306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23012151840430306}
{"step": 189416, "time": 6194.821904182434, "episode/length": 288.0, "episode/score": 0.2546922091610213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2546922091610213}
{"step": 189616, "time": 6201.207283258438, "episode/length": 288.0, "episode/score": 0.2854550441466017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2854550441466017}
{"step": 189736, "time": 6204.708598613739, "episode/length": 288.0, "episode/score": 0.1486160776282759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1486160776282759}
{"step": 189816, "time": 6207.172613143921, "episode/length": 288.0, "episode/score": 0.17000887401400178, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17000887401400178}
{"step": 190008, "time": 6217.733992576599, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6217.740753173828, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6217.746486902237, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6217.7520406246185, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6217.757366657257, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6217.762846231461, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6217.76811003685, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6217.77369260788, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190448, "time": 6231.53181385994, "episode/length": 288.0, "episode/score": 0.21309074758187307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21309074758187307}
{"step": 190489, "time": 6233.542012453079, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7117396320788387, "train/action_min": 0.0, "train/action_std": 1.8601313514757882, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0004314307911977613, "train/actor_opt_grad_steps": 10820.0, "train/actor_opt_loss": 1.5818082562217555, "train/adv_mag": 0.0018622481127075737, "train/adv_max": 0.0017942398937825625, "train/adv_mean": 0.0006183654485571908, "train/adv_min": -0.00031794796740343124, "train/adv_std": 0.00037971596067123053, "train/cont_avg": 0.9963614371827412, "train/cont_loss_mean": 0.02408725402417219, "train/cont_loss_std": 0.32927517009216883, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.664379119873047, "train/cont_pos_acc": 0.9999999818463011, "train/cont_pos_loss": 0.003503960775930037, "train/cont_pred": 0.996502271158441, "train/cont_rate": 0.9963614371827412, "train/dyn_loss_mean": 1.000215766998717, "train/dyn_loss_std": 4.07338369316256e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0613724819906316, "train/extr_critic_critic_opt_grad_steps": 10820.0, "train/extr_critic_critic_opt_loss": 6593.7190728357, "train/extr_critic_mag": 0.1510012355552712, "train/extr_critic_max": 0.1510012355552712, "train/extr_critic_mean": 0.15087094623122724, "train/extr_critic_min": 0.15061443650783016, "train/extr_critic_std": 4.8344444329753976e-05, "train/extr_return_normed_mag": 0.0028772885121669868, "train/extr_return_normed_max": 0.002793487180308037, "train/extr_return_normed_mean": 0.001739159295042841, "train/extr_return_normed_min": 0.0008239649274022446, "train/extr_return_normed_std": 0.000371308917796535, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.15254362040969927, "train/extr_return_raw_max": 0.15254362040969927, "train/extr_return_raw_mean": 0.1514892995660075, "train/extr_return_raw_min": 0.15057409815679346, "train/extr_return_raw_std": 0.0003713089180342963, "train/extr_reward_mag": 0.0006978517861535706, "train/extr_reward_max": 0.0006978517861535706, "train/extr_reward_mean": 0.000547968596633675, "train/extr_reward_min": 0.0004101065814797648, "train/extr_reward_std": 4.611523244862999e-05, "train/image_loss_mean": 0.23939614187037278, "train/image_loss_std": 0.08628285956110446, "train/model_loss_mean": 0.8827557040350086, "train/model_loss_std": 0.382833673907113, "train/model_opt_grad_norm": 45.83305605777024, "train/model_opt_grad_steps": 10807.959390862945, "train/model_opt_loss": 2319.5980082090737, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2626.903553299492, "train/policy_entropy_mag": 1.8533860892813823, "train/policy_entropy_max": 1.8533860892813823, "train/policy_entropy_mean": 1.8194794213106185, "train/policy_entropy_min": 1.7358788253389639, "train/policy_entropy_std": 0.015439874982475515, "train/policy_logprob_mag": 2.7820433190631384, "train/policy_logprob_max": -1.3865626374552698, "train/policy_logprob_mean": -1.8197164686803284, "train/policy_logprob_min": -2.7820433190631384, "train/policy_logprob_std": 0.18940174227892445, "train/policy_randomness_mag": 0.9524520948756164, "train/policy_randomness_max": 0.9524520948756164, "train/policy_randomness_mean": 0.9350275102303113, "train/policy_randomness_min": 0.892065302861221, "train/policy_randomness_std": 0.00793452663237801, "train/post_ent_mag": 64.9452093676262, "train/post_ent_max": 64.9452093676262, "train/post_ent_mean": 64.78046035766602, "train/post_ent_min": 64.67405853658764, "train/post_ent_std": 0.050232822018755875, "train/prior_ent_mag": 61.82121958466351, "train/prior_ent_max": 61.82121958466351, "train/prior_ent_mean": 61.046843978959295, "train/prior_ent_min": 60.78158019399885, "train/prior_ent_std": 0.15079976209831722, "train/rep_loss_mean": 1.000215766998717, "train/rep_loss_std": 4.07338369316256e-05, "train/reward_avg": 0.0004754042825224303, "train/reward_loss_mean": 0.019142829354493147, "train/reward_loss_std": 0.07522903982228434, "train/reward_max_data": 0.08203045606641525, "train/reward_max_pred": 0.0006553618435932295, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.017508030750878572, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.524065657665854, "train/reward_pred": 0.0004550385528816109, "train/reward_rate": 0.00019332963197969544, "train_stats/mean_log_entropy": 1.8406489491462708, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020084863528609276, "report/cont_loss_std": 0.3035934865474701, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.620816230773926, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0036282604560256004, "report/cont_pred": 0.9963781833648682, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.23925839364528656, "report/image_loss_std": 0.0838785395026207, "report/model_loss_mean": 0.8762770891189575, "report/model_loss_std": 0.31808167695999146, "report/post_ent_mag": 56.8194465637207, "report/post_ent_max": 56.8194465637207, "report/post_ent_mean": 56.795440673828125, "report/post_ent_min": 56.76934051513672, "report/post_ent_std": 0.008158835582435131, "report/prior_ent_mag": 58.47760009765625, "report/prior_ent_max": 58.47760009765625, "report/prior_ent_mean": 58.378456115722656, "report/prior_ent_min": 58.08625030517578, "report/prior_ent_std": 0.061886951327323914, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00042157081770710647, "report/reward_loss_mean": 0.016933836042881012, "report/reward_loss_std": 0.026222696527838707, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.001471877098083496, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.016933836042881012, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0005719320615753531, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0036282604560256004, "eval/cont_loss_std": 9.313225746154785e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0036282604560256004, "eval/cont_pred": 0.9963781833648682, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22822615504264832, "eval/image_loss_std": 0.09198113530874252, "eval/model_loss_mean": 0.8344764709472656, "eval/model_loss_std": 0.09242979437112808, "eval/post_ent_mag": 56.820438385009766, "eval/post_ent_max": 56.820438385009766, "eval/post_ent_mean": 56.792518615722656, "eval/post_ent_min": 56.77201461791992, "eval/post_ent_std": 0.008283634670078754, "eval/prior_ent_mag": 58.49026870727539, "eval/prior_ent_max": 58.49026870727539, "eval/prior_ent_mean": 58.382293701171875, "eval/prior_ent_min": 58.08625030517578, "eval/prior_ent_std": 0.06108452007174492, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.002622069790959358, "eval/reward_loss_std": 0.002908805850893259, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0015321969985961914, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002622069790959358, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0004736481932923198, "eval/reward_rate": 0.0, "replay/size": 189985.0, "replay/inserts": 31552.0, "replay/samples": 31552.0, "replay/insert_wait_avg": 1.1697335973472672e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.342675636554586e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 47296.0, "eval_replay/inserts": 9248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0000535361082084e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1020512580872, "timer/env.step_count": 3944.0, "timer/env.step_total": 33.68429255485535, "timer/env.step_frac": 0.03368085538119024, "timer/env.step_avg": 0.008540642128513019, "timer/env.step_min": 0.007249593734741211, "timer/env.step_max": 0.04659271240234375, "timer/replay._sample_count": 31552.0, "timer/replay._sample_total": 15.83632206916809, "timer/replay._sample_frac": 0.01583470611748736, "timer/replay._sample_avg": 0.0005019118302854998, "timer/replay._sample_min": 0.00040602684020996094, "timer/replay._sample_max": 0.03180742263793945, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5100.0, "timer/agent.policy_total": 43.46291184425354, "timer/agent.policy_frac": 0.04345847685201624, "timer/agent.policy_avg": 0.008522139577304615, "timer/agent.policy_min": 0.0073909759521484375, "timer/agent.policy_max": 0.07828712463378906, "timer/dataset_train_count": 1972.0, "timer/dataset_train_total": 0.20544791221618652, "timer/dataset_train_frac": 0.00020542694813768407, "timer/dataset_train_avg": 0.00010418251126581466, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.00022935867309570312, "timer/agent.train_count": 1972.0, "timer/agent.train_total": 874.4972107410431, "timer/agent.train_frac": 0.8744079763069795, "timer/agent.train_avg": 0.44345700341837885, "timer/agent.train_min": 0.4319939613342285, "timer/agent.train_max": 0.5876932144165039, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47974491119384766, "timer/agent.report_frac": 0.00047969595761787343, "timer/agent.report_avg": 0.23987245559692383, "timer/agent.report_min": 0.23550152778625488, "timer/agent.report_max": 0.24424338340759277, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.0276069834881854e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 31.54822795837149}
{"step": 190536, "time": 6234.787118911743, "episode/length": 288.0, "episode/score": 0.1839967680521113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1839967680521113}
{"step": 190888, "time": 6245.72479057312, "episode/length": 288.0, "episode/score": 0.22849401924395352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22849401924395352}
{"step": 190984, "time": 6248.676467895508, "episode/length": 288.0, "episode/score": 0.17774053584957983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17774053584957983}
{"step": 191728, "time": 6271.8595361709595, "episode/length": 288.0, "episode/score": 0.22804852794797625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22804852794797625}
{"step": 191928, "time": 6277.8796598911285, "episode/length": 288.0, "episode/score": 0.23773250268641277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23773250268641277}
{"step": 192048, "time": 6281.814337491989, "episode/length": 288.0, "episode/score": 0.23763243151347524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23763243151347524}
{"step": 192128, "time": 6284.2874755859375, "episode/length": 288.0, "episode/score": 0.2526697305422658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2526697305422658}
{"step": 192760, "time": 6303.5218868255615, "episode/length": 288.0, "episode/score": 0.27936159424848483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27936159424848483}
{"step": 192848, "time": 6306.521679401398, "episode/length": 288.0, "episode/score": 0.2302845545073069, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2302845545073069}
{"step": 193200, "time": 6317.322128534317, "episode/length": 288.0, "episode/score": 0.3395096975186789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3395096975186789}
{"step": 193296, "time": 6320.302615404129, "episode/length": 288.0, "episode/score": 0.28769759795113714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28769759795113714}
{"step": 194040, "time": 6343.080687046051, "episode/length": 288.0, "episode/score": 0.2919504937772217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2919504937772217}
{"step": 194240, "time": 6349.454505681992, "episode/length": 288.0, "episode/score": 0.2909019067246845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2909019067246845}
{"step": 194360, "time": 6352.918027877808, "episode/length": 288.0, "episode/score": 0.27416060818268306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27416060818268306}
{"step": 194440, "time": 6355.383241653442, "episode/length": 288.0, "episode/score": 0.350686323951777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.350686323951777}
{"step": 195072, "time": 6375.267067432404, "episode/length": 288.0, "episode/score": 0.22453658381891728, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22453658381891728}
{"step": 195160, "time": 6377.77376127243, "episode/length": 288.0, "episode/score": 0.34037720952801465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34037720952801465}
{"step": 195512, "time": 6388.603439331055, "episode/length": 288.0, "episode/score": 0.3207173279261042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3207173279261042}
{"step": 195608, "time": 6391.536249876022, "episode/length": 288.0, "episode/score": 0.29926978357525513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29926978357525513}
{"step": 196352, "time": 6414.707728385925, "episode/length": 288.0, "episode/score": 0.26704238974161854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26704238974161854}
{"step": 196552, "time": 6420.6481075286865, "episode/length": 288.0, "episode/score": 0.2510517169102968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2510517169102968}
{"step": 196672, "time": 6425.184717178345, "episode/length": 288.0, "episode/score": 0.3073706987042897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3073706987042897}
{"step": 196752, "time": 6427.6624751091, "episode/length": 288.0, "episode/score": 0.2122762711960604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2122762711960604}
{"step": 197384, "time": 6446.863109827042, "episode/length": 288.0, "episode/score": 0.2718351661787892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2718351661787892}
{"step": 197472, "time": 6449.80215883255, "episode/length": 288.0, "episode/score": 0.2774717145221075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2774717145221075}
{"step": 197824, "time": 6460.716869831085, "episode/length": 288.0, "episode/score": 0.27454709016728884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27454709016728884}
{"step": 197920, "time": 6463.677132129669, "episode/length": 288.0, "episode/score": 0.2671127119074299, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2671127119074299}
{"step": 198664, "time": 6487.188485145569, "episode/length": 288.0, "episode/score": 0.2570510298087356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2570510298087356}
{"step": 198864, "time": 6493.583778142929, "episode/length": 288.0, "episode/score": 0.2016668920578013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2016668920578013}
{"step": 198984, "time": 6497.043314933777, "episode/length": 288.0, "episode/score": 0.19829930875357604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19829930875357604}
{"step": 199064, "time": 6499.514432191849, "episode/length": 288.0, "episode/score": 0.21066106618945923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21066106618945923}
{"step": 199696, "time": 6519.244399547577, "episode/length": 288.0, "episode/score": 0.21208906014680906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21208906014680906}
{"step": 199784, "time": 6521.7343554496765, "episode/length": 288.0, "episode/score": 0.20529472430553142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20529472430553142}
{"step": 200096, "time": 6533.940898656845, "eval_episode/length": 155.0, "eval_episode/score": 0.515625, "eval_episode/reward_rate": 0.00641025641025641}
{"step": 200096, "time": 6536.553327798843, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6536.559548377991, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6536.564888238907, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6536.5702912807465, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6536.575439691544, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6536.580593585968, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6536.5858335494995, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200136, "time": 6537.619489908218, "episode/length": 288.0, "episode/score": 0.18462898638563274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18462898638563274}
{"step": 200232, "time": 6540.5621342659, "episode/length": 288.0, "episode/score": 0.23768439416880938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23768439416880938}
{"step": 200976, "time": 6563.663169384003, "episode/length": 288.0, "episode/score": 0.1834541620928576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1834541620928576}
{"step": 201176, "time": 6569.576821088791, "episode/length": 288.0, "episode/score": 0.21404300646054253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21404300646054253}
{"step": 201296, "time": 6573.485279798508, "episode/length": 288.0, "episode/score": 0.20280497788280627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20280497788280627}
{"step": 201376, "time": 6575.989900588989, "episode/length": 288.0, "episode/score": 0.23870654249185463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23870654249185463}
{"step": 202008, "time": 6595.239302873611, "episode/length": 288.0, "episode/score": 0.20816008741439873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20816008741439873}
{"step": 202096, "time": 6598.186456680298, "episode/length": 288.0, "episode/score": 0.25028983783772674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25028983783772674}
{"step": 202448, "time": 6609.272757530212, "episode/length": 288.0, "episode/score": 0.23073815315501633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23073815315501633}
{"step": 202544, "time": 6612.293593883514, "episode/length": 288.0, "episode/score": 0.15648249394780578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15648249394780578}
{"step": 203288, "time": 6635.25332736969, "episode/length": 288.0, "episode/score": 0.17201245221167483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17201245221167483}
{"step": 203488, "time": 6641.743819475174, "episode/length": 288.0, "episode/score": 0.18667360651238596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18667360651238596}
{"step": 203608, "time": 6645.272851705551, "episode/length": 288.0, "episode/score": 0.2279425566619011, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2279425566619011}
{"step": 203688, "time": 6647.772976636887, "episode/length": 288.0, "episode/score": 0.21314867503429014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21314867503429014}
{"step": 204320, "time": 6667.54669880867, "episode/length": 288.0, "episode/score": 0.22252671392789125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22252671392789125}
{"step": 204408, "time": 6670.03525686264, "episode/length": 288.0, "episode/score": 0.20339374734726334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20339374734726334}
{"step": 204760, "time": 6680.917380809784, "episode/length": 288.0, "episode/score": 0.1659311459861783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1659311459861783}
{"step": 204856, "time": 6684.371491193771, "episode/length": 288.0, "episode/score": 0.22426114018890075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22426114018890075}
{"step": 205600, "time": 6707.587095737457, "episode/length": 288.0, "episode/score": 0.22710898473405905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22710898473405905}
{"step": 205800, "time": 6713.531074047089, "episode/length": 288.0, "episode/score": 0.25788621107199106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25788621107199106}
{"step": 205920, "time": 6717.453234195709, "episode/length": 288.0, "episode/score": 0.16210845827913545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16210845827913545}
{"step": 206000, "time": 6719.921777009964, "episode/length": 288.0, "episode/score": 0.1553226634046041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1553226634046041}
{"step": 206632, "time": 6739.2621438503265, "episode/length": 288.0, "episode/score": 0.07935909779268968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07935909779268968}
{"step": 206720, "time": 6742.224119901657, "episode/length": 288.0, "episode/score": 0.23376983759794712, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23376983759794712}
{"step": 207072, "time": 6753.061458826065, "episode/length": 288.0, "episode/score": 0.23928249060372764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23928249060372764}
{"step": 207168, "time": 6756.159583568573, "episode/length": 288.0, "episode/score": 0.22053935601354624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22053935601354624}
{"step": 207912, "time": 6778.826010227203, "episode/length": 288.0, "episode/score": 0.23454819083417533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23454819083417533}
{"step": 208112, "time": 6785.294618606567, "episode/length": 288.0, "episode/score": 0.21443202397620098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21443202397620098}
{"step": 208232, "time": 6788.757079601288, "episode/length": 288.0, "episode/score": 0.14813720474467118, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14813720474467118}
{"step": 208312, "time": 6791.242497205734, "episode/length": 288.0, "episode/score": 0.2565340707224095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2565340707224095}
{"step": 208944, "time": 6810.936419963837, "episode/length": 288.0, "episode/score": 0.18769241391737523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18769241391737523}
{"step": 209032, "time": 6813.419717311859, "episode/length": 288.0, "episode/score": 0.19836162472336127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19836162472336127}
{"step": 209384, "time": 6824.374783039093, "episode/length": 288.0, "episode/score": 0.12073842326719841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12073842326719841}
{"step": 209480, "time": 6827.3520402908325, "episode/length": 288.0, "episode/score": 0.16408631599699675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16408631599699675}
{"step": 210080, "time": 6850.841743946075, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6850.848716497421, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6850.8545179367065, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6850.860021829605, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6850.865705013275, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6850.871533155441, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6850.877072572708, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6850.883023738861, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210224, "time": 6855.331344604492, "episode/length": 288.0, "episode/score": 0.24262196861059238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24262196861059238}
{"step": 210424, "time": 6861.266322374344, "episode/length": 288.0, "episode/score": 0.30699832769096247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30699832769096247}
{"step": 210544, "time": 6865.177802324295, "episode/length": 288.0, "episode/score": 0.20816400201431406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20816400201431406}
{"step": 210624, "time": 6867.635919332504, "episode/length": 288.0, "episode/score": 0.22060270750955624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22060270750955624}
{"step": 211256, "time": 6886.990715503693, "episode/length": 288.0, "episode/score": 0.25260572254148883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25260572254148883}
{"step": 211344, "time": 6889.933310031891, "episode/length": 288.0, "episode/score": 0.2435388038812789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2435388038812789}
{"step": 211696, "time": 6900.773137807846, "episode/length": 288.0, "episode/score": 0.17770378339446324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17770378339446324}
{"step": 211792, "time": 6903.734142780304, "episode/length": 288.0, "episode/score": 0.21783328813694425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21783328813694425}
{"step": 212536, "time": 6926.436383485794, "episode/length": 288.0, "episode/score": 0.18164829940599247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18164829940599247}
{"step": 212736, "time": 6932.809587955475, "episode/length": 288.0, "episode/score": 0.19763103759032674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19763103759032674}
{"step": 212856, "time": 6936.415712356567, "episode/length": 288.0, "episode/score": 0.22324147524477667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22324147524477667}
{"step": 212936, "time": 6938.8993973731995, "episode/length": 288.0, "episode/score": 0.15947866551846346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15947866551846346}
{"step": 213568, "time": 6959.022382259369, "episode/length": 288.0, "episode/score": 0.18367471773285615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18367471773285615}
{"step": 213656, "time": 6961.505301475525, "episode/length": 288.0, "episode/score": 0.1628386631327885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1628386631327885}
{"step": 214008, "time": 6972.396986961365, "episode/length": 288.0, "episode/score": 0.21560663241291422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21560663241291422}
{"step": 214104, "time": 6975.370119571686, "episode/length": 288.0, "episode/score": 0.19550337560167463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19550337560167463}
{"step": 214848, "time": 6998.536967515945, "episode/length": 288.0, "episode/score": 0.23902948857949013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23902948857949013}
{"step": 215048, "time": 7004.472050905228, "episode/length": 288.0, "episode/score": 0.17446852746024888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17446852746024888}
{"step": 215168, "time": 7008.386840343475, "episode/length": 288.0, "episode/score": 0.14809590594643396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14809590594643396}
{"step": 215248, "time": 7010.846185922623, "episode/length": 288.0, "episode/score": 0.2118988995765676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2118988995765676}
{"step": 215880, "time": 7030.160712480545, "episode/length": 288.0, "episode/score": 0.17144507300520218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17144507300520218}
{"step": 215968, "time": 7033.098571300507, "episode/length": 288.0, "episode/score": 0.15965760343249258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15965760343249258}
{"step": 216320, "time": 7044.090378284454, "episode/length": 288.0, "episode/score": 0.09542615925431619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09542615925431619}
{"step": 216416, "time": 7047.088081121445, "episode/length": 288.0, "episode/score": 0.20084183057758764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20084183057758764}
{"step": 217160, "time": 7070.067115783691, "episode/length": 288.0, "episode/score": 0.17509077192198674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17509077192198674}
{"step": 217360, "time": 7076.453685998917, "episode/length": 288.0, "episode/score": 0.1503004368415759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1503004368415759}
{"step": 217480, "time": 7079.9300417900085, "episode/length": 288.0, "episode/score": 0.22917847413305026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22917847413305026}
{"step": 217560, "time": 7082.408602952957, "episode/length": 288.0, "episode/score": 0.1511217293517575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1511217293517575}
{"step": 218192, "time": 7102.127686500549, "episode/length": 288.0, "episode/score": 0.2507541706131633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2507541706131633}
{"step": 218280, "time": 7104.605827093124, "episode/length": 288.0, "episode/score": 0.2530000570454831, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2530000570454831}
{"step": 218632, "time": 7115.48525929451, "episode/length": 288.0, "episode/score": 0.18741411571522804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18741411571522804}
{"step": 218728, "time": 7118.461668968201, "episode/length": 288.0, "episode/score": 0.2092684111091785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2092684111091785}
{"step": 219472, "time": 7141.523994684219, "episode/length": 288.0, "episode/score": 0.23070099905538655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23070099905538655}
{"step": 219672, "time": 7147.538273096085, "episode/length": 288.0, "episode/score": 0.29337287005910184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29337287005910184}
{"step": 219792, "time": 7151.454571723938, "episode/length": 288.0, "episode/score": 0.20971567645545974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20971567645545974}
{"step": 219872, "time": 7153.909444093704, "episode/length": 288.0, "episode/score": 0.20672980166170873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20672980166170873}
{"step": 220064, "time": 7164.213678121567, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7164.219815254211, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7164.225294351578, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7164.23059463501, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7164.235827922821, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7164.2409336566925, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7164.246164798737, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7164.251449346542, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220504, "time": 7177.660905838013, "episode/length": 288.0, "episode/score": 0.18871557040745301, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18871557040745301}
{"step": 220592, "time": 7180.595242261887, "episode/length": 288.0, "episode/score": 0.1779859120786682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1779859120786682}
{"step": 220944, "time": 7191.400660276413, "episode/length": 288.0, "episode/score": 0.24531760411008463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24531760411008463}
{"step": 221040, "time": 7194.351103544235, "episode/length": 288.0, "episode/score": 0.08789531150813445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08789531150813445}
{"step": 221784, "time": 7217.744029045105, "episode/length": 288.0, "episode/score": 0.2158172643130456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2158172643130456}
{"step": 221984, "time": 7224.1045026779175, "episode/length": 288.0, "episode/score": 0.20519874764420365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20519874764420365}
{"step": 222104, "time": 7227.581521034241, "episode/length": 288.0, "episode/score": 0.28203359906984815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28203359906984815}
{"step": 222184, "time": 7230.0384085178375, "episode/length": 288.0, "episode/score": 0.2070422886833967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2070422886833967}
{"step": 222281, "time": 7233.989404678345, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.5797039396199748, "train/action_min": 0.0, "train/action_std": 1.4085328033821067, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0008183819664192933, "train/actor_opt_grad_steps": 12800.0, "train/actor_opt_loss": 14.624864845195008, "train/adv_mag": 0.00549484527290766, "train/adv_max": 0.00547688720214307, "train/adv_mean": 0.0016744453749188279, "train/adv_min": -0.0018427242436001648, "train/adv_std": 0.0010785287095177638, "train/cont_avg": 0.9964961526381909, "train/cont_loss_mean": 0.023349616728049128, "train/cont_loss_std": 0.3209844170112468, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.642904025043933, "train/cont_pos_acc": 0.9999999850239586, "train/cont_pos_loss": 0.0035750691617497396, "train/cont_pred": 0.996431454941256, "train/cont_rate": 0.9964961526381909, "train/dyn_loss_mean": 1.0000008027158191, "train/dyn_loss_std": 2.567763159510179e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08444840017584475, "train/extr_critic_critic_opt_grad_steps": 12800.0, "train/extr_critic_critic_opt_loss": 8896.386153177998, "train/extr_critic_mag": 0.20795976396781116, "train/extr_critic_max": 0.20795976396781116, "train/extr_critic_mean": 0.20539210347374479, "train/extr_critic_min": 0.20282055325244538, "train/extr_critic_std": 0.0007798415723145032, "train/extr_return_normed_mag": 0.009064535025376172, "train/extr_return_normed_max": 0.009064535025376172, "train/extr_return_normed_mean": 0.004898322810507824, "train/extr_return_normed_min": 0.0010236333213259827, "train/extr_return_normed_std": 0.0013497851554412, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.21123278934751924, "train/extr_return_raw_max": 0.21123278934751924, "train/extr_return_raw_mean": 0.20706658978857587, "train/extr_return_raw_min": 0.20319188764346904, "train/extr_return_raw_std": 0.0013497851533936945, "train/extr_reward_mag": 0.001767119570593139, "train/extr_reward_max": 0.001767119570593139, "train/extr_reward_mean": 0.000944971159304113, "train/extr_reward_min": 9.618811870939169e-05, "train/extr_reward_std": 0.00040146713972854516, "train/image_loss_mean": 0.20683080047818284, "train/image_loss_std": 0.09483399792532225, "train/model_loss_mean": 0.848394988469742, "train/model_loss_std": 0.3630557517759764, "train/model_opt_grad_norm": 39.85614113352407, "train/model_opt_grad_steps": 12786.090452261307, "train/model_opt_loss": 2291.4479808711526, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2701.005025125628, "train/policy_entropy_mag": 1.688568209283915, "train/policy_entropy_max": 1.688568209283915, "train/policy_entropy_mean": 1.3408121613401864, "train/policy_entropy_min": 0.7595759038649612, "train/policy_entropy_std": 0.12586741133513463, "train/policy_logprob_mag": 4.535361267214444, "train/policy_logprob_max": -0.21553110604609677, "train/policy_logprob_mean": -1.3409711661650308, "train/policy_logprob_min": -4.535361267214444, "train/policy_logprob_std": 0.9129883479233363, "train/policy_randomness_mag": 0.8677524567848474, "train/policy_randomness_max": 0.8677524567848474, "train/policy_randomness_mean": 0.6890411883143325, "train/policy_randomness_min": 0.39034482072945215, "train/policy_randomness_std": 0.06468305754096214, "train/post_ent_mag": 62.42135591363188, "train/post_ent_max": 62.42135591363188, "train/post_ent_mean": 62.17665895624975, "train/post_ent_min": 61.998112606642835, "train/post_ent_std": 0.07388407919537182, "train/prior_ent_mag": 60.94528418689517, "train/prior_ent_max": 60.94528418689517, "train/prior_ent_mean": 58.085914458461744, "train/prior_ent_min": 56.78472716365028, "train/prior_ent_std": 0.6829517885817954, "train/rep_loss_mean": 1.0000008027158191, "train/rep_loss_std": 2.567763159510179e-05, "train/reward_avg": 0.0004872498952200983, "train/reward_loss_mean": 0.018214068937129412, "train/reward_loss_std": 0.05893712444932916, "train/reward_max_data": 0.05958961447157977, "train/reward_max_pred": 0.0016848651608031, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.01709761346067915, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.121376156806946, "train/reward_pred": 0.0004991085406617454, "train/reward_rate": 0.00012268373115577888, "train_stats/mean_log_entropy": 1.3501391335650608, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020042967051267624, "report/cont_loss_std": 0.3076048493385315, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.6947760581970215, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0033689173869788647, "report/cont_pred": 0.996636688709259, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.18219131231307983, "report/image_loss_std": 0.09343605488538742, "report/model_loss_mean": 0.8195679187774658, "report/model_loss_std": 0.32230231165885925, "report/post_ent_mag": 63.567012786865234, "report/post_ent_max": 63.567012786865234, "report/post_ent_mean": 63.20644760131836, "report/post_ent_min": 62.965484619140625, "report/post_ent_std": 0.10431889444589615, "report/prior_ent_mag": 62.15339660644531, "report/prior_ent_max": 62.15339660644531, "report/prior_ent_mean": 58.74948501586914, "report/prior_ent_min": 57.09749221801758, "report/prior_ent_std": 0.9701500535011292, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004365889762993902, "report/reward_loss_mean": 0.017333585768938065, "report/reward_loss_std": 0.028505565598607063, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.0016679763793945312, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.017333583906292915, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0004763267934322357, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014485024847090244, "eval/cont_loss_std": 0.2512812316417694, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.694775581359863, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0033689946867525578, "eval/cont_pred": 0.9966366291046143, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20616649091243744, "eval/image_loss_std": 0.10119260847568512, "eval/model_loss_mean": 0.8230822086334229, "eval/model_loss_std": 0.26734817028045654, "eval/post_ent_mag": 63.567726135253906, "eval/post_ent_max": 63.567726135253906, "eval/post_ent_mean": 63.19437789916992, "eval/post_ent_min": 62.97932815551758, "eval/post_ent_std": 0.09975841641426086, "eval/prior_ent_mag": 62.253013610839844, "eval/prior_ent_max": 62.253013610839844, "eval/prior_ent_mean": 58.692047119140625, "eval/prior_ent_min": 57.033233642578125, "eval/prior_ent_std": 0.9826145172119141, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0024306681007146835, "eval/reward_loss_std": 0.002468847669661045, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0015619993209838867, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0024306681007146835, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.000461909337900579, "eval/reward_rate": 0.0, "replay/size": 221777.0, "replay/inserts": 31792.0, "replay/samples": 31792.0, "replay/insert_wait_avg": 1.1729471156749524e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.321742172509986e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 54232.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.026581727922169e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4289450645447, "timer/env.step_count": 3974.0, "timer/env.step_total": 33.585166931152344, "timer/env.step_frac": 0.033570766916370585, "timer/env.step_avg": 0.0084512246932945, "timer/env.step_min": 0.007160663604736328, "timer/env.step_max": 0.03706979751586914, "timer/replay._sample_count": 31792.0, "timer/replay._sample_total": 15.62411880493164, "timer/replay._sample_frac": 0.015617419789791887, "timer/replay._sample_avg": 0.0004914481254696666, "timer/replay._sample_min": 0.0003581047058105469, "timer/replay._sample_max": 0.03177618980407715, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4841.0, "timer/agent.policy_total": 40.58654451370239, "timer/agent.policy_frac": 0.0405691425802198, "timer/agent.policy_avg": 0.008383917478558644, "timer/agent.policy_min": 0.00738072395324707, "timer/agent.policy_max": 0.07926607131958008, "timer/dataset_train_count": 1987.0, "timer/dataset_train_total": 0.20386958122253418, "timer/dataset_train_frac": 0.00020378216986652773, "timer/dataset_train_avg": 0.00010260170167213598, "timer/dataset_train_min": 8.797645568847656e-05, "timer/dataset_train_max": 0.0010864734649658203, "timer/agent.train_count": 1987.0, "timer/agent.train_total": 880.0279722213745, "timer/agent.train_frac": 0.8796506504163549, "timer/agent.train_avg": 0.44289278924075215, "timer/agent.train_min": 0.43415212631225586, "timer/agent.train_max": 1.170792818069458, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47165489196777344, "timer/agent.report_frac": 0.00047145266467409503, "timer/agent.report_avg": 0.23582744598388672, "timer/agent.report_min": 0.2243192195892334, "timer/agent.report_max": 0.24733567237854004, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.288765691789625e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 31.777810652464805}
{"step": 222816, "time": 7250.537934541702, "episode/length": 288.0, "episode/score": 0.25115620872651334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25115620872651334}
{"step": 222904, "time": 7253.032167196274, "episode/length": 288.0, "episode/score": 0.2243412584287512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2243412584287512}
{"step": 223256, "time": 7263.850758075714, "episode/length": 288.0, "episode/score": 0.2449880105271518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2449880105271518}
{"step": 223352, "time": 7266.93004822731, "episode/length": 288.0, "episode/score": 0.25728341522653864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25728341522653864}
{"step": 224096, "time": 7290.00049328804, "episode/length": 288.0, "episode/score": 0.21932196491798095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21932196491798095}
{"step": 224296, "time": 7296.035259246826, "episode/length": 288.0, "episode/score": 0.3602057609004987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3602057609004987}
{"step": 224416, "time": 7299.942721605301, "episode/length": 288.0, "episode/score": 0.24165779348277283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24165779348277283}
{"step": 224496, "time": 7302.425066947937, "episode/length": 288.0, "episode/score": 0.3054275507493003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3054275507493003}
{"step": 225128, "time": 7321.682307004929, "episode/length": 288.0, "episode/score": 0.2437286318322549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2437286318322549}
{"step": 225216, "time": 7324.636877775192, "episode/length": 288.0, "episode/score": 0.2171072009236923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2171072009236923}
{"step": 225568, "time": 7335.599759578705, "episode/length": 288.0, "episode/score": 0.2834500878407198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2834500878407198}
{"step": 225664, "time": 7338.5563905239105, "episode/length": 288.0, "episode/score": 0.3133455142078674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3133455142078674}
{"step": 226408, "time": 7361.369946718216, "episode/length": 288.0, "episode/score": 0.1840183300114404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1840183300114404}
{"step": 226608, "time": 7367.761743307114, "episode/length": 288.0, "episode/score": 0.22628688849636092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22628688849636092}
{"step": 226728, "time": 7371.247935533524, "episode/length": 288.0, "episode/score": 0.2059380187397437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2059380187397437}
{"step": 226808, "time": 7373.710324764252, "episode/length": 288.0, "episode/score": 0.2781757259558617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2781757259558617}
{"step": 227440, "time": 7393.57271361351, "episode/length": 288.0, "episode/score": 0.2279849973947421, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2279849973947421}
{"step": 227528, "time": 7396.076041221619, "episode/length": 288.0, "episode/score": 0.24331781627915916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24331781627915916}
{"step": 227880, "time": 7406.938268899918, "episode/length": 288.0, "episode/score": 0.18714151269978174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18714151269978174}
{"step": 227976, "time": 7409.895380973816, "episode/length": 288.0, "episode/score": 0.2202423154421922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2202423154421922}
{"step": 228720, "time": 7433.13679933548, "episode/length": 288.0, "episode/score": 0.22090951708014472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22090951708014472}
{"step": 228920, "time": 7439.086053609848, "episode/length": 288.0, "episode/score": 0.15311036840193992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15311036840193992}
{"step": 229040, "time": 7442.987711429596, "episode/length": 288.0, "episode/score": 0.1116771763122415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1116771763122415}
{"step": 229120, "time": 7445.566859960556, "episode/length": 288.0, "episode/score": 0.2230366038743341, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2230366038743341}
{"step": 229752, "time": 7465.58850312233, "episode/length": 288.0, "episode/score": 0.32473670941726596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32473670941726596}
{"step": 229840, "time": 7468.554652929306, "episode/length": 244.0, "episode/score": 0.4896098661374708, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.2521098714460095}
{"step": 229840, "time": 7468.562264204025, "episode/length": 288.0, "episode/score": 0.20673487447311345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20673487447311345}
{"step": 230048, "time": 7479.831481933594, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7479.837876081467, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7479.843297719955, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7479.848936319351, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7479.854478359222, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7479.859779119492, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7479.864993095398, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7479.87025141716, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230288, "time": 7487.3492159843445, "episode/length": 288.0, "episode/score": 0.1879442310828381, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1879442310828381}
{"step": 231032, "time": 7510.257467985153, "episode/length": 288.0, "episode/score": 0.2732851712066804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2732851712066804}
{"step": 231232, "time": 7516.655599594116, "episode/length": 288.0, "episode/score": 0.15854974156536628, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15854974156536628}
{"step": 231352, "time": 7520.156737089157, "episode/length": 288.0, "episode/score": 0.2139664603384972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2139664603384972}
{"step": 231432, "time": 7522.62220454216, "episode/length": 288.0, "episode/score": 0.2642946604107692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2642946604107692}
{"step": 232064, "time": 7542.3964149951935, "episode/length": 288.0, "episode/score": 0.15678820006860406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15678820006860406}
{"step": 232152, "time": 7544.965311527252, "episode/length": 288.0, "episode/score": 0.17043490899573044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17043490899573044}
{"step": 232152, "time": 7544.973452329636, "episode/length": 288.0, "episode/score": 0.21124768563868201, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21124768563868201}
{"step": 232600, "time": 7558.8616535663605, "episode/length": 288.0, "episode/score": 0.24378492999744594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24378492999744594}
{"step": 233344, "time": 7582.157601118088, "episode/length": 288.0, "episode/score": 0.17376132034723923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17376132034723923}
{"step": 233544, "time": 7588.079317808151, "episode/length": 288.0, "episode/score": 0.30257302583436285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30257302583436285}
{"step": 233664, "time": 7591.998598098755, "episode/length": 288.0, "episode/score": 0.2829917255608052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2829917255608052}
{"step": 233744, "time": 7594.473876237869, "episode/length": 288.0, "episode/score": 0.2646380639121162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2646380639121162}
{"step": 233896, "time": 7599.0069053173065, "episode/length": 217.0, "episode/score": 0.5413090023091627, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.21943399867700464}
{"step": 234064, "time": 7604.405675411224, "episode/length": 249.0, "episode/score": 0.5050631497015274, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.2831881550100661}
{"step": 234464, "time": 7616.74955034256, "episode/length": 288.0, "episode/score": 0.19274248335273114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19274248335273114}
{"step": 234776, "time": 7626.239572286606, "episode/length": 153.0, "episode/score": 0.6835898928256938, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.16171487061365042}
{"step": 234912, "time": 7630.661726951599, "episode/length": 288.0, "episode/score": 0.18923945134747555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18923945134747555}
{"step": 235656, "time": 7653.413439035416, "episode/length": 288.0, "episode/score": 0.27674738097903173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27674738097903173}
{"step": 235976, "time": 7663.397272109985, "episode/length": 288.0, "episode/score": 0.2409304480963783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2409304480963783}
{"step": 236056, "time": 7665.867470264435, "episode/length": 288.0, "episode/score": 0.16643691090666834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16643691090666834}
{"step": 236208, "time": 7670.782924413681, "episode/length": 288.0, "episode/score": 0.19215812755555817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19215812755555817}
{"step": 236376, "time": 7675.741899967194, "episode/length": 288.0, "episode/score": 0.19680419083397283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19680419083397283}
{"step": 236776, "time": 7688.185362100601, "episode/length": 288.0, "episode/score": 0.157520083881991, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.157520083881991}
{"step": 237088, "time": 7698.035070896149, "episode/length": 288.0, "episode/score": 0.1325827873124581, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1325827873124581}
{"step": 237224, "time": 7702.002812862396, "episode/length": 288.0, "episode/score": 0.1445569491736478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1445569491736478}
{"step": 237968, "time": 7725.725244522095, "episode/length": 288.0, "episode/score": 0.14128977872371706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14128977872371706}
{"step": 238288, "time": 7735.6278285980225, "episode/length": 288.0, "episode/score": 0.17079609254960815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17079609254960815}
{"step": 238368, "time": 7738.162792205811, "episode/length": 288.0, "episode/score": 0.14327868206567018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14327868206567018}
{"step": 238520, "time": 7742.63337802887, "episode/length": 288.0, "episode/score": 0.11445469143848186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11445469143848186}
{"step": 238688, "time": 7748.1479642391205, "episode/length": 288.0, "episode/score": 0.08502978160925068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08502978160925068}
{"step": 239088, "time": 7760.460653305054, "episode/length": 288.0, "episode/score": 0.11371613828350746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11371613828350746}
{"step": 239400, "time": 7769.862066984177, "episode/length": 288.0, "episode/score": 0.09167860406091677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09167860406091677}
{"step": 239536, "time": 7774.282732486725, "episode/length": 288.0, "episode/score": 0.1220433182030547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1220433182030547}
{"step": 240032, "time": 7794.798325061798, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7794.804631233215, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7794.810254812241, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7794.815751791, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7794.8212151527405, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7794.826541185379, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7794.831840276718, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7794.837171077728, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240280, "time": 7802.311661720276, "episode/length": 288.0, "episode/score": 0.17561501215868702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17561501215868702}
{"step": 240600, "time": 7812.272664070129, "episode/length": 288.0, "episode/score": 0.16177662184486508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16177662184486508}
{"step": 240680, "time": 7814.731112003326, "episode/length": 288.0, "episode/score": 0.2008335962602814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2008335962602814}
{"step": 240832, "time": 7819.629273414612, "episode/length": 288.0, "episode/score": 0.1732920548624861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1732920548624861}
{"step": 241000, "time": 7824.580442667007, "episode/length": 288.0, "episode/score": 0.17668400626473613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17668400626473613}
{"step": 241400, "time": 7836.974876880646, "episode/length": 288.0, "episode/score": 0.09543467716923715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09543467716923715}
{"step": 241712, "time": 7846.7998695373535, "episode/length": 288.0, "episode/score": 0.20302022663565822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20302022663565822}
{"step": 241848, "time": 7850.761737823486, "episode/length": 288.0, "episode/score": 0.26669415930746254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26669415930746254}
{"step": 242592, "time": 7874.0589594841, "episode/length": 288.0, "episode/score": 0.26221148177592113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26221148177592113}
{"step": 242912, "time": 7883.935110330582, "episode/length": 288.0, "episode/score": 0.24623645789097282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24623645789097282}
{"step": 242992, "time": 7886.454615831375, "episode/length": 288.0, "episode/score": 0.15908102452158346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15908102452158346}
{"step": 243144, "time": 7890.908286333084, "episode/length": 288.0, "episode/score": 0.1554027818938266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1554027818938266}
{"step": 243312, "time": 7896.433587312698, "episode/length": 288.0, "episode/score": 0.166289770325875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.166289770325875}
{"step": 243712, "time": 7908.776280641556, "episode/length": 288.0, "episode/score": 0.20291345870964506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20291345870964506}
{"step": 244024, "time": 7918.200566530228, "episode/length": 288.0, "episode/score": 0.14947048055137202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14947048055137202}
{"step": 244160, "time": 7922.618165016174, "episode/length": 288.0, "episode/score": 0.1976076252490202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1976076252490202}
{"step": 244904, "time": 7945.422901391983, "episode/length": 288.0, "episode/score": 0.1637011911520858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1637011911520858}
{"step": 245224, "time": 7955.425723075867, "episode/length": 288.0, "episode/score": 0.20598038608341085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20598038608341085}
{"step": 245304, "time": 7957.907516479492, "episode/length": 288.0, "episode/score": 0.2103023922588818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2103023922588818}
{"step": 245456, "time": 7962.825217723846, "episode/length": 288.0, "episode/score": 0.17525662295520306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17525662295520306}
{"step": 245624, "time": 7967.791305303574, "episode/length": 288.0, "episode/score": 0.15455877028898612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15455877028898612}
{"step": 246024, "time": 7980.588945865631, "episode/length": 288.0, "episode/score": 0.1843637157462581, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1843637157462581}
{"step": 246336, "time": 7990.54064822197, "episode/length": 288.0, "episode/score": 0.10016128772576849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10016128772576849}
{"step": 246472, "time": 7994.528617143631, "episode/length": 288.0, "episode/score": 0.1637417821955296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1637417821955296}
{"step": 247216, "time": 8017.705390453339, "episode/length": 288.0, "episode/score": 0.2152831056996547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2152831056996547}
{"step": 247536, "time": 8027.593460083008, "episode/length": 288.0, "episode/score": 0.15919206562170984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15919206562170984}
{"step": 247616, "time": 8030.054746389389, "episode/length": 288.0, "episode/score": 0.2531620843587916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2531620843587916}
{"step": 247768, "time": 8034.514625549316, "episode/length": 288.0, "episode/score": 0.18919911233774656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18919911233774656}
{"step": 247936, "time": 8039.89727807045, "episode/length": 288.0, "episode/score": 0.2267172249178202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2267172249178202}
{"step": 248336, "time": 8052.310590267181, "episode/length": 288.0, "episode/score": 0.11070385250263826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11070385250263826}
{"step": 248648, "time": 8061.705178976059, "episode/length": 288.0, "episode/score": 0.23149978100127555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23149978100127555}
{"step": 248784, "time": 8066.169592857361, "episode/length": 288.0, "episode/score": 0.1793617084881589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1793617084881589}
{"step": 249528, "time": 8089.345669746399, "episode/length": 288.0, "episode/score": 0.22536909245695824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22536909245695824}
{"step": 249848, "time": 8099.242018938065, "episode/length": 288.0, "episode/score": 0.13935510860778777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13935510860778777}
{"step": 249928, "time": 8101.750289678574, "episode/length": 288.0, "episode/score": 0.14765597359746607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14765597359746607}
{"step": 250016, "time": 8105.436447620392, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 250016, "time": 8107.6216559410095, "eval_episode/length": 168.0, "eval_episode/score": 0.4749999940395355, "eval_episode/reward_rate": 0.005917159763313609}
{"step": 250016, "time": 8109.555168628693, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8109.56219959259, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8109.567969083786, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8109.573694467545, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8109.5794949531555, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8109.584914445877, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250080, "time": 8111.608078718185, "episode/length": 288.0, "episode/score": 0.16552478814764982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16552478814764982}
{"step": 250248, "time": 8116.64385509491, "episode/length": 288.0, "episode/score": 0.16383846197049934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16383846197049934}
{"step": 250648, "time": 8129.171768188477, "episode/length": 288.0, "episode/score": 0.12428945460123941, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12428945460123941}
{"step": 250960, "time": 8139.211245536804, "episode/length": 288.0, "episode/score": 0.15379072676410033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15379072676410033}
{"step": 251096, "time": 8143.202335834503, "episode/length": 288.0, "episode/score": 0.1497446294420115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1497446294420115}
{"step": 251840, "time": 8166.466175317764, "episode/length": 288.0, "episode/score": 0.17993756437113007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17993756437113007}
{"step": 252160, "time": 8176.32793712616, "episode/length": 288.0, "episode/score": 0.2648368226305138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2648368226305138}
{"step": 252240, "time": 8178.789427757263, "episode/length": 288.0, "episode/score": 0.24935210667922547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24935210667922547}
{"step": 252392, "time": 8183.284152507782, "episode/length": 288.0, "episode/score": 0.23922967146859264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23922967146859264}
{"step": 252560, "time": 8188.6908502578735, "episode/length": 288.0, "episode/score": 0.19730557310458607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19730557310458607}
{"step": 252960, "time": 8201.144854307175, "episode/length": 288.0, "episode/score": 0.27632447099449564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27632447099449564}
{"step": 253272, "time": 8210.560742139816, "episode/length": 288.0, "episode/score": 0.23346862958010206, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23346862958010206}
{"step": 253408, "time": 8214.973502159119, "episode/length": 288.0, "episode/score": 0.24518476162006664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24518476162006664}
{"step": 253993, "time": 8234.313998937607, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.8510242808948865, "train/action_min": 0.0, "train/action_std": 1.5193946761916381, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0017186832031284487, "train/actor_opt_grad_steps": 14785.0, "train/actor_opt_loss": 4.600130050457224, "train/adv_mag": 0.0072901973670179195, "train/adv_max": 0.007075391333512586, "train/adv_mean": 0.001178530342768323, "train/adv_min": -0.0031550887106644985, "train/adv_std": 0.0013263363551672999, "train/cont_avg": 0.9967891808712122, "train/cont_loss_mean": 0.02167330730254903, "train/cont_loss_std": 0.30874414848530607, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.6766857063214395, "train/cont_pos_acc": 0.9999999867545234, "train/cont_pos_loss": 0.003449593141505664, "train/cont_pred": 0.9965564340654046, "train/cont_rate": 0.9967891808712122, "train/dyn_loss_mean": 1.0000033125732883, "train/dyn_loss_std": 9.465532352668092e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15860683015651172, "train/extr_critic_critic_opt_grad_steps": 14785.0, "train/extr_critic_critic_opt_loss": 12947.931246054293, "train/extr_critic_mag": 0.2527713221733016, "train/extr_critic_max": 0.2527713221733016, "train/extr_critic_mean": 0.2506928288123824, "train/extr_critic_min": 0.24803177816699248, "train/extr_critic_std": 0.0006688268692938216, "train/extr_return_normed_mag": 0.011147527532144026, "train/extr_return_normed_max": 0.011063206903260164, "train/extr_return_normed_mean": 0.004871698493724295, "train/extr_return_normed_min": 0.0003716083939629372, "train/extr_return_normed_std": 0.0015015427144879306, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2580628575700702, "train/extr_return_raw_max": 0.2580628575700702, "train/extr_return_raw_mean": 0.25187136097387836, "train/extr_return_raw_min": 0.24737125906077298, "train/extr_return_raw_std": 0.001501542716251799, "train/extr_reward_mag": 0.0031777367447361803, "train/extr_reward_max": 0.0031777367447361803, "train/extr_reward_mean": 0.0009702782120468621, "train/extr_reward_min": 4.044446078213778e-05, "train/extr_reward_std": 0.0005475997905255145, "train/image_loss_mean": 0.1942728157296325, "train/image_loss_std": 0.09902472963387315, "train/model_loss_mean": 0.8354120642849894, "train/model_loss_std": 0.3462488852591828, "train/model_opt_grad_norm": 37.77397847416425, "train/model_opt_grad_steps": 14769.343434343435, "train/model_opt_loss": 2394.1163626006155, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2866.161616161616, "train/policy_entropy_mag": 1.6760373121560221, "train/policy_entropy_max": 1.6760373121560221, "train/policy_entropy_mean": 1.1580869564504335, "train/policy_entropy_min": 0.42805855100353557, "train/policy_entropy_std": 0.21007193865800144, "train/policy_logprob_mag": 5.166562116507328, "train/policy_logprob_max": -0.09969599338982141, "train/policy_logprob_mean": -1.1588562152000388, "train/policy_logprob_min": -5.166562116507328, "train/policy_logprob_std": 0.9545559931283045, "train/policy_randomness_mag": 0.8613128493530582, "train/policy_randomness_max": 0.8613128493530582, "train/policy_randomness_mean": 0.5951390007529596, "train/policy_randomness_min": 0.2199785930264478, "train/policy_randomness_std": 0.10795562744441659, "train/post_ent_mag": 64.61322614881728, "train/post_ent_max": 64.61322614881728, "train/post_ent_mean": 64.08298201512808, "train/post_ent_min": 63.7341040601634, "train/post_ent_std": 0.14176538259242522, "train/prior_ent_mag": 63.160159294051354, "train/prior_ent_max": 63.160159294051354, "train/prior_ent_mean": 59.39109817659012, "train/prior_ent_min": 57.83564396097203, "train/prior_ent_std": 0.8340417637367441, "train/rep_loss_mean": 1.0000033125732883, "train/rep_loss_std": 9.465532352668092e-05, "train/reward_avg": 0.0005135436094309571, "train/reward_loss_mean": 0.019463932659063075, "train/reward_loss_std": 0.04911508071565568, "train/reward_max_data": 0.042937709460731104, "train/reward_max_pred": 0.0022118723753726845, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.018688863340878124, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.29909446504381, "train/reward_pred": 0.0005213628985185289, "train/reward_rate": 9.371054292929292e-05, "train_stats/mean_log_entropy": 1.1784791973752713, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.03601190447807312, "report/cont_loss_std": 0.4024791419506073, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.278550148010254, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005112866871058941, "report/cont_pred": 0.9948999881744385, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.17936936020851135, "report/image_loss_std": 0.10129284113645554, "report/model_loss_mean": 0.835823118686676, "report/model_loss_std": 0.4172479212284088, "report/post_ent_mag": 64.35580444335938, "report/post_ent_max": 64.35580444335938, "report/post_ent_mean": 63.74192428588867, "report/post_ent_min": 63.340171813964844, "report/post_ent_std": 0.16858525574207306, "report/prior_ent_mag": 64.42001342773438, "report/prior_ent_max": 64.42001342773438, "report/prior_ent_mean": 60.36030197143555, "report/prior_ent_min": 58.029052734375, "report/prior_ent_std": 0.9564107060432434, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0005134741659276187, "report/reward_loss_mean": 0.020441804081201553, "report/reward_loss_std": 0.027530290186405182, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.0020372867584228516, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.020441805943846703, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0006230395520105958, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02056238427758217, "eval/cont_loss_std": 0.28501471877098083, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.278550148010254, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.005112866405397654, "eval/cont_pred": 0.9948999881744385, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18745800852775574, "eval/image_loss_std": 0.12075124680995941, "eval/model_loss_mean": 0.8106801509857178, "eval/model_loss_std": 0.3136698007583618, "eval/post_ent_mag": 64.36054992675781, "eval/post_ent_max": 64.36054992675781, "eval/post_ent_mean": 63.73316192626953, "eval/post_ent_min": 63.30070114135742, "eval/post_ent_std": 0.16280877590179443, "eval/prior_ent_mag": 64.05081939697266, "eval/prior_ent_max": 64.05081939697266, "eval/prior_ent_mean": 60.44889831542969, "eval/prior_ent_min": 58.371498107910156, "eval/prior_ent_std": 0.9620506167411804, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0026596831157803535, "eval/reward_loss_std": 0.0032514119520783424, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0021173954010009766, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0026596831157803535, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00044726673513650894, "eval/reward_rate": 0.0, "replay/size": 253489.0, "replay/inserts": 31712.0, "replay/samples": 31712.0, "replay/insert_wait_avg": 1.1718688169954764e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.727026458224423e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 61168.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0734679652195352e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3063313961029, "timer/env.step_count": 3964.0, "timer/env.step_total": 33.9462788105011, "timer/env.step_frac": 0.03393588318402735, "timer/env.step_avg": 0.008563642484990187, "timer/env.step_min": 0.007187843322753906, "timer/env.step_max": 0.05014514923095703, "timer/replay._sample_count": 31712.0, "timer/replay._sample_total": 15.735441446304321, "timer/replay._sample_frac": 0.015730622662702486, "timer/replay._sample_avg": 0.0004961983301685267, "timer/replay._sample_min": 0.0003952980041503906, "timer/replay._sample_max": 0.011220693588256836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4831.0, "timer/agent.policy_total": 41.248507261276245, "timer/agent.policy_frac": 0.041235875417989926, "timer/agent.policy_avg": 0.008538295852054697, "timer/agent.policy_min": 0.007403135299682617, "timer/agent.policy_max": 0.08267354965209961, "timer/dataset_train_count": 1982.0, "timer/dataset_train_total": 0.20778846740722656, "timer/dataset_train_frac": 0.00020772483476858664, "timer/dataset_train_avg": 0.0001048377736666128, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.0006299018859863281, "timer/agent.train_count": 1982.0, "timer/agent.train_total": 878.6009767055511, "timer/agent.train_frac": 0.8783319160634617, "timer/agent.train_avg": 0.4432900992459895, "timer/agent.train_min": 0.4331340789794922, "timer/agent.train_max": 0.6350812911987305, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4710249900817871, "timer/agent.report_frac": 0.00047088074452591853, "timer/agent.report_avg": 0.23551249504089355, "timer/agent.report_min": 0.2241358757019043, "timer/agent.report_max": 0.2468891143798828, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.193830589377577e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 31.70173962985336}
{"step": 254152, "time": 8238.97324347496, "episode/length": 288.0, "episode/score": 0.22196157487860546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22196157487860546}
{"step": 254472, "time": 8248.865306854248, "episode/length": 288.0, "episode/score": 0.18280807860810455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18280807860810455}
{"step": 254552, "time": 8251.353472948074, "episode/length": 288.0, "episode/score": 0.2592127253662966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2592127253662966}
{"step": 254704, "time": 8256.380608797073, "episode/length": 288.0, "episode/score": 0.23923508176108044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23923508176108044}
{"step": 254872, "time": 8261.34465932846, "episode/length": 288.0, "episode/score": 0.21587201669603928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21587201669603928}
{"step": 255272, "time": 8273.661375522614, "episode/length": 288.0, "episode/score": 0.18351880227010042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18351880227010042}
{"step": 255584, "time": 8283.513997077942, "episode/length": 288.0, "episode/score": 0.1952850722174162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1952850722174162}
{"step": 255720, "time": 8287.610209941864, "episode/length": 288.0, "episode/score": 0.1433891578794828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1433891578794828}
{"step": 255968, "time": 8295.496842622757, "episode/length": 226.0, "episode/score": 0.4021870433502954, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.10843705759953082}
{"step": 256784, "time": 8320.655850887299, "episode/length": 288.0, "episode/score": 0.17870241255093333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17870241255093333}
{"step": 256864, "time": 8323.11658167839, "episode/length": 288.0, "episode/score": 0.15773461330513783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15773461330513783}
{"step": 257016, "time": 8327.575885295868, "episode/length": 288.0, "episode/score": 0.18735462045106033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18735462045106033}
{"step": 257184, "time": 8332.966967821121, "episode/length": 288.0, "episode/score": 0.15145234549174802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15145234549174802}
{"step": 257584, "time": 8345.394522666931, "episode/length": 288.0, "episode/score": 0.15871274423989234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15871274423989234}
{"step": 257896, "time": 8354.78993010521, "episode/length": 288.0, "episode/score": 0.17093825106746863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17093825106746863}
{"step": 258032, "time": 8359.211471796036, "episode/length": 288.0, "episode/score": 0.07641505729736764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07641505729736764}
{"step": 258280, "time": 8366.63215136528, "episode/length": 288.0, "episode/score": 0.2005952890286835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2005952890286835}
{"step": 259096, "time": 8391.872414588928, "episode/length": 288.0, "episode/score": 0.1824367528898847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1824367528898847}
{"step": 259176, "time": 8394.403884887695, "episode/length": 288.0, "episode/score": 0.1423182059699002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1423182059699002}
{"step": 259176, "time": 8394.410541772842, "episode/length": 142.0, "episode/score": 0.6922469240637383, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.13599694953541075}
{"step": 259328, "time": 8399.422514677048, "episode/length": 288.0, "episode/score": 0.2178046561748488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2178046561748488}
{"step": 259496, "time": 8404.463491916656, "episode/length": 288.0, "episode/score": 0.16572668254002565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16572668254002565}
{"step": 259896, "time": 8417.074535131454, "episode/length": 288.0, "episode/score": 0.18887304566919738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18887304566919738}
{"step": 260000, "time": 8421.732010126114, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 260000, "time": 8425.331113576889, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8425.339024305344, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8425.344937086105, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8425.351024150848, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8425.357027053833, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8425.362803220749, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8425.36872267723, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260208, "time": 8431.880646944046, "episode/length": 288.0, "episode/score": 0.20469152089174258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20469152089174258}
{"step": 260592, "time": 8443.990226507187, "episode/length": 288.0, "episode/score": 0.16192735817719495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16192735817719495}
{"step": 261176, "time": 8461.811598777771, "episode/length": 120.0, "episode/score": 0.7363911551396995, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.11139115746800599}
{"step": 261408, "time": 8469.327208518982, "episode/length": 288.0, "episode/score": 0.15424969901846453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15424969901846453}
{"step": 261488, "time": 8471.780170440674, "episode/length": 288.0, "episode/score": 0.1898828294475834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1898828294475834}
{"step": 261488, "time": 8471.787212610245, "episode/length": 288.0, "episode/score": 0.19354244050168745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19354244050168745}
{"step": 261640, "time": 8476.289742469788, "episode/length": 288.0, "episode/score": 0.18787996162552645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18787996162552645}
{"step": 261808, "time": 8481.696774959564, "episode/length": 288.0, "episode/score": 0.1654863578110053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1654863578110053}
{"step": 262208, "time": 8494.50284075737, "episode/length": 288.0, "episode/score": 0.19629560103771837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19629560103771837}
{"step": 262544, "time": 8504.983747720718, "episode/length": 170.0, "episode/score": 0.6587834849151477, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.19003348654496222}
{"step": 262904, "time": 8515.875244140625, "episode/length": 288.0, "episode/score": 0.16600661311667864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16600661311667864}
{"step": 263720, "time": 8541.141061067581, "episode/length": 288.0, "episode/score": 0.1726736329353571, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1726736329353571}
{"step": 263800, "time": 8543.619402170181, "episode/length": 288.0, "episode/score": 0.2200486753936275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2200486753936275}
{"step": 263800, "time": 8543.626741886139, "episode/length": 288.0, "episode/score": 0.28118687281562416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28118687281562416}
{"step": 263952, "time": 8548.557059049606, "episode/length": 288.0, "episode/score": 0.19681601217143907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19681601217143907}
{"step": 264120, "time": 8553.498679637909, "episode/length": 288.0, "episode/score": 0.19776477758887268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19776477758887268}
{"step": 264520, "time": 8565.872577428818, "episode/length": 288.0, "episode/score": 0.20454852597208628, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20454852597208628}
{"step": 264856, "time": 8576.247373580933, "episode/length": 288.0, "episode/score": 0.16594810397782567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16594810397782567}
{"step": 265216, "time": 8587.703631162643, "episode/length": 288.0, "episode/score": 0.2024343901427983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2024343901427983}
{"step": 266032, "time": 8612.963011264801, "episode/length": 288.0, "episode/score": 0.2102009747716238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2102009747716238}
{"step": 266112, "time": 8615.500409841537, "episode/length": 288.0, "episode/score": 0.22268337211971811, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22268337211971811}
{"step": 266112, "time": 8615.521043300629, "episode/length": 288.0, "episode/score": 0.20872667872868078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20872667872868078}
{"step": 266144, "time": 8616.523139715195, "episode/length": 252.0, "episode/score": 0.40302458443898104, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.19052457964266978}
{"step": 266264, "time": 8620.026054143906, "episode/length": 288.0, "episode/score": 0.14716127375208998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14716127375208998}
{"step": 266832, "time": 8637.772965431213, "episode/length": 288.0, "episode/score": 0.21421049069044784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21421049069044784}
{"step": 267168, "time": 8648.239736318588, "episode/length": 288.0, "episode/score": 0.17401014084407507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17401014084407507}
{"step": 267528, "time": 8659.135314702988, "episode/length": 288.0, "episode/score": 0.10455909789357065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10455909789357065}
{"step": 268344, "time": 8685.301275730133, "episode/length": 288.0, "episode/score": 0.17095515249559412, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17095515249559412}
{"step": 268424, "time": 8687.759157180786, "episode/length": 288.0, "episode/score": 0.213298018581213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.213298018581213}
{"step": 268424, "time": 8687.766702890396, "episode/length": 288.0, "episode/score": 0.2335784602360036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2335784602360036}
{"step": 268456, "time": 8688.77490568161, "episode/length": 288.0, "episode/score": 0.16645566474892348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16645566474892348}
{"step": 268576, "time": 8692.69644832611, "episode/length": 288.0, "episode/score": 0.16500586393613048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16500586393613048}
{"step": 269144, "time": 8710.32184290886, "episode/length": 288.0, "episode/score": 0.24723881127204095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24723881127204095}
{"step": 269480, "time": 8720.703719615936, "episode/length": 288.0, "episode/score": 0.2105201987201326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2105201987201326}
{"step": 269840, "time": 8731.977638959885, "episode/length": 288.0, "episode/score": 0.22948650905425438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22948650905425438}
{"step": 270088, "time": 8744.512687206268, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8744.51888370514, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8744.530563354492, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8744.537725925446, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8744.542967796326, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8744.548184156418, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8744.55335855484, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8744.558630943298, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270656, "time": 8762.72397017479, "episode/length": 288.0, "episode/score": 0.2299451643386874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2299451643386874}
{"step": 270736, "time": 8765.293824195862, "episode/length": 288.0, "episode/score": 0.1782666880577608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1782666880577608}
{"step": 270736, "time": 8765.302030086517, "episode/length": 288.0, "episode/score": 0.20467451316471852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20467451316471852}
{"step": 270768, "time": 8766.299644231796, "episode/length": 288.0, "episode/score": 0.15004815874556243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15004815874556243}
{"step": 270888, "time": 8769.780116319656, "episode/length": 288.0, "episode/score": 0.23276252363359617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23276252363359617}
{"step": 271312, "time": 8783.072922229767, "episode/length": 67.0, "episode/score": 0.8548259570459322, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.06420098321609657}
{"step": 271456, "time": 8787.503225326538, "episode/length": 288.0, "episode/score": 0.23370141029135993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23370141029135993}
{"step": 271792, "time": 8797.946780204773, "episode/length": 288.0, "episode/score": 0.1607351760229676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1607351760229676}
{"step": 272152, "time": 8808.785828351974, "episode/length": 288.0, "episode/score": 0.21832296458796918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21832296458796918}
{"step": 272520, "time": 8820.150441169739, "episode/length": 203.0, "episode/score": 0.5462685766046889, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.18064358419496784}
{"step": 272968, "time": 8834.106011629105, "episode/length": 288.0, "episode/score": 0.14018641031475454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14018641031475454}
{"step": 273048, "time": 8836.628358840942, "episode/length": 288.0, "episode/score": 0.18369194475201311, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18369194475201311}
{"step": 273048, "time": 8836.635444879532, "episode/length": 288.0, "episode/score": 0.14194641764697735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14194641764697735}
{"step": 273624, "time": 8854.421048879623, "episode/length": 288.0, "episode/score": 0.1662209081621313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1662209081621313}
{"step": 273768, "time": 8858.958372116089, "episode/length": 288.0, "episode/score": 0.2002710015131015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2002710015131015}
{"step": 274104, "time": 8869.321075677872, "episode/length": 288.0, "episode/score": 0.19934408008089122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19934408008089122}
{"step": 274464, "time": 8880.653960704803, "episode/length": 288.0, "episode/score": 0.12656812090961012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12656812090961012}
{"step": 274832, "time": 8892.140605449677, "episode/length": 288.0, "episode/score": 0.11818933372830998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11818933372830998}
{"step": 275280, "time": 8906.030116319656, "episode/length": 288.0, "episode/score": 0.16680658222503553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16680658222503553}
{"step": 275360, "time": 8908.530308246613, "episode/length": 156.0, "episode/score": 0.5966429270575873, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.08414294130682265}
{"step": 275360, "time": 8908.537387132645, "episode/length": 288.0, "episode/score": 0.1747784577295306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1747784577295306}
{"step": 275360, "time": 8908.543700933456, "episode/length": 288.0, "episode/score": 0.2088037993812577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2088037993812577}
{"step": 275640, "time": 8917.081012010574, "episode/length": 100.0, "episode/score": 0.7672322107775926, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.07973221310589906}
{"step": 275928, "time": 8925.982201099396, "episode/length": 70.0, "episode/score": 0.8324210475286691, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.051171049158483584}
{"step": 275936, "time": 8926.455924034119, "episode/length": 288.0, "episode/score": 0.14920286262383797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14920286262383797}
{"step": 276080, "time": 8930.917078018188, "episode/length": 288.0, "episode/score": 0.0876090634361617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0876090634361617}
{"step": 276560, "time": 8945.83166050911, "episode/length": 149.0, "episode/score": 0.6322788268640807, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.09790378630498253}
{"step": 276648, "time": 8948.348345279694, "episode/length": 89.0, "episode/score": 0.7904676249685849, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.06859261386256321}
{"step": 276776, "time": 8952.309489011765, "episode/length": 288.0, "episode/score": 0.11148427233308666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11148427233308666}
{"step": 277248, "time": 8967.139310836792, "episode/length": 145.0, "episode/score": 0.5874323616207562, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.040557374542856905}
{"step": 277264, "time": 8967.64236998558, "episode/length": 237.0, "episode/score": 0.3544215739945571, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.09504656919824583}
{"step": 277592, "time": 8977.691208600998, "episode/length": 288.0, "episode/score": 0.10969164517609897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10969164517609897}
{"step": 277952, "time": 8989.073225975037, "episode/length": 288.0, "episode/score": 0.1351513513781697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1351513513781697}
{"step": 278248, "time": 8998.129016637802, "episode/length": 288.0, "episode/score": 0.1126448427962714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1126448427962714}
{"step": 278512, "time": 9006.754139184952, "episode/length": 243.0, "episode/score": 0.3669224426124629, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.12629744711773583}
{"step": 278536, "time": 9007.55587053299, "episode/length": 35.0, "episode/score": 0.9216078448491203, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.030982845664027536}
{"step": 278848, "time": 9017.934355735779, "episode/length": 156.0, "episode/score": 0.6115380760716675, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.09903809032090294}
{"step": 278960, "time": 9021.47485113144, "episode/length": 288.0, "episode/score": 0.11322662022740815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11322662022740815}
{"step": 279088, "time": 9025.456107616425, "episode/length": 288.0, "episode/score": 0.09553301285626503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09553301285626503}
{"step": 279560, "time": 9039.905040979385, "episode/length": 288.0, "episode/score": 0.12357000451044087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12357000451044087}
{"step": 279576, "time": 9040.405688762665, "episode/length": 288.0, "episode/score": 0.07705425455344539, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07705425455344539}
{"step": 279792, "time": 9047.316382408142, "episode/length": 229.0, "episode/score": 0.3999522246838296, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.11557721509120711}
{"step": 280072, "time": 9056.838193893433, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 280072, "time": 9057.761434316635, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 280072, "time": 9058.61949801445, "eval_episode/length": 187.0, "eval_episode/score": 0.4156250059604645, "eval_episode/reward_rate": 0.005319148936170213}
{"step": 280072, "time": 9058.869635343552, "eval_episode/length": 203.0, "eval_episode/score": 0.3656249940395355, "eval_episode/reward_rate": 0.004901960784313725}
{"step": 280072, "time": 9058.997893810272, "eval_episode/length": 211.0, "eval_episode/score": 0.34062498807907104, "eval_episode/reward_rate": 0.0047169811320754715}
{"step": 280072, "time": 9059.279836654663, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 280072, "time": 9060.18718123436, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9060.19339632988, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9060.199288129807, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280824, "time": 9083.501290082932, "episode/length": 288.0, "episode/score": 0.12381016160264835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12381016160264835}
{"step": 280848, "time": 9084.46664762497, "episode/length": 288.0, "episode/score": 0.11923658768319001, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11923658768319001}
{"step": 281160, "time": 9093.856432676315, "episode/length": 288.0, "episode/score": 0.11626394294285092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11626394294285092}
{"step": 281272, "time": 9097.423389673233, "episode/length": 288.0, "episode/score": 0.07531351629995697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07531351629995697}
{"step": 281400, "time": 9101.454219818115, "episode/length": 288.0, "episode/score": 0.13085732086847202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13085732086847202}
{"step": 281672, "time": 9109.907560825348, "episode/length": 263.0, "episode/score": 0.2671947823037044, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.08906978942832211}
{"step": 281888, "time": 9116.919854164124, "episode/length": 288.0, "episode/score": 0.07424360742470526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07424360742470526}
{"step": 282016, "time": 9120.911456346512, "episode/length": 148.0, "episode/score": 0.6126649443456245, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.07516492283207299}
{"step": 282104, "time": 9123.45470905304, "episode/length": 288.0, "episode/score": 0.11771073634804452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11771073634804452}
{"step": 283160, "time": 9156.349742174149, "episode/length": 288.0, "episode/score": 0.11826186665643945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11826186665643945}
{"step": 283192, "time": 9157.332471370697, "episode/length": 239.0, "episode/score": 0.36448836396562, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.11136335367450556}
{"step": 283472, "time": 9166.199035167694, "episode/length": 288.0, "episode/score": 0.10646206825299487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10646206825299487}
{"step": 283712, "time": 9173.562292337418, "episode/length": 288.0, "episode/score": 0.08127194717008024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08127194717008024}
{"step": 283984, "time": 9181.926971673965, "episode/length": 288.0, "episode/score": 0.12251301980154494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12251301980154494}
{"step": 284200, "time": 9188.426687955856, "episode/length": 288.0, "episode/score": 0.09758110068514725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09758110068514725}
{"step": 284256, "time": 9190.372203111649, "episode/length": 97.0, "episode/score": 0.7619342843378263, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.06505927954151502}
{"step": 284288, "time": 9191.384676456451, "episode/length": 283.0, "episode/score": 0.1991427421805838, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.08351774185462091}
{"step": 284416, "time": 9195.316883087158, "episode/length": 288.0, "episode/score": 0.108790439501945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.108790439501945}
{"step": 284472, "time": 9196.83508682251, "episode/length": 163.0, "episode/score": 0.5553217370162429, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.06469675589880808}
{"step": 284528, "time": 9198.775495767593, "episode/length": 166.0, "episode/score": 0.575978687189945, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.09472870143918044}
{"step": 285624, "time": 9232.495083332062, "episode/length": 204.0, "episode/score": 0.4276394939444117, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.06513948365329725}
{"step": 285657, "time": 9234.47338938713, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.0767594154434974, "train/action_min": 0.0, "train/action_std": 1.6644979077156143, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0015033475094536, "train/actor_opt_grad_steps": 16765.0, "train/actor_opt_loss": -0.4900129746005993, "train/adv_mag": 0.009508216320866287, "train/adv_max": 0.008724989162551032, "train/adv_mean": 0.0007305713129759317, "train/adv_min": -0.004388972213774016, "train/adv_std": 0.001536054971199859, "train/cont_avg": 0.99658203125, "train/cont_loss_mean": 0.022846618721336878, "train/cont_loss_std": 0.3171195257943849, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.666543024191585, "train/cont_pos_acc": 0.9999999861524562, "train/cont_pos_loss": 0.0034932916080861382, "train/cont_pred": 0.9965128645752416, "train/cont_rate": 0.99658203125, "train/dyn_loss_mean": 1.0000016340101607, "train/dyn_loss_std": 5.225297251735071e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11128211914822742, "train/extr_critic_critic_opt_grad_steps": 16765.0, "train/extr_critic_critic_opt_loss": 12972.644546046402, "train/extr_critic_mag": 0.2916981132343562, "train/extr_critic_max": 0.2916981132343562, "train/extr_critic_mean": 0.2886426397646316, "train/extr_critic_min": 0.2849521173371209, "train/extr_critic_std": 0.0009135128855246655, "train/extr_return_normed_mag": 0.013432917570826984, "train/extr_return_normed_max": 0.013242990531102575, "train/extr_return_normed_mean": 0.004166153856920463, "train/extr_return_normed_min": -0.0009954609353132922, "train/extr_return_normed_std": 0.001765969549211664, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2984500640269482, "train/extr_return_raw_max": 0.2984500640269482, "train/extr_return_raw_mean": 0.28937324309589885, "train/extr_return_raw_min": 0.2842116125605323, "train/extr_return_raw_std": 0.0017659695403923214, "train/extr_reward_mag": 0.006157058658021869, "train/extr_reward_max": 0.006157058658021869, "train/extr_reward_mean": 0.0009701884112960536, "train/extr_reward_min": 3.093782097402245e-05, "train/extr_reward_std": 0.0007540354553099741, "train/image_loss_mean": 0.18465633028083378, "train/image_loss_std": 0.10175914294791943, "train/model_loss_mean": 0.8281370410413453, "train/model_loss_std": 0.36358182963849317, "train/model_opt_grad_norm": 34.12148276723997, "train/model_opt_grad_steps": 16747.641414141413, "train/model_opt_loss": 2392.3735801619714, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2891.4141414141413, "train/policy_entropy_mag": 1.7627891916217227, "train/policy_entropy_max": 1.7627891916217227, "train/policy_entropy_mean": 1.0222985076181816, "train/policy_entropy_min": 0.20396653702012216, "train/policy_entropy_std": 0.32288135302187215, "train/policy_logprob_mag": 5.845145536191536, "train/policy_logprob_max": -0.037696888411624566, "train/policy_logprob_mean": -1.023161651510181, "train/policy_logprob_min": -5.845145536191536, "train/policy_logprob_std": 1.026215019250157, "train/policy_randomness_mag": 0.9058944962241433, "train/policy_randomness_max": 0.9058944962241433, "train/policy_randomness_mean": 0.525357540809747, "train/policy_randomness_min": 0.10481807162439583, "train/policy_randomness_std": 0.1659282014300727, "train/post_ent_mag": 62.455013159549594, "train/post_ent_max": 62.455013159549594, "train/post_ent_mean": 61.78398134250833, "train/post_ent_min": 61.269951001562255, "train/post_ent_std": 0.19792972008387247, "train/prior_ent_mag": 63.75863150394324, "train/prior_ent_max": 63.75863150394324, "train/prior_ent_mean": 60.68267725934886, "train/prior_ent_min": 58.128905132563425, "train/prior_ent_std": 0.9053408383118986, "train/rep_loss_mean": 1.0000016340101607, "train/rep_loss_std": 5.225297251735071e-05, "train/reward_avg": 0.000567336064631665, "train/reward_loss_mean": 0.020633095390906537, "train/reward_loss_std": 0.05733277475593066, "train/reward_max_data": 0.07206334127583588, "train/reward_max_pred": 0.0026114354229936697, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.019576297743678694, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 7.933235480235173, "train/reward_pred": 0.0005452960542628937, "train/reward_rate": 0.00013316761363636363, "train_stats/mean_log_entropy": 1.0096323391622748, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.030933910980820656, "report/cont_loss_std": 0.38338473439216614, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.504078388214111, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004078443627804518, "report/cont_pred": 0.9959297776222229, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.18223118782043457, "report/image_loss_std": 0.100447878241539, "report/model_loss_mean": 0.8461469411849976, "report/model_loss_std": 0.6565268039703369, "report/post_ent_mag": 60.03740692138672, "report/post_ent_max": 60.03740692138672, "report/post_ent_mean": 59.27580261230469, "report/post_ent_min": 58.79344940185547, "report/post_ent_std": 0.21053339540958405, "report/prior_ent_mag": 61.2939338684082, "report/prior_ent_max": 61.2939338684082, "report/prior_ent_mean": 58.5289306640625, "report/prior_ent_min": 55.466854095458984, "report/prior_ent_std": 1.0825649499893188, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0014071715995669365, "report/reward_loss_mean": 0.032981809228658676, "report/reward_loss_std": 0.31539812684059143, "report/reward_max_data": 0.7931249737739563, "report/reward_max_pred": 0.001996278762817383, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01909840665757656, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 7.1274003982543945, "report/reward_pred": 0.0005049095489084721, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.025562819093465805, "eval/cont_loss_std": 0.34307795763015747, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.504078388214111, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0040784431621432304, "eval/cont_pred": 0.9959297776222229, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18534205853939056, "eval/image_loss_std": 0.11936777830123901, "eval/model_loss_mean": 0.8199722766876221, "eval/model_loss_std": 0.5120406746864319, "eval/post_ent_mag": 59.857505798339844, "eval/post_ent_max": 59.857505798339844, "eval/post_ent_mean": 59.25889587402344, "eval/post_ent_min": 58.785301208496094, "eval/post_ent_std": 0.1916498839855194, "eval/prior_ent_mag": 61.373870849609375, "eval/prior_ent_max": 61.373870849609375, "eval/prior_ent_mean": 58.48143005371094, "eval/prior_ent_min": 55.95364761352539, "eval/prior_ent_std": 1.1134288311004639, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0006317138904705644, "eval/reward_loss_mean": 0.009067355655133724, "eval/reward_loss_std": 0.21168947219848633, "eval/reward_max_data": 0.6468750238418579, "eval/reward_max_pred": 0.0022085905075073242, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0024494221433997154, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.779213905334473, "eval/reward_pred": 0.0004236195236444473, "eval/reward_rate": 0.0009765625, "replay/size": 285153.0, "replay/inserts": 31664.0, "replay/samples": 31664.0, "replay/insert_wait_avg": 1.1869350908500129e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.565633524181025e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 68104.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0262723612537847e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1435744762421, "timer/env.step_count": 3958.0, "timer/env.step_total": 33.90382122993469, "timer/env.step_frac": 0.033898954205339504, "timer/env.step_avg": 0.008565897228381681, "timer/env.step_min": 0.0072345733642578125, "timer/env.step_max": 0.03863859176635742, "timer/replay._sample_count": 31664.0, "timer/replay._sample_total": 15.823915004730225, "timer/replay._sample_frac": 0.015821643420562827, "timer/replay._sample_avg": 0.0004997446628578267, "timer/replay._sample_min": 0.000408172607421875, "timer/replay._sample_max": 0.011028289794921875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4825.0, "timer/agent.policy_total": 40.872132778167725, "timer/agent.policy_frac": 0.04086626542551329, "timer/agent.policy_avg": 0.008470908347806783, "timer/agent.policy_min": 0.007426738739013672, "timer/agent.policy_max": 0.07137227058410645, "timer/dataset_train_count": 1979.0, "timer/dataset_train_total": 0.20797181129455566, "timer/dataset_train_frac": 0.00020794195613711453, "timer/dataset_train_avg": 0.00010508934375672343, "timer/dataset_train_min": 8.797645568847656e-05, "timer/dataset_train_max": 0.00037789344787597656, "timer/agent.train_count": 1979.0, "timer/agent.train_total": 879.106654882431, "timer/agent.train_frac": 0.8789804557238735, "timer/agent.train_avg": 0.4442176123711122, "timer/agent.train_min": 0.43412303924560547, "timer/agent.train_max": 1.357452154159546, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4718911647796631, "timer/agent.report_frac": 0.00047182342297883014, "timer/agent.report_avg": 0.23594558238983154, "timer/agent.report_min": 0.2237236499786377, "timer/agent.report_max": 0.2481675148010254, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.337380944700719e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 31.65891816086346}
{"step": 285936, "time": 9243.074208259583, "episode/length": 175.0, "episode/score": 0.538210239413047, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.08508524174135346}
{"step": 286024, "time": 9245.711071491241, "episode/length": 288.0, "episode/score": 0.1268532005092311, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1268532005092311}
{"step": 286512, "time": 9261.202477693558, "episode/length": 288.0, "episode/score": 0.1413314531201877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1413314531201877}
{"step": 286552, "time": 9262.239971637726, "episode/length": 259.0, "episode/score": 0.3172082044950457, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.1265832098035844}
{"step": 286568, "time": 9262.748601913452, "episode/length": 288.0, "episode/score": 0.11757434912306053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11757434912306053}
{"step": 286600, "time": 9263.752824783325, "episode/length": 288.0, "episode/score": 0.14278009913300593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14278009913300593}
{"step": 286728, "time": 9268.06051659584, "episode/length": 288.0, "episode/score": 0.12483524842753013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12483524842753013}
{"step": 287320, "time": 9286.575295448303, "episode/length": 100.0, "episode/score": 0.74206222800467, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.05456219936650086}
{"step": 287648, "time": 9296.84562087059, "episode/length": 114.0, "episode/score": 0.7046235960178819, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.060873597019053705}
{"step": 287936, "time": 9305.735512971878, "episode/length": 288.0, "episode/score": 0.16219599819328323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16219599819328323}
{"step": 288184, "time": 9313.131483793259, "episode/length": 30.0, "episode/score": 0.9365621762633509, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.030312177078258173}
{"step": 288248, "time": 9315.108106136322, "episode/length": 288.0, "episode/score": 0.06664965553181901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06664965553181901}
{"step": 288336, "time": 9318.0576171875, "episode/length": 288.0, "episode/score": 0.2605186175264862, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.1605186183646765}
{"step": 288456, "time": 9321.56068611145, "episode/length": 100.0, "episode/score": 0.7357791398324025, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.04827914216070894}
{"step": 288776, "time": 9331.436207056046, "episode/length": 181.0, "episode/score": 0.5036664858134827, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.06929149936422618}
{"step": 288864, "time": 9334.366404056549, "episode/length": 288.0, "episode/score": 0.13319848256219302, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13319848256219302}
{"step": 288880, "time": 9334.892249822617, "episode/length": 288.0, "episode/score": 0.08322898312644611, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08322898312644611}
{"step": 288912, "time": 9335.981697797775, "episode/length": 288.0, "episode/score": 0.10831445996291222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10831445996291222}
{"step": 289160, "time": 9343.423270463943, "episode/length": 87.0, "episode/score": 0.7599870632930106, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.031862072815783904}
{"step": 289616, "time": 9357.69559264183, "episode/length": 170.0, "episode/score": 0.4993250690217792, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.030575070185932418}
{"step": 290056, "time": 9371.488174200058, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 290056, "time": 9372.727770090103, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 290056, "time": 9375.52780175209, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9375.534170389175, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9375.53957748413, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9375.54502081871, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9375.550287485123, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9375.55569934845, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290080, "time": 9376.507573366165, "episode/length": 217.0, "episode/score": 0.42530728534075024, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.10343228054443898}
{"step": 290280, "time": 9382.418733119965, "episode/length": 176.0, "episode/score": 0.5482976451537525, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.09829765870449592}
{"step": 290496, "time": 9389.22434926033, "episode/length": 288.0, "episode/score": 0.11534336359886765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11534336359886765}
{"step": 290888, "time": 9401.314888238907, "episode/length": 215.0, "episode/score": 0.4706326922423614, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.1425076934065146}
{"step": 291088, "time": 9407.76518702507, "episode/length": 288.0, "episode/score": 0.1194633349864489, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1194633349864489}
{"step": 291144, "time": 9409.275354385376, "episode/length": 31.0, "episode/score": 0.921408555201424, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.018283547797409483}
{"step": 291192, "time": 9410.775430679321, "episode/length": 288.0, "episode/score": 0.12119840633499734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12119840633499734}
{"step": 291224, "time": 9411.76560139656, "episode/length": 288.0, "episode/score": 0.1055605086766036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1055605086766036}
{"step": 291408, "time": 9417.656046152115, "episode/length": 223.0, "episode/score": 0.4306735491353493, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.12754856801791448}
{"step": 292104, "time": 9439.010648727417, "episode/length": 126.0, "episode/score": 0.6788103126489204, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.07256029593168023}
{"step": 292352, "time": 9446.89249587059, "episode/length": 117.0, "episode/score": 0.7003324233734247, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.06595744803018988}
{"step": 292392, "time": 9447.927027702332, "episode/length": 288.0, "episode/score": 0.1433368308541958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1433368308541958}
{"step": 292568, "time": 9453.342643976212, "episode/length": 57.0, "episode/score": 0.8691136427958099, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.04723867955976857}
{"step": 292592, "time": 9454.32155585289, "episode/length": 288.0, "episode/score": 0.07894335144396791, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07894335144396791}
{"step": 292800, "time": 9460.801500558853, "episode/length": 55.0, "episode/score": 0.8893489120582672, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0612239143865736}
{"step": 292808, "time": 9460.836534261703, "episode/length": 288.0, "episode/score": 0.10847494778613509, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10847494778613509}
{"step": 293320, "time": 9476.520859718323, "episode/length": 63.0, "episode/score": 0.8473052918843678, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.044180280964610574}
{"step": 293456, "time": 9480.906620979309, "episode/length": 288.0, "episode/score": 0.08554462775282445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08554462775282445}
{"step": 293504, "time": 9482.374288320541, "episode/length": 288.0, "episode/score": 0.1092233961378497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1092233961378497}
{"step": 293536, "time": 9483.353197336197, "episode/length": 288.0, "episode/score": 0.06906907588040667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06906907588040667}
{"step": 294704, "time": 9519.222592830658, "episode/length": 288.0, "episode/score": 0.12499788626564623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12499788626564623}
{"step": 294880, "time": 9524.620388269424, "episode/length": 288.0, "episode/score": 0.10616272966626639, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10616272966626639}
{"step": 294904, "time": 9525.14364862442, "episode/length": 288.0, "episode/score": 0.079141003748191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.079141003748191}
{"step": 295112, "time": 9531.985769748688, "episode/length": 288.0, "episode/score": 0.11544603751372051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11544603751372051}
{"step": 295632, "time": 9548.216669082642, "episode/length": 288.0, "episode/score": 0.08573598172415586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08573598172415586}
{"step": 295768, "time": 9552.18122625351, "episode/length": 288.0, "episode/score": 0.11128761020427191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11128761020427191}
{"step": 295816, "time": 9553.683696746826, "episode/length": 288.0, "episode/score": 0.08862650145965745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08862650145965745}
{"step": 295848, "time": 9554.675961017609, "episode/length": 288.0, "episode/score": 0.07367955525296566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07367955525296566}
{"step": 296032, "time": 9560.595045566559, "episode/length": 49.0, "episode/score": 0.8745713598400471, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.02769634954893263}
{"step": 296176, "time": 9565.018875598907, "episode/length": 183.0, "episode/score": 0.4765355817166892, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.04841058884130689}
{"step": 297192, "time": 9596.20509147644, "episode/length": 288.0, "episode/score": 0.07360562335179566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07360562335179566}
{"step": 297216, "time": 9597.16275525093, "episode/length": 288.0, "episode/score": 0.03869176095054172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03869176095054172}
{"step": 297424, "time": 9603.561712503433, "episode/length": 288.0, "episode/score": 0.09660138061485668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09660138061485668}
{"step": 297656, "time": 9610.583128929138, "episode/length": 57.0, "episode/score": 0.8844361742417277, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.06256120041189206}
{"step": 298080, "time": 9623.91528749466, "episode/length": 288.0, "episode/score": 0.09985628989556972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09985628989556972}
{"step": 298128, "time": 9625.397443771362, "episode/length": 288.0, "episode/score": 0.08503225732852115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08503225732852115}
{"step": 298160, "time": 9626.387643575668, "episode/length": 288.0, "episode/score": 0.06731014222555132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06731014222555132}
{"step": 298344, "time": 9631.837903022766, "episode/length": 288.0, "episode/score": 0.1410809706424061, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1410809706424061}
{"step": 298488, "time": 9636.384103536606, "episode/length": 288.0, "episode/score": 0.07346935259170095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07346935259170095}
{"step": 299312, "time": 9661.954778432846, "episode/length": 143.0, "episode/score": 0.6622332297304183, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.10910817725039124}
{"step": 299528, "time": 9668.430231571198, "episode/length": 288.0, "episode/score": 0.1316087935856558, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1316087935856558}
{"step": 299736, "time": 9674.830470085144, "episode/length": 288.0, "episode/score": 0.1316911395513216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1316911395513216}
{"step": 299968, "time": 9682.200668811798, "episode/length": 288.0, "episode/score": 0.11577419166428626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11577419166428626}
{"step": 300040, "time": 9685.407542467117, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 300040, "time": 9685.687074661255, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 300040, "time": 9685.691998958588, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 300040, "time": 9685.821686506271, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 300040, "time": 9686.687324285507, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 300040, "time": 9687.184198617935, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 300040, "time": 9688.697751283646, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9688.7042491436, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9688.709824323654, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9688.715302228928, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9688.720741271973, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300392, "time": 9699.621928930283, "episode/length": 288.0, "episode/score": 0.10640147747767514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10640147747767514}
{"step": 300440, "time": 9701.106150865555, "episode/length": 288.0, "episode/score": 0.12115580070371834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12115580070371834}
{"step": 300648, "time": 9707.488490819931, "episode/length": 139.0, "episode/score": 0.6518835231241837, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.08625851283306929}
{"step": 300656, "time": 9707.960633993149, "episode/length": 288.0, "episode/score": 0.14396102133514432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14396102133514432}
{"step": 300800, "time": 9712.398781299591, "episode/length": 288.0, "episode/score": 0.13347687924931506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13347687924931506}
{"step": 301296, "time": 9727.764922618866, "episode/length": 112.0, "episode/score": 0.7460718095255743, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.09607180472926302}
{"step": 301624, "time": 9737.622843265533, "episode/length": 288.0, "episode/score": 0.07392794235465772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07392794235465772}
{"step": 302008, "time": 9749.385701417923, "episode/length": 283.0, "episode/score": 0.24372905299549075, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.12810405383368106}
{"step": 302280, "time": 9757.838362455368, "episode/length": 288.0, "episode/score": 0.09326808509740658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09326808509740658}
{"step": 302752, "time": 9772.556005716324, "episode/length": 288.0, "episode/score": 0.11429342855728919, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11429342855728919}
{"step": 302960, "time": 9778.927701234818, "episode/length": 288.0, "episode/score": 0.18250373484033844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18250373484033844}
{"step": 302968, "time": 9778.9614174366, "episode/length": 288.0, "episode/score": 0.1252931371733439, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1252931371733439}
{"step": 303112, "time": 9783.634983301163, "episode/length": 288.0, "episode/score": 0.14640695439175033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14640695439175033}
{"step": 303376, "time": 9792.249778747559, "episode/length": 77.0, "episode/score": 0.8120799591773675, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.05270499594132616}
{"step": 303520, "time": 9796.661833286285, "episode/length": 68.0, "episode/score": 0.8460390142585084, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.05853900333875117}
{"step": 303608, "time": 9799.146835327148, "episode/length": 288.0, "episode/score": 0.1203550866630394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1203550866630394}
{"step": 303920, "time": 9808.915004014969, "episode/length": 204.0, "episode/score": 0.448192526940943, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.08569252846598374}
{"step": 303936, "time": 9809.437396764755, "episode/length": 288.0, "episode/score": 0.12466465887303002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12466465887303002}
{"step": 304184, "time": 9816.988590955734, "episode/length": 100.0, "episode/score": 0.7518661136817855, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0643661160100919}
{"step": 304320, "time": 9821.440613985062, "episode/length": 288.0, "episode/score": 0.17891525118102436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17891525118102436}
{"step": 304648, "time": 9831.3974776268, "episode/length": 140.0, "episode/score": 0.6958125469058132, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.13331254923411961}
{"step": 304760, "time": 9834.904087305069, "episode/length": 71.0, "episode/score": 0.8325700955419961, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.054445109092739585}
{"step": 305048, "time": 9843.810018539429, "episode/length": 260.0, "episode/score": 0.31993178522748167, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.1324317875557881}
{"step": 305320, "time": 9852.34924530983, "episode/length": 124.0, "episode/score": 0.7186523216423666, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.10615231135125214}
{"step": 305368, "time": 9853.832159996033, "episode/length": 281.0, "episode/score": 0.3086885591549162, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.1868135541956235}
{"step": 305400, "time": 9854.840226888657, "episode/length": 43.0, "episode/score": 0.9159366004641925, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.05031157895064098}
{"step": 305424, "time": 9855.800905942917, "episode/length": 185.0, "episode/score": 0.5265176599114056, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.10464267335737532}
{"step": 305424, "time": 9855.811728477478, "episode/length": 82.0, "episode/score": 0.8125926114780668, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.06884263694973924}
{"step": 305432, "time": 9855.852827072144, "episode/length": 227.0, "episode/score": 0.44043451933396227, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.149809514537651}
{"step": 306232, "time": 9880.625575065613, "episode/length": 288.0, "episode/score": 0.16195384161164839, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16195384161164839}
{"step": 306288, "time": 9882.556537628174, "episode/length": 107.0, "episode/score": 0.7348001201175975, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.06917511532128628}
{"step": 306952, "time": 9902.708497285843, "episode/length": 89.0, "episode/score": 0.7827774262818821, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.06090241599076762}
{"step": 306960, "time": 9903.181743144989, "episode/length": 288.0, "episode/score": 0.09340286657243269, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09340286657243269}
{"step": 307144, "time": 9908.700291633606, "episode/length": 214.0, "episode/score": 0.431613827103547, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.10036381751092449}
{"step": 307392, "time": 9916.539443016052, "episode/length": 30.0, "episode/score": 0.9401536682562437, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.03390367058455013}
{"step": 307632, "time": 9923.906752109528, "episode/length": 288.0, "episode/score": 0.10138272520021019, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10138272520021019}
{"step": 307680, "time": 9925.3796646595, "episode/length": 288.0, "episode/score": 0.11925433562259968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11925433562259968}
{"step": 307712, "time": 9926.365835666656, "episode/length": 288.0, "episode/score": 0.12104090038906179, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12104090038906179}
{"step": 307744, "time": 9927.355011701584, "episode/length": 288.0, "episode/score": 0.05376818239597014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05376818239597014}
{"step": 308208, "time": 9941.743456602097, "episode/length": 239.0, "episode/score": 0.3417377218565889, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.08861271109981317}
{"step": 308392, "time": 9947.173707962036, "episode/length": 22.0, "episode/score": 0.954963122238496, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.023713147710168414}
{"step": 308616, "time": 9954.096468925476, "episode/length": 152.0, "episode/score": 0.6011097797909315, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.07610977499462024}
{"step": 308728, "time": 9957.54259300232, "episode/length": 220.0, "episode/score": 0.39255214604327193, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.08005215896537266}
{"step": 309256, "time": 9973.854630708694, "episode/length": 79.0, "episode/score": 0.7924549551516975, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0393299440456758}
{"step": 309264, "time": 9974.327768564224, "episode/length": 288.0, "episode/score": 0.048025636425336415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048025636425336415}
{"step": 309696, "time": 9987.513796329498, "episode/length": 54.0, "episode/score": 0.8777081705347882, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.04645815942876652}
{"step": 309872, "time": 9992.925580501556, "episode/length": 265.0, "episode/score": 0.23125149076736307, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.059376491931516284}
{"step": 309944, "time": 9994.986314296722, "episode/length": 288.0, "episode/score": 0.09708213719318337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09708213719318337}
{"step": 309992, "time": 9996.493613958359, "episode/length": 288.0, "episode/score": 0.10100887571957173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10100887571957173}
{"step": 310024, "time": 9997.482979536057, "episode/length": 288.0, "episode/score": 0.08871785593987624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08871785593987624}
{"step": 310024, "time": 9998.433511257172, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 310024, "time": 9999.830559015274, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 310024, "time": 10000.232106685638, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 310024, "time": 10001.415750741959, "eval_episode/length": 216.0, "eval_episode/score": 0.32499998807907104, "eval_episode/reward_rate": 0.004608294930875576}
{"step": 310024, "time": 10002.512201786041, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10002.518156290054, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10002.523795604706, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10002.529210329056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310352, "time": 10012.811044216156, "episode/length": 50.0, "episode/score": 0.8817985156395025, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.038048516454409764}
{"step": 310448, "time": 10015.753461837769, "episode/length": 256.0, "episode/score": 0.2970094561262613, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.09700945372810565}
{"step": 310944, "time": 10031.076585054398, "episode/length": 73.0, "episode/score": 0.8239650263992644, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.05209000337231373}
{"step": 311008, "time": 10033.064992904663, "episode/length": 163.0, "episode/score": 0.54300448242725, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.05237947406862986}
{"step": 311040, "time": 10034.056607246399, "episode/length": 288.0, "episode/score": 0.11662568733459011, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11662568733459011}
{"step": 311576, "time": 10050.773213148117, "episode/length": 288.0, "episode/score": 0.08644925506030177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08644925506030177}
{"step": 311776, "time": 10057.254323244095, "episode/length": 222.0, "episode/score": 0.40591754733225116, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.09966754370009312}
{"step": 312184, "time": 10069.552660942078, "episode/length": 288.0, "episode/score": 0.17416281853684268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17416281853684268}
{"step": 312336, "time": 10074.41843509674, "episode/length": 288.0, "episode/score": 0.11879951263756539, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11879951263756539}
{"step": 312640, "time": 10083.765603780746, "episode/length": 199.0, "episode/score": 0.45788176936855507, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.07975675977593255}
{"step": 312760, "time": 10087.319846391678, "episode/length": 288.0, "episode/score": 0.15842847212263678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15842847212263678}
{"step": 312944, "time": 10093.165843725204, "episode/length": 170.0, "episode/score": 0.5892117349774253, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.12046173730573173}
{"step": 313072, "time": 10097.106787204742, "episode/length": 257.0, "episode/score": 0.3646493507476407, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.16777434641699074}
{"step": 313208, "time": 10101.028615951538, "episode/length": 178.0, "episode/score": 0.5841460392414319, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.14039604753020285}
{"step": 313256, "time": 10102.508019924164, "episode/length": 288.0, "episode/score": 0.1813689323789731, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1813689323789731}
{"step": 313360, "time": 10105.88459444046, "episode/length": 51.0, "episode/score": 0.8893599497205287, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.04873496396976407}
{"step": 313400, "time": 10106.906578063965, "episode/length": 151.0, "episode/score": 0.6210377929589868, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.09291280650973022}
{"step": 313664, "time": 10115.259273529053, "episode/length": 50.0, "episode/score": 0.8952255993008293, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.051475570662660175}
{"step": 313888, "time": 10122.137066364288, "episode/length": 65.0, "episode/score": 0.8445972115123368, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.047722213142151304}
{"step": 313976, "time": 10124.620335817337, "episode/length": 166.0, "episode/score": 0.5985591515532178, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.11730916463829999}
{"step": 314648, "time": 10145.315064907074, "episode/length": 288.0, "episode/score": 0.1563233676068876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1563233676068876}
{"step": 314976, "time": 10155.593334674835, "episode/length": 40.0, "episode/score": 0.9288232723124565, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.05382324367428737}
{"step": 315072, "time": 10158.590419530869, "episode/length": 288.0, "episode/score": 0.12797000533578284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12797000533578284}
{"step": 315384, "time": 10167.947862625122, "episode/length": 288.0, "episode/score": 0.11268820093823706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11268820093823706}
{"step": 315520, "time": 10172.358871936798, "episode/length": 288.0, "episode/score": 0.1313521984129693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1313521984129693}
{"step": 315712, "time": 10178.365139484406, "episode/length": 288.0, "episode/score": 0.07423517566940063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07423517566940063}
{"step": 315760, "time": 10179.833062171936, "episode/length": 46.0, "episode/score": 0.8873262896124743, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.03107631445550396}
{"step": 315976, "time": 10186.245439052582, "episode/length": 288.0, "episode/score": 0.10012438547391866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10012438547391866}
{"step": 315984, "time": 10186.713678836823, "episode/length": 33.0, "episode/score": 0.9153898618294534, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.01851482163124274}
{"step": 316080, "time": 10189.64997267723, "episode/length": 39.0, "episode/score": 0.9102685167708842, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.03214348849360249}
{"step": 316200, "time": 10193.11330318451, "episode/length": 288.0, "episode/score": 0.1013044678516053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1013044678516053}
{"step": 316288, "time": 10196.095739126205, "episode/length": 288.0, "episode/score": 0.07007658196448574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07007658196448574}
{"step": 317288, "time": 10226.92069888115, "episode/length": 288.0, "episode/score": 0.041373143498731224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041373143498731224}
{"step": 317384, "time": 10229.849733114243, "episode/length": 288.0, "episode/score": 0.09560382456129446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09560382456129446}
{"step": 317513, "time": 10234.807362794876, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3126015207875312, "train/action_min": 0.0, "train/action_std": 1.6451843671463242, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.002219212776162292, "train/actor_opt_grad_steps": 18750.0, "train/actor_opt_loss": 9.682613712234712, "train/adv_mag": 0.016629836068081497, "train/adv_max": 0.016006069716496683, "train/adv_mean": 0.003370519357912, "train/adv_min": -0.006041630428640088, "train/adv_std": 0.0030631382856635032, "train/cont_avg": 0.996412727701005, "train/cont_loss_mean": 0.02379098361891568, "train/cont_loss_std": 0.32706417839730806, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.636255225943561, "train/cont_pos_acc": 0.9999999835263544, "train/cont_pos_loss": 0.003594327269908247, "train/cont_pred": 0.9964122152208683, "train/cont_rate": 0.996412727701005, "train/dyn_loss_mean": 1.0000027478040763, "train/dyn_loss_std": 8.790791163398842e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.4033034324608556, "train/extr_critic_critic_opt_grad_steps": 18750.0, "train/extr_critic_critic_opt_loss": 5336.087441909253, "train/extr_critic_mag": 0.3677919899398957, "train/extr_critic_max": 0.3677919899398957, "train/extr_critic_mean": 0.36440896733322337, "train/extr_critic_min": 0.3588212500864537, "train/extr_critic_std": 0.0016317685105751302, "train/extr_return_normed_mag": 0.024745146084071405, "train/extr_return_normed_max": 0.024635715999794965, "train/extr_return_normed_mean": 0.010427554305680868, "train/extr_return_normed_min": 0.0007364257196685178, "train/extr_return_normed_std": 0.0036277511881327436, "train/extr_return_rate": 6.543132669559151e-07, "train/extr_return_raw_mag": 0.38198763087167215, "train/extr_return_raw_max": 0.38198763087167215, "train/extr_return_raw_mean": 0.3677794883898155, "train/extr_return_raw_min": 0.3580883405915457, "train/extr_return_raw_std": 0.0036277511972002685, "train/extr_reward_mag": 0.012897003835170113, "train/extr_reward_max": 0.012897003835170113, "train/extr_reward_mean": 0.0015104055189967493, "train/extr_reward_min": 2.6565101278487164e-05, "train/extr_reward_std": 0.0022807627320804414, "train/image_loss_mean": 0.1735070288630586, "train/image_loss_std": 0.10636895880028231, "train/model_loss_mean": 0.8184771687541176, "train/model_loss_std": 0.38695958346577747, "train/model_opt_grad_norm": 32.14166286738232, "train/model_opt_grad_steps": 18731.05025125628, "train/model_opt_loss": 2325.3275416388583, "train/model_opt_model_opt_grad_overflow": 0.005025125628140704, "train/model_opt_model_opt_grad_scale": 2826.6331658291456, "train/policy_entropy_mag": 1.6619431032008263, "train/policy_entropy_max": 1.6619431032008263, "train/policy_entropy_mean": 0.5041392478511562, "train/policy_entropy_min": 0.06778548983623035, "train/policy_entropy_std": 0.35283462531003523, "train/policy_logprob_mag": 6.530113078841013, "train/policy_logprob_max": -0.009115934273667971, "train/policy_logprob_mean": -0.503672543183044, "train/policy_logprob_min": -6.530113078841013, "train/policy_logprob_std": 0.9406463674564457, "train/policy_randomness_mag": 0.8540698559439961, "train/policy_randomness_max": 0.8540698559439961, "train/policy_randomness_mean": 0.259076338317526, "train/policy_randomness_min": 0.03483485290078662, "train/policy_randomness_std": 0.18132113878750922, "train/post_ent_mag": 54.423732297504365, "train/post_ent_max": 54.423732297504365, "train/post_ent_mean": 53.82487606642833, "train/post_ent_min": 53.34079991632969, "train/post_ent_std": 0.1858633507286484, "train/prior_ent_mag": 56.26932157583572, "train/prior_ent_max": 56.26932157583572, "train/prior_ent_mean": 53.87669067766199, "train/prior_ent_min": 51.86291342883853, "train/prior_ent_std": 0.7867828907080032, "train/rep_loss_mean": 1.0000027478040763, "train/rep_loss_std": 8.790791163398842e-05, "train/reward_avg": 0.000620109973453107, "train/reward_loss_mean": 0.021177486142134248, "train/reward_loss_std": 0.07693272494902863, "train/reward_max_data": 0.130818885898489, "train/reward_max_pred": 0.007458527483532776, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.01930586320708445, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 6.404238215199223, "train/reward_pred": 0.0006073895688566505, "train/reward_rate": 0.0002944409547738693, "train_stats/mean_log_entropy": 0.5056363325946185, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025676462799310684, "report/cont_loss_std": 0.3615962862968445, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.799907207489014, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003032427979633212, "report/cont_pred": 0.9969721436500549, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1510043442249298, "report/image_loss_std": 0.11517486721277237, "report/model_loss_mean": 0.8073375225067139, "report/model_loss_std": 0.5997679829597473, "report/post_ent_mag": 49.99372100830078, "report/post_ent_max": 49.99372100830078, "report/post_ent_mean": 49.50605773925781, "report/post_ent_min": 49.131919860839844, "report/post_ent_std": 0.1562473326921463, "report/prior_ent_mag": 52.51909255981445, "report/prior_ent_max": 52.51909255981445, "report/prior_ent_mean": 50.635589599609375, "report/prior_ent_min": 48.679237365722656, "report/prior_ent_std": 0.6933826208114624, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0016995046753436327, "report/reward_loss_mean": 0.03065669909119606, "report/reward_loss_std": 0.25413820147514343, "report/reward_max_data": 0.9087499976158142, "report/reward_max_pred": 0.007974028587341309, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01948835514485836, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.7376813888549805, "report/reward_pred": 0.0005730912089347839, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.036998480558395386, "eval/cont_loss_std": 0.442428857088089, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.799907207489014, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0030324282124638557, "eval/cont_pred": 0.9969721436500549, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18492227792739868, "eval/image_loss_std": 0.11594178527593613, "eval/model_loss_mean": 0.8239410519599915, "eval/model_loss_std": 0.46040353178977966, "eval/post_ent_mag": 49.96647644042969, "eval/post_ent_max": 49.96647644042969, "eval/post_ent_mean": 49.481117248535156, "eval/post_ent_min": 49.15320587158203, "eval/post_ent_std": 0.13862751424312592, "eval/prior_ent_mag": 52.883792877197266, "eval/prior_ent_max": 52.883792877197266, "eval/prior_ent_mean": 50.703468322753906, "eval/prior_ent_min": 48.66382598876953, "eval/prior_ent_std": 0.7306517362594604, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0020202449522912502, "eval/reward_loss_std": 0.002488290425390005, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.005035400390625, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0020202449522912502, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00035456125624477863, "eval/reward_rate": 0.0, "replay/size": 317009.0, "replay/inserts": 31856.0, "replay/samples": 31856.0, "replay/insert_wait_avg": 1.1755601656850051e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.473108218819097e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 75040.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.763612054211046e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2850868701935, "timer/env.step_count": 3982.0, "timer/env.step_total": 33.90710496902466, "timer/env.step_frac": 0.03389744125359011, "timer/env.step_avg": 0.008515094166003179, "timer/env.step_min": 0.007135868072509766, "timer/env.step_max": 0.04703927040100098, "timer/replay._sample_count": 31856.0, "timer/replay._sample_total": 15.914307832717896, "timer/replay._sample_frac": 0.015909772165565723, "timer/replay._sample_avg": 0.0004995701856076687, "timer/replay._sample_min": 0.00039315223693847656, "timer/replay._sample_max": 0.04512953758239746, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4849.0, "timer/agent.policy_total": 40.85759210586548, "timer/agent.policy_frac": 0.040845947462543296, "timer/agent.policy_avg": 0.008425983111129198, "timer/agent.policy_min": 0.007402896881103516, "timer/agent.policy_max": 0.07893991470336914, "timer/dataset_train_count": 1991.0, "timer/dataset_train_total": 0.20660161972045898, "timer/dataset_train_frac": 0.00020654273709797854, "timer/dataset_train_avg": 0.00010376776480183776, "timer/dataset_train_min": 8.630752563476562e-05, "timer/dataset_train_max": 0.00026416778564453125, "timer/agent.train_count": 1991.0, "timer/agent.train_total": 878.7717123031616, "timer/agent.train_frac": 0.8785212574274832, "timer/agent.train_avg": 0.44137203028787625, "timer/agent.train_min": 0.4285118579864502, "timer/agent.train_max": 0.5960977077484131, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47824716567993164, "timer/agent.report_frac": 0.0004781108625505216, "timer/agent.report_avg": 0.23912358283996582, "timer/agent.report_min": 0.2311389446258545, "timer/agent.report_max": 0.24710822105407715, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.003217918682741e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 31.846366284076222}
{"step": 317832, "time": 10244.485307455063, "episode/length": 288.0, "episode/score": 0.0284731198623831, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0284731198623831}
{"step": 318288, "time": 10258.746508359909, "episode/length": 288.0, "episode/score": 0.08289758724708918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08289758724708918}
{"step": 318296, "time": 10258.780909538269, "episode/length": 288.0, "episode/score": 0.06714828044437127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06714828044437127}
{"step": 318392, "time": 10261.770683288574, "episode/length": 288.0, "episode/score": 0.0401709312169487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0401709312169487}
{"step": 318392, "time": 10261.776175498962, "episode/length": 69.0, "episode/score": 0.823007954068089, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.03863292282221664}
{"step": 318512, "time": 10265.810091257095, "episode/length": 288.0, "episode/score": 0.07465361138179105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07465361138179105}
{"step": 318600, "time": 10268.320809602737, "episode/length": 288.0, "episode/score": 0.08549069574951318, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08549069574951318}
{"step": 318664, "time": 10270.293803930283, "episode/length": 46.0, "episode/score": 0.8867394346417541, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.030489423221411016}
{"step": 318688, "time": 10271.272627830505, "episode/length": 36.0, "episode/score": 0.9215164268171065, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.03401644036785001}
{"step": 319224, "time": 10287.657654762268, "episode/length": 88.0, "episode/score": 0.7987717064062281, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0737716531695014}
{"step": 319336, "time": 10291.151417732239, "episode/length": 255.0, "episode/score": 0.2748905502841126, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.07176554830505211}
{"step": 319528, "time": 10297.746129274368, "episode/length": 104.0, "episode/score": 0.7299489349112491, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.05494892380522742}
{"step": 319664, "time": 10302.166043996811, "episode/length": 124.0, "episode/score": 0.6851915446801513, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.07269153357412961}
{"step": 319696, "time": 10303.15256690979, "episode/length": 288.0, "episode/score": 0.0347419265631288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0347419265631288}
{"step": 319768, "time": 10305.157486200333, "episode/length": 145.0, "episode/score": 0.5953796192977734, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.048504599972829965}
{"step": 320008, "time": 10313.238489627838, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 320008, "time": 10313.259269952774, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 320008, "time": 10313.609577178955, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 320008, "time": 10314.53374004364, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 320008, "time": 10314.601420164108, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 320008, "time": 10314.94671034813, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 320008, "time": 10316.12964105606, "eval_episode/length": 222.0, "eval_episode/score": 0.3062500059604645, "eval_episode/reward_rate": 0.004484304932735426}
{"step": 320008, "time": 10317.158140420914, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10317.164635181427, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10317.17034626007, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10317.175963163376, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320096, "time": 10320.123898506165, "episode/length": 70.0, "episode/score": 0.8320420150703285, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.05079198643215932}
{"step": 320336, "time": 10327.684933662415, "episode/length": 70.0, "episode/score": 0.8667653904662984, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.08551539090285587}
{"step": 320592, "time": 10335.601110935211, "episode/length": 111.0, "episode/score": 0.7556509633641326, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.10252596096597699}
{"step": 320608, "time": 10336.099290847778, "episode/length": 288.0, "episode/score": 0.15184436960043968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15184436960043968}
{"step": 320704, "time": 10339.040811777115, "episode/length": 288.0, "episode/score": 0.14857564881867802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14857564881867802}
{"step": 320752, "time": 10340.538758039474, "episode/length": 51.0, "episode/score": 0.8927505001762484, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.052125482702308545}
{"step": 321144, "time": 10352.320113897324, "episode/length": 66.0, "episode/score": 0.8438456987438485, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.05009570248660111}
{"step": 321240, "time": 10355.377717018127, "episode/length": 60.0, "episode/score": 0.8546774617735764, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.042177442448632974}
{"step": 321368, "time": 10359.327575445175, "episode/length": 82.0, "episode/score": 0.7844024389070228, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.04065246356378793}
{"step": 321536, "time": 10364.726037979126, "episode/length": 288.0, "episode/score": 0.07116359531630678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07116359531630678}
{"step": 321648, "time": 10368.191032409668, "episode/length": 288.0, "episode/score": 0.10435552364367595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10435552364367595}
{"step": 321808, "time": 10373.11372256279, "episode/length": 267.0, "episode/score": 0.2723666171916648, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.10674161795418513}
{"step": 321824, "time": 10373.61112689972, "episode/length": 72.0, "episode/score": 0.8308009453529621, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.05580097000972728}
{"step": 322304, "time": 10388.377391338348, "episode/length": 59.0, "episode/score": 0.844016894369588, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.028391859107387063}
{"step": 322408, "time": 10391.34620308876, "episode/length": 288.0, "episode/score": 0.05764131762873603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05764131762873603}
{"step": 322528, "time": 10395.244010925293, "episode/length": 123.0, "episode/score": 0.6682522335300973, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.05262723800626645}
{"step": 322904, "time": 10406.475286960602, "episode/length": 288.0, "episode/score": 0.04872633447098451, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04872633447098451}
{"step": 323144, "time": 10413.792023897171, "episode/length": 186.0, "episode/score": 0.47966410960134453, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.060914107203188905}
{"step": 323456, "time": 10423.653713703156, "episode/length": 288.0, "episode/score": 0.044967197837081585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044967197837081585}
{"step": 323496, "time": 10424.676245212555, "episode/length": 135.0, "episode/score": 0.6241885172706816, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.04606351770723904}
{"step": 323680, "time": 10430.514500617981, "episode/length": 288.0, "episode/score": 0.0719793583093633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0719793583093633}
{"step": 323736, "time": 10432.011556625366, "episode/length": 178.0, "episode/score": 0.4903640935879139, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.046614106009428724}
{"step": 324120, "time": 10443.802154064178, "episode/length": 288.0, "episode/score": 0.10375215193806753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10375215193806753}
{"step": 324776, "time": 10464.146003723145, "episode/length": 136.0, "episode/score": 0.6533103464864212, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.07831038672537716}
{"step": 324840, "time": 10466.114526748657, "episode/length": 288.0, "episode/score": 0.08397358996433013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08397358996433013}
{"step": 324968, "time": 10470.036909341812, "episode/length": 153.0, "episode/score": 0.5918132188082268, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0699381806472843}
{"step": 325216, "time": 10477.900520086288, "episode/length": 288.0, "episode/score": 0.10514741166804242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10514741166804242}
{"step": 325248, "time": 10478.900497198105, "episode/length": 50.0, "episode/score": 0.8776596278463558, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.033909631222400094}
{"step": 325256, "time": 10478.93258357048, "episode/length": 59.0, "episode/score": 0.8495197070537301, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.03389468174503918}
{"step": 325456, "time": 10485.285639286041, "episode/length": 288.0, "episode/score": 0.09667776982934129, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09667776982934129}
{"step": 325768, "time": 10494.64881181717, "episode/length": 288.0, "episode/score": 0.08803323433198784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08803323433198784}
{"step": 325808, "time": 10496.095670938492, "episode/length": 288.0, "episode/score": 0.07820413743257859, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07820413743257859}
{"step": 326208, "time": 10508.503705978394, "episode/length": 49.0, "episode/score": 0.8895735797713087, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.04269855353129515}
{"step": 326432, "time": 10515.397736310959, "episode/length": 288.0, "episode/score": 0.05212888089181433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05212888089181433}
{"step": 327224, "time": 10539.675664424896, "episode/length": 98.0, "episode/score": 0.7540683428088073, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.06031831078877303}
{"step": 327280, "time": 10541.624934911728, "episode/length": 288.0, "episode/score": 0.07212711928758608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07212711928758608}
{"step": 327528, "time": 10549.070207595825, "episode/length": 288.0, "episode/score": 0.09686477740683586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09686477740683586}
{"step": 327544, "time": 10549.569089651108, "episode/length": 166.0, "episode/score": 0.5475211947922958, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.06627121008926906}
{"step": 327560, "time": 10550.065904140472, "episode/length": 288.0, "episode/score": 0.07833896258108553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07833896258108553}
{"step": 327568, "time": 10550.542250871658, "episode/length": 288.0, "episode/score": 0.024213938913703714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024213938913703714}
{"step": 327736, "time": 10555.958817243576, "episode/length": 245.0, "episode/score": 0.2923584505127792, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.05798344335323691}
{"step": 327768, "time": 10556.937427043915, "episode/length": 288.0, "episode/score": 0.055227807070764356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055227807070764356}
{"step": 328024, "time": 10564.894021511078, "episode/length": 59.0, "episode/score": 0.8562066186678976, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.04058159242788406}
{"step": 328176, "time": 10569.838765382767, "episode/length": 76.0, "episode/score": 0.8025228824122337, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.040022875008219216}
{"step": 328384, "time": 10576.21461224556, "episode/length": 106.0, "episode/score": 0.7146898675734974, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.04593985417409385}
{"step": 328488, "time": 10579.193104505539, "episode/length": 93.0, "episode/score": 0.7424285925034724, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0330535969796415}
{"step": 328640, "time": 10584.074632167816, "episode/length": 76.0, "episode/score": 0.7852148556056591, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.022714870902632356}
{"step": 328792, "time": 10588.529334783554, "episode/length": 127.0, "episode/score": 0.6659340687678537, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.06280907328476815}
{"step": 329536, "time": 10611.70681476593, "episode/length": 288.0, "episode/score": 0.06015428148521096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06015428148521096}
{"step": 329592, "time": 10613.237685203552, "episode/length": 288.0, "episode/score": 0.08227072304902094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08227072304902094}
{"step": 329880, "time": 10622.119995594025, "episode/length": 288.0, "episode/score": 0.09090426860535672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09090426860535672}
{"step": 330096, "time": 10630.149377584457, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 330096, "time": 10630.201700687408, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 330096, "time": 10630.236966133118, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 330096, "time": 10631.327428102493, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 330096, "time": 10632.258214235306, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 330096, "time": 10633.66843533516, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10633.675803661346, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10633.681314945221, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10633.68665933609, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10633.692412614822, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330160, "time": 10635.663543701172, "episode/length": 170.0, "episode/score": 0.5808980444875829, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.11214803281694685}
{"step": 330488, "time": 10645.555138349533, "episode/length": 288.0, "episode/score": 0.07787917305898873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07787917305898873}
{"step": 330696, "time": 10652.004864692688, "episode/length": 288.0, "episode/score": 0.0827251804675484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0827251804675484}
{"step": 330800, "time": 10655.501373529434, "episode/length": 288.0, "episode/score": 0.060559475296429355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060559475296429355}
{"step": 330952, "time": 10659.981139659882, "episode/length": 288.0, "episode/score": 0.07923750163269005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07923750163269005}
{"step": 331200, "time": 10667.842640399933, "episode/length": 164.0, "episode/score": 0.553211780612628, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0657117751527494}
{"step": 331296, "time": 10670.801781654358, "episode/length": 42.0, "episode/score": 0.8968088280913094, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.028058828591895235}
{"step": 331712, "time": 10683.645340442657, "episode/length": 51.0, "episode/score": 0.8604583678574613, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.01983335038352152}
{"step": 331760, "time": 10685.230417490005, "episode/length": 119.0, "episode/score": 0.6648063256067189, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.03668133181747635}
{"step": 331848, "time": 10687.743740797043, "episode/length": 288.0, "episode/score": 0.09356804516750117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09356804516750117}
{"step": 331904, "time": 10689.696044921875, "episode/length": 87.0, "episode/score": 0.7674833049061363, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0393582993531254}
{"step": 331904, "time": 10689.70316028595, "episode/length": 288.0, "episode/score": 0.08540860798342464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08540860798342464}
{"step": 332088, "time": 10695.153863430023, "episode/length": 29.0, "episode/score": 0.9298037212217309, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.020428695913039974}
{"step": 332408, "time": 10705.043125629425, "episode/length": 80.0, "episode/score": 0.797702108676674, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.04770210049849766}
{"step": 332424, "time": 10705.541895151138, "episode/length": 64.0, "episode/score": 0.8256218422772577, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.025621833732373034}
{"step": 332472, "time": 10707.043131351471, "episode/length": 288.0, "episode/score": 0.05532290614695512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05532290614695512}
{"step": 332800, "time": 10717.469338178635, "episode/length": 288.0, "episode/score": 0.07585897000581099, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07585897000581099}
{"step": 332936, "time": 10721.482295751572, "episode/length": 105.0, "episode/score": 0.7205520432925141, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0486770179721816}
{"step": 333008, "time": 10723.946262598038, "episode/length": 288.0, "episode/score": 0.05860546647159026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05860546647159026}
{"step": 333152, "time": 10728.423722982407, "episode/length": 43.0, "episode/score": 0.8877458616863692, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.022120841220555576}
{"step": 333232, "time": 10730.910005807877, "episode/length": 100.0, "episode/score": 0.7191001180970602, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.031600109918883845}
{"step": 334024, "time": 10755.342576265335, "episode/length": 288.0, "episode/score": 0.04567967283816188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04567967283816188}
{"step": 334216, "time": 10761.289796352386, "episode/length": 288.0, "episode/score": 0.07253967625337054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07253967625337054}
{"step": 334536, "time": 10771.209109067917, "episode/length": 63.0, "episode/score": 0.8480904650897969, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.04496545937962537}
{"step": 334720, "time": 10777.222567558289, "episode/length": 288.0, "episode/score": 0.050638816414220855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050638816414220855}
{"step": 334784, "time": 10779.195196390152, "episode/length": 288.0, "episode/score": 0.05071616766014131, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05071616766014131}
{"step": 334872, "time": 10781.713788986206, "episode/length": 214.0, "episode/score": 0.4118026795118226, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.08055266780917236}
{"step": 335064, "time": 10787.659125328064, "episode/length": 34.0, "episode/score": 0.915172457018457, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.021422415702659237}
{"step": 335160, "time": 10790.637000799179, "episode/length": 77.0, "episode/score": 0.7896628175731166, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.03028781609464204}
{"step": 335248, "time": 10793.573457717896, "episode/length": 288.0, "episode/score": 0.08774207692277969, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08774207692277969}
{"step": 335320, "time": 10795.597754240036, "episode/length": 288.0, "episode/score": 0.07455684428111908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07455684428111908}
{"step": 335464, "time": 10800.018447637558, "episode/length": 73.0, "episode/score": 0.8039390470374315, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.032064047351752833}
{"step": 335544, "time": 10802.495114803314, "episode/length": 288.0, "episode/score": 0.11144450501714687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11144450501714687}
{"step": 335856, "time": 10812.450970888138, "episode/length": 86.0, "episode/score": 0.7735708928419456, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.04232090498115326}
{"step": 335968, "time": 10816.398178577423, "episode/length": 52.0, "episode/score": 0.8550708866385435, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.017570923649884662}
{"step": 336232, "time": 10824.321783542633, "episode/length": 46.0, "episode/score": 0.8747144307203882, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.018464455810800473}
{"step": 336528, "time": 10833.725196361542, "episode/length": 288.0, "episode/score": 0.08907546407675682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08907546407675682}
{"step": 336560, "time": 10834.716516494751, "episode/length": 73.0, "episode/score": 0.8191975851612767, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.047322563647725246}
{"step": 337032, "time": 10849.142076730728, "episode/length": 288.0, "episode/score": 0.08145954501264896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08145954501264896}
{"step": 337160, "time": 10853.08815574646, "episode/length": 74.0, "episode/score": 0.8378525855732732, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0691025752821588}
{"step": 337376, "time": 10859.9792907238, "episode/length": 288.0, "episode/score": 0.08149627236812762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08149627236812762}
{"step": 337512, "time": 10863.98688030243, "episode/length": 122.0, "episode/score": 0.6920506058304454, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.07330063130211784}
{"step": 337560, "time": 10865.569132566452, "episode/length": 288.0, "episode/score": 0.07640683626456735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07640683626456735}
{"step": 337584, "time": 10866.530212640762, "episode/length": 25.0, "episode/score": 0.9460634149372709, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.024188386299101694}
{"step": 337632, "time": 10868.011351823807, "episode/length": 288.0, "episode/score": 0.09413865879048444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09413865879048444}
{"step": 337704, "time": 10870.013937473297, "episode/length": 67.0, "episode/score": 0.8318816212286038, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.041256645885368926}
{"step": 337776, "time": 10872.475581884384, "episode/length": 288.0, "episode/score": 0.06251282336791064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06251282336791064}
{"step": 337816, "time": 10873.489508152008, "episode/length": 197.0, "episode/score": 0.5092785104390032, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.12490350610835321}
{"step": 338144, "time": 10883.84279370308, "episode/length": 78.0, "episode/score": 0.805750803560386, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.04950078134834257}
{"step": 338272, "time": 10887.80738568306, "episode/length": 85.0, "episode/score": 0.7925782577485734, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.05820322911040421}
{"step": 338312, "time": 10888.81664943695, "episode/length": 93.0, "episode/score": 0.7496021581127934, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.04022713590075}
{"step": 338352, "time": 10890.2884786129, "episode/length": 164.0, "episode/score": 0.5823101732089526, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.09481017421012439}
{"step": 338696, "time": 10900.746455430984, "episode/length": 132.0, "episode/score": 0.6479345841426039, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.06043459162810905}
{"step": 339016, "time": 10910.613592386246, "episode/length": 108.0, "episode/score": 0.715168877630731, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.05266883743252038}
{"step": 339096, "time": 10913.07777094841, "episode/length": 102.0, "episode/score": 0.7376691016056611, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.05641912626242629}
{"step": 339112, "time": 10913.577028036118, "episode/length": 51.0, "episode/score": 0.874027322228585, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.03340231482457057}
{"step": 339312, "time": 10919.972836017609, "episode/length": 119.0, "episode/score": 0.6784319739551847, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.05030696247081323}
{"step": 339352, "time": 10920.990027666092, "episode/length": 129.0, "episode/score": 0.6797975911035792, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.08292257999755748}
{"step": 340016, "time": 10941.816496133804, "episode/length": 288.0, "episode/score": 0.06669867139430607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06669867139430607}
{"step": 340080, "time": 10944.55412864685, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 340080, "time": 10945.669666528702, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 340080, "time": 10945.70652627945, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 340080, "time": 10948.899554014206, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10948.905979156494, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10948.911447048187, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10948.916913032532, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10948.922328948975, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10948.927760362625, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340088, "time": 10948.959548473358, "episode/length": 288.0, "episode/score": 0.09240522653476546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09240522653476546}
{"step": 340128, "time": 10950.432268857956, "episode/length": 288.0, "episode/score": 0.08907515271789634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08907515271789634}
{"step": 340272, "time": 10954.91483426094, "episode/length": 156.0, "episode/score": 0.6125158820711931, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.10001589562193658}
{"step": 340944, "time": 10975.74812412262, "episode/length": 115.0, "episode/score": 0.6990567388761519, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.058431741204458376}
{"step": 341168, "time": 10982.645763874054, "episode/length": 256.0, "episode/score": 0.3207146090794595, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.12071460772904175}
{"step": 341408, "time": 10990.137053489685, "episode/length": 288.0, "episode/score": 0.08121521295652201, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08121521295652201}
{"step": 341552, "time": 10994.586699724197, "episode/length": 47.0, "episode/score": 0.8853807269288154, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.032255752400487836}
{"step": 341624, "time": 10996.582142591476, "episode/length": 288.0, "episode/score": 0.09959362138351935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09959362138351935}
{"step": 341632, "time": 10997.054259300232, "episode/length": 27.0, "episode/score": 0.9436588303378812, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.028033856508045574}
{"step": 341648, "time": 10997.553597927094, "episode/length": 171.0, "episode/score": 0.557447417833373, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0918224313841165}
{"step": 341664, "time": 10998.05520248413, "episode/length": 288.0, "episode/score": 0.0518914296510502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0518914296510502}
{"step": 342016, "time": 11008.911360025406, "episode/length": 57.0, "episode/score": 0.8595856284368892, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.03771062364057798}
{"step": 342168, "time": 11013.375113010406, "episode/length": 67.0, "episode/score": 0.8183252840235582, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.02770032078751683}
{"step": 342336, "time": 11018.863900661469, "episode/length": 85.0, "episode/score": 0.7785406657530984, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.04416564939674572}
{"step": 342400, "time": 11020.864459991455, "episode/length": 288.0, "episode/score": 0.05144060912925852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05144060912925852}
{"step": 342440, "time": 11021.876490831375, "episode/length": 288.0, "episode/score": 0.08160339566211405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08160339566211405}
{"step": 342512, "time": 11024.333988904953, "episode/length": 109.0, "episode/score": 0.6922422186585209, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.03286720755249917}
{"step": 342968, "time": 11038.192412137985, "episode/length": 99.0, "episode/score": 0.7691664717308413, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.07854146143972685}
{"step": 343008, "time": 11039.661562681198, "episode/length": 83.0, "episode/score": 0.7994787674574582, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.05885371497743108}
{"step": 343256, "time": 11047.210895299911, "episode/length": 288.0, "episode/score": 0.04565498514830324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04565498514830324}
{"step": 343288, "time": 11048.194542169571, "episode/length": 39.0, "episode/score": 0.9158557120608748, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.03773071306204656}
{"step": 343784, "time": 11063.64908504486, "episode/length": 65.0, "episode/score": 0.8360909378720862, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.03921593868699347}
{"step": 343976, "time": 11069.557482481003, "episode/length": 288.0, "episode/score": 0.16372425996610218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16372425996610218}
{"step": 344144, "time": 11075.514128446579, "episode/length": 141.0, "episode/score": 0.6704216922801152, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.11104670652935056}
{"step": 344328, "time": 11080.939293384552, "episode/length": 288.0, "episode/score": 0.06812697518284949, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06812697518284949}
{"step": 344504, "time": 11086.337584495544, "episode/length": 65.0, "episode/score": 0.8565436216063063, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0596686239346127}
{"step": 344712, "time": 11092.70898604393, "episode/length": 288.0, "episode/score": 0.06466090582603101, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06466090582603101}
{"step": 344752, "time": 11094.166705846786, "episode/length": 288.0, "episode/score": 0.09299548503145161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09299548503145161}
{"step": 344824, "time": 11096.153861522675, "episode/length": 288.0, "episode/score": 0.11226632488092037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11226632488092037}
{"step": 344984, "time": 11101.059880495071, "episode/length": 81.0, "episode/score": 0.83410892795564, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.08723394150638342}
{"step": 345600, "time": 11120.336854219437, "episode/length": 288.0, "episode/score": 0.0943095518643986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0943095518643986}
{"step": 346096, "time": 11135.815603494644, "episode/length": 288.0, "episode/score": 0.10761004982032318, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10761004982032318}
{"step": 346456, "time": 11146.731075048447, "episode/length": 288.0, "episode/score": 0.08961552857272181, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08961552857272181}
{"step": 346600, "time": 11151.153601169586, "episode/length": 235.0, "episode/score": 0.352649535360797, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.08702453699061152}
{"step": 346816, "time": 11158.00348997116, "episode/length": 288.0, "episode/score": 0.08349481231698519, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08349481231698519}
{"step": 347064, "time": 11165.49665760994, "episode/length": 288.0, "episode/score": 0.09565314892188326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09565314892188326}
{"step": 347136, "time": 11167.933624505997, "episode/length": 288.0, "episode/score": 0.10316135556149675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10316135556149675}
{"step": 347296, "time": 11172.910403966904, "episode/length": 288.0, "episode/score": 0.09818010664912435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09818010664912435}
{"step": 347608, "time": 11182.356224298477, "episode/length": 125.0, "episode/score": 0.6836002982122409, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.07422530054054732}
{"step": 347656, "time": 11183.842057943344, "episode/length": 73.0, "episode/score": 0.8229293893377871, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.05105436782423567}
{"step": 347768, "time": 11187.263527154922, "episode/length": 78.0, "episode/score": 0.8000004076279765, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.043750385415933124}
{"step": 347856, "time": 11190.186372756958, "episode/length": 129.0, "episode/score": 0.6670149916299124, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.07013999263108417}
{"step": 347912, "time": 11191.681984901428, "episode/length": 288.0, "episode/score": 0.10622053676115684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10622053676115684}
{"step": 348368, "time": 11207.108220338821, "episode/length": 74.0, "episode/score": 0.8229178987548948, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.054167858195796725}
{"step": 348408, "time": 11208.121331214905, "episode/length": 288.0, "episode/score": 0.07946854703845929, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07946854703845929}
{"step": 348552, "time": 11212.546464920044, "episode/length": 117.0, "episode/score": 0.6924254897667197, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.05805051523839211}
{"step": 348592, "time": 11214.012423753738, "episode/length": 116.0, "episode/score": 0.6964482075097749, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.05894820307435111}
{"step": 348648, "time": 11215.518344640732, "episode/length": 91.0, "episode/score": 0.7621056697457789, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.046480653028538654}
{"step": 348768, "time": 11219.425476312637, "episode/length": 288.0, "episode/score": 0.085357998348627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.085357998348627}
{"step": 348816, "time": 11220.90402007103, "episode/length": 119.0, "episode/score": 0.680419458024744, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.052294446918722315}
{"step": 349184, "time": 11232.317569255829, "episode/length": 51.0, "episode/score": 0.872791821976989, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.03216683471282522}
{"step": 349192, "time": 11232.349927425385, "episode/length": 67.0, "episode/score": 0.8223944203475639, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.03176942987033726}
{"step": 349241, "time": 11234.829295873642, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.407828939619975, "train/action_min": 0.0, "train/action_std": 1.8320796921025568, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0023483562814984376, "train/actor_opt_grad_steps": 20740.0, "train/actor_opt_loss": 9.692308318478304, "train/adv_mag": 0.021921458256304562, "train/adv_max": 0.021243396266620963, "train/adv_mean": 0.0047488879708862215, "train/adv_min": -0.009648560129817407, "train/adv_std": 0.004256364358261452, "train/cont_avg": 0.9963783762562815, "train/cont_loss_mean": 0.023998384738350333, "train/cont_loss_std": 0.3257888701747636, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.613443357603891, "train/cont_pos_acc": 0.9999999874201252, "train/cont_pos_loss": 0.0036834534047049793, "train/cont_pred": 0.9963234117881736, "train/cont_rate": 0.9963783762562815, "train/dyn_loss_mean": 1.0000106042353951, "train/dyn_loss_std": 0.0003180932355243198, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.39257605058894535, "train/extr_critic_critic_opt_grad_steps": 20740.0, "train/extr_critic_critic_opt_loss": 11575.172247958542, "train/extr_critic_mag": 0.49277591285993105, "train/extr_critic_max": 0.49277591285993105, "train/extr_critic_mean": 0.4857224032806991, "train/extr_critic_min": 0.4751492654857923, "train/extr_critic_std": 0.0031284005258316594, "train/extr_return_normed_mag": 0.03685129841967444, "train/extr_return_normed_max": 0.0367954028910728, "train/extr_return_normed_mean": 0.01688914190590687, "train/extr_return_normed_min": 0.00203292932941686, "train/extr_return_normed_std": 0.005327527635337682, "train/extr_return_rate": 0.3905644796135465, "train/extr_return_raw_mag": 0.510377537066014, "train/extr_return_raw_max": 0.510377537066014, "train/extr_return_raw_mean": 0.49047129911993015, "train/extr_return_raw_min": 0.47561506350435806, "train/extr_return_raw_std": 0.005327527641187698, "train/extr_reward_mag": 0.017417476404851407, "train/extr_reward_max": 0.017417476404851407, "train/extr_reward_mean": 0.0020273440934591297, "train/extr_reward_min": 2.1170731165900302e-05, "train/extr_reward_std": 0.0035124985467825066, "train/image_loss_mean": 0.15436561851195954, "train/image_loss_std": 0.1085539696429243, "train/model_loss_mean": 0.8005957342871469, "train/model_loss_std": 0.40520668022297135, "train/model_opt_grad_norm": 30.72783242331611, "train/model_opt_grad_steps": 20719.21608040201, "train/model_opt_loss": 2252.7926736956265, "train/model_opt_model_opt_grad_overflow": 0.005025125628140704, "train/model_opt_model_opt_grad_scale": 2801.5075376884424, "train/policy_entropy_mag": 1.6405451315731259, "train/policy_entropy_max": 1.6405451315731259, "train/policy_entropy_mean": 0.3410606604425152, "train/policy_entropy_min": 0.06489385709391167, "train/policy_entropy_std": 0.3194161932073047, "train/policy_logprob_mag": 6.549772842445565, "train/policy_logprob_max": -0.008640350418249567, "train/policy_logprob_mean": -0.34108680029909816, "train/policy_logprob_min": -6.549772842445565, "train/policy_logprob_std": 0.8453529426200905, "train/policy_randomness_mag": 0.8430734720062371, "train/policy_randomness_max": 0.8430734720062371, "train/policy_randomness_mean": 0.17527051887769796, "train/policy_randomness_min": 0.033348847517565866, "train/policy_randomness_std": 0.16414746159135396, "train/post_ent_mag": 47.55439610696917, "train/post_ent_max": 47.55439610696917, "train/post_ent_mean": 47.076247593865325, "train/post_ent_min": 46.7297045453709, "train/post_ent_std": 0.14514311841085328, "train/prior_ent_mag": 49.34189061303834, "train/prior_ent_max": 49.34189061303834, "train/prior_ent_mean": 47.20354845056582, "train/prior_ent_min": 45.42346902588504, "train/prior_ent_std": 0.7026387312304434, "train/rep_loss_mean": 1.0000106042353951, "train/rep_loss_std": 0.0003180932355243198, "train/reward_avg": 0.0007548719042287344, "train/reward_loss_mean": 0.022225349734364144, "train/reward_loss_std": 0.09649521783555871, "train/reward_max_data": 0.2293730943917704, "train/reward_max_pred": 0.012228115120125775, "train/reward_neg_acc": 0.9999999997004791, "train/reward_neg_loss": 0.019296684583190397, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.781528667970137, "train/reward_pred": 0.0007334506547490332, "train/reward_rate": 0.0005054569723618091, "train_stats/mean_log_entropy": 0.2929418676317075, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020093170925974846, "report/cont_loss_std": 0.3029601275920868, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.609139919281006, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003670893609523773, "report/cont_pred": 0.9963359832763672, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.16397513449192047, "report/image_loss_std": 0.12651880085468292, "report/model_loss_mean": 0.8043377995491028, "report/model_loss_std": 0.32734230160713196, "report/post_ent_mag": 45.691749572753906, "report/post_ent_max": 45.691749572753906, "report/post_ent_mean": 45.217369079589844, "report/post_ent_min": 44.874000549316406, "report/post_ent_std": 0.13882869482040405, "report/prior_ent_mag": 46.868446350097656, "report/prior_ent_max": 46.868446350097656, "report/prior_ent_mean": 45.275291442871094, "report/prior_ent_min": 44.04913330078125, "report/prior_ent_std": 0.5476186275482178, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0005139558925293386, "report/reward_loss_mean": 0.020269466564059258, "report/reward_loss_std": 0.029167456552386284, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.0138930082321167, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.020269468426704407, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0006880098953843117, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014619052410125732, "eval/cont_loss_std": 0.24748705327510834, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.609139919281006, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0036708659026771784, "eval/cont_pred": 0.9963359832763672, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18084216117858887, "eval/image_loss_std": 0.11730761080980301, "eval/model_loss_mean": 0.8077483177185059, "eval/model_loss_std": 0.543472409248352, "eval/post_ent_mag": 45.66267395019531, "eval/post_ent_max": 45.66267395019531, "eval/post_ent_mean": 45.16963577270508, "eval/post_ent_min": 44.85962677001953, "eval/post_ent_std": 0.12681476771831512, "eval/prior_ent_mag": 46.84958267211914, "eval/prior_ent_max": 46.84958267211914, "eval/prior_ent_mean": 45.18584442138672, "eval/prior_ent_min": 43.89466094970703, "eval/prior_ent_std": 0.5029585957527161, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0001983642578125, "eval/reward_loss_mean": 0.012287115678191185, "eval/reward_loss_std": 0.31037425994873047, "eval/reward_max_data": 0.203125, "eval/reward_max_pred": 0.00909566879272461, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0025836920831352472, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 9.938888549804688, "eval/reward_pred": 0.00044136017095297575, "eval/reward_rate": 0.0009765625, "replay/size": 348737.0, "replay/inserts": 31728.0, "replay/samples": 31728.0, "replay/insert_wait_avg": 1.1710975125649934e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.413910064081681e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 81976.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.885296277108901e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0380575656891, "timer/env.step_count": 3966.0, "timer/env.step_total": 33.7779426574707, "timer/env.step_frac": 0.033776657200120554, "timer/env.step_avg": 0.008516879137032451, "timer/env.step_min": 0.007126808166503906, "timer/env.step_max": 0.04028058052062988, "timer/replay._sample_count": 31728.0, "timer/replay._sample_total": 15.791411638259888, "timer/replay._sample_frac": 0.01579081067844521, "timer/replay._sample_avg": 0.0004977121671161084, "timer/replay._sample_min": 0.0003871917724609375, "timer/replay._sample_max": 0.011018991470336914, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4833.0, "timer/agent.policy_total": 40.73427629470825, "timer/agent.policy_frac": 0.040732726106308764, "timer/agent.policy_avg": 0.008428362568737482, "timer/agent.policy_min": 0.007385969161987305, "timer/agent.policy_max": 0.07890152931213379, "timer/dataset_train_count": 1983.0, "timer/dataset_train_total": 0.20532631874084473, "timer/dataset_train_frac": 0.00020531850481836041, "timer/dataset_train_avg": 0.00010354327722685059, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.0006058216094970703, "timer/agent.train_count": 1983.0, "timer/agent.train_total": 878.6523134708405, "timer/agent.train_frac": 0.8786188753752752, "timer/agent.train_avg": 0.4430924424966417, "timer/agent.train_min": 0.4313797950744629, "timer/agent.train_max": 1.534656286239624, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47127699851989746, "timer/agent.report_frac": 0.00047125906354712993, "timer/agent.report_avg": 0.23563849925994873, "timer/agent.report_min": 0.2236800193786621, "timer/agent.report_max": 0.24759697914123535, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.409255933170716e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 31.726255583313975}
{"step": 349344, "time": 11237.989870548248, "episode/length": 98.0, "episode/score": 0.7789687653817055, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.08521872518349483}
{"step": 349608, "time": 11245.898020505905, "episode/length": 288.0, "episode/score": 0.07771756092984106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07771756092984106}
{"step": 349824, "time": 11252.78731226921, "episode/length": 125.0, "episode/score": 0.6628434711567479, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.05346845183180449}
{"step": 350064, "time": 11260.805918693542, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 350064, "time": 11261.281640529633, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 350064, "time": 11261.5774538517, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 350064, "time": 11261.765473604202, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 350064, "time": 11262.182085990906, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 350064, "time": 11262.36955666542, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 350064, "time": 11262.634278774261, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 350064, "time": 11262.940028905869, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 350072, "time": 11262.970165014267, "episode/length": 90.0, "episode/score": 0.7752949090515813, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.05654488972663785}
{"step": 350632, "time": 11280.156995296478, "episode/length": 127.0, "episode/score": 0.665298147564954, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.06217317222171914}
{"step": 350680, "time": 11281.64908003807, "episode/length": 288.0, "episode/score": 0.030112757817732927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030112757817732927}
{"step": 350720, "time": 11283.116801738739, "episode/length": 288.0, "episode/score": 0.09208422264396177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09208422264396177}
{"step": 350904, "time": 11288.669989824295, "episode/length": 288.0, "episode/score": 0.06570396212509877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06570396212509877}
{"step": 351136, "time": 11296.024511814117, "episode/length": 51.0, "episode/score": 0.8694981723474484, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.028873155630208203}
{"step": 351152, "time": 11296.543071746826, "episode/length": 134.0, "episode/score": 0.6532935593568254, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0720435187977273}
{"step": 351248, "time": 11299.492202997208, "episode/length": 42.0, "episode/score": 0.881259206607865, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.012509214093370247}
{"step": 351344, "time": 11302.45339512825, "episode/length": 82.0, "episode/score": 0.7775486288662705, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.033798633383185006}
{"step": 351496, "time": 11306.901072740555, "episode/length": 288.0, "episode/score": 0.08993354677204479, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08993354677204479}
{"step": 351504, "time": 11307.37586736679, "episode/length": 288.0, "episode/score": 0.09452187382703414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09452187382703414}
{"step": 351688, "time": 11312.804026603699, "episode/length": 54.0, "episode/score": 0.8761016716071026, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0448516620144801}
{"step": 352048, "time": 11324.187532186508, "episode/length": 68.0, "episode/score": 0.8378392606430225, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.050339239129471025}
{"step": 352136, "time": 11326.687126159668, "episode/length": 288.0, "episode/score": 0.05967644294275942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05967644294275942}
{"step": 352216, "time": 11329.141397714615, "episode/length": 108.0, "episode/score": 0.7221998991656164, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.059699876138665786}
{"step": 352240, "time": 11330.09962272644, "episode/length": 135.0, "episode/score": 0.6436194425868962, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.06549441394872701}
{"step": 352632, "time": 11342.426331281662, "episode/length": 51.0, "episode/score": 0.8588471281923375, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.01822212579418192}
{"step": 352928, "time": 11351.934997320175, "episode/length": 85.0, "episode/score": 0.7996385101587293, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.06526352308083005}
{"step": 352944, "time": 11352.431615114212, "episode/length": 288.0, "episode/score": 0.05358972813860419, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05358972813860419}
{"step": 353448, "time": 11367.671210765839, "episode/length": 288.0, "episode/score": 0.08862205524883393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08862205524883393}
{"step": 353656, "time": 11374.036610841751, "episode/length": 200.0, "episode/score": 0.45978919340018365, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.08478920684615332}
{"step": 353664, "time": 11374.504521846771, "episode/length": 190.0, "episode/score": 0.48043514269829757, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.07418514432811207}
{"step": 353664, "time": 11374.51025223732, "episode/length": 128.0, "episode/score": 0.6603587751046689, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.06035873490645827}
{"step": 353776, "time": 11378.050831079483, "episode/length": 103.0, "episode/score": 0.7229585701611541, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.04483353200021156}
{"step": 353800, "time": 11378.57389140129, "episode/length": 43.0, "episode/score": 0.8937460382810514, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.028120991097921433}
{"step": 353816, "time": 11379.072171926498, "episode/length": 288.0, "episode/score": 0.0632167535870849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0632167535870849}
{"step": 354000, "time": 11384.93501996994, "episode/length": 288.0, "episode/score": 0.06248372713525896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06248372713525896}
{"step": 354008, "time": 11384.967047214508, "episode/length": 134.0, "episode/score": 0.6611133184510436, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.07986330815992915}
{"step": 354024, "time": 11385.458913564682, "episode/length": 45.0, "episode/score": 0.8770069652573511, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.017631941916079086}
{"step": 354608, "time": 11403.613672018051, "episode/length": 98.0, "episode/score": 0.7369298035951033, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.043179751115076215}
{"step": 354968, "time": 11414.565246582031, "episode/length": 119.0, "episode/score": 0.68765231965358, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.05952732065475175}
{"step": 355040, "time": 11417.016990661621, "episode/length": 154.0, "episode/score": 0.5556652733175724, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.036915262211550726}
{"step": 355280, "time": 11424.400688171387, "episode/length": 83.0, "episode/score": 0.7848137207133732, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.04418867353024325}
{"step": 355976, "time": 11445.721618413925, "episode/length": 288.0, "episode/score": 0.045883511607712535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045883511607712535}
{"step": 355976, "time": 11445.73000240326, "episode/length": 288.0, "episode/score": 0.07255130635837759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07255130635837759}
{"step": 356024, "time": 11447.20819735527, "episode/length": 92.0, "episode/score": 0.7477878791513604, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.03528788960545626}
{"step": 356088, "time": 11449.185070514679, "episode/length": 288.0, "episode/score": 0.03519376922349693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03519376922349693}
{"step": 356312, "time": 11456.088818073273, "episode/length": 288.0, "episode/score": 0.09472315652772068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09472315652772068}
{"step": 356320, "time": 11456.5582883358, "episode/length": 42.0, "episode/score": 0.8966460206734155, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.02789601587710422}
{"step": 356336, "time": 11457.054707050323, "episode/length": 288.0, "episode/score": 0.05239281539593321, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05239281539593321}
{"step": 356584, "time": 11464.5223903656, "episode/length": 69.0, "episode/score": 0.8253463903351985, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.04097136409518498}
{"step": 356992, "time": 11477.571165561676, "episode/length": 112.0, "episode/score": 0.6894718504107686, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.03947186607445019}
{"step": 357280, "time": 11486.439079284668, "episode/length": 288.0, "episode/score": 0.075535004693279, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.075535004693279}
{"step": 357352, "time": 11488.427171707153, "episode/length": 288.0, "episode/score": 0.05979279798236803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05979279798236803}
{"step": 357392, "time": 11489.89818930626, "episode/length": 134.0, "episode/score": 0.6185726691205673, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.03732265004009605}
{"step": 358088, "time": 11511.174515724182, "episode/length": 136.0, "episode/score": 0.6351966141271532, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.060196654366109215}
{"step": 358288, "time": 11517.539794683456, "episode/length": 288.0, "episode/score": 0.04999617162047798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04999617162047798}
{"step": 358464, "time": 11522.952360630035, "episode/length": 138.0, "episode/score": 0.6314473462887236, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.06269731528732336}
{"step": 358632, "time": 11528.019155025482, "episode/length": 288.0, "episode/score": 0.03519273549079571, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03519273549079571}
{"step": 358648, "time": 11528.518607854843, "episode/length": 288.0, "episode/score": 0.10406095722692044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10406095722692044}
{"step": 358896, "time": 11536.37126994133, "episode/length": 288.0, "episode/score": 0.03963621754564883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03963621754564883}
{"step": 359592, "time": 11557.690234661102, "episode/length": 288.0, "episode/score": 0.04689397324790434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04689397324790434}
{"step": 359592, "time": 11557.696494579315, "episode/length": 187.0, "episode/score": 0.4705342287870735, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0549092292876594}
{"step": 359664, "time": 11560.147230386734, "episode/length": 126.0, "episode/score": 0.6358443381928396, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.029594368245454916}
{"step": 359704, "time": 11561.161449193954, "episode/length": 288.0, "episode/score": 0.03709051051322376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03709051051322376}
{"step": 360048, "time": 11576.44417476654, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11576.451586008072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11576.457222938538, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11576.462788820267, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11576.472303390503, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11576.47760796547, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11576.482667207718, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11576.488035202026, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360600, "time": 11593.820877552032, "episode/length": 288.0, "episode/score": 0.04407289574362494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04407289574362494}
{"step": 360776, "time": 11599.225055456161, "episode/length": 288.0, "episode/score": 0.10342157290006071, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10342157290006071}
{"step": 360944, "time": 11604.597312688828, "episode/length": 288.0, "episode/score": 0.08153256267178222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08153256267178222}
{"step": 361208, "time": 11612.470155477524, "episode/length": 288.0, "episode/score": 0.07931693924643923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07931693924643923}
{"step": 361904, "time": 11634.121326446533, "episode/length": 288.0, "episode/score": 0.12944840530673218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12944840530673218}
{"step": 361904, "time": 11634.128472566605, "episode/length": 288.0, "episode/score": 0.0866182389930259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0866182389930259}
{"step": 361976, "time": 11636.114580154419, "episode/length": 288.0, "episode/score": 0.10519191237068526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10519191237068526}
{"step": 362016, "time": 11637.560485363007, "episode/length": 288.0, "episode/score": 0.09688655532369239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09688655532369239}
{"step": 362912, "time": 11665.162931203842, "episode/length": 288.0, "episode/score": 0.08875987567847687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08875987567847687}
{"step": 363088, "time": 11670.574004888535, "episode/length": 288.0, "episode/score": 0.07461101900395306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07461101900395306}
{"step": 363256, "time": 11675.633588552475, "episode/length": 288.0, "episode/score": 0.10235707811557404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10235707811557404}
{"step": 363520, "time": 11683.973476409912, "episode/length": 288.0, "episode/score": 0.12720971258897862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12720971258897862}
{"step": 363768, "time": 11691.374684333801, "episode/length": 84.0, "episode/score": 0.7832089886554172, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.04570896957494597}
{"step": 364088, "time": 11701.220430374146, "episode/length": 146.0, "episode/score": 0.5901384879088596, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.04638851796147492}
{"step": 364216, "time": 11705.257426977158, "episode/length": 288.0, "episode/score": 0.10232635293846215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10232635293846215}
{"step": 364216, "time": 11705.2668633461, "episode/length": 288.0, "episode/score": 0.10645865027817081, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10645865027817081}
{"step": 364288, "time": 11707.713022708893, "episode/length": 288.0, "episode/score": 0.11958667468292106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11958667468292106}
{"step": 364328, "time": 11708.722821474075, "episode/length": 288.0, "episode/score": 0.09099895412845171, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09099895412845171}
{"step": 364960, "time": 11728.369687795639, "episode/length": 108.0, "episode/score": 0.7269292193311117, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.06442919886529808}
{"step": 365032, "time": 11730.358122825623, "episode/length": 87.0, "episode/score": 0.7670779062203792, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.038952904741904604}
{"step": 365352, "time": 11740.365065097809, "episode/length": 48.0, "episode/score": 0.8749130171313482, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.024913008394378267}
{"step": 365568, "time": 11747.29307460785, "episode/length": 288.0, "episode/score": 0.1002528422470732, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1002528422470732}
{"step": 365832, "time": 11755.165692090988, "episode/length": 288.0, "episode/score": 0.06841957191841175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06841957191841175}
{"step": 366080, "time": 11763.030562639236, "episode/length": 288.0, "episode/score": 0.0689460520591183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0689460520591183}
{"step": 366528, "time": 11776.868788480759, "episode/length": 288.0, "episode/score": 0.050020058961422365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050020058961422365}
{"step": 366528, "time": 11776.875894069672, "episode/length": 288.0, "episode/score": 0.044625642041069113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044625642041069113}
{"step": 366600, "time": 11778.866972208023, "episode/length": 288.0, "episode/score": 0.06411736770706966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06411736770706966}
{"step": 366864, "time": 11787.179237604141, "episode/length": 161.0, "episode/score": 0.5725709332218685, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.07569594630695065}
{"step": 366960, "time": 11790.124756336212, "episode/length": 109.0, "episode/score": 0.7035377291940677, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.04416271808804595}
{"step": 367008, "time": 11791.610189199448, "episode/length": 246.0, "episode/score": 0.2963042732428107, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.06505426828351801}
{"step": 367664, "time": 11811.845670223236, "episode/length": 288.0, "episode/score": 0.08262942835858667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08262942835858667}
{"step": 368144, "time": 11826.69571185112, "episode/length": 288.0, "episode/score": 0.05064643876642094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05064643876642094}
{"step": 368840, "time": 11848.70017361641, "episode/length": 288.0, "episode/score": 0.09779195486055414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09779195486055414}
{"step": 368840, "time": 11848.707459688187, "episode/length": 288.0, "episode/score": 0.03974293216776914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03974293216776914}
{"step": 368912, "time": 11851.206131696701, "episode/length": 288.0, "episode/score": 0.05359639685480033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05359639685480033}
{"step": 369176, "time": 11859.3146276474, "episode/length": 288.0, "episode/score": 0.06996096589011813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06996096589011813}
{"step": 369272, "time": 11862.332184791565, "episode/length": 288.0, "episode/score": 0.12321854062531656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12321854062531656}
{"step": 369320, "time": 11863.829779863358, "episode/length": 288.0, "episode/score": 0.09786249238391065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09786249238391065}
{"step": 369976, "time": 11884.304280042648, "episode/length": 288.0, "episode/score": 0.05477748299222185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05477748299222185}
{"step": 370032, "time": 11891.019692659378, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11891.026592493057, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11891.032620429993, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11891.038824796677, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11891.04427242279, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11891.049871444702, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11891.055319070816, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11891.060852050781, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370456, "time": 11904.066928625107, "episode/length": 288.0, "episode/score": 0.08430831829639374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08430831829639374}
{"step": 370552, "time": 11907.075092792511, "episode/length": 71.0, "episode/score": 0.8240414927157644, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.045916506964999826}
{"step": 370720, "time": 11912.530597686768, "episode/length": 32.0, "episode/score": 0.9193106363336483, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.019310643819153483}
{"step": 371128, "time": 11925.126675844193, "episode/length": 71.0, "episode/score": 0.797382625125465, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.01925760840822477}
{"step": 371152, "time": 11926.119213342667, "episode/length": 288.0, "episode/score": 0.09418778294184449, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09418778294184449}
{"step": 371152, "time": 11926.12863779068, "episode/length": 288.0, "episode/score": 0.1108896629298215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1108896629298215}
{"step": 371224, "time": 11928.162999391556, "episode/length": 288.0, "episode/score": 0.038979843146762505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038979843146762505}
{"step": 371488, "time": 11936.644213438034, "episode/length": 288.0, "episode/score": 0.06927582648575026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06927582648575026}
{"step": 371584, "time": 11939.603693008423, "episode/length": 288.0, "episode/score": 0.1040710158396223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1040710158396223}
{"step": 371624, "time": 11940.613721132278, "episode/length": 61.0, "episode/score": 0.8313928523750747, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.022017849976919024}
{"step": 371632, "time": 11941.103605270386, "episode/length": 288.0, "episode/score": 0.0857121367101854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0857121367101854}
{"step": 372392, "time": 11964.350254297256, "episode/length": 100.0, "episode/score": 0.7300777708543364, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0425777716692437}
{"step": 372824, "time": 11977.747728347778, "episode/length": 148.0, "episode/score": 0.5681243907307589, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.030624352569816438}
{"step": 373032, "time": 11984.144163608551, "episode/length": 288.0, "episode/score": 0.050887201388036374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050887201388036374}
{"step": 373120, "time": 11987.078778982162, "episode/length": 245.0, "episode/score": 0.2985561392637237, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.06418113780853218}
{"step": 373192, "time": 11989.140201091766, "episode/length": 195.0, "episode/score": 0.4484543021674199, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.057829302982327135}
{"step": 373408, "time": 11995.994530439377, "episode/length": 46.0, "episode/score": 0.8635351598827583, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.007285148462415236}
{"step": 373464, "time": 11997.493032217026, "episode/length": 288.0, "episode/score": 0.03766994945965507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03766994945965507}
{"step": 373536, "time": 11999.912855625153, "episode/length": 288.0, "episode/score": 0.048805359172831686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048805359172831686}
{"step": 373648, "time": 12003.355242729187, "episode/length": 102.0, "episode/score": 0.719445922911575, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.038195918115263794}
{"step": 373800, "time": 12007.917630910873, "episode/length": 288.0, "episode/score": 0.05680057933631133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05680057933631133}
{"step": 374040, "time": 12015.302575349808, "episode/length": 105.0, "episode/score": 0.6989592710310717, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.02708425671198711}
{"step": 374704, "time": 12035.968745231628, "episode/length": 288.0, "episode/score": 0.021841720867655567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021841720867655567}
{"step": 374912, "time": 12042.337585449219, "episode/length": 187.0, "episode/score": 0.4466452119452242, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.031020212445810103}
{"step": 375016, "time": 12045.324611902237, "episode/length": 184.0, "episode/score": 0.46991181479882016, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.04491180328534483}
{"step": 375088, "time": 12047.746497154236, "episode/length": 21.0, "episode/score": 0.9466623939484862, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.012287377231245955}
{"step": 375104, "time": 12048.243808746338, "episode/length": 181.0, "episode/score": 0.45804202994855814, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.023667055315456764}
{"step": 375392, "time": 12057.097353696823, "episode/length": 198.0, "episode/score": 0.40772157827120736, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.026471597153772564}
{"step": 375424, "time": 12058.081382751465, "episode/length": 41.0, "episode/score": 0.887177600366158, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.015302592962143535}
{"step": 375432, "time": 12058.115329504013, "episode/length": 288.0, "episode/score": 0.03284649320812605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03284649320812605}
{"step": 375560, "time": 12062.065578222275, "episode/length": 56.0, "episode/score": 0.8439848943966126, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.01898487692267281}
{"step": 375728, "time": 12067.534777641296, "episode/length": 41.0, "episode/score": 0.8795932539826481, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.007718252515815038}
{"step": 375776, "time": 12069.005003213882, "episode/length": 288.0, "episode/score": 0.02190188619658784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02190188619658784}
{"step": 376224, "time": 12082.741728544235, "episode/length": 98.0, "episode/score": 0.711689774763272, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.01793974274323773}
{"step": 376352, "time": 12086.669712305069, "episode/length": 288.0, "episode/score": 0.033669009236405145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033669009236405145}
{"step": 377016, "time": 12107.380511283875, "episode/length": 288.0, "episode/score": 0.04363246881149507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04363246881149507}
{"step": 377280, "time": 12115.688373088837, "episode/length": 131.0, "episode/score": 0.6324977859500791, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.041872774529736034}
{"step": 377328, "time": 12117.158215761185, "episode/length": 288.0, "episode/score": 0.05515340640204158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05515340640204158}
{"step": 377400, "time": 12119.165619373322, "episode/length": 47.0, "episode/score": 0.8731062087551891, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.019981256753226262}
{"step": 377688, "time": 12128.08622598648, "episode/length": 166.0, "episode/score": 0.5409534495889261, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.059703471987234025}
{"step": 377736, "time": 12129.577013969421, "episode/length": 288.0, "episode/score": 0.04944833440225693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04944833440225693}
{"step": 377872, "time": 12133.970302343369, "episode/length": 288.0, "episode/score": 0.08537115869933132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08537115869933132}
{"step": 378000, "time": 12137.877861499786, "episode/length": 74.0, "episode/score": 0.788916539320212, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.020166527835840498}
{"step": 378040, "time": 12138.924481153488, "episode/length": 288.0, "episode/score": 0.028129505292781687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028129505292781687}
{"step": 378088, "time": 12140.440739631653, "episode/length": 288.0, "episode/score": 0.061422712614387365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061422712614387365}
{"step": 378376, "time": 12149.287127494812, "episode/length": 79.0, "episode/score": 0.7858375467680503, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.032712518490768616}
{"step": 378696, "time": 12159.204373836517, "episode/length": 125.0, "episode/score": 0.6689601766790929, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.05958514804092374}
{"step": 378760, "time": 12161.173387765884, "episode/length": 83.0, "episode/score": 0.7578392753537173, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.017214253141673908}
{"step": 378792, "time": 12162.156977415085, "episode/length": 98.0, "episode/score": 0.7300111407155896, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.03626108823556251}
{"step": 379072, "time": 12170.976906776428, "episode/length": 86.0, "episode/score": 0.755286872927627, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.02403688566346318}
{"step": 379120, "time": 12172.448206424713, "episode/length": 155.0, "episode/score": 0.5664746888303966, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.05084967247404393}
{"step": 379176, "time": 12173.965161323547, "episode/length": 141.0, "episode/score": 0.5810715149491443, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0216965125509887}
{"step": 379416, "time": 12181.314529657364, "episode/length": 81.0, "episode/score": 0.7649956542186374, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.018120651820481726}
{"step": 379584, "time": 12186.802394151688, "episode/length": 50.0, "episode/score": 0.865950113190479, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.02220008984920696}
{"step": 379592, "time": 12186.837232351303, "episode/length": 288.0, "episode/score": 0.06544715061420447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06544715061420447}
{"step": 379640, "time": 12188.329064130783, "episode/length": 288.0, "episode/score": 0.05448512231981795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05448512231981795}
{"step": 379704, "time": 12190.292776823044, "episode/length": 78.0, "episode/score": 0.7749535528519118, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.018703512653701182}
{"step": 379976, "time": 12198.641161203384, "episode/length": 33.0, "episode/score": 0.9231384451363738, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.02626339795324384}
{"step": 380016, "time": 12200.485773801804, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 380016, "time": 12200.652193069458, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 380016, "time": 12200.881965875626, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 380016, "time": 12200.938799381256, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 380016, "time": 12201.14472603798, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 380016, "time": 12201.30452299118, "eval_episode/length": 21.0, "eval_episode/score": 0.934374988079071, "eval_episode/reward_rate": 0.045454545454545456}
{"step": 380016, "time": 12201.835567712784, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 380016, "time": 12202.055648326874, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 380064, "time": 12203.533195018768, "episode/length": 52.0, "episode/score": 0.8654127262376505, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.027912735760423857}
{"step": 380168, "time": 12206.548240184784, "episode/length": 183.0, "episode/score": 0.46726614822341617, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.039141167629850315}
{"step": 380192, "time": 12207.510562419891, "episode/length": 96.0, "episode/score": 0.7191018756674339, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.019101879410186484}
{"step": 380240, "time": 12208.982818365097, "episode/length": 81.0, "episode/score": 0.7629795642726549, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.016104562805821843}
{"step": 380336, "time": 12211.939588546753, "episode/length": 44.0, "episode/score": 0.8852407250578835, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.02274068374208582}
{"step": 380528, "time": 12217.95345377922, "episode/length": 116.0, "episode/score": 0.6718410446520693, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.034341033231726215}
{"step": 381049, "time": 12234.888128042221, "train_stats/mean_log_entropy": 0.2156601507471215, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.602338078046086, "train/action_min": 0.0, "train/action_std": 1.9485796334767582, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005972737790969661, "train/actor_opt_grad_steps": 22725.0, "train/actor_opt_loss": 10.683669438040015, "train/adv_mag": 0.09654004074106312, "train/adv_max": 0.09573459294107226, "train/adv_mean": 0.009096960636840106, "train/adv_min": -0.024688152351764716, "train/adv_std": 0.012537719263234224, "train/cont_avg": 0.9960394965277778, "train/cont_loss_mean": 0.025888990465024807, "train/cont_loss_std": 0.340731699965104, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.563696948404845, "train/cont_pos_acc": 0.9999999828410872, "train/cont_pos_loss": 0.003866642466605161, "train/cont_pred": 0.9961409279794404, "train/cont_rate": 0.9960394965277778, "train/dyn_loss_mean": 1.0000051573069408, "train/dyn_loss_std": 0.0001497410556714036, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.6770264894955538, "train/extr_critic_critic_opt_grad_steps": 22725.0, "train/extr_critic_critic_opt_loss": 9156.6764298256, "train/extr_critic_mag": 0.7092149299804611, "train/extr_critic_max": 0.7092149299804611, "train/extr_critic_mean": 0.6951624513274491, "train/extr_critic_min": 0.6696126015499385, "train/extr_critic_std": 0.006444045250783815, "train/extr_return_normed_mag": 0.12469866540696886, "train/extr_return_normed_max": 0.12469866540696886, "train/extr_return_normed_mean": 0.03255523365012116, "train/extr_return_normed_min": 0.00017140068189062255, "train/extr_return_normed_std": 0.014643783422393931, "train/extr_return_rate": 1.0, "train/extr_return_raw_mag": 0.7964027987586128, "train/extr_return_raw_max": 0.7964027987586128, "train/extr_return_raw_mean": 0.7042594025231371, "train/extr_return_raw_min": 0.6718755340335345, "train/extr_return_raw_std": 0.014643783350663278, "train/extr_reward_mag": 0.08734836783071961, "train/extr_reward_max": 0.08734836783071961, "train/extr_reward_mean": 0.003099713630908442, "train/extr_reward_min": 1.903374989827474e-05, "train/extr_reward_std": 0.008282250963149104, "train/image_loss_mean": 0.14032609343077196, "train/image_loss_std": 0.11007711535902938, "train/model_loss_mean": 0.788974875753576, "train/model_loss_std": 0.4373692922444657, "train/model_opt_grad_norm": 29.071207176555287, "train/model_opt_grad_steps": 22702.58585858586, "train/model_opt_loss": 2302.225985440341, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2916.6666666666665, "train/policy_entropy_mag": 1.5883752191909637, "train/policy_entropy_max": 1.5883752191909637, "train/policy_entropy_mean": 0.2532734029521846, "train/policy_entropy_min": 0.06472107034289476, "train/policy_entropy_std": 0.27738350343824636, "train/policy_logprob_mag": 6.550932547058722, "train/policy_logprob_max": -0.008613675846859362, "train/policy_logprob_mean": -0.2536273544484919, "train/policy_logprob_min": -6.550932547058722, "train/policy_logprob_std": 0.7839850644872646, "train/policy_randomness_mag": 0.8162634426897223, "train/policy_randomness_max": 0.8162634426897223, "train/policy_randomness_mean": 0.1301567909693477, "train/policy_randomness_min": 0.03326005266621859, "train/policy_randomness_std": 0.14254693043502895, "train/post_ent_mag": 43.10975436971645, "train/post_ent_max": 43.10975436971645, "train/post_ent_mean": 42.62843866059274, "train/post_ent_min": 42.30123203932637, "train/post_ent_std": 0.14227361653489295, "train/prior_ent_mag": 44.46792993641863, "train/prior_ent_max": 44.46792993641863, "train/prior_ent_mean": 42.506561722418276, "train/prior_ent_min": 40.814001410898534, "train/prior_ent_std": 0.573485846320788, "train/rep_loss_mean": 1.0000051573069408, "train/rep_loss_std": 0.0001497410556714036, "train/reward_avg": 0.0008753517429777092, "train/reward_loss_mean": 0.0227566767305211, "train/reward_loss_std": 0.11598325939378654, "train/reward_max_data": 0.3165614934793363, "train/reward_max_pred": 0.020356245715208728, "train/reward_neg_acc": 0.999995066963061, "train/reward_neg_loss": 0.01883892418647354, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.644026820192632, "train/reward_pred": 0.0007967476202692422, "train/reward_rate": 0.0006954308712121212, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.03105146810412407, "report/cont_loss_std": 0.3912811279296875, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.616923809051514, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0036428680177778006, "report/cont_pred": 0.9963638782501221, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1407424509525299, "report/image_loss_std": 0.11453790962696075, "report/model_loss_mean": 0.7894370555877686, "report/model_loss_std": 0.40515488386154175, "report/post_ent_mag": 41.997318267822266, "report/post_ent_max": 41.997318267822266, "report/post_ent_mean": 41.455772399902344, "report/post_ent_min": 41.097801208496094, "report/post_ent_std": 0.16887828707695007, "report/prior_ent_mag": 42.92827606201172, "report/prior_ent_max": 42.92827606201172, "report/prior_ent_mean": 40.86840057373047, "report/prior_ent_min": 39.405517578125, "report/prior_ent_std": 0.6152763366699219, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00043929729145020247, "report/reward_loss_mean": 0.01764306053519249, "report/reward_loss_std": 0.026678944006562233, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.01202237606048584, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01764306053519249, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0006461270386353135, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.01460639201104641, "eval/cont_loss_std": 0.24783192574977875, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.616923809051514, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003642950439825654, "eval/cont_pred": 0.9963638186454773, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1972006857395172, "eval/image_loss_std": 0.1069050282239914, "eval/model_loss_mean": 0.8144452571868896, "eval/model_loss_std": 0.27139246463775635, "eval/post_ent_mag": 41.991859436035156, "eval/post_ent_max": 41.991859436035156, "eval/post_ent_mean": 41.423702239990234, "eval/post_ent_min": 41.00657653808594, "eval/post_ent_std": 0.15133386850357056, "eval/prior_ent_mag": 42.846012115478516, "eval/prior_ent_max": 42.846012115478516, "eval/prior_ent_mean": 40.858482360839844, "eval/prior_ent_min": 39.052268981933594, "eval/prior_ent_std": 0.6214410066604614, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.002638177014887333, "eval/reward_loss_std": 0.003298040246590972, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.012394905090332031, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002638177014887333, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0004315777914598584, "eval/reward_rate": 0.0, "replay/size": 380545.0, "replay/inserts": 31808.0, "replay/samples": 31808.0, "replay/insert_wait_avg": 1.1705956468639719e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.412877960703982e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 88936.0, "eval_replay/inserts": 6960.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0224594466987698e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.385807991027832e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0409231185913, "timer/env.step_count": 3976.0, "timer/env.step_total": 33.91979146003723, "timer/env.step_frac": 0.033918403413191925, "timer/env.step_avg": 0.008531134673047593, "timer/env.step_min": 0.00719761848449707, "timer/env.step_max": 0.03829789161682129, "timer/replay._sample_count": 31808.0, "timer/replay._sample_total": 15.928179025650024, "timer/replay._sample_frac": 0.01592752722156467, "timer/replay._sample_avg": 0.0005007601554844701, "timer/replay._sample_min": 0.00037360191345214844, "timer/replay._sample_max": 0.03372836112976074, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4846.0, "timer/agent.policy_total": 40.46607708930969, "timer/agent.policy_frac": 0.04046442115900387, "timer/agent.policy_avg": 0.008350407983761802, "timer/agent.policy_min": 0.007436275482177734, "timer/agent.policy_max": 0.08761167526245117, "timer/dataset_train_count": 1988.0, "timer/dataset_train_total": 0.20780253410339355, "timer/dataset_train_frac": 0.00020779403052363987, "timer/dataset_train_avg": 0.00010452843767776336, "timer/dataset_train_min": 8.678436279296875e-05, "timer/dataset_train_max": 0.0002262592315673828, "timer/agent.train_count": 1988.0, "timer/agent.train_total": 878.5956811904907, "timer/agent.train_frac": 0.878559727786561, "timer/agent.train_avg": 0.44194953782217844, "timer/agent.train_min": 0.42994189262390137, "timer/agent.train_max": 0.5989971160888672, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.482388973236084, "timer/agent.report_frac": 0.00048236923318274966, "timer/agent.report_avg": 0.241194486618042, "timer/agent.report_min": 0.23454499244689941, "timer/agent.report_max": 0.24784398078918457, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8847467542953744e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 31.806130892050646}
{"step": 381104, "time": 12236.656175613403, "episode/length": 288.0, "episode/score": 0.047886588776009376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047886588776009376}
{"step": 381432, "time": 12246.70661854744, "episode/length": 288.0, "episode/score": 0.026938187926702994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026938187926702994}
{"step": 381664, "time": 12254.029821634293, "episode/length": 141.0, "episode/score": 0.5978194240018411, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.038444412581498}
{"step": 381840, "time": 12259.435538053513, "episode/length": 221.0, "episode/score": 0.3703733540419307, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0609983671270129}
{"step": 381936, "time": 12262.394613981247, "episode/length": 199.0, "episode/score": 0.4477585852145012, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.06963357445772544}
{"step": 382192, "time": 12270.255178689957, "episode/length": 135.0, "episode/score": 0.6195808463219237, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.04145583200283909}
{"step": 382336, "time": 12274.665307283401, "episode/length": 61.0, "episode/score": 0.8301214260550296, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.02074641865101512}
{"step": 382480, "time": 12279.181087732315, "episode/length": 288.0, "episode/score": 0.08654403235436803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08654403235436803}
{"step": 382504, "time": 12279.700059890747, "episode/length": 288.0, "episode/score": 0.022943135423474814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022943135423474814}
{"step": 382552, "time": 12281.19115114212, "episode/length": 288.0, "episode/score": 0.03923192254853802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03923192254853802}
{"step": 383040, "time": 12296.369297504425, "episode/length": 171.0, "episode/score": 0.5164872040949149, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.050862228937944565}
{"step": 383152, "time": 12299.81632399559, "episode/length": 151.0, "episode/score": 0.5744361448083737, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.046311142410218054}
{"step": 383368, "time": 12306.305124044418, "episode/length": 110.0, "episode/score": 0.6849497139412506, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.028699690599978567}
{"step": 383512, "time": 12310.718532562256, "episode/length": 146.0, "episode/score": 0.5606052265183052, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.016855251361334922}
{"step": 383744, "time": 12318.03709602356, "episode/length": 288.0, "episode/score": 0.027668380932254877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027668380932254877}
{"step": 383912, "time": 12322.97040939331, "episode/length": 214.0, "episode/score": 0.3950946860290969, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.06384467454472542}
{"step": 384304, "time": 12335.306711435318, "episode/length": 143.0, "episode/score": 0.5760360701387981, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.022911032909178175}
{"step": 384472, "time": 12340.24414396286, "episode/length": 239.0, "episode/score": 0.3129062316733098, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.05978122621343118}
{"step": 384736, "time": 12348.556163787842, "episode/length": 278.0, "episode/score": 0.1902074181050466, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.058957422086450606}
{"step": 385352, "time": 12367.784386873245, "episode/length": 288.0, "episode/score": 0.03512213708825129, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03512213708825129}
{"step": 385680, "time": 12378.05692243576, "episode/length": 288.0, "episode/score": 0.06436542101187115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06436542101187115}
{"step": 385824, "time": 12382.476468801498, "episode/length": 288.0, "episode/score": 0.05127903854508986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05127903854508986}
{"step": 385904, "time": 12384.940794706345, "episode/length": 178.0, "episode/score": 0.5075725087366436, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.06382251551201534}
{"step": 385904, "time": 12384.95522904396, "episode/length": 248.0, "episode/score": 0.30492657488827035, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.07992657520259172}
{"step": 386056, "time": 12389.407255649567, "episode/length": 288.0, "episode/score": 0.047698811225927784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047698811225927784}
{"step": 386592, "time": 12406.175181627274, "episode/length": 85.0, "episode/score": 0.7788765433041362, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0445015441190435}
{"step": 386616, "time": 12406.69902420044, "episode/length": 288.0, "episode/score": 0.11553818231050172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11553818231050172}
{"step": 386624, "time": 12407.169810295105, "episode/length": 158.0, "episode/score": 0.5544128209060091, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.04816282122033044}
{"step": 387048, "time": 12420.021247625351, "episode/length": 288.0, "episode/score": 0.1138777721301949, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1138777721301949}
{"step": 387672, "time": 12439.292203903198, "episode/length": 230.0, "episode/score": 0.3569535494965521, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.07570353517746753}
{"step": 387992, "time": 12449.16466164589, "episode/length": 288.0, "episode/score": 0.05249573504084992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05249573504084992}
{"step": 388216, "time": 12456.213594913483, "episode/length": 288.0, "episode/score": 0.10614568428377424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10614568428377424}
{"step": 388368, "time": 12461.116059541702, "episode/length": 288.0, "episode/score": 0.11356911809946268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11356911809946268}
{"step": 388904, "time": 12477.35929942131, "episode/length": 288.0, "episode/score": 0.11921883603321248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11921883603321248}
{"step": 388928, "time": 12478.403435230255, "episode/length": 288.0, "episode/score": 0.15743139459027589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15743139459027589}
{"step": 388936, "time": 12478.43696308136, "episode/length": 288.0, "episode/score": 0.12791613794360046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12791613794360046}
{"step": 389360, "time": 12491.781391143799, "episode/length": 288.0, "episode/score": 0.1352143597646318, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1352143597646318}
{"step": 389696, "time": 12502.117591619492, "episode/length": 252.0, "episode/score": 0.344221552365525, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.13172154721996776}
{"step": 390000, "time": 12512.731592178345, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 390000, "time": 12516.724154233932, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12516.7307305336, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12516.736489772797, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12516.742068052292, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12516.747430086136, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12516.752849340439, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12516.758253097534, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390304, "time": 12526.11906003952, "episode/length": 288.0, "episode/score": 0.19784248600166165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19784248600166165}
{"step": 390528, "time": 12533.033806085587, "episode/length": 288.0, "episode/score": 0.15814726125717016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15814726125717016}
{"step": 390680, "time": 12537.49628829956, "episode/length": 288.0, "episode/score": 0.16623553161201698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16623553161201698}
{"step": 391032, "time": 12548.42705821991, "episode/length": 90.0, "episode/score": 0.8127201525180681, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.09397013819898348}
{"step": 391216, "time": 12554.31159734726, "episode/length": 288.0, "episode/score": 0.13146567318688085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13146567318688085}
{"step": 391240, "time": 12554.839520692825, "episode/length": 288.0, "episode/score": 0.1661395531286871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1661395531286871}
{"step": 391248, "time": 12555.314811229706, "episode/length": 288.0, "episode/score": 0.15798696830165682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15798696830165682}
{"step": 391672, "time": 12568.170165777206, "episode/length": 288.0, "episode/score": 0.10684096725015024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10684096725015024}
{"step": 391984, "time": 12578.129764795303, "episode/length": 285.0, "episode/score": 0.22314067303295815, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.11376567157776662}
{"step": 392840, "time": 12604.263718605042, "episode/length": 288.0, "episode/score": 0.10223841809954592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10223841809954592}
{"step": 392992, "time": 12609.274710893631, "episode/length": 288.0, "episode/score": 0.113402262912075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.113402262912075}
{"step": 393344, "time": 12620.60029911995, "episode/length": 288.0, "episode/score": 0.10608714088584748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10608714088584748}
{"step": 393528, "time": 12626.0417740345, "episode/length": 288.0, "episode/score": 0.10955875659897174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10955875659897174}
{"step": 393552, "time": 12627.01886844635, "episode/length": 288.0, "episode/score": 0.12788494134275652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12788494134275652}
{"step": 393560, "time": 12627.052934885025, "episode/length": 288.0, "episode/score": 0.08408541385233548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08408541385233548}
{"step": 393984, "time": 12640.38217139244, "episode/length": 288.0, "episode/score": 0.11094886057242093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11094886057242093}
{"step": 394296, "time": 12649.763207435608, "episode/length": 288.0, "episode/score": 0.09061498222121145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09061498222121145}
{"step": 395152, "time": 12676.434899568558, "episode/length": 288.0, "episode/score": 0.08305780401303764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08305780401303764}
{"step": 395304, "time": 12680.86689567566, "episode/length": 288.0, "episode/score": 0.11577133478294854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11577133478294854}
{"step": 395656, "time": 12691.683110952377, "episode/length": 288.0, "episode/score": 0.10785944964254668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10785944964254668}
{"step": 395840, "time": 12697.668407917023, "episode/length": 288.0, "episode/score": 0.04679838432707584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04679838432707584}
{"step": 395864, "time": 12698.196144580841, "episode/length": 288.0, "episode/score": 0.10440562451060487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10440562451060487}
{"step": 395872, "time": 12698.667051792145, "episode/length": 288.0, "episode/score": 0.0610055127809801, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0610055127809801}
{"step": 396296, "time": 12711.467603206635, "episode/length": 288.0, "episode/score": 0.10719839266079134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10719839266079134}
{"step": 396608, "time": 12721.257089138031, "episode/length": 288.0, "episode/score": 0.12947776971878966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12947776971878966}
{"step": 397464, "time": 12747.329051494598, "episode/length": 288.0, "episode/score": 0.11984963594539977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11984963594539977}
{"step": 397616, "time": 12752.217816591263, "episode/length": 288.0, "episode/score": 0.10873571469909393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10873571469909393}
{"step": 397968, "time": 12763.129809379578, "episode/length": 288.0, "episode/score": 0.15222572707648396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15222572707648396}
{"step": 398152, "time": 12768.56540298462, "episode/length": 288.0, "episode/score": 0.127587415850428, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.127587415850428}
{"step": 398176, "time": 12769.523336410522, "episode/length": 288.0, "episode/score": 0.14548414564535506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14548414564535506}
{"step": 398184, "time": 12769.556992530823, "episode/length": 288.0, "episode/score": 0.15013877049938174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15013877049938174}
{"step": 398608, "time": 12782.790844202042, "episode/length": 288.0, "episode/score": 0.09691256735021625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09691256735021625}
{"step": 398920, "time": 12792.291390180588, "episode/length": 288.0, "episode/score": 0.1323576142466436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1323576142466436}
{"step": 399776, "time": 12818.903795003891, "episode/length": 288.0, "episode/score": 0.12239434733817234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12239434733817234}
{"step": 399928, "time": 12823.366029262543, "episode/length": 288.0, "episode/score": 0.09499872136035492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09499872136035492}
{"step": 400088, "time": 12832.755143880844, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12832.761485338211, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12832.766952991486, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12832.772025585175, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12832.778250694275, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12832.784632205963, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12832.791110038757, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12832.796161651611, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400280, "time": 12838.709764242172, "episode/length": 288.0, "episode/score": 0.09769512991266538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09769512991266538}
{"step": 400464, "time": 12844.591867685318, "episode/length": 288.0, "episode/score": 0.1194548111159861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1194548111159861}
{"step": 400488, "time": 12845.24063539505, "episode/length": 288.0, "episode/score": 0.08504751646103159, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08504751646103159}
{"step": 400496, "time": 12845.709736585617, "episode/length": 288.0, "episode/score": 0.08769328913609797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08769328913609797}
{"step": 400920, "time": 12858.54681134224, "episode/length": 288.0, "episode/score": 0.07141146634830875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07141146634830875}
{"step": 401232, "time": 12868.36068725586, "episode/length": 288.0, "episode/score": 0.05366997302780874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05366997302780874}
{"step": 402088, "time": 12895.001240968704, "episode/length": 288.0, "episode/score": 0.08011716353962584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08011716353962584}
{"step": 402240, "time": 12899.88221669197, "episode/length": 288.0, "episode/score": 0.10035016173327449, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10035016173327449}
{"step": 402592, "time": 12910.782551288605, "episode/length": 288.0, "episode/score": 0.1142611015577586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1142611015577586}
{"step": 402776, "time": 12916.205492258072, "episode/length": 288.0, "episode/score": 0.11432870875268009, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11432870875268009}
{"step": 402800, "time": 12917.160447597504, "episode/length": 288.0, "episode/score": 0.11007516289015484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11007516289015484}
{"step": 402808, "time": 12917.193370342255, "episode/length": 288.0, "episode/score": 0.13726541287962846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13726541287962846}
{"step": 403232, "time": 12930.436005592346, "episode/length": 288.0, "episode/score": 0.1324072315749163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1324072315749163}
{"step": 403544, "time": 12939.904081583023, "episode/length": 288.0, "episode/score": 0.202169364847407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.202169364847407}
{"step": 404400, "time": 12966.485572576523, "episode/length": 288.0, "episode/score": 0.18240852708544253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18240852708544253}
{"step": 404552, "time": 12971.001281738281, "episode/length": 288.0, "episode/score": 0.20264005480009928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20264005480009928}
{"step": 404904, "time": 12981.810357809067, "episode/length": 288.0, "episode/score": 0.1574432354569808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1574432354569808}
{"step": 405088, "time": 12987.699449062347, "episode/length": 288.0, "episode/score": 0.17455181274925735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17455181274925735}
{"step": 405112, "time": 12988.221950054169, "episode/length": 288.0, "episode/score": 0.16994103487229495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16994103487229495}
{"step": 405120, "time": 12988.690873146057, "episode/length": 288.0, "episode/score": 0.22477895438163387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22477895438163387}
{"step": 405544, "time": 13001.596449136734, "episode/length": 288.0, "episode/score": 0.14844066630092811, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14844066630092811}
{"step": 405856, "time": 13011.385254621506, "episode/length": 288.0, "episode/score": 0.20896412753677396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20896412753677396}
{"step": 406712, "time": 13037.545751810074, "episode/length": 288.0, "episode/score": 0.18404864923650166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18404864923650166}
{"step": 406864, "time": 13042.441430807114, "episode/length": 288.0, "episode/score": 0.19443017446246813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19443017446246813}
{"step": 407216, "time": 13053.234986543655, "episode/length": 288.0, "episode/score": 0.19001386310173984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19001386310173984}
{"step": 407400, "time": 13058.73983669281, "episode/length": 288.0, "episode/score": 0.16471086796900636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16471086796900636}
{"step": 407424, "time": 13059.696951627731, "episode/length": 288.0, "episode/score": 0.1653421175760741, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1653421175760741}
{"step": 407432, "time": 13059.730856895447, "episode/length": 288.0, "episode/score": 0.2458374333782558, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2458374333782558}
{"step": 407856, "time": 13072.961750984192, "episode/length": 288.0, "episode/score": 0.15795917082687083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15795917082687083}
{"step": 408168, "time": 13082.451223611832, "episode/length": 288.0, "episode/score": 0.1919848494890175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1919848494890175}
{"step": 409024, "time": 13109.046126365662, "episode/length": 288.0, "episode/score": 0.12753459185751126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12753459185751126}
{"step": 409176, "time": 13113.504710435867, "episode/length": 288.0, "episode/score": 0.16080666042626035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16080666042626035}
{"step": 409528, "time": 13124.397339582443, "episode/length": 288.0, "episode/score": 0.1712522981379152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1712522981379152}
{"step": 409712, "time": 13130.796239376068, "episode/length": 288.0, "episode/score": 0.15771147265513719, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15771147265513719}
{"step": 409736, "time": 13131.32128405571, "episode/length": 288.0, "episode/score": 0.1333965494181939, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1333965494181939}
{"step": 409744, "time": 13131.79187130928, "episode/length": 288.0, "episode/score": 0.15439043298329125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15439043298329125}
{"step": 410072, "time": 13146.25627875328, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13146.262150287628, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13146.267926216125, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13146.273843288422, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13146.280901670456, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13146.287386655807, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13146.292593240738, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13146.297568321228, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410168, "time": 13149.2399995327, "episode/length": 288.0, "episode/score": 0.11758840127731673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11758840127731673}
{"step": 410480, "time": 13159.048570156097, "episode/length": 288.0, "episode/score": 0.08572443990215106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08572443990215106}
{"step": 411336, "time": 13185.29868221283, "episode/length": 288.0, "episode/score": 0.08270370759373691, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08270370759373691}
{"step": 411488, "time": 13190.181929826736, "episode/length": 288.0, "episode/score": 0.14009825882385485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14009825882385485}
{"step": 411840, "time": 13200.984803676605, "episode/length": 288.0, "episode/score": 0.11509295491350713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11509295491350713}
{"step": 412024, "time": 13206.494132041931, "episode/length": 288.0, "episode/score": 0.08544963827989704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08544963827989704}
{"step": 412048, "time": 13207.455695152283, "episode/length": 288.0, "episode/score": 0.102538564599854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.102538564599854}
{"step": 412056, "time": 13207.49170923233, "episode/length": 288.0, "episode/score": 0.06677292586846306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06677292586846306}
{"step": 412480, "time": 13220.75584077835, "episode/length": 288.0, "episode/score": 0.1078634036243784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1078634036243784}
{"step": 412792, "time": 13230.127742528915, "episode/length": 288.0, "episode/score": 0.09477993756536307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09477993756536307}
{"step": 412921, "time": 13235.139420509338, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.83623291015625, "train/action_min": 0.0, "train/action_std": 1.2247385051846504, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00662574996764306, "train/actor_opt_grad_steps": 24715.0, "train/actor_opt_loss": -3.081517976820469, "train/adv_mag": 0.13770418643951415, "train/adv_max": 0.12499577730894089, "train/adv_mean": 0.003161590763629647, "train/adv_min": -0.046621259748935696, "train/adv_std": 0.01861867750296369, "train/cont_avg": 0.9961083984375, "train/cont_loss_mean": 0.02550357221625745, "train/cont_loss_std": 0.33531762309372426, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.540037376880646, "train/cont_pos_acc": 0.9999999877810478, "train/cont_pos_loss": 0.003946031347149983, "train/cont_pred": 0.9960617905855179, "train/cont_rate": 0.9961083984375, "train/dyn_loss_mean": 1.000007700920105, "train/dyn_loss_std": 0.00021420262443825778, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8494813914131373, "train/extr_critic_critic_opt_grad_steps": 24715.0, "train/extr_critic_critic_opt_loss": 9802.8825390625, "train/extr_critic_mag": 0.982491894364357, "train/extr_critic_max": 0.982491894364357, "train/extr_critic_mean": 0.9603462964296341, "train/extr_critic_min": 0.9215070599317551, "train/extr_critic_std": 0.011446485202759505, "train/extr_return_normed_mag": 0.16916536629199982, "train/extr_return_normed_max": 0.16242756485939025, "train/extr_return_normed_mean": 0.030777338757470716, "train/extr_return_normed_min": -0.014524688124656676, "train/extr_return_normed_std": 0.02313330346252769, "train/extr_return_rate": 0.9999882814288139, "train/extr_return_raw_mag": 1.095158089697361, "train/extr_return_raw_max": 1.095158089697361, "train/extr_return_raw_mean": 0.9635079064965248, "train/extr_return_raw_min": 0.9182058367878199, "train/extr_return_raw_std": 0.023133303343784065, "train/extr_reward_mag": 0.10183449983596801, "train/extr_reward_max": 0.10183449983596801, "train/extr_reward_mean": 0.0031419145202380605, "train/extr_reward_min": 1.5428066253662108e-05, "train/extr_reward_std": 0.009729433109023376, "train/image_loss_mean": 0.12448403358459473, "train/image_loss_std": 0.10792190991342068, "train/model_loss_mean": 0.7733680874109268, "train/model_loss_std": 0.43988436527550223, "train/model_opt_grad_norm": 27.769950695037842, "train/model_opt_grad_steps": 24691.415, "train/model_opt_loss": 3366.074700317383, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4350.0, "train/policy_entropy_mag": 1.2107725873589517, "train/policy_entropy_max": 1.2107725873589517, "train/policy_entropy_mean": 0.15187195517122745, "train/policy_entropy_min": 0.06468744542449713, "train/policy_entropy_std": 0.18015130937099458, "train/policy_logprob_mag": 6.551077373027802, "train/policy_logprob_max": -0.008608379224315286, "train/policy_logprob_mean": -0.15181425653398037, "train/policy_logprob_min": -6.551077373027802, "train/policy_logprob_std": 0.6856469884514809, "train/policy_randomness_mag": 0.6222140635550022, "train/policy_randomness_max": 0.6222140635550022, "train/policy_randomness_mean": 0.07804675044491888, "train/policy_randomness_min": 0.03324277278035879, "train/policy_randomness_std": 0.0925794643908739, "train/post_ent_mag": 40.228804149627685, "train/post_ent_max": 40.228804149627685, "train/post_ent_mean": 39.660819664001465, "train/post_ent_min": 39.26763568878174, "train/post_ent_std": 0.17007898077368735, "train/prior_ent_mag": 41.46675724029541, "train/prior_ent_max": 41.46675724029541, "train/prior_ent_mean": 39.01213577270508, "train/prior_ent_min": 37.2418257522583, "train/prior_ent_std": 0.635521586239338, "train/rep_loss_mean": 1.000007700920105, "train/rep_loss_std": 0.00021420262443825778, "train/reward_avg": 0.0009859149616386275, "train/reward_loss_mean": 0.023375835502520204, "train/reward_loss_std": 0.123608377315104, "train/reward_max_data": 0.3823310740850866, "train/reward_max_pred": 0.050789120197296145, "train/reward_neg_acc": 0.9999511563777923, "train/reward_neg_loss": 0.018976154904812574, "train/reward_pos_acc": 0.0565476194024086, "train/reward_pos_loss": 5.18754270034177, "train/reward_pred": 0.0008594246447319165, "train/reward_rate": 0.000859375, "train_stats/mean_log_entropy": 0.15058037031348012, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020222101360559464, "report/cont_loss_std": 0.29522037506103516, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.466475486755371, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004219399765133858, "report/cont_pred": 0.9957893490791321, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09179742634296417, "report/image_loss_std": 0.09288997948169708, "report/model_loss_mean": 0.7350769639015198, "report/model_loss_std": 0.43221500515937805, "report/post_ent_mag": 39.1495246887207, "report/post_ent_max": 39.1495246887207, "report/post_ent_mean": 38.55442428588867, "report/post_ent_min": 38.180179595947266, "report/post_ent_std": 0.17841015756130219, "report/prior_ent_mag": 39.797279357910156, "report/prior_ent_max": 39.797279357910156, "report/prior_ent_mean": 37.500465393066406, "report/prior_ent_min": 35.517845153808594, "report/prior_ent_std": 0.6736646890640259, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0012329325545579195, "report/reward_loss_mean": 0.023057417944073677, "report/reward_loss_std": 0.16712631285190582, "report/reward_max_data": 0.8161250352859497, "report/reward_max_pred": 0.01702880859375, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.017896050587296486, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.303137302398682, "report/reward_pred": 0.0006980347679927945, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014916522428393364, "eval/cont_loss_std": 0.2417076826095581, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.478792667388916, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004224005620926619, "eval/cont_pred": 0.9957848787307739, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21276021003723145, "eval/image_loss_std": 0.1392863392829895, "eval/model_loss_mean": 0.8302078247070312, "eval/model_loss_std": 0.2759089171886444, "eval/post_ent_mag": 39.149803161621094, "eval/post_ent_max": 39.149803161621094, "eval/post_ent_mean": 38.514347076416016, "eval/post_ent_min": 38.128814697265625, "eval/post_ent_std": 0.17973527312278748, "eval/prior_ent_mag": 40.85210418701172, "eval/prior_ent_max": 40.85210418701172, "eval/prior_ent_mean": 37.357242584228516, "eval/prior_ent_min": 35.54796600341797, "eval/prior_ent_std": 0.7356342077255249, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0025310576893389225, "eval/reward_loss_std": 0.0031351831275969744, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.008484363555908203, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0025310576893389225, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0004309876821935177, "eval/reward_rate": 0.0, "replay/size": 412417.0, "replay/inserts": 31872.0, "replay/samples": 31872.0, "replay/insert_wait_avg": 1.155700250323039e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.44130477369071e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 95872.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.914857980976742e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2349035739899, "timer/env.step_count": 3984.0, "timer/env.step_total": 33.66157841682434, "timer/env.step_frac": 0.03365367304874731, "timer/env.step_avg": 0.008449191369684824, "timer/env.step_min": 0.007090330123901367, "timer/env.step_max": 0.03917646408081055, "timer/replay._sample_count": 31872.0, "timer/replay._sample_total": 15.854995250701904, "timer/replay._sample_frac": 0.01585127173032017, "timer/replay._sample_avg": 0.0004974584353257375, "timer/replay._sample_min": 0.00039124488830566406, "timer/replay._sample_max": 0.019271373748779297, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4851.0, "timer/agent.policy_total": 40.96384859085083, "timer/agent.policy_frac": 0.040954228296254044, "timer/agent.policy_avg": 0.008444413232498626, "timer/agent.policy_min": 0.007414102554321289, "timer/agent.policy_max": 0.07336735725402832, "timer/dataset_train_count": 1992.0, "timer/dataset_train_total": 0.20642471313476562, "timer/dataset_train_frac": 0.0002063762346196669, "timer/dataset_train_avg": 0.00010362686402347672, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0004131793975830078, "timer/agent.train_count": 1992.0, "timer/agent.train_total": 878.8468654155731, "timer/agent.train_frac": 0.8786404696290051, "timer/agent.train_avg": 0.4411881854495849, "timer/agent.train_min": 0.43145227432250977, "timer/agent.train_max": 0.6030476093292236, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.558922290802002, "timer/agent.report_frac": 0.0005587910287922252, "timer/agent.report_avg": 0.279461145401001, "timer/agent.report_min": 0.25715041160583496, "timer/agent.report_max": 0.301771879196167, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.9318598185993923e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 31.863961937151167}
{"step": 413648, "time": 13257.561286449432, "episode/length": 288.0, "episode/score": 0.16033757435775442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16033757435775442}
{"step": 413800, "time": 13262.072981834412, "episode/length": 288.0, "episode/score": 0.1461545705565186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1461545705565186}
{"step": 414152, "time": 13273.09202170372, "episode/length": 288.0, "episode/score": 0.12583359663949523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12583359663949523}
{"step": 414336, "time": 13278.968533277512, "episode/length": 288.0, "episode/score": 0.20302696887893035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20302696887893035}
{"step": 414360, "time": 13279.506567239761, "episode/length": 288.0, "episode/score": 0.1810430461764554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1810430461764554}
{"step": 414368, "time": 13279.975711584091, "episode/length": 288.0, "episode/score": 0.185516902056861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.185516902056861}
{"step": 414792, "time": 13292.716134786606, "episode/length": 288.0, "episode/score": 0.06828792641636028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06828792641636028}
{"step": 415104, "time": 13302.6069521904, "episode/length": 288.0, "episode/score": 0.22763509356377654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22763509356377654}
{"step": 415960, "time": 13328.865616083145, "episode/length": 288.0, "episode/score": 0.1687250391755697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1687250391755697}
{"step": 416112, "time": 13333.768646001816, "episode/length": 288.0, "episode/score": 0.14503552757378202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14503552757378202}
{"step": 416464, "time": 13344.611627817154, "episode/length": 288.0, "episode/score": 0.17551009133103435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17551009133103435}
{"step": 416648, "time": 13350.083052873611, "episode/length": 288.0, "episode/score": 0.21996337103928454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21996337103928454}
{"step": 416672, "time": 13351.042990922928, "episode/length": 288.0, "episode/score": 0.1497998622353407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1497998622353407}
{"step": 416680, "time": 13351.075924634933, "episode/length": 288.0, "episode/score": 0.18829502535072606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18829502535072606}
{"step": 417104, "time": 13364.374978542328, "episode/length": 288.0, "episode/score": 0.13337363979940164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13337363979940164}
{"step": 417416, "time": 13373.71686887741, "episode/length": 288.0, "episode/score": 0.16524911941041864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16524911941041864}
{"step": 418272, "time": 13400.766098976135, "episode/length": 288.0, "episode/score": 0.17395543987004203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17395543987004203}
{"step": 418424, "time": 13405.247727394104, "episode/length": 288.0, "episode/score": 0.19149615908554551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19149615908554551}
{"step": 418776, "time": 13416.211264371872, "episode/length": 288.0, "episode/score": 0.13798896479556788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13798896479556788}
{"step": 418960, "time": 13422.083626747131, "episode/length": 288.0, "episode/score": 0.15343265591582167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15343265591582167}
{"step": 418984, "time": 13422.608581066132, "episode/length": 288.0, "episode/score": 0.19300189009663882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19300189009663882}
{"step": 418992, "time": 13423.09883093834, "episode/length": 288.0, "episode/score": 0.2162483188258193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2162483188258193}
{"step": 419416, "time": 13435.973219633102, "episode/length": 288.0, "episode/score": 0.20239167152794835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20239167152794835}
{"step": 419728, "time": 13445.911841154099, "episode/length": 288.0, "episode/score": 0.19931363982095718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19931363982095718}
{"step": 420056, "time": 13460.875492572784, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13460.881930112839, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13460.887816905975, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13460.893212795258, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13460.89848446846, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13460.903757095337, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13460.908859014511, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13460.914393901825, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420584, "time": 13477.21562576294, "episode/length": 288.0, "episode/score": 0.1486002003257454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1486002003257454}
{"step": 420736, "time": 13482.098063707352, "episode/length": 288.0, "episode/score": 0.14880097517743707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14880097517743707}
{"step": 421088, "time": 13492.893161058426, "episode/length": 288.0, "episode/score": 0.14161743463773746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14161743463773746}
{"step": 421272, "time": 13498.325025081635, "episode/length": 288.0, "episode/score": 0.18317374318576185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18317374318576185}
{"step": 421296, "time": 13499.28389620781, "episode/length": 288.0, "episode/score": 0.12648885788439657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12648885788439657}
{"step": 421304, "time": 13499.316978931427, "episode/length": 288.0, "episode/score": 0.14454233873766498, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14454233873766498}
{"step": 421728, "time": 13512.60862994194, "episode/length": 288.0, "episode/score": 0.15727021857674117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15727021857674117}
{"step": 422040, "time": 13521.957025527954, "episode/length": 288.0, "episode/score": 0.1631897914921865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1631897914921865}
{"step": 422896, "time": 13548.557718515396, "episode/length": 288.0, "episode/score": 0.14396451618267747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14396451618267747}
{"step": 423048, "time": 13553.019215345383, "episode/length": 288.0, "episode/score": 0.15275201197982824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15275201197982824}
{"step": 423400, "time": 13563.887813091278, "episode/length": 288.0, "episode/score": 0.16179238458244072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16179238458244072}
{"step": 423584, "time": 13569.888022899628, "episode/length": 288.0, "episode/score": 0.09392287902846874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09392287902846874}
{"step": 423608, "time": 13570.411915302277, "episode/length": 288.0, "episode/score": 0.12319786133957678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12319786133957678}
{"step": 423616, "time": 13570.884420633316, "episode/length": 288.0, "episode/score": 0.12618712265975773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12618712265975773}
{"step": 424040, "time": 13583.75377368927, "episode/length": 288.0, "episode/score": 0.08199390533536643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08199390533536643}
{"step": 424352, "time": 13593.619744300842, "episode/length": 288.0, "episode/score": 0.1278986320576223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1278986320576223}
{"step": 425208, "time": 13619.79312968254, "episode/length": 288.0, "episode/score": 0.13678848843937885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13678848843937885}
{"step": 425360, "time": 13624.65944314003, "episode/length": 288.0, "episode/score": 0.12065869840444066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12065869840444066}
{"step": 425712, "time": 13635.567281484604, "episode/length": 288.0, "episode/score": 0.08020818535806029, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08020818535806029}
{"step": 425896, "time": 13640.98485159874, "episode/length": 288.0, "episode/score": 0.1233549652806687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1233549652806687}
{"step": 425920, "time": 13641.94306731224, "episode/length": 288.0, "episode/score": 0.10521106019768922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10521106019768922}
{"step": 425928, "time": 13641.975889205933, "episode/length": 288.0, "episode/score": 0.11832409886119422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11832409886119422}
{"step": 426352, "time": 13655.75854063034, "episode/length": 288.0, "episode/score": 0.1292127240631089, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1292127240631089}
{"step": 426664, "time": 13665.08128619194, "episode/length": 288.0, "episode/score": 0.1324629469854699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1324629469854699}
{"step": 427520, "time": 13691.905451536179, "episode/length": 288.0, "episode/score": 0.060086410552685265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060086410552685265}
{"step": 427672, "time": 13696.409175872803, "episode/length": 288.0, "episode/score": 0.14121168833571573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14121168833571573}
{"step": 428024, "time": 13707.357591867447, "episode/length": 288.0, "episode/score": 0.11137305583906709, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11137305583906709}
{"step": 428208, "time": 13713.30540060997, "episode/length": 288.0, "episode/score": 0.10224445122366888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10224445122366888}
{"step": 428232, "time": 13713.833503961563, "episode/length": 288.0, "episode/score": 0.1449103722397922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1449103722397922}
{"step": 428240, "time": 13714.30994939804, "episode/length": 288.0, "episode/score": 0.12008230844367063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12008230844367063}
{"step": 428664, "time": 13727.26176404953, "episode/length": 288.0, "episode/score": 0.18416089730453677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18416089730453677}
{"step": 428976, "time": 13737.044107198715, "episode/length": 288.0, "episode/score": 0.10099692056792264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10099692056792264}
{"step": 429832, "time": 13763.502366304398, "episode/length": 288.0, "episode/score": 0.10737367108504259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10737367108504259}
{"step": 429984, "time": 13768.386669158936, "episode/length": 288.0, "episode/score": 0.15075639281712938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15075639281712938}
{"step": 430040, "time": 13774.363285541534, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13774.369667053223, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13774.375221252441, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13774.380734920502, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13774.38618516922, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13774.39166855812, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13774.397135972977, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13774.402570962906, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430336, "time": 13783.755027770996, "episode/length": 288.0, "episode/score": 0.14174729796104657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14174729796104657}
{"step": 430520, "time": 13789.17054104805, "episode/length": 288.0, "episode/score": 0.1110486233883421, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1110486233883421}
{"step": 430544, "time": 13790.120230674744, "episode/length": 288.0, "episode/score": 0.11356286710997665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11356286710997665}
{"step": 430552, "time": 13790.154112577438, "episode/length": 288.0, "episode/score": 0.11780188188276952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11780188188276952}
{"step": 430976, "time": 13803.262911558151, "episode/length": 288.0, "episode/score": 0.08498094453352678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08498094453352678}
{"step": 431288, "time": 13812.65784740448, "episode/length": 288.0, "episode/score": 0.068077151732723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.068077151732723}
{"step": 432144, "time": 13839.125531435013, "episode/length": 288.0, "episode/score": 0.012254183512595773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012254183512595773}
{"step": 432296, "time": 13843.573627233505, "episode/length": 288.0, "episode/score": 0.03153028268934577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03153028268934577}
{"step": 432648, "time": 13854.43140077591, "episode/length": 288.0, "episode/score": 0.044838282484306546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044838282484306546}
{"step": 432832, "time": 13860.386189460754, "episode/length": 288.0, "episode/score": 0.046212117820687126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046212117820687126}
{"step": 432856, "time": 13860.91893362999, "episode/length": 288.0, "episode/score": 0.04959101926215226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04959101926215226}
{"step": 432864, "time": 13861.395828008652, "episode/length": 288.0, "episode/score": 0.04960611434762541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04960611434762541}
{"step": 433288, "time": 13874.527685880661, "episode/length": 288.0, "episode/score": 0.042947039938553644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042947039938553644}
{"step": 433600, "time": 13884.438660860062, "episode/length": 288.0, "episode/score": 0.04121095538539521, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04121095538539521}
{"step": 434456, "time": 13911.155037164688, "episode/length": 288.0, "episode/score": 0.039865786751761334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039865786751761334}
{"step": 434608, "time": 13916.035133123398, "episode/length": 288.0, "episode/score": 0.04184854926643311, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04184854926643311}
{"step": 434960, "time": 13926.944740056992, "episode/length": 288.0, "episode/score": 0.06556468978578778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06556468978578778}
{"step": 435144, "time": 13932.371909618378, "episode/length": 288.0, "episode/score": 0.030884671000421804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030884671000421804}
{"step": 435168, "time": 13933.345845460892, "episode/length": 288.0, "episode/score": 0.032919771546403354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032919771546403354}
{"step": 435176, "time": 13933.378461837769, "episode/length": 288.0, "episode/score": 0.031297677147449576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031297677147449576}
{"step": 435600, "time": 13946.594256401062, "episode/length": 288.0, "episode/score": 0.04910794928582618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04910794928582618}
{"step": 435912, "time": 13956.00126028061, "episode/length": 288.0, "episode/score": 0.07474928641022416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07474928641022416}
{"step": 436768, "time": 13982.408135652542, "episode/length": 288.0, "episode/score": 0.03985771912630298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03985771912630298}
{"step": 436920, "time": 13986.927956104279, "episode/length": 288.0, "episode/score": 0.06595567038857553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06595567038857553}
{"step": 437272, "time": 13997.672810792923, "episode/length": 288.0, "episode/score": 0.04980615401655086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04980615401655086}
{"step": 437456, "time": 14003.522564172745, "episode/length": 288.0, "episode/score": 0.028487105802923907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028487105802923907}
{"step": 437480, "time": 14004.042895078659, "episode/length": 288.0, "episode/score": 0.03938938631290512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03938938631290512}
{"step": 437488, "time": 14004.50971364975, "episode/length": 288.0, "episode/score": 0.026884092338150367, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026884092338150367}
{"step": 437912, "time": 14017.358796596527, "episode/length": 288.0, "episode/score": 0.06458415193901601, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06458415193901601}
{"step": 438224, "time": 14027.117609977722, "episode/length": 288.0, "episode/score": 0.029043881095276447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029043881095276447}
{"step": 439080, "time": 14053.196209430695, "episode/length": 288.0, "episode/score": 0.03876495238364441, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03876495238364441}
{"step": 439232, "time": 14058.057700634003, "episode/length": 288.0, "episode/score": 0.028293742552705226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028293742552705226}
{"step": 439584, "time": 14068.825507640839, "episode/length": 288.0, "episode/score": 0.06526094929085957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06526094929085957}
{"step": 439768, "time": 14074.250003576279, "episode/length": 288.0, "episode/score": 0.03898777574613632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03898777574613632}
{"step": 439792, "time": 14075.344637393951, "episode/length": 288.0, "episode/score": 0.03902038784144679, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03902038784144679}
{"step": 439800, "time": 14075.37787103653, "episode/length": 288.0, "episode/score": 0.049804679216322256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049804679216322256}
{"step": 440024, "time": 14086.73927950859, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14086.74559879303, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14086.751111984253, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14086.756526708603, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14086.761683940887, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14086.767000436783, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14086.784955501556, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14086.78987455368, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440224, "time": 14093.156273841858, "episode/length": 288.0, "episode/score": 0.025780501186090987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025780501186090987}
{"step": 440536, "time": 14103.91510605812, "episode/length": 288.0, "episode/score": 0.03751682550955593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03751682550955593}
{"step": 441392, "time": 14130.728316783905, "episode/length": 288.0, "episode/score": 0.026519372734583158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026519372734583158}
{"step": 441544, "time": 14135.291819810867, "episode/length": 288.0, "episode/score": 0.04920329207016039, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04920329207016039}
{"step": 441896, "time": 14146.27062869072, "episode/length": 288.0, "episode/score": 0.051311886752955616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051311886752955616}
{"step": 442080, "time": 14152.17691373825, "episode/length": 288.0, "episode/score": 0.02876549320990307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02876549320990307}
{"step": 442104, "time": 14152.70323061943, "episode/length": 288.0, "episode/score": 0.04243560551731207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04243560551731207}
{"step": 442112, "time": 14153.176311254501, "episode/length": 288.0, "episode/score": 0.050870312386905425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050870312386905425}
{"step": 442536, "time": 14166.587425470352, "episode/length": 288.0, "episode/score": 0.05318488283228362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05318488283228362}
{"step": 442848, "time": 14176.383873462677, "episode/length": 288.0, "episode/score": 0.08997124371308018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08997124371308018}
{"step": 443704, "time": 14202.489795207977, "episode/length": 288.0, "episode/score": 0.04865281562979362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04865281562979362}
{"step": 443856, "time": 14207.376293420792, "episode/length": 288.0, "episode/score": 0.08219442212794092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08219442212794092}
{"step": 444208, "time": 14218.23721575737, "episode/length": 288.0, "episode/score": 0.04906540649244562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04906540649244562}
{"step": 444392, "time": 14223.683310747147, "episode/length": 288.0, "episode/score": 0.06383844407719153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06383844407719153}
{"step": 444416, "time": 14224.647631168365, "episode/length": 288.0, "episode/score": 0.04547433150764846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04547433150764846}
{"step": 444424, "time": 14224.680923938751, "episode/length": 288.0, "episode/score": 0.03163338633294188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03163338633294188}
{"step": 444729, "time": 14235.097202301025, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 0.2746853298611111, "train/action_min": 0.0, "train/action_std": 0.6146989028261165, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007165108550709945, "train/actor_opt_grad_steps": 26705.0, "train/actor_opt_loss": -8.25334782431824, "train/adv_mag": 0.02491153942214118, "train/adv_max": 0.006290391238048823, "train/adv_mean": -0.005268376966176385, "train/adv_min": -0.02387791300060773, "train/adv_std": 0.0027190624922043597, "train/cont_avg": 0.9960542929292929, "train/cont_loss_mean": 0.02548271840946241, "train/cont_loss_std": 0.33452405932952056, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.453070285946432, "train/cont_pos_acc": 0.9999999843462549, "train/cont_pos_loss": 0.003956651270408371, "train/cont_pred": 0.9960503587217042, "train/cont_rate": 0.9960542929292929, "train/dyn_loss_mean": 1.0427070266068583, "train/dyn_loss_std": 0.031151968499317364, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0678766065199549, "train/extr_critic_critic_opt_grad_steps": 26705.0, "train/extr_critic_critic_opt_loss": 10597.326178040168, "train/extr_critic_mag": 0.7887484690155646, "train/extr_critic_max": 0.7887484690155646, "train/extr_critic_mean": 0.77423797231732, "train/extr_critic_min": 0.7564040271922795, "train/extr_critic_std": 0.0049911167436147656, "train/extr_return_normed_mag": 0.020365585281391336, "train/extr_return_normed_max": 0.01573280252591528, "train/extr_return_normed_mean": -0.0011302003327783136, "train/extr_return_normed_min": -0.016496981635238186, "train/extr_return_normed_std": 0.005893007228903548, "train/extr_return_rate": 1.0, "train/extr_return_raw_mag": 0.7858325212892859, "train/extr_return_raw_max": 0.7858325212892859, "train/extr_return_raw_mean": 0.768969555394818, "train/extr_return_raw_min": 0.7536027371281325, "train/extr_return_raw_std": 0.005893007233607197, "train/extr_reward_mag": 0.004787201833243322, "train/extr_reward_max": 0.004787201833243322, "train/extr_reward_mean": 0.0007880941837981363, "train/extr_reward_min": 2.4607085218333234e-05, "train/extr_reward_std": 0.00021062838056946708, "train/image_loss_mean": 0.17252324175353, "train/image_loss_std": 0.09633066087509647, "train/model_loss_mean": 0.847048897634853, "train/model_loss_std": 0.45070267897663696, "train/model_opt_grad_norm": 27.869342924368503, "train/model_opt_grad_steps": 26678.560606060608, "train/model_opt_loss": 1647.223618324357, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2092.8030303030305, "train/policy_entropy_mag": 0.47148763888863604, "train/policy_entropy_max": 0.47148763888863604, "train/policy_entropy_mean": 0.13269163559031005, "train/policy_entropy_min": 0.06468695609105958, "train/policy_entropy_std": 0.10401688055636175, "train/policy_logprob_mag": 6.551079983663077, "train/policy_logprob_max": -0.008608225737745412, "train/policy_logprob_mean": -0.13216803078022268, "train/policy_logprob_min": -6.551079983663077, "train/policy_logprob_std": 0.6533363217657263, "train/policy_randomness_mag": 0.24229673029045867, "train/policy_randomness_max": 0.24229673029045867, "train/policy_randomness_mean": 0.06819001557023237, "train/policy_randomness_min": 0.03324252122429886, "train/policy_randomness_std": 0.05345410539934798, "train/post_ent_mag": 64.05359709383261, "train/post_ent_max": 64.05359709383261, "train/post_ent_mean": 63.69598854912652, "train/post_ent_min": 63.32468364214656, "train/post_ent_std": 0.12704222005876628, "train/prior_ent_mag": 64.17152439464222, "train/prior_ent_max": 64.17152439464222, "train/prior_ent_mean": 62.496293771146526, "train/prior_ent_min": 60.543088643237795, "train/prior_ent_std": 0.5509816814552654, "train/rep_loss_mean": 1.0427070266068583, "train/rep_loss_std": 0.031151968499317364, "train/reward_avg": 0.0009553471325562721, "train/reward_loss_mean": 0.023418701710085376, "train/reward_loss_std": 0.12766320172772563, "train/reward_max_data": 0.3744473067686112, "train/reward_max_pred": 0.042772585093373, "train/reward_neg_acc": 0.9999407608099659, "train/reward_neg_loss": 0.01897011992681508, "train/reward_pos_acc": 0.05863636393438686, "train/reward_pos_loss": 5.523655734278939, "train/reward_pred": 0.0008525593515551377, "train/reward_rate": 0.0008039378156565656, "train_stats/mean_log_entropy": 0.16113958385857668, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02474130690097809, "report/cont_loss_std": 0.32712244987487793, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.243708610534668, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00427476828917861, "report/cont_pred": 0.9957304000854492, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.20647501945495605, "report/image_loss_std": 0.08732929080724716, "report/model_loss_mean": 0.8620134592056274, "report/model_loss_std": 0.5403998494148254, "report/post_ent_mag": 93.5737075805664, "report/post_ent_max": 93.5737075805664, "report/post_ent_mean": 93.47891235351562, "report/post_ent_min": 93.10419464111328, "report/post_ent_std": 0.07481285184621811, "report/prior_ent_mag": 92.97549438476562, "report/prior_ent_max": 92.97549438476562, "report/prior_ent_mean": 92.03520202636719, "report/prior_ent_min": 89.813232421875, "report/prior_ent_std": 0.4615742266178131, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0019618922378867865, "report/reward_loss_mean": 0.030797094106674194, "report/reward_loss_std": 0.24251589179039001, "report/reward_max_data": 0.9087499976158142, "report/reward_max_pred": 0.009275674819946289, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.020192673429846764, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.4496564865112305, "report/reward_pred": 0.0009493145626038313, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.025648413226008415, "eval/cont_loss_std": 0.34363606572151184, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.512836456298828, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0041300272569060326, "eval/cont_pred": 0.9958791732788086, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0000227689743042, "eval/dyn_loss_std": 0.0006625468959100544, "eval/image_loss_mean": 0.23456165194511414, "eval/image_loss_std": 0.08486851304769516, "eval/model_loss_mean": 0.8636499643325806, "eval/model_loss_std": 0.35285279154777527, "eval/post_ent_mag": 93.58198547363281, "eval/post_ent_max": 93.58198547363281, "eval/post_ent_mean": 93.47523498535156, "eval/post_ent_min": 93.10398864746094, "eval/post_ent_std": 0.07580895721912384, "eval/prior_ent_mag": 93.01213836669922, "eval/prior_ent_max": 93.01213836669922, "eval/prior_ent_mean": 92.06062316894531, "eval/prior_ent_min": 89.813232421875, "eval/prior_ent_std": 0.4808369576931, "eval/rep_loss_mean": 1.0000227689743042, "eval/rep_loss_std": 0.0006625468959100544, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0034262151457369328, "eval/reward_loss_std": 0.002876593731343746, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0075452327728271484, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0034262151457369328, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0006892600795254111, "eval/reward_rate": 0.0, "replay/size": 444225.0, "replay/inserts": 31808.0, "replay/samples": 31808.0, "replay/insert_wait_avg": 1.16955376486903e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.582952079158913e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.748487461534476e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9401416778564, "timer/env.step_count": 3976.0, "timer/env.step_total": 33.793670654296875, "timer/env.step_frac": 0.033795693607811914, "timer/env.step_avg": 0.00849941414846501, "timer/env.step_min": 0.007195234298706055, "timer/env.step_max": 0.037819623947143555, "timer/replay._sample_count": 31808.0, "timer/replay._sample_total": 15.87012529373169, "timer/replay._sample_frac": 0.01587107530967034, "timer/replay._sample_avg": 0.000498935025582611, "timer/replay._sample_min": 0.000385284423828125, "timer/replay._sample_max": 0.010701417922973633, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4843.0, "timer/agent.policy_total": 40.72148370742798, "timer/agent.policy_frac": 0.040723921373032476, "timer/agent.policy_avg": 0.008408317924308895, "timer/agent.policy_min": 0.0073986053466796875, "timer/agent.policy_max": 0.06504464149475098, "timer/dataset_train_count": 1988.0, "timer/dataset_train_total": 0.2284409999847412, "timer/dataset_train_frac": 0.00022845467489826648, "timer/dataset_train_avg": 0.00011490995975087587, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.021006107330322266, "timer/agent.train_count": 1988.0, "timer/agent.train_total": 878.9707510471344, "timer/agent.train_frac": 0.8790233679110625, "timer/agent.train_avg": 0.44213820475207966, "timer/agent.train_min": 0.4313318729400635, "timer/agent.train_max": 1.740586519241333, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4728729724884033, "timer/agent.report_frac": 0.0004729012795655377, "timer/agent.report_avg": 0.23643648624420166, "timer/agent.report_min": 0.2304086685180664, "timer/agent.report_max": 0.24246430397033691, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7896643601162216e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 31.809360309012067}
{"step": 444848, "time": 14238.754421949387, "episode/length": 288.0, "episode/score": 0.032152383393622586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032152383393622586}
{"step": 445160, "time": 14248.094623088837, "episode/length": 288.0, "episode/score": 0.03879859988228418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03879859988228418}
{"step": 446016, "time": 14274.95216345787, "episode/length": 288.0, "episode/score": 0.03982772869858309, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03982772869858309}
{"step": 446168, "time": 14279.497121810913, "episode/length": 288.0, "episode/score": 0.03915242356561066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03915242356561066}
{"step": 446520, "time": 14290.610923290253, "episode/length": 288.0, "episode/score": 0.039600821315616486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039600821315616486}
{"step": 446704, "time": 14296.59563422203, "episode/length": 288.0, "episode/score": 0.03908089802644099, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03908089802644099}
{"step": 446728, "time": 14297.128451347351, "episode/length": 288.0, "episode/score": 0.042329195797719876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042329195797719876}
{"step": 446736, "time": 14297.607353687286, "episode/length": 288.0, "episode/score": 0.04969327652725042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04969327652725042}
{"step": 447160, "time": 14310.670889854431, "episode/length": 288.0, "episode/score": 0.049584979034989374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049584979034989374}
{"step": 447472, "time": 14320.589757680893, "episode/length": 288.0, "episode/score": 0.04955496313232288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04955496313232288}
{"step": 448328, "time": 14346.736980199814, "episode/length": 288.0, "episode/score": 0.028141967306510196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028141967306510196}
{"step": 448480, "time": 14351.650914669037, "episode/length": 288.0, "episode/score": 0.02890905461026705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02890905461026705}
{"step": 448832, "time": 14362.481969356537, "episode/length": 288.0, "episode/score": 0.042368003756564576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042368003756564576}
{"step": 449016, "time": 14367.924004793167, "episode/length": 288.0, "episode/score": 0.01257003138834989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01257003138834989}
{"step": 449040, "time": 14368.892975091934, "episode/length": 288.0, "episode/score": 0.030563053494006454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030563053494006454}
{"step": 449048, "time": 14368.92664527893, "episode/length": 288.0, "episode/score": 0.03222742421166913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03222742421166913}
{"step": 449472, "time": 14382.35400891304, "episode/length": 288.0, "episode/score": 0.11181771938572638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11181771938572638}
{"step": 449784, "time": 14391.750714302063, "episode/length": 288.0, "episode/score": 0.039611846749721735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039611846749721735}
{"step": 450008, "time": 14403.10726070404, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14403.11349439621, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14403.119065284729, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14403.124534845352, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14403.129788160324, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14403.13491988182, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14403.140706777573, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14403.15076828003, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450640, "time": 14423.441172361374, "episode/length": 288.0, "episode/score": 0.05026596380776027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05026596380776027}
{"step": 450792, "time": 14427.911175012589, "episode/length": 288.0, "episode/score": 0.05098581195488805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05098581195488805}
{"step": 451144, "time": 14438.846855640411, "episode/length": 288.0, "episode/score": 0.04916069407045143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04916069407045143}
{"step": 451328, "time": 14444.762574672699, "episode/length": 288.0, "episode/score": 0.07850329354187124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07850329354187124}
{"step": 451352, "time": 14445.285986423492, "episode/length": 288.0, "episode/score": 0.0421539615108486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0421539615108486}
{"step": 451360, "time": 14445.75700378418, "episode/length": 288.0, "episode/score": 0.07850887051245081, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07850887051245081}
{"step": 451784, "time": 14458.544626951218, "episode/length": 288.0, "episode/score": 0.04463170202143374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04463170202143374}
{"step": 452096, "time": 14468.450951814651, "episode/length": 288.0, "episode/score": 0.04562711465769098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04562711465769098}
{"step": 452952, "time": 14494.501696825027, "episode/length": 288.0, "episode/score": 0.04959101926215226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04959101926215226}
{"step": 453104, "time": 14499.479031562805, "episode/length": 288.0, "episode/score": 0.049542963763087755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049542963763087755}
{"step": 453456, "time": 14510.271186828613, "episode/length": 288.0, "episode/score": 0.049432165713369614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049432165713369614}
{"step": 453640, "time": 14515.682792425156, "episode/length": 288.0, "episode/score": 0.06732751070831, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06732751070831}
{"step": 453664, "time": 14516.6401720047, "episode/length": 288.0, "episode/score": 0.05701930466966587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05701930466966587}
{"step": 453672, "time": 14516.672827482224, "episode/length": 288.0, "episode/score": 0.07973396820671041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07973396820671041}
{"step": 454096, "time": 14529.978592395782, "episode/length": 288.0, "episode/score": 0.06973298695811536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06973298695811536}
{"step": 454408, "time": 14539.329139947891, "episode/length": 288.0, "episode/score": 0.07373701477808936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07373701477808936}
{"step": 455264, "time": 14566.02142381668, "episode/length": 288.0, "episode/score": 0.1522247753709962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1522247753709962}
{"step": 455416, "time": 14570.490568637848, "episode/length": 288.0, "episode/score": 0.16175653731261264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16175653731261264}
{"step": 455768, "time": 14581.363764047623, "episode/length": 288.0, "episode/score": 0.13014814384587226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13014814384587226}
{"step": 455952, "time": 14587.446105957031, "episode/length": 288.0, "episode/score": 0.19610975989508006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19610975989508006}
{"step": 455976, "time": 14587.98092341423, "episode/length": 288.0, "episode/score": 0.1921928146703067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1921928146703067}
{"step": 455984, "time": 14588.463146448135, "episode/length": 288.0, "episode/score": 0.16159082648118783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16159082648118783}
{"step": 456408, "time": 14601.503007888794, "episode/length": 288.0, "episode/score": 0.1729790462695746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1729790462695746}
{"step": 456720, "time": 14611.369445323944, "episode/length": 288.0, "episode/score": 0.12412497610512219, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12412497610512219}
{"step": 457000, "time": 14619.869112968445, "episode/length": 127.0, "episode/score": 0.7403602303756998, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.1372352565458641}
{"step": 457080, "time": 14622.347101926804, "episode/length": 140.0, "episode/score": 0.7043005778359657, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.1418005801642721}
{"step": 457576, "time": 14637.575437545776, "episode/length": 288.0, "episode/score": 0.2110296856185414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2110296856185414}
{"step": 457680, "time": 14640.979464530945, "episode/length": 238.0, "episode/score": 0.4269810547357338, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.1707310630245047}
{"step": 457728, "time": 14642.471834897995, "episode/length": 288.0, "episode/score": 0.24076751652410167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24076751652410167}
{"step": 458264, "time": 14658.808976888657, "episode/length": 231.0, "episode/score": 0.4655857901880154, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.18746080373875884}
{"step": 458296, "time": 14659.793207406998, "episode/length": 288.0, "episode/score": 0.20761360645155946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20761360645155946}
{"step": 458952, "time": 14680.483744382858, "episode/length": 278.0, "episode/score": 0.2818015326315617, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.15055153661296572}
{"step": 459312, "time": 14691.775493621826, "episode/length": 288.0, "episode/score": 0.14183201672312862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14183201672312862}
{"step": 459344, "time": 14692.755475521088, "episode/length": 48.0, "episode/score": 0.8808421957105566, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.03084217419700508}
{"step": 459392, "time": 14694.2269718647, "episode/length": 288.0, "episode/score": 0.19163950217648562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19163950217648562}
{"step": 459536, "time": 14698.655554056168, "episode/length": 23.0, "episode/score": 0.9379983049930161, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.009873252512988984}
{"step": 459888, "time": 14709.608561038971, "episode/length": 288.0, "episode/score": 0.17849207688050228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17849207688050228}
{"step": 459992, "time": 14712.607832670212, "episode/length": 288.0, "episode/score": 0.13181585458710288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13181585458710288}
{"step": 460040, "time": 14714.087118148804, "episode/length": 288.0, "episode/score": 0.10221955747010725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10221955747010725}
{"step": 460096, "time": 14717.235055446625, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 460096, "time": 14721.09507060051, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14721.101289987564, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14721.106733083725, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14721.112050533295, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14721.117113351822, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14721.12236237526, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14721.127492189407, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460576, "time": 14736.023268461227, "episode/length": 288.0, "episode/score": 0.15876759541811225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15876759541811225}
{"step": 460608, "time": 14737.032397508621, "episode/length": 288.0, "episode/score": 0.1322324613818182, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1322324613818182}
{"step": 460648, "time": 14738.046330451965, "episode/length": 156.0, "episode/score": 0.6302091719885539, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.11770918553929732}
{"step": 460784, "time": 14742.450304746628, "episode/length": 155.0, "episode/score": 0.6039735451847719, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0883485165466027}
{"step": 460944, "time": 14747.369104623795, "episode/length": 131.0, "episode/score": 0.6488300629860078, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.05820507572184397}
{"step": 461624, "time": 14768.067984580994, "episode/length": 288.0, "episode/score": 0.1452961689337826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1452961689337826}
{"step": 461808, "time": 14773.960325717926, "episode/length": 226.0, "episode/score": 0.4275562623303131, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.13380627588105654}
{"step": 462136, "time": 14783.853344917297, "episode/length": 63.0, "episode/score": 0.851877956796443, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.04875294587668577}
{"step": 462352, "time": 14790.727119922638, "episode/length": 288.0, "episode/score": 0.13789584852281678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13789584852281678}
{"step": 462448, "time": 14793.668699502945, "episode/length": 79.0, "episode/score": 0.7779748045061297, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.024849776228847986}
{"step": 462888, "time": 14807.08196425438, "episode/length": 288.0, "episode/score": 0.07196902983378095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07196902983378095}
{"step": 462920, "time": 14808.073295116425, "episode/length": 288.0, "episode/score": 0.11545335091830111, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11545335091830111}
{"step": 462960, "time": 14809.520540952682, "episode/length": 288.0, "episode/score": 0.08955830496051931, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08955830496051931}
{"step": 463096, "time": 14813.524223089218, "episode/length": 288.0, "episode/score": 0.07513320414307145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07513320414307145}
{"step": 463256, "time": 14818.463381290436, "episode/length": 288.0, "episode/score": 0.1169313399350358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1169313399350358}
{"step": 464104, "time": 14844.688014745712, "episode/length": 147.0, "episode/score": 0.5818462801512396, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.041221275354928366}
{"step": 464448, "time": 14855.582312583923, "episode/length": 288.0, "episode/score": 0.0829274294037532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0829274294037532}
{"step": 464664, "time": 14862.014798164368, "episode/length": 288.0, "episode/score": 0.11481591905749156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11481591905749156}
{"step": 464760, "time": 14864.984235525131, "episode/length": 288.0, "episode/score": 0.05977246077713971, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05977246077713971}
{"step": 465200, "time": 14878.805616617203, "episode/length": 288.0, "episode/score": 0.09086444380727698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09086444380727698}
{"step": 465272, "time": 14880.828360080719, "episode/length": 288.0, "episode/score": 0.15200071579386076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15200071579386076}
{"step": 465408, "time": 14885.354842662811, "episode/length": 288.0, "episode/score": 0.1320367713997257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1320367713997257}
{"step": 465568, "time": 14890.288577318192, "episode/length": 288.0, "episode/score": 0.05398932800790135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05398932800790135}
{"step": 465648, "time": 14892.749103069305, "episode/length": 149.0, "episode/score": 0.6202868903055787, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.08591188071295619}
{"step": 466416, "time": 14916.528043746948, "episode/length": 288.0, "episode/score": 0.08163334127516464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08163334127516464}
{"step": 466624, "time": 14922.939101457596, "episode/length": 25.0, "episode/score": 0.9329225845006022, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.011047585315509423}
{"step": 466784, "time": 14927.890649318695, "episode/length": 264.0, "episode/score": 0.25908418105223063, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.08408418519661609}
{"step": 467072, "time": 14937.292266845703, "episode/length": 288.0, "episode/score": 0.042137011912245725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042137011912245725}
{"step": 467496, "time": 14950.27190375328, "episode/length": 52.0, "episode/score": 0.867695082245973, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.030195107717645442}
{"step": 467512, "time": 14950.771098852158, "episode/length": 288.0, "episode/score": 0.07588591761498265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07588591761498265}
{"step": 467584, "time": 14953.209855556488, "episode/length": 288.0, "episode/score": 0.09747493745419433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09747493745419433}
{"step": 467720, "time": 14957.203032255173, "episode/length": 288.0, "episode/score": 0.06606080926690083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06606080926690083}
{"step": 467880, "time": 14962.143258571625, "episode/length": 288.0, "episode/score": 0.05133523503161541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05133523503161541}
{"step": 467960, "time": 14964.628666639328, "episode/length": 288.0, "episode/score": 0.07509636641532325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07509636641532325}
{"step": 468936, "time": 14994.692883491516, "episode/length": 288.0, "episode/score": 0.08581679667395292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08581679667395292}
{"step": 469096, "time": 14999.638426065445, "episode/length": 288.0, "episode/score": 0.0795994220185321, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0795994220185321}
{"step": 469808, "time": 15021.972047567368, "episode/length": 288.0, "episode/score": 0.08520071841826393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08520071841826393}
{"step": 469824, "time": 15022.468799591064, "episode/length": 288.0, "episode/score": 0.09395612578555301, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09395612578555301}
{"step": 469896, "time": 15024.478894233704, "episode/length": 288.0, "episode/score": 0.06199325006855361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06199325006855361}
{"step": 470032, "time": 15028.871009349823, "episode/length": 288.0, "episode/score": 0.07938467135386418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07938467135386418}
{"step": 470080, "time": 15034.041556358337, "eval_episode/length": 241.0, "eval_episode/score": 0.24687500298023224, "eval_episode/reward_rate": 0.004132231404958678}
{"step": 470080, "time": 15034.796213388443, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15034.802685499191, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15034.823871612549, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15034.829171180725, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15034.834371328354, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15034.85140967369, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15034.85659623146, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470192, "time": 15038.378719568253, "episode/length": 288.0, "episode/score": 0.022556476207341802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022556476207341802}
{"step": 470272, "time": 15040.822959899902, "episode/length": 288.0, "episode/score": 0.0967537584663205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0967537584663205}
{"step": 471248, "time": 15070.843005895615, "episode/length": 288.0, "episode/score": 0.07768888093357873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07768888093357873}
{"step": 471408, "time": 15075.791857481003, "episode/length": 288.0, "episode/score": 0.041247427587563834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041247427587563834}
{"step": 471424, "time": 15076.290732622147, "episode/length": 199.0, "episode/score": 0.4411734959654723, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.06304849696664405}
{"step": 472120, "time": 15097.653874397278, "episode/length": 288.0, "episode/score": 0.048486955633393336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048486955633393336}
{"step": 472208, "time": 15100.57956814766, "episode/length": 288.0, "episode/score": 0.08032723324072322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08032723324072322}
{"step": 472296, "time": 15103.080582857132, "episode/length": 110.0, "episode/score": 0.6913549648364778, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.035104945511534424}
{"step": 472344, "time": 15104.557497262955, "episode/length": 288.0, "episode/score": 0.07667911623036616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07667911623036616}
{"step": 472504, "time": 15109.488495111465, "episode/length": 288.0, "episode/score": 0.10450846196363273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10450846196363273}
{"step": 472584, "time": 15111.956096410751, "episode/length": 288.0, "episode/score": 0.059973085609385635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059973085609385635}
{"step": 472808, "time": 15118.85905623436, "episode/length": 74.0, "episode/score": 0.8429354164159122, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.07418540612479774}
{"step": 473184, "time": 15130.817023038864, "episode/length": 132.0, "episode/score": 0.6345793568485192, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.04707938112693455}
{"step": 473536, "time": 15141.832828760147, "episode/length": 90.0, "episode/score": 0.8071179960111863, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.08836797965483356}
{"step": 473560, "time": 15142.382849931717, "episode/length": 288.0, "episode/score": 0.14558577942489137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14558577942489137}
{"step": 473728, "time": 15147.78744316101, "episode/length": 178.0, "episode/score": 0.6071608541900559, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.16341086247882686}
{"step": 473736, "time": 15147.820131540298, "episode/length": 288.0, "episode/score": 0.1235078070943132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1235078070943132}
{"step": 473800, "time": 15149.777400970459, "episode/length": 181.0, "episode/score": 0.5687666669983287, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.13439168054907213}
{"step": 474632, "time": 15175.350989103317, "episode/length": 111.0, "episode/score": 0.7778621596999074, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.12473717325065081}
{"step": 474816, "time": 15181.207840919495, "episode/length": 288.0, "episode/score": 0.22167285602404263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22167285602404263}
{"step": 474896, "time": 15183.683177232742, "episode/length": 288.0, "episode/score": 0.24560799783762377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24560799783762377}
{"step": 475264, "time": 15195.610437631607, "episode/length": 182.0, "episode/score": 0.5883030203713133, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.15705301673915528}
{"step": 475480, "time": 15202.056080818176, "episode/length": 286.0, "episode/score": 0.3680597336744995, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.2618097323240818}
{"step": 475576, "time": 15205.009083747864, "episode/length": 94.0, "episode/score": 0.7954445831674093, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.08919454260831117}
{"step": 475824, "time": 15212.873114347458, "episode/length": 148.0, "episode/score": 0.6718216109338755, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.13432158942032402}
{"step": 475848, "time": 15213.401365756989, "episode/length": 288.0, "episode/score": 0.2109410296372971, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2109410296372971}
{"step": 475872, "time": 15214.359765768051, "episode/length": 288.0, "episode/score": 0.29029621385961946, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.19029621399931784}
{"step": 476040, "time": 15219.423090696335, "episode/length": 288.0, "episode/score": 0.2551713537068281, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2551713537068281}
{"step": 476328, "time": 15228.281145811081, "episode/length": 56.0, "episode/score": 0.8739223928987485, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.048922407147983904}
{"step": 476521, "time": 15235.179955005646, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.6093268466355213, "train/action_min": 0.0, "train/action_std": 1.2168861250182492, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011318469245666096, "train/actor_opt_grad_steps": 28690.0, "train/actor_opt_loss": -1.0955688254018525, "train/adv_mag": 0.2964831081467058, "train/adv_max": 0.20844715803711858, "train/adv_mean": 0.0057187551477790605, "train/adv_min": -0.20764088331155442, "train/adv_std": 0.029853045609873258, "train/cont_avg": 0.9959367148241206, "train/cont_loss_mean": 0.02555613859027774, "train/cont_loss_std": 0.3321354891274162, "train/cont_neg_acc": 0.004859086658273425, "train/cont_neg_loss": 5.345646169112653, "train/cont_pos_acc": 0.9999852126567208, "train/cont_pos_loss": 0.003865597394046996, "train/cont_pred": 0.9961168523409858, "train/cont_rate": 0.9959367148241206, "train/dyn_loss_mean": 1.0003266897632848, "train/dyn_loss_std": 0.004100599496136302, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7720015928577445, "train/extr_critic_critic_opt_grad_steps": 28690.0, "train/extr_critic_critic_opt_loss": 10644.67103093593, "train/extr_critic_mag": 0.7464215132459324, "train/extr_critic_max": 0.7464215132459324, "train/extr_critic_mean": 0.7258041725685848, "train/extr_critic_min": 0.7045315366294516, "train/extr_critic_std": 0.007713621684663634, "train/extr_return_normed_mag": 0.30165041481430205, "train/extr_return_normed_max": 0.24908827357555755, "train/extr_return_normed_mean": 0.03823581006178011, "train/extr_return_normed_min": -0.16976902742481711, "train/extr_return_normed_std": 0.03211089343431607, "train/extr_return_rate": 0.9953321449121638, "train/extr_return_raw_mag": 0.94237534993857, "train/extr_return_raw_max": 0.94237534993857, "train/extr_return_raw_mean": 0.7315229279312057, "train/extr_return_raw_min": 0.5235180489381953, "train/extr_return_raw_std": 0.032110893197975415, "train/extr_reward_mag": 0.2071542044979843, "train/extr_reward_max": 0.2071542044979843, "train/extr_reward_mean": 0.0028016189579505605, "train/extr_reward_min": 1.947903752926007e-05, "train/extr_reward_std": 0.012341296983427653, "train/image_loss_mean": 0.14421534871485964, "train/image_loss_std": 0.10514529569813953, "train/model_loss_mean": 0.7923584388728118, "train/model_loss_std": 0.414748779980082, "train/model_opt_grad_norm": 25.728730978079177, "train/model_opt_grad_steps": 28662.0, "train/model_opt_loss": 1432.311194031682, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1824.748743718593, "train/policy_entropy_mag": 1.1791959065363635, "train/policy_entropy_max": 1.1791959065363635, "train/policy_entropy_mean": 0.15022831956795113, "train/policy_entropy_min": 0.06468747631089772, "train/policy_entropy_std": 0.1661079062961569, "train/policy_logprob_mag": 6.551074389836297, "train/policy_logprob_max": -0.008608374449812887, "train/policy_logprob_mean": -0.1497645417237701, "train/policy_logprob_min": -6.551074389836297, "train/policy_logprob_std": 0.6795393054808804, "train/policy_randomness_mag": 0.6059868573655735, "train/policy_randomness_max": 0.6059868573655735, "train/policy_randomness_mean": 0.0772020885318368, "train/policy_randomness_min": 0.03324278846532855, "train/policy_randomness_std": 0.08536258269751172, "train/post_ent_mag": 28.26725454665908, "train/post_ent_max": 28.26725454665908, "train/post_ent_mean": 27.940532248223846, "train/post_ent_min": 27.60798956041959, "train/post_ent_std": 0.11988373559398867, "train/prior_ent_mag": 33.06614755985126, "train/prior_ent_max": 33.06614755985126, "train/prior_ent_mean": 27.662595988518028, "train/prior_ent_min": 25.421269733103077, "train/prior_ent_std": 1.0135442569627235, "train/rep_loss_mean": 1.0003266897632848, "train/rep_loss_std": 0.004100599496136302, "train/reward_avg": 0.0009037746663787987, "train/reward_loss_mean": 0.022390915431905932, "train/reward_loss_std": 0.11069213519406379, "train/reward_max_data": 0.33489822783278084, "train/reward_max_pred": 0.049477929445966407, "train/reward_neg_acc": 0.9998870632756296, "train/reward_neg_loss": 0.018665690354104317, "train/reward_pos_acc": 0.09166666686534881, "train/reward_pos_loss": 5.128297489881516, "train/reward_pred": 0.0007966070765882132, "train/reward_rate": 0.0007311950376884422, "train_stats/mean_log_entropy": 0.14192147801319757, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0314054861664772, "report/cont_loss_std": 0.3936212360858917, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.642775535583496, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0038717768620699644, "report/cont_pred": 0.9961376786231995, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1264374703168869, "report/image_loss_std": 0.10947754979133606, "report/model_loss_mean": 0.7753108739852905, "report/model_loss_std": 0.41160258650779724, "report/post_ent_mag": 9.712678909301758, "report/post_ent_max": 9.712678909301758, "report/post_ent_mean": 9.345139503479004, "report/post_ent_min": 8.983692169189453, "report/post_ent_std": 0.13133929669857025, "report/prior_ent_mag": 14.519186019897461, "report/prior_ent_max": 14.519186019897461, "report/prior_ent_mean": 8.781875610351562, "report/prior_ent_min": 6.598698616027832, "report/prior_ent_std": 0.9180010557174683, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004264534800313413, "report/reward_loss_mean": 0.017467867583036423, "report/reward_loss_std": 0.02507857047021389, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.010998368263244629, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.017467869445681572, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0006344141438603401, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.035165976732969284, "eval/cont_loss_std": 0.4089907705783844, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.350785255432129, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0038361994083970785, "eval/cont_pred": 0.996166467666626, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18868336081504822, "eval/image_loss_std": 0.1407081037759781, "eval/model_loss_mean": 0.8358873724937439, "eval/model_loss_std": 0.5991644859313965, "eval/post_ent_mag": 9.766337394714355, "eval/post_ent_max": 9.766337394714355, "eval/post_ent_mean": 9.372919082641602, "eval/post_ent_min": 8.978544235229492, "eval/post_ent_std": 0.1352512091398239, "eval/prior_ent_mag": 14.020364761352539, "eval/prior_ent_max": 14.020364761352539, "eval/prior_ent_mean": 8.901227951049805, "eval/prior_ent_min": 7.436918258666992, "eval/prior_ent_std": 0.7989815473556519, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0004638671816792339, "eval/reward_loss_mean": 0.012038039043545723, "eval/reward_loss_std": 0.2791997194290161, "eval/reward_max_data": 0.4749999940395355, "eval/reward_max_pred": 0.005430698394775391, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.003309402847662568, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.94143295288086, "eval/reward_pred": 0.0005610297666862607, "eval/reward_rate": 0.0009765625, "replay/size": 476017.0, "replay/inserts": 31792.0, "replay/samples": 31792.0, "replay/insert_wait_avg": 1.1903605511516077e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.608141440750068e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.371060126105532e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0646224021912, "timer/env.step_count": 3974.0, "timer/env.step_total": 33.97389626502991, "timer/env.step_frac": 0.033971700932109154, "timer/env.step_avg": 0.00854904284474834, "timer/env.step_min": 0.0071582794189453125, "timer/env.step_max": 0.05481100082397461, "timer/replay._sample_count": 31792.0, "timer/replay._sample_total": 15.979175329208374, "timer/replay._sample_frac": 0.01597814278323917, "timer/replay._sample_avg": 0.0005026162345624174, "timer/replay._sample_min": 0.0003597736358642578, "timer/replay._sample_max": 0.047553300857543945, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4841.0, "timer/agent.policy_total": 40.749053716659546, "timer/agent.policy_frac": 0.04074642058508065, "timer/agent.policy_avg": 0.008417486824346116, "timer/agent.policy_min": 0.0074024200439453125, "timer/agent.policy_max": 0.07334351539611816, "timer/dataset_train_count": 1987.0, "timer/dataset_train_total": 0.20609569549560547, "timer/dataset_train_frac": 0.0002060823779572926, "timer/dataset_train_avg": 0.00010372204101439631, "timer/dataset_train_min": 8.869171142578125e-05, "timer/dataset_train_max": 0.0003299713134765625, "timer/agent.train_count": 1987.0, "timer/agent.train_total": 878.7742767333984, "timer/agent.train_frac": 0.8787174918982246, "timer/agent.train_avg": 0.44226184032883664, "timer/agent.train_min": 0.4317903518676758, "timer/agent.train_max": 0.638739824295044, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48050665855407715, "timer/agent.report_frac": 0.00048047560906602506, "timer/agent.report_avg": 0.24025332927703857, "timer/agent.report_min": 0.23348093032836914, "timer/agent.report_max": 0.247025728225708, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.0038799787395674e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 31.78939251135019}
{"step": 476632, "time": 15238.384267807007, "episode/length": 143.0, "episode/score": 0.6712729881937776, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.11814796598173416}
{"step": 476768, "time": 15242.827486276627, "episode/length": 187.0, "episode/score": 0.5083054879405609, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0926804949021971}
{"step": 477208, "time": 15256.298292398453, "episode/length": 288.0, "episode/score": 0.17311172376867034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17311172376867034}
{"step": 477464, "time": 15264.197717428207, "episode/length": 141.0, "episode/score": 0.684368034309955, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.12499304786069843}
{"step": 477584, "time": 15268.11855340004, "episode/length": 219.0, "episode/score": 0.3940036723938647, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0783786739189054}
{"step": 477712, "time": 15272.063487052917, "episode/length": 232.0, "episode/score": 0.395846417478424, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.12084642199533846}
{"step": 477888, "time": 15277.629480600357, "episode/length": 288.0, "episode/score": 0.12060875540464622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12060875540464622}
{"step": 477896, "time": 15277.66239309311, "episode/length": 140.0, "episode/score": 0.6274860526300472, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.06498605306660465}
{"step": 477944, "time": 15279.148366212845, "episode/length": 163.0, "episode/score": 0.5957186164005179, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.10509362399079691}
{"step": 477984, "time": 15280.602660894394, "episode/length": 33.0, "episode/score": 0.9315443586838228, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.034669347764065606}
{"step": 478072, "time": 15283.097057819366, "episode/length": 107.0, "episode/score": 0.7249576156509647, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.05933265241492336}
{"step": 478320, "time": 15291.012149095535, "episode/length": 30.0, "episode/score": 0.9235650049699871, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.01731500578489431}
{"step": 478352, "time": 15292.040092468262, "episode/length": 288.0, "episode/score": 0.11495917452793947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11495917452793947}
{"step": 478712, "time": 15303.074139118195, "episode/length": 95.0, "episode/score": 0.7822490769781325, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.07912407779303976}
{"step": 478720, "time": 15303.55253124237, "episode/length": 103.0, "episode/score": 0.7412439157264998, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.06311890480674265}
{"step": 478848, "time": 15307.65067243576, "episode/length": 157.0, "episode/score": 0.5954634030099442, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.08608840752685865}
{"step": 479104, "time": 15315.544404506683, "episode/length": 97.0, "episode/score": 0.7669455745653977, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.07007059922216285}
{"step": 479304, "time": 15321.500404596329, "episode/length": 56.0, "episode/score": 0.8582786701858822, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.03327866575045846}
{"step": 479776, "time": 15336.376433849335, "episode/length": 288.0, "episode/score": 0.14810305842638627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14810305842638627}
{"step": 480064, "time": 15346.260914802551, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 480064, "time": 15346.328443527222, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 480064, "time": 15346.363696575165, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 480064, "time": 15346.980766057968, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 480064, "time": 15347.154232025146, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 480064, "time": 15347.174617290497, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 480064, "time": 15347.734279155731, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 480064, "time": 15348.89444231987, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 480168, "time": 15351.942810058594, "episode/length": 132.0, "episode/score": 0.7131595434573228, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.12565955298009612}
{"step": 480208, "time": 15353.425303697586, "episode/length": 288.0, "episode/score": 0.10304555812626859, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10304555812626859}
{"step": 480296, "time": 15355.973808526993, "episode/length": 288.0, "episode/score": 0.08945216886991147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08945216886991147}
{"step": 480512, "time": 15362.963879823685, "episode/length": 150.0, "episode/score": 0.657253499755825, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.12600348543674045}
{"step": 480560, "time": 15364.478927373886, "episode/length": 32.0, "episode/score": 0.9352687061245888, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.035268710641503276}
{"step": 480664, "time": 15367.61071062088, "episode/length": 288.0, "episode/score": 0.1274247692786048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1274247692786048}
{"step": 480872, "time": 15374.114488840103, "episode/length": 82.0, "episode/score": 0.829579917604633, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0858299181052189}
{"step": 480912, "time": 15375.605522155762, "episode/length": 92.0, "episode/score": 0.801195157511529, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.08869516202844352}
{"step": 481024, "time": 15379.115401029587, "episode/length": 288.0, "episode/score": 0.1273606494762589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1273606494762589}
{"step": 481032, "time": 15379.150047302246, "episode/length": 288.0, "episode/score": 0.12030155356546857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12030155356546857}
{"step": 481216, "time": 15385.134983778, "episode/length": 42.0, "episode/score": 0.914296265055782, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.045546291225946334}
{"step": 481352, "time": 15389.097161531448, "episode/length": 104.0, "episode/score": 0.7471836826643994, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0721836474021984}
{"step": 481936, "time": 15407.547189474106, "episode/length": 112.0, "episode/score": 0.7220514088060099, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.07205140325299908}
{"step": 482088, "time": 15412.018018484116, "episode/length": 288.0, "episode/score": 0.08554212936951444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08554212936951444}
{"step": 482120, "time": 15413.00370335579, "episode/length": 136.0, "episode/score": 0.6679930677757966, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.09299305030185678}
{"step": 482272, "time": 15417.89874958992, "episode/length": 41.0, "episode/score": 0.9046283934717394, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.03275340582922581}
{"step": 482408, "time": 15421.872905731201, "episode/length": 186.0, "episode/score": 0.5408495782526188, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.1220995905810014}
{"step": 482624, "time": 15428.856710672379, "episode/length": 26.0, "episode/score": 0.9398250132840076, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.021074996566767368}
{"step": 482872, "time": 15436.35950756073, "episode/length": 288.0, "episode/score": 0.10983887021757255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10983887021757255}
{"step": 482928, "time": 15438.302165031433, "episode/length": 81.0, "episode/score": 0.7761358404283101, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.029260844171062672}
{"step": 482936, "time": 15438.334772825241, "episode/length": 105.0, "episode/score": 0.7278766588880217, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.056001683044200945}
{"step": 482976, "time": 15439.779633760452, "episode/length": 288.0, "episode/score": 0.06577951893939371, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06577951893939371}
{"step": 483104, "time": 15443.727647781372, "episode/length": 122.0, "episode/score": 0.6670517861765575, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.048301795699330796}
{"step": 483200, "time": 15446.686337709427, "episode/length": 40.0, "episode/score": 0.9028607755385565, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.027860756213613058}
{"step": 483528, "time": 15457.21451830864, "episode/length": 288.0, "episode/score": 0.07799729428847968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07799729428847968}
{"step": 483624, "time": 15460.155182361603, "episode/length": 85.0, "episode/score": 0.8109040319428686, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.07652900330469947}
{"step": 483664, "time": 15461.624979257584, "episode/length": 288.0, "episode/score": 0.09723300128518986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09723300128518986}
{"step": 483952, "time": 15470.49403309822, "episode/length": 93.0, "episode/score": 0.7719548884698497, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.06257985644981545}
{"step": 484344, "time": 15482.325794696808, "episode/length": 84.0, "episode/score": 0.8000283168153146, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.06252832905056493}
{"step": 484376, "time": 15483.317797899246, "episode/length": 158.0, "episode/score": 0.5522323242341827, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.045982320532175436}
{"step": 484680, "time": 15492.828068494797, "episode/length": 90.0, "episode/score": 0.7970442599676062, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.07829426229591263}
{"step": 484696, "time": 15493.325377225876, "episode/length": 133.0, "episode/score": 0.6487533944934967, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.06437837228145327}
{"step": 484888, "time": 15499.234220027924, "episode/length": 63.0, "episode/score": 0.85999911128647, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.05687405880644292}
{"step": 484936, "time": 15500.729359149933, "episode/length": 288.0, "episode/score": 0.028653541771291202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028653541771291202}
{"step": 485240, "time": 15510.049349784851, "episode/length": 288.0, "episode/score": 0.06321513198577122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06321513198577122}
{"step": 485288, "time": 15511.51860332489, "episode/length": 288.0, "episode/score": 0.07665054823553419, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07665054823553419}
{"step": 485464, "time": 15517.02984547615, "episode/length": 71.0, "episode/score": 0.8426471235038662, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.06452213775310156}
{"step": 485464, "time": 15517.035367012024, "episode/length": 97.0, "episode/score": 0.7548913128853201, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.05801634964927871}
{"step": 485840, "time": 15528.814999818802, "episode/length": 288.0, "episode/score": 0.0981639160368104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0981639160368104}
{"step": 485920, "time": 15531.289036989212, "episode/length": 84.0, "episode/score": 0.8080282446862839, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.07052820412718575}
{"step": 486368, "time": 15545.228953838348, "episode/length": 65.0, "episode/score": 0.859695635978369, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.06282060734019979}
{"step": 486656, "time": 15554.094222545624, "episode/length": 288.0, "episode/score": 0.10819857646151831, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10819857646151831}
{"step": 487008, "time": 15564.996593952179, "episode/length": 288.0, "episode/score": 0.0788247058487741, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0788247058487741}
{"step": 487248, "time": 15572.381439208984, "episode/length": 288.0, "episode/score": 0.06660335439823939, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06660335439823939}
{"step": 487376, "time": 15576.443561315536, "episode/length": 45.0, "episode/score": 0.8945025788921157, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.03512757970702296}
{"step": 487600, "time": 15583.354338884354, "episode/length": 288.0, "episode/score": 0.09621702290564826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09621702290564826}
{"step": 487776, "time": 15588.76923942566, "episode/length": 288.0, "episode/score": 0.07506069283840588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07506069283840588}
{"step": 487776, "time": 15588.77663564682, "episode/length": 288.0, "episode/score": 0.10857741755194183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10857741755194183}
{"step": 488080, "time": 15598.090651035309, "episode/length": 59.0, "episode/score": 0.8728622945777715, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.05723728498514902}
{"step": 488232, "time": 15602.53696012497, "episode/length": 288.0, "episode/score": 0.07419902787114552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07419902787114552}
{"step": 488544, "time": 15612.434515953064, "episode/length": 57.0, "episode/score": 0.864848833315591, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.04297385878726345}
{"step": 488552, "time": 15612.466193199158, "episode/length": 39.0, "episode/score": 0.910663109114239, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.032538110115410745}
{"step": 488680, "time": 15616.398279190063, "episode/length": 288.0, "episode/score": 0.11770959742761988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11770959742761988}
{"step": 488968, "time": 15625.281497716904, "episode/length": 288.0, "episode/score": 0.12091166148843513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12091166148843513}
{"step": 489216, "time": 15633.100764274597, "episode/length": 83.0, "episode/score": 0.7723566947286145, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.03173168380885727}
{"step": 489312, "time": 15636.185561656952, "episode/length": 241.0, "episode/score": 0.3261083944116763, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.07923339259559725}
{"step": 489320, "time": 15636.220616340637, "episode/length": 258.0, "episode/score": 0.29578226649687167, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.10203227408715065}
{"step": 489416, "time": 15639.230919361115, "episode/length": 55.0, "episode/score": 0.859062755136847, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.030937738780494328}
{"step": 489520, "time": 15642.702353477478, "episode/length": 120.0, "episode/score": 0.7135476678283794, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0885476514720267}
{"step": 489760, "time": 15650.204023122787, "episode/length": 54.0, "episode/score": 0.8615396906761816, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.030289691677353403}
{"step": 490048, "time": 15659.17732000351, "episode/length": 78.0, "episode/score": 0.7979255942011605, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.041675571174209836}
{"step": 490048, "time": 15659.8306286335, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 490048, "time": 15659.835410356522, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 490048, "time": 15659.953472137451, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 490048, "time": 15660.039425373077, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 490048, "time": 15660.145651817322, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 490048, "time": 15660.360337734222, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 490048, "time": 15660.735924005508, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 490048, "time": 15660.951998472214, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 490088, "time": 15661.983670473099, "episode/length": 288.0, "episode/score": 0.11310556405373973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11310556405373973}
{"step": 490088, "time": 15661.99199104309, "episode/length": 288.0, "episode/score": 0.09947768726829054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09947768726829054}
{"step": 490096, "time": 15662.47228550911, "episode/length": 97.0, "episode/score": 0.7384003384897824, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.041525345975287564}
{"step": 490120, "time": 15663.002454519272, "episode/length": 74.0, "episode/score": 0.8094615774571139, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.04071154621124151}
{"step": 490456, "time": 15673.601219177246, "episode/length": 41.0, "episode/score": 0.8930863848395347, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0212113824413791}
{"step": 490608, "time": 15678.608589172363, "episode/length": 64.0, "episode/score": 0.8465820163805802, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.04658199014056663}
{"step": 490640, "time": 15679.608803033829, "episode/length": 73.0, "episode/score": 0.8372057866931755, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.06533074352637414}
{"step": 490688, "time": 15681.123718976974, "episode/length": 74.0, "episode/score": 0.8207110448831827, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.05196101660590102}
{"step": 490736, "time": 15682.622675418854, "episode/length": 79.0, "episode/score": 0.7716833903932638, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.018558359147391457}
{"step": 490760, "time": 15683.15574169159, "episode/length": 14.0, "episode/score": 0.9660393526651205, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.00978931740291955}
{"step": 490912, "time": 15688.117491483688, "episode/length": 37.0, "episode/score": 0.9221934282279562, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.037818432744870734}
{"step": 490992, "time": 15690.614898443222, "episode/length": 288.0, "episode/score": 0.09978662509411151, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09978662509411151}
{"step": 491064, "time": 15692.61666059494, "episode/length": 46.0, "episode/score": 0.8746355651182967, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.018385547644356848}
{"step": 491080, "time": 15693.117975234985, "episode/length": 77.0, "episode/score": 0.7786717917394981, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.019296816017913443}
{"step": 491360, "time": 15702.258996963501, "episode/length": 74.0, "episode/score": 0.8035904084017602, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.034840396917388716}
{"step": 491528, "time": 15707.4887342453, "episode/length": 288.0, "episode/score": 0.0308045593760653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0308045593760653}
{"step": 491696, "time": 15713.087317705154, "episode/length": 87.0, "episode/score": 0.7787196273852715, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0505946218322606}
{"step": 491816, "time": 15716.570715427399, "episode/length": 56.0, "episode/score": 0.8567171543809309, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.03171714697691641}
{"step": 491872, "time": 15718.501253843307, "episode/length": 42.0, "episode/score": 0.8890269950308038, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.020277019309219213}
{"step": 492072, "time": 15724.405965328217, "episode/length": 288.0, "episode/score": 0.0840878661882698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0840878661882698}
{"step": 492248, "time": 15729.900886774063, "episode/length": 53.0, "episode/score": 0.8569940603899795, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.022619060704300864}
{"step": 492344, "time": 15732.876109361649, "episode/length": 58.0, "episode/score": 0.8554928072751409, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.03674277525510661}
{"step": 492448, "time": 15736.310258865356, "episode/length": 93.0, "episode/score": 0.7521997035465802, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.042824672545179965}
{"step": 492960, "time": 15752.109327077866, "episode/length": 76.0, "episode/score": 0.8200593392772362, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.057559364120265855}
{"step": 493048, "time": 15754.587795734406, "episode/length": 288.0, "episode/score": 0.05733557415646828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05733557415646828}
{"step": 493224, "time": 15760.163176774979, "episode/length": 288.0, "episode/score": 0.09248637607333876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09248637607333876}
{"step": 493376, "time": 15765.08515572548, "episode/length": 288.0, "episode/score": 0.07041747817379473, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07041747817379473}
{"step": 493392, "time": 15765.607870817184, "episode/length": 288.0, "episode/score": 0.06973891269353771, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06973891269353771}
{"step": 493656, "time": 15773.525682210922, "episode/length": 150.0, "episode/score": 0.590426672368153, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0591766731830603}
{"step": 494152, "time": 15788.881980895996, "episode/length": 94.0, "episode/score": 0.7320382505231464, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.025788224283132877}
{"step": 494384, "time": 15796.234013080597, "episode/length": 288.0, "episode/score": 0.07733408565695754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07733408565695754}
{"step": 494560, "time": 15801.650050401688, "episode/length": 288.0, "episode/score": 0.11389552715945683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11389552715945683}
{"step": 494728, "time": 15806.59016084671, "episode/length": 71.0, "episode/score": 0.8037549492057678, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.025629944770344082}
{"step": 495272, "time": 15823.407311677933, "episode/length": 288.0, "episode/score": 0.08632857563134166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08632857563134166}
{"step": 495360, "time": 15826.343736171722, "episode/length": 288.0, "episode/score": 0.08276858089675443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08276858089675443}
{"step": 495536, "time": 15831.764449119568, "episode/length": 288.0, "episode/score": 0.07434006801304349, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07434006801304349}
{"step": 495688, "time": 15836.226000070572, "episode/length": 288.0, "episode/score": 0.08504269534887499, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08504269534887499}
{"step": 495968, "time": 15845.210784196854, "episode/length": 288.0, "episode/score": 0.1269574096920678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1269574096920678}
{"step": 496696, "time": 15867.340931892395, "episode/length": 288.0, "episode/score": 0.0982605493270512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0982605493270512}
{"step": 496872, "time": 15872.768206834793, "episode/length": 288.0, "episode/score": 0.05476611958874855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05476611958874855}
{"step": 497040, "time": 15878.272995710373, "episode/length": 288.0, "episode/score": 0.05206197429174608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05206197429174608}
{"step": 497584, "time": 15895.014062404633, "episode/length": 288.0, "episode/score": 0.10288939692236454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10288939692236454}
{"step": 497672, "time": 15897.493581533432, "episode/length": 288.0, "episode/score": 0.07385191794412549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07385191794412549}
{"step": 497848, "time": 15902.895310401917, "episode/length": 288.0, "episode/score": 0.07056469113217645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07056469113217645}
{"step": 498000, "time": 15907.907557725906, "episode/length": 288.0, "episode/score": 0.07213288854245548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07213288854245548}
{"step": 498280, "time": 15916.300882816315, "episode/length": 288.0, "episode/score": 0.0964182395532589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0964182395532589}
{"step": 499008, "time": 15939.184504508972, "episode/length": 288.0, "episode/score": 0.08118370237139061, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08118370237139061}
{"step": 499184, "time": 15944.579779863358, "episode/length": 288.0, "episode/score": 0.06626061372617187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06626061372617187}
{"step": 499352, "time": 15949.565326213837, "episode/length": 288.0, "episode/score": 0.033104964807989745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033104964807989745}
{"step": 499896, "time": 15966.843027353287, "episode/length": 288.0, "episode/score": 0.06404712667040258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06404712667040258}
{"step": 499984, "time": 15969.769856452942, "episode/length": 288.0, "episode/score": 0.05130759841995314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05130759841995314}
{"step": 500032, "time": 15976.382722616196, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15976.389174461365, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15976.394824504852, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15976.400604486465, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15976.408519268036, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15976.41449022293, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15976.419739484787, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15976.425307035446, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500160, "time": 15980.391079902649, "episode/length": 288.0, "episode/score": 0.036497501908570484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036497501908570484}
{"step": 500312, "time": 15984.859771251678, "episode/length": 288.0, "episode/score": 0.04734270805306551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04734270805306551}
{"step": 500592, "time": 15993.713185548782, "episode/length": 288.0, "episode/score": 0.08703208122858541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08703208122858541}
{"step": 501320, "time": 16016.07086133957, "episode/length": 288.0, "episode/score": 0.08614925370636684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08614925370636684}
{"step": 501496, "time": 16021.48986005783, "episode/length": 288.0, "episode/score": 0.049779712387589825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049779712387589825}
{"step": 501664, "time": 16026.960158586502, "episode/length": 288.0, "episode/score": 0.08384019193772474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08384019193772474}
{"step": 502208, "time": 16043.669601678848, "episode/length": 288.0, "episode/score": 0.1258695798202325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1258695798202325}
{"step": 502296, "time": 16046.146632909775, "episode/length": 288.0, "episode/score": 0.08732756354424964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08732756354424964}
{"step": 502472, "time": 16051.54364323616, "episode/length": 288.0, "episode/score": 0.06548932295436316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06548932295436316}
{"step": 502624, "time": 16056.51938033104, "episode/length": 288.0, "episode/score": 0.09633122395530336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09633122395530336}
{"step": 502904, "time": 16064.890490055084, "episode/length": 288.0, "episode/score": 0.1183567864983388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1183567864983388}
{"step": 503632, "time": 16087.523211717606, "episode/length": 288.0, "episode/score": 0.09843359649880767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09843359649880767}
{"step": 503808, "time": 16092.914205312729, "episode/length": 288.0, "episode/score": 0.107848635852406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.107848635852406}
{"step": 503976, "time": 16097.89345741272, "episode/length": 288.0, "episode/score": 0.0876040329717398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0876040329717398}
{"step": 504520, "time": 16114.572828292847, "episode/length": 288.0, "episode/score": 0.15235184210087027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15235184210087027}
{"step": 504608, "time": 16117.641550540924, "episode/length": 288.0, "episode/score": 0.1413665340855914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1413665340855914}
{"step": 504784, "time": 16123.05036497116, "episode/length": 288.0, "episode/score": 0.13091223237552185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13091223237552185}
{"step": 504936, "time": 16127.4994866848, "episode/length": 288.0, "episode/score": 0.17318798661108303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17318798661108303}
{"step": 505216, "time": 16136.280139923096, "episode/length": 288.0, "episode/score": 0.1594886299492373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1594886299492373}
{"step": 505944, "time": 16158.446145534515, "episode/length": 288.0, "episode/score": 0.10365479065944783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10365479065944783}
{"step": 506120, "time": 16163.840743780136, "episode/length": 288.0, "episode/score": 0.1364921709682676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1364921709682676}
{"step": 506288, "time": 16169.188479661942, "episode/length": 288.0, "episode/score": 0.11836470298135282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11836470298135282}
{"step": 506832, "time": 16185.924211978912, "episode/length": 288.0, "episode/score": 0.12272505633177389, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12272505633177389}
{"step": 506920, "time": 16188.400959253311, "episode/length": 288.0, "episode/score": 0.11227200017117411, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11227200017117411}
{"step": 507096, "time": 16193.799749851227, "episode/length": 288.0, "episode/score": 0.08095706972665084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08095706972665084}
{"step": 507248, "time": 16198.700288772583, "episode/length": 288.0, "episode/score": 0.13887029145621455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13887029145621455}
{"step": 507528, "time": 16207.227720499039, "episode/length": 288.0, "episode/score": 0.14113556771530966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14113556771530966}
{"step": 508256, "time": 16230.376583576202, "episode/length": 288.0, "episode/score": 0.19417426771497048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19417426771497048}
{"step": 508393, "time": 16235.37661242485, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.197987312048524, "train/action_min": 0.0, "train/action_std": 1.6527446454493844, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012325899452017855, "train/actor_opt_grad_steps": 30680.0, "train/actor_opt_loss": -4.555679954026812, "train/adv_mag": 0.4387992997864383, "train/adv_max": 0.25335710132541367, "train/adv_mean": 0.007012837905772838, "train/adv_min": -0.38988818445397383, "train/adv_std": 0.037815434883943004, "train/cont_avg": 0.9959956030150754, "train/cont_loss_mean": 0.023853463601629862, "train/cont_loss_std": 0.3168075637735108, "train/cont_neg_acc": 0.038566594877218835, "train/cont_neg_loss": 4.978974106348105, "train/cont_pos_acc": 0.9999802786501208, "train/cont_pos_loss": 0.0038315933256236902, "train/cont_pred": 0.9960342852314513, "train/cont_rate": 0.9959956030150754, "train/dyn_loss_mean": 1.0000501403856517, "train/dyn_loss_std": 0.0012293210570190345, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.6797560745307324, "train/extr_critic_critic_opt_grad_steps": 30680.0, "train/extr_critic_critic_opt_loss": 10648.075763338175, "train/extr_critic_mag": 1.0918797925489032, "train/extr_critic_max": 1.0918797925489032, "train/extr_critic_mean": 1.0397516605842054, "train/extr_critic_min": 0.979826827145102, "train/extr_critic_std": 0.016913497446095525, "train/extr_return_normed_mag": 0.4308360356781351, "train/extr_return_normed_max": 0.3218622755764717, "train/extr_return_normed_mean": 0.05439851968432192, "train/extr_return_normed_min": -0.32671389657648364, "train/extr_return_normed_std": 0.04392929347559585, "train/extr_return_rate": 0.9977573671532636, "train/extr_return_raw_mag": 1.314228199235159, "train/extr_return_raw_max": 1.314228199235159, "train/extr_return_raw_mean": 1.0467644890948156, "train/extr_return_raw_min": 0.6656520270822036, "train/extr_return_raw_std": 0.04392929346623582, "train/extr_reward_mag": 0.2746492246886594, "train/extr_reward_max": 0.2746492246886594, "train/extr_reward_mean": 0.0030577468095539166, "train/extr_reward_min": 1.0870209890394354e-05, "train/extr_reward_std": 0.015092014101387736, "train/image_loss_mean": 0.12228451556895846, "train/image_loss_std": 0.1089994304219083, "train/model_loss_mean": 0.7686284474991075, "train/model_loss_std": 0.4053491947788689, "train/model_opt_grad_norm": 24.64264577357613, "train/model_opt_grad_steps": 30651.336683417085, "train/model_opt_loss": 2810.7923442898086, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3668.3417085427136, "train/policy_entropy_mag": 1.41018517412732, "train/policy_entropy_max": 1.41018517412732, "train/policy_entropy_mean": 0.16687637822112844, "train/policy_entropy_min": 0.06468669055544551, "train/policy_entropy_std": 0.20273115429746447, "train/policy_logprob_mag": 6.551080212521193, "train/policy_logprob_max": -0.00860820925471621, "train/policy_logprob_mean": -0.16711485067653895, "train/policy_logprob_min": -6.551080212521193, "train/policy_logprob_std": 0.6959951948280909, "train/policy_randomness_mag": 0.724691866330765, "train/policy_randomness_max": 0.724691866330765, "train/policy_randomness_mean": 0.08575749936415322, "train/policy_randomness_min": 0.033242385010773215, "train/policy_randomness_std": 0.10418321005064039, "train/post_ent_mag": 10.329305021008055, "train/post_ent_max": 10.329305021008055, "train/post_ent_mean": 9.959955752195425, "train/post_ent_min": 9.561184044459358, "train/post_ent_std": 0.14646486952975768, "train/prior_ent_mag": 15.720174621697048, "train/prior_ent_max": 15.720174621697048, "train/prior_ent_mean": 8.921881670927881, "train/prior_ent_min": 6.5926065828332945, "train/prior_ent_std": 1.1542725961412017, "train/rep_loss_mean": 1.0000501403856517, "train/rep_loss_std": 0.0012293210570190345, "train/reward_avg": 0.0010018398430685152, "train/reward_loss_mean": 0.02246036505017748, "train/reward_loss_std": 0.11285637043903221, "train/reward_max_data": 0.40491994976735296, "train/reward_max_pred": 0.11326314396594638, "train/reward_neg_acc": 0.9998722983964125, "train/reward_neg_loss": 0.01853732435248006, "train/reward_pos_acc": 0.2159420301084933, "train/reward_pos_loss": 4.416269576031229, "train/reward_pred": 0.0008615719303067531, "train/reward_rate": 0.0008931375628140703, "train_stats/mean_log_entropy": 0.12383434991791563, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014147905632853508, "report/cont_loss_std": 0.25124743580818176, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.6299638748168945, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003158051520586014, "report/cont_pred": 0.9968514442443848, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1101442202925682, "report/image_loss_std": 0.11247081309556961, "report/model_loss_mean": 0.7419437170028687, "report/model_loss_std": 0.2774450182914734, "report/post_ent_mag": 11.329084396362305, "report/post_ent_max": 11.329084396362305, "report/post_ent_mean": 10.944002151489258, "report/post_ent_min": 10.508747100830078, "report/post_ent_std": 0.14905701577663422, "report/prior_ent_mag": 17.49919891357422, "report/prior_ent_max": 17.49919891357422, "report/prior_ent_mean": 9.08627700805664, "report/prior_ent_min": 6.323294639587402, "report/prior_ent_std": 1.547934889793396, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004318961873650551, "report/reward_loss_mean": 0.01765161007642746, "report/reward_loss_std": 0.025678882375359535, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.013418078422546387, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01765161007642746, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0006123785860836506, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.004049613140523434, "eval/cont_loss_std": 0.006208215840160847, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004049613140523434, "eval/cont_pred": 0.9959774613380432, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22229936718940735, "eval/image_loss_std": 0.12863987684249878, "eval/model_loss_mean": 0.8292735815048218, "eval/model_loss_std": 0.12945467233657837, "eval/post_ent_mag": 11.313851356506348, "eval/post_ent_max": 11.313851356506348, "eval/post_ent_mean": 10.997879028320312, "eval/post_ent_min": 10.543743133544922, "eval/post_ent_std": 0.13991884887218475, "eval/prior_ent_mag": 15.710029602050781, "eval/prior_ent_max": 15.710029602050781, "eval/prior_ent_mean": 8.964981079101562, "eval/prior_ent_min": 6.714479446411133, "eval/prior_ent_std": 1.2692089080810547, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.002924604807049036, "eval/reward_loss_std": 0.00313211465254426, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.015032768249511719, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002924604807049036, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00048680289182811975, "eval/reward_rate": 0.0, "replay/size": 507889.0, "replay/inserts": 31872.0, "replay/samples": 31872.0, "replay/insert_wait_avg": 1.1977257139711495e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.723843357170442e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4984.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0232768510356186e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1790919303894, "timer/env.step_count": 3984.0, "timer/env.step_total": 34.033162355422974, "timer/env.step_frac": 0.03402706838206094, "timer/env.step_avg": 0.008542460430578056, "timer/env.step_min": 0.007139921188354492, "timer/env.step_max": 0.04655766487121582, "timer/replay._sample_count": 31872.0, "timer/replay._sample_total": 16.032420873641968, "timer/replay._sample_frac": 0.01602955011056939, "timer/replay._sample_avg": 0.0005030252533145698, "timer/replay._sample_min": 0.0004088878631591797, "timer/replay._sample_max": 0.03564095497131348, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4607.0, "timer/agent.policy_total": 39.03597974777222, "timer/agent.policy_frac": 0.03902898997061723, "timer/agent.policy_avg": 0.008473188571255093, "timer/agent.policy_min": 0.007387876510620117, "timer/agent.policy_max": 0.07721781730651855, "timer/dataset_train_count": 1992.0, "timer/dataset_train_total": 0.20733213424682617, "timer/dataset_train_frac": 0.0002072950093834356, "timer/dataset_train_avg": 0.00010408239671025411, "timer/dataset_train_min": 8.726119995117188e-05, "timer/dataset_train_max": 0.0004620552062988281, "timer/agent.train_count": 1992.0, "timer/agent.train_total": 881.828577041626, "timer/agent.train_frac": 0.8816706769381254, "timer/agent.train_avg": 0.4426850286353544, "timer/agent.train_min": 0.43210482597351074, "timer/agent.train_max": 0.59248948097229, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4857902526855469, "timer/agent.report_frac": 0.0004857032671498366, "timer/agent.report_avg": 0.24289512634277344, "timer/agent.report_min": 0.241347074508667, "timer/agent.report_max": 0.24444317817687988, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.6716461181640625e-05, "timer/dataset_eval_frac": 3.670988673716049e-08, "timer/dataset_eval_avg": 3.6716461181640625e-05, "timer/dataset_eval_min": 3.6716461181640625e-05, "timer/dataset_eval_max": 3.6716461181640625e-05, "fps": 31.865695645974423}
{"step": 508432, "time": 16236.594057559967, "episode/length": 288.0, "episode/score": 0.1551388517052601, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1551388517052601}
{"step": 508600, "time": 16241.571454763412, "episode/length": 288.0, "episode/score": 0.09643032489793768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09643032489793768}
{"step": 509144, "time": 16258.300514698029, "episode/length": 288.0, "episode/score": 0.10721617936349048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10721617936349048}
{"step": 509232, "time": 16261.240516424179, "episode/length": 288.0, "episode/score": 0.1304530781685571, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1304530781685571}
{"step": 509408, "time": 16266.739255189896, "episode/length": 288.0, "episode/score": 0.12659736885632356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12659736885632356}
{"step": 509560, "time": 16271.19725394249, "episode/length": 288.0, "episode/score": 0.1780343484082323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1780343484082323}
{"step": 509840, "time": 16280.036667346954, "episode/length": 288.0, "episode/score": 0.08906454779923934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08906454779923934}
{"step": 510016, "time": 16290.039417266846, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16290.046076774597, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16290.051987886429, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16290.057547092438, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16290.063035488129, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16290.06837797165, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16290.073873996735, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16290.079313993454, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510568, "time": 16306.972270965576, "episode/length": 288.0, "episode/score": 0.15165984489635775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15165984489635775}
{"step": 510744, "time": 16312.379930257797, "episode/length": 288.0, "episode/score": 0.1288995547357672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1288995547357672}
{"step": 510912, "time": 16317.761805772781, "episode/length": 288.0, "episode/score": 0.1313859829795092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1313859829795092}
{"step": 511456, "time": 16334.554997682571, "episode/length": 288.0, "episode/score": 0.1066446002757857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1066446002757857}
{"step": 511544, "time": 16337.059510469437, "episode/length": 288.0, "episode/score": 0.10255755026753377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10255755026753377}
{"step": 511720, "time": 16342.464263439178, "episode/length": 288.0, "episode/score": 0.09394986857193999, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09394986857193999}
{"step": 511872, "time": 16347.354677438736, "episode/length": 288.0, "episode/score": 0.11162166953522501, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11162166953522501}
{"step": 512152, "time": 16355.833196401596, "episode/length": 288.0, "episode/score": 0.0823371387490397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0823371387490397}
{"step": 512880, "time": 16378.384500265121, "episode/length": 288.0, "episode/score": 0.09864709583018794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09864709583018794}
{"step": 513056, "time": 16383.790748357773, "episode/length": 288.0, "episode/score": 0.15097511201156522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15097511201156522}
{"step": 513224, "time": 16388.850182294846, "episode/length": 288.0, "episode/score": 0.10327383857156747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10327383857156747}
{"step": 513768, "time": 16405.61523795128, "episode/length": 288.0, "episode/score": 0.08616470249774011, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08616470249774011}
{"step": 513856, "time": 16408.53663134575, "episode/length": 288.0, "episode/score": 0.110690316382545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.110690316382545}
{"step": 514032, "time": 16413.98990702629, "episode/length": 288.0, "episode/score": 0.09130346832830583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09130346832830583}
{"step": 514184, "time": 16418.542678117752, "episode/length": 288.0, "episode/score": 0.05963563321103038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05963563321103038}
{"step": 514464, "time": 16427.394426822662, "episode/length": 288.0, "episode/score": 0.08448722330450664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08448722330450664}
{"step": 515192, "time": 16449.701218128204, "episode/length": 288.0, "episode/score": 0.07127293537712376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07127293537712376}
{"step": 515368, "time": 16455.156777620316, "episode/length": 288.0, "episode/score": 0.09285056322408991, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09285056322408991}
{"step": 515536, "time": 16460.550830841064, "episode/length": 288.0, "episode/score": 0.05445527709338194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05445527709338194}
{"step": 516080, "time": 16477.395961999893, "episode/length": 288.0, "episode/score": 0.044542298358976495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044542298358976495}
{"step": 516168, "time": 16480.39430117607, "episode/length": 288.0, "episode/score": 0.04271311710493819, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04271311710493819}
{"step": 516344, "time": 16485.81086373329, "episode/length": 288.0, "episode/score": 0.04891665651632593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04891665651632593}
{"step": 516496, "time": 16490.73861169815, "episode/length": 288.0, "episode/score": 0.07721992906289188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07721992906289188}
{"step": 516776, "time": 16499.128460407257, "episode/length": 288.0, "episode/score": 0.02561190707501737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02561190707501737}
{"step": 517504, "time": 16521.80971956253, "episode/length": 288.0, "episode/score": 0.028548327771261484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028548327771261484}
{"step": 517680, "time": 16527.224836587906, "episode/length": 288.0, "episode/score": 0.044012258972315976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044012258972315976}
{"step": 517848, "time": 16532.173286676407, "episode/length": 288.0, "episode/score": 0.03918125742666234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03918125742666234}
{"step": 518392, "time": 16549.01268672943, "episode/length": 288.0, "episode/score": 0.038456216104577834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038456216104577834}
{"step": 518480, "time": 16551.929141044617, "episode/length": 288.0, "episode/score": 0.0208278646692861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0208278646692861}
{"step": 518656, "time": 16557.337656497955, "episode/length": 288.0, "episode/score": 0.05347708775934734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05347708775934734}
{"step": 518808, "time": 16561.80131840706, "episode/length": 288.0, "episode/score": 0.014750922759958485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014750922759958485}
{"step": 519088, "time": 16570.882521152496, "episode/length": 288.0, "episode/score": 0.03405616684051438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03405616684051438}
{"step": 519816, "time": 16593.18006682396, "episode/length": 288.0, "episode/score": 0.04952582236194303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04952582236194303}
{"step": 519992, "time": 16598.71762561798, "episode/length": 288.0, "episode/score": 0.03433901028222408, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03433901028222408}
{"step": 520000, "time": 16603.74943780899, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 16603.755972146988, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 16603.76136803627, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 16603.767143011093, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 16603.772535562515, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 16603.778022289276, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 16603.78351378441, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 16603.789004564285, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520160, "time": 16608.711017370224, "episode/length": 288.0, "episode/score": 0.02906302194799082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02906302194799082}
{"step": 520704, "time": 16625.56307077408, "episode/length": 288.0, "episode/score": 0.03473956414609347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03473956414609347}
{"step": 520792, "time": 16628.08106803894, "episode/length": 288.0, "episode/score": 0.046674642588527604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046674642588527604}
{"step": 520968, "time": 16633.576545238495, "episode/length": 288.0, "episode/score": 0.0439304170554351, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0439304170554351}
{"step": 521120, "time": 16638.556614875793, "episode/length": 288.0, "episode/score": 0.02839748908081674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02839748908081674}
{"step": 521400, "time": 16646.987414598465, "episode/length": 288.0, "episode/score": 0.04207497506143909, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04207497506143909}
{"step": 522128, "time": 16669.69836616516, "episode/length": 288.0, "episode/score": 0.032511346618377956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032511346618377956}
{"step": 522304, "time": 16675.19275379181, "episode/length": 288.0, "episode/score": 0.014433870432185358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014433870432185358}
{"step": 522472, "time": 16680.133925437927, "episode/length": 288.0, "episode/score": 0.02143476229116459, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02143476229116459}
{"step": 523016, "time": 16696.94698357582, "episode/length": 288.0, "episode/score": 0.04641923125006997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04641923125006997}
{"step": 523104, "time": 16699.86588025093, "episode/length": 288.0, "episode/score": 0.04957674974502879, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04957674974502879}
{"step": 523280, "time": 16705.316653966904, "episode/length": 288.0, "episode/score": 0.05062557114018773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05062557114018773}
{"step": 523432, "time": 16709.843802928925, "episode/length": 288.0, "episode/score": 0.027177699003402722, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027177699003402722}
{"step": 523712, "time": 16718.855647802353, "episode/length": 288.0, "episode/score": 0.06322673854157301, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06322673854157301}
{"step": 524440, "time": 16741.52062034607, "episode/length": 288.0, "episode/score": 0.06479184600084409, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06479184600084409}
{"step": 524616, "time": 16747.019181489944, "episode/length": 288.0, "episode/score": 0.07933167472310743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07933167472310743}
{"step": 524784, "time": 16752.426522254944, "episode/length": 288.0, "episode/score": 0.04670630295186129, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04670630295186129}
{"step": 525328, "time": 16769.129298448563, "episode/length": 288.0, "episode/score": 0.08793166458360702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08793166458360702}
{"step": 525416, "time": 16771.628936767578, "episode/length": 288.0, "episode/score": 0.07330034573885769, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07330034573885769}
{"step": 525592, "time": 16777.16304755211, "episode/length": 288.0, "episode/score": 0.10816414065789104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10816414065789104}
{"step": 525744, "time": 16782.069157123566, "episode/length": 288.0, "episode/score": 0.08563264358610922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08563264358610922}
{"step": 526024, "time": 16790.46383213997, "episode/length": 288.0, "episode/score": 0.09735997824782316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09735997824782316}
{"step": 526752, "time": 16813.202048301697, "episode/length": 288.0, "episode/score": 0.13992365938918283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13992365938918283}
{"step": 526928, "time": 16818.630812883377, "episode/length": 288.0, "episode/score": 0.09599830588263103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09599830588263103}
{"step": 527096, "time": 16823.58346748352, "episode/length": 288.0, "episode/score": 0.14117758619647702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14117758619647702}
{"step": 527640, "time": 16840.441910982132, "episode/length": 288.0, "episode/score": 0.1349097756461788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1349097756461788}
{"step": 527728, "time": 16843.36992263794, "episode/length": 288.0, "episode/score": 0.12935150799694384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12935150799694384}
{"step": 527904, "time": 16848.787636756897, "episode/length": 288.0, "episode/score": 0.11435618974883255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11435618974883255}
{"step": 528056, "time": 16853.26290988922, "episode/length": 288.0, "episode/score": 0.14328049188884506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14328049188884506}
{"step": 528336, "time": 16862.09281539917, "episode/length": 288.0, "episode/score": 0.1743334436469013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1743334436469013}
{"step": 529064, "time": 16884.562289476395, "episode/length": 288.0, "episode/score": 0.11767154967185434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11767154967185434}
{"step": 529240, "time": 16890.094285964966, "episode/length": 288.0, "episode/score": 0.11785192011552681, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11785192011552681}
{"step": 529408, "time": 16895.734803915024, "episode/length": 288.0, "episode/score": 0.10682287598876883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10682287598876883}
{"step": 529952, "time": 16912.766702890396, "episode/length": 288.0, "episode/score": 0.16213706205724066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16213706205724066}
{"step": 530040, "time": 16915.316419363022, "episode/length": 288.0, "episode/score": 0.08802656824082078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08802656824082078}
{"step": 530088, "time": 16921.499182462692, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 16921.506365299225, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 16921.51266503334, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 16921.518409252167, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 16921.52389550209, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 16921.529808998108, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 16921.53554058075, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 16921.541389465332, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530216, "time": 16925.71541118622, "episode/length": 288.0, "episode/score": 0.10453159669367551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10453159669367551}
{"step": 530368, "time": 16930.62959742546, "episode/length": 288.0, "episode/score": 0.12979650009987154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12979650009987154}
{"step": 530648, "time": 16939.161051511765, "episode/length": 288.0, "episode/score": 0.1479984809067787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1479984809067787}
{"step": 531376, "time": 16962.128707885742, "episode/length": 288.0, "episode/score": 0.1178548615798718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1178548615798718}
{"step": 531552, "time": 16967.542314291, "episode/length": 288.0, "episode/score": 0.1405772574927937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1405772574927937}
{"step": 531720, "time": 16972.504858493805, "episode/length": 288.0, "episode/score": 0.0519460327300294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0519460327300294}
{"step": 532264, "time": 16989.362341165543, "episode/length": 288.0, "episode/score": 0.1309876686770508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1309876686770508}
{"step": 532352, "time": 16992.3061709404, "episode/length": 288.0, "episode/score": 0.1313625944848127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1313625944848127}
{"step": 532528, "time": 16998.18965101242, "episode/length": 288.0, "episode/score": 0.09509781290620367, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09509781290620367}
{"step": 532680, "time": 17002.646009922028, "episode/length": 288.0, "episode/score": 0.07466886255753025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07466886255753025}
{"step": 532960, "time": 17011.479253292084, "episode/length": 288.0, "episode/score": 0.12526834636020112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12526834636020112}
{"step": 533688, "time": 17033.78095293045, "episode/length": 288.0, "episode/score": 0.07824153312390081, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07824153312390081}
{"step": 533864, "time": 17039.19699072838, "episode/length": 288.0, "episode/score": 0.060210790932273994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060210790932273994}
{"step": 534032, "time": 17044.594041109085, "episode/length": 288.0, "episode/score": 0.09252112428305281, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09252112428305281}
{"step": 534576, "time": 17061.479466199875, "episode/length": 288.0, "episode/score": 0.08802423404449655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08802423404449655}
{"step": 534664, "time": 17063.96160030365, "episode/length": 288.0, "episode/score": 0.15388561515629817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15388561515629817}
{"step": 534840, "time": 17069.389195919037, "episode/length": 288.0, "episode/score": 0.13538799835851023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13538799835851023}
{"step": 534992, "time": 17074.278077840805, "episode/length": 288.0, "episode/score": 0.10990590425740265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10990590425740265}
{"step": 535272, "time": 17082.7728638649, "episode/length": 288.0, "episode/score": 0.12031086012569858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12031086012569858}
{"step": 536000, "time": 17105.480476140976, "episode/length": 288.0, "episode/score": 0.13688694132582668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13688694132582668}
{"step": 536176, "time": 17110.884433746338, "episode/length": 288.0, "episode/score": 0.09661349665168473, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09661349665168473}
{"step": 536344, "time": 17115.8513982296, "episode/length": 288.0, "episode/score": 0.15634044170144534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15634044170144534}
{"step": 536888, "time": 17132.581573486328, "episode/length": 288.0, "episode/score": 0.12094052268821542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12094052268821542}
{"step": 536976, "time": 17135.671476364136, "episode/length": 288.0, "episode/score": 0.09447685280747464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09447685280747464}
{"step": 537152, "time": 17141.1922454834, "episode/length": 288.0, "episode/score": 0.11412939314368487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11412939314368487}
{"step": 537304, "time": 17145.673291921616, "episode/length": 288.0, "episode/score": 0.1306736665610515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1306736665610515}
{"step": 537584, "time": 17154.562786340714, "episode/length": 288.0, "episode/score": 0.10969829947134713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10969829947134713}
{"step": 538312, "time": 17176.884441137314, "episode/length": 288.0, "episode/score": 0.1017984179177347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1017984179177347}
{"step": 538488, "time": 17182.319927215576, "episode/length": 288.0, "episode/score": 0.12640051991797918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12640051991797918}
{"step": 538656, "time": 17187.718235254288, "episode/length": 288.0, "episode/score": 0.15394786385263615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15394786385263615}
{"step": 539200, "time": 17204.666592359543, "episode/length": 288.0, "episode/score": 0.1999070315305289, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1999070315305289}
{"step": 539288, "time": 17207.14545273781, "episode/length": 288.0, "episode/score": 0.14518060407226585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14518060407226585}
{"step": 539464, "time": 17212.571171283722, "episode/length": 288.0, "episode/score": 0.11088535009434963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11088535009434963}
{"step": 539616, "time": 17217.453741550446, "episode/length": 288.0, "episode/score": 0.09993207902448376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09993207902448376}
{"step": 539896, "time": 17225.9338657856, "episode/length": 288.0, "episode/score": 0.0763341709910037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0763341709910037}
{"step": 540072, "time": 17236.43045115471, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17236.436361789703, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17236.44259786606, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17236.4509472847, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17236.45937037468, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17236.466822862625, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17236.47364282608, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17236.48333311081, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540073, "time": 17237.48716711998, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.9485877451270517, "train/action_min": 0.0, "train/action_std": 1.3049586132319286, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0027625437448450334, "train/actor_opt_grad_steps": 32665.0, "train/actor_opt_loss": -11.414279453682177, "train/adv_mag": 0.16961119030461166, "train/adv_max": 0.04343009627226627, "train/adv_mean": -0.005541940637443196, "train/adv_min": -0.154036556831514, "train/adv_std": 0.005294618250877418, "train/cont_avg": 0.9961036142676768, "train/cont_loss_mean": 0.022059336558661678, "train/cont_loss_std": 0.2979243031392495, "train/cont_neg_acc": 0.03829972521991146, "train/cont_neg_loss": 4.701587787696293, "train/cont_pos_acc": 0.9999653212349824, "train/cont_pos_loss": 0.003736579870085486, "train/cont_pred": 0.9961016981890707, "train/cont_rate": 0.9961036142676768, "train/dyn_loss_mean": 1.0000241609534832, "train/dyn_loss_std": 0.0006937862690208912, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.06411031146787784, "train/extr_critic_critic_opt_grad_steps": 32665.0, "train/extr_critic_critic_opt_loss": 10644.117361357718, "train/extr_critic_mag": 1.0197594888282544, "train/extr_critic_max": 1.0197594888282544, "train/extr_critic_mean": 0.984307106095131, "train/extr_critic_min": 0.9551079483947369, "train/extr_critic_std": 0.009195836092759337, "train/extr_return_normed_mag": 0.1714185873667399, "train/extr_return_normed_max": 0.05756725656865823, "train/extr_return_normed_mean": 0.005016189484424581, "train/extr_return_normed_min": -0.1406302840420694, "train/extr_return_normed_std": 0.01081608411046968, "train/extr_return_rate": 0.9999605513582326, "train/extr_return_raw_mag": 1.0313161777125464, "train/extr_return_raw_max": 1.0313161777125464, "train/extr_return_raw_mean": 0.9787651649629227, "train/extr_return_raw_min": 0.8331186371018188, "train/extr_return_raw_std": 0.010816084094006907, "train/extr_reward_mag": 0.07306029399236043, "train/extr_reward_max": 0.07306029399236043, "train/extr_reward_mean": 0.0006304237106109433, "train/extr_reward_min": 9.010536502106021e-06, "train/extr_reward_std": 0.001143651915951679, "train/image_loss_mean": 0.12229262886926381, "train/image_loss_std": 0.10928653786429252, "train/model_loss_mean": 0.76595765171629, "train/model_loss_std": 0.38105032758580315, "train/model_opt_grad_norm": 24.57496660887593, "train/model_opt_grad_steps": 32634.939393939392, "train/model_opt_loss": 2445.7490246705333, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3194.4444444444443, "train/policy_entropy_mag": 1.229169194144432, "train/policy_entropy_max": 1.229169194144432, "train/policy_entropy_mean": 0.15451005819921543, "train/policy_entropy_min": 0.06468662382526831, "train/policy_entropy_std": 0.18891493276213156, "train/policy_logprob_mag": 6.55108016909975, "train/policy_logprob_max": -0.008608151664675184, "train/policy_logprob_mean": -0.15443419409219664, "train/policy_logprob_min": -6.55108016909975, "train/policy_logprob_std": 0.6859005081533182, "train/policy_randomness_mag": 0.63166804747148, "train/policy_randomness_max": 0.63166804747148, "train/policy_randomness_mean": 0.0794024674052542, "train/policy_randomness_min": 0.03324235112152316, "train/policy_randomness_std": 0.09708307611972394, "train/post_ent_mag": 11.165031909942627, "train/post_ent_max": 11.165031909942627, "train/post_ent_mean": 10.84434647993608, "train/post_ent_min": 10.502509160475297, "train/post_ent_std": 0.1202991319951987, "train/prior_ent_mag": 14.712540968500003, "train/prior_ent_max": 14.712540968500003, "train/prior_ent_mean": 7.898079862498274, "train/prior_ent_min": 5.730662353111036, "train/prior_ent_std": 1.1274672289087315, "train/rep_loss_mean": 1.0000241609534832, "train/rep_loss_std": 0.0006937862690208912, "train/reward_avg": 0.0009451493745225227, "train/reward_loss_mean": 0.021591166956256135, "train/reward_loss_std": 0.10600261828589319, "train/reward_max_data": 0.37714955868726274, "train/reward_max_pred": 0.10574569666024411, "train/reward_neg_acc": 0.9998419932042709, "train/reward_neg_loss": 0.018006377378384574, "train/reward_pos_acc": 0.24092261945562704, "train/reward_pos_loss": 4.294284930186612, "train/reward_pred": 0.0008497995958249602, "train/reward_rate": 0.0008384627525252525, "train_stats/mean_log_entropy": 0.181475709083381, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.0148253683000803, "report/cont_loss_std": 0.24182483553886414, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 3.831636428833008, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003610448446124792, "report/cont_pred": 0.9959044456481934, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10871954262256622, "report/image_loss_std": 0.1078302189707756, "report/model_loss_mean": 0.742452085018158, "report/model_loss_std": 0.27234113216400146, "report/post_ent_mag": 10.226818084716797, "report/post_ent_max": 10.226818084716797, "report/post_ent_mean": 10.003378868103027, "report/post_ent_min": 9.775413513183594, "report/post_ent_std": 0.08000368624925613, "report/prior_ent_mag": 15.910772323608398, "report/prior_ent_max": 15.910772323608398, "report/prior_ent_mean": 7.217496871948242, "report/prior_ent_min": 4.884160995483398, "report/prior_ent_std": 1.1055428981781006, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004584284615702927, "report/reward_loss_mean": 0.018907152116298676, "report/reward_loss_std": 0.02645469270646572, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.018286943435668945, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.018907152116298676, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0007476186146959662, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.03357616066932678, "eval/cont_loss_std": 0.4272010922431946, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.076019287109375, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003927270416170359, "eval/cont_pred": 0.9961422681808472, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16408413648605347, "eval/image_loss_std": 0.13601182401180267, "eval/model_loss_mean": 0.8169048428535461, "eval/model_loss_std": 0.721296489238739, "eval/post_ent_mag": 10.233182907104492, "eval/post_ent_max": 10.233182907104492, "eval/post_ent_mean": 10.0064697265625, "eval/post_ent_min": 9.794044494628906, "eval/post_ent_std": 0.08158952742815018, "eval/prior_ent_mag": 18.249088287353516, "eval/prior_ent_max": 18.249088287353516, "eval/prior_ent_mean": 7.053203582763672, "eval/prior_ent_min": 5.14955997467041, "eval/prior_ent_std": 1.1295491456985474, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0011077880626544356, "eval/reward_loss_mean": 0.019244518131017685, "eval/reward_loss_std": 0.36412477493286133, "eval/reward_max_data": 0.768750011920929, "eval/reward_max_pred": 0.09260237216949463, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00408523203805089, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.765639781951904, "eval/reward_pred": 0.0008615728002041578, "eval/reward_rate": 0.001953125, "replay/size": 539569.0, "replay/inserts": 31680.0, "replay/samples": 31680.0, "replay/insert_wait_avg": 1.2108171829069503e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.776675200221514e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 9248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0216060806723202e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1002.0936763286591, "timer/env.step_count": 3960.0, "timer/env.step_total": 33.9899480342865, "timer/env.step_frac": 0.03391893276765748, "timer/env.step_avg": 0.008583320210678409, "timer/env.step_min": 0.007305145263671875, "timer/env.step_max": 0.03825712203979492, "timer/replay._sample_count": 31680.0, "timer/replay._sample_total": 15.889159679412842, "timer/replay._sample_frac": 0.015855962426212972, "timer/replay._sample_avg": 0.0005015517575572236, "timer/replay._sample_min": 0.00039649009704589844, "timer/replay._sample_max": 0.032541751861572266, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5116.0, "timer/agent.policy_total": 43.15066838264465, "timer/agent.policy_frac": 0.04306051360461078, "timer/agent.policy_avg": 0.008434454335935234, "timer/agent.policy_min": 0.007387399673461914, "timer/agent.policy_max": 0.08646488189697266, "timer/dataset_train_count": 1980.0, "timer/dataset_train_total": 0.20434093475341797, "timer/dataset_train_frac": 0.0002039140048284266, "timer/dataset_train_avg": 0.00010320249229970604, "timer/dataset_train_min": 8.845329284667969e-05, "timer/dataset_train_max": 0.0002949237823486328, "timer/agent.train_count": 1980.0, "timer/agent.train_total": 876.2519438266754, "timer/agent.train_frac": 0.8744211888822347, "timer/agent.train_avg": 0.4425514867811492, "timer/agent.train_min": 0.4330940246582031, "timer/agent.train_max": 0.6230731010437012, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4771084785461426, "timer/agent.report_frac": 0.00047611165484459574, "timer/agent.report_avg": 0.2385542392730713, "timer/agent.report_min": 0.23165130615234375, "timer/agent.report_max": 0.24545717239379883, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.307094264533421e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 31.61326145609581}
{"step": 540624, "time": 17254.43298268318, "episode/length": 288.0, "episode/score": 0.053833305257739994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053833305257739994}
{"step": 540800, "time": 17260.45356607437, "episode/length": 288.0, "episode/score": 0.1074758695001492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1074758695001492}
{"step": 540968, "time": 17265.406180858612, "episode/length": 288.0, "episode/score": 0.07581305555959261, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07581305555959261}
{"step": 541512, "time": 17282.15836262703, "episode/length": 288.0, "episode/score": 0.0947254583652466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0947254583652466}
{"step": 541600, "time": 17285.23665547371, "episode/length": 288.0, "episode/score": 0.10071688829066261, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10071688829066261}
{"step": 541776, "time": 17290.668043136597, "episode/length": 288.0, "episode/score": 0.050253936544550015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050253936544550015}
{"step": 541928, "time": 17295.12917304039, "episode/length": 288.0, "episode/score": 0.10200078849175043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10200078849175043}
{"step": 542208, "time": 17303.977211236954, "episode/length": 288.0, "episode/score": 0.13696970015826082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13696970015826082}
{"step": 542936, "time": 17326.2641582489, "episode/length": 288.0, "episode/score": 0.2001818972082674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2001818972082674}
{"step": 543112, "time": 17331.75642967224, "episode/length": 288.0, "episode/score": 0.119266208542399, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.119266208542399}
{"step": 543280, "time": 17337.253432035446, "episode/length": 288.0, "episode/score": 0.16790588526248484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16790588526248484}
{"step": 543824, "time": 17354.210089445114, "episode/length": 288.0, "episode/score": 0.1708853967753612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1708853967753612}
{"step": 543912, "time": 17356.69439291954, "episode/length": 288.0, "episode/score": 0.16372941797476415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16372941797476415}
{"step": 544088, "time": 17362.119437932968, "episode/length": 288.0, "episode/score": 0.07990556837285112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07990556837285112}
{"step": 544240, "time": 17367.041373968124, "episode/length": 288.0, "episode/score": 0.1402091206031173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1402091206031173}
{"step": 544520, "time": 17375.568147420883, "episode/length": 288.0, "episode/score": 0.13939119429892344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13939119429892344}
{"step": 545248, "time": 17398.193378686905, "episode/length": 288.0, "episode/score": 0.09442380717996457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09442380717996457}
{"step": 545424, "time": 17403.624091386795, "episode/length": 288.0, "episode/score": 0.12988405655460156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12988405655460156}
{"step": 545592, "time": 17408.705216407776, "episode/length": 288.0, "episode/score": 0.06511178683592789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06511178683592789}
{"step": 546136, "time": 17427.00899863243, "episode/length": 288.0, "episode/score": 0.1448502481049445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1448502481049445}
{"step": 546224, "time": 17429.95202589035, "episode/length": 288.0, "episode/score": 0.14039225015903867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14039225015903867}
{"step": 546400, "time": 17435.486560106277, "episode/length": 288.0, "episode/score": 0.18473199686741282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18473199686741282}
{"step": 546552, "time": 17439.96226334572, "episode/length": 288.0, "episode/score": 0.10115906529892982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10115906529892982}
{"step": 546832, "time": 17448.81807589531, "episode/length": 288.0, "episode/score": 0.1621592889943031, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1621592889943031}
{"step": 547560, "time": 17471.148882865906, "episode/length": 288.0, "episode/score": 0.07088633225339436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07088633225339436}
{"step": 547736, "time": 17476.577169418335, "episode/length": 288.0, "episode/score": 0.1744015414506066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1744015414506066}
{"step": 547904, "time": 17481.980969429016, "episode/length": 288.0, "episode/score": 0.07427913201036063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07427913201036063}
{"step": 548448, "time": 17498.88930416107, "episode/length": 288.0, "episode/score": 0.11015674189843594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11015674189843594}
{"step": 548536, "time": 17501.374963521957, "episode/length": 288.0, "episode/score": 0.11227300631082926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11227300631082926}
{"step": 548712, "time": 17506.80390405655, "episode/length": 288.0, "episode/score": 0.07725739844556756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07725739844556756}
{"step": 548864, "time": 17511.837683439255, "episode/length": 288.0, "episode/score": 0.05850794240870982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05850794240870982}
{"step": 549144, "time": 17520.574412822723, "episode/length": 288.0, "episode/score": 0.11421453939306048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11421453939306048}
{"step": 549872, "time": 17543.2679772377, "episode/length": 288.0, "episode/score": 0.11245516013946144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11245516013946144}
{"step": 550048, "time": 17548.69342803955, "episode/length": 288.0, "episode/score": 0.0811774395313023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0811774395313023}
{"step": 550056, "time": 17553.296412467957, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17553.303092241287, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17553.308691740036, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17553.314675807953, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17553.32117176056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17553.32990050316, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17553.336051940918, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17553.341641426086, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550216, "time": 17558.392090559006, "episode/length": 288.0, "episode/score": 0.0733197626244646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0733197626244646}
{"step": 550760, "time": 17575.121838092804, "episode/length": 288.0, "episode/score": 0.08770553627681466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08770553627681466}
{"step": 550848, "time": 17578.05892753601, "episode/length": 288.0, "episode/score": 0.12261241784079857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12261241784079857}
{"step": 551024, "time": 17583.571087121964, "episode/length": 288.0, "episode/score": 0.08174938541310439, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08174938541310439}
{"step": 551176, "time": 17588.176936388016, "episode/length": 288.0, "episode/score": 0.10553330928053128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10553330928053128}
{"step": 551456, "time": 17597.010528564453, "episode/length": 288.0, "episode/score": 0.041317664705331936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041317664705331936}
{"step": 552184, "time": 17619.280189037323, "episode/length": 288.0, "episode/score": 0.06371634780657587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06371634780657587}
{"step": 552360, "time": 17624.659054517746, "episode/length": 288.0, "episode/score": 0.048854540254239964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048854540254239964}
{"step": 552528, "time": 17630.005043268204, "episode/length": 288.0, "episode/score": 0.12732601727805104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12732601727805104}
{"step": 553072, "time": 17646.78713274002, "episode/length": 288.0, "episode/score": 0.05661759961157031, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05661759961157031}
{"step": 553160, "time": 17649.27367424965, "episode/length": 288.0, "episode/score": 0.05769611084184589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05769611084184589}
{"step": 553336, "time": 17654.684900283813, "episode/length": 288.0, "episode/score": 0.07038568881921492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07038568881921492}
{"step": 553488, "time": 17659.58729839325, "episode/length": 288.0, "episode/score": 0.1609361098880413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1609361098880413}
{"step": 553768, "time": 17667.97228217125, "episode/length": 288.0, "episode/score": 0.047031209586236855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047031209586236855}
{"step": 554496, "time": 17690.63273882866, "episode/length": 288.0, "episode/score": 0.1313418173179457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1313418173179457}
{"step": 554672, "time": 17696.066686153412, "episode/length": 288.0, "episode/score": 0.05134132886644238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05134132886644238}
{"step": 554840, "time": 17701.02460551262, "episode/length": 288.0, "episode/score": 0.10455860447422083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10455860447422083}
{"step": 555384, "time": 17717.879169225693, "episode/length": 288.0, "episode/score": 0.10649258689949193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10649258689949193}
{"step": 555472, "time": 17720.840217113495, "episode/length": 288.0, "episode/score": 0.04603295946776598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04603295946776598}
{"step": 555648, "time": 17726.263643980026, "episode/length": 288.0, "episode/score": 0.09152036685696885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09152036685696885}
{"step": 555800, "time": 17730.752645015717, "episode/length": 288.0, "episode/score": 0.0825262378714342, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0825262378714342}
{"step": 556080, "time": 17739.75404024124, "episode/length": 288.0, "episode/score": 0.05453042796779073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05453042796779073}
{"step": 556808, "time": 17761.89414358139, "episode/length": 288.0, "episode/score": 0.06809640514359216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06809640514359216}
{"step": 556984, "time": 17767.433149814606, "episode/length": 288.0, "episode/score": 0.07254685826683271, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07254685826683271}
{"step": 557152, "time": 17773.301114320755, "episode/length": 288.0, "episode/score": 0.07999587914804351, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07999587914804351}
{"step": 557568, "time": 17786.08304977417, "episode/length": 72.0, "episode/score": 0.8041405945222095, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.029140620692373886}
{"step": 557696, "time": 17790.01074075699, "episode/length": 288.0, "episode/score": 0.08097803499418887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08097803499418887}
{"step": 557784, "time": 17792.513707637787, "episode/length": 288.0, "episode/score": 0.06166175932389706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06166175932389706}
{"step": 557960, "time": 17798.01301574707, "episode/length": 288.0, "episode/score": 0.08769589561569546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08769589561569546}
{"step": 557976, "time": 17798.51015353203, "episode/length": 271.0, "episode/score": 0.19981290799432827, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.04668790664391054}
{"step": 558392, "time": 17811.44233417511, "episode/length": 288.0, "episode/score": 0.0780789049467785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0780789049467785}
{"step": 559120, "time": 17834.335695028305, "episode/length": 288.0, "episode/score": 0.07386562495349835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07386562495349835}
{"step": 559464, "time": 17844.665075063705, "episode/length": 288.0, "episode/score": 0.06499343390481727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06499343390481727}
{"step": 559880, "time": 17857.52400994301, "episode/length": 288.0, "episode/score": 0.06788186505519889, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06788186505519889}
{"step": 560008, "time": 17861.46600794792, "episode/length": 288.0, "episode/score": 0.08365827550323957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08365827550323957}
{"step": 560040, "time": 17864.743062019348, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 560040, "time": 17866.940936803818, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17866.947385072708, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17866.952894449234, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17866.958406448364, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17866.963765382767, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17866.96923995018, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17866.974653482437, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560096, "time": 17868.920816898346, "episode/length": 288.0, "episode/score": 0.0563941054779491, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0563941054779491}
{"step": 560272, "time": 17874.376132965088, "episode/length": 288.0, "episode/score": 0.03185255144583721, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03185255144583721}
{"step": 560288, "time": 17874.87034702301, "episode/length": 288.0, "episode/score": 0.08528235403019835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08528235403019835}
{"step": 560576, "time": 17883.710276842117, "episode/length": 70.0, "episode/score": 0.8056855854968319, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.024435598418932614}
{"step": 560704, "time": 17887.78052520752, "episode/length": 288.0, "episode/score": 0.06624206143166589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06624206143166589}
{"step": 560976, "time": 17896.160093069077, "episode/length": 87.0, "episode/score": 0.7524281627100038, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.024303199473962422}
{"step": 561432, "time": 17909.969493865967, "episode/length": 288.0, "episode/score": 0.036742235453374406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036742235453374406}
{"step": 561776, "time": 17920.964448451996, "episode/length": 288.0, "episode/score": 0.08242724484097153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08242724484097153}
{"step": 562192, "time": 17933.801709651947, "episode/length": 288.0, "episode/score": 0.031654542023915155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031654542023915155}
{"step": 562312, "time": 17937.266154766083, "episode/length": 200.0, "episode/score": 0.4392363372432726, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0642363388730871}
{"step": 562408, "time": 17940.238534927368, "episode/length": 288.0, "episode/score": 0.09041968635202124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09041968635202124}
{"step": 562600, "time": 17946.279257535934, "episode/length": 288.0, "episode/score": 0.08608920457311342, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08608920457311342}
{"step": 562888, "time": 17955.14515399933, "episode/length": 288.0, "episode/score": 0.04482487580074235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04482487580074235}
{"step": 563288, "time": 17967.433442115784, "episode/length": 288.0, "episode/score": 0.07382020291075264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07382020291075264}
{"step": 563744, "time": 17981.790502786636, "episode/length": 288.0, "episode/score": 0.07608243898272349, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07608243898272349}
{"step": 564088, "time": 17992.141252040863, "episode/length": 288.0, "episode/score": 0.07324716066523251, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07324716066523251}
{"step": 564504, "time": 18005.042320251465, "episode/length": 288.0, "episode/score": 0.07493427248755324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07493427248755324}
{"step": 564624, "time": 18008.966967105865, "episode/length": 288.0, "episode/score": 0.03572978129079729, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03572978129079729}
{"step": 564720, "time": 18011.935420036316, "episode/length": 288.0, "episode/score": 0.05770839764443281, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05770839764443281}
{"step": 564912, "time": 18017.867864131927, "episode/length": 288.0, "episode/score": 0.08461905033141193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08461905033141193}
{"step": 565200, "time": 18026.722193956375, "episode/length": 288.0, "episode/score": 0.048457008584250616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048457008584250616}
{"step": 565600, "time": 18039.64644765854, "episode/length": 288.0, "episode/score": 0.06181148368477807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06181148368477807}
{"step": 565624, "time": 18040.167387723923, "episode/length": 234.0, "episode/score": 0.34093786944595195, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0721878591548375}
{"step": 566400, "time": 18064.377219438553, "episode/length": 288.0, "episode/score": 0.05636558645380774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05636558645380774}
{"step": 566816, "time": 18077.273889780045, "episode/length": 288.0, "episode/score": 0.07600239192549907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07600239192549907}
{"step": 566936, "time": 18080.759687900543, "episode/length": 288.0, "episode/score": 0.09284455124213764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09284455124213764}
{"step": 567032, "time": 18083.727984428406, "episode/length": 288.0, "episode/score": 0.0937757171082012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0937757171082012}
{"step": 567224, "time": 18089.629393815994, "episode/length": 288.0, "episode/score": 0.11517217235143562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11517217235143562}
{"step": 567512, "time": 18098.57676076889, "episode/length": 288.0, "episode/score": 0.10340385956317277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10340385956317277}
{"step": 567728, "time": 18105.425060987473, "episode/length": 98.0, "episode/score": 0.774588593384351, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.08083857187079957}
{"step": 567912, "time": 18110.854798078537, "episode/length": 288.0, "episode/score": 0.11960294424022777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11960294424022777}
{"step": 567936, "time": 18111.818305253983, "episode/length": 288.0, "episode/score": 0.10317516479574351, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10317516479574351}
{"step": 568712, "time": 18135.68515729904, "episode/length": 288.0, "episode/score": 0.12347213936391199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12347213936391199}
{"step": 569128, "time": 18148.43704867363, "episode/length": 288.0, "episode/score": 0.15332175911942159, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15332175911942159}
{"step": 569344, "time": 18155.41773033142, "episode/length": 288.0, "episode/score": 0.13847394774973054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13847394774973054}
{"step": 569536, "time": 18161.34581375122, "episode/length": 288.0, "episode/score": 0.15734200250813046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15734200250813046}
{"step": 569824, "time": 18170.22363114357, "episode/length": 288.0, "episode/score": 0.18428722159512745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18428722159512745}
{"step": 570024, "time": 18176.966817378998, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 570024, "time": 18177.30455136299, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 570024, "time": 18181.297039985657, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18181.303491592407, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18181.3091275692, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18181.31460261345, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18181.320109844208, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18181.3256483078, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18181.331438064575, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570040, "time": 18181.849330425262, "episode/length": 288.0, "episode/score": 0.17840283901352905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17840283901352905}
{"step": 570224, "time": 18187.81293320656, "episode/length": 288.0, "episode/score": 0.1288455362263221, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1288455362263221}
{"step": 570248, "time": 18188.33687067032, "episode/length": 288.0, "episode/score": 0.1545325821057304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1545325821057304}
{"step": 570456, "time": 18194.725301027298, "episode/length": 78.0, "episode/score": 0.8208013677603958, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.06455134624684433}
{"step": 571024, "time": 18212.419023036957, "episode/length": 288.0, "episode/score": 0.10065014327938115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10065014327938115}
{"step": 571440, "time": 18225.285569667816, "episode/length": 288.0, "episode/score": 0.14996175786473032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14996175786473032}
{"step": 571528, "time": 18227.785269975662, "episode/length": 133.0, "episode/score": 0.6983093465405545, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.11393432502700307}
{"step": 571656, "time": 18231.741663455963, "episode/length": 288.0, "episode/score": 0.10795642708990272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10795642708990272}
{"step": 571817, "time": 18237.670422792435, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.9534896773908605, "train/action_min": 0.0, "train/action_std": 1.264331373737086, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.003865144985386325, "train/actor_opt_grad_steps": 34650.0, "train/actor_opt_loss": -10.164123278766422, "train/adv_mag": 0.3549157878262314, "train/adv_max": 0.09584288920589427, "train/adv_mean": -0.004317706651475524, "train/adv_min": -0.3288945378969662, "train/adv_std": 0.009506454467820238, "train/cont_avg": 0.9960986573492462, "train/cont_loss_mean": 0.01898526144447975, "train/cont_loss_std": 0.27042302511744765, "train/cont_neg_acc": 0.1350228495594829, "train/cont_neg_loss": 4.00701595624589, "train/cont_pos_acc": 0.9998323656805795, "train/cont_pos_loss": 0.0034666867141644633, "train/cont_pred": 0.9960806252968372, "train/cont_rate": 0.9960986573492462, "train/dyn_loss_mean": 1.0000168043165352, "train/dyn_loss_std": 0.0005374935169846998, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10070218519546353, "train/extr_critic_critic_opt_grad_steps": 34650.0, "train/extr_critic_critic_opt_loss": 11726.521634049152, "train/extr_critic_mag": 0.783575304189519, "train/extr_critic_max": 0.783575304189519, "train/extr_critic_mean": 0.7570827824985562, "train/extr_critic_min": 0.7327205901169896, "train/extr_critic_std": 0.007099137905910237, "train/extr_return_normed_mag": 0.35408609895849946, "train/extr_return_normed_max": 0.10511658299508406, "train/extr_return_normed_mean": 0.0043709605311256505, "train/extr_return_normed_min": -0.32243926351393887, "train/extr_return_normed_std": 0.012529632238081501, "train/extr_return_rate": 0.9997510607518143, "train/extr_return_raw_mag": 0.8535106640365255, "train/extr_return_raw_max": 0.8535106640365255, "train/extr_return_raw_mean": 0.7527650777419009, "train/extr_return_raw_min": 0.42595481752750264, "train/extr_return_raw_std": 0.012529632315301716, "train/extr_reward_mag": 0.13853141530674307, "train/extr_reward_max": 0.13853141530674307, "train/extr_reward_mean": 0.0006981448515496174, "train/extr_reward_min": 8.674722221029463e-06, "train/extr_reward_std": 0.002505392203254897, "train/image_loss_mean": 0.1215516643682916, "train/image_loss_std": 0.10949963664439455, "train/model_loss_mean": 0.7617932602987817, "train/model_loss_std": 0.3570836649168676, "train/model_opt_grad_norm": 23.57828808310044, "train/model_opt_grad_steps": 34618.34170854271, "train/model_opt_loss": 2301.627824179491, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3027.638190954774, "train/policy_entropy_mag": 1.3063766297383523, "train/policy_entropy_max": 1.3063766297383523, "train/policy_entropy_mean": 0.1670751889521752, "train/policy_entropy_min": 0.06468663986154537, "train/policy_entropy_std": 0.19884009700474428, "train/policy_logprob_mag": 6.55108006635503, "train/policy_logprob_max": -0.008608229463012075, "train/policy_logprob_mean": -0.16740885863651583, "train/policy_logprob_min": -6.55108006635503, "train/policy_logprob_std": 0.6950976591014383, "train/policy_randomness_mag": 0.6713448244722644, "train/policy_randomness_max": 0.6713448244722644, "train/policy_randomness_mean": 0.08585966837091662, "train/policy_randomness_min": 0.03324235913966169, "train/policy_randomness_std": 0.10218360177685867, "train/post_ent_mag": 8.673657333431532, "train/post_ent_max": 8.673657333431532, "train/post_ent_mean": 8.457359992079999, "train/post_ent_min": 8.263154130485189, "train/post_ent_std": 0.0805079019885866, "train/prior_ent_mag": 11.086172297971332, "train/prior_ent_max": 11.086172297971332, "train/prior_ent_mean": 5.608709296988483, "train/prior_ent_min": 4.057926448745344, "train/prior_ent_std": 0.9562393465832849, "train/rep_loss_mean": 1.0000168043165352, "train/rep_loss_std": 0.0005374935169846998, "train/reward_avg": 0.0009168308390884767, "train/reward_loss_mean": 0.021246229289052773, "train/reward_loss_std": 0.10153095207022662, "train/reward_max_data": 0.36593893305609126, "train/reward_max_pred": 0.11597462575040271, "train/reward_neg_acc": 0.9998330294187344, "train/reward_neg_loss": 0.01785169444959517, "train/reward_pos_acc": 0.2484709486502026, "train/reward_pos_loss": 4.147092574233309, "train/reward_pred": 0.0008149613215630154, "train/reward_rate": 0.0008048052763819096, "train_stats/mean_log_entropy": 0.17432263833388947, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.005349600687623024, "report/cont_loss_std": 0.07942251861095428, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.2911524772644043, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0028333524242043495, "report/cont_pred": 0.9962236881256104, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09627114236354828, "report/image_loss_std": 0.09598205983638763, "report/model_loss_mean": 0.7259830236434937, "report/model_loss_std": 0.27051928639411926, "report/post_ent_mag": 7.1938934326171875, "report/post_ent_max": 7.1938934326171875, "report/post_ent_mean": 6.880789756774902, "report/post_ent_min": 6.720846176147461, "report/post_ent_std": 0.08315470814704895, "report/prior_ent_mag": 8.22916316986084, "report/prior_ent_max": 8.22916316986084, "report/prior_ent_mean": 4.289632797241211, "report/prior_ent_min": 3.3410072326660156, "report/prior_ent_std": 0.7238113284111023, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006937329890206456, "report/reward_loss_mean": 0.02436230331659317, "report/reward_loss_std": 0.16562867164611816, "report/reward_max_data": 0.23225000500679016, "report/reward_max_pred": 0.08295083045959473, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.019267156720161438, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.236700057983398, "report/reward_pred": 0.0008735434385016561, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.026167131960392, "eval/cont_loss_std": 0.36429548263549805, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.716802597045898, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.003850914305076003, "eval/cont_pred": 0.9963670969009399, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17913492023944855, "eval/image_loss_std": 0.14928126335144043, "eval/model_loss_mean": 0.8084149360656738, "eval/model_loss_std": 0.3877122104167938, "eval/post_ent_mag": 7.179326057434082, "eval/post_ent_max": 7.179326057434082, "eval/post_ent_mean": 6.896048545837402, "eval/post_ent_min": 6.749055862426758, "eval/post_ent_std": 0.08514668792486191, "eval/prior_ent_mag": 10.495748519897461, "eval/prior_ent_max": 10.495748519897461, "eval/prior_ent_mean": 4.429449081420898, "eval/prior_ent_min": 3.4405369758605957, "eval/prior_ent_std": 0.8422220349311829, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0031128795817494392, "eval/reward_loss_std": 0.0036167858634144068, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.01751852035522461, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0031128795817494392, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0006309653399512172, "eval/reward_rate": 0.0, "replay/size": 571313.0, "replay/inserts": 31744.0, "replay/samples": 31744.0, "replay/insert_wait_avg": 1.2182375235903647e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.828892839531745e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.811735758181949e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1621532440186, "timer/env.step_count": 3968.0, "timer/env.step_total": 33.91089630126953, "timer/env.step_frac": 0.033905398430924216, "timer/env.step_avg": 0.008546092817860266, "timer/env.step_min": 0.007134437561035156, "timer/env.step_max": 0.04548764228820801, "timer/replay._sample_count": 31744.0, "timer/replay._sample_total": 15.882677555084229, "timer/replay._sample_frac": 0.015880102544941217, "timer/replay._sample_avg": 0.000500336364512482, "timer/replay._sample_min": 0.00037670135498046875, "timer/replay._sample_max": 0.010923385620117188, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4835.0, "timer/agent.policy_total": 40.98624110221863, "timer/agent.policy_frac": 0.04097959612776794, "timer/agent.policy_avg": 0.008476988852578827, "timer/agent.policy_min": 0.0074005126953125, "timer/agent.policy_max": 0.0808861255645752, "timer/dataset_train_count": 1984.0, "timer/dataset_train_total": 0.20298290252685547, "timer/dataset_train_frac": 0.00020294999352703152, "timer/dataset_train_avg": 0.00010230993070910054, "timer/dataset_train_min": 8.702278137207031e-05, "timer/dataset_train_max": 0.00029659271240234375, "timer/agent.train_count": 1984.0, "timer/agent.train_total": 878.511922121048, "timer/agent.train_frac": 0.8783694916585286, "timer/agent.train_avg": 0.44279834784327016, "timer/agent.train_min": 0.4325447082519531, "timer/agent.train_max": 1.9745185375213623, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4767489433288574, "timer/agent.report_frac": 0.00047667164947456345, "timer/agent.report_avg": 0.2383744716644287, "timer/agent.report_min": 0.2324976921081543, "timer/agent.report_max": 0.24425125122070312, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.839897155761719e-05, "timer/dataset_eval_frac": 4.8391124779752445e-08, "timer/dataset_eval_avg": 4.839897155761719e-05, "timer/dataset_eval_min": 4.839897155761719e-05, "timer/dataset_eval_max": 4.839897155761719e-05, "fps": 31.7382727088043}
{"step": 571848, "time": 18238.39429950714, "episode/length": 288.0, "episode/score": 0.11078278547256559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11078278547256559}
{"step": 572352, "time": 18254.52304840088, "episode/length": 288.0, "episode/score": 0.15055300458152487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15055300458152487}
{"step": 572536, "time": 18260.07453751564, "episode/length": 288.0, "episode/score": 0.11428596643418132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11428596643418132}
{"step": 572560, "time": 18261.054070711136, "episode/length": 288.0, "episode/score": 0.11627052638641544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11627052638641544}
{"step": 572960, "time": 18273.560569524765, "episode/length": 49.0, "episode/score": 0.9095790618016508, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0627040522090283}
{"step": 573248, "time": 18282.69486141205, "episode/length": 225.0, "episode/score": 0.36641612241555777, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.06954112404537227}
{"step": 573336, "time": 18285.220863580704, "episode/length": 288.0, "episode/score": 0.10473933985895201, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10473933985895201}
{"step": 573384, "time": 18286.70668363571, "episode/length": 215.0, "episode/score": 0.46810373635275937, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.13997873798257388}
{"step": 573488, "time": 18290.61245894432, "episode/length": 141.0, "episode/score": 0.6733269393462251, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.11395195359546051}
{"step": 573744, "time": 18298.466284751892, "episode/length": 150.0, "episode/score": 0.6126263915725758, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.08137636293440664}
{"step": 573840, "time": 18301.412168741226, "episode/length": 288.0, "episode/score": 0.16077551953003422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16077551953003422}
{"step": 573928, "time": 18303.913103103638, "episode/length": 54.0, "episode/score": 0.8673962830146138, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.03614627272349935}
{"step": 573928, "time": 18303.91904592514, "episode/length": 73.0, "episode/score": 0.8085423077502583, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.03666729683050107}
{"step": 574104, "time": 18309.443591356277, "episode/length": 106.0, "episode/score": 0.7440547103615245, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.07530473520455416}
{"step": 574144, "time": 18310.902998924255, "episode/length": 147.0, "episode/score": 0.6213466334343138, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.08072164091981904}
{"step": 574160, "time": 18311.400463819504, "episode/length": 288.0, "episode/score": 0.05807187280538528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05807187280538528}
{"step": 574712, "time": 18328.18520474434, "episode/length": 108.0, "episode/score": 0.7304469990576763, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.06794695885946567}
{"step": 575032, "time": 18338.171154737473, "episode/length": 205.0, "episode/score": 0.4623365378301969, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.10296155075229763}
{"step": 575160, "time": 18342.109466314316, "episode/length": 153.0, "episode/score": 0.6555917028567819, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.13371665037675484}
{"step": 575392, "time": 18349.445563316345, "episode/length": 153.0, "episode/score": 0.6622516493014245, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.14037662708938115}
{"step": 575568, "time": 18354.85144352913, "episode/length": 106.0, "episode/score": 0.7611193435097903, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.09236935624562648}
{"step": 575960, "time": 18366.813854694366, "episode/length": 115.0, "episode/score": 0.7324711001549531, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.09184608379860038}
{"step": 576056, "time": 18369.766189336777, "episode/length": 288.0, "episode/score": 0.10098279472913418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10098279472913418}
{"step": 576240, "time": 18375.640315055847, "episode/length": 288.0, "episode/score": 0.15222269638456964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15222269638456964}
{"step": 576416, "time": 18381.050055503845, "episode/length": 288.0, "episode/score": 0.14295469142189177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14295469142189177}
{"step": 576456, "time": 18382.082567453384, "episode/length": 288.0, "episode/score": 0.151881108925636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.151881108925636}
{"step": 576736, "time": 18390.91962313652, "episode/length": 84.0, "episode/score": 0.8055335473700325, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.06803353777740995}
{"step": 576896, "time": 18395.956518888474, "episode/length": 19.0, "episode/score": 0.9645118815860769, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.023886871993454406}
{"step": 577168, "time": 18404.333812713623, "episode/length": 33.0, "episode/score": 0.9313606378145778, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.03448561560253438}
{"step": 577392, "time": 18411.234006643295, "episode/length": 143.0, "episode/score": 0.6421117925488034, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.08898678162904616}
{"step": 577472, "time": 18413.67822766304, "episode/length": 288.0, "episode/score": 0.15935778309358284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15935778309358284}
{"step": 577704, "time": 18420.583280563354, "episode/length": 288.0, "episode/score": 0.11755134124450706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11755134124450706}
{"step": 577880, "time": 18426.11523461342, "episode/length": 288.0, "episode/score": 0.12739290215040455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12739290215040455}
{"step": 578272, "time": 18438.390823364258, "episode/length": 288.0, "episode/score": 0.11631146267268377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11631146267268377}
{"step": 578400, "time": 18442.34625864029, "episode/length": 64.0, "episode/score": 0.8566901158310429, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.05669010623842041}
{"step": 578456, "time": 18443.852768182755, "episode/length": 160.0, "episode/score": 0.611274990419588, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.11127496178141882}
{"step": 578728, "time": 18452.210205078125, "episode/length": 288.0, "episode/score": 0.10806705015966145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10806705015966145}
{"step": 578768, "time": 18453.66257405281, "episode/length": 288.0, "episode/score": 0.05660297453255225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05660297453255225}
{"step": 579704, "time": 18482.536732912064, "episode/length": 288.0, "episode/score": 0.09048379154478425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09048379154478425}
{"step": 579784, "time": 18485.149488449097, "episode/length": 288.0, "episode/score": 0.13531568882035572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13531568882035572}
{"step": 580008, "time": 18492.709739923477, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 580008, "time": 18493.482877731323, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 580008, "time": 18493.537298202515, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 580008, "time": 18493.97641134262, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 580008, "time": 18494.290230989456, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 580008, "time": 18495.653223752975, "eval_episode/length": 222.0, "eval_episode/score": 0.3062500059604645, "eval_episode/reward_rate": 0.004484304932735426}
{"step": 580008, "time": 18495.983741521835, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 580008, "time": 18496.281514167786, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 580016, "time": 18496.755646705627, "episode/length": 288.0, "episode/score": 0.08727360054717792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08727360054717792}
{"step": 580200, "time": 18502.22769331932, "episode/length": 22.0, "episode/score": 0.9541340670668887, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.02288409172365391}
{"step": 580448, "time": 18510.05081653595, "episode/length": 214.0, "episode/score": 0.4354984348160542, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.10424842452493976}
{"step": 580584, "time": 18513.997847557068, "episode/length": 288.0, "episode/score": 0.0757993478989647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0757993478989647}
{"step": 580648, "time": 18516.074288129807, "episode/length": 234.0, "episode/score": 0.43094242302163366, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.16219241226485792}
{"step": 580712, "time": 18518.048284053802, "episode/length": 288.0, "episode/score": 0.11053589372590977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11053589372590977}
{"step": 580768, "time": 18520.007672309875, "episode/length": 288.0, "episode/score": 0.09033244514830585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09033244514830585}
{"step": 581120, "time": 18530.8191716671, "episode/length": 166.0, "episode/score": 0.5552620341727561, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.07401205953965473}
{"step": 582016, "time": 18559.153980255127, "episode/length": 288.0, "episode/score": 0.06509049573037373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06509049573037373}
{"step": 582144, "time": 18563.11145401001, "episode/length": 194.0, "episode/score": 0.4846899448155, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.09093993522287747}
{"step": 582344, "time": 18569.04065656662, "episode/length": 203.0, "episode/score": 0.5140644231828446, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.14843943147161553}
{"step": 582344, "time": 18569.050008058548, "episode/length": 152.0, "episode/score": 0.6272330687500016, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.10223309422167404}
{"step": 582512, "time": 18574.570336580276, "episode/length": 288.0, "episode/score": 0.1105215604991372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1105215604991372}
{"step": 582760, "time": 18582.244131803513, "episode/length": 288.0, "episode/score": 0.14069522682484603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14069522682484603}
{"step": 582880, "time": 18586.19782114029, "episode/length": 91.0, "episode/score": 0.775993558913342, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.06036854219610177}
{"step": 582960, "time": 18588.653054714203, "episode/length": 288.0, "episode/score": 0.12054846373689543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12054846373689543}
{"step": 583080, "time": 18592.1247010231, "episode/length": 288.0, "episode/score": 0.14451913562788832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14451913562788832}
{"step": 583208, "time": 18596.06403541565, "episode/length": 148.0, "episode/score": 0.6108414205086774, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.07334139748172674}
{"step": 583296, "time": 18598.986719846725, "episode/length": 51.0, "episode/score": 0.8707399594622984, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0301149570641428}
{"step": 583520, "time": 18605.98291182518, "episode/length": 146.0, "episode/score": 0.6297630365243094, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.08601305077354482}
{"step": 583624, "time": 18608.97245144844, "episode/length": 138.0, "episode/score": 0.6610602239297805, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.09231017674665054}
{"step": 583648, "time": 18609.952059030533, "episode/length": 70.0, "episode/score": 0.8342379443602113, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.052987925035267835}
{"step": 583712, "time": 18611.914093017578, "episode/length": 170.0, "episode/score": 0.5491373643385487, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.08038736477510611}
{"step": 583712, "time": 18611.91966485977, "episode/length": 62.0, "episode/score": 0.8567893513736635, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.05053937684533594}
{"step": 583984, "time": 18620.281490564346, "episode/length": 44.0, "episode/score": 0.889221910798824, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.026721900507709506}
{"step": 584120, "time": 18624.246635198593, "episode/length": 74.0, "episode/score": 0.8098451414639385, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.04109514246511026}
{"step": 584280, "time": 18629.15026640892, "episode/length": 78.0, "episode/score": 0.8110175210258603, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.05476746854583325}
{"step": 584312, "time": 18630.12993121147, "episode/length": 74.0, "episode/score": 0.8175431483505236, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.04879312007324188}
{"step": 584384, "time": 18632.559515953064, "episode/length": 49.0, "episode/score": 0.8597262712100928, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.012851251110987505}
{"step": 584600, "time": 18639.21065378189, "episode/length": 39.0, "episode/score": 0.8996490937081489, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.021524082602127237}
{"step": 585072, "time": 18653.930532693863, "episode/length": 288.0, "episode/score": 0.08210550931835314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08210550931835314}
{"step": 585272, "time": 18659.860392570496, "episode/length": 288.0, "episode/score": 0.0975848032144313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0975848032144313}
{"step": 585272, "time": 18659.866330862045, "episode/length": 83.0, "episode/score": 0.7996556211144252, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.05903059808747457}
{"step": 585472, "time": 18666.361359119415, "episode/length": 271.0, "episode/score": 0.20586933823528852, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.05274433758336272}
{"step": 585800, "time": 18676.21325969696, "episode/length": 40.0, "episode/score": 0.9351311480095319, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.060131150337838335}
{"step": 586000, "time": 18682.581426382065, "episode/length": 115.0, "episode/score": 0.7331731629533351, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.09254816458314963}
{"step": 586024, "time": 18683.10269188881, "episode/length": 288.0, "episode/score": 0.09161171668665702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09161171668665702}
{"step": 586040, "time": 18683.61549091339, "episode/length": 95.0, "episode/score": 0.7938067755114844, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.09068177783979081}
{"step": 586080, "time": 18685.060394763947, "episode/length": 100.0, "episode/score": 0.7333804887803126, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.04588047242395987}
{"step": 586432, "time": 18695.973417282104, "episode/length": 288.0, "episode/score": 0.11533109661172603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11533109661172603}
{"step": 586624, "time": 18701.87296319008, "episode/length": 288.0, "episode/score": 0.109915457001307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.109915457001307}
{"step": 586696, "time": 18703.904044151306, "episode/length": 288.0, "episode/score": 0.11162314650346161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11162314650346161}
{"step": 587072, "time": 18715.63404774666, "episode/length": 130.0, "episode/score": 0.6903367611021167, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.09658673246394756}
{"step": 587120, "time": 18717.102746248245, "episode/length": 134.0, "episode/score": 0.667232082589635, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0859820722985205}
{"step": 587248, "time": 18721.04019999504, "episode/length": 68.0, "episode/score": 0.8408434199563999, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.05334339774435648}
{"step": 587352, "time": 18724.025772571564, "episode/length": 158.0, "episode/score": 0.6018238462766021, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.09557383535684494}
{"step": 587840, "time": 18739.472576141357, "episode/length": 73.0, "episode/score": 0.8268189101390817, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.054943887927038304}
{"step": 587904, "time": 18741.44288134575, "episode/length": 183.0, "episode/score": 0.5339835851928001, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.10585860407536529}
{"step": 588104, "time": 18747.348615169525, "episode/length": 287.0, "episode/score": 0.22314215345932098, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.12001715297037663}
{"step": 588312, "time": 18753.760687828064, "episode/length": 288.0, "episode/score": 0.09298424191729282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09298424191729282}
{"step": 588928, "time": 18772.976313829422, "episode/length": 127.0, "episode/score": 0.6421670838767568, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.03904209339953013}
{"step": 588936, "time": 18773.009729623795, "episode/length": 288.0, "episode/score": 0.11803248749401973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11803248749401973}
{"step": 589008, "time": 18775.432114362717, "episode/length": 86.0, "episode/score": 0.7964833416422152, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.06523336648524491}
{"step": 589120, "time": 18778.880609989166, "episode/length": 126.0, "episode/score": 0.6722528277184665, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.06600282532031088}
{"step": 589384, "time": 18786.86053133011, "episode/length": 288.0, "episode/score": 0.11392915939381965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11392915939381965}
{"step": 589432, "time": 18788.355899333954, "episode/length": 288.0, "episode/score": 0.09279320014070436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09279320014070436}
{"step": 589664, "time": 18795.703147411346, "episode/length": 288.0, "episode/score": 0.05591125992691559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05591125992691559}
{"step": 590088, "time": 18808.981714963913, "episode/length": 52.0, "episode/score": 0.8794206164577645, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.041920641114529644}
{"step": 590096, "time": 18810.454451084137, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 590096, "time": 18810.676296710968, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 590096, "time": 18810.727962255478, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 590096, "time": 18811.024215698242, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 590096, "time": 18811.23398566246, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 590096, "time": 18812.443430662155, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 590096, "time": 18812.463697195053, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 590096, "time": 18813.961180210114, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590096, "time": 18813.967459201813, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590096, "time": 18813.973121643066, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590152, "time": 18815.55885195732, "episode/length": 288.0, "episode/score": 0.08536853258715382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08536853258715382}
{"step": 590296, "time": 18819.993344068527, "episode/length": 113.0, "episode/score": 0.7176627369358357, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.07078771390888505}
{"step": 590584, "time": 18828.867805957794, "episode/length": 143.0, "episode/score": 0.6316397775112819, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.07851473731307124}
{"step": 590904, "time": 18838.69521832466, "episode/length": 93.0, "episode/score": 0.7750094867437838, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0656344758240266}
{"step": 591152, "time": 18846.677305459976, "episode/length": 70.0, "episode/score": 0.7985293875481148, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.017279358153245994}
{"step": 591240, "time": 18849.1482257843, "episode/length": 288.0, "episode/score": 0.05463201197289891, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05463201197289891}
{"step": 591248, "time": 18849.619473218918, "episode/length": 288.0, "episode/score": 0.07547426539167645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07547426539167645}
{"step": 591320, "time": 18851.634926319122, "episode/length": 288.0, "episode/score": 0.10072222712278744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10072222712278744}
{"step": 591432, "time": 18855.06552195549, "episode/length": 288.0, "episode/score": 0.05003549754508185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05003549754508185}
{"step": 591568, "time": 18859.463047981262, "episode/length": 51.0, "episode/score": 0.8684217667482699, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.027796762312846113}
{"step": 591944, "time": 18870.910548448563, "episode/length": 129.0, "episode/score": 0.6298604225470399, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.03298538728483891}
{"step": 592120, "time": 18876.523863315582, "episode/length": 99.0, "episode/score": 0.7042704262699999, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.013645400029986376}
{"step": 592400, "time": 18885.381239175797, "episode/length": 288.0, "episode/score": 0.0843066481936603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0843066481936603}
{"step": 592608, "time": 18891.80197429657, "episode/length": 288.0, "episode/score": 0.07632172650346547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07632172650346547}
{"step": 593552, "time": 18920.918731212616, "episode/length": 288.0, "episode/score": 0.06902881250539394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06902881250539394}
{"step": 593560, "time": 18920.95241713524, "episode/length": 288.0, "episode/score": 0.046371729590532595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046371729590532595}
{"step": 593744, "time": 18926.8156580925, "episode/length": 288.0, "episode/score": 0.08328004348129525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08328004348129525}
{"step": 593880, "time": 18930.790087223053, "episode/length": 288.0, "episode/score": 0.09612362450968703, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09612362450968703}
{"step": 594216, "time": 18941.272056102753, "episode/length": 283.0, "episode/score": 0.24537482695529889, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.12974982604725938}
{"step": 594432, "time": 18948.239158153534, "episode/length": 288.0, "episode/score": 0.06189212747210604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06189212747210604}
{"step": 594592, "time": 18953.151113271713, "episode/length": 88.0, "episode/score": 0.7792673409924191, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.054267300794208495}
{"step": 594712, "time": 18956.634492635727, "episode/length": 288.0, "episode/score": 0.0997248422369239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0997248422369239}
{"step": 594920, "time": 18963.033873796463, "episode/length": 288.0, "episode/score": 0.09970565937874198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09970565937874198}
{"step": 595480, "time": 18980.33988046646, "episode/length": 240.0, "episode/score": 0.31563431782808493, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0656343283054639}
{"step": 595536, "time": 18982.2784011364, "episode/length": 223.0, "episode/score": 0.39029542238154136, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0871704348030562}
{"step": 595856, "time": 18992.114946603775, "episode/length": 157.0, "episode/score": 0.5439985638854523, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.03462355833244146}
{"step": 595872, "time": 18992.613401651382, "episode/length": 288.0, "episode/score": 0.04366269539616496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04366269539616496}
{"step": 596296, "time": 19005.549085617065, "episode/length": 94.0, "episode/score": 0.7631535425377933, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.05690350122199561}
{"step": 596416, "time": 19009.442001581192, "episode/length": 67.0, "episode/score": 0.8353897434282089, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.04476474794512342}
{"step": 596528, "time": 19012.895392656326, "episode/length": 288.0, "episode/score": 0.11738612316105446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11738612316105446}
{"step": 596744, "time": 19019.319478034973, "episode/length": 288.0, "episode/score": 0.07857102172374653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07857102172374653}
{"step": 596896, "time": 19024.265727043152, "episode/length": 246.0, "episode/score": 0.32315826486842525, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.09190826043300149}
{"step": 597024, "time": 19028.408770799637, "episode/length": 288.0, "episode/score": 0.12897941829294268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12897941829294268}
{"step": 597312, "time": 19037.360856056213, "episode/length": 126.0, "episode/score": 0.6381291966284834, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.03187920037123604}
{"step": 597448, "time": 19041.40083503723, "episode/length": 114.0, "episode/score": 0.7290878206757725, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.08533779443575895}
{"step": 597488, "time": 19042.8759496212, "episode/length": 73.0, "episode/score": 0.8324304503501025, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.060555450664423915}
{"step": 597640, "time": 19047.412845611572, "episode/length": 18.0, "episode/score": 0.9648137417433418, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.021063698576540446}
{"step": 597792, "time": 19052.379328489304, "episode/length": 288.0, "episode/score": 0.05815622792596287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05815622792596287}
{"step": 598168, "time": 19064.547376394272, "episode/length": 288.0, "episode/score": 0.07530127639705597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07530127639705597}
{"step": 598728, "time": 19081.823417901993, "episode/length": 288.0, "episode/score": 0.05637549151981602, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05637549151981602}
{"step": 599056, "time": 19092.174084424973, "episode/length": 288.0, "episode/score": 0.06872542234282264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06872542234282264}
{"step": 599336, "time": 19100.543846845627, "episode/length": 288.0, "episode/score": 0.12749463603756794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12749463603756794}
{"step": 599624, "time": 19109.366886615753, "episode/length": 288.0, "episode/score": 0.07967794974354092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07967794974354092}
{"step": 599760, "time": 19113.75683784485, "episode/length": 288.0, "episode/score": 0.11968462710996164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11968462710996164}
{"step": 599912, "time": 19118.313683271408, "episode/length": 147.0, "episode/score": 0.6398237690200403, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.09919876422372909}
{"step": 599952, "time": 19119.77783894539, "episode/length": 288.0, "episode/score": 0.04674134289336962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04674134289336962}
{"step": 600000, "time": 19121.249254465103, "episode/length": 46.0, "episode/score": 0.8913236808593865, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.035073695108621905}
{"step": 600080, "time": 19124.28531718254, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 600080, "time": 19124.871339082718, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 600080, "time": 19125.2877471447, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 600080, "time": 19126.369983673096, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 600080, "time": 19127.705704927444, "eval_episode/length": 179.0, "eval_episode/score": 0.44062501192092896, "eval_episode/reward_rate": 0.005555555555555556}
{"step": 600080, "time": 19128.27845454216, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19128.28470635414, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19128.290272951126, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19128.2957611084, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19128.301202058792, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19128.306571245193, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600104, "time": 19128.83138871193, "episode/length": 288.0, "episode/score": 0.07525723062911993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07525723062911993}
{"step": 600312, "time": 19135.250030517578, "episode/length": 68.0, "episode/score": 0.8452998317020501, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.05779981018849867}
{"step": 600368, "time": 19137.186967134476, "episode/length": 32.0, "episode/score": 0.9266484324539306, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.026648457925602997}
{"step": 600480, "time": 19140.6575922966, "episode/length": 288.0, "episode/score": 0.1288859278390646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1288859278390646}
{"step": 600792, "time": 19150.13302707672, "episode/length": 109.0, "episode/score": 0.7320655257294675, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.07269051543835303}
{"step": 601368, "time": 19167.84304523468, "episode/length": 288.0, "episode/score": 0.08967060012491856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08967060012491856}
{"step": 601648, "time": 19176.791596889496, "episode/length": 288.0, "episode/score": 0.09914442743229301, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09914442743229301}
{"step": 602264, "time": 19195.475873470306, "episode/length": 288.0, "episode/score": 0.07085987463187848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07085987463187848}
{"step": 602312, "time": 19196.978007555008, "episode/length": 288.0, "episode/score": 0.05027003473196601, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05027003473196601}
{"step": 602552, "time": 19204.37659931183, "episode/length": 219.0, "episode/score": 0.39228023052396566, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.07665521976718992}
{"step": 602624, "time": 19206.897327661514, "episode/length": 288.0, "episode/score": 0.07796834940290864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07796834940290864}
{"step": 602680, "time": 19208.417102336884, "episode/length": 288.0, "episode/score": 0.050629841932732234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050629841932732234}
{"step": 602792, "time": 19211.85817837715, "episode/length": 288.0, "episode/score": 0.08583437864467669, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08583437864467669}
{"step": 602816, "time": 19212.815161943436, "episode/length": 68.0, "episode/score": 0.8130692001702755, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.02556915997206488}
{"step": 603056, "time": 19220.295924663544, "episode/length": 46.0, "episode/score": 0.8782513779053716, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.022001391456115016}
{"step": 603296, "time": 19227.758589982986, "episode/length": 92.0, "episode/score": 0.744048849033561, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.03154885855633438}
{"step": 603520, "time": 19234.647745847702, "episode/length": 57.0, "episode/score": 0.8357970974907403, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.013922107013513596}
{"step": 603593, "time": 19237.73545408249, "train_stats/mean_log_entropy": 0.11028936624894907, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2109257861821336, "train/action_min": 0.0, "train/action_std": 1.6918406510593915, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013793591529864705, "train/actor_opt_grad_steps": 36635.0, "train/actor_opt_loss": -2.8800621071472916, "train/adv_mag": 0.7575658866853425, "train/adv_max": 0.3296267558829953, "train/adv_mean": 0.009212611215660199, "train/adv_min": -0.7383234404554271, "train/adv_std": 0.04413680162755867, "train/cont_avg": 0.9961480034722222, "train/cont_loss_mean": 0.016732632860451974, "train/cont_loss_std": 0.24394160369058338, "train/cont_neg_acc": 0.2567746726815234, "train/cont_neg_loss": 3.4198209304727385, "train/cont_pos_acc": 0.9996978071602908, "train/cont_pos_loss": 0.0033231073310786875, "train/cont_pred": 0.9960073900945259, "train/cont_rate": 0.9961480034722222, "train/dyn_loss_mean": 1.000078209722885, "train/dyn_loss_std": 0.002043441355444792, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.5431593661431713, "train/extr_critic_critic_opt_grad_steps": 36635.0, "train/extr_critic_critic_opt_loss": 10774.596618035826, "train/extr_critic_mag": 0.9497077272395895, "train/extr_critic_max": 0.9497077272395895, "train/extr_critic_mean": 0.8733856807453464, "train/extr_critic_min": 0.8027160908236648, "train/extr_critic_std": 0.018284347458657892, "train/extr_return_normed_mag": 0.7287162674797906, "train/extr_return_normed_max": 0.38931747006647516, "train/extr_return_normed_mean": 0.053822415019503106, "train/extr_return_normed_min": -0.6986164507841823, "train/extr_return_normed_std": 0.04925833814871507, "train/extr_return_rate": 0.9965514977170964, "train/extr_return_raw_mag": 1.2180933253933686, "train/extr_return_raw_max": 1.2180933253933686, "train/extr_return_raw_mean": 0.882598312515201, "train/extr_return_raw_min": 0.13015940454271105, "train/extr_return_raw_std": 0.049258338336861045, "train/extr_reward_mag": 0.37554869085851345, "train/extr_reward_max": 0.37554869085851345, "train/extr_reward_mean": 0.00309023708269715, "train/extr_reward_min": 7.227213695795849e-06, "train/extr_reward_std": 0.016027115224249135, "train/image_loss_mean": 0.11986576946395816, "train/image_loss_std": 0.10991112857755989, "train/model_loss_mean": 0.7579108922168462, "train/model_loss_std": 0.3427703982651836, "train/model_opt_grad_norm": 22.977752309856992, "train/model_opt_grad_steps": 36602.21212121212, "train/model_opt_loss": 3789.5544643209437, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5025.252525252526, "train/policy_entropy_mag": 1.3827625519097453, "train/policy_entropy_max": 1.3827625519097453, "train/policy_entropy_mean": 0.12827828089998225, "train/policy_entropy_min": 0.06468651413616508, "train/policy_entropy_std": 0.16611045493622018, "train/policy_logprob_mag": 6.551080246164341, "train/policy_logprob_max": -0.008608139717405794, "train/policy_logprob_mean": -0.12795228819654444, "train/policy_logprob_min": -6.551080246164341, "train/policy_logprob_std": 0.662540655545514, "train/policy_randomness_mag": 0.7105994245620689, "train/policy_randomness_max": 0.7105994245620689, "train/policy_randomness_mean": 0.06592199998446788, "train/policy_randomness_min": 0.03324229337952354, "train/policy_randomness_std": 0.08536389227392095, "train/post_ent_mag": 6.59174852660208, "train/post_ent_max": 6.59174852660208, "train/post_ent_mean": 6.3105412830006, "train/post_ent_min": 6.114129104999581, "train/post_ent_std": 0.1118955577187466, "train/prior_ent_mag": 7.950353251563178, "train/prior_ent_max": 7.950353251563178, "train/prior_ent_mean": 3.797811160183916, "train/prior_ent_min": 3.079543957806597, "train/prior_ent_std": 0.6410748184931399, "train/rep_loss_mean": 1.000078209722885, "train/rep_loss_std": 0.002043441355444792, "train/reward_avg": 0.0009736393422836137, "train/reward_loss_mean": 0.021265538851495343, "train/reward_loss_std": 0.10547229845189687, "train/reward_max_data": 0.38602769800762865, "train/reward_max_pred": 0.13638333118323123, "train/reward_neg_acc": 0.9998222736999242, "train/reward_neg_loss": 0.017668107383404717, "train/reward_pos_acc": 0.30930931020427394, "train/reward_pos_loss": 4.126204082557747, "train/reward_pred": 0.000843600191251196, "train/reward_rate": 0.0008779198232323232, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.006619034800678492, "report/cont_loss_std": 0.13504339754581451, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.321956634521484, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00240071932785213, "report/cont_pred": 0.9976078271865845, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08845476806163788, "report/image_loss_std": 0.0969291627407074, "report/model_loss_mean": 0.7179368734359741, "report/model_loss_std": 0.31860771775245667, "report/post_ent_mag": 6.0090460777282715, "report/post_ent_max": 6.0090460777282715, "report/post_ent_mean": 5.701305389404297, "report/post_ent_min": 5.513619422912598, "report/post_ent_std": 0.09654927253723145, "report/prior_ent_mag": 6.469852924346924, "report/prior_ent_max": 6.469852924346924, "report/prior_ent_mean": 3.296266794204712, "report/prior_ent_min": 2.9098217487335205, "report/prior_ent_std": 0.4151707887649536, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0011836225166916847, "report/reward_loss_mean": 0.022863034158945084, "report/reward_loss_std": 0.15430280566215515, "report/reward_max_data": 0.7774999737739563, "report/reward_max_pred": 0.03707313537597656, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.018107131123542786, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.888150215148926, "report/reward_pred": 0.0010585370473563671, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.028888754546642303, "eval/cont_loss_std": 0.451924204826355, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.87752103805542, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.002031373791396618, "eval/cont_pred": 0.9979631304740906, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19430074095726013, "eval/image_loss_std": 0.14449992775917053, "eval/model_loss_mean": 0.8306760191917419, "eval/model_loss_std": 0.5152986645698547, "eval/post_ent_mag": 6.020940780639648, "eval/post_ent_max": 6.020940780639648, "eval/post_ent_mean": 5.666594505310059, "eval/post_ent_min": 5.51619815826416, "eval/post_ent_std": 0.09441618621349335, "eval/prior_ent_mag": 5.215213298797607, "eval/prior_ent_max": 5.215213298797607, "eval/prior_ent_mean": 3.195566177368164, "eval/prior_ent_min": 2.8718714714050293, "eval/prior_ent_std": 0.39472225308418274, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0006896972772665322, "eval/reward_loss_mean": 0.007486501708626747, "eval/reward_loss_std": 0.13118453323841095, "eval/reward_max_data": 0.706250011920929, "eval/reward_max_pred": 0.02824115753173828, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0033873608335852623, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.2009077072143555, "eval/reward_pred": 0.0007387377554550767, "eval/reward_rate": 0.0009765625, "replay/size": 603089.0, "replay/inserts": 31776.0, "replay/samples": 31776.0, "replay/insert_wait_avg": 1.191094982900168e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.727895258416583e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6728.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.660417486456146e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0496468544006, "timer/env.step_count": 3972.0, "timer/env.step_total": 34.206475496292114, "timer/env.step_frac": 0.034204777336691874, "timer/env.step_avg": 0.00861190218939882, "timer/env.step_min": 0.007193565368652344, "timer/env.step_max": 0.037297725677490234, "timer/replay._sample_count": 31776.0, "timer/replay._sample_total": 15.943509578704834, "timer/replay._sample_frac": 0.01594271807290192, "timer/replay._sample_avg": 0.0005017469026530977, "timer/replay._sample_min": 0.0003876686096191406, "timer/replay._sample_max": 0.010992050170898438, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4813.0, "timer/agent.policy_total": 40.42847442626953, "timer/agent.policy_frac": 0.04042646737932962, "timer/agent.policy_avg": 0.008399849247095269, "timer/agent.policy_min": 0.007447719573974609, "timer/agent.policy_max": 0.0727684497833252, "timer/dataset_train_count": 1986.0, "timer/dataset_train_total": 0.20673513412475586, "timer/dataset_train_frac": 0.00020672487088519003, "timer/dataset_train_avg": 0.0001040962407476112, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.001085519790649414, "timer/agent.train_count": 1986.0, "timer/agent.train_total": 878.7588746547699, "timer/agent.train_frac": 0.8787152492067329, "timer/agent.train_avg": 0.4424767747506394, "timer/agent.train_min": 0.4302971363067627, "timer/agent.train_max": 0.6480977535247803, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47980761528015137, "timer/agent.report_frac": 0.0004797837955239112, "timer/agent.report_avg": 0.23990380764007568, "timer/agent.report_min": 0.23375678062438965, "timer/agent.report_max": 0.24605083465576172, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.765518218297799e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 31.773888931893698}
{"step": 603680, "time": 19240.408891677856, "episode/length": 288.0, "episode/score": 0.09884469431494836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09884469431494836}
{"step": 603688, "time": 19240.441502332687, "episode/length": 48.0, "episode/score": 0.8722556977357954, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.02225565055266543}
{"step": 603960, "time": 19248.820113420486, "episode/length": 288.0, "episode/score": 0.10469698322663135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10469698322663135}
{"step": 604584, "time": 19268.025642871857, "episode/length": 77.0, "episode/score": 0.7720265301878726, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.012651524634861744}
{"step": 604624, "time": 19269.494612455368, "episode/length": 288.0, "episode/score": 0.05330883577732948, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05330883577732948}
{"step": 604760, "time": 19273.45488858223, "episode/length": 245.0, "episode/score": 0.323268941363267, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.08889394369157344}
{"step": 604936, "time": 19278.86426258087, "episode/length": 288.0, "episode/score": 0.06683312299935551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06683312299935551}
{"step": 605128, "time": 19284.76159620285, "episode/length": 288.0, "episode/score": 0.05258576174037444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05258576174037444}
{"step": 605256, "time": 19288.696832180023, "episode/length": 61.0, "episode/score": 0.8327389683656747, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.02336396689884168}
{"step": 605488, "time": 19296.179511785507, "episode/length": 107.0, "episode/score": 0.6991745723986469, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0335495978703193}
{"step": 605808, "time": 19306.001006364822, "episode/length": 264.0, "episode/score": 0.2571786430046359, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.08217864714902134}
{"step": 605832, "time": 19306.524898290634, "episode/length": 288.0, "episode/score": 0.04538891915365184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04538891915365184}
{"step": 605992, "time": 19311.448407411575, "episode/length": 288.0, "episode/score": 0.03494889787646116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03494889787646116}
{"step": 606896, "time": 19339.990344285965, "episode/length": 288.0, "episode/score": 0.08390032958755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08390032958755}
{"step": 607248, "time": 19350.7861866951, "episode/length": 288.0, "episode/score": 0.06229266905336317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06229266905336317}
{"step": 607288, "time": 19351.796460151672, "episode/length": 161.0, "episode/score": 0.5205480679755965, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.023673080711432704}
{"step": 607440, "time": 19356.785902023315, "episode/length": 288.0, "episode/score": 0.07851100697337188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07851100697337188}
{"step": 607568, "time": 19360.726530313492, "episode/length": 288.0, "episode/score": 0.06840915409100035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06840915409100035}
{"step": 607800, "time": 19367.6365442276, "episode/length": 288.0, "episode/score": 0.08877009805678426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08877009805678426}
{"step": 607928, "time": 19371.5652179718, "episode/length": 261.0, "episode/score": 0.23789445549283528, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.053519452949160495}
{"step": 607992, "time": 19373.5393948555, "episode/length": 52.0, "episode/score": 0.8620853005173785, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.024585317199694146}
{"step": 608120, "time": 19377.475133419037, "episode/length": 288.0, "episode/score": 0.05198416555555241, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05198416555555241}
{"step": 608568, "time": 19391.322664499283, "episode/length": 79.0, "episode/score": 0.8063179702081698, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.05319294489947879}
{"step": 609048, "time": 19406.081532478333, "episode/length": 200.0, "episode/score": 0.4621255491684906, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0871255503326438}
{"step": 609208, "time": 19411.003418922424, "episode/length": 288.0, "episode/score": 0.04686706115933248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04686706115933248}
{"step": 609376, "time": 19416.48451280594, "episode/length": 100.0, "episode/score": 0.7229009516261158, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.03540097578229506}
{"step": 609560, "time": 19421.942857265472, "episode/length": 288.0, "episode/score": 0.08948830908656191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08948830908656191}
{"step": 609600, "time": 19423.399937152863, "episode/length": 288.0, "episode/score": 0.07945942696551356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07945942696551356}
{"step": 609856, "time": 19431.282322645187, "episode/length": 59.0, "episode/score": 0.8363341762786831, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.020709135719584992}
{"step": 610032, "time": 19436.705953598022, "episode/length": 122.0, "episode/score": 0.6840984194822681, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.06534845624622676}
{"step": 610064, "time": 19438.27229976654, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 610064, "time": 19438.369055509567, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 610064, "time": 19438.937527418137, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 610064, "time": 19439.73724603653, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 610064, "time": 19440.585812807083, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 610064, "time": 19440.767705202103, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 610064, "time": 19440.865619897842, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 610064, "time": 19441.162855386734, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 610088, "time": 19441.68107318878, "episode/length": 245.0, "episode/score": 0.2920130570431638, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0576380555879723}
{"step": 610096, "time": 19442.153569459915, "episode/length": 66.0, "episode/score": 0.8470191170575276, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.053269141900557315}
{"step": 610112, "time": 19442.647703409195, "episode/length": 288.0, "episode/score": 0.039310627201871284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039310627201871284}
{"step": 610304, "time": 19448.77384710312, "episode/length": 288.0, "episode/score": 0.081019593246765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.081019593246765}
{"step": 610512, "time": 19455.28900551796, "episode/length": 113.0, "episode/score": 0.719611239639562, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0727362181260105}
{"step": 610528, "time": 19455.789071321487, "episode/length": 61.0, "episode/score": 0.875596184313963, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.06622119856319841}
{"step": 610536, "time": 19455.82155919075, "episode/length": 54.0, "episode/score": 0.8747794993523144, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.04352948975969184}
{"step": 610816, "time": 19464.690999507904, "episode/length": 87.0, "episode/score": 0.8223498504609665, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.09422487593263895}
{"step": 610896, "time": 19467.160528421402, "episode/length": 129.0, "episode/score": 0.6690093261240122, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.07213431653138969}
{"step": 611088, "time": 19473.05887889862, "episode/length": 124.0, "episode/score": 0.6961639549922438, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.08366391443314569}
{"step": 611128, "time": 19474.072125434875, "episode/length": 76.0, "episode/score": 0.81683084969427, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.05433086243010621}
{"step": 611128, "time": 19474.07781147957, "episode/length": 102.0, "episode/score": 0.7663208684080018, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.08507090517196048}
{"step": 611320, "time": 19480.128964662552, "episode/length": 52.0, "episode/score": 0.8692331317733988, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.031733156430163945}
{"step": 611472, "time": 19485.047267198563, "episode/length": 47.0, "episode/score": 0.8859315800000331, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.03280657520372188}
{"step": 611520, "time": 19486.54150891304, "episode/length": 288.0, "episode/score": 0.09918919693990347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09918919693990347}
{"step": 611912, "time": 19498.461510181427, "episode/length": 97.0, "episode/score": 0.7671387768386921, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.07026380231036455}
{"step": 611928, "time": 19498.954872846603, "episode/length": 99.0, "episode/score": 0.7404568903157269, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.04983186203844525}
{"step": 611992, "time": 19500.932531118393, "episode/length": 58.0, "episode/score": 0.863202633574474, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.044452593376263394}
{"step": 612104, "time": 19504.346898317337, "episode/length": 160.0, "episode/score": 0.5860164643981989, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0860164773202996}
{"step": 612192, "time": 19507.39949154854, "episode/length": 89.0, "episode/score": 0.7870453472487497, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.06517030668965162}
{"step": 612408, "time": 19513.81452012062, "episode/length": 51.0, "episode/score": 0.8701945154780333, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.02956954032106296}
{"step": 612472, "time": 19515.795949935913, "episode/length": 67.0, "episode/score": 0.8182837508015837, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.027658758287088858}
{"step": 612736, "time": 19524.114991903305, "episode/length": 102.0, "episode/score": 0.757216182611046, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.07596619213381928}
{"step": 612840, "time": 19527.094440221786, "episode/length": 288.0, "episode/score": 0.061362224334061466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061362224334061466}
{"step": 612848, "time": 19527.565142154694, "episode/length": 288.0, "episode/score": 0.07101733216927641, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07101733216927641}
{"step": 612896, "time": 19529.03574323654, "episode/length": 52.0, "episode/score": 0.8666519413145579, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.02915196597132308}
{"step": 612912, "time": 19529.54712843895, "episode/length": 62.0, "episode/score": 0.8538687479494911, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.04761875246640557}
{"step": 613136, "time": 19536.51208949089, "episode/length": 35.0, "episode/score": 0.9248171850945255, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.03419218590943274}
{"step": 613296, "time": 19541.40803360939, "episode/length": 148.0, "episode/score": 0.6187266017982438, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.08122656160003316}
{"step": 613568, "time": 19549.76126766205, "episode/length": 53.0, "episode/score": 0.8695678151163975, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.035192791711097016}
{"step": 613632, "time": 19551.721586704254, "episode/length": 288.0, "episode/score": 0.07480020170919488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07480020170919488}
{"step": 613752, "time": 19555.200919151306, "episode/length": 104.0, "episode/score": 0.7282794714101328, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.05327943009433511}
{"step": 614504, "time": 19578.8427131176, "episode/length": 288.0, "episode/score": 0.102423526497887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.102423526497887}
{"step": 614616, "time": 19582.290322303772, "episode/length": 107.0, "episode/score": 0.7110255090440205, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.04540052470770206}
{"step": 614656, "time": 19583.731393814087, "episode/length": 127.0, "episode/score": 0.6681460581830834, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.06502106269999786}
{"step": 614904, "time": 19591.125754594803, "episode/length": 166.0, "episode/score": 0.5420939408720642, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.060843963270372114}
{"step": 615048, "time": 19595.712622880936, "episode/length": 288.0, "episode/score": 0.08082616841920753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08082616841920753}
{"step": 615096, "time": 19597.184770584106, "episode/length": 59.0, "episode/score": 0.8527238096473866, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.03709882188263691}
{"step": 615152, "time": 19599.148368358612, "episode/length": 288.0, "episode/score": 0.05247273271618269, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05247273271618269}
{"step": 615176, "time": 19599.670934915543, "episode/length": 83.0, "episode/score": 0.775873424383235, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.03524838622229254}
{"step": 615208, "time": 19600.655495405197, "episode/length": 288.0, "episode/score": 0.058677277441233855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058677277441233855}
{"step": 615216, "time": 19601.126639842987, "episode/length": 69.0, "episode/score": 0.8345026939337004, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.05012766769368682}
{"step": 615608, "time": 19612.95483136177, "episode/length": 288.0, "episode/score": 0.04970294173995171, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04970294173995171}
{"step": 616152, "time": 19629.710424423218, "episode/length": 131.0, "episode/score": 0.6237403815216567, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.03311539507240013}
{"step": 616824, "time": 19650.287654161453, "episode/length": 151.0, "episode/score": 0.618212361406222, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.09008737565545744}
{"step": 616968, "time": 19654.699278831482, "episode/length": 218.0, "episode/score": 0.4233481302767359, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.10459813786701488}
{"step": 617216, "time": 19662.590217590332, "episode/length": 288.0, "episode/score": 0.06241689255318761, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06241689255318761}
{"step": 617296, "time": 19665.051994800568, "episode/length": 264.0, "episode/score": 0.32219718731721514, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.1471971914616006}
{"step": 617360, "time": 19667.016374111176, "episode/length": 288.0, "episode/score": 0.07261383082220618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07261383082220618}
{"step": 617368, "time": 19667.04872918129, "episode/length": 49.0, "episode/score": 0.8807561658868508, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.03388115478082909}
{"step": 617464, "time": 19670.000426530838, "episode/length": 288.0, "episode/score": 0.1801005774029818, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.08010057649494229}
{"step": 617472, "time": 19670.471957445145, "episode/length": 164.0, "episode/score": 0.5530355362998307, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.06553552600871626}
{"step": 617520, "time": 19671.949580430984, "episode/length": 288.0, "episode/score": 0.09491205471886133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09491205471886133}
{"step": 617760, "time": 19679.325541973114, "episode/length": 48.0, "episode/score": 0.874825002088528, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.024824991168770794}
{"step": 617856, "time": 19682.255861997604, "episode/length": 61.0, "episode/score": 0.8398400222131386, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.03046501079279551}
{"step": 617872, "time": 19682.77037215233, "episode/length": 49.0, "episode/score": 0.8691087297381728, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.022233694475971788}
{"step": 618080, "time": 19689.23829293251, "episode/length": 76.0, "episode/score": 0.8137455022490485, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.05124549082870544}
{"step": 618128, "time": 19690.704884290695, "episode/length": 75.0, "episode/score": 0.793431717419935, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.02780671785649247}
{"step": 618256, "time": 19694.683507442474, "episode/length": 61.0, "episode/score": 0.8273128466000799, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.017937850342832462}
{"step": 618320, "time": 19696.639143943787, "episode/length": 55.0, "episode/score": 0.8622482936943925, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.03412326505622332}
{"step": 618920, "time": 19714.862038850784, "episode/length": 98.0, "episode/score": 0.735366458450244, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.041616435423293296}
{"step": 619096, "time": 19720.31664466858, "episode/length": 21.0, "episode/score": 0.9504608429633663, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.01608585569920251}
{"step": 619136, "time": 19721.75877404213, "episode/length": 288.0, "episode/score": 0.08641485022758388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08641485022758388}
{"step": 619264, "time": 19725.704744577408, "episode/length": 117.0, "episode/score": 0.6781658954648719, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0437909201216371}
{"step": 619336, "time": 19727.707193613052, "episode/length": 134.0, "episode/score": 0.653313082938439, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0720630839396108}
{"step": 619528, "time": 19733.59042930603, "episode/length": 288.0, "episode/score": 0.026113365142236944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026113365142236944}
{"step": 619608, "time": 19736.040746212006, "episode/length": 288.0, "episode/score": 0.07291728920904461, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07291728920904461}
{"step": 619872, "time": 19744.375668287277, "episode/length": 75.0, "episode/score": 0.8058714553544633, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.04024643602951983}
{"step": 619984, "time": 19747.927468061447, "episode/length": 56.0, "episode/score": 0.8498443710639094, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.02484435964356635}
{"step": 620048, "time": 19750.566379070282, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 620048, "time": 19750.851469039917, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 620048, "time": 19751.103146076202, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 620048, "time": 19751.170113563538, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 620048, "time": 19751.744196653366, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 620048, "time": 19752.061224222183, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 620048, "time": 19752.745047569275, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 620048, "time": 19752.982729911804, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 620088, "time": 19753.995506048203, "episode/length": 118.0, "episode/score": 0.6711707410925101, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0399207090724758}
{"step": 620168, "time": 19756.475402116776, "episode/length": 288.0, "episode/score": 0.05023145087670855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05023145087670855}
{"step": 620392, "time": 19763.34898877144, "episode/length": 288.0, "episode/score": 0.09598745757693905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09598745757693905}
{"step": 620440, "time": 19764.840020656586, "episode/length": 70.0, "episode/score": 0.8059007973536154, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.024650767958746655}
{"step": 620648, "time": 19771.228718042374, "episode/length": 82.0, "episode/score": 0.8051364433488288, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.06138645287160216}
{"step": 620816, "time": 19776.709418535233, "episode/length": 90.0, "episode/score": 0.750026170791898, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.03127616261372168}
{"step": 621056, "time": 19784.071088314056, "episode/length": 82.0, "episode/score": 0.7744972928496736, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.03074730953198923}
{"step": 621248, "time": 19789.989980459213, "episode/length": 74.0, "episode/score": 0.8185991847499281, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.04984915350405572}
{"step": 621360, "time": 19793.428502082825, "episode/length": 67.0, "episode/score": 0.8216026466400308, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.030977694638067987}
{"step": 621408, "time": 19794.925246953964, "episode/length": 288.0, "episode/score": 0.03303552422062239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03303552422062239}
{"step": 621584, "time": 19800.33327937126, "episode/length": 41.0, "episode/score": 0.8990770132949137, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.027202005890899272}
{"step": 621648, "time": 19802.299052476883, "episode/length": 288.0, "episode/score": 0.06539187518694689, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06539187518694689}
{"step": 621720, "time": 19804.302907943726, "episode/length": 38.0, "episode/score": 0.8951980079615396, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.013947970731919668}
{"step": 621920, "time": 19810.78040766716, "episode/length": 288.0, "episode/score": 0.0661356665347057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0661356665347057}
{"step": 622080, "time": 19815.727991580963, "episode/length": 61.0, "episode/score": 0.8607269265961577, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.051351909122217876}
{"step": 622424, "time": 19826.055914878845, "episode/length": 87.0, "episode/score": 0.7798174871844594, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.051692502848140975}
{"step": 622480, "time": 19828.000752449036, "episode/length": 288.0, "episode/score": 0.06559922875089796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06559922875089796}
{"step": 622584, "time": 19830.974424362183, "episode/length": 152.0, "episode/score": 0.6089165653690998, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0839165748918731}
{"step": 622752, "time": 19836.940357923508, "episode/length": 288.0, "episode/score": 0.10742858977994274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10742858977994274}
{"step": 623008, "time": 19844.799047470093, "episode/length": 52.0, "episode/score": 0.8735566419496763, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.036056652403772205}
{"step": 623208, "time": 19850.715131521225, "episode/length": 56.0, "episode/score": 0.8579908304476476, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0329908230436331}
{"step": 623368, "time": 19855.627401590347, "episode/length": 288.0, "episode/score": 0.0960660454184108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0960660454184108}
{"step": 623536, "time": 19861.003734588623, "episode/length": 40.0, "episode/score": 0.9193945660531426, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.044394590209321905}
{"step": 623552, "time": 19861.49952149391, "episode/length": 203.0, "episode/score": 0.46075416605197006, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.09512916636629143}
{"step": 623784, "time": 19868.500459194183, "episode/length": 51.0, "episode/score": 0.8760249567648088, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.03539996912229526}
{"step": 623960, "time": 19873.984278678894, "episode/length": 288.0, "episode/score": 0.10871872357927259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10871872357927259}
{"step": 624360, "time": 19886.26046204567, "episode/length": 168.0, "episode/score": 0.5523322306428327, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.07733223511900178}
{"step": 624392, "time": 19887.24441933632, "episode/length": 288.0, "episode/score": 0.06990144895030426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06990144895030426}
{"step": 624736, "time": 19898.15297317505, "episode/length": 288.0, "episode/score": 0.08410650643122608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08410650643122608}
{"step": 624792, "time": 19899.67691874504, "episode/length": 288.0, "episode/score": 0.1040935680612165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1040935680612165}
{"step": 624912, "time": 19903.60381960869, "episode/length": 14.0, "episode/score": 0.9780607034645072, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.021810693173392792}
{"step": 624944, "time": 19904.590430021286, "episode/length": 122.0, "episode/score": 0.6695468350651481, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.05079688722503306}
{"step": 625672, "time": 19926.891766786575, "episode/length": 94.0, "episode/score": 0.775775273990007, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.06952526439738449}
{"step": 625848, "time": 19932.31680750847, "episode/length": 288.0, "episode/score": 0.03313760260573417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03313760260573417}
{"step": 625864, "time": 19932.817081928253, "episode/length": 288.0, "episode/score": 0.06191306793698459, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06191306793698459}
{"step": 625912, "time": 19934.31265592575, "episode/length": 146.0, "episode/score": 0.6416263265300586, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.09787634008080204}
{"step": 625992, "time": 19936.76637983322, "episode/length": 130.0, "episode/score": 0.6814057337929853, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.08765573612129174}
{"step": 626096, "time": 19940.203692913055, "episode/length": 288.0, "episode/score": 0.08231208041206628, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08231208041206628}
{"step": 626376, "time": 19948.561037540436, "episode/length": 65.0, "episode/score": 0.8532200199933868, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.05634502162320132}
{"step": 626408, "time": 19949.543091773987, "episode/length": 67.0, "episode/score": 0.8235188933431346, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.03289393010709318}
{"step": 626440, "time": 19950.525566339493, "episode/length": 65.0, "episode/score": 0.8568748109282751, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.05999982385037583}
{"step": 626504, "time": 19952.488530635834, "episode/length": 103.0, "episode/score": 0.7356798738474026, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.057554862927645445}
{"step": 626656, "time": 19957.454823493958, "episode/length": 82.0, "episode/score": 0.8157392645534856, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0719892907236499}
{"step": 626672, "time": 19957.9699549675, "episode/length": 288.0, "episode/score": 0.06150284272735007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06150284272735007}
{"step": 626704, "time": 19958.954601049423, "episode/length": 288.0, "episode/score": 0.10004506845234573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10004506845234573}
{"step": 626800, "time": 19961.890263795853, "episode/length": 44.0, "episode/score": 0.911514998916573, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0490149886254585}
{"step": 627160, "time": 19972.729915618896, "episode/length": 93.0, "episode/score": 0.7745057636561796, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.06513074062922897}
{"step": 627200, "time": 19974.183073043823, "episode/length": 137.0, "episode/score": 0.6652740289923713, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.09339902419606005}
{"step": 627304, "time": 19977.149778842926, "episode/length": 115.0, "episode/score": 0.7191754161458448, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.07855042906794552}
{"step": 627432, "time": 19981.080854415894, "episode/length": 33.0, "episode/score": 0.9153130275958574, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.018437989434914925}
{"step": 627568, "time": 19985.564702749252, "episode/length": 32.0, "episode/score": 0.9193609537787779, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.019360954279363796}
{"step": 627632, "time": 19987.54551076889, "episode/length": 53.0, "episode/score": 0.8708302844770515, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.03645526145010081}
{"step": 627832, "time": 19993.466991901398, "episode/length": 140.0, "episode/score": 0.663423891074217, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.10092390399631768}
{"step": 627944, "time": 19996.892419338226, "episode/length": 63.0, "episode/score": 0.8435593293359034, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.04043428215277345}
{"step": 628208, "time": 20005.23872447014, "episode/length": 32.0, "episode/score": 0.9124414137991153, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.012441408246104402}
{"step": 628360, "time": 20009.696268558502, "episode/length": 65.0, "episode/score": 0.8448415855662006, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.04796657217843858}
{"step": 628816, "time": 20024.082760810852, "episode/length": 288.0, "episode/score": 0.08683079880347577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08683079880347577}
{"step": 628968, "time": 20028.53208422661, "episode/length": 288.0, "episode/score": 0.050957632410245424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050957632410245424}
{"step": 628984, "time": 20029.029956817627, "episode/length": 288.0, "episode/score": 0.09804028671146625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09804028671146625}
{"step": 629088, "time": 20032.45013642311, "episode/length": 189.0, "episode/score": 0.5034372574245936, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0940622471334791}
{"step": 629112, "time": 20032.971252918243, "episode/length": 288.0, "episode/score": 0.09442884305053667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09442884305053667}
{"step": 629304, "time": 20038.877052545547, "episode/length": 117.0, "episode/score": 0.7227614554203683, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.08838648159053264}
{"step": 629424, "time": 20042.788057804108, "episode/length": 56.0, "episode/score": 0.8582476601204689, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.033247672856305144}
{"step": 629480, "time": 20044.2839717865, "episode/length": 82.0, "episode/score": 0.7895471583351537, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.04579718380682607}
{"step": 629632, "time": 20049.27880167961, "episode/length": 67.0, "episode/score": 0.8276004056760939, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.036975442440052575}
{"step": 629888, "time": 20057.132015943527, "episode/length": 112.0, "episode/score": 0.709161996232524, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.059162032996482594}
{"step": 629944, "time": 20058.63336968422, "episode/length": 288.0, "episode/score": 0.10370607326080972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10370607326080972}
{"step": 630032, "time": 20062.623125076294, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 630032, "time": 20062.62827396393, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 630032, "time": 20062.64882493019, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 630032, "time": 20062.669167280197, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 630032, "time": 20062.891721248627, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 630032, "time": 20063.534354686737, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 630032, "time": 20063.538986444473, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 630032, "time": 20063.576053380966, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 630200, "time": 20068.517101049423, "episode/length": 96.0, "episode/score": 0.7563805806239543, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.05638056390671409}
{"step": 630496, "time": 20077.915013074875, "episode/length": 68.0, "episode/score": 0.8293952850544883, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.04189526202753768}
{"step": 630520, "time": 20078.454551696777, "episode/length": 288.0, "episode/score": 0.06838197456340822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06838197456340822}
{"step": 630936, "time": 20091.696094989777, "episode/length": 54.0, "episode/score": 0.8696756581589398, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.038425647052918066}
{"step": 630952, "time": 20092.19258069992, "episode/length": 164.0, "episode/score": 0.6270360729672575, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.13953606221048176}
{"step": 631000, "time": 20093.68966269493, "episode/length": 99.0, "episode/score": 0.7492862367257658, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.05866119616666765}
{"step": 631224, "time": 20100.556555986404, "episode/length": 33.0, "episode/score": 0.9195088420042339, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.022633789524206804}
{"step": 631272, "time": 20102.02651643753, "episode/length": 93.0, "episode/score": 0.7704651621693301, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.061090121971119515}
{"step": 631424, "time": 20107.022305250168, "episode/length": 288.0, "episode/score": 0.04685010797356881, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04685010797356881}
{"step": 631616, "time": 20112.933878421783, "episode/length": 288.0, "episode/score": 0.13124006455905146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13124006455905146}
{"step": 631736, "time": 20116.40988087654, "episode/length": 57.0, "episode/score": 0.8554075346632999, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.03353257142725852}
{"step": 631792, "time": 20118.36554288864, "episode/length": 288.0, "episode/score": 0.07274808263468913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07274808263468913}
{"step": 631792, "time": 20118.371040821075, "episode/length": 70.0, "episode/score": 0.8304528613180082, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.049202841993064794}
{"step": 632200, "time": 20130.6745095253, "episode/length": 288.0, "episode/score": 0.12004115799845749, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12004115799845749}
{"step": 632376, "time": 20136.21205306053, "episode/length": 72.0, "episode/score": 0.8012055435601724, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.02620554807708686}
{"step": 632912, "time": 20152.979100227356, "episode/length": 139.0, "episode/score": 0.6415467711801739, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0759217596958024}
{"step": 633248, "time": 20163.45722913742, "episode/length": 288.0, "episode/score": 0.10262703537205198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10262703537205198}
{"step": 633312, "time": 20165.543448209763, "episode/length": 288.0, "episode/score": 0.1265220639729705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1265220639729705}
{"step": 633736, "time": 20178.453206300735, "episode/length": 288.0, "episode/score": 0.13093482721569671, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13093482721569671}
{"step": 633928, "time": 20184.335376739502, "episode/length": 288.0, "episode/score": 0.0924895853443104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0924895853443104}
{"step": 634048, "time": 20188.250732183456, "episode/length": 288.0, "episode/score": 0.05012765194214808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05012765194214808}
{"step": 634512, "time": 20202.606852054596, "episode/length": 288.0, "episode/score": 0.04322049889128721, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04322049889128721}
{"step": 634688, "time": 20207.995403528214, "episode/length": 288.0, "episode/score": 0.04451689170264217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04451689170264217}
{"step": 635024, "time": 20218.25758123398, "episode/length": 41.0, "episode/score": 0.9058407862812601, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.03396578388310445}
{"step": 635224, "time": 20224.219071626663, "episode/length": 288.0, "episode/score": 0.09052576505041543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09052576505041543}
{"step": 635264, "time": 20225.76845550537, "episode/length": 29.0, "episode/score": 0.9305350444348051, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.02116001318893268}
{"step": 635424, "time": 20230.760408878326, "episode/length": 263.0, "episode/score": 0.29530986551480964, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.11718487191183158}
{"step": 635560, "time": 20234.792091608047, "episode/length": 288.0, "episode/score": 0.08799062820594372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08799062820594372}
{"step": 635625, "time": 20237.794687986374, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4392384391518966, "train/action_min": 0.0, "train/action_std": 1.7461197299150686, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012767187515459029, "train/actor_opt_grad_steps": 38630.0, "train/actor_opt_loss": -6.252754536285923, "train/adv_mag": 0.8679073269094401, "train/adv_max": 0.2798808122155678, "train/adv_mean": 0.003190983972029728, "train/adv_min": -0.8467520771928094, "train/adv_std": 0.037706053811148624, "train/cont_avg": 0.9956759172885572, "train/cont_loss_mean": 0.01636544101412839, "train/cont_loss_std": 0.24066096152507918, "train/cont_neg_acc": 0.31990907416122044, "train/cont_neg_loss": 3.018637261650614, "train/cont_pos_acc": 0.9997217296367854, "train/cont_pos_loss": 0.003255782192816207, "train/cont_pred": 0.9956250315281883, "train/cont_rate": 0.9956759172885572, "train/dyn_loss_mean": 1.0000074704488118, "train/dyn_loss_std": 0.00023893867410830597, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.34324054963034184, "train/extr_critic_critic_opt_grad_steps": 38630.0, "train/extr_critic_critic_opt_loss": 12839.147198577426, "train/extr_critic_mag": 1.0961291422298298, "train/extr_critic_max": 1.0961291422298298, "train/extr_critic_mean": 1.0275690122623349, "train/extr_critic_min": 0.9543351522132532, "train/extr_critic_std": 0.016583049442822958, "train/extr_return_normed_mag": 0.8549394414792606, "train/extr_return_normed_max": 0.32292640060927735, "train/extr_return_normed_mean": 0.03513065909682883, "train/extr_return_normed_min": -0.8242209909567192, "train/extr_return_normed_std": 0.04210424651183299, "train/extr_return_rate": 0.9981793962900911, "train/extr_return_raw_mag": 1.3185556952039994, "train/extr_return_raw_max": 1.3185556952039994, "train/extr_return_raw_mean": 1.0307600189797321, "train/extr_return_raw_min": 0.17140830363800277, "train/extr_return_raw_std": 0.04210424628479416, "train/extr_reward_mag": 0.3393589169231813, "train/extr_reward_max": 0.3393589169231813, "train/extr_reward_mean": 0.0024688057010687553, "train/extr_reward_min": 6.500168226251555e-06, "train/extr_reward_std": 0.01129837515207925, "train/image_loss_mean": 0.11598109383488175, "train/image_loss_std": 0.10846904991426277, "train/model_loss_mean": 0.7539231955115475, "train/model_loss_std": 0.34085633868898324, "train/model_opt_grad_norm": 21.75403986878656, "train/model_opt_grad_steps": 38595.2736318408, "train/model_opt_loss": 3863.6585152849034, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5149.253731343284, "train/policy_entropy_mag": 1.3715337704663253, "train/policy_entropy_max": 1.3715337704663253, "train/policy_entropy_mean": 0.13373958304598557, "train/policy_entropy_min": 0.06468650316865883, "train/policy_entropy_std": 0.17401390711763012, "train/policy_logprob_mag": 6.55108023638749, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1340500773556197, "train/policy_logprob_min": -6.55108023638749, "train/policy_logprob_std": 0.6706413683013537, "train/policy_randomness_mag": 0.7048289713574879, "train/policy_randomness_max": 0.7048289713574879, "train/policy_randomness_mean": 0.06872855434518549, "train/policy_randomness_min": 0.033242287364468645, "train/policy_randomness_std": 0.0894254635444921, "train/post_ent_mag": 5.55101820011044, "train/post_ent_max": 5.55101820011044, "train/post_ent_mean": 5.268263873769276, "train/post_ent_min": 5.0871106902165195, "train/post_ent_std": 0.10582865959969326, "train/prior_ent_mag": 5.454429112856661, "train/prior_ent_max": 5.454429112856661, "train/prior_ent_mean": 3.0308988165499557, "train/prior_ent_min": 2.8411767577650533, "train/prior_ent_std": 0.26370295415173717, "train/rep_loss_mean": 1.0000074704488118, "train/rep_loss_std": 0.00023893867410830597, "train/reward_avg": 0.001026020518391722, "train/reward_loss_mean": 0.021572153774363483, "train/reward_loss_std": 0.10800665239826661, "train/reward_max_data": 0.4182882530994676, "train/reward_max_pred": 0.1511972537681238, "train/reward_neg_acc": 0.999771390388261, "train/reward_neg_loss": 0.01780709066886955, "train/reward_pos_acc": 0.28471074456518347, "train/reward_pos_loss": 3.9643595189102423, "train/reward_pred": 0.0009204110690156248, "train/reward_rate": 0.0009376943407960199, "train_stats/mean_log_entropy": 0.10098458503939442, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.004682234022766352, "report/cont_loss_std": 0.10762728005647659, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.444549083709717, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0013197057414799929, "report/cont_pred": 0.998659610748291, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09131726622581482, "report/image_loss_std": 0.10071536898612976, "report/model_loss_mean": 0.7227092981338501, "report/model_loss_std": 0.2825395166873932, "report/post_ent_mag": 5.189044952392578, "report/post_ent_max": 5.189044952392578, "report/post_ent_mean": 4.948123455047607, "report/post_ent_min": 4.801736354827881, "report/post_ent_std": 0.08295702189207077, "report/prior_ent_mag": 3.6879029273986816, "report/prior_ent_max": 3.6879029273986816, "report/prior_ent_mean": 2.8795406818389893, "report/prior_ent_min": 2.819737672805786, "report/prior_ent_std": 0.13081692159175873, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0010486317332834005, "report/reward_loss_mean": 0.02670976147055626, "report/reward_loss_std": 0.1469445675611496, "report/reward_max_data": 0.5097916722297668, "report/reward_max_pred": 0.05592381954193115, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.02219599112868309, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.644297122955322, "report/reward_pred": 0.0009241079678758979, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9912109375, "eval/cont_loss_mean": 0.07870204746723175, "eval/cont_loss_std": 0.8492064476013184, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.846633911132812, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0009568371460773051, "eval/cont_pred": 0.9990483522415161, "eval/cont_rate": 0.9912109375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2243345081806183, "eval/image_loss_std": 0.15086521208286285, "eval/model_loss_mean": 0.9066543579101562, "eval/model_loss_std": 0.8625303506851196, "eval/post_ent_mag": 5.176974296569824, "eval/post_ent_max": 5.176974296569824, "eval/post_ent_mean": 4.964019775390625, "eval/post_ent_min": 4.760723114013672, "eval/post_ent_std": 0.09652078151702881, "eval/prior_ent_mag": 3.6879029273986816, "eval/prior_ent_max": 3.6879029273986816, "eval/prior_ent_mean": 2.8983073234558105, "eval/prior_ent_min": 2.8196377754211426, "eval/prior_ent_std": 0.15394023060798645, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0036177868023514748, "eval/reward_loss_std": 0.0031207555439323187, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.010989189147949219, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0036177868023514748, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0006042541936039925, "eval/reward_rate": 0.0, "replay/size": 635121.0, "replay/inserts": 32032.0, "replay/samples": 32032.0, "replay/insert_wait_avg": 1.1801838755726694e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.58061220834067e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4064.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.994924537778839e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.042254447937, "timer/env.step_count": 4004.0, "timer/env.step_total": 34.08939075469971, "timer/env.step_frac": 0.03408795038717479, "timer/env.step_avg": 0.008513833854820107, "timer/env.step_min": 0.0071718692779541016, "timer/env.step_max": 0.0387120246887207, "timer/replay._sample_count": 32032.0, "timer/replay._sample_total": 15.903897047042847, "timer/replay._sample_frac": 0.015903225065047304, "timer/replay._sample_avg": 0.0004965002824376513, "timer/replay._sample_min": 0.00041413307189941406, "timer/replay._sample_max": 0.011129617691040039, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4512.0, "timer/agent.policy_total": 38.10694074630737, "timer/agent.policy_frac": 0.03810533062659829, "timer/agent.policy_avg": 0.008445687222142591, "timer/agent.policy_min": 0.007402896881103516, "timer/agent.policy_max": 0.07903552055358887, "timer/dataset_train_count": 2002.0, "timer/dataset_train_total": 0.20419931411743164, "timer/dataset_train_frac": 0.00020419068615271438, "timer/dataset_train_avg": 0.0001019976593993165, "timer/dataset_train_min": 8.702278137207031e-05, "timer/dataset_train_max": 0.0002529621124267578, "timer/agent.train_count": 2002.0, "timer/agent.train_total": 883.488187789917, "timer/agent.train_frac": 0.8834508580616302, "timer/agent.train_avg": 0.4413027911038546, "timer/agent.train_min": 0.42906618118286133, "timer/agent.train_max": 0.6001987457275391, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4771132469177246, "timer/agent.report_frac": 0.000477093087612693, "timer/agent.report_avg": 0.2385566234588623, "timer/agent.report_min": 0.23757076263427734, "timer/agent.report_max": 0.23954248428344727, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.2411346435546875e-05, "timer/dataset_eval_frac": 2.2410399496488102e-08, "timer/dataset_eval_avg": 2.2411346435546875e-05, "timer/dataset_eval_min": 2.2411346435546875e-05, "timer/dataset_eval_max": 2.2411346435546875e-05, "fps": 32.03008683358093}
{"step": 636024, "time": 20250.004377126694, "episode/length": 74.0, "episode/score": 0.8488042529437507, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.08005424145937923}
{"step": 636032, "time": 20250.488680124283, "episode/length": 247.0, "episode/score": 0.29123864814243916, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.06311364369537387}
{"step": 636048, "time": 20251.000957012177, "episode/length": 288.0, "episode/score": 0.040243317961881075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040243317961881075}
{"step": 636088, "time": 20252.036628484726, "episode/length": 107.0, "episode/score": 0.7029364814828796, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.037311506139644735}
{"step": 636240, "time": 20257.129791021347, "episode/length": 288.0, "episode/score": 0.07866982669997924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07866982669997924}
{"step": 636624, "time": 20269.15075302124, "episode/length": 71.0, "episode/score": 0.8413050277064258, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.063180040442262}
{"step": 636784, "time": 20274.173796653748, "episode/length": 283.0, "episode/score": 0.17309568810503606, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.05747068513062459}
{"step": 637096, "time": 20283.68593621254, "episode/length": 106.0, "episode/score": 0.7247381940459263, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.05598819880731298}
{"step": 637576, "time": 20298.74159669876, "episode/length": 288.0, "episode/score": 0.06910653794807331, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06910653794807331}
{"step": 637872, "time": 20308.07652616501, "episode/length": 288.0, "episode/score": 0.07343801503270697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07343801503270697}
{"step": 637944, "time": 20310.068435668945, "episode/length": 239.0, "episode/score": 0.357640495517785, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.1045154970428257}
{"step": 638344, "time": 20322.481477975845, "episode/length": 288.0, "episode/score": 0.033794589290778276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033794589290778276}
{"step": 638400, "time": 20324.4588098526, "episode/length": 288.0, "episode/score": 0.04692515754766191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04692515754766191}
{"step": 638624, "time": 20331.397642612457, "episode/length": 34.0, "episode/score": 0.9127499541152702, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.018999962334191878}
{"step": 638752, "time": 20335.348803043365, "episode/length": 43.0, "episode/score": 0.8919803090283267, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.02635525579160003}
{"step": 638936, "time": 20340.783381700516, "episode/length": 288.0, "episode/score": 0.03852636320118563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03852636320118563}
{"step": 639096, "time": 20346.284638643265, "episode/length": 288.0, "episode/score": 0.05124452602888141, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05124452602888141}
{"step": 639408, "time": 20356.126005649567, "episode/length": 288.0, "episode/score": 0.045670573920347124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045670573920347124}
{"step": 639888, "time": 20370.969840049744, "episode/length": 288.0, "episode/score": 0.03773802925172731, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03773802925172731}
{"step": 640016, "time": 20375.411623716354, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 640016, "time": 20375.822828531265, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 640016, "time": 20375.874502658844, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 640016, "time": 20375.879856586456, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 640016, "time": 20376.075541734695, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 640016, "time": 20376.080937623978, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 640016, "time": 20376.180629730225, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 640016, "time": 20376.327623605728, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 640112, "time": 20379.30420231819, "episode/length": 169.0, "episode/score": 0.5383503456123435, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.06647534015246492}
{"step": 640184, "time": 20381.338751792908, "episode/length": 288.0, "episode/score": 0.04837413981942973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04837413981942973}
{"step": 640256, "time": 20383.787751674652, "episode/length": 288.0, "episode/score": 0.0876766960709574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0876766960709574}
{"step": 640408, "time": 20388.26452612877, "episode/length": 163.0, "episode/score": 0.540417307622306, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.04979232004382084}
{"step": 640848, "time": 20402.029529571533, "episode/length": 82.0, "episode/score": 0.8059049809694443, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.06215500524785966}
{"step": 640936, "time": 20404.534873008728, "episode/length": 288.0, "episode/score": 0.10737421521832857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10737421521832857}
{"step": 640952, "time": 20405.128534555435, "episode/length": 67.0, "episode/score": 0.8353571247812397, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.044732132266744884}
{"step": 641112, "time": 20410.099710702896, "episode/length": 106.0, "episode/score": 0.7446409868235833, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.07589096934964346}
{"step": 641248, "time": 20414.51558470726, "episode/length": 288.0, "episode/score": 0.06788603723214237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06788603723214237}
{"step": 641440, "time": 20420.457761764526, "episode/length": 73.0, "episode/score": 0.8266028876984137, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.054727855678379456}
{"step": 641720, "time": 20428.8740234375, "episode/length": 288.0, "episode/score": 0.13451776929161952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13451776929161952}
{"step": 641728, "time": 20429.34201979637, "episode/length": 59.0, "episode/score": 0.8632543742868393, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.047629348046825726}
{"step": 641984, "time": 20437.334493875504, "episode/length": 67.0, "episode/score": 0.8525080201457058, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.061883068143743}
{"step": 642200, "time": 20443.79056620598, "episode/length": 288.0, "episode/score": 0.09911271064174798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09911271064174798}
{"step": 642224, "time": 20444.749528884888, "episode/length": 61.0, "episode/score": 0.8359130162712063, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.026538056510162278}
{"step": 642424, "time": 20450.74658060074, "episode/length": 288.0, "episode/score": 0.10165797066781579, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10165797066781579}
{"step": 642712, "time": 20459.596740722656, "episode/length": 90.0, "episode/score": 0.8093981311660627, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.09064813349436918}
{"step": 642816, "time": 20463.01700758934, "episode/length": 76.0, "episode/score": 0.8255919147843542, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.06309189806711402}
{"step": 642848, "time": 20464.024433374405, "episode/length": 77.0, "episode/score": 0.815500133059686, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.05612512826337479}
{"step": 643144, "time": 20472.993830680847, "episode/length": 177.0, "episode/score": 0.5586153433845311, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.11174033823897389}
{"step": 643248, "time": 20476.443022966385, "episode/length": 288.0, "episode/score": 0.07772757478028325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07772757478028325}
{"step": 643264, "time": 20476.942960500717, "episode/length": 288.0, "episode/score": 0.08437681896964477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08437681896964477}
{"step": 643424, "time": 20481.87272667885, "episode/length": 288.0, "episode/score": 0.11530062148790421, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11530062148790421}
{"step": 643560, "time": 20485.842914819717, "episode/length": 88.0, "episode/score": 0.8032817762696141, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0782817532426634}
{"step": 643704, "time": 20490.284332036972, "episode/length": 56.0, "episode/score": 0.8692761365882689, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.04427615083750425}
{"step": 643792, "time": 20493.228427886963, "episode/length": 45.0, "episode/score": 0.8913188389083189, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.03194384053813337}
{"step": 643912, "time": 20496.76734495163, "episode/length": 95.0, "episode/score": 0.7877844769727744, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.08465947930108086}
{"step": 643944, "time": 20497.75676035881, "episode/length": 84.0, "episode/score": 0.7988852049543311, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.061385164395233005}
{"step": 644512, "time": 20515.627722740173, "episode/length": 74.0, "episode/score": 0.8347642132489455, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.06601420365632293}
{"step": 644584, "time": 20517.66485619545, "episode/length": 109.0, "episode/score": 0.7371585223827424, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.07778349614272884}
{"step": 644736, "time": 20522.666221141815, "episode/length": 288.0, "episode/score": 0.1073262661593617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1073262661593617}
{"step": 645024, "time": 20531.743152856827, "episode/length": 288.0, "episode/score": 0.0998558589590175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0998558589590175}
{"step": 645128, "time": 20534.753021001816, "episode/length": 288.0, "episode/score": 0.0956137709245013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0956137709245013}
{"step": 645312, "time": 20540.682311058044, "episode/length": 99.0, "episode/score": 0.7530992117967799, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.06247420069075815}
{"step": 645872, "time": 20558.194878339767, "episode/length": 288.0, "episode/score": 0.1139181274393195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1139181274393195}
{"step": 646104, "time": 20565.191879987717, "episode/length": 288.0, "episode/score": 0.08335795859079553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08335795859079553}
{"step": 646256, "time": 20570.14273762703, "episode/length": 288.0, "episode/score": 0.11906611715812687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11906611715812687}
{"step": 646496, "time": 20577.547754764557, "episode/length": 77.0, "episode/score": 0.8025599666777907, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.04318500344174936}
{"step": 646872, "time": 20589.06157374382, "episode/length": 95.0, "episode/score": 0.7605307985290892, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.057405769890920055}
{"step": 646896, "time": 20590.03023791313, "episode/length": 288.0, "episode/score": 0.1115133313064689, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1115133313064689}
{"step": 646904, "time": 20590.063174962997, "episode/length": 80.0, "episode/score": 0.7984604181626764, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.048460418977583686}
{"step": 647048, "time": 20594.54633164406, "episode/length": 288.0, "episode/score": 0.10477665985308704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10477665985308704}
{"step": 647336, "time": 20603.933336257935, "episode/length": 288.0, "episode/score": 0.07449153195420877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07449153195420877}
{"step": 647440, "time": 20607.36039185524, "episode/length": 288.0, "episode/score": 0.07651496852611217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07651496852611217}
{"step": 647520, "time": 20609.865738391876, "episode/length": 80.0, "episode/score": 0.824958091201097, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0749581041231977}
{"step": 647552, "time": 20610.864964723587, "episode/length": 81.0, "episode/score": 0.802281392068835, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.055406387633411214}
{"step": 647568, "time": 20611.367219686508, "episode/length": 281.0, "episode/score": 0.231636729435877, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.10976172546611451}
{"step": 647856, "time": 20620.379592180252, "episode/length": 100.0, "episode/score": 0.7636110199858877, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.07611100066094423}
{"step": 647872, "time": 20620.8759868145, "episode/length": 53.0, "episode/score": 0.871104185808008, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.03672913862487803}
{"step": 648072, "time": 20626.816012859344, "episode/length": 91.0, "episode/score": 0.7723331160048019, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.05670809853086212}
{"step": 648328, "time": 20634.69614815712, "episode/length": 96.0, "episode/score": 0.766185276981787, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.06618526957777249}
{"step": 648424, "time": 20637.651319503784, "episode/length": 68.0, "episode/score": 0.855479644576917, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.06797960437870643}
{"step": 648560, "time": 20642.051656246185, "episode/length": 16.0, "episode/score": 0.9717683376231889, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.02176834998067534}
{"step": 648808, "time": 20649.56836414337, "episode/length": 288.0, "episode/score": 0.09349732663872601, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09349732663872601}
{"step": 648904, "time": 20652.519340753555, "episode/length": 130.0, "episode/score": 0.6961354410611875, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.10238542674210294}
{"step": 649216, "time": 20662.33869290352, "episode/length": 288.0, "episode/score": 0.029623685306319203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029623685306319203}
{"step": 649456, "time": 20669.731785058975, "episode/length": 111.0, "episode/score": 0.7079249353182604, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.05479992791424593}
{"step": 649752, "time": 20678.71568632126, "episode/length": 117.0, "episode/score": 0.7045504320440159, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.07017543254460179}
{"step": 649832, "time": 20681.186622858047, "episode/length": 288.0, "episode/score": 0.0718557539610174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0718557539610174}
{"step": 649880, "time": 20682.68876361847, "episode/length": 288.0, "episode/score": 0.03253326553021907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03253326553021907}
{"step": 650000, "time": 20687.66106247902, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 650000, "time": 20687.74444961548, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 650000, "time": 20687.828130960464, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 650000, "time": 20688.164513111115, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 650000, "time": 20688.27809023857, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 650000, "time": 20688.314406871796, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 650000, "time": 20688.335228204727, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 650000, "time": 20688.466457128525, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 650384, "time": 20700.30295562744, "episode/length": 288.0, "episode/score": 0.08940570091408517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08940570091408517}
{"step": 650640, "time": 20708.27339529991, "episode/length": 288.0, "episode/score": 0.1365269847763102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1365269847763102}
{"step": 650880, "time": 20715.69087767601, "episode/length": 246.0, "episode/score": 0.3399362112148765, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.10868620939879747}
{"step": 650944, "time": 20717.679282426834, "episode/length": 215.0, "episode/score": 0.3955211357150574, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.06739612232729542}
{"step": 650952, "time": 20717.71247291565, "episode/length": 133.0, "episode/score": 0.6484061291448597, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.06403109191523981}
{"step": 650952, "time": 20717.718199253082, "episode/length": 149.0, "episode/score": 0.6050184642515433, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.07064344415243795}
{"step": 650992, "time": 20719.196364879608, "episode/length": 144.0, "episode/score": 0.6225341232375285, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.07253413547277887}
{"step": 651248, "time": 20727.061587810516, "episode/length": 75.0, "episode/score": 0.8091633076581957, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.04353833181437494}
{"step": 651408, "time": 20731.97857427597, "episode/length": 57.0, "episode/score": 0.8646717819817695, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.042796829979806716}
{"step": 651416, "time": 20732.013573884964, "episode/length": 244.0, "episode/score": 0.35785802451903237, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.12035802033972232}
{"step": 651720, "time": 20741.455164432526, "episode/length": 90.0, "episode/score": 0.7530657420833222, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.03431573492377993}
{"step": 651920, "time": 20747.801367998123, "episode/length": 63.0, "episode/score": 0.8495861203916775, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.04646109992586389}
{"step": 652224, "time": 20757.14090013504, "episode/length": 100.0, "episode/score": 0.7491557333106584, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.06165570996938641}
{"step": 652288, "time": 20759.1316010952, "episode/length": 166.0, "episode/score": 0.5691773248016716, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.08792732505196454}
{"step": 652296, "time": 20759.16576051712, "episode/length": 167.0, "episode/score": 0.554797242642735, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.07667224116426041}
{"step": 652304, "time": 20759.634793758392, "episode/length": 47.0, "episode/score": 0.878933173152177, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.025808197430592372}
{"step": 652576, "time": 20768.138278722763, "episode/length": 106.0, "episode/score": 0.7390453128280114, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.07029531136117839}
{"step": 652696, "time": 20771.63579249382, "episode/length": 288.0, "episode/score": 0.06744617466995351, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06744617466995351}
{"step": 652800, "time": 20775.06645298004, "episode/length": 71.0, "episode/score": 0.8392961494316751, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.06117114796484202}
{"step": 652888, "time": 20777.547641038895, "episode/length": 74.0, "episode/score": 0.8378679031201273, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.06911791535537759}
{"step": 653192, "time": 20786.92231273651, "episode/length": 288.0, "episode/score": 0.09645492902239994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09645492902239994}
{"step": 653352, "time": 20791.878587961197, "episode/length": 81.0, "episode/score": 0.7956111296297195, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.04873614492669276}
{"step": 653536, "time": 20797.882643699646, "episode/length": 91.0, "episode/score": 0.7784280449642438, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.06280304870699638}
{"step": 653560, "time": 20798.436206817627, "episode/length": 288.0, "episode/score": 0.02392179849596232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02392179849596232}
{"step": 654376, "time": 20823.672372579575, "episode/length": 147.0, "episode/score": 0.6433568400474883, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.10273185571116983}
{"step": 654536, "time": 20828.712752103806, "episode/length": 205.0, "episode/score": 0.4536846778959216, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.09430967224977849}
{"step": 654608, "time": 20831.15012383461, "episode/length": 288.0, "episode/score": 0.1324047196441711, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1324047196441711}
{"step": 654616, "time": 20831.185127019882, "episode/length": 288.0, "episode/score": 0.09794061673403576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09794061673403576}
{"step": 654888, "time": 20839.574125766754, "episode/length": 288.0, "episode/score": 0.09337046660999704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09337046660999704}
{"step": 655616, "time": 20862.80437850952, "episode/length": 125.0, "episode/score": 0.696666682882551, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.08729171120057799}
{"step": 655664, "time": 20864.300148248672, "episode/length": 288.0, "episode/score": 0.10083827629853204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10083827629853204}
{"step": 655848, "time": 20869.768179178238, "episode/length": 288.0, "episode/score": 0.08193975045475099, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08193975045475099}
{"step": 655872, "time": 20870.73792028427, "episode/length": 288.0, "episode/score": 0.10943369030763961, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10943369030763961}
{"step": 656688, "time": 20896.16171836853, "episode/length": 288.0, "episode/score": 0.07930403131416597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07930403131416597}
{"step": 656848, "time": 20901.139307022095, "episode/length": 288.0, "episode/score": 0.08212548439286138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08212548439286138}
{"step": 656928, "time": 20903.635952711105, "episode/length": 288.0, "episode/score": 0.06889509997898813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06889509997898813}
{"step": 657200, "time": 20912.040608644485, "episode/length": 288.0, "episode/score": 0.10019821508478799, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10019821508478799}
{"step": 657536, "time": 20922.526982069016, "episode/length": 85.0, "episode/score": 0.7881889204793424, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.05381389515900992}
{"step": 657584, "time": 20924.024489164352, "episode/length": 239.0, "episode/score": 0.3675820028590806, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.11445698127567994}
{"step": 657928, "time": 20934.408936738968, "episode/length": 288.0, "episode/score": 0.06046300880893796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06046300880893796}
{"step": 658112, "time": 20940.299345731735, "episode/length": 71.0, "episode/score": 0.8292318327460748, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.051106864806854446}
{"step": 658160, "time": 20941.78286743164, "episode/length": 288.0, "episode/score": 0.09664451689735643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09664451689735643}
{"step": 658184, "time": 20942.306342601776, "episode/length": 288.0, "episode/score": 0.06598788321872462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06598788321872462}
{"step": 658328, "time": 20946.822226047516, "episode/length": 17.0, "episode/score": 0.9596621505347684, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.012787149056293856}
{"step": 658344, "time": 20947.321289539337, "episode/length": 94.0, "episode/score": 0.7524463130130812, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.04619630446819656}
{"step": 659000, "time": 20967.567363023758, "episode/length": 288.0, "episode/score": 0.08499935063935027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08499935063935027}
{"step": 659024, "time": 20968.52900671959, "episode/length": 113.0, "episode/score": 0.7089887874330429, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.06211376380946376}
{"step": 659024, "time": 20968.53462934494, "episode/length": 86.0, "episode/score": 0.7732729279803721, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.042022964057480294}
{"step": 659240, "time": 20975.153187274933, "episode/length": 288.0, "episode/score": 0.03503898057033439, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03503898057033439}
{"step": 659368, "time": 20979.24196243286, "episode/length": 15.0, "episode/score": 0.9776885448002304, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.02456354712853681}
{"step": 659512, "time": 20983.717098474503, "episode/length": 288.0, "episode/score": 0.04689753269292396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04689753269292396}
{"step": 659680, "time": 20989.124854564667, "episode/length": 81.0, "episode/score": 0.8038722818867541, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.05699729543749754}
{"step": 659776, "time": 20992.07926106453, "episode/length": 50.0, "episode/score": 0.870024266972905, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.026274279895005748}
{"step": 659824, "time": 20993.586932182312, "episode/length": 99.0, "episode/score": 0.7807801231685971, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.09015511287748268}
{"step": 660048, "time": 21000.48215699196, "episode/length": 33.0, "episode/score": 0.924145919608236, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.027270896581285342}
{"step": 660080, "time": 21001.468592643738, "episode/length": 239.0, "episode/score": 0.3295278110600748, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.07640280030329905}
{"step": 660088, "time": 21002.269545555115, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 660088, "time": 21002.480886936188, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 660088, "time": 21002.581049203873, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 660088, "time": 21002.92489218712, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 660088, "time": 21002.976795196533, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 660088, "time": 21003.40935230255, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 660088, "time": 21003.462223291397, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 660088, "time": 21003.99614262581, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 660240, "time": 21009.01571416855, "episode/length": 288.0, "episode/score": 0.033461445114994604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033461445114994604}
{"step": 660424, "time": 21014.463693618774, "episode/length": 113.0, "episode/score": 0.7245609661667913, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.07768594395474793}
{"step": 660488, "time": 21016.45468235016, "episode/length": 54.0, "episode/score": 0.8728864500344571, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.04163640947535896}
{"step": 660656, "time": 21021.858119487762, "episode/length": 288.0, "episode/score": 0.10561188162546387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10561188162546387}
{"step": 660760, "time": 21024.87404036522, "episode/length": 41.0, "episode/score": 0.9133678031948875, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.041492786477647314}
{"step": 660952, "time": 21030.79834651947, "episode/length": 57.0, "episode/score": 0.860290599230666, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0384156087534393}
{"step": 661312, "time": 21042.462000846863, "episode/length": 288.0, "episode/score": 0.09171584701988422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09171584701988422}
{"step": 661392, "time": 21044.980331659317, "episode/length": 91.0, "episode/score": 0.7769036317154132, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.06127865655844289}
{"step": 661400, "time": 21045.015137672424, "episode/length": 164.0, "episode/score": 0.5824944731421056, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.09499446203608386}
{"step": 661688, "time": 21054.010633707047, "episode/length": 115.0, "episode/score": 0.7109818325275228, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0703568454496235}
{"step": 661992, "time": 21063.36601114273, "episode/length": 288.0, "episode/score": 0.10688321171846837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10688321171846837}
{"step": 662136, "time": 21067.917165756226, "episode/length": 288.0, "episode/score": 0.10177268907227699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10177268907227699}
{"step": 662552, "time": 21080.713538646698, "episode/length": 288.0, "episode/score": 0.0734535088931807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0734535088931807}
{"step": 663264, "time": 21102.894639253616, "episode/length": 288.0, "episode/score": 0.09158914070303581, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09158914070303581}
{"step": 663624, "time": 21114.2322473526, "episode/length": 288.0, "episode/score": 0.08433346089282168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08433346089282168}
{"step": 663704, "time": 21116.708480358124, "episode/length": 288.0, "episode/score": 0.0960132583925315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0960132583925315}
{"step": 663712, "time": 21117.180565834045, "episode/length": 288.0, "episode/score": 0.04912958476916174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04912958476916174}
{"step": 664000, "time": 21127.886830806732, "episode/length": 288.0, "episode/score": 0.07670798643198395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07670798643198395}
{"step": 664304, "time": 21137.24379324913, "episode/length": 288.0, "episode/score": 0.02535002711033485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02535002711033485}
{"step": 664448, "time": 21141.670914411545, "episode/length": 288.0, "episode/score": 0.03865935079204519, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03865935079204519}
{"step": 664864, "time": 21154.42369699478, "episode/length": 288.0, "episode/score": 0.051337331236595674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051337331236595674}
{"step": 665576, "time": 21176.17551970482, "episode/length": 288.0, "episode/score": 0.057178328494273956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057178328494273956}
{"step": 665936, "time": 21187.539661169052, "episode/length": 288.0, "episode/score": 0.029090193011597876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029090193011597876}
{"step": 666016, "time": 21189.987526655197, "episode/length": 288.0, "episode/score": 0.05049940742878789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05049940742878789}
{"step": 666024, "time": 21190.021418094635, "episode/length": 288.0, "episode/score": 0.006511195653956747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.006511195653956747}
{"step": 666312, "time": 21198.880450963974, "episode/length": 288.0, "episode/score": 0.02204236869590659, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02204236869590659}
{"step": 666448, "time": 21203.280600309372, "episode/length": 52.0, "episode/score": 0.877345526006934, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.039845550663699214}
{"step": 666616, "time": 21208.217842817307, "episode/length": 288.0, "episode/score": 0.02630958538179584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02630958538179584}
{"step": 666760, "time": 21212.636306524277, "episode/length": 288.0, "episode/score": 0.026125018449079107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026125018449079107}
{"step": 667176, "time": 21225.600085496902, "episode/length": 288.0, "episode/score": 0.05119568408190389, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05119568408190389}
{"step": 667545, "time": 21237.95405292511, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.035741451397613, "train/action_min": 0.0, "train/action_std": 1.4126622467184786, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012083968431946247, "train/actor_opt_grad_steps": 40630.0, "train/actor_opt_loss": -8.019212911701082, "train/adv_mag": 0.9294512763095262, "train/adv_max": 0.278968431841788, "train/adv_mean": 0.0013897403779224787, "train/adv_min": -0.9108141271313231, "train/adv_std": 0.036776429360460994, "train/cont_avg": 0.9956668106155779, "train/cont_loss_mean": 0.01625499244306667, "train/cont_loss_std": 0.24009780862822605, "train/cont_neg_acc": 0.327767711908079, "train/cont_neg_loss": 3.0071537974125087, "train/cont_pos_acc": 0.9997683862345902, "train/cont_pos_loss": 0.003080298415099706, "train/cont_pred": 0.9957831079636387, "train/cont_rate": 0.9956668106155779, "train/dyn_loss_mean": 1.0000086615433046, "train/dyn_loss_std": 0.00027703278552946735, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.23924481910864012, "train/extr_critic_critic_opt_grad_steps": 40630.0, "train/extr_critic_critic_opt_loss": 10991.875402402638, "train/extr_critic_mag": 1.1815460806515947, "train/extr_critic_max": 1.1815460806515947, "train/extr_critic_mean": 1.1172633003349879, "train/extr_critic_min": 1.0386730240817046, "train/extr_critic_std": 0.015645494600336755, "train/extr_return_normed_mag": 0.9242899873148855, "train/extr_return_normed_max": 0.31839104573331284, "train/extr_return_normed_mean": 0.03200883673850316, "train/extr_return_normed_min": -0.8904131285509272, "train/extr_return_normed_std": 0.040992608312611006, "train/extr_return_rate": 0.9986151918094961, "train/extr_return_raw_mag": 1.405035155502396, "train/extr_return_raw_max": 1.405035155502396, "train/extr_return_raw_mean": 1.1186529937101968, "train/extr_return_raw_min": 0.1962309812181559, "train/extr_return_raw_std": 0.04099260820497071, "train/extr_reward_mag": 0.31473362925064624, "train/extr_reward_max": 0.31473362925064624, "train/extr_reward_mean": 0.002381529877677176, "train/extr_reward_min": 6.3109038463189975e-06, "train/extr_reward_std": 0.011100642559769091, "train/image_loss_mean": 0.11339102786539787, "train/image_loss_std": 0.10943170689308464, "train/model_loss_mean": 0.7520075653066587, "train/model_loss_std": 0.3505969567215023, "train/model_opt_grad_norm": 21.231235173479398, "train/model_opt_grad_steps": 40593.38190954774, "train/model_opt_loss": 4058.3368453596104, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5402.010050251256, "train/policy_entropy_mag": 1.3588286692173637, "train/policy_entropy_max": 1.3588286692173637, "train/policy_entropy_mean": 0.12469487008287679, "train/policy_entropy_min": 0.06468649961091766, "train/policy_entropy_std": 0.16305331766006337, "train/policy_logprob_mag": 6.551080274821526, "train/policy_logprob_max": -0.008608139714403967, "train/policy_logprob_mean": -0.12430930553219426, "train/policy_logprob_min": -6.551080274821526, "train/policy_logprob_std": 0.6581637454991365, "train/policy_randomness_mag": 0.6982998434622684, "train/policy_randomness_max": 0.6982998434622684, "train/policy_randomness_mean": 0.06408049078218302, "train/policy_randomness_min": 0.03324228566345857, "train/policy_randomness_std": 0.0837928347252122, "train/post_ent_mag": 4.301802403962792, "train/post_ent_max": 4.301802403962792, "train/post_ent_mean": 4.129249394239492, "train/post_ent_min": 4.028992166471242, "train/post_ent_std": 0.061080625627058835, "train/prior_ent_mag": 4.405452691130901, "train/prior_ent_max": 4.405452691130901, "train/prior_ent_mean": 2.881022818723516, "train/prior_ent_min": 2.8153435417156123, "train/prior_ent_std": 0.1704358180713414, "train/rep_loss_mean": 1.0000086615433046, "train/rep_loss_std": 0.00027703278552946735, "train/reward_avg": 0.0011391301335762231, "train/reward_loss_mean": 0.022356324651320675, "train/reward_loss_std": 0.12122289134404766, "train/reward_max_data": 0.4810400070557043, "train/reward_max_pred": 0.15714564754735286, "train/reward_neg_acc": 0.9998378442160448, "train/reward_neg_loss": 0.017854764168361324, "train/reward_pos_acc": 0.28296296342655464, "train/reward_pos_loss": 4.011987941794925, "train/reward_pred": 0.0009955829196614237, "train/reward_rate": 0.0011237829773869347, "train_stats/mean_log_entropy": 0.10461255510648092, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.013362584635615349, "report/cont_loss_std": 0.21188630163669586, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.688464641571045, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0025640486273914576, "report/cont_pred": 0.9973977208137512, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1145668551325798, "report/image_loss_std": 0.10368013381958008, "report/model_loss_mean": 0.75462806224823, "report/model_loss_std": 0.38137948513031006, "report/post_ent_mag": 3.897369623184204, "report/post_ent_max": 3.897369623184204, "report/post_ent_mean": 3.752145767211914, "report/post_ent_min": 3.6691160202026367, "report/post_ent_std": 0.0505903922021389, "report/prior_ent_mag": 4.513011932373047, "report/prior_ent_max": 4.513011932373047, "report/prior_ent_mean": 2.8736610412597656, "report/prior_ent_min": 2.812525510787964, "report/prior_ent_std": 0.23393261432647705, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002055670600384474, "report/reward_loss_mean": 0.026698581874370575, "report/reward_loss_std": 0.18031004071235657, "report/reward_max_data": 0.8789583444595337, "report/reward_max_pred": 0.03192460536956787, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01884130761027336, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.041765213012695, "report/reward_pred": 0.0008784527890384197, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.03917953372001648, "eval/cont_loss_std": 0.5719806551933289, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.685697078704834, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0016598185757175088, "eval/cont_pred": 0.9983906149864197, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20990556478500366, "eval/image_loss_std": 0.13761073350906372, "eval/model_loss_mean": 0.8524329662322998, "eval/model_loss_std": 0.5829470157623291, "eval/post_ent_mag": 3.889871120452881, "eval/post_ent_max": 3.889871120452881, "eval/post_ent_mean": 3.7433791160583496, "eval/post_ent_min": 3.6740903854370117, "eval/post_ent_std": 0.0513298474252224, "eval/prior_ent_mag": 4.513011932373047, "eval/prior_ent_max": 4.513011932373047, "eval/prior_ent_mean": 2.8713653087615967, "eval/prior_ent_min": 2.812302589416504, "eval/prior_ent_std": 0.24306733906269073, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.003347837831825018, "eval/reward_loss_std": 0.003340385854244232, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.014616847038269043, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.003347837831825018, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0006446731276810169, "eval/reward_rate": 0.0, "replay/size": 667041.0, "replay/inserts": 31920.0, "replay/samples": 31920.0, "replay/insert_wait_avg": 1.1855124829705796e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.559781086474732e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2808.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.911182599189954e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1387753486633, "timer/env.step_count": 3990.0, "timer/env.step_total": 34.028284549713135, "timer/env.step_frac": 0.03402356291790643, "timer/env.step_avg": 0.00852839211772259, "timer/env.step_min": 0.007197380065917969, "timer/env.step_max": 0.03722095489501953, "timer/replay._sample_count": 31920.0, "timer/replay._sample_total": 15.954959154129028, "timer/replay._sample_frac": 0.015952745306337005, "timer/replay._sample_avg": 0.0004998420787634408, "timer/replay._sample_min": 0.00035309791564941406, "timer/replay._sample_max": 0.03369307518005371, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4341.0, "timer/agent.policy_total": 36.294718742370605, "timer/agent.policy_frac": 0.03628968262901088, "timer/agent.policy_avg": 0.008360911942494956, "timer/agent.policy_min": 0.00641632080078125, "timer/agent.policy_max": 0.06798768043518066, "timer/dataset_train_count": 1995.0, "timer/dataset_train_total": 0.20622515678405762, "timer/dataset_train_frac": 0.00020619654178707795, "timer/dataset_train_avg": 0.0001033710059067958, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.00031113624572753906, "timer/agent.train_count": 1995.0, "timer/agent.train_total": 886.4594032764435, "timer/agent.train_frac": 0.8863364016332739, "timer/agent.train_avg": 0.4443405530207737, "timer/agent.train_min": 0.43259334564208984, "timer/agent.train_max": 2.1884007453918457, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47820067405700684, "timer/agent.report_frac": 0.00047813432079992993, "timer/agent.report_avg": 0.23910033702850342, "timer/agent.report_min": 0.23484444618225098, "timer/agent.report_max": 0.24335622787475586, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.4318695068359375e-05, "timer/dataset_eval_frac": 2.4315320701251198e-08, "timer/dataset_eval_avg": 2.4318695068359375e-05, "timer/dataset_eval_min": 2.4318695068359375e-05, "timer/dataset_eval_max": 2.4318695068359375e-05, "fps": 31.915005975551157}
{"step": 667712, "time": 21243.16423034668, "episode/length": 221.0, "episode/score": 0.34108562066580816, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.03171064603270679}
{"step": 667888, "time": 21248.774343967438, "episode/length": 288.0, "episode/score": 0.04601215440720807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04601215440720807}
{"step": 667968, "time": 21251.28976535797, "episode/length": 168.0, "episode/score": 0.5300524068636605, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.05505241363903224}
{"step": 668328, "time": 21262.38064312935, "episode/length": 288.0, "episode/score": 0.05849689723561369, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05849689723561369}
{"step": 668624, "time": 21271.898599147797, "episode/length": 288.0, "episode/score": 0.1348633608646992, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.034863361004397575}
{"step": 668760, "time": 21276.056014060974, "episode/length": 288.0, "episode/score": 0.04563282675297842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04563282675297842}
{"step": 668792, "time": 21277.04155397415, "episode/length": 201.0, "episode/score": 0.4018292799860319, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.029954304829061584}
{"step": 668840, "time": 21278.518715381622, "episode/length": 259.0, "episode/score": 0.26167880708743496, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.07105381239597364}
{"step": 668888, "time": 21279.99378991127, "episode/length": 69.0, "episode/score": 0.8515435462913956, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.06716851801411394}
{"step": 668952, "time": 21281.984402179718, "episode/length": 132.0, "episode/score": 0.6451571316471245, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.05765715781728886}
{"step": 669024, "time": 21284.42348051071, "episode/length": 22.0, "episode/score": 0.9601223370473235, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.028872362518995942}
{"step": 669600, "time": 21302.132557868958, "episode/length": 100.0, "episode/score": 0.7562966095745196, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.06879662249662033}
{"step": 669712, "time": 21305.70733189583, "episode/length": 102.0, "episode/score": 0.7647766909440179, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.08352671711418225}
{"step": 669768, "time": 21307.208726406097, "episode/length": 92.0, "episode/score": 0.7586837148282939, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0461837402999663}
{"step": 669840, "time": 21309.645455360413, "episode/length": 134.0, "episode/score": 0.6505028149913414, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.06925277443224331}
{"step": 670024, "time": 21315.068032979965, "episode/length": 288.0, "episode/score": 0.06281457664965728, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06281457664965728}
{"step": 670072, "time": 21316.883437395096, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 670072, "time": 21317.486245393753, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 670072, "time": 21317.52225637436, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 670072, "time": 21318.205544948578, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 670072, "time": 21319.48387980461, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 670072, "time": 21320.024800300598, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 670072, "time": 21321.032153844833, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 21321.03900361061, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 21321.044820070267, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 21321.050313472748, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670152, "time": 21323.49725008011, "episode/length": 54.0, "episode/score": 0.8950884162431976, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.06383837568409945}
{"step": 670168, "time": 21323.988379716873, "episode/length": 49.0, "episode/score": 0.8789574827203523, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.03208244216125422}
{"step": 670280, "time": 21327.494691371918, "episode/length": 288.0, "episode/score": 0.09721107598045364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09721107598045364}
{"step": 670424, "time": 21331.93199110031, "episode/length": 72.0, "episode/score": 0.81525474468026, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.04025474518084593}
{"step": 670488, "time": 21333.8952190876, "episode/length": 110.0, "episode/score": 0.7291359649411788, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.07288594858482611}
{"step": 670712, "time": 21340.920085906982, "episode/length": 67.0, "episode/score": 0.8620196537583524, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.07139466328112576}
{"step": 670936, "time": 21347.82183790207, "episode/length": 288.0, "episode/score": 0.07967084792562673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07967084792562673}
{"step": 671216, "time": 21356.641039133072, "episode/length": 62.0, "episode/score": 0.8545136974950083, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.048263722151773436}
{"step": 671264, "time": 21358.11121249199, "episode/length": 288.0, "episode/score": 0.08150560734452483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08150560734452483}
{"step": 671344, "time": 21360.583497285843, "episode/length": 106.0, "episode/score": 0.7418051089243818, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.07305509750403871}
{"step": 671528, "time": 21366.10059952736, "episode/length": 155.0, "episode/score": 0.6444034319522416, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.12877840331407242}
{"step": 671616, "time": 21369.022525548935, "episode/length": 43.0, "episode/score": 0.8915801928162637, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.025955154655321167}
{"step": 671872, "time": 21377.405930519104, "episode/length": 65.0, "episode/score": 0.8397505621936716, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.04287554787458703}
{"step": 672304, "time": 21390.741968870163, "episode/length": 85.0, "episode/score": 0.7922736841192091, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.05789866479426564}
{"step": 672336, "time": 21391.729159355164, "episode/length": 288.0, "episode/score": 0.08705949766931553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08705949766931553}
{"step": 672464, "time": 21395.77391767502, "episode/length": 288.0, "episode/score": 0.08548146013936275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08548146013936275}
{"step": 672736, "time": 21404.100177049637, "episode/length": 288.0, "episode/score": 0.09121280698491319, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09121280698491319}
{"step": 673136, "time": 21416.343565940857, "episode/length": 274.0, "episode/score": 0.222936753490103, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.07918675449127477}
{"step": 673304, "time": 21421.285790205002, "episode/length": 104.0, "episode/score": 0.7278048460657374, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.05280480474993965}
{"step": 673528, "time": 21428.250396728516, "episode/length": 288.0, "episode/score": 0.08273636315720978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08273636315720978}
{"step": 673688, "time": 21433.167102098465, "episode/length": 68.0, "episode/score": 0.8243156195339907, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.03681557235086075}
{"step": 673840, "time": 21438.03417468071, "episode/length": 288.0, "episode/score": 0.0717512132318916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0717512132318916}
{"step": 674120, "time": 21446.4071662426, "episode/length": 53.0, "episode/score": 0.8540186996847297, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.019643646448002983}
{"step": 674184, "time": 21448.37504386902, "episode/length": 288.0, "episode/score": 0.09524114169369113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09524114169369113}
{"step": 674264, "time": 21450.846369981766, "episode/length": 119.0, "episode/score": 0.704878225720563, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.07675322672173479}
{"step": 674488, "time": 21457.858823299408, "episode/length": 80.0, "episode/score": 0.7925501577043406, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0425501283094718}
{"step": 674616, "time": 21461.794624090195, "episode/length": 288.0, "episode/score": 0.07004184970571714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07004184970571714}
{"step": 674648, "time": 21462.77696299553, "episode/length": 288.0, "episode/score": 0.05103733069188365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05103733069188365}
{"step": 674704, "time": 21464.731815576553, "episode/length": 72.0, "episode/score": 0.8300361782822847, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.05503618873638061}
{"step": 674912, "time": 21471.101135253906, "episode/length": 80.0, "episode/score": 0.7822926187889152, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.032292611629372914}
{"step": 675016, "time": 21474.08708548546, "episode/length": 38.0, "episode/score": 0.9095128522014875, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.02826282917453682}
{"step": 675048, "time": 21475.07018327713, "episode/length": 288.0, "episode/score": 0.05155878294658578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05155878294658578}
{"step": 675232, "time": 21480.938836097717, "episode/length": 212.0, "episode/score": 0.4599938017356635, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.12249378759702267}
{"step": 675344, "time": 21484.404562473297, "episode/length": 90.0, "episode/score": 0.7771981033898783, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.05844809000211626}
{"step": 675960, "time": 21503.370260715485, "episode/length": 76.0, "episode/score": 0.8349506832103089, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.07245069594614506}
{"step": 676128, "time": 21508.784107923508, "episode/length": 134.0, "episode/score": 0.6321875411694009, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.05093754738015832}
{"step": 676424, "time": 21517.71260690689, "episode/length": 221.0, "episode/score": 0.4042363697546989, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.09486138283978107}
{"step": 676496, "time": 21520.153134584427, "episode/length": 288.0, "episode/score": 0.10022730748232789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10022730748232789}
{"step": 676624, "time": 21524.107926368713, "episode/length": 82.0, "episode/score": 0.7894064004940446, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.04565642596571706}
{"step": 676696, "time": 21526.133556604385, "episode/length": 275.0, "episode/score": 0.1746265904481561, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.03400159161230931}
{"step": 676736, "time": 21527.60590815544, "episode/length": 38.0, "episode/score": 0.9020483912099735, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.020798348043172155}
{"step": 676736, "time": 21527.616219997406, "episode/length": 214.0, "episode/score": 0.39126616056159946, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.06001616156277123}
{"step": 676864, "time": 21531.623114347458, "episode/length": 91.0, "episode/score": 0.7843187792188928, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0686937625016526}
{"step": 677144, "time": 21540.172084093094, "episode/length": 50.0, "episode/score": 0.881334447229392, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.03758446015149275}
{"step": 677200, "time": 21542.144261598587, "episode/length": 87.0, "episode/score": 0.7815604098716449, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.05343543452841004}
{"step": 677224, "time": 21542.678791999817, "episode/length": 288.0, "episode/score": 0.03862411384591269, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03862411384591269}
{"step": 677248, "time": 21543.674852609634, "episode/length": 68.0, "episode/score": 0.8373819599441958, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.04988193843064437}
{"step": 677496, "time": 21551.263110160828, "episode/length": 78.0, "episode/score": 0.8199497628311292, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0636997246701867}
{"step": 677544, "time": 21552.761298894882, "episode/length": 288.0, "episode/score": 0.08520715773511256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08520715773511256}
{"step": 677592, "time": 21554.277745485306, "episode/length": 120.0, "episode/score": 0.7161705328123844, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.09117051849329982}
{"step": 677840, "time": 21562.23117852211, "episode/length": 137.0, "episode/score": 0.6591385687045204, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.08726356920510625}
{"step": 677872, "time": 21563.240266799927, "episode/length": 34.0, "episode/score": 0.9253975056285526, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.03164749533743816}
{"step": 677880, "time": 21563.275138616562, "episode/length": 84.0, "episode/score": 0.8073972145875814, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.06989720499495888}
{"step": 677952, "time": 21565.733396053314, "episode/length": 90.0, "episode/score": 0.7827681419980763, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.06401811335990715}
{"step": 678112, "time": 21570.71530866623, "episode/length": 120.0, "episode/score": 0.7222391026857622, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0972391043155767}
{"step": 678216, "time": 21573.747936725616, "episode/length": 120.0, "episode/score": 0.6957112264044554, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.07071122684101283}
{"step": 678392, "time": 21579.336124181747, "episode/length": 105.0, "episode/score": 0.7346659087302214, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.06279092165232214}
{"step": 678664, "time": 21587.765067100525, "episode/length": 88.0, "episode/score": 0.8037437160510308, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.07874369264573033}
{"step": 678792, "time": 21591.671347141266, "episode/length": 161.0, "episode/score": 0.5604580859767339, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.06358308971948645}
{"step": 678848, "time": 21593.624035835266, "episode/length": 91.0, "episode/score": 0.7609564696604139, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.04533149450344354}
{"step": 678936, "time": 21596.09815120697, "episode/length": 67.0, "episode/score": 0.8441522369653285, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.053527247419424384}
{"step": 678984, "time": 21597.56882429123, "episode/length": 23.0, "episode/score": 0.9550594071179148, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.026934407432236185}
{"step": 679224, "time": 21605.043300390244, "episode/length": 69.0, "episode/score": 0.839036241035501, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.05466122195502976}
{"step": 679256, "time": 21606.02838563919, "episode/length": 39.0, "episode/score": 0.9122161454126854, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.03409114641385713}
{"step": 679552, "time": 21615.354984283447, "episode/length": 87.0, "episode/score": 0.8109887119935593, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.08286373816372361}
{"step": 679576, "time": 21615.876653671265, "episode/length": 73.0, "episode/score": 0.8301340791908842, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.05825905767733275}
{"step": 680056, "time": 21632.12714457512, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 680056, "time": 21632.72269010544, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 680056, "time": 21632.77756357193, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 680056, "time": 21633.05966615677, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 680056, "time": 21633.51744031906, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 680056, "time": 21633.63514494896, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 680056, "time": 21634.05937409401, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 680056, "time": 21634.29741501808, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 680120, "time": 21636.45677423477, "episode/length": 107.0, "episode/score": 0.7497705561879684, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.08414559295192703}
{"step": 680152, "time": 21637.449635267258, "episode/length": 288.0, "episode/score": 0.06413875941620972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06413875941620972}
{"step": 680184, "time": 21638.43116760254, "episode/length": 288.0, "episode/score": 0.09027234701193265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09027234701193265}
{"step": 680192, "time": 21638.899031877518, "episode/length": 288.0, "episode/score": 0.09565788801296549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09565788801296549}
{"step": 680528, "time": 21649.277519464493, "episode/length": 288.0, "episode/score": 0.05545267392722053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05545267392722053}
{"step": 680680, "time": 21653.776127815247, "episode/length": 61.0, "episode/score": 0.8735647139064895, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.06418972815572488}
{"step": 681104, "time": 21667.17798614502, "episode/length": 118.0, "episode/score": 0.6611696947270502, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.029919672515006823}
{"step": 681136, "time": 21668.16600894928, "episode/length": 75.0, "episode/score": 0.8078751206430752, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.04225013356517593}
{"step": 681408, "time": 21676.539312124252, "episode/length": 90.0, "episode/score": 0.7735683649234488, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.05481836655326333}
{"step": 681536, "time": 21680.45897102356, "episode/length": 288.0, "episode/score": 0.088042737134856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.088042737134856}
{"step": 681816, "time": 21688.85656428337, "episode/length": 88.0, "episode/score": 0.7784440381133209, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.05344398563329378}
{"step": 681864, "time": 21690.327254533768, "episode/length": 288.0, "episode/score": 0.11355088159552906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11355088159552906}
{"step": 681888, "time": 21691.301100492477, "episode/length": 288.0, "episode/score": 0.09575004857083513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09575004857083513}
{"step": 681952, "time": 21693.2745013237, "episode/length": 51.0, "episode/score": 0.8754390415363105, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.03481405578554586}
{"step": 682328, "time": 21704.663763284683, "episode/length": 46.0, "episode/score": 0.8887549306109577, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.03250495545398735}
{"step": 682432, "time": 21708.07761144638, "episode/length": 288.0, "episode/score": 0.10880101769930661, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10880101769930661}
{"step": 682480, "time": 21709.559109687805, "episode/length": 76.0, "episode/score": 0.807759511390941, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.045259524941684504}
{"step": 682504, "time": 21710.085913181305, "episode/length": 288.0, "episode/score": 0.11290732759880484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11290732759880484}
{"step": 682920, "time": 21722.94397521019, "episode/length": 54.0, "episode/score": 0.8549840164341731, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.023733975875074975}
{"step": 683064, "time": 21727.467414855957, "episode/length": 206.0, "episode/score": 0.45555419928996344, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.09930421202579964}
{"step": 683120, "time": 21729.398111343384, "episode/length": 24.0, "episode/score": 0.9516957286650722, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.026695688105974114}
{"step": 683224, "time": 21732.39271736145, "episode/length": 89.0, "episode/score": 0.7838536853241749, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.06197864476507675}
{"step": 683272, "time": 21733.866832971573, "episode/length": 117.0, "episode/score": 0.6989121795195388, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.06453720417630393}
{"step": 683304, "time": 21734.849014520645, "episode/length": 108.0, "episode/score": 0.7394262032148617, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.07692616505391925}
{"step": 683448, "time": 21739.284856557846, "episode/length": 288.0, "episode/score": 0.1610150272510964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1610150272510964}
{"step": 684128, "time": 21760.438225507736, "episode/length": 288.0, "episode/score": 0.11548736141730842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11548736141730842}
{"step": 684200, "time": 21762.419638872147, "episode/length": 288.0, "episode/score": 0.12802484368694422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12802484368694422}
{"step": 684488, "time": 21771.244369506836, "episode/length": 129.0, "episode/score": 0.6756812931475906, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.07880628204156892}
{"step": 684584, "time": 21774.188220500946, "episode/length": 56.0, "episode/score": 0.8542476535258174, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.029247636808577226}
{"step": 684800, "time": 21781.058167934418, "episode/length": 186.0, "episode/score": 0.5007339723651967, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.08198398591594014}
{"step": 684896, "time": 21783.99943470955, "episode/length": 228.0, "episode/score": 0.3649802288327919, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.07748024771535711}
{"step": 684920, "time": 21784.543523788452, "episode/length": 205.0, "episode/score": 0.4177920229190022, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.058417035841102916}
{"step": 685040, "time": 21788.549685239792, "episode/length": 104.0, "episode/score": 0.7459407596238634, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.07094076062503518}
{"step": 685080, "time": 21789.59034371376, "episode/length": 244.0, "episode/score": 0.3264080652611483, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.08890806905628779}
{"step": 685280, "time": 21795.990382432938, "episode/length": 256.0, "episode/score": 0.31024959963247056, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.1102495951970468}
{"step": 685336, "time": 21797.498297929764, "episode/length": 93.0, "episode/score": 0.7482899425001506, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.03891489933334924}
{"step": 685584, "time": 21805.358275413513, "episode/length": 82.0, "episode/score": 0.8105691792279686, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.06681918374488305}
{"step": 685584, "time": 21805.364147424698, "episode/length": 136.0, "episode/score": 0.6504004506471119, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.07540044621168818}
{"step": 685752, "time": 21810.307317495346, "episode/length": 118.0, "episode/score": 0.6596103675847189, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.02836032942377642}
{"step": 685832, "time": 21812.76093363762, "episode/length": 61.0, "episode/score": 0.848062457546348, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.038687455148192385}
{"step": 685920, "time": 21815.80177640915, "episode/length": 109.0, "episode/score": 0.685536376397522, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.026161335081724246}
{"step": 686080, "time": 21820.752019643784, "episode/length": 124.0, "episode/score": 0.674152925761291, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.06165289748400937}
{"step": 686208, "time": 21824.686846733093, "episode/length": 56.0, "episode/score": 0.8440041800101881, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.019004168589844994}
{"step": 686432, "time": 21831.555444717407, "episode/length": 27.0, "episode/score": 0.9436755840163187, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.028050608294734047}
{"step": 687128, "time": 21852.790872573853, "episode/length": 230.0, "episode/score": 0.37274826862721966, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.09149827910459862}
{"step": 687208, "time": 21855.272749185562, "episode/length": 288.0, "episode/score": 0.08451972347950232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08451972347950232}
{"step": 687224, "time": 21855.769924879074, "episode/length": 98.0, "episode/score": 0.7273434277161641, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.03359340431086366}
{"step": 687312, "time": 21858.71132159233, "episode/length": 215.0, "episode/score": 0.38683968825375814, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.05871467486599613}
{"step": 687568, "time": 21866.578619241714, "episode/length": 54.0, "episode/score": 0.8454761455270727, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.014226157762323055}
{"step": 687808, "time": 21874.055281162262, "episode/length": 29.0, "episode/score": 0.9212906634377305, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.011915638129039507}
{"step": 687896, "time": 21876.739893198013, "episode/length": 288.0, "episode/score": 0.05896903862617364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05896903862617364}
{"step": 687984, "time": 21879.729498147964, "episode/length": 237.0, "episode/score": 0.33868181452999124, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.07930679425044218}
{"step": 688144, "time": 21885.14223217964, "episode/length": 288.0, "episode/score": 0.08629807134116163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08629807134116163}
{"step": 688152, "time": 21885.17381310463, "episode/length": 104.0, "episode/score": 0.7149149142275064, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0399148941284011}
{"step": 688232, "time": 21887.633216381073, "episode/length": 288.0, "episode/score": 0.07747282134425859, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07747282134425859}
{"step": 688344, "time": 21891.084650039673, "episode/length": 66.0, "episode/score": 0.8230770188422412, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.029327007421898088}
{"step": 688568, "time": 21898.013449192047, "episode/length": 83.0, "episode/score": 0.7701918364995208, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.02956680549812063}
{"step": 688584, "time": 21898.517133951187, "episode/length": 29.0, "episode/score": 0.9332393567169674, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.023864315401169733}
{"step": 688880, "time": 21908.10214447975, "episode/length": 90.0, "episode/score": 0.7573436527919739, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.03859364563243162}
{"step": 688904, "time": 21908.63604283333, "episode/length": 83.0, "episode/score": 0.7871425575397097, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.046517562015878866}
{"step": 689000, "time": 21911.647654771805, "episode/length": 106.0, "episode/score": 0.7093740985002341, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.04062411085772055}
{"step": 689432, "time": 21925.16756939888, "episode/length": 68.0, "episode/score": 0.8108764101535826, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.023376389687769006}
{"step": 689456, "time": 21926.14290690422, "episode/length": 108.0, "episode/score": 0.706675957802986, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0441759373371724}
{"step": 689464, "time": 21926.176271915436, "episode/length": 184.0, "episode/score": 0.5000248185048122, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.07502480680216195}
{"step": 689520, "time": 21928.13877224922, "episode/length": 288.0, "episode/score": 0.050745398364711036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050745398364711036}
{"step": 689536, "time": 21928.644632339478, "episode/length": 288.0, "episode/score": 0.09546450508764792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09546450508764792}
{"step": 689792, "time": 21936.728182792664, "episode/length": 98.0, "episode/score": 0.7330255238058498, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.039275513133475215}
{"step": 690040, "time": 21945.09518289566, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 690040, "time": 21945.441890001297, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 690040, "time": 21945.463037014008, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 690040, "time": 21945.77531027794, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 690040, "time": 21946.106903791428, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 690040, "time": 21946.499231815338, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 690040, "time": 21946.673988103867, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 690040, "time": 21946.69485783577, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 690056, "time": 21947.19361805916, "episode/length": 64.0, "episode/score": 0.82088957647602, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.02088953923475856}
{"step": 690152, "time": 21950.143714666367, "episode/length": 44.0, "episode/score": 0.8878569661518441, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.025356924836046346}
{"step": 690176, "time": 21951.102874994278, "episode/length": 92.0, "episode/score": 0.7436758808618151, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.031175896525496682}
{"step": 690536, "time": 21961.959504127502, "episode/length": 133.0, "episode/score": 0.6408591552924463, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.05648413188714585}
{"step": 690576, "time": 21963.418015241623, "episode/length": 139.0, "episode/score": 0.6185641158946282, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.05293911907858728}
{"step": 690592, "time": 21963.91318297386, "episode/length": 133.0, "episode/score": 0.6629151268655278, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0785401032419486}
{"step": 690712, "time": 21967.472137451172, "episode/length": 69.0, "episode/score": 0.821775038007786, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.037400018927314704}
{"step": 690880, "time": 21972.859370470047, "episode/length": 288.0, "episode/score": 0.05213207837914524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05213207837914524}
{"step": 690912, "time": 21973.848670721054, "episode/length": 91.0, "episode/score": 0.7498218969392383, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.034196885518895215}
{"step": 691088, "time": 21979.25681400299, "episode/length": 61.0, "episode/score": 0.8355315647362431, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.026156568478995723}
{"step": 691208, "time": 21982.769814252853, "episode/length": 40.0, "episode/score": 0.8955074748389507, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.020507461451188647}
{"step": 691216, "time": 21983.24992132187, "episode/length": 288.0, "episode/score": 0.06117100769949957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06117100769949957}
{"step": 691520, "time": 21992.682169675827, "episode/length": 117.0, "episode/score": 0.670547444777867, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.03617249172816628}
{"step": 691680, "time": 21997.676567792892, "episode/length": 142.0, "episode/score": 0.6253679666660901, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0691179864188598}
{"step": 692240, "time": 22014.88191652298, "episode/length": 89.0, "episode/score": 0.7772348791579589, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.05535984479797662}
{"step": 692368, "time": 22018.832872629166, "episode/length": 288.0, "episode/score": 0.07465350768626422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07465350768626422}
{"step": 692384, "time": 22019.32878637314, "episode/length": 87.0, "episode/score": 0.7481657042873167, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.020040714741412557}
{"step": 692872, "time": 22034.178425312042, "episode/length": 60.0, "episode/score": 0.8307582362541552, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.018258236414226303}
{"step": 693024, "time": 22039.060559749603, "episode/length": 288.0, "episode/score": 0.04494552774917793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04494552774917793}
{"step": 693024, "time": 22039.066638231277, "episode/length": 97.0, "episode/score": 0.7231325581985288, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.026257602180237427}
{"step": 693224, "time": 22044.986341238022, "episode/length": 288.0, "episode/score": 0.060030316731001676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060030316731001676}
{"step": 693400, "time": 22050.407727956772, "episode/length": 288.0, "episode/score": 0.06675532551298602, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06675532551298602}
{"step": 693520, "time": 22054.292437553406, "episode/length": 288.0, "episode/score": 0.04913556492334692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04913556492334692}
{"step": 693528, "time": 22054.326268196106, "episode/length": 288.0, "episode/score": 0.04846270152938814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04846270152938814}
{"step": 693624, "time": 22057.39286994934, "episode/length": 49.0, "episode/score": 0.8660864658501737, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.019211446769702434}
{"step": 693792, "time": 22062.78680920601, "episode/length": 95.0, "episode/score": 0.726110246032988, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.022985270189167295}
{"step": 694464, "time": 22083.50342941284, "episode/length": 83.0, "episode/score": 0.768961605192942, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.02833660757363532}
{"step": 694576, "time": 22087.03204679489, "episode/length": 131.0, "episode/score": 0.6448986723025882, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.054273687599561526}
{"step": 694680, "time": 22090.016136407852, "episode/length": 288.0, "episode/score": 0.029482151526110556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029482151526110556}
{"step": 694760, "time": 22092.455715179443, "episode/length": 36.0, "episode/score": 0.9158141932476269, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.028314179848223375}
{"step": 695184, "time": 22105.66084241867, "episode/length": 288.0, "episode/score": 0.029916793162783506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029916793162783506}
{"step": 695184, "time": 22105.666168928146, "episode/length": 52.0, "episode/score": 0.8761290410263314, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.038629085008039965}
{"step": 695336, "time": 22110.083549022675, "episode/length": 288.0, "episode/score": 0.059396657628155936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059396657628155936}
{"step": 695600, "time": 22118.42519903183, "episode/length": 51.0, "episode/score": 0.8787959909352026, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.03817101493422115}
{"step": 695712, "time": 22121.855803012848, "episode/length": 288.0, "episode/score": 0.08658094156584184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08658094156584184}
{"step": 695792, "time": 22124.31564474106, "episode/length": 151.0, "episode/score": 0.5629887880872957, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.03486382832625168}
{"step": 695840, "time": 22125.780864477158, "episode/length": 288.0, "episode/score": 0.05686510752616414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05686510752616414}
{"step": 695936, "time": 22128.761649131775, "episode/length": 288.0, "episode/score": 0.04273779391229482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04273779391229482}
{"step": 695960, "time": 22129.300548553467, "episode/length": 30.0, "episode/score": 0.927919299178825, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.02166932749685202}
{"step": 696008, "time": 22130.764949798584, "episode/length": 83.0, "episode/score": 0.754716874593214, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.014091864910369623}
{"step": 696352, "time": 22142.001247882843, "episode/length": 63.0, "episode/score": 0.8185654921853711, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.015440471719557536}
{"step": 696728, "time": 22153.584691286087, "episode/length": 116.0, "episode/score": 0.6785136614399789, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.041013683430833225}
{"step": 696736, "time": 22154.059436559677, "episode/length": 99.0, "episode/score": 0.7275323668312126, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.03690736807976691}
{"step": 696824, "time": 22156.589151859283, "episode/length": 107.0, "episode/score": 0.6985945619436507, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.032969589161552904}
{"step": 696944, "time": 22160.538347244263, "episode/length": 116.0, "episode/score": 0.6716510155872015, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.034151002187797985}
{"step": 696992, "time": 22162.03099346161, "episode/length": 288.0, "episode/score": 0.04092251823396964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04092251823396964}
{"step": 697040, "time": 22163.522794485092, "episode/length": 37.0, "episode/score": 0.9170413311483117, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.03266632966983707}
{"step": 697048, "time": 22163.55542588234, "episode/length": 12.0, "episode/score": 0.96724290762387, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.004742954574169289}
{"step": 697272, "time": 22170.538649320602, "episode/length": 67.0, "episode/score": 0.8118447219229665, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.021219755834749776}
{"step": 697496, "time": 22177.5818836689, "episode/length": 288.0, "episode/score": 0.04295726855752946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04295726855752946}
{"step": 697776, "time": 22186.49459028244, "episode/length": 177.0, "episode/score": 0.4686897312651581, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.02181473847417692}
{"step": 697904, "time": 22190.485030651093, "episode/length": 134.0, "episode/score": 0.6320970347984485, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.05084700768532002}
{"step": 697912, "time": 22190.519648075104, "episode/length": 288.0, "episode/score": 0.05558826668294614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05558826668294614}
{"step": 698328, "time": 22203.286885499954, "episode/length": 160.0, "episode/score": 0.5606921468934161, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.06069216006289935}
{"step": 698336, "time": 22203.755526781082, "episode/length": 69.0, "episode/score": 0.812143230950312, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.027768233188396607}
{"step": 698728, "time": 22215.6902384758, "episode/length": 101.0, "episode/score": 0.6993873734620024, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.015012394448774558}
{"step": 698992, "time": 22224.030473709106, "episode/length": 135.0, "episode/score": 0.641341843234045, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0632168433504603}
{"step": 699056, "time": 22226.00260901451, "episode/length": 222.0, "episode/score": 0.35697298353295537, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.05072298094853522}
{"step": 699304, "time": 22233.378911972046, "episode/length": 288.0, "episode/score": 0.020963859923085693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020963859923085693}
{"step": 699360, "time": 22235.44246864319, "episode/length": 288.0, "episode/score": 0.06322889324047765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06322889324047765}
{"step": 699424, "time": 22237.40492582321, "episode/length": 135.0, "episode/score": 0.6034966046109389, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.025371631022665042}
{"step": 699425, "time": 22237.962733268738, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.0640961153423367, "train/action_min": 0.0, "train/action_std": 1.5801783692297624, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009771342191555017, "train/actor_opt_grad_steps": 42620.0, "train/actor_opt_loss": -6.974797927779169, "train/adv_mag": 0.9337850647356043, "train/adv_max": 0.28161883414091177, "train/adv_mean": 0.0016458600830949548, "train/adv_min": -0.9080009011167977, "train/adv_std": 0.029338740399715738, "train/cont_avg": 0.995563756281407, "train/cont_loss_mean": 0.016445131081474672, "train/cont_loss_std": 0.24109177587287098, "train/cont_neg_acc": 0.31006421508202003, "train/cont_neg_loss": 2.989150651622957, "train/cont_pos_acc": 0.9998421788814679, "train/cont_pos_loss": 0.0030463956601814784, "train/cont_pred": 0.9957432051998886, "train/cont_rate": 0.995563756281407, "train/dyn_loss_mean": 1.0000190770805781, "train/dyn_loss_std": 0.0006101575666037037, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.18441127515374567, "train/extr_critic_critic_opt_grad_steps": 42620.0, "train/extr_critic_critic_opt_loss": 7782.374126491834, "train/extr_critic_mag": 1.2242180929711117, "train/extr_critic_max": 1.2242180929711117, "train/extr_critic_mean": 1.1492875299262042, "train/extr_critic_min": 1.0165840327440194, "train/extr_critic_std": 0.01637099435712075, "train/extr_return_normed_mag": 0.931241458384835, "train/extr_return_normed_max": 0.2974178976749056, "train/extr_return_normed_mean": 0.03082835087646267, "train/extr_return_normed_min": -0.8963789921909121, "train/extr_return_normed_std": 0.034268738800219856, "train/extr_return_rate": 0.9991994934465418, "train/extr_return_raw_mag": 1.4175229342139546, "train/extr_return_raw_max": 1.4175229342139546, "train/extr_return_raw_mean": 1.1509334400071571, "train/extr_return_raw_min": 0.22372604434813687, "train/extr_return_raw_std": 0.03426873865981946, "train/extr_reward_mag": 0.30602439204652104, "train/extr_reward_max": 0.30602439204652104, "train/extr_reward_mean": 0.0019670546648031728, "train/extr_reward_min": 6.064098684032958e-06, "train/extr_reward_std": 0.00819886124215496, "train/image_loss_mean": 0.10943530930496341, "train/image_loss_std": 0.1077753843823869, "train/model_loss_mean": 0.7494101865806772, "train/model_loss_std": 0.3682151203928281, "train/model_opt_grad_norm": 20.75706816917688, "train/model_opt_grad_steps": 42581.331658291456, "train/model_opt_loss": 2806.3763004475504, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3743.718592964824, "train/policy_entropy_mag": 1.316227797886834, "train/policy_entropy_max": 1.316227797886834, "train/policy_entropy_mean": 0.11954297627036894, "train/policy_entropy_min": 0.06468649463138389, "train/policy_entropy_std": 0.15529828387588712, "train/policy_logprob_mag": 6.551080270029193, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11939803009206926, "train/policy_logprob_min": -6.551080270029193, "train/policy_logprob_std": 0.6542767295286284, "train/policy_randomness_mag": 0.6764073246088459, "train/policy_randomness_max": 0.6764073246088459, "train/policy_randomness_mean": 0.06143294061398386, "train/policy_randomness_min": 0.033242282855450805, "train/policy_randomness_std": 0.07980753511340175, "train/post_ent_mag": 3.56508562552869, "train/post_ent_max": 3.56508562552869, "train/post_ent_mean": 3.513849324317434, "train/post_ent_min": 3.4722086532631113, "train/post_ent_std": 0.016574301148516747, "train/prior_ent_mag": 3.929138126085751, "train/prior_ent_max": 3.929138126085751, "train/prior_ent_mean": 2.8660084769953436, "train/prior_ent_min": 2.8161803837397588, "train/prior_ent_std": 0.07903525093804352, "train/rep_loss_mean": 1.0000190770805781, "train/rep_loss_std": 0.0006101575666037037, "train/reward_avg": 0.0012265519057950427, "train/reward_loss_mean": 0.023518279124631655, "train/reward_loss_std": 0.13682935001263066, "train/reward_max_data": 0.5049497201669044, "train/reward_max_pred": 0.1606047087578318, "train/reward_neg_acc": 0.9997051774556912, "train/reward_neg_loss": 0.01812239348345516, "train/reward_pos_acc": 0.22910798246591862, "train/reward_pos_loss": 4.224545065366047, "train/reward_pred": 0.0010669575998297513, "train/reward_rate": 0.0012660961055276383, "train_stats/mean_log_entropy": 0.096768414690381, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.012081299908459187, "report/cont_loss_std": 0.22612887620925903, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.925930023193359, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0024651577696204185, "report/cont_pred": 0.9975481629371643, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1170162782073021, "report/image_loss_std": 0.10270733386278152, "report/model_loss_mean": 0.7457112669944763, "report/model_loss_std": 0.24883073568344116, "report/post_ent_mag": 3.4073171615600586, "report/post_ent_max": 3.4073171615600586, "report/post_ent_mean": 3.3662261962890625, "report/post_ent_min": 3.333465576171875, "report/post_ent_std": 0.013265140354633331, "report/prior_ent_mag": 3.2034807205200195, "report/prior_ent_max": 3.2034807205200195, "report/prior_ent_mean": 2.8626084327697754, "report/prior_ent_min": 2.8163394927978516, "report/prior_ent_std": 0.04695151001214981, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0003861597506329417, "report/reward_loss_mean": 0.01661364734172821, "report/reward_loss_std": 0.026064235717058182, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.0918952226638794, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01661364734172821, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0008059283718466759, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0455215647816658, "eval/cont_loss_std": 0.6712047457695007, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.018821716308594, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0014916348736733198, "eval/cont_pred": 0.9985108971595764, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19307249784469604, "eval/image_loss_std": 0.15120558440685272, "eval/model_loss_mean": 0.8565099835395813, "eval/model_loss_std": 0.8684449791908264, "eval/post_ent_mag": 3.4005308151245117, "eval/post_ent_max": 3.4005308151245117, "eval/post_ent_mean": 3.364699363708496, "eval/post_ent_min": 3.3298046588897705, "eval/post_ent_std": 0.012294648215174675, "eval/prior_ent_mag": 3.1887269020080566, "eval/prior_ent_max": 3.1887269020080566, "eval/prior_ent_mean": 2.85679292678833, "eval/prior_ent_min": 2.816293716430664, "eval/prior_ent_std": 0.038873109966516495, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0010772704845294356, "eval/reward_loss_mean": 0.017915919423103333, "eval/reward_loss_std": 0.3451574742794037, "eval/reward_max_data": 0.778124988079071, "eval/reward_max_pred": 0.05252242088317871, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0033388177398592234, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.466814041137695, "eval/reward_pred": 0.0006400640122592449, "eval/reward_rate": 0.001953125, "replay/size": 698921.0, "replay/inserts": 31880.0, "replay/samples": 31872.0, "replay/insert_wait_avg": 1.1825202549416267e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.480203387248947e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4808.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0256759338886687e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.993884563446, "timer/env.step_count": 3985.0, "timer/env.step_total": 34.28089237213135, "timer/env.step_frac": 0.03428110201603573, "timer/env.step_avg": 0.00860248240204049, "timer/env.step_min": 0.007170677185058594, "timer/env.step_max": 0.04960823059082031, "timer/replay._sample_count": 31872.0, "timer/replay._sample_total": 15.745655298233032, "timer/replay._sample_frac": 0.015745751590377877, "timer/replay._sample_avg": 0.0004940278394274922, "timer/replay._sample_min": 0.0004057884216308594, "timer/replay._sample_max": 0.026121139526367188, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4586.0, "timer/agent.policy_total": 39.00633382797241, "timer/agent.policy_frac": 0.03900657237019093, "timer/agent.policy_avg": 0.008505524166587966, "timer/agent.policy_min": 0.00726008415222168, "timer/agent.policy_max": 0.0787193775177002, "timer/dataset_train_count": 1992.0, "timer/dataset_train_total": 0.20760011672973633, "timer/dataset_train_frac": 0.0002076013863028428, "timer/dataset_train_avg": 0.00010421692606914474, "timer/dataset_train_min": 8.869171142578125e-05, "timer/dataset_train_max": 0.0002334117889404297, "timer/agent.train_count": 1992.0, "timer/agent.train_total": 881.3994069099426, "timer/agent.train_frac": 0.8814047970850576, "timer/agent.train_avg": 0.4424695817820997, "timer/agent.train_min": 0.4319767951965332, "timer/agent.train_max": 0.5926382541656494, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47071075439453125, "timer/agent.report_frac": 0.000470713633013889, "timer/agent.report_avg": 0.23535537719726562, "timer/agent.report_min": 0.2279832363128662, "timer/agent.report_max": 0.24272751808166504, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.76837158203125e-05, "timer/dataset_eval_frac": 4.768400742883457e-08, "timer/dataset_eval_avg": 4.76837158203125e-05, "timer/dataset_eval_min": 4.76837158203125e-05, "timer/dataset_eval_max": 4.76837158203125e-05, "fps": 31.87965209309691}
{"step": 699448, "time": 22238.6252553463, "episode/length": 56.0, "episode/score": 0.8433291148091371, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.018329104291012754}
{"step": 699808, "time": 22250.209141016006, "episode/length": 288.0, "episode/score": 0.029621283303413293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029621283303413293}
{"step": 699864, "time": 22251.74058532715, "episode/length": 62.0, "episode/score": 0.8223475760162842, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.016097574537809578}
{"step": 699952, "time": 22254.726987361908, "episode/length": 62.0, "episode/score": 0.8315085736059018, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.025258591001261266}
{"step": 699968, "time": 22255.22933936119, "episode/length": 67.0, "episode/score": 0.8160965634174318, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.02547156482023638}
{"step": 700024, "time": 22257.761274576187, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 700024, "time": 22258.409072875977, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 700024, "time": 22258.543529510498, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 700024, "time": 22259.350263357162, "eval_episode/length": 159.0, "eval_episode/score": 0.503125011920929, "eval_episode/reward_rate": 0.00625}
{"step": 700024, "time": 22261.4319126606, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 22261.43857049942, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 22261.445878505707, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 22261.452182531357, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 22261.459550619125, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700064, "time": 22262.933933973312, "episode/length": 31.0, "episode/score": 0.9102767049010367, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.007151731926853699}
{"step": 700296, "time": 22270.020067691803, "episode/length": 53.0, "episode/score": 0.8564468851934066, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.02207184202660528}
{"step": 700544, "time": 22277.89336538315, "episode/length": 71.0, "episode/score": 0.8145597301880798, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.03643474373882327}
{"step": 700640, "time": 22280.85462331772, "episode/length": 288.0, "episode/score": 0.07314930786571949, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07314930786571949}
{"step": 700712, "time": 22282.852387666702, "episode/length": 94.0, "episode/score": 0.7737149988305418, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.06746499983171361}
{"step": 701032, "time": 22292.69888162613, "episode/length": 48.0, "episode/score": 0.8974834815544455, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.04748346004089399}
{"step": 701040, "time": 22293.170312404633, "episode/length": 288.0, "episode/score": 0.0918803344991943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0918803344991943}
{"step": 701304, "time": 22301.200431108475, "episode/length": 125.0, "episode/score": 0.709736101173803, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.10036110350210947}
{"step": 701368, "time": 22303.172326803207, "episode/length": 288.0, "episode/score": 0.07787297934544313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07787297934544313}
{"step": 701456, "time": 22306.120314359665, "episode/length": 113.0, "episode/score": 0.7157096130031277, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.06883456052310066}
{"step": 701616, "time": 22311.047263622284, "episode/length": 288.0, "episode/score": 0.1085932846859805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1085932846859805}
{"step": 701824, "time": 22317.430747509003, "episode/length": 98.0, "episode/score": 0.7685368572233529, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.07478680474332577}
{"step": 701920, "time": 22320.38907933235, "episode/length": 76.0, "episode/score": 0.8049553072519302, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.042455319987766416}
{"step": 702248, "time": 22330.328705072403, "episode/length": 78.0, "episode/score": 0.8279172306010878, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.07166721968133061}
{"step": 702320, "time": 22332.76352906227, "episode/length": 118.0, "episode/score": 0.7337411903572502, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.10249113787722308}
{"step": 702376, "time": 22334.28160715103, "episode/length": 288.0, "episode/score": 0.10281158816354719, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10281158816354719}
{"step": 702616, "time": 22341.64253807068, "episode/length": 36.0, "episode/score": 0.9213890282380817, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.03388905308111134}
{"step": 702784, "time": 22347.022263526917, "episode/length": 107.0, "episode/score": 0.7371062444417475, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.07148128120570618}
{"step": 703024, "time": 22354.420363664627, "episode/length": 288.0, "episode/score": 0.10144263290726485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10144263290726485}
{"step": 703176, "time": 22358.951536893845, "episode/length": 69.0, "episode/score": 0.8295303843551665, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.04515537324914476}
{"step": 703352, "time": 22364.356563806534, "episode/length": 288.0, "episode/score": 0.0944169959179817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0944169959179817}
{"step": 703416, "time": 22366.32975077629, "episode/length": 145.0, "episode/score": 0.6293607762818283, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.08248577709673555}
{"step": 703736, "time": 22376.133292913437, "episode/length": 47.0, "episode/score": 0.903880295225008, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.050755319881773175}
{"step": 703768, "time": 22377.119307518005, "episode/length": 288.0, "episode/score": 0.06869484419371474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06869484419371474}
{"step": 703912, "time": 22381.545216798782, "episode/length": 61.0, "episode/score": 0.8597747719807103, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.05039976754528652}
{"step": 704136, "time": 22388.510453939438, "episode/length": 288.0, "episode/score": 0.07131086272852372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07131086272852372}
{"step": 704688, "time": 22406.134006500244, "episode/length": 288.0, "episode/score": 0.08612752775184163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08612752775184163}
{"step": 704824, "time": 22410.09323000908, "episode/length": 205.0, "episode/score": 0.4670981927890807, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.10772319925013107}
{"step": 705048, "time": 22417.184601306915, "episode/length": 27.0, "episode/score": 0.929962250076187, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.014337259598960372}
{"step": 705096, "time": 22418.709977388382, "episode/length": 288.0, "episode/score": 0.09944423915112566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09944423915112566}
{"step": 705336, "time": 22426.16184949875, "episode/length": 288.0, "episode/score": 0.10017907409348936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10017907409348936}
{"step": 705368, "time": 22427.1463906765, "episode/length": 153.0, "episode/score": 0.6173900929688898, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.09551505480794731}
{"step": 705696, "time": 22437.449108600616, "episode/length": 74.0, "episode/score": 0.790534034429129, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.02178399916692797}
{"step": 705752, "time": 22438.97187924385, "episode/length": 87.0, "episode/score": 0.7913006533590305, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.06317566288180387}
{"step": 705976, "time": 22445.956971406937, "episode/length": 75.0, "episode/score": 0.8232460759102196, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.05762106252245758}
{"step": 706048, "time": 22448.399713516235, "episode/length": 288.0, "episode/score": 0.07322548232900772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07322548232900772}
{"step": 706080, "time": 22449.38614463806, "episode/length": 288.0, "episode/score": 0.09913178419776614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09913178419776614}
{"step": 706160, "time": 22451.845309257507, "episode/length": 9.0, "episode/score": 0.9849625535189261, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.013087518256725161}
{"step": 706224, "time": 22453.823744773865, "episode/length": 288.0, "episode/score": 0.040702920883177285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040702920883177285}
{"step": 706456, "time": 22460.72864460945, "episode/length": 139.0, "episode/score": 0.6380895444034422, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.07246455663869256}
{"step": 706608, "time": 22465.615250587463, "episode/length": 78.0, "episode/score": 0.8201631018654325, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.06391307846013206}
{"step": 706672, "time": 22467.597262382507, "episode/length": 26.0, "episode/score": 0.9426513834223442, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.023901397671579616}
{"step": 706816, "time": 22471.999016284943, "episode/length": 139.0, "episode/score": 0.606293277437544, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.040668236121746304}
{"step": 706912, "time": 22475.034883975983, "episode/length": 93.0, "episode/score": 0.7442039687238093, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.03482893149418942}
{"step": 707000, "time": 22477.536538362503, "episode/length": 288.0, "episode/score": 0.036025653259002866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036025653259002866}
{"step": 707232, "time": 22484.878964662552, "episode/length": 147.0, "episode/score": 0.6270792964642169, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.08645429696480278}
{"step": 707256, "time": 22485.403245449066, "episode/length": 80.0, "episode/score": 0.7771506369444978, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.027150607549629058}
{"step": 708064, "time": 22510.568707942963, "episode/length": 288.0, "episode/score": 0.0893895843523751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0893895843523751}
{"step": 708496, "time": 22523.856964349747, "episode/length": 157.0, "episode/score": 0.5438361181542177, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.03446114537211997}
{"step": 708536, "time": 22524.868372917175, "episode/length": 288.0, "episode/score": 0.06832534965212744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06832534965212744}
{"step": 708832, "time": 22534.17927122116, "episode/length": 95.0, "episode/score": 0.7183866214840009, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.015261614324458606}
{"step": 708912, "time": 22536.73135495186, "episode/length": 51.0, "episode/score": 0.8643993263268612, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.02377433846606891}
{"step": 708952, "time": 22537.73903155327, "episode/length": 51.0, "episode/score": 0.8791193181925792, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.03849432295396582}
{"step": 708984, "time": 22538.728207826614, "episode/length": 288.0, "episode/score": 0.03071806145521805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03071806145521805}
{"step": 709048, "time": 22540.688777446747, "episode/length": 26.0, "episode/score": 0.9414532834242664, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.022703315485046005}
{"step": 709128, "time": 22543.146734714508, "episode/length": 288.0, "episode/score": 0.04981307328091589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04981307328091589}
{"step": 709224, "time": 22546.09245491028, "episode/length": 288.0, "episode/score": 0.05984327517398924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05984327517398924}
{"step": 709312, "time": 22549.021824121475, "episode/length": 288.0, "episode/score": 0.0734163818980278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0734163818980278}
{"step": 709320, "time": 22549.054401397705, "episode/length": 45.0, "episode/score": 0.8798970941269317, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.020522064732062972}
{"step": 709568, "time": 22556.909969091415, "episode/length": 288.0, "episode/score": 0.07258284091949463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07258284091949463}
{"step": 709872, "time": 22566.34713959694, "episode/length": 119.0, "episode/score": 0.6797320198968464, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.05160699458815543}
{"step": 709880, "time": 22566.380501031876, "episode/length": 70.0, "episode/score": 0.8535804777775411, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.07233048115358542}
{"step": 710008, "time": 22570.8773021698, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 710008, "time": 22571.496562957764, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 710008, "time": 22571.75860953331, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 710008, "time": 22571.975389003754, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 710008, "time": 22572.541336536407, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 710008, "time": 22572.964688539505, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 710008, "time": 22573.04973244667, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 710008, "time": 22573.964235305786, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 710416, "time": 22586.786591768265, "episode/length": 148.0, "episode/score": 0.6007252605635358, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.06322520732680914}
{"step": 710480, "time": 22588.76136136055, "episode/length": 75.0, "episode/score": 0.8193068501601601, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.05368183677239813}
{"step": 710528, "time": 22590.256830453873, "episode/length": 80.0, "episode/score": 0.7916687608596931, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.041668731464824305}
{"step": 710920, "time": 22602.169373512268, "episode/length": 168.0, "episode/score": 0.555700118486925, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.08070011105962749}
{"step": 711024, "time": 22605.591458559036, "episode/length": 61.0, "episode/score": 0.8473980804532175, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.03802311653032575}
{"step": 711136, "time": 22609.023666620255, "episode/length": 81.0, "episode/score": 0.7902844487662151, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.043409462316958525}
{"step": 711296, "time": 22613.93469810486, "episode/length": 288.0, "episode/score": 0.08191814145459375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08191814145459375}
{"step": 711360, "time": 22615.913796186447, "episode/length": 288.0, "episode/score": 0.0848170267089472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0848170267089472}
{"step": 711440, "time": 22618.35621714592, "episode/length": 288.0, "episode/score": 0.03763667542807525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03763667542807525}
{"step": 711592, "time": 22622.801419496536, "episode/length": 70.0, "episode/score": 0.8420537669263695, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.060803770302413795}
{"step": 711632, "time": 22624.26775741577, "episode/length": 288.0, "episode/score": 0.07894052010726682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07894052010726682}
{"step": 711896, "time": 22632.25015449524, "episode/length": 94.0, "episode/score": 0.7783763198037832, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.07212633203903351}
{"step": 711952, "time": 22634.201598644257, "episode/length": 81.0, "episode/score": 0.8006118536166014, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.053736883669216695}
{"step": 712088, "time": 22638.154828071594, "episode/length": 23.0, "episode/score": 0.9442623478774976, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.016137315857463363}
{"step": 712104, "time": 22638.652263641357, "episode/length": 92.0, "episode/score": 0.7820789556469663, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.06957895085065502}
{"step": 712408, "time": 22647.9743578434, "episode/length": 101.0, "episode/score": 0.7343024685939099, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.04992747335529657}
{"step": 712704, "time": 22657.51645731926, "episode/length": 93.0, "episode/score": 0.7476859900333466, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.038310994509515695}
{"step": 712728, "time": 22658.37333893776, "episode/length": 288.0, "episode/score": 0.07680262716553443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07680262716553443}
{"step": 712744, "time": 22658.87203669548, "episode/length": 41.0, "episode/score": 0.8880239609823093, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.016148965743695953}
{"step": 713144, "time": 22671.21540403366, "episode/length": 54.0, "episode/score": 0.8776919864940282, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.04644197620291379}
{"step": 713184, "time": 22672.666353464127, "episode/length": 54.0, "episode/score": 0.8711352358239424, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.03988519526484424}
{"step": 713232, "time": 22674.173988819122, "episode/length": 288.0, "episode/score": 0.06717204705648783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06717204705648783}
{"step": 713696, "time": 22688.660393238068, "episode/length": 63.0, "episode/score": 0.8542595175240422, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.05113449531199876}
{"step": 713752, "time": 22690.17217850685, "episode/length": 288.0, "episode/score": 0.060616791291749905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060616791291749905}
{"step": 713888, "time": 22694.582091093063, "episode/length": 92.0, "episode/score": 0.7811893709131255, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.06868939638479787}
{"step": 713944, "time": 22696.08322072029, "episode/length": 288.0, "episode/score": 0.06927721047736668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06927721047736668}
{"step": 714232, "time": 22704.951509475708, "episode/length": 66.0, "episode/score": 0.8429131391594638, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.049163153408699145}
{"step": 714400, "time": 22710.347631931305, "episode/length": 288.0, "episode/score": 0.09354874157742188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09354874157742188}
{"step": 714416, "time": 22710.870749235153, "episode/length": 288.0, "episode/score": 0.06961271305300443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06961271305300443}
{"step": 714960, "time": 22727.703350305557, "episode/length": 67.0, "episode/score": 0.8423391965911833, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.05171419179487202}
{"step": 714968, "time": 22727.738059282303, "episode/length": 70.0, "episode/score": 0.8112586636939341, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0300086350557649}
{"step": 715040, "time": 22730.19403409958, "episode/length": 288.0, "episode/score": 0.07047624802623886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07047624802623886}
{"step": 715152, "time": 22733.65705370903, "episode/length": 13.0, "episode/score": 0.9748745816832525, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.015499570763495285}
{"step": 715392, "time": 22741.139681100845, "episode/length": 53.0, "episode/score": 0.8780344385611443, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.04365942764138708}
{"step": 715472, "time": 22743.633353710175, "episode/length": 197.0, "episode/score": 0.48975499065340955, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.1053799976150458}
{"step": 715544, "time": 22745.741271018982, "episode/length": 288.0, "episode/score": 0.09760078901808811, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09760078901808811}
{"step": 715864, "time": 22755.61102604866, "episode/length": 48.0, "episode/score": 0.8894823538316814, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.03948231363347077}
{"step": 716024, "time": 22760.538021326065, "episode/length": 78.0, "episode/score": 0.7958257217073879, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.03957567854058652}
{"step": 716048, "time": 22761.50400686264, "episode/length": 111.0, "episode/score": 0.7285084084310256, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.07538343327405528}
{"step": 716064, "time": 22762.00634765625, "episode/length": 288.0, "episode/score": 0.05742672188262077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05742672188262077}
{"step": 716224, "time": 22766.95306968689, "episode/length": 84.0, "episode/score": 0.7972378761141954, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.05973783555509726}
{"step": 716256, "time": 22767.935424804688, "episode/length": 288.0, "episode/score": 0.06498254648454349, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06498254648454349}
{"step": 716544, "time": 22776.88014936447, "episode/length": 288.0, "episode/score": 0.10357853462460298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10357853462460298}
{"step": 716592, "time": 22778.366981744766, "episode/length": 67.0, "episode/score": 0.8262819932249386, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.035657002747711886}
{"step": 716752, "time": 22783.291393756866, "episode/length": 85.0, "episode/score": 0.7875723830941297, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.053197368775045106}
{"step": 717280, "time": 22799.493958711624, "episode/length": 288.0, "episode/score": 0.03296192554807931, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03296192554807931}
{"step": 717448, "time": 22804.437031030655, "episode/length": 86.0, "episode/score": 0.7562908997792874, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0250408973811318}
{"step": 717888, "time": 22818.25452876091, "episode/length": 54.0, "episode/score": 0.8526843007600746, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.02143426549787364}
{"step": 718104, "time": 22824.6617975235, "episode/length": 188.0, "episode/score": 0.4811106034915156, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.06861061591303041}
{"step": 718168, "time": 22826.619380950928, "episode/length": 34.0, "episode/score": 0.9059698091930386, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.012219768633940475}
{"step": 718176, "time": 22827.089579582214, "episode/length": 288.0, "episode/score": 0.09189052943804654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09189052943804654}
{"step": 718336, "time": 22831.999248743057, "episode/length": 288.0, "episode/score": 0.07292322783041527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07292322783041527}
{"step": 718376, "time": 22833.032024383545, "episode/length": 228.0, "episode/score": 0.35842237032966295, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.07092237745428065}
{"step": 718536, "time": 22838.042261123657, "episode/length": 288.0, "episode/score": 0.05215974530915446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05215974530915446}
{"step": 718568, "time": 22839.030433416367, "episode/length": 288.0, "episode/score": 0.07748856301691376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07748856301691376}
{"step": 718944, "time": 22850.782376527786, "episode/length": 70.0, "episode/score": 0.824711002120921, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.04346100255747842}
{"step": 718960, "time": 22851.27991580963, "episode/length": 77.0, "episode/score": 0.7814997452458101, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.02212476990257528}
{"step": 719312, "time": 22862.091062545776, "episode/length": 92.0, "episode/score": 0.7321170288983012, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.019617036383806408}
{"step": 719392, "time": 22864.5691511631, "episode/length": 55.0, "episode/score": 0.8592600619344921, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.031135033296322945}
{"step": 719592, "time": 22870.626746416092, "episode/length": 288.0, "episode/score": 0.08282275286228469, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08282275286228469}
{"step": 719904, "time": 22880.418614387512, "episode/length": 38.0, "episode/score": 0.9175109769803385, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.03626095476829505}
{"step": 720096, "time": 22887.018384695053, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 720096, "time": 22887.284667015076, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 720096, "time": 22887.39950489998, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 720096, "time": 22887.96675181389, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 720096, "time": 22889.052348136902, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 720096, "time": 22889.089054346085, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 720096, "time": 22889.310463428497, "eval_episode/length": 13.0, "eval_episode/score": 0.9593750238418579, "eval_episode/reward_rate": 0.07142857142857142}
{"step": 720096, "time": 22890.41091942787, "eval_episode/length": 225.0, "eval_episode/score": 0.296875, "eval_episode/reward_rate": 0.004424778761061947}
{"step": 720304, "time": 22896.91738009453, "episode/length": 167.0, "episode/score": 0.592737786751286, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.11461279371292221}
{"step": 720312, "time": 22896.9514272213, "episode/length": 275.0, "episode/score": 0.20736176736625112, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.06673676853040433}
{"step": 720424, "time": 22900.37767457962, "episode/length": 64.0, "episode/score": 0.8510048707642, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.051004830205101825}
{"step": 720480, "time": 22902.3365585804, "episode/length": 288.0, "episode/score": 0.08920227957071347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08920227957071347}
{"step": 720488, "time": 22902.370242357254, "episode/length": 288.0, "episode/score": 0.07154306455561255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07154306455561255}
{"step": 720560, "time": 22904.79141521454, "episode/length": 155.0, "episode/score": 0.5583605087788328, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.04273548014066364}
{"step": 720640, "time": 22907.25927233696, "episode/length": 155.0, "episode/score": 0.5751761215951774, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.059551122410084645}
{"step": 720848, "time": 22913.642246246338, "episode/length": 288.0, "episode/score": 0.10066348597342767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10066348597342767}
{"step": 720888, "time": 22914.655975818634, "episode/length": 72.0, "episode/score": 0.8258805450996078, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.050880540303296584}
{"step": 720928, "time": 22916.60483789444, "episode/length": 54.0, "episode/score": 0.8753087648738074, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.044058765874979144}
{"step": 721088, "time": 22921.53620505333, "episode/length": 75.0, "episode/score": 0.7936120013209802, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.027986987001895614}
{"step": 721320, "time": 22928.511296510696, "episode/length": 48.0, "episode/score": 0.8725793889470879, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.02257935078614537}
{"step": 721360, "time": 22929.96019434929, "episode/length": 130.0, "episode/score": 0.6421166667837497, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.04836666759865693}
{"step": 721456, "time": 22932.925184488297, "episode/length": 75.0, "episode/score": 0.793963752543732, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.028338733218788548}
{"step": 721624, "time": 22937.86207485199, "episode/length": 66.0, "episode/score": 0.8126128155347487, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.018862827892235146}
{"step": 721840, "time": 22944.69699525833, "episode/length": 59.0, "episode/score": 0.8395925744621309, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.02396754822211733}
{"step": 722248, "time": 22957.099142074585, "episode/length": 98.0, "episode/score": 0.7350018201691455, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.04125178293952558}
{"step": 722712, "time": 22971.32129716873, "episode/length": 285.0, "episode/score": 0.21021134070042535, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.10083634128250196}
{"step": 722848, "time": 22975.73875284195, "episode/length": 125.0, "episode/score": 0.6300255261212442, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.020650539043344907}
{"step": 722872, "time": 22976.261731863022, "episode/length": 288.0, "episode/score": 0.04236425449153103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04236425449153103}
{"step": 722952, "time": 22978.715726614, "episode/length": 288.0, "episode/score": 0.0708212411917657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0708212411917657}
{"step": 723200, "time": 22986.694880723953, "episode/length": 288.0, "episode/score": 0.06719659707209757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06719659707209757}
{"step": 723216, "time": 22987.191605091095, "episode/length": 62.0, "episode/score": 0.8312839133541274, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.025033938010892598}
{"step": 723632, "time": 22999.997856616974, "episode/length": 288.0, "episode/score": 0.03916788556261963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03916788556261963}
{"step": 723936, "time": 23009.337862730026, "episode/length": 288.0, "episode/score": 0.06930273593525271, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06930273593525271}
{"step": 724168, "time": 23016.438168764114, "episode/length": 151.0, "episode/score": 0.5530003243843566, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.024875316980342177}
{"step": 724424, "time": 23024.30797600746, "episode/length": 98.0, "episode/score": 0.7313838286033842, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.03763381768362706}
{"step": 724560, "time": 23028.72122144699, "episode/length": 288.0, "episode/score": 0.046428849927451665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046428849927451665}
{"step": 724760, "time": 23034.675652742386, "episode/length": 192.0, "episode/score": 0.481701750023376, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.08170172974382695}
{"step": 724936, "time": 23040.08341360092, "episode/length": 124.0, "episode/score": 0.6797691284625671, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.06726911817145265}
{"step": 724960, "time": 23041.040995121002, "episode/length": 98.0, "episode/score": 0.744851519282065, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.05110149776851358}
{"step": 725056, "time": 23043.98305273056, "episode/length": 78.0, "episode/score": 0.8078695627489196, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.05161955182916245}
{"step": 725160, "time": 23047.058606863022, "episode/length": 288.0, "episode/score": 0.05012198083795738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05012198083795738}
{"step": 725184, "time": 23048.026057958603, "episode/length": 288.0, "episode/score": 0.055372443329360976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055372443329360976}
{"step": 725256, "time": 23050.027544021606, "episode/length": 86.0, "episode/score": 0.7631325346819722, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.03188254741780838}
{"step": 725288, "time": 23051.009585618973, "episode/length": 65.0, "episode/score": 0.853377691348669, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.05650269297848354}
{"step": 725512, "time": 23057.881194591522, "episode/length": 288.0, "episode/score": 0.06845919763668462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06845919763668462}
{"step": 725536, "time": 23058.84124135971, "episode/length": 46.0, "episode/score": 0.8693413761511692, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.013091371715745481}
{"step": 725680, "time": 23063.258959054947, "episode/length": 52.0, "episode/score": 0.8666941106083641, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.029194115125278586}
{"step": 725824, "time": 23067.68257498741, "episode/length": 66.0, "episode/score": 0.8146491625489034, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.020899151128560334}
{"step": 726056, "time": 23074.610011339188, "episode/length": 67.0, "episode/score": 0.8291808089056758, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.03855581842844913}
{"step": 726216, "time": 23079.657726049423, "episode/length": 128.0, "episode/score": 0.644379593847134, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.04437955568619145}
{"step": 726584, "time": 23090.953536510468, "episode/length": 94.0, "episode/score": 0.7417406755646425, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0354906342488448}
{"step": 726656, "time": 23093.373478412628, "episode/length": 54.0, "episode/score": 0.847106534299428, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.015856492983630233}
{"step": 726816, "time": 23098.27890443802, "episode/length": 94.0, "episode/score": 0.7473590475262881, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.041109006210490406}
{"step": 727192, "time": 23109.70200061798, "episode/length": 66.0, "episode/score": 0.8128293715959671, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.019079407673075366}
{"step": 727248, "time": 23111.643953561783, "episode/length": 288.0, "episode/score": 0.04041730817948519, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04041730817948519}
{"step": 727272, "time": 23112.166499614716, "episode/length": 288.0, "episode/score": 0.024689957645705363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024689957645705363}
{"step": 727368, "time": 23115.116271972656, "episode/length": 288.0, "episode/score": 0.03736786326771835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03736786326771835}
{"step": 727456, "time": 23118.02793455124, "episode/length": 239.0, "episode/score": 0.27156042055457874, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.01843541911102875}
{"step": 727704, "time": 23125.421623706818, "episode/length": 63.0, "episode/score": 0.8402359431040622, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.03711090494311975}
{"step": 727784, "time": 23127.872751235962, "episode/length": 262.0, "episode/score": 0.26280481670903555, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.08155481156347832}
{"step": 728008, "time": 23134.885472774506, "episode/length": 68.0, "episode/score": 0.8107115620485956, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.02321151888179429}
{"step": 728160, "time": 23139.85451555252, "episode/length": 18.0, "episode/score": 0.9582864676943927, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.014536429533450246}
{"step": 728464, "time": 23149.20358991623, "episode/length": 37.0, "episode/score": 0.8993439631633464, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.014968987441761783}
{"step": 728896, "time": 23162.530277729034, "episode/length": 288.0, "episode/score": 0.04096951794895176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04096951794895176}
{"step": 729112, "time": 23169.572479963303, "episode/length": 229.0, "episode/score": 0.3424327558667528, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.05805774476073111}
{"step": 729120, "time": 23170.04289984703, "episode/length": 81.0, "episode/score": 0.7992318295396217, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.052356825104197924}
{"step": 729128, "time": 23170.075701236725, "episode/length": 288.0, "episode/score": 0.03980291650111667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03980291650111667}
{"step": 729560, "time": 23183.427201747894, "episode/length": 288.0, "episode/score": 0.04349042123124036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04349042123124036}
{"step": 729680, "time": 23187.400280237198, "episode/length": 288.0, "episode/score": 0.1153552788421166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1153552788421166}
{"step": 730008, "time": 23197.50516295433, "episode/length": 111.0, "episode/score": 0.7218703923531393, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.06874540471062573}
{"step": 730016, "time": 23197.98536300659, "episode/length": 111.0, "episode/score": 0.7308379899404827, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.07771298754232703}
{"step": 730016, "time": 23197.993048906326, "episode/length": 288.0, "episode/score": 0.09752324880355445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09752324880355445}
{"step": 730080, "time": 23200.447739124298, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 730080, "time": 23200.48549246788, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 730080, "time": 23200.797372817993, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 730080, "time": 23201.188689231873, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 730080, "time": 23201.275863170624, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 730080, "time": 23201.329545736313, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 730080, "time": 23201.463927030563, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 730080, "time": 23202.32095193863, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 730096, "time": 23202.81587123871, "episode/length": 288.0, "episode/score": 0.14503092140364515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14503092140364515}
{"step": 730184, "time": 23205.311695575714, "episode/length": 77.0, "episode/score": 0.8005198222193712, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.04114482271995712}
{"step": 730328, "time": 23209.750361680984, "episode/length": 80.0, "episode/score": 0.7988715623442886, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.04887154598793586}
{"step": 730464, "time": 23214.16664791107, "episode/length": 166.0, "episode/score": 0.5391119977796279, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.05786202017793585}
{"step": 730792, "time": 23224.0483314991, "episode/length": 96.0, "episode/score": 0.7387349226407878, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.038734905166847966}
{"step": 730808, "time": 23224.544165849686, "episode/length": 59.0, "episode/score": 0.8529264278014352, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.03730139253923426}
{"step": 730832, "time": 23225.63910675049, "episode/length": 102.0, "episode/score": 0.7464674392283541, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.06521744968245002}
{"step": 730864, "time": 23226.622854948044, "episode/length": 49.0, "episode/score": 0.903573858194477, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.05669883195446346}
{"step": 730912, "time": 23228.101453065872, "episode/length": 111.0, "episode/score": 0.7213282106521319, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.06820324672924016}
{"step": 731208, "time": 23236.993515968323, "episode/length": 288.0, "episode/score": 0.0754419161730766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0754419161730766}
{"step": 731209, "time": 23237.998698711395, "train_stats/mean_log_entropy": 0.08870168524508429, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1228321784704773, "train/action_min": 0.0, "train/action_std": 1.6315193487771193, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010863556328870767, "train/actor_opt_grad_steps": 44610.0, "train/actor_opt_loss": -7.45854496386782, "train/adv_mag": 0.9566832388465728, "train/adv_max": 0.3234150972797643, "train/adv_mean": 0.0012467734180428471, "train/adv_min": -0.9193656824941012, "train/adv_std": 0.031809470431420524, "train/cont_avg": 0.9956962547110553, "train/cont_loss_mean": 0.016404868667505346, "train/cont_loss_std": 0.2353780178514651, "train/cont_neg_acc": 0.31063011574624766, "train/cont_neg_loss": 3.0170682671978466, "train/cont_pos_acc": 0.99987666361296, "train/cont_pos_loss": 0.0031071794061364615, "train/cont_pred": 0.9957747546272662, "train/cont_rate": 0.9956962547110553, "train/dyn_loss_mean": 1.000013402958012, "train/dyn_loss_std": 0.00042866318294750385, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2082504801845281, "train/extr_critic_critic_opt_grad_steps": 44610.0, "train/extr_critic_critic_opt_loss": 4107.24161702065, "train/extr_critic_mag": 1.254299964138012, "train/extr_critic_max": 1.254299964138012, "train/extr_critic_mean": 1.1870811159287267, "train/extr_critic_min": 1.0355719345897885, "train/extr_critic_std": 0.01564903801597243, "train/extr_return_normed_mag": 0.9557035274841078, "train/extr_return_normed_max": 0.33100457886355605, "train/extr_return_normed_mean": 0.029246105798449946, "train/extr_return_normed_min": -0.9115860977364545, "train/extr_return_normed_std": 0.03654723153940996, "train/extr_return_rate": 0.9990898903889872, "train/extr_return_raw_mag": 1.4900862883083785, "train/extr_return_raw_max": 1.4900862883083785, "train/extr_return_raw_mean": 1.1883278767667225, "train/extr_return_raw_min": 0.2474956117083679, "train/extr_return_raw_std": 0.03654723156281003, "train/extr_reward_mag": 0.340876539148877, "train/extr_reward_max": 0.340876539148877, "train/extr_reward_mean": 0.0021728983379423095, "train/extr_reward_min": 5.656151316273752e-06, "train/extr_reward_std": 0.009127360604815747, "train/image_loss_mean": 0.10680318346724438, "train/image_loss_std": 0.10759541062853444, "train/model_loss_mean": 0.7477983724531816, "train/model_loss_std": 0.38200282533863683, "train/model_opt_grad_norm": 19.97965350222947, "train/model_opt_grad_steps": 44570.236180904525, "train/model_opt_loss": 3908.592163699356, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5226.130653266332, "train/policy_entropy_mag": 1.3403219308086376, "train/policy_entropy_max": 1.3403219308086376, "train/policy_entropy_mean": 0.11540665470026246, "train/policy_entropy_min": 0.06468649219777715, "train/policy_entropy_std": 0.15134215272551205, "train/policy_logprob_mag": 6.551080272425359, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11589622621110936, "train/policy_logprob_min": -6.551080272425359, "train/policy_logprob_std": 0.6542996689302838, "train/policy_randomness_mag": 0.6887892568530749, "train/policy_randomness_max": 0.6887892568530749, "train/policy_randomness_mean": 0.059307291598326, "train/policy_randomness_min": 0.033242281582487286, "train/policy_randomness_std": 0.0777744861628542, "train/post_ent_mag": 3.1665245168772174, "train/post_ent_max": 3.1665245168772174, "train/post_ent_mean": 3.1425624504760283, "train/post_ent_min": 3.1233653483079307, "train/post_ent_std": 0.007999245814473635, "train/prior_ent_mag": 3.7346069177790504, "train/prior_ent_max": 3.7346069177790504, "train/prior_ent_mean": 2.8466060377245572, "train/prior_ent_min": 2.8138048013850074, "train/prior_ent_std": 0.053645071138314265, "train/rep_loss_mean": 1.000013402958012, "train/rep_loss_std": 0.00042866318294750385, "train/reward_avg": 0.0013879925148893879, "train/reward_loss_mean": 0.024582256034166368, "train/reward_loss_std": 0.15503260541014635, "train/reward_max_data": 0.5801929367434739, "train/reward_max_pred": 0.16820387265191006, "train/reward_neg_acc": 0.9997934887756654, "train/reward_neg_loss": 0.018179293286673087, "train/reward_pos_acc": 0.2472746342233142, "train/reward_pos_loss": 4.297691618496517, "train/reward_pred": 0.0011481041294620863, "train/reward_rate": 0.0014771121231155779, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.003467112546786666, "report/cont_loss_std": 0.0445161797106266, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 1.401729941368103, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0021002867724746466, "report/cont_pred": 0.9976968765258789, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10825783014297485, "report/image_loss_std": 0.11088046431541443, "report/model_loss_mean": 0.726587176322937, "report/model_loss_std": 0.12416382879018784, "report/post_ent_mag": 2.943040132522583, "report/post_ent_max": 2.943040132522583, "report/post_ent_mean": 2.9308767318725586, "report/post_ent_min": 2.923696517944336, "report/post_ent_std": 0.0051979911513626575, "report/prior_ent_mag": 3.1512584686279297, "report/prior_ent_max": 3.1512584686279297, "report/prior_ent_mean": 2.82500958442688, "report/prior_ent_min": 2.8120923042297363, "report/prior_ent_std": 0.020043237134814262, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0003596906899474561, "report/reward_loss_mean": 0.014862177893519402, "report/reward_loss_std": 0.023866428062319756, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.0133742094039917, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.014862176962196827, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0005785108078271151, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.018942318856716156, "eval/cont_loss_std": 0.2818581461906433, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.192232131958008, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003741663182154298, "eval/cont_pred": 0.9964264631271362, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18488359451293945, "eval/image_loss_std": 0.15385332703590393, "eval/model_loss_mean": 0.8159469366073608, "eval/model_loss_std": 0.5253979563713074, "eval/post_ent_mag": 2.942930221557617, "eval/post_ent_max": 2.942930221557617, "eval/post_ent_mean": 2.9311437606811523, "eval/post_ent_min": 2.9234843254089355, "eval/post_ent_std": 0.004521885886788368, "eval/prior_ent_mag": 3.205142021179199, "eval/prior_ent_max": 3.205142021179199, "eval/prior_ent_mean": 2.8302531242370605, "eval/prior_ent_min": 2.8122916221618652, "eval/prior_ent_std": 0.034396201372146606, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007720947032794356, "eval/reward_loss_mean": 0.012120995670557022, "eval/reward_loss_std": 0.2756592929363251, "eval/reward_max_data": 0.7906249761581421, "eval/reward_max_pred": 0.07780539989471436, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0035045011900365353, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.82679557800293, "eval/reward_pred": 0.0007200980326160789, "eval/reward_rate": 0.0009765625, "replay/size": 730705.0, "replay/inserts": 31784.0, "replay/samples": 31792.0, "replay/insert_wait_avg": 1.175020132921758e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.429282510466592e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7136.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0068641115197153e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0182602405548, "timer/env.step_count": 3973.0, "timer/env.step_total": 33.767930030822754, "timer/env.step_frac": 0.0337673134315566, "timer/env.step_avg": 0.008499353141410208, "timer/env.step_min": 0.007194042205810547, "timer/env.step_max": 0.04438209533691406, "timer/replay._sample_count": 31792.0, "timer/replay._sample_total": 15.614810943603516, "timer/replay._sample_frac": 0.015614525818605918, "timer/replay._sample_avg": 0.0004911553517741418, "timer/replay._sample_min": 0.0003986358642578125, "timer/replay._sample_max": 0.010803461074829102, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4865.0, "timer/agent.policy_total": 40.963658809661865, "timer/agent.policy_frac": 0.04096291081705652, "timer/agent.policy_avg": 0.008420073753270682, "timer/agent.policy_min": 0.007374286651611328, "timer/agent.policy_max": 0.07070326805114746, "timer/dataset_train_count": 1987.0, "timer/dataset_train_total": 0.20464634895324707, "timer/dataset_train_frac": 0.0002046426121299218, "timer/dataset_train_avg": 0.0001029926265491933, "timer/dataset_train_min": 8.845329284667969e-05, "timer/dataset_train_max": 0.00025343894958496094, "timer/agent.train_count": 1987.0, "timer/agent.train_total": 877.8092505931854, "timer/agent.train_frac": 0.8777932218777965, "timer/agent.train_avg": 0.4417761704042201, "timer/agent.train_min": 0.43130064010620117, "timer/agent.train_max": 0.601356029510498, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4784362316131592, "timer/agent.report_frac": 0.0004784274954120049, "timer/agent.report_avg": 0.2392181158065796, "timer/agent.report_min": 0.23254680633544922, "timer/agent.report_max": 0.24588942527770996, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7894464395252808e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 31.782875101135073}
{"step": 731424, "time": 23244.579971551895, "episode/length": 69.0, "episode/score": 0.8138254389331223, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.029450455330220393}
{"step": 731448, "time": 23245.1033308506, "episode/length": 81.0, "episode/score": 0.7896153374257437, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.04274034978323016}
{"step": 731480, "time": 23246.108639478683, "episode/length": 80.0, "episode/score": 0.7954792824818924, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.04547925308702361}
{"step": 731600, "time": 23250.001007318497, "episode/length": 85.0, "episode/score": 0.7606583477826234, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.02628332845768}
{"step": 731648, "time": 23251.499580144882, "episode/length": 104.0, "episode/score": 0.7413232209706848, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.06632318570848383}
{"step": 731864, "time": 23258.02924489975, "episode/length": 81.0, "episode/score": 0.791368366538677, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.04449337889616345}
{"step": 732024, "time": 23262.941981077194, "episode/length": 46.0, "episode/score": 0.8685076992775294, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0122576978106963}
{"step": 732072, "time": 23264.423050165176, "episode/length": 77.0, "episode/score": 0.8010116640730303, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.04163667452712616}
{"step": 732408, "time": 23274.791614055634, "episode/length": 288.0, "episode/score": 0.13605270496282174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13605270496282174}
{"step": 732488, "time": 23277.2722094059, "episode/length": 57.0, "episode/score": 0.8500650371961456, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.028190089356030512}
{"step": 732496, "time": 23277.744762182236, "episode/length": 288.0, "episode/score": 0.11164685004587227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11164685004587227}
{"step": 732552, "time": 23279.249727249146, "episode/length": 133.0, "episode/score": 0.6766986347395232, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.09232363921569231}
{"step": 732640, "time": 23282.19450545311, "episode/length": 129.0, "episode/score": 0.6756178644043302, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.07874287061508767}
{"step": 732720, "time": 23284.659927368164, "episode/length": 80.0, "episode/score": 0.7981129475249418, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.04811296565662815}
{"step": 732928, "time": 23291.17333817482, "episode/length": 54.0, "episode/score": 0.861656965526663, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.03040696677521737}
{"step": 733056, "time": 23295.10299181938, "episode/length": 41.0, "episode/score": 0.8951240263037334, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.023249012904329902}
{"step": 733168, "time": 23298.55657196045, "episode/length": 65.0, "episode/score": 0.8358948367118728, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.03901981337060079}
{"step": 733368, "time": 23304.491953849792, "episode/length": 108.0, "episode/score": 0.7303917397356372, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.06789171633033675}
{"step": 733384, "time": 23304.98546886444, "episode/length": 26.0, "episode/score": 0.9377936494711321, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.019043684500502422}
{"step": 733632, "time": 23312.838197231293, "episode/length": 152.0, "episode/score": 0.5981938282587862, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0731938387128821}
{"step": 733736, "time": 23315.947390317917, "episode/length": 288.0, "episode/score": 0.11880103749717819, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11880103749717819}
{"step": 733776, "time": 23317.395044088364, "episode/length": 48.0, "episode/score": 0.8778620618363675, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.027862029816333234}
{"step": 734048, "time": 23325.75271677971, "episode/length": 84.0, "episode/score": 0.7786655018697957, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.041165460553997946}
{"step": 734080, "time": 23326.737832069397, "episode/length": 127.0, "episode/score": 0.6553228515012961, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.05219790175488015}
{"step": 734176, "time": 23329.682492017746, "episode/length": 288.0, "episode/score": 0.07614735295874198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07614735295874198}
{"step": 734600, "time": 23342.533670663834, "episode/length": 107.0, "episode/score": 0.7264946040259019, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.06086961968958349}
{"step": 734656, "time": 23344.4796295166, "episode/length": 59.0, "episode/score": 0.8371805215004997, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.021555533735750032}
{"step": 734808, "time": 23349.025620937347, "episode/length": 128.0, "episode/score": 0.6565072935798071, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.05650728484283718}
{"step": 734864, "time": 23350.98557972908, "episode/length": 288.0, "episode/score": 0.09720946770164574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09720946770164574}
{"step": 735144, "time": 23359.455297231674, "episode/length": 136.0, "episode/score": 0.6367774495535059, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.061777487886161}
{"step": 735240, "time": 23362.42085456848, "episode/length": 288.0, "episode/score": 0.10616072109473862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10616072109473862}
{"step": 735392, "time": 23367.32052230835, "episode/length": 91.0, "episode/score": 0.7889987787369819, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.07337377727014882}
{"step": 735472, "time": 23369.79678440094, "episode/length": 75.0, "episode/score": 0.8207516892072135, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.05512668102903717}
{"step": 735696, "time": 23376.78963661194, "episode/length": 136.0, "episode/score": 0.67029607123402, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.09529610731112825}
{"step": 735848, "time": 23381.263268709183, "episode/length": 87.0, "episode/score": 0.7796788680010422, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.051553915999079436}
{"step": 735944, "time": 23384.21243953705, "episode/length": 288.0, "episode/score": 0.09528607811620304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09528607811620304}
{"step": 736008, "time": 23386.19428706169, "episode/length": 149.0, "episode/score": 0.5890139708167794, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.05463895173630817}
{"step": 736336, "time": 23396.487461566925, "episode/length": 107.0, "episode/score": 0.7279003778742776, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.06227542482457693}
{"step": 736376, "time": 23397.498228549957, "episode/length": 65.0, "episode/score": 0.8209557858463086, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.024080814164335607}
{"step": 736392, "time": 23397.99769449234, "episode/length": 288.0, "episode/score": 0.08623500914200122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08623500914200122}
{"step": 736432, "time": 23399.468878746033, "episode/length": 60.0, "episode/score": 0.8425253861660167, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.030025414484043722}
{"step": 736736, "time": 23408.909445524216, "episode/length": 129.0, "episode/score": 0.6587983041077337, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.06192328502726241}
{"step": 736784, "time": 23410.405792474747, "episode/length": 192.0, "episode/score": 0.4730194950167288, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.07301949243230865}
{"step": 736800, "time": 23410.903586626053, "episode/length": 57.0, "episode/score": 0.8414555074618306, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.019580549435374905}
{"step": 737328, "time": 23427.634108543396, "episode/length": 65.0, "episode/score": 0.8233966394822687, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.026521633035770265}
{"step": 737344, "time": 23428.12978696823, "episode/length": 113.0, "episode/score": 0.7196845818848487, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0728095761746772}
{"step": 737544, "time": 23434.05888223648, "episode/length": 191.0, "episode/score": 0.46922696477429326, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.06610197521092687}
{"step": 737632, "time": 23437.12113761902, "episode/length": 111.0, "episode/score": 0.6892199768383875, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.03609500889916717}
{"step": 737672, "time": 23438.134962320328, "episode/length": 284.0, "episode/score": 0.164788161211618, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.05228816756789456}
{"step": 737888, "time": 23444.99919629097, "episode/length": 67.0, "episode/score": 0.841685922554575, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.05106094661471161}
{"step": 737952, "time": 23446.96787571907, "episode/length": 145.0, "episode/score": 0.5814687785459682, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.03459377876424696}
{"step": 738032, "time": 23449.451854228973, "episode/length": 204.0, "episode/score": 0.4017279979295836, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.03922799917813791}
{"step": 738184, "time": 23453.888782024384, "episode/length": 63.0, "episode/score": 0.834851650425378, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.03172664672337078}
{"step": 738200, "time": 23454.40675354004, "episode/length": 38.0, "episode/score": 0.8986712114238458, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.01742121399371399}
{"step": 738688, "time": 23469.70568561554, "episode/length": 288.0, "episode/score": 0.08596336843788777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08596336843788777}
{"step": 739000, "time": 23479.057436943054, "episode/length": 130.0, "episode/score": 0.672734096542797, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.07898409991884137}
{"step": 739344, "time": 23489.817157268524, "episode/length": 144.0, "episode/score": 0.6354343249088856, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.08543433111964305}
{"step": 739352, "time": 23489.849309921265, "episode/length": 164.0, "episode/score": 0.5467307492639861, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.05923074470632628}
{"step": 739640, "time": 23498.812546253204, "episode/length": 288.0, "episode/score": 0.06143760985406743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06143760985406743}
{"step": 739856, "time": 23505.73841071129, "episode/length": 288.0, "episode/score": 0.07958174862596934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07958174862596934}
{"step": 739888, "time": 23506.73735976219, "episode/length": 66.0, "episode/score": 0.8152818987896921, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.02153190426412266}
{"step": 739944, "time": 23508.260470867157, "episode/length": 288.0, "episode/score": 0.05641853515845696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05641853515845696}
{"step": 740064, "time": 23513.736275434494, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 740064, "time": 23514.077352046967, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 740064, "time": 23514.399318933487, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 740064, "time": 23515.893831014633, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 740064, "time": 23515.93162894249, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 740064, "time": 23516.390926361084, "eval_episode/length": 259.0, "eval_episode/score": 0.19062499701976776, "eval_episode/reward_rate": 0.0038461538461538464}
{"step": 740064, "time": 23516.852095127106, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740064, "time": 23516.858428239822, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740064, "time": 23516.864258289337, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740064, "time": 23516.8699054718, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740512, "time": 23530.859308719635, "episode/length": 288.0, "episode/score": 0.09071501689624029, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09071501689624029}
{"step": 740608, "time": 23533.860677480698, "episode/length": 89.0, "episode/score": 0.7439577971961171, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.022082778828689698}
{"step": 740776, "time": 23538.891652345657, "episode/length": 114.0, "episode/score": 0.6913821375118232, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.047632103151840965}
{"step": 740840, "time": 23540.895112752914, "episode/length": 28.0, "episode/score": 0.9320298206207553, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.019529808856987074}
{"step": 741000, "time": 23545.888550519943, "episode/length": 288.0, "episode/score": 0.09519784919376661, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09519784919376661}
{"step": 741312, "time": 23555.94276046753, "episode/length": 288.0, "episode/score": 0.08096769912646096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08096769912646096}
{"step": 741352, "time": 23556.97356724739, "episode/length": 63.0, "episode/score": 0.8473836310673164, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.044258625357144865}
{"step": 741656, "time": 23566.477996587753, "episode/length": 288.0, "episode/score": 0.060425313943710535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060425313943710535}
{"step": 741952, "time": 23575.930555582047, "episode/length": 288.0, "episode/score": 0.09772387949050199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09772387949050199}
{"step": 742256, "time": 23585.420896291733, "episode/length": 288.0, "episode/score": 0.06898760798492276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06898760798492276}
{"step": 742464, "time": 23591.810841083527, "episode/length": 138.0, "episode/score": 0.6266491158905296, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.05789906672833922}
{"step": 742520, "time": 23593.333202123642, "episode/length": 150.0, "episode/score": 0.5819871632973559, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.05073716351563462}
{"step": 742584, "time": 23595.29710006714, "episode/length": 78.0, "episode/score": 0.7828689224648997, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.026618910701131426}
{"step": 742680, "time": 23598.259215593338, "episode/length": 209.0, "episode/score": 0.44009946903884156, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.09322445727798367}
{"step": 742824, "time": 23602.679337501526, "episode/length": 288.0, "episode/score": 0.08599355601182879, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08599355601182879}
{"step": 742928, "time": 23606.100826501846, "episode/length": 50.0, "episode/score": 0.8610797192253585, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.017329719370877683}
{"step": 742984, "time": 23607.60091304779, "episode/length": 64.0, "episode/score": 0.8261653893518996, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.026165370984472247}
{"step": 742992, "time": 23608.08679175377, "episode/length": 166.0, "episode/score": 0.5299754626306026, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.048725470462443354}
{"step": 743064, "time": 23610.073013544083, "episode/length": 100.0, "episode/score": 0.7588808381629519, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.07138085133243521}
{"step": 743088, "time": 23611.03542995453, "episode/length": 288.0, "episode/score": 0.08252548345438981, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08252548345438981}
{"step": 743384, "time": 23620.019535303116, "episode/length": 99.0, "episode/score": 0.7209048400497409, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.030279840206901554}
{"step": 743656, "time": 23628.375623703003, "episode/length": 121.0, "episode/score": 0.6693535436090201, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0474785676080387}
{"step": 743688, "time": 23629.3564286232, "episode/length": 87.0, "episode/score": 0.8135225693282564, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.08539756784978181}
{"step": 744024, "time": 23639.686988830566, "episode/length": 116.0, "episode/score": 0.7010130197220974, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0635130578655776}
{"step": 744096, "time": 23642.114883184433, "episode/length": 128.0, "episode/score": 0.6399330251365996, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.03993302770646778}
{"step": 744472, "time": 23653.571749448776, "episode/length": 184.0, "episode/score": 0.4987231159881276, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.07372310421271777}
{"step": 744496, "time": 23654.529137849808, "episode/length": 58.0, "episode/score": 0.8576486018715173, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.038898578247938076}
{"step": 744560, "time": 23656.493153572083, "episode/length": 57.0, "episode/score": 0.8418795959125873, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.02000460456224573}
{"step": 744808, "time": 23663.92341852188, "episode/length": 177.0, "episode/score": 0.5280700898333066, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.08119507717896113}
{"step": 744864, "time": 23665.860969781876, "episode/length": 45.0, "episode/score": 0.8885348002677915, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.029159823376232907}
{"step": 744920, "time": 23667.377373218536, "episode/length": 55.0, "episode/score": 0.8670841459556868, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.03895917217823808}
{"step": 745136, "time": 23674.228160619736, "episode/length": 288.0, "episode/score": 0.10296967220688202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10296967220688202}
{"step": 745200, "time": 23676.292791366577, "episode/length": 79.0, "episode/score": 0.8121289772573732, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.05900397540636959}
{"step": 745240, "time": 23677.322508096695, "episode/length": 288.0, "episode/score": 0.09160826383561016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09160826383561016}
{"step": 745256, "time": 23677.817381858826, "episode/length": 55.0, "episode/score": 0.8571169806289163, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.028991965436716782}
{"step": 745384, "time": 23681.737600803375, "episode/length": 57.0, "episode/score": 0.852047067665012, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.03017210467635323}
{"step": 745648, "time": 23690.561686754227, "episode/length": 63.0, "episode/score": 0.8304552750343532, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.027330261262420663}
{"step": 745664, "time": 23691.059729099274, "episode/length": 250.0, "episode/score": 0.25446547092769833, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.03571546509238033}
{"step": 745664, "time": 23691.064992189407, "episode/length": 50.0, "episode/score": 0.869557954947993, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.025807950480555064}
{"step": 745904, "time": 23698.50073504448, "episode/length": 276.0, "episode/score": 0.1868456168481316, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0493456131257517}
{"step": 746000, "time": 23701.498696565628, "episode/length": 141.0, "episode/score": 0.6362855862666379, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.07691062459929299}
{"step": 746072, "time": 23703.543293952942, "episode/length": 50.0, "episode/score": 0.8612423836621588, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.017492379194720797}
{"step": 746104, "time": 23704.54287457466, "episode/length": 89.0, "episode/score": 0.7538462268393005, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.031971241330097655}
{"step": 746344, "time": 23712.15487885475, "episode/length": 54.0, "episode/score": 0.8569425123228598, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.025692517544086968}
{"step": 746368, "time": 23713.14659690857, "episode/length": 140.0, "episode/score": 0.6163318389531014, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.05383183486401322}
{"step": 746416, "time": 23714.649832725525, "episode/length": 42.0, "episode/score": 0.8984369783329385, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.029686998085708183}
{"step": 746480, "time": 23716.640033483505, "episode/length": 159.0, "episode/score": 0.53314588930931, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.030020849274080774}
{"step": 747032, "time": 23733.713020801544, "episode/length": 85.0, "episode/score": 0.7722274295986153, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.037852401484315124}
{"step": 747232, "time": 23740.16373538971, "episode/length": 140.0, "episode/score": 0.603710190981019, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.04121020238972051}
{"step": 747584, "time": 23751.05034136772, "episode/length": 137.0, "episode/score": 0.6051042036334024, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.03322922102876191}
{"step": 747648, "time": 23753.073276519775, "episode/length": 247.0, "episode/score": 0.26835614908304706, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.040231145363577525}
{"step": 747760, "time": 23756.567692279816, "episode/length": 167.0, "episode/score": 0.5136843653849041, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0355593715025293}
{"step": 747856, "time": 23759.593915700912, "episode/length": 275.0, "episode/score": 0.2237951184040412, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.08317012576731031}
{"step": 747880, "time": 23760.12768626213, "episode/length": 105.0, "episode/score": 0.7234916711909705, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.05161664875191718}
{"step": 748312, "time": 23773.602728128433, "episode/length": 288.0, "episode/score": 0.033640167006126376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033640167006126376}
{"step": 748360, "time": 23775.08324456215, "episode/length": 74.0, "episode/score": 0.7925895015269475, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.023839489766089628}
{"step": 748400, "time": 23776.534247159958, "episode/length": 145.0, "episode/score": 0.5751555839285629, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.028280592994406106}
{"step": 748680, "time": 23784.915825605392, "episode/length": 288.0, "episode/score": 0.09097086522524478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09097086522524478}
{"step": 748704, "time": 23785.87484240532, "episode/length": 105.0, "episode/score": 0.7062109736322668, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.034335973777785966}
{"step": 748736, "time": 23786.859973669052, "episode/length": 46.0, "episode/score": 0.8861626578918163, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.029912683971758725}
{"step": 749048, "time": 23796.349365711212, "episode/length": 38.0, "episode/score": 0.8971405996840645, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.015890553403153262}
{"step": 749448, "time": 23808.806933879852, "episode/length": 141.0, "episode/score": 0.5881072026389518, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.028732204970168596}
{"step": 749504, "time": 23810.736246585846, "episode/length": 56.0, "episode/score": 0.8533281610706354, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.028328143298381292}
{"step": 749720, "time": 23817.162098169327, "episode/length": 129.0, "episode/score": 0.6286097528707444, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.031734717732234685}
{"step": 749896, "time": 23822.62215065956, "episode/length": 288.0, "episode/score": 0.047673952387640384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047673952387640384}
{"step": 749960, "time": 23824.62246465683, "episode/length": 288.0, "episode/score": 0.03129674651987102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03129674651987102}
{"step": 749992, "time": 23825.734466314316, "episode/length": 60.0, "episode/score": 0.8442363797537666, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.03173638982369198}
{"step": 750048, "time": 23828.66446018219, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 750048, "time": 23829.00774860382, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 750048, "time": 23829.272954702377, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 750048, "time": 23829.75851035118, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 750048, "time": 23830.03776407242, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 750048, "time": 23830.300636053085, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 750048, "time": 23830.531273841858, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 750048, "time": 23830.98615550995, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 750104, "time": 23832.512216329575, "episode/length": 81.0, "episode/score": 0.7748288981796065, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.027953922178625135}
{"step": 750128, "time": 23833.49188733101, "episode/length": 215.0, "episode/score": 0.384920049313223, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.05679503665305674}
{"step": 750192, "time": 23835.51777434349, "episode/length": 288.0, "episode/score": 0.048407334335735186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048407334335735186}
{"step": 750400, "time": 23841.953913211823, "episode/length": 62.0, "episode/score": 0.8325465016142175, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.026296542598231554}
{"step": 750864, "time": 23856.34200692177, "episode/length": 94.0, "episode/score": 0.7323808670189464, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.026130855243536644}
{"step": 750896, "time": 23857.328147888184, "episode/length": 112.0, "episode/score": 0.7048994253718206, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.05489944935919766}
{"step": 751016, "time": 23860.798295497894, "episode/length": 288.0, "episode/score": 0.06344446969396245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06344446969396245}
{"step": 751104, "time": 23863.739639997482, "episode/length": 121.0, "episode/score": 0.6699179983790202, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.048043010445468326}
{"step": 751144, "time": 23864.7513153553, "episode/length": 118.0, "episode/score": 0.6867891681077936, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.055539158424949164}
{"step": 751592, "time": 23878.539848804474, "episode/length": 90.0, "episode/score": 0.7673169420397414, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.04856695210966677}
{"step": 751672, "time": 23881.01809334755, "episode/length": 81.0, "episode/score": 0.8095025724369407, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.06262759576657118}
{"step": 751712, "time": 23882.465885162354, "episode/length": 101.0, "episode/score": 0.7572872437176841, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.07291226979762655}
{"step": 751800, "time": 23885.046253204346, "episode/length": 81.0, "episode/score": 0.788943561781366, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.04206858511099654}
{"step": 752032, "time": 23892.484436750412, "episode/length": 288.0, "episode/score": 0.07020335708398306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07020335708398306}
{"step": 752120, "time": 23894.98891186714, "episode/length": 126.0, "episode/score": 0.6877374094108291, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.08148742366006445}
{"step": 752256, "time": 23899.371299505234, "episode/length": 82.0, "episode/score": 0.8009969829517161, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.05724700912188041}
{"step": 752272, "time": 23899.88985490799, "episode/length": 288.0, "episode/score": 0.05541314764934668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05541314764934668}
{"step": 752432, "time": 23904.808349132538, "episode/length": 94.0, "episode/score": 0.7905529422681639, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.08430293267554134}
{"step": 752608, "time": 23910.222447633743, "episode/length": 100.0, "episode/score": 0.772363750328509, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.08486372169033984}
{"step": 752712, "time": 23913.19734454155, "episode/length": 288.0, "episode/score": 0.07556119919419757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07556119919419757}
{"step": 752824, "time": 23916.744228363037, "episode/length": 87.0, "episode/score": 0.8001050513712471, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.07198007602801226}
{"step": 753192, "time": 23928.027269363403, "episode/length": 94.0, "episode/score": 0.7559741899594883, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.04972417885346658}
{"step": 753488, "time": 23937.344819307327, "episode/length": 82.0, "episode/score": 0.803278118880371, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.059528144352043455}
{"step": 753568, "time": 23939.82100367546, "episode/length": 119.0, "episode/score": 0.673162815042815, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.045037805450192536}
{"step": 753992, "time": 23953.217718839645, "episode/length": 62.0, "episode/score": 0.8437539775145524, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.03750397271824113}
{"step": 754024, "time": 23954.208654403687, "episode/length": 288.0, "episode/score": 0.11334598334767065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11334598334767065}
{"step": 754112, "time": 23957.156280755997, "episode/length": 67.0, "episode/score": 0.856098605815987, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0654736010196757}
{"step": 754336, "time": 23964.037242650986, "episode/length": 42.0, "episode/score": 0.8887078234611181, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.01995783298389142}
{"step": 754344, "time": 23964.07164311409, "episode/length": 288.0, "episode/score": 0.09881380062552125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09881380062552125}
{"step": 754568, "time": 23970.968298196793, "episode/length": 288.0, "episode/score": 0.12497766303886237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12497766303886237}
{"step": 754584, "time": 23971.464733839035, "episode/length": 288.0, "episode/score": 0.10255453765944367, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10255453765944367}
{"step": 754992, "time": 23984.32369375229, "episode/length": 81.0, "episode/score": 0.8064898941315732, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.059614889696149476}
{"step": 755024, "time": 23985.306604623795, "episode/length": 288.0, "episode/score": 0.09880910460242376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09880910460242376}
{"step": 755360, "time": 23995.647683143616, "episode/length": 98.0, "episode/score": 0.7531502190302035, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.05940017586340218}
{"step": 755504, "time": 24000.089433431625, "episode/length": 288.0, "episode/score": 0.10058692176448858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10058692176448858}
{"step": 755592, "time": 24002.57850265503, "episode/length": 125.0, "episode/score": 0.6736570341954575, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.06428203582527203}
{"step": 755704, "time": 24006.15512943268, "episode/length": 88.0, "episode/score": 0.7855184689651651, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.060518416485138005}
{"step": 756024, "time": 24016.00929927826, "episode/length": 53.0, "episode/score": 0.8771704328778469, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.04279542195808972}
{"step": 756272, "time": 24023.850300312042, "episode/length": 240.0, "episode/score": 0.3527987652473712, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.10279877816947192}
{"step": 756336, "time": 24025.807057142258, "episode/length": 288.0, "episode/score": 0.06605039442456473, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06605039442456473}
{"step": 756392, "time": 24027.31238436699, "episode/length": 110.0, "episode/score": 0.7186246509329521, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.06237465136950959}
{"step": 756424, "time": 24028.298799991608, "episode/length": 288.0, "episode/score": 0.10655183055246198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10655183055246198}
{"step": 756568, "time": 24032.727863550186, "episode/length": 28.0, "episode/score": 0.9458640022064628, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.03336397917951217}
{"step": 756864, "time": 24042.145823955536, "episode/length": 104.0, "episode/score": 0.7462412734294048, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.07124126232338313}
{"step": 757048, "time": 24047.58451986313, "episode/length": 96.0, "episode/score": 0.7802311162490696, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.08023110482872653}
{"step": 757112, "time": 24049.561032533646, "episode/length": 67.0, "episode/score": 0.8470753992955906, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.05645039374257976}
{"step": 757280, "time": 24054.952295064926, "episode/length": 196.0, "episode/score": 0.4167099415251414, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.02920996689204003}
{"step": 757336, "time": 24056.448051452637, "episode/length": 288.0, "episode/score": 0.10775216207707672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10775216207707672}
{"step": 757496, "time": 24061.370141983032, "episode/length": 133.0, "episode/score": 0.6322333743830768, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.04785833622213431}
{"step": 757512, "time": 24061.864966869354, "episode/length": 139.0, "episode/score": 0.6358383379119914, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.07021331167197786}
{"step": 757672, "time": 24066.920217990875, "episode/length": 288.0, "episode/score": 0.08774412159812073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08774412159812073}
{"step": 757744, "time": 24069.357010126114, "episode/length": 57.0, "episode/score": 0.862385693459828, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.04051070298260129}
{"step": 757800, "time": 24070.855523586273, "episode/length": 116.0, "episode/score": 0.6874351987039518, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.04993519129993729}
{"step": 758256, "time": 24085.04924583435, "episode/length": 72.0, "episode/score": 0.8367879593547514, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.06178795985533725}
{"step": 758272, "time": 24085.546159505844, "episode/length": 144.0, "episode/score": 0.6619674361792249, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.1119674371803967}
{"step": 758560, "time": 24094.359754562378, "episode/length": 130.0, "episode/score": 0.6378350860857154, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.044085056690846613}
{"step": 758632, "time": 24096.429005146027, "episode/length": 197.0, "episode/score": 0.46520290765511163, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.08082790210210078}
{"step": 758840, "time": 24102.838850021362, "episode/length": 136.0, "episode/score": 0.6688240985520224, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0938240810780826}
{"step": 759288, "time": 24116.59976887703, "episode/length": 81.0, "episode/score": 0.8081085226256164, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.06123352115878333}
{"step": 759648, "time": 24127.995419979095, "episode/length": 288.0, "episode/score": 0.13169678970211862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13169678970211862}
{"step": 759792, "time": 24132.470784902573, "episode/length": 62.0, "episode/score": 0.8493050673281459, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.04305509198491109}
{"step": 759808, "time": 24132.966856241226, "episode/length": 288.0, "episode/score": 0.10262284260795695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10262284260795695}
{"step": 759952, "time": 24137.39865040779, "episode/length": 211.0, "episode/score": 0.42971925204085437, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.08909424964269874}
{"step": 760032, "time": 24140.653923034668, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 760032, "time": 24141.107202529907, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 760032, "time": 24141.19120001793, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 760032, "time": 24141.227878808975, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 760032, "time": 24141.34062576294, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 760032, "time": 24141.514672994614, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 760032, "time": 24141.889971017838, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 760032, "time": 24142.34374165535, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 760112, "time": 24144.814479589462, "episode/length": 288.0, "episode/score": 0.09370938861195555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09370938861195555}
{"step": 760416, "time": 24154.302528619766, "episode/length": 75.0, "episode/score": 0.8152204523937598, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.049595436037407126}
{"step": 760552, "time": 24158.470577955246, "episode/length": 112.0, "episode/score": 0.7068057635963214, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0568057681132359}
{"step": 760584, "time": 24159.47511458397, "episode/length": 288.0, "episode/score": 0.07296177440525753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07296177440525753}
{"step": 760872, "time": 24168.424352645874, "episode/length": 288.0, "episode/score": 0.09060464251285794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09060464251285794}
{"step": 760896, "time": 24169.384825229645, "episode/length": 137.0, "episode/score": 0.6262168185206747, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.054341842799090045}
{"step": 760952, "time": 24170.90539765358, "episode/length": 104.0, "episode/score": 0.7158804739989364, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0408804625145649}
{"step": 761040, "time": 24173.823585748672, "episode/length": 274.0, "episode/score": 0.2541637633876235, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.11041376677530934}
{"step": 761264, "time": 24180.72975707054, "episode/length": 88.0, "episode/score": 0.7565852796284389, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.03158527994276028}
{"step": 761320, "time": 24182.236163377762, "episode/length": 55.0, "episode/score": 0.8581807092795088, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.030055733435688126}
{"step": 761336, "time": 24182.729467630386, "episode/length": 36.0, "episode/score": 0.9064026396084728, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.018902632204458314}
{"step": 761376, "time": 24184.180802106857, "episode/length": 98.0, "episode/score": 0.7306758845179502, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.03692584728833026}
{"step": 761584, "time": 24190.659026384354, "episode/length": 32.0, "episode/score": 0.9214816903016754, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.021481705965356923}
{"step": 761840, "time": 24198.499895095825, "episode/length": 62.0, "episode/score": 0.8288949968085717, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.02264504896845665}
{"step": 761920, "time": 24201.446219921112, "episode/length": 187.0, "episode/score": 0.48819090305687496, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.07256589145026737}
{"step": 762040, "time": 24204.917726039886, "episode/length": 82.0, "episode/score": 0.8114646306178201, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.06771463513473464}
{"step": 762128, "time": 24207.82165145874, "episode/length": 146.0, "episode/score": 0.6252150096701143, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.08146504990907033}
{"step": 762240, "time": 24211.272679567337, "episode/length": 81.0, "episode/score": 0.784082854033386, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.03720786639087237}
{"step": 762264, "time": 24211.799008131027, "episode/length": 288.0, "episode/score": 0.09167344018771928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09167344018771928}
{"step": 762456, "time": 24217.811851263046, "episode/length": 23.0, "episode/score": 0.9461692967196313, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.018044273314330894}
{"step": 762528, "time": 24220.26036119461, "episode/length": 157.0, "episode/score": 0.5764914751460992, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.06711649080978077}
{"step": 762536, "time": 24220.293745040894, "episode/length": 61.0, "episode/score": 0.8364515415051983, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.027076581744154282}
{"step": 762736, "time": 24226.66623544693, "episode/length": 75.0, "episode/score": 0.8126300587493915, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.047005082905570816}
{"step": 762816, "time": 24229.12274670601, "episode/length": 111.0, "episode/score": 0.6775385446409246, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.024413559937897844}
{"step": 763081, "time": 24238.031732797623, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1092756261777637, "train/action_min": 0.0, "train/action_std": 1.6616365789768084, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011271443859154556, "train/actor_opt_grad_steps": 46600.0, "train/actor_opt_loss": -8.42278004111956, "train/adv_mag": 0.9911641277859559, "train/adv_max": 0.322312123212383, "train/adv_mean": 0.001481487511369577, "train/adv_min": -0.9603700158584058, "train/adv_std": 0.03393093049385814, "train/cont_avg": 0.995774772298995, "train/cont_loss_mean": 0.015145312070415997, "train/cont_loss_std": 0.22193293556121726, "train/cont_neg_acc": 0.3347005460298423, "train/cont_neg_loss": 2.857111143684391, "train/cont_pos_acc": 0.9998225989054196, "train/cont_pos_loss": 0.003139264138073815, "train/cont_pred": 0.99562706779595, "train/cont_rate": 0.995774772298995, "train/dyn_loss_mean": 1.0000004804314082, "train/dyn_loss_std": 1.5365998798878348e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.26571409211461267, "train/extr_critic_critic_opt_grad_steps": 46600.0, "train/extr_critic_critic_opt_loss": 3535.6321966276696, "train/extr_critic_mag": 1.269046638479185, "train/extr_critic_max": 1.269046638479185, "train/extr_critic_mean": 1.2004850713451902, "train/extr_critic_min": 1.056584237807959, "train/extr_critic_std": 0.015710216464858557, "train/extr_return_normed_mag": 0.9831936796705927, "train/extr_return_normed_max": 0.3330412635851146, "train/extr_return_normed_mean": 0.03044398204334567, "train/extr_return_normed_min": -0.9425556701631402, "train/extr_return_normed_std": 0.03851878273314867, "train/extr_return_rate": 0.9990650325564284, "train/extr_return_raw_mag": 1.5045637874747042, "train/extr_return_raw_max": 1.5045637874747042, "train/extr_return_raw_mean": 1.201966570250353, "train/extr_return_raw_min": 0.22896685372644932, "train/extr_return_raw_std": 0.038518782634868395, "train/extr_reward_mag": 0.3513472906908198, "train/extr_reward_max": 0.3513472906908198, "train/extr_reward_mean": 0.0024025799500657684, "train/extr_reward_min": 5.583667275893629e-06, "train/extr_reward_std": 0.009945672742517, "train/image_loss_mean": 0.10612571385487839, "train/image_loss_std": 0.11817338864258187, "train/model_loss_mean": 0.745658280262396, "train/model_loss_std": 0.38346523930079973, "train/model_opt_grad_norm": 19.34515246674044, "train/model_opt_grad_steps": 46558.39698492462, "train/model_opt_loss": 4031.457280297974, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5402.010050251256, "train/policy_entropy_mag": 1.3159025182676076, "train/policy_entropy_max": 1.3159025182676076, "train/policy_entropy_mean": 0.11129550830503206, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.14577495898283907, "train/policy_logprob_mag": 6.551080253256027, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1115750056789748, "train/policy_logprob_min": -6.551080253256027, "train/policy_logprob_std": 0.6490539237482464, "train/policy_randomness_mag": 0.6762401629332921, "train/policy_randomness_max": 0.6762401629332921, "train/policy_randomness_mean": 0.05719457978579267, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0749135146001775, "train/post_ent_mag": 2.9222418495159053, "train/post_ent_max": 2.9222418495159053, "train/post_ent_mean": 2.912359696536807, "train/post_ent_min": 2.9062481405746996, "train/post_ent_std": 0.003536794850621466, "train/prior_ent_mag": 3.298199513449741, "train/prior_ent_max": 3.298199513449741, "train/prior_ent_mean": 2.8229502481431816, "train/prior_ent_min": 2.8118003037706694, "train/prior_ent_std": 0.025763342580547435, "train/rep_loss_mean": 1.0000004804314082, "train/rep_loss_std": 1.5365998798878348e-05, "train/reward_avg": 0.0013827239790634163, "train/reward_loss_mean": 0.02438694103410346, "train/reward_loss_std": 0.1577854910444225, "train/reward_max_data": 0.5888786347461256, "train/reward_max_pred": 0.15388493382152002, "train/reward_neg_acc": 0.9998083066700691, "train/reward_neg_loss": 0.01790470288289552, "train/reward_pos_acc": 0.17638036892092301, "train/reward_pos_loss": 4.3850983352017545, "train/reward_pred": 0.0011556298710667908, "train/reward_rate": 0.0015016488693467337, "train_stats/mean_log_entropy": 0.09017133661028412, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.0156859178096056, "report/cont_loss_std": 0.23783865571022034, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.1549530029296875, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0030772702302783728, "report/cont_pred": 0.9940498471260071, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07637711614370346, "report/image_loss_std": 0.08103752881288528, "report/model_loss_mean": 0.7214015126228333, "report/model_loss_std": 0.454761803150177, "report/post_ent_mag": 2.9114527702331543, "report/post_ent_max": 2.9114527702331543, "report/post_ent_mean": 2.9027724266052246, "report/post_ent_min": 2.8977208137512207, "report/post_ent_std": 0.002938422840088606, "report/prior_ent_mag": 2.9507036209106445, "report/prior_ent_max": 2.9507036209106445, "report/prior_ent_mean": 2.819004535675049, "report/prior_ent_min": 2.81174373626709, "report/prior_ent_std": 0.010538188740611076, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0018047839403152466, "report/reward_loss_mean": 0.029338452965021133, "report/reward_loss_std": 0.23358990252017975, "report/reward_max_data": 0.8447499871253967, "report/reward_max_pred": 0.4938758611679077, "report/reward_neg_acc": 0.999020516872406, "report/reward_neg_loss": 0.01777278445661068, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.9655208587646484, "report/reward_pred": 0.0019852877594530582, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.03864135220646858, "eval/cont_loss_std": 0.536586344242096, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.410855293273926, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0024675866588950157, "eval/cont_pred": 0.9975881576538086, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20090419054031372, "eval/image_loss_std": 0.13171182572841644, "eval/model_loss_mean": 0.8430954217910767, "eval/model_loss_std": 0.560640275478363, "eval/post_ent_mag": 2.9116907119750977, "eval/post_ent_max": 2.9116907119750977, "eval/post_ent_mean": 2.903848171234131, "eval/post_ent_min": 2.897758722305298, "eval/post_ent_std": 0.0038760467432439327, "eval/prior_ent_mag": 2.8806915283203125, "eval/prior_ent_max": 2.8806915283203125, "eval/prior_ent_mean": 2.8200888633728027, "eval/prior_ent_min": 2.8118185997009277, "eval/prior_ent_std": 0.010455158539116383, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.003549877554178238, "eval/reward_loss_std": 0.0031482402700930834, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.021485090255737305, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.003549877554178238, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0006398227997124195, "eval/reward_rate": 0.0, "replay/size": 762577.0, "replay/inserts": 31872.0, "replay/samples": 31872.0, "replay/insert_wait_avg": 1.1775807204495472e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.604005705400643e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5176.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0565314816175693e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3262033462524414e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.013913154602, "timer/env.step_count": 3984.0, "timer/env.step_total": 34.11858248710632, "timer/env.step_frac": 0.03411810779659782, "timer/env.step_avg": 0.008563901226683313, "timer/env.step_min": 0.007220268249511719, "timer/env.step_max": 0.03873848915100098, "timer/replay._sample_count": 31872.0, "timer/replay._sample_total": 15.728795289993286, "timer/replay._sample_frac": 0.015728576455877386, "timer/replay._sample_avg": 0.0004934988482051106, "timer/replay._sample_min": 0.0003895759582519531, "timer/replay._sample_max": 0.01098942756652832, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4631.0, "timer/agent.policy_total": 39.086787939071655, "timer/agent.policy_frac": 0.03908624412611431, "timer/agent.policy_avg": 0.008440247881466563, "timer/agent.policy_min": 0.007424592971801758, "timer/agent.policy_max": 0.08057022094726562, "timer/dataset_train_count": 1992.0, "timer/dataset_train_total": 0.20793628692626953, "timer/dataset_train_frac": 0.00020793339391681303, "timer/dataset_train_avg": 0.00010438568620796663, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.00025153160095214844, "timer/agent.train_count": 1992.0, "timer/agent.train_total": 881.2855236530304, "timer/agent.train_frac": 0.8812732623618845, "timer/agent.train_avg": 0.44241241147240484, "timer/agent.train_min": 0.43320488929748535, "timer/agent.train_max": 0.5973153114318848, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4785442352294922, "timer/agent.report_frac": 0.00047853757726219683, "timer/agent.report_avg": 0.2392721176147461, "timer/agent.report_min": 0.23396730422973633, "timer/agent.report_max": 0.24457693099975586, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4809112548828125e-05, "timer/dataset_eval_frac": 3.480862825100178e-08, "timer/dataset_eval_avg": 3.4809112548828125e-05, "timer/dataset_eval_min": 3.4809112548828125e-05, "timer/dataset_eval_max": 3.4809112548828125e-05, "fps": 31.87089830730868}
{"step": 763096, "time": 24238.095852851868, "episode/length": 70.0, "episode/score": 0.80897058019616, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.027720583572204305}
{"step": 763208, "time": 24241.930477380753, "episode/length": 288.0, "episode/score": 0.06180789018117139, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06180789018117139}
{"step": 763240, "time": 24242.922179460526, "episode/length": 97.0, "episode/score": 0.7364464393369872, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.03957143785851258}
{"step": 763800, "time": 24260.50848698616, "episode/length": 157.0, "episode/score": 0.6053976173193405, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.09602264453724274}
{"step": 763832, "time": 24261.49820113182, "episode/length": 77.0, "episode/score": 0.809172409065809, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.04979745103935329}
{"step": 763936, "time": 24264.901362895966, "episode/length": 139.0, "episode/score": 0.6052496787496011, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.039624695146699196}
{"step": 764152, "time": 24271.369071483612, "episode/length": 288.0, "episode/score": 0.08081705329271927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08081705329271927}
{"step": 764544, "time": 24283.73220562935, "episode/length": 88.0, "episode/score": 0.7990626282272615, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.07406260601521808}
{"step": 764552, "time": 24283.76514673233, "episode/length": 288.0, "episode/score": 0.06898420285352813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06898420285352813}
{"step": 764656, "time": 24287.18038868904, "episode/length": 62.0, "episode/score": 0.8610825319192372, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.05483255808940157}
{"step": 765048, "time": 24298.980399608612, "episode/length": 288.0, "episode/score": 0.1006832905286501, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1006832905286501}
{"step": 765192, "time": 24303.42052435875, "episode/length": 156.0, "episode/score": 0.5811230010206145, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.06862298430337432}
{"step": 765408, "time": 24310.50724720955, "episode/length": 288.0, "episode/score": 0.07145108726609806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07145108726609806}
{"step": 765464, "time": 24312.044809103012, "episode/length": 113.0, "episode/score": 0.6849601700314452, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0380851470044945}
{"step": 765552, "time": 24315.04890727997, "episode/length": 288.0, "episode/score": 0.10439574310811395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10439574310811395}
{"step": 765672, "time": 24318.57878780365, "episode/length": 126.0, "episode/score": 0.6677399926602448, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.06149000621098821}
{"step": 765848, "time": 24324.0288772583, "episode/length": 81.0, "episode/score": 0.788626551807738, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.04175156535848146}
{"step": 765904, "time": 24325.992367506027, "episode/length": 106.0, "episode/score": 0.746640026346995, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.07789000962975479}
{"step": 766024, "time": 24329.45828652382, "episode/length": 76.0, "episode/score": 0.8154317043977244, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.052931729240754066}
{"step": 766112, "time": 24332.401575803757, "episode/length": 288.0, "episode/score": 0.06181791920135993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06181791920135993}
{"step": 766408, "time": 24341.417605638504, "episode/length": 106.0, "episode/score": 0.7355761793196507, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.06682619287039415}
{"step": 766512, "time": 24344.8592004776, "episode/length": 75.0, "episode/score": 0.8194507363468801, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.05382570770871098}
{"step": 766720, "time": 24351.269055604935, "episode/length": 108.0, "episode/score": 0.6925809552567443, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.030080912089943013}
{"step": 766776, "time": 24352.77753329277, "episode/length": 32.0, "episode/score": 0.9116373098413533, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.011637334119768639}
{"step": 766856, "time": 24355.263332366943, "episode/length": 288.0, "episode/score": 0.06047828507735176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06047828507735176}
{"step": 767048, "time": 24361.18061351776, "episode/length": 33.0, "episode/score": 0.9182506167203428, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.02137557855940031}
{"step": 767136, "time": 24364.100739717484, "episode/length": 138.0, "episode/score": 0.6147583644401493, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.04600834141319865}
{"step": 767144, "time": 24364.134427547455, "episode/length": 209.0, "episode/score": 0.403369938474043, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.05649491223402947}
{"step": 767240, "time": 24367.224794387817, "episode/length": 140.0, "episode/score": 0.6380749548429776, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.07557495647279211}
{"step": 767312, "time": 24369.687767267227, "episode/length": 112.0, "episode/score": 0.7008201817948247, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.050820207266497164}
{"step": 767368, "time": 24371.18922686577, "episode/length": 211.0, "episode/score": 0.43034487136856114, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.08971988445364332}
{"step": 767544, "time": 24376.618858337402, "episode/length": 49.0, "episode/score": 0.86798446319699, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.02110942263789184}
{"step": 767592, "time": 24378.097502946854, "episode/length": 56.0, "episode/score": 0.8632213810669782, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.038221364349737996}
{"step": 767848, "time": 24386.004880666733, "episode/length": 123.0, "episode/score": 0.6658244750242375, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.05019942254421039}
{"step": 767912, "time": 24387.97619152069, "episode/length": 148.0, "episode/score": 0.5956182251266, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.05811820209964935}
{"step": 767944, "time": 24388.964844226837, "episode/length": 78.0, "episode/score": 0.8065913207365156, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.05034129852447222}
{"step": 768064, "time": 24392.892866373062, "episode/length": 18.0, "episode/score": 0.95544999446156, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.011699954263349355}
{"step": 768080, "time": 24393.391905784607, "episode/length": 88.0, "episode/score": 0.7808218707441483, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.05582185982439114}
{"step": 768104, "time": 24393.913262844086, "episode/length": 131.0, "episode/score": 0.6842100632063648, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.09358505877094103}
{"step": 768248, "time": 24398.4580013752, "episode/length": 81.0, "episode/score": 0.7895028705329423, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.04262786609751856}
{"step": 768256, "time": 24398.9304895401, "episode/length": 18.0, "episode/score": 0.9540624569563079, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.010312433551007416}
{"step": 768560, "time": 24408.31003856659, "episode/length": 88.0, "episode/score": 0.7408264627301833, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.01582642253197264}
{"step": 768688, "time": 24412.27002763748, "episode/length": 75.0, "episode/score": 0.7960234395673069, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.030398440382214176}
{"step": 768720, "time": 24413.26984000206, "episode/length": 96.0, "episode/score": 0.7416978318378824, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.041697829439726775}
{"step": 768736, "time": 24413.770034074783, "episode/length": 59.0, "episode/score": 0.8495592813158055, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.03393425303852382}
{"step": 769008, "time": 24422.18384695053, "episode/length": 33.0, "episode/score": 0.9146758971251074, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.017800874098156783}
{"step": 769200, "time": 24428.219361782074, "episode/length": 63.0, "episode/score": 0.8320127098927514, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.028887666725950112}
{"step": 769216, "time": 24428.717243909836, "episode/length": 120.0, "episode/score": 0.6857661271069446, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0607661037656726}
{"step": 769368, "time": 24433.21662569046, "episode/length": 80.0, "episode/score": 0.7853298633028771, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0353298399616051}
{"step": 769496, "time": 24437.178537368774, "episode/length": 116.0, "episode/score": 0.6885731283482528, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.051073140705739206}
{"step": 769552, "time": 24439.147244930267, "episode/length": 288.0, "episode/score": 0.06685051438580558, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06685051438580558}
{"step": 769712, "time": 24444.091797351837, "episode/length": 87.0, "episode/score": 0.7585069211836526, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.03038193070642592}
{"step": 769808, "time": 24447.040813446045, "episode/length": 54.0, "episode/score": 0.8518848120547773, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.020634776792576304}
{"step": 769856, "time": 24448.524993658066, "episode/length": 288.0, "episode/score": 0.08260938481180347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08260938481180347}
{"step": 770016, "time": 24453.862344026566, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 770016, "time": 24454.17840027809, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 770016, "time": 24454.758293628693, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 770016, "time": 24455.159640312195, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 770016, "time": 24455.46076774597, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 770016, "time": 24456.3227994442, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 770016, "time": 24457.12150669098, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 770016, "time": 24457.76053762436, "eval_episode/length": 199.0, "eval_episode/score": 0.37812501192092896, "eval_episode/reward_rate": 0.005}
{"step": 770016, "time": 24457.766275405884, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 770256, "time": 24465.73371553421, "episode/length": 55.0, "episode/score": 0.8544157315200209, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.02629074444212165}
{"step": 770376, "time": 24469.221824645996, "episode/length": 288.0, "episode/score": 0.09202627009040043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09202627009040043}
{"step": 770512, "time": 24473.621762514114, "episode/length": 99.0, "episode/score": 0.7670406001370793, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.07641559054445679}
{"step": 770688, "time": 24479.030307531357, "episode/length": 141.0, "episode/score": 0.5999733704875325, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.04059838322336873}
{"step": 770768, "time": 24481.478481531143, "episode/length": 63.0, "episode/score": 0.8374866950089199, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.034361684089162736}
{"step": 771016, "time": 24488.993089675903, "episode/length": 30.0, "episode/score": 0.9216023051503726, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.015352318072473281}
{"step": 771080, "time": 24490.963901281357, "episode/length": 87.0, "episode/score": 0.7651067227566273, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0369817322794006}
{"step": 771512, "time": 24504.277296066284, "episode/length": 288.0, "episode/score": 0.030853763149025326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030853763149025326}
{"step": 771528, "time": 24504.799475431442, "episode/length": 288.0, "episode/score": 0.08070088663157549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08070088663157549}
{"step": 771600, "time": 24507.24275493622, "episode/length": 72.0, "episode/score": 0.8010897991871389, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.026089799687724735}
{"step": 771720, "time": 24510.728341817856, "episode/length": 277.0, "episode/score": 0.21881273710732785, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0844377291678029}
{"step": 772168, "time": 24524.663747787476, "episode/length": 288.0, "episode/score": 0.0640869071578436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0640869071578436}
{"step": 772176, "time": 24525.135410308838, "episode/length": 80.0, "episode/score": 0.7778847697252331, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.02788477054014038}
{"step": 772200, "time": 24525.658019542694, "episode/length": 139.0, "episode/score": 0.6060674307520912, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.04044242046097679}
{"step": 772208, "time": 24526.13470673561, "episode/length": 86.0, "episode/score": 0.7737946606830519, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.042544673418888124}
{"step": 772664, "time": 24539.98363518715, "episode/length": 132.0, "episode/score": 0.6524604221935988, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.06496045895755742}
{"step": 772824, "time": 24545.000211000443, "episode/length": 288.0, "episode/score": 0.021274308269539688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021274308269539688}
{"step": 772872, "time": 24546.50213766098, "episode/length": 87.0, "episode/score": 0.7575766845075123, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.029451709164277418}
{"step": 772912, "time": 24547.97899746895, "episode/length": 148.0, "episode/score": 0.5970022474552934, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.05950223653553621}
{"step": 773000, "time": 24550.47118115425, "episode/length": 288.0, "episode/score": 0.07929318144533681, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07929318144533681}
{"step": 773464, "time": 24564.775964975357, "episode/length": 99.0, "episode/score": 0.7217085429901999, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.03108350772799895}
{"step": 773496, "time": 24565.76237654686, "episode/length": 160.0, "episode/score": 0.5429938648094321, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.042993836171262956}
{"step": 773616, "time": 24569.673182487488, "episode/length": 98.0, "episode/score": 0.7262866659189058, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.03253664251360533}
{"step": 773648, "time": 24570.659665346146, "episode/length": 96.0, "episode/score": 0.7349252431449713, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.034925255880807526}
{"step": 774128, "time": 24585.544058799744, "episode/length": 140.0, "episode/score": 0.6114911515314816, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.048991152346388844}
{"step": 774160, "time": 24586.528624534607, "episode/length": 67.0, "episode/score": 0.8091877381741597, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.01856276283092484}
{"step": 774224, "time": 24588.50874900818, "episode/length": 90.0, "episode/score": 0.766566752582321, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.04781676550442171}
{"step": 774488, "time": 24596.407380580902, "episode/length": 288.0, "episode/score": 0.02164939023464285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02164939023464285}
{"step": 774512, "time": 24597.39276123047, "episode/length": 288.0, "episode/score": 0.018556677868218685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018556677868218685}
{"step": 774968, "time": 24611.32816720009, "episode/length": 104.0, "episode/score": 0.7076563429679936, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.032656331483622125}
{"step": 775040, "time": 24613.77551674843, "episode/length": 101.0, "episode/score": 0.7212077242650139, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.036832721866858265}
{"step": 775224, "time": 24619.23460483551, "episode/length": 288.0, "episode/score": 0.0370474539136012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0370474539136012}
{"step": 775400, "time": 24624.649557352066, "episode/length": 44.0, "episode/score": 0.8803577144310566, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.017857688191043053}
{"step": 775504, "time": 24628.08795595169, "episode/length": 123.0, "episode/score": 0.6519636389300558, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.03633859576325449}
{"step": 775616, "time": 24631.522100925446, "episode/length": 80.0, "episode/score": 0.7822840003635747, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.03228398103863128}
{"step": 775776, "time": 24636.539717674255, "episode/length": 288.0, "episode/score": 0.0775220887537671, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0775220887537671}
{"step": 775960, "time": 24642.045219421387, "episode/length": 288.0, "episode/score": 0.053301133047284566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053301133047284566}
{"step": 776064, "time": 24645.462503910065, "episode/length": 82.0, "episode/score": 0.7801880953541058, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.03643811963252119}
{"step": 776472, "time": 24657.821910619736, "episode/length": 288.0, "episode/score": 0.061349727200308735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061349727200308735}
{"step": 776800, "time": 24668.24536371231, "episode/length": 288.0, "episode/score": 0.08014894253119564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08014894253119564}
{"step": 777184, "time": 24680.066022634506, "episode/length": 47.0, "episode/score": 0.8924558424223505, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.03933085287644644}
{"step": 777328, "time": 24684.518993854523, "episode/length": 227.0, "episode/score": 0.3858760816544873, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.09525107610147643}
{"step": 777328, "time": 24684.526970386505, "episode/length": 170.0, "episode/score": 0.557344039390955, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.08859403982751246}
{"step": 777480, "time": 24688.992896556854, "episode/length": 212.0, "episode/score": 0.425688432125753, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.088188426601846}
{"step": 777536, "time": 24690.936121940613, "episode/length": 288.0, "episode/score": 0.08446203407777375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08446203407777375}
{"step": 777648, "time": 24694.411134004593, "episode/length": 253.0, "episode/score": 0.30021775548016194, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.09084276790167678}
{"step": 778376, "time": 24717.12375020981, "episode/length": 288.0, "episode/score": 0.07650291629533967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07650291629533967}
{"step": 778600, "time": 24724.081737041473, "episode/length": 118.0, "episode/score": 0.681881183734049, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.05063115171401478}
{"step": 778696, "time": 24727.250688552856, "episode/length": 144.0, "episode/score": 0.5829460434349585, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.032946024354487236}
{"step": 778784, "time": 24730.226910352707, "episode/length": 288.0, "episode/score": 0.08015226056181746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08015226056181746}
{"step": 778848, "time": 24732.247742414474, "episode/length": 30.0, "episode/score": 0.9151950159827038, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.008945040138883087}
{"step": 779496, "time": 24752.089029550552, "episode/length": 288.0, "episode/score": 0.10245023979848611, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10245023979848611}
{"step": 779528, "time": 24753.076666116714, "episode/length": 103.0, "episode/score": 0.7163337346300978, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.03820870261006348}
{"step": 779640, "time": 24756.653549194336, "episode/length": 288.0, "episode/score": 0.057048063301863294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057048063301863294}
{"step": 779640, "time": 24756.66052007675, "episode/length": 288.0, "episode/score": 0.036800935103769916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036800935103769916}
{"step": 779664, "time": 24757.71032357216, "episode/length": 101.0, "episode/score": 0.7380422306670198, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.05366723542840646}
{"step": 779792, "time": 24761.659618139267, "episode/length": 288.0, "episode/score": 0.08297507271640825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08297507271640825}
{"step": 780000, "time": 24768.36734032631, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 780000, "time": 24768.529403686523, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 780000, "time": 24769.067469358444, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 780000, "time": 24769.633523225784, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 780000, "time": 24770.027975559235, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 780000, "time": 24770.486181735992, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 780000, "time": 24770.882911920547, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 780000, "time": 24770.951251268387, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 780632, "time": 24790.298455953598, "episode/length": 281.0, "episode/score": 0.21213041264331878, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.09025541146752403}
{"step": 780720, "time": 24793.218421459198, "episode/length": 148.0, "episode/score": 0.5981382356100085, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.060638215144194874}
{"step": 780928, "time": 24799.645503282547, "episode/length": 160.0, "episode/score": 0.5708696213359872, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.07086960794822517}
{"step": 781096, "time": 24804.60256099701, "episode/length": 288.0, "episode/score": 0.1085098692764177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1085098692764177}
{"step": 781520, "time": 24817.98912715912, "episode/length": 252.0, "episode/score": 0.31162022291618996, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.09912021739228294}
{"step": 781880, "time": 24828.874606609344, "episode/length": 118.0, "episode/score": 0.7032895974601274, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.07203955929918493}
{"step": 781952, "time": 24831.30852818489, "episode/length": 288.0, "episode/score": 0.1671417857603501, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.06714178456127229}
{"step": 781960, "time": 24831.343060016632, "episode/length": 286.0, "episode/score": 0.17694523762804693, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.07069523616121387}
{"step": 782104, "time": 24835.787069797516, "episode/length": 288.0, "episode/score": 0.07198385634910665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07198385634910665}
{"step": 782248, "time": 24840.23086667061, "episode/length": 190.0, "episode/score": 0.4923377489798213, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.08608773931734959}
{"step": 782360, "time": 24843.70780491829, "episode/length": 215.0, "episode/score": 0.4373537301402166, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.1092287346222065}
{"step": 782784, "time": 24857.07056951523, "episode/length": 112.0, "episode/score": 0.7131924945774131, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.06319254257545026}
{"step": 783096, "time": 24866.475417613983, "episode/length": 105.0, "episode/score": 0.7187220974327602, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.04684707409148814}
{"step": 783184, "time": 24869.470091581345, "episode/length": 152.0, "episode/score": 0.5983360088778795, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.07333600332486867}
{"step": 783408, "time": 24876.543013334274, "episode/length": 288.0, "episode/score": 0.08382177756305964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08382177756305964}
{"step": 783832, "time": 24889.416237831116, "episode/length": 288.0, "episode/score": 0.04516225086024406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04516225086024406}
{"step": 783968, "time": 24893.83105111122, "episode/length": 69.0, "episode/score": 0.8196317330628631, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0352567392736205}
{"step": 784264, "time": 24902.737510204315, "episode/length": 288.0, "episode/score": 0.13786419243376713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13786419243376713}
{"step": 784304, "time": 24904.211408138275, "episode/length": 150.0, "episode/score": 0.5629933730668881, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.03174338817177613}
{"step": 784416, "time": 24907.7765147686, "episode/length": 288.0, "episode/score": 0.13847993931682367, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13847993931682367}
{"step": 784464, "time": 24909.27798461914, "episode/length": 209.0, "episode/score": 0.438704568545802, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.09182954946533073}
{"step": 784592, "time": 24913.240008831024, "episode/length": 175.0, "episode/score": 0.4872822150389311, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.034157203368295086}
{"step": 784672, "time": 24915.69657278061, "episode/length": 288.0, "episode/score": 0.08268785188687389, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08268785188687389}
{"step": 784824, "time": 24920.1746237278, "episode/length": 50.0, "episode/score": 0.8534757438591782, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.009725758964066245}
{"step": 784904, "time": 24922.645549058914, "episode/length": 133.0, "episode/score": 0.6426797339951804, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.058304733261763886}
{"step": 785200, "time": 24931.9766497612, "episode/length": 116.0, "episode/score": 0.6629691488660683, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.02546913546666474}
{"step": 785392, "time": 24938.00930404663, "episode/length": 89.0, "episode/score": 0.7509370086506806, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.029062011834639634}
{"step": 785544, "time": 24942.465416669846, "episode/length": 196.0, "episode/score": 0.47016993534009544, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.08266993759855268}
{"step": 785632, "time": 24945.411719322205, "episode/length": 90.0, "episode/score": 0.7448994482405737, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.02614946637226012}
{"step": 786120, "time": 24960.226498126984, "episode/length": 60.0, "episode/score": 0.8373463145753135, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.024846289254981002}
{"step": 786208, "time": 24963.166437625885, "episode/length": 101.0, "episode/score": 0.6999988753573234, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.015623902383140376}
{"step": 786240, "time": 24964.155519247055, "episode/length": 129.0, "episode/score": 0.6543269806160765, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.05745199285132685}
{"step": 786616, "time": 24976.101680755615, "episode/length": 288.0, "episode/score": 0.0595567110225943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0595567110225943}
{"step": 786776, "time": 24981.05531668663, "episode/length": 288.0, "episode/score": 0.05855277516559454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05855277516559454}
{"step": 786904, "time": 24985.058885335922, "episode/length": 288.0, "episode/score": 0.053996705069494055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053996705069494055}
{"step": 787000, "time": 24988.07337999344, "episode/length": 98.0, "episode/score": 0.7133370927995202, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.019587081035751908}
{"step": 787136, "time": 24992.541844844818, "episode/length": 288.0, "episode/score": 0.044971161912030766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044971161912030766}
{"step": 787856, "time": 25015.23620223999, "episode/length": 288.0, "episode/score": 0.05239324118002742, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05239324118002742}
{"step": 788064, "time": 25021.713389396667, "episode/length": 242.0, "episode/score": 0.3000167558336102, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.05626675324919006}
{"step": 788160, "time": 25024.691200733185, "episode/length": 144.0, "episode/score": 0.5952414687457122, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.045241476964633875}
{"step": 788248, "time": 25027.278470993042, "episode/length": 138.0, "episode/score": 0.6156739908005306, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.04692397033471707}
{"step": 788400, "time": 25032.172141075134, "episode/length": 186.0, "episode/score": 0.44830623017350035, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.029556242312708036}
{"step": 788464, "time": 25034.162436246872, "episode/length": 49.0, "episode/score": 0.8679824114652774, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.021107425766899723}
{"step": 788544, "time": 25036.620491743088, "episode/length": 36.0, "episode/score": 0.893439722523226, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0059397262659786065}
{"step": 788552, "time": 25036.65351510048, "episode/length": 288.0, "episode/score": 0.04110568293179995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04110568293179995}
{"step": 788928, "time": 25048.4840798378, "episode/length": 288.0, "episode/score": 0.021199720491949847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021199720491949847}
{"step": 789088, "time": 25053.401773929596, "episode/length": 288.0, "episode/score": 0.05999655326888842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05999655326888842}
{"step": 789112, "time": 25053.923169851303, "episode/length": 70.0, "episode/score": 0.801396041254975, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.020146034095432697}
{"step": 789472, "time": 25065.30960893631, "episode/length": 163.0, "episode/score": 0.5210714639134153, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.030446463179998773}
{"step": 789632, "time": 25070.231879472733, "episode/length": 87.0, "episode/score": 0.7649139359355672, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.036788955688336955}
{"step": 789664, "time": 25071.223973989487, "episode/length": 68.0, "episode/score": 0.8092918539717289, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.02179184329935424}
{"step": 790088, "time": 25084.65949320793, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 790088, "time": 25084.942389011383, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 790088, "time": 25085.182150125504, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 790088, "time": 25085.57685303688, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 790088, "time": 25085.70870947838, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 790088, "time": 25086.06238913536, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 790088, "time": 25086.592680454254, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 790088, "time": 25087.174868106842, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 790168, "time": 25089.63046526909, "episode/length": 288.0, "episode/score": 0.02883637950156981, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02883637950156981}
{"step": 790712, "time": 25106.380269527435, "episode/length": 288.0, "episode/score": 0.026746050001520416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026746050001520416}
{"step": 790776, "time": 25108.345593690872, "episode/length": 288.0, "episode/score": 0.03715406205117233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03715406205117233}
{"step": 790864, "time": 25111.290879249573, "episode/length": 288.0, "episode/score": 0.04764685949152181, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04764685949152181}
{"step": 791016, "time": 25115.857875823975, "episode/length": 105.0, "episode/score": 0.709840717466875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.03796571337778687}
{"step": 791136, "time": 25119.754526615143, "episode/length": 33.0, "episode/score": 0.905191564295194, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.008316540671614803}
{"step": 791160, "time": 25120.29779982567, "episode/length": 210.0, "episode/score": 0.38031844342833665, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.03656842873090227}
{"step": 791288, "time": 25124.229803323746, "episode/length": 63.0, "episode/score": 0.8422967186141364, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.03917169493234951}
{"step": 791400, "time": 25127.685037136078, "episode/length": 288.0, "episode/score": 0.04874738199259809, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04874738199259809}
{"step": 791416, "time": 25128.183730840683, "episode/length": 87.0, "episode/score": 0.7637454738085694, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.03562052075886868}
{"step": 791640, "time": 25135.091358184814, "episode/length": 59.0, "episode/score": 0.8326334523255241, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.01700844378063948}
{"step": 791672, "time": 25136.083689928055, "episode/length": 33.0, "episode/score": 0.9220022548284419, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.02512724306467362}
{"step": 791704, "time": 25137.077780485153, "episode/length": 85.0, "episode/score": 0.7727144068816187, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.03833940704168981}
{"step": 791880, "time": 25142.501972436905, "episode/length": 73.0, "episode/score": 0.7981477039322158, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.026272683466402214}
{"step": 791944, "time": 25144.47465157509, "episode/length": 288.0, "episode/score": 0.019169319691911824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019169319691911824}
{"step": 791976, "time": 25145.578308582306, "episode/length": 288.0, "episode/score": 0.03161578967984724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03161578967984724}
{"step": 792200, "time": 25152.479024887085, "episode/length": 132.0, "episode/score": 0.6192551570591718, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.03175518106110076}
{"step": 792328, "time": 25156.435519218445, "episode/length": 113.0, "episode/score": 0.6657856637383475, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.018910651974579196}
{"step": 792344, "time": 25156.93663072586, "episode/length": 49.0, "episode/score": 0.8583641142501506, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.011489128551772865}
{"step": 792480, "time": 25161.37859225273, "episode/length": 34.0, "episode/score": 0.9131104266153329, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.01936038658010375}
{"step": 792536, "time": 25162.914011716843, "episode/length": 69.0, "episode/score": 0.7955459160440341, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.011170927231546557}
{"step": 792536, "time": 25162.921758174896, "episode/length": 111.0, "episode/score": 0.6934338840158034, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.04030890600665771}
{"step": 792672, "time": 25167.353219270706, "episode/length": 98.0, "episode/score": 0.7173650442503003, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.02361503047836777}
{"step": 792976, "time": 25176.976021528244, "episode/length": 78.0, "episode/score": 0.799185934612126, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.04293591414631237}
{"step": 793368, "time": 25188.859422922134, "episode/length": 86.0, "episode/score": 0.7485733932131211, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.017323408510094396}
{"step": 793440, "time": 25191.312729120255, "episode/length": 112.0, "episode/score": 0.6821218091853609, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.03212182855978085}
{"step": 793520, "time": 25193.76513195038, "episode/length": 67.0, "episode/score": 0.8053710566873917, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.014746074082751193}
{"step": 793648, "time": 25197.714729309082, "episode/length": 145.0, "episode/score": 0.5833053821308738, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.03643039220079913}
{"step": 793920, "time": 25206.203719854355, "episode/length": 68.0, "episode/score": 0.8048416657073858, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.01734164208380662}
{"step": 793984, "time": 25208.169505119324, "episode/length": 288.0, "episode/score": 0.04360605379255844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04360605379255844}
{"step": 794016, "time": 25209.159640789032, "episode/length": 288.0, "episode/score": 0.053770792090659825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053770792090659825}
{"step": 794312, "time": 25218.067109823227, "episode/length": 82.0, "episode/score": 0.7637331938356624, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.01998321123102187}
{"step": 794528, "time": 25225.06140422821, "episode/length": 125.0, "episode/score": 0.6296106348899002, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.020235635035419364}
{"step": 794640, "time": 25229.059806585312, "episode/length": 288.0, "episode/score": 0.043045211466562705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043045211466562705}
{"step": 794848, "time": 25235.77138018608, "episode/length": 288.0, "episode/score": 0.08556968817580923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08556968817580923}
{"step": 794905, "time": 25240.340600967407, "train_stats/mean_log_entropy": 0.09791956185765073, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.162034844633323, "train/action_min": 0.0, "train/action_std": 1.6502188929361314, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.017249870458009405, "train/actor_opt_grad_steps": 48590.0, "train/actor_opt_loss": -10.472592825041943, "train/adv_mag": 1.0230362037917478, "train/adv_max": 0.43394932794810537, "train/adv_mean": 0.0028086146629532744, "train/adv_min": -0.9931764521790509, "train/adv_std": 0.04871516103561425, "train/cont_avg": 0.9953821843592965, "train/cont_loss_mean": 0.017044341380019958, "train/cont_loss_std": 0.2428224122633774, "train/cont_neg_acc": 0.3100344850564722, "train/cont_neg_loss": 2.951156158815138, "train/cont_pos_acc": 0.9998471781836084, "train/cont_pos_loss": 0.0032454785614756485, "train/cont_pred": 0.9954837473792646, "train/cont_rate": 0.9953821843592965, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.3200052534815055, "train/extr_critic_critic_opt_grad_steps": 48590.0, "train/extr_critic_critic_opt_loss": 8233.741786324199, "train/extr_critic_mag": 1.3494500023635787, "train/extr_critic_max": 1.3494500023635787, "train/extr_critic_mean": 1.2541242993656714, "train/extr_critic_min": 1.0308607517175339, "train/extr_critic_std": 0.022145970235461717, "train/extr_return_normed_mag": 1.003874194681944, "train/extr_return_normed_max": 0.3927250339757258, "train/extr_return_normed_mean": 0.04207657740203355, "train/extr_return_normed_min": -0.9735570007832206, "train/extr_return_normed_std": 0.054543824763453784, "train/extr_return_rate": 0.9987444188726607, "train/extr_return_raw_mag": 1.6075813788265438, "train/extr_return_raw_max": 1.6075813788265438, "train/extr_return_raw_mean": 1.2569329816492358, "train/extr_return_raw_min": 0.2412993440675975, "train/extr_return_raw_std": 0.05454382470729363, "train/extr_reward_mag": 0.40372876725604184, "train/extr_reward_max": 0.40372876725604184, "train/extr_reward_mean": 0.0029808484762556026, "train/extr_reward_min": 5.3254803221429415e-06, "train/extr_reward_std": 0.015411649074817273, "train/image_loss_mean": 0.10213379752845621, "train/image_loss_std": 0.10577741377617246, "train/model_loss_mean": 0.7436863198951261, "train/model_loss_std": 0.38776944184572854, "train/model_opt_grad_norm": 19.33944280902345, "train/model_opt_grad_steps": 48546.45728643216, "train/model_opt_loss": 3737.1420886169126, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5025.125628140703, "train/policy_entropy_mag": 1.3198293812909918, "train/policy_entropy_max": 1.3198293812909918, "train/policy_entropy_mean": 0.11816828615551618, "train/policy_entropy_min": 0.06468649313377975, "train/policy_entropy_std": 0.15396555820152388, "train/policy_logprob_mag": 6.551080246067526, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1180517249296059, "train/policy_logprob_min": -6.551080246067526, "train/policy_logprob_std": 0.6535735184223808, "train/policy_randomness_mag": 0.6782581713331405, "train/policy_randomness_max": 0.6782581713331405, "train/policy_randomness_mean": 0.06072648906677812, "train/policy_randomness_min": 0.03324228208792868, "train/policy_randomness_std": 0.07912265000181581, "train/post_ent_mag": 2.9084365727314396, "train/post_ent_max": 2.9084365727314396, "train/post_ent_mean": 2.900251117782976, "train/post_ent_min": 2.895305683864421, "train/post_ent_std": 0.00290958791732526, "train/prior_ent_mag": 3.0444020949416424, "train/prior_ent_max": 3.0444020949416424, "train/prior_ent_mean": 2.821033213006791, "train/prior_ent_min": 2.811723401199034, "train/prior_ent_std": 0.01505257211971897, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0015086886268541985, "train/reward_loss_mean": 0.024508157922844193, "train/reward_loss_std": 0.15708717717859313, "train/reward_max_data": 0.623845120297567, "train/reward_max_pred": 0.20962928168138667, "train/reward_neg_acc": 0.9997148978051229, "train/reward_neg_loss": 0.017793172881493916, "train/reward_pos_acc": 0.26528599734842423, "train/reward_pos_loss": 3.9515564900178175, "train/reward_pred": 0.0012829448412355017, "train/reward_rate": 0.0016832207914572865, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.007007847540080547, "report/cont_loss_std": 0.11191605776548386, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 1.244842290878296, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0033707243856042624, "report/cont_pred": 0.9949387311935425, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1107165664434433, "report/image_loss_std": 0.11259815841913223, "report/model_loss_mean": 0.7377758026123047, "report/model_loss_std": 0.2883199453353882, "report/post_ent_mag": 2.9055628776550293, "report/post_ent_max": 2.9055628776550293, "report/post_ent_mean": 2.898700714111328, "report/post_ent_min": 2.894679069519043, "report/post_ent_std": 0.0026267021894454956, "report/prior_ent_mag": 2.924208402633667, "report/prior_ent_max": 2.924208402633667, "report/prior_ent_mean": 2.820399761199951, "report/prior_ent_min": 2.8115973472595215, "report/prior_ent_std": 0.013003513216972351, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0009096747380681336, "report/reward_loss_mean": 0.020051399245858192, "report/reward_loss_std": 0.14125606417655945, "report/reward_max_data": 0.5850000381469727, "report/reward_max_pred": 0.23972606658935547, "report/reward_neg_acc": 0.9990224838256836, "report/reward_neg_loss": 0.015715990215539932, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.455177307128906, "report/reward_pred": 0.0012413525255396962, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.04339763522148132, "eval/cont_loss_std": 0.6100362539291382, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.382081985473633, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002481623785570264, "eval/cont_pred": 0.9975786209106445, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19779056310653687, "eval/image_loss_std": 0.12205454707145691, "eval/model_loss_mean": 0.8446286916732788, "eval/model_loss_std": 0.6164707541465759, "eval/post_ent_mag": 2.905571699142456, "eval/post_ent_max": 2.905571699142456, "eval/post_ent_mean": 2.898968458175659, "eval/post_ent_min": 2.894005537033081, "eval/post_ent_std": 0.0025132556911557913, "eval/prior_ent_mag": 3.005760669708252, "eval/prior_ent_max": 3.005760669708252, "eval/prior_ent_mean": 2.8202309608459473, "eval/prior_ent_min": 2.8115384578704834, "eval/prior_ent_std": 0.013880850747227669, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0034404927864670753, "eval/reward_loss_std": 0.003573998576030135, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0206758975982666, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0034404927864670753, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0006599633488804102, "eval/reward_rate": 0.0, "replay/size": 794401.0, "replay/inserts": 31824.0, "replay/samples": 31824.0, "replay/insert_wait_avg": 1.1957039360786696e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.681027916342005e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4736.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.890142324808483e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2606120109558, "timer/env.step_count": 3978.0, "timer/env.step_total": 34.18322777748108, "timer/env.step_frac": 0.03417432153882179, "timer/env.step_avg": 0.0085930688228962, "timer/env.step_min": 0.007231950759887695, "timer/env.step_max": 0.03995823860168457, "timer/replay._sample_count": 31824.0, "timer/replay._sample_total": 15.839025497436523, "timer/replay._sample_frac": 0.01583489873263453, "timer/replay._sample_avg": 0.0004977069349370451, "timer/replay._sample_min": 0.000408172607421875, "timer/replay._sample_max": 0.011806726455688477, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4570.0, "timer/agent.policy_total": 39.106547355651855, "timer/agent.policy_frac": 0.03909635837507468, "timer/agent.policy_avg": 0.00855723136885161, "timer/agent.policy_min": 0.007487773895263672, "timer/agent.policy_max": 0.08085799217224121, "timer/dataset_train_count": 1989.0, "timer/dataset_train_total": 0.2090897560119629, "timer/dataset_train_frac": 0.0002090352789075661, "timer/dataset_train_avg": 0.00010512305480742226, "timer/dataset_train_min": 8.845329284667969e-05, "timer/dataset_train_max": 0.0002410411834716797, "timer/agent.train_count": 1989.0, "timer/agent.train_total": 881.2036197185516, "timer/agent.train_frac": 0.8809740273056956, "timer/agent.train_avg": 0.4430385217287841, "timer/agent.train_min": 0.43094825744628906, "timer/agent.train_max": 0.5963075160980225, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47815704345703125, "timer/agent.report_frac": 0.0004780324624556885, "timer/agent.report_avg": 0.23907852172851562, "timer/agent.report_min": 0.23221826553344727, "timer/agent.report_max": 0.24593877792358398, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9079488186496775e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 31.815142939049263}
{"step": 795120, "time": 25246.997777223587, "episode/length": 137.0, "episode/score": 0.6269910863189239, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.05511609584169719}
{"step": 795752, "time": 25266.33420753479, "episode/length": 288.0, "episode/score": 0.04775985243776404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04775985243776404}
{"step": 795792, "time": 25267.807108402252, "episode/length": 157.0, "episode/score": 0.5566444319631785, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0472694414859518}
{"step": 796128, "time": 25278.164858818054, "episode/length": 125.0, "episode/score": 0.6369401353399553, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.027565121952193294}
{"step": 796232, "time": 25281.170006513596, "episode/length": 288.0, "episode/score": 0.049555564394950125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049555564394950125}
{"step": 796296, "time": 25283.171362876892, "episode/length": 288.0, "episode/score": 0.0656031057980897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0656031057980897}
{"step": 796520, "time": 25290.106450796127, "episode/length": 90.0, "episode/score": 0.7435522321036387, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0248022325401962}
{"step": 796624, "time": 25293.554580450058, "episode/length": 288.0, "episode/score": 0.04876309370470722, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04876309370470722}
{"step": 796808, "time": 25299.172625541687, "episode/length": 63.0, "episode/score": 0.8170344438640313, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.013909403665820719}
{"step": 796840, "time": 25300.163543701172, "episode/length": 75.0, "episode/score": 0.7910270924503493, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.025402076093996584}
{"step": 796848, "time": 25300.64023041725, "episode/length": 136.0, "episode/score": 0.6019817608789708, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.02698175347495635}
{"step": 796952, "time": 25303.64792394638, "episode/length": 288.0, "episode/score": 0.04907658110164448, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04907658110164448}
{"step": 796968, "time": 25304.14380478859, "episode/length": 104.0, "episode/score": 0.7010040744394246, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.02600403312362687}
{"step": 797160, "time": 25310.088930130005, "episode/length": 288.0, "episode/score": 0.028304133230790285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028304133230790285}
{"step": 797232, "time": 25312.55804681778, "episode/length": 47.0, "episode/score": 0.8749088577433213, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.02178387340700283}
{"step": 797256, "time": 25313.0834441185, "episode/length": 78.0, "episode/score": 0.7686475472460188, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.01239752384071835}
{"step": 797696, "time": 25327.04652762413, "episode/length": 110.0, "episode/score": 0.6996879501581361, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.04343793677037411}
{"step": 797752, "time": 25328.578582525253, "episode/length": 73.0, "episode/score": 0.7836116063213012, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.011736569091681304}
{"step": 798512, "time": 25352.298552036285, "episode/length": 94.0, "episode/score": 0.7346028430529259, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.02835283194690419}
{"step": 798624, "time": 25355.850742816925, "episode/length": 173.0, "episode/score": 0.4955895496798348, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.03621456856240002}
{"step": 798832, "time": 25362.294921398163, "episode/length": 288.0, "episode/score": 0.037712534428806066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037712534428806066}
{"step": 798880, "time": 25363.78095293045, "episode/length": 254.0, "episode/score": 0.23948079738033812, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.03323080079712781}
{"step": 799144, "time": 25371.70624613762, "episode/length": 78.0, "episode/score": 0.7820864876773612, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.025836444510559886}
{"step": 799264, "time": 25375.612773418427, "episode/length": 288.0, "episode/score": 0.031329704891732035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031329704891732035}
{"step": 799280, "time": 25376.11013317108, "episode/length": 288.0, "episode/score": 0.03847439448031764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03847439448031764}
{"step": 799528, "time": 25383.556370019913, "episode/length": 112.0, "episode/score": 0.6829593593786285, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.032959353825617654}
{"step": 799544, "time": 25384.0559091568, "episode/length": 230.0, "episode/score": 0.3166877911842221, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.035437791620779535}
{"step": 799568, "time": 25385.13526558876, "episode/length": 288.0, "episode/score": 0.03665040324767688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03665040324767688}
{"step": 799656, "time": 25387.63510274887, "episode/length": 96.0, "episode/score": 0.7364403813598983, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.03644037395588384}
{"step": 799824, "time": 25393.009927749634, "episode/length": 123.0, "episode/score": 0.641808063233043, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.02618303121300869}
{"step": 799984, "time": 25397.932369709015, "episode/length": 89.0, "episode/score": 0.7468027790871474, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.02492775284713389}
{"step": 800040, "time": 25399.438560009003, "episode/length": 47.0, "episode/score": 0.8688768646238714, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.015751865124457254}
{"step": 800072, "time": 25401.252676963806, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 800072, "time": 25402.055691719055, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 800072, "time": 25402.186707019806, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 800072, "time": 25402.617426395416, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 800072, "time": 25402.701516389847, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 800072, "time": 25403.17703819275, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 800072, "time": 25403.323531627655, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 800072, "time": 25403.69001030922, "eval_episode/length": 204.0, "eval_episode/score": 0.36250001192092896, "eval_episode/reward_rate": 0.004878048780487805}
{"step": 800112, "time": 25405.165579319, "episode/length": 103.0, "episode/score": 0.7055945136376067, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.027469518113775848}
{"step": 800360, "time": 25412.547927618027, "episode/length": 151.0, "episode/score": 0.5671555063096321, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.03903048883569227}
{"step": 800400, "time": 25413.989134788513, "episode/length": 103.0, "episode/score": 0.7021714768488891, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.024046429665759206}
{"step": 800480, "time": 25416.558889627457, "episode/length": 116.0, "episode/score": 0.6723988103076408, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.034898798887297744}
{"step": 800704, "time": 25423.44092988968, "episode/length": 42.0, "episode/score": 0.8913135156331009, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.022563510080090055}
{"step": 800920, "time": 25429.861127614975, "episode/length": 100.0, "episode/score": 0.7137705058786423, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.026270476483773564}
{"step": 801000, "time": 25432.312873363495, "episode/length": 146.0, "episode/score": 0.575946344173758, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.03219634270692495}
{"step": 801040, "time": 25433.76687860489, "episode/length": 41.0, "episode/score": 0.8874537693303637, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.01557876786353063}
{"step": 801360, "time": 25443.628702163696, "episode/length": 109.0, "episode/score": 0.6734071167735465, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.01403207545774876}
{"step": 801768, "time": 25456.07517695427, "episode/length": 105.0, "episode/score": 0.7091776905731422, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.037302718891169206}
{"step": 801840, "time": 25458.511252880096, "episode/length": 288.0, "episode/score": 0.027225882200241358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027225882200241358}
{"step": 802096, "time": 25466.419603586197, "episode/length": 40.0, "episode/score": 0.8867519974450033, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.011752021601182605}
{"step": 802296, "time": 25472.37235379219, "episode/length": 288.0, "episode/score": 0.013834355263497855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.013834355263497855}
{"step": 802352, "time": 25474.33462381363, "episode/length": 288.0, "episode/score": 0.036309277042278154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036309277042278154}
{"step": 802712, "time": 25485.30259823799, "episode/length": 288.0, "episode/score": 0.03130320739091985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03130320739091985}
{"step": 802760, "time": 25486.786581754684, "episode/length": 114.0, "episode/score": 0.6901041434573472, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.046354151676268884}
{"step": 802880, "time": 25491.18344116211, "episode/length": 65.0, "episode/score": 0.8088691559237304, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.011994147745554073}
{"step": 803168, "time": 25500.06169939041, "episode/length": 50.0, "episode/score": 0.8572076393477346, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.01345765747942096}
{"step": 803240, "time": 25502.064764022827, "episode/length": 8.0, "episode/score": 0.9815983465598492, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.006598346874170602}
{"step": 803312, "time": 25504.512603998184, "episode/length": 126.0, "episode/score": 0.6358497801718386, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.02959978391459117}
{"step": 803312, "time": 25504.519482135773, "episode/length": 288.0, "episode/score": 0.019863849097760067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019863849097760067}
{"step": 803352, "time": 25505.664385080338, "episode/length": 288.0, "episode/score": 0.022863836836336304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022863836836336304}
{"step": 803672, "time": 25515.5389482975, "episode/length": 288.0, "episode/score": 0.026317624961620822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026317624961620822}
{"step": 803688, "time": 25516.040432214737, "episode/length": 46.0, "episode/score": 0.8696551893733613, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.013405221434140913}
{"step": 803960, "time": 25524.452781677246, "episode/length": 75.0, "episode/score": 0.7743194141237382, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.008694442441765204}
{"step": 804352, "time": 25536.87749195099, "episode/length": 138.0, "episode/score": 0.58068969772944, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.011939702205609137}
{"step": 804360, "time": 25536.910450220108, "episode/length": 49.0, "episode/score": 0.8634596986854604, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.01658469014057573}
{"step": 804368, "time": 25537.38050198555, "episode/length": 86.0, "episode/score": 0.7510760390441646, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.01982607512127288}
{"step": 804408, "time": 25538.39792060852, "episode/length": 288.0, "episode/score": 0.026286190653763697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026286190653763697}
{"step": 804544, "time": 25542.817103862762, "episode/length": 153.0, "episode/score": 0.5490728703238119, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.027197849857998335}
{"step": 804600, "time": 25544.351157188416, "episode/length": 23.0, "episode/score": 0.9452854889676701, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.017160439805479655}
{"step": 804800, "time": 25550.731859207153, "episode/length": 55.0, "episode/score": 0.8399373503867196, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.01181234322717728}
{"step": 804944, "time": 25555.152119874954, "episode/length": 49.0, "episode/score": 0.8639158159003273, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.017040807355442666}
{"step": 804952, "time": 25555.18463563919, "episode/length": 258.0, "episode/score": 0.2212746336207374, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.02752463809690653}
{"step": 805024, "time": 25557.603310346603, "episode/length": 288.0, "episode/score": 0.0495271316964363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0495271316964363}
{"step": 805064, "time": 25558.615446805954, "episode/length": 57.0, "episode/score": 0.8339463748055778, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.012071373327103174}
{"step": 805080, "time": 25559.129242897034, "episode/length": 88.0, "episode/score": 0.742600706428675, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.017600700718503504}
{"step": 805320, "time": 25566.60959291458, "episode/length": 119.0, "episode/score": 0.643417871141537, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.015292872390091361}
{"step": 805560, "time": 25574.01842212677, "episode/length": 75.0, "episode/score": 0.7990891898189147, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.03346420795060112}
{"step": 805616, "time": 25575.965341567993, "episode/length": 240.0, "episode/score": 0.2663520290517454, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.016352029270024104}
{"step": 805624, "time": 25575.998985290527, "episode/length": 102.0, "episode/score": 0.7015078649498037, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.02025790389654958}
{"step": 805680, "time": 25577.93915104866, "episode/length": 91.0, "episode/score": 0.744948254577821, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.02932328463043632}
{"step": 805920, "time": 25585.362847566605, "episode/length": 111.0, "episode/score": 0.6834941940931003, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.030369234332056294}
{"step": 806080, "time": 25590.277910470963, "episode/length": 57.0, "episode/score": 0.8359918934385178, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.014116943692101813}
{"step": 806216, "time": 25594.231626033783, "episode/length": 66.0, "episode/score": 0.8128380622002283, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.01908806767465876}
{"step": 806264, "time": 25595.794438123703, "episode/length": 79.0, "episode/score": 0.7805494268957318, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.027424435114653534}
{"step": 806392, "time": 25599.730580568314, "episode/length": 58.0, "episode/score": 0.8320493457063094, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.013299336969339492}
{"step": 806704, "time": 25609.520831346512, "episode/length": 142.0, "episode/score": 0.6027272528692151, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.04647729981951443}
{"step": 806928, "time": 25616.38537144661, "episode/length": 105.0, "episode/score": 0.6977213239937896, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.02584635040551575}
{"step": 807232, "time": 25625.829545259476, "episode/length": 126.0, "episode/score": 0.625686135810156, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.01943617414281107}
{"step": 807376, "time": 25630.28506565094, "episode/length": 288.0, "episode/score": 0.043567977258646806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043567977258646806}
{"step": 807392, "time": 25630.778678894043, "episode/length": 288.0, "episode/score": 0.042598556306359114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042598556306359114}
{"step": 807600, "time": 25637.130026102066, "episode/length": 25.0, "episode/score": 0.9439155323494788, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.02204052518993649}
{"step": 807632, "time": 25638.127225399017, "episode/length": 288.0, "episode/score": 0.04801992402349242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04801992402349242}
{"step": 807648, "time": 25638.62050628662, "episode/length": 89.0, "episode/score": 0.7782715027147447, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.05639651494999498}
{"step": 807712, "time": 25640.570231437683, "episode/length": 164.0, "episode/score": 0.5266739755695653, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.03917395648909405}
{"step": 807968, "time": 25648.3957259655, "episode/length": 73.0, "episode/score": 0.8315099661828071, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.059634935181406945}
{"step": 808136, "time": 25653.3223028183, "episode/length": 20.0, "episode/score": 0.948092560738587, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.01059258087843773}
{"step": 808312, "time": 25658.838079452515, "episode/length": 134.0, "episode/score": 0.654499824465006, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.07324978314920827}
{"step": 808576, "time": 25667.166783571243, "episode/length": 288.0, "episode/score": 0.02318191383380963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02318191383380963}
{"step": 808640, "time": 25669.141757965088, "episode/length": 123.0, "episode/score": 0.7146174239003358, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.09899238667071586}
{"step": 808704, "time": 25671.101059436798, "episode/length": 15.0, "episode/score": 0.9722290055385656, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.01910403385659265}
{"step": 808736, "time": 25672.079705953598, "episode/length": 52.0, "episode/score": 0.8787962522389989, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.041296304398883876}
{"step": 808912, "time": 25677.5166079998, "episode/length": 96.0, "episode/score": 0.7648561605105897, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.06485616425334229}
{"step": 809016, "time": 25680.505625486374, "episode/length": 288.0, "episode/score": 0.07098348522845299, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07098348522845299}
{"step": 809368, "time": 25691.511976003647, "episode/length": 78.0, "episode/score": 0.8027546940003276, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.04650467178828421}
{"step": 809576, "time": 25697.90057826042, "episode/length": 116.0, "episode/score": 0.7097769370765263, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.07227695132576173}
{"step": 809792, "time": 25704.719388961792, "episode/length": 52.0, "episode/score": 0.8746157339901401, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.03711576016030449}
{"step": 809912, "time": 25708.191891908646, "episode/length": 288.0, "episode/score": 0.09650738025629835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09650738025629835}
{"step": 809944, "time": 25709.174959897995, "episode/length": 288.0, "episode/score": 0.05795371859653642, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05795371859653642}
{"step": 810024, "time": 25711.62377500534, "episode/length": 288.0, "episode/score": 0.10265397260138798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10265397260138798}
{"step": 810032, "time": 25712.114898443222, "episode/length": 126.0, "episode/score": 0.6991630971293716, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.09291308041213142}
{"step": 810056, "time": 25713.511864423752, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 810056, "time": 25714.11705684662, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 810056, "time": 25714.122605085373, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 810056, "time": 25714.739884614944, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 810056, "time": 25714.875679016113, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 810056, "time": 25714.880974531174, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 810056, "time": 25715.475428819656, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 810056, "time": 25715.63734602928, "eval_episode/length": 176.0, "eval_episode/score": 0.44999998807907104, "eval_episode/reward_rate": 0.005649717514124294}
{"step": 810232, "time": 25721.044691324234, "episode/length": 190.0, "episode/score": 0.4877111835616006, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0814611851914151}
{"step": 810312, "time": 25723.50158381462, "episode/length": 49.0, "episode/score": 0.894609817577475, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.04773480728636059}
{"step": 810536, "time": 25730.41042160988, "episode/length": 63.0, "episode/score": 0.8508423192888586, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.04771726680883148}
{"step": 810736, "time": 25736.763863563538, "episode/length": 52.0, "episode/score": 0.8705825515112338, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.03308258827519239}
{"step": 810952, "time": 25743.202698469162, "episode/length": 125.0, "episode/score": 0.6787328890331992, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0693579019552999}
{"step": 811224, "time": 25752.20545721054, "episode/length": 288.0, "episode/score": 0.0777070285055288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0777070285055288}
{"step": 811384, "time": 25757.11626791954, "episode/length": 105.0, "episode/score": 0.738133902343634, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.06625890315854122}
{"step": 811520, "time": 25761.509003162384, "episode/length": 70.0, "episode/score": 0.8082222678676771, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.026972253548592562}
{"step": 811552, "time": 25762.495953559875, "episode/length": 101.0, "episode/score": 0.7471434174012757, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.06276840999726119}
{"step": 811888, "time": 25772.816406965256, "episode/length": 288.0, "episode/score": 0.09587190741513041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09587190741513041}
{"step": 811960, "time": 25774.91144299507, "episode/length": 215.0, "episode/score": 0.3842109817524033, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.056085995198372984}
{"step": 812072, "time": 25778.429581165314, "episode/length": 85.0, "episode/score": 0.7718326744288788, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.03745766010979423}
{"step": 812104, "time": 25779.415330171585, "episode/length": 288.0, "episode/score": 0.09280213032957363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09280213032957363}
{"step": 812344, "time": 25786.79641032219, "episode/length": 288.0, "episode/score": 0.05915763245548078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05915763245548078}
{"step": 812480, "time": 25791.18437886238, "episode/length": 156.0, "episode/score": 0.6046950324434874, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0921950300453318}
{"step": 812552, "time": 25793.16192650795, "episode/length": 59.0, "episode/score": 0.8644175200654445, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.04879247950634635}
{"step": 812664, "time": 25796.5966296196, "episode/length": 96.0, "episode/score": 0.743301164984814, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.043301177342300434}
{"step": 812672, "time": 25797.067332983017, "episode/length": 88.0, "episode/score": 0.7718930766418453, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.04689303347504392}
{"step": 812712, "time": 25798.07904601097, "episode/length": 144.0, "episode/score": 0.6296797638649423, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.07967975238057079}
{"step": 812808, "time": 25801.038303613663, "episode/length": 87.0, "episode/score": 0.786621938528242, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.05849693373193077}
{"step": 812968, "time": 25806.04376268387, "episode/length": 180.0, "episode/score": 0.5025258036746436, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.06502580411120107}
{"step": 812992, "time": 25807.00514984131, "episode/length": 63.0, "episode/score": 0.8302042946222628, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.027079262602228482}
{"step": 813232, "time": 25814.387951374054, "episode/length": 110.0, "episode/score": 0.7473095660468516, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.09105956767666612}
{"step": 813256, "time": 25814.910549640656, "episode/length": 67.0, "episode/score": 0.826329462124022, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.03570448678078719}
{"step": 813352, "time": 25817.905474185944, "episode/length": 99.0, "episode/score": 0.7440857270980814, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.05346070085806787}
{"step": 813624, "time": 25826.37708044052, "episode/length": 78.0, "episode/score": 0.8074136512561836, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.05116361105797296}
{"step": 813656, "time": 25827.383579969406, "episode/length": 52.0, "episode/score": 0.8740941328030658, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.036594128006754545}
{"step": 813752, "time": 25830.403936624527, "episode/length": 135.0, "episode/score": 0.6660576992737788, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.08793270008868603}
{"step": 813856, "time": 25833.867369174957, "episode/length": 110.0, "episode/score": 0.7531223575083459, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.09687233416707386}
{"step": 813912, "time": 25835.513052225113, "episode/length": 137.0, "episode/score": 0.6257139676918086, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.05383897517731384}
{"step": 814056, "time": 25840.021520376205, "episode/length": 53.0, "episode/score": 0.8585032125085945, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.024128159271867844}
{"step": 814072, "time": 25840.525423049927, "episode/length": 51.0, "episode/score": 0.8620982542395268, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.02147329031663503}
{"step": 814104, "time": 25841.530337572098, "episode/length": 105.0, "episode/score": 0.7171557531573853, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.04528073383244191}
{"step": 814360, "time": 25849.542367458344, "episode/length": 37.0, "episode/score": 0.9156458327584005, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.03127088075643769}
{"step": 814432, "time": 25852.027278661728, "episode/length": 71.0, "episode/score": 0.8332227568521375, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.055097754453981906}
{"step": 814792, "time": 25863.12034344673, "episode/length": 89.0, "episode/score": 0.7721859606378985, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.050310920078800336}
{"step": 814856, "time": 25865.261993408203, "episode/length": 93.0, "episode/score": 0.7622547031933209, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.05287968098127749}
{"step": 814872, "time": 25865.768473386765, "episode/length": 119.0, "episode/score": 0.683358921861327, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.05523388130222884}
{"step": 814984, "time": 25869.18878054619, "episode/length": 288.0, "episode/score": 0.08277271463657598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08277271463657598}
{"step": 814992, "time": 25869.67662835121, "episode/length": 69.0, "episode/score": 0.8203008154637246, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.03592580435770287}
{"step": 815376, "time": 25881.474026203156, "episode/length": 126.0, "episode/score": 0.6680751163405603, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.06182514118358995}
{"step": 815448, "time": 25883.484848499298, "episode/length": 71.0, "episode/score": 0.8097569857345661, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.031631983336410485}
{"step": 815512, "time": 25885.500735521317, "episode/length": 89.0, "episode/score": 0.7529513534373109, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.03107632719729736}
{"step": 815520, "time": 25885.975430727005, "episode/length": 220.0, "episode/score": 0.38557840111798214, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0730784075790325}
{"step": 815664, "time": 25890.48865866661, "episode/length": 35.0, "episode/score": 0.9158078768004998, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.02518287761540705}
{"step": 815664, "time": 25890.49706697464, "episode/length": 288.0, "episode/score": 0.06917743817325572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06917743817325572}
{"step": 815872, "time": 25897.04258966446, "episode/length": 110.0, "episode/score": 0.713066541216449, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0568165125782798}
{"step": 815880, "time": 25897.075305461884, "episode/length": 110.0, "episode/score": 0.7148124125324102, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.058562383894241066}
{"step": 815952, "time": 25899.528292179108, "episode/length": 136.0, "episode/score": 0.6238465226965673, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.04884652029841163}
{"step": 816016, "time": 25901.490067481995, "episode/length": 62.0, "episode/score": 0.8213006015994324, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.015050611122205737}
{"step": 816344, "time": 25911.362674236298, "episode/length": 84.0, "episode/score": 0.7690143940117196, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.031514353452621435}
{"step": 816424, "time": 25913.826085805893, "episode/length": 58.0, "episode/score": 0.848183203338067, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.029433180311116303}
{"step": 816552, "time": 25917.790985822678, "episode/length": 84.0, "episode/score": 0.7871413579837281, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.04964134687770638}
{"step": 816576, "time": 25918.756412267685, "episode/length": 69.0, "episode/score": 0.8048088544701386, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.020433842985767114}
{"step": 816744, "time": 25923.71977710724, "episode/length": 39.0, "episode/score": 0.8939643703308775, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.01583933506867652}
{"step": 816768, "time": 25924.703687906265, "episode/length": 52.0, "episode/score": 0.8610525610790773, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.023552568564582543}
{"step": 817176, "time": 25937.130713939667, "episode/length": 188.0, "episode/score": 0.4827321460504663, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.07023215244748826}
{"step": 817328, "time": 25942.01710343361, "episode/length": 96.0, "episode/score": 0.7336363006775173, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.03363629624209352}
{"step": 817344, "time": 25942.516503334045, "episode/length": 227.0, "episode/score": 0.3880935691313425, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.09746857661684771}
{"step": 817464, "time": 25945.998599529266, "episode/length": 89.0, "episode/score": 0.770025868626135, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.04815084034885331}
{"step": 817760, "time": 25955.428324222565, "episode/length": 288.0, "episode/score": 0.05466245445700224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05466245445700224}
{"step": 818040, "time": 25963.795121192932, "episode/length": 71.0, "episode/score": 0.8065601474061168, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.02843514297069305}
{"step": 818192, "time": 25968.71022248268, "episode/length": 288.0, "episode/score": 0.08234515244726026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08234515244726026}
{"step": 818392, "time": 25974.61931014061, "episode/length": 78.0, "episode/score": 0.7955277633082005, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.03927774028124986}
{"step": 818504, "time": 25978.03887820244, "episode/length": 57.0, "episode/score": 0.8387366596225547, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.016861654826243466}
{"step": 818584, "time": 25980.508672475815, "episode/length": 156.0, "episode/score": 0.574286931291681, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.061786956134710636}
{"step": 818608, "time": 25981.47130036354, "episode/length": 157.0, "episode/score": 0.593063133013402, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.08368814049890716}
{"step": 818888, "time": 25989.958785533905, "episode/length": 288.0, "episode/score": 0.0950308921121632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0950308921121632}
{"step": 819032, "time": 25994.40766763687, "episode/length": 52.0, "episode/score": 0.8529373238916378, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.015437331377142982}
{"step": 819032, "time": 25994.413109064102, "episode/length": 55.0, "episode/score": 0.8411124208982983, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.01298739755702627}
{"step": 819080, "time": 25995.887991905212, "episode/length": 288.0, "episode/score": 0.04605202208017545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04605202208017545}
{"step": 819136, "time": 25997.8353600502, "episode/length": 117.0, "episode/score": 0.6633405429051891, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0289655796691477}
{"step": 819216, "time": 26000.808095932007, "episode/length": 102.0, "episode/score": 0.7164543907456391, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.035204398231144296}
{"step": 819336, "time": 26004.293924808502, "episode/length": 37.0, "episode/score": 0.9065314995386871, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.02215650003927294}
{"step": 819432, "time": 26007.246881484985, "episode/length": 115.0, "episode/score": 0.6860434605473529, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.04541844715959087}
{"step": 819488, "time": 26009.214029550552, "episode/length": 288.0, "episode/score": 0.04344118747189896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04344118747189896}
{"step": 819608, "time": 26012.67720389366, "episode/length": 89.0, "episode/score": 0.7604916775137553, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.03861664626788297}
{"step": 819680, "time": 26015.24349617958, "episode/length": 67.0, "episode/score": 0.8395260539994069, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.048901061484912134}
{"step": 819688, "time": 26015.27580189705, "episode/length": 75.0, "episode/score": 0.8018414167879655, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.03621641760287275}
{"step": 819696, "time": 26015.74493575096, "episode/length": 82.0, "episode/score": 0.797711186236711, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.053961195759484326}
{"step": 820040, "time": 26026.924870729446, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 820040, "time": 26026.96149778366, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 820040, "time": 26027.029233694077, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 820040, "time": 26027.361076116562, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 820040, "time": 26027.523395061493, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 820040, "time": 26028.076221227646, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 820040, "time": 26028.378651618958, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 820040, "time": 26028.46360397339, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 820168, "time": 26032.409040927887, "episode/length": 84.0, "episode/score": 0.7723910331376374, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.03489099787543637}
{"step": 820184, "time": 26032.902715206146, "episode/length": 71.0, "episode/score": 0.8066746583999702, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.028549650995955744}
{"step": 820256, "time": 26035.32913684845, "episode/length": 114.0, "episode/score": 0.6943108060881968, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.05056077082599586}
{"step": 820448, "time": 26041.238556861877, "episode/length": 126.0, "episode/score": 0.6335403853429398, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0272903739225967}
{"step": 820472, "time": 26041.76203250885, "episode/length": 97.0, "episode/score": 0.7337454905118648, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.03687048495885392}
{"step": 820512, "time": 26043.216037273407, "episode/length": 161.0, "episode/score": 0.5374765063966152, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.04060151013936775}
{"step": 820600, "time": 26045.813114643097, "episode/length": 51.0, "episode/score": 0.8565574291287703, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.015932433890156972}
{"step": 821040, "time": 26059.593149900436, "episode/length": 97.0, "episode/score": 0.747448019374815, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.050573029828910876}
{"step": 821080, "time": 26060.623493433, "episode/length": 70.0, "episode/score": 0.8107020476722937, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.02945201827742494}
{"step": 821376, "time": 26069.894317150116, "episode/length": 115.0, "episode/score": 0.6896927032300937, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.049067695051917326}
{"step": 821560, "time": 26075.443397045135, "episode/length": 119.0, "episode/score": 0.6764595435465708, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.04833451526928911}
{"step": 821640, "time": 26077.893117666245, "episode/length": 69.0, "episode/score": 0.8028873257728719, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.01851233399179364}
{"step": 821680, "time": 26079.329537391663, "episode/length": 37.0, "episode/score": 0.900487358460623, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.016112402442331586}
{"step": 821688, "time": 26079.363011598587, "episode/length": 151.0, "episode/score": 0.5846509345828963, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.05652592717888183}
{"step": 821992, "time": 26088.69024825096, "episode/length": 288.0, "episode/score": 0.04387758704240241, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04387758704240241}
{"step": 822008, "time": 26089.188864946365, "episode/length": 288.0, "episode/score": 0.09163863034166297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09163863034166297}
{"step": 822112, "time": 26092.599827051163, "episode/length": 68.0, "episode/score": 0.8022981519272889, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.014798120925888725}
{"step": 822296, "time": 26098.014060497284, "episode/length": 81.0, "episode/score": 0.7735885736003638, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.026713603652979145}
{"step": 822480, "time": 26103.85867881775, "episode/length": 288.0, "episode/score": 0.06411528614125928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06411528614125928}
{"step": 822640, "time": 26108.862805843353, "episode/length": 80.0, "episode/score": 0.775910718353316, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.02591071119377375}
{"step": 822704, "time": 26110.84625339508, "episode/length": 73.0, "episode/score": 0.8144968846431766, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.04262184741355668}
{"step": 822768, "time": 26112.81518626213, "episode/length": 58.0, "episode/score": 0.8313385424369244, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.012588519031623946}
{"step": 823088, "time": 26122.643194437027, "episode/length": 75.0, "episode/score": 0.7859401973523745, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.020315197570653254}
{"step": 823352, "time": 26130.531331300735, "episode/length": 288.0, "episode/score": 0.04386827446603547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04386827446603547}
{"step": 823552, "time": 26136.971922636032, "episode/length": 113.0, "episode/score": 0.6778309164535585, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.030955907716588626}
{"step": 823664, "time": 26140.411571741104, "episode/length": 38.0, "episode/score": 0.8963583055550544, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.015108308124922587}
{"step": 823992, "time": 26150.27601003647, "episode/length": 288.0, "episode/score": 0.026940978451307274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026940978451307274}
{"step": 824000, "time": 26150.749022960663, "episode/length": 288.0, "episode/score": 0.05533616124898799, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05533616124898799}
{"step": 824312, "time": 26160.137847423553, "episode/length": 94.0, "episode/score": 0.7408640272710727, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.034613985955274984}
{"step": 824320, "time": 26160.61231970787, "episode/length": 288.0, "episode/score": 0.06933468116301356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06933468116301356}
{"step": 824384, "time": 26162.588341474533, "episode/length": 161.0, "episode/score": 0.5464113622315381, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.04953636699292474}
{"step": 824552, "time": 26167.727848529816, "episode/length": 68.0, "episode/score": 0.803093233641448, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.015593213175634446}
{"step": 824864, "time": 26177.59495306015, "episode/length": 67.0, "episode/score": 0.8269259052044617, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.03630091565855764}
{"step": 825000, "time": 26181.611680030823, "episode/length": 76.0, "episode/score": 0.8144278766103525, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.05192788035310514}
{"step": 825016, "time": 26182.115121364594, "episode/length": 288.0, "episode/score": 0.056061346960177616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056061346960177616}
{"step": 825080, "time": 26184.114411115646, "episode/length": 288.0, "episode/score": 0.09816637398830608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09816637398830608}
{"step": 825312, "time": 26191.484011888504, "episode/length": 28.0, "episode/score": 0.9470998758146152, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.03459985278766453}
{"step": 825360, "time": 26192.959772348404, "episode/length": 100.0, "episode/score": 0.7511825000010504, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.06368248067610693}
{"step": 825976, "time": 26211.738206386566, "episode/length": 288.0, "episode/score": 0.07377875008273804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07377875008273804}
{"step": 826304, "time": 26222.00159597397, "episode/length": 288.0, "episode/score": 0.09951343750549313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09951343750549313}
{"step": 826624, "time": 26231.890321731567, "episode/length": 288.0, "episode/score": 0.08906709006407709, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08906709006407709}
{"step": 826656, "time": 26232.87467122078, "episode/length": 43.0, "episode/score": 0.8936796004759344, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.028054553292804485}
{"step": 826817, "time": 26238.32880139351, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1345316057828203, "train/action_min": 0.0, "train/action_std": 1.7455984228220418, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011156038161198697, "train/actor_opt_grad_steps": 50580.0, "train/actor_opt_loss": -9.306113394510806, "train/adv_mag": 1.020461268760451, "train/adv_max": 0.3803459256138634, "train/adv_mean": 0.002595462013223323, "train/adv_min": -0.9750693778895853, "train/adv_std": 0.03332578278048404, "train/cont_avg": 0.9952153344849246, "train/cont_loss_mean": 0.0176989235330242, "train/cont_loss_std": 0.24481978506111918, "train/cont_neg_acc": 0.2860512940503245, "train/cont_neg_loss": 2.937808032746628, "train/cont_pos_acc": 0.999832368376267, "train/cont_pos_loss": 0.003332393026873282, "train/cont_pred": 0.9954752661474985, "train/cont_rate": 0.9952153344849246, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16506372349589465, "train/extr_critic_critic_opt_grad_steps": 50580.0, "train/extr_critic_critic_opt_loss": 11688.303529365578, "train/extr_critic_mag": 1.3915707933243795, "train/extr_critic_max": 1.3915707933243795, "train/extr_critic_mean": 1.3044633589797283, "train/extr_critic_min": 1.0370994830251339, "train/extr_critic_std": 0.0211899369281141, "train/extr_return_normed_mag": 1.0223390960214127, "train/extr_return_normed_max": 0.30261189853725723, "train/extr_return_normed_mean": 0.039400124576073794, "train/extr_return_normed_min": -0.9774168532098358, "train/extr_return_normed_std": 0.04002142721908775, "train/extr_return_rate": 0.999122935323859, "train/extr_return_raw_mag": 1.5702706233939934, "train/extr_return_raw_max": 1.5702706233939934, "train/extr_return_raw_mean": 1.3070589220104505, "train/extr_return_raw_min": 0.2902418716469003, "train/extr_return_raw_std": 0.040021427265887886, "train/extr_reward_mag": 0.35131133381445806, "train/extr_reward_max": 0.35131133381445806, "train/extr_reward_mean": 0.002254764193460701, "train/extr_reward_min": 5.371007488001531e-06, "train/extr_reward_std": 0.00889033377966165, "train/image_loss_mean": 0.10066843390389903, "train/image_loss_std": 0.10607487352649171, "train/model_loss_mean": 0.7438564018987531, "train/model_loss_std": 0.40926680972228696, "train/model_opt_grad_norm": 18.987340289743702, "train/model_opt_grad_steps": 50534.497487437184, "train/model_opt_loss": 3775.7480689580716, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5075.37688442211, "train/policy_entropy_mag": 1.2897441465051929, "train/policy_entropy_max": 1.2897441465051929, "train/policy_entropy_mean": 0.1025833410384068, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1312948935220589, "train/policy_logprob_mag": 6.55108025085986, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1020931825041771, "train/policy_logprob_min": -6.55108025085986, "train/policy_logprob_std": 0.6367086423701377, "train/policy_randomness_mag": 0.6627974162748711, "train/policy_randomness_max": 0.6627974162748711, "train/policy_randomness_mean": 0.05271741004670086, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06747223178495713, "train/post_ent_mag": 2.920610069629535, "train/post_ent_max": 2.920610069629535, "train/post_ent_mean": 2.9127779689865494, "train/post_ent_min": 2.9077528265852424, "train/post_ent_std": 0.0027224854414056444, "train/prior_ent_mag": 3.26401610709914, "train/prior_ent_max": 3.26401610709914, "train/prior_ent_mean": 2.8218267395268732, "train/prior_ent_min": 2.811576606041223, "train/prior_ent_std": 0.023405935460860706, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0016558772769356474, "train/reward_loss_mean": 0.02548901859820638, "train/reward_loss_std": 0.17604745817768513, "train/reward_max_data": 0.6475950045249046, "train/reward_max_pred": 0.20600909264243428, "train/reward_neg_acc": 0.9997689448409344, "train/reward_neg_loss": 0.01767282457039434, "train/reward_pos_acc": 0.2173410420645179, "train/reward_pos_loss": 4.2080996153671615, "train/reward_pred": 0.0013257518665743383, "train/reward_rate": 0.001889329459798995, "train_stats/mean_log_entropy": 0.08263731487425027, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.024484090507030487, "report/cont_loss_std": 0.3037884533405304, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.6154351234436035, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0033193512354046106, "report/cont_pred": 0.9963915348052979, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08916975557804108, "report/image_loss_std": 0.09670484811067581, "report/model_loss_mean": 0.7453934550285339, "report/model_loss_std": 0.4858192503452301, "report/post_ent_mag": 2.90474271774292, "report/post_ent_max": 2.90474271774292, "report/post_ent_mean": 2.899214744567871, "report/post_ent_min": 2.8964951038360596, "report/post_ent_std": 0.0016902901697903872, "report/prior_ent_mag": 2.9918041229248047, "report/prior_ent_max": 2.9918041229248047, "report/prior_ent_mean": 2.822077751159668, "report/prior_ent_min": 2.8116493225097656, "report/prior_ent_std": 0.019668128341436386, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0033568362705409527, "report/reward_loss_mean": 0.03173957020044327, "report/reward_loss_std": 0.21294710040092468, "report/reward_max_data": 0.8411805629730225, "report/reward_max_pred": 0.07586503028869629, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.018715785816311836, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.3528037071228027, "report/reward_pred": 0.0018916077679023147, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.01761694625020027, "eval/cont_loss_std": 0.4249434471130371, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 13.546875953674316, "eval/cont_pos_acc": 0.9980449676513672, "eval/cont_pos_loss": 0.004391862545162439, "eval/cont_pred": 0.9962537288665771, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.14494888484477997, "eval/image_loss_std": 0.13561375439167023, "eval/model_loss_mean": 0.7664788961410522, "eval/model_loss_std": 0.44767478108406067, "eval/post_ent_mag": 2.905035972595215, "eval/post_ent_max": 2.905035972595215, "eval/post_ent_mean": 2.899333953857422, "eval/post_ent_min": 2.896212100982666, "eval/post_ent_std": 0.0018664855742827058, "eval/prior_ent_mag": 2.9905824661254883, "eval/prior_ent_max": 2.9905824661254883, "eval/prior_ent_mean": 2.821362018585205, "eval/prior_ent_min": 2.811776638031006, "eval/prior_ent_std": 0.01487091276794672, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.003913021646440029, "eval/reward_loss_std": 0.009675462730228901, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.13921141624450684, "eval/reward_neg_acc": 0.9990234375, "eval/reward_neg_loss": 0.003913021646440029, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.001012421678751707, "eval/reward_rate": 0.0, "replay/size": 826313.0, "replay/inserts": 31912.0, "replay/samples": 31904.0, "replay/insert_wait_avg": 1.1610130105409506e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.714003832672639e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4232.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.684909719600569e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9992144107819, "timer/env.step_count": 3989.0, "timer/env.step_total": 34.319220304489136, "timer/env.step_frac": 0.03431924726531976, "timer/env.step_avg": 0.008603464603782687, "timer/env.step_min": 0.0071866512298583984, "timer/env.step_max": 0.04000687599182129, "timer/replay._sample_count": 31904.0, "timer/replay._sample_total": 15.961427450180054, "timer/replay._sample_frac": 0.015961439989315214, "timer/replay._sample_avg": 0.0005002954943010298, "timer/replay._sample_min": 0.0003962516784667969, "timer/replay._sample_max": 0.032854318618774414, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4518.0, "timer/agent.policy_total": 38.0552020072937, "timer/agent.policy_frac": 0.038055231903073576, "timer/agent.policy_avg": 0.008423019479259341, "timer/agent.policy_min": 0.007417917251586914, "timer/agent.policy_max": 0.06467938423156738, "timer/dataset_train_count": 1994.0, "timer/dataset_train_total": 0.20703506469726562, "timer/dataset_train_frac": 0.000207035227341908, "timer/dataset_train_avg": 0.00010382901940685337, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.00030684471130371094, "timer/agent.train_count": 1994.0, "timer/agent.train_total": 881.1421933174133, "timer/agent.train_frac": 0.8811428855337639, "timer/agent.train_avg": 0.441896787019766, "timer/agent.train_min": 0.42899036407470703, "timer/agent.train_max": 0.5937960147857666, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4762294292449951, "timer/agent.report_frac": 0.000476229803365994, "timer/agent.report_avg": 0.23811471462249756, "timer/agent.report_min": 0.23028039932250977, "timer/agent.report_max": 0.24594902992248535, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.290178976330692e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 31.911449730968048}
{"step": 826880, "time": 26240.489297151566, "episode/length": 112.0, "episode/score": 0.7242314755384314, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.07423151751197565}
{"step": 827176, "time": 26249.34550333023, "episode/length": 288.0, "episode/score": 0.07902252269957444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07902252269957444}
{"step": 827256, "time": 26251.800373077393, "episode/length": 242.0, "episode/score": 0.2779337985791699, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.03418379116351389}
{"step": 827312, "time": 26253.762350082397, "episode/length": 288.0, "episode/score": 0.05055176216080781, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05055176216080781}
{"step": 827328, "time": 26254.257398366928, "episode/length": 288.0, "episode/score": 0.06228888363148144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06228888363148144}
{"step": 827512, "time": 26260.276727437973, "episode/length": 78.0, "episode/score": 0.79829068719107, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0420406490301275}
{"step": 827672, "time": 26265.183365345, "episode/length": 288.0, "episode/score": 0.08157114912773977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08157114912773977}
{"step": 827880, "time": 26271.559009313583, "episode/length": 152.0, "episode/score": 0.5654429472949687, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.04044295181188318}
{"step": 828264, "time": 26283.363961696625, "episode/length": 47.0, "episode/score": 0.8809785823387983, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.02785357678578748}
{"step": 828312, "time": 26284.89333486557, "episode/length": 131.0, "episode/score": 0.649237730595928, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.058612713121988236}
{"step": 828368, "time": 26286.92447733879, "episode/length": 106.0, "episode/score": 0.7123812862758996, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.043631298633385995}
{"step": 828536, "time": 26291.893439292908, "episode/length": 152.0, "episode/score": 0.6114508481003895, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.08645084662191493}
{"step": 828696, "time": 26296.805806159973, "episode/length": 53.0, "episode/score": 0.8671214562100431, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.03274643280474265}
{"step": 828784, "time": 26299.73977971077, "episode/length": 30.0, "episode/score": 0.9272749217893761, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.021024908401614084}
{"step": 828848, "time": 26301.708138227463, "episode/length": 277.0, "episode/score": 0.22869396885528204, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.09431895724867445}
{"step": 828864, "time": 26302.203575849533, "episode/length": 68.0, "episode/score": 0.8247745104788464, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0372744732492265}
{"step": 828992, "time": 26306.152634382248, "episode/length": 36.0, "episode/score": 0.9066020947384459, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.01910209327161283}
{"step": 829152, "time": 26311.108298540115, "episode/length": 97.0, "episode/score": 0.7572008289934047, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.06032588115328963}
{"step": 829296, "time": 26315.68493795395, "episode/length": 53.0, "episode/score": 0.864750575289122, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.030375543269087757}
{"step": 829488, "time": 26321.604773521423, "episode/length": 288.0, "episode/score": 0.09366575765210428, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09366575765210428}
{"step": 829608, "time": 26325.08553814888, "episode/length": 94.0, "episode/score": 0.7599590793162747, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.053709067613624484}
{"step": 829640, "time": 26326.075854063034, "episode/length": 288.0, "episode/score": 0.04460687362285398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04460687362285398}
{"step": 829856, "time": 26332.945216178894, "episode/length": 107.0, "episode/score": 0.712929750259832, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.04730478920657788}
{"step": 829984, "time": 26336.908676624298, "episode/length": 288.0, "episode/score": 0.08774016852959221, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08774016852959221}
{"step": 830024, "time": 26338.67892408371, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 830024, "time": 26338.825513362885, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 830024, "time": 26339.370131731033, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 830024, "time": 26339.47480249405, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 830024, "time": 26339.547612905502, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 830024, "time": 26339.724739551544, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 830024, "time": 26341.043306350708, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 830024, "time": 26341.483238220215, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 830272, "time": 26349.427218914032, "episode/length": 78.0, "episode/score": 0.7945738530612516, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.03832385563111984}
{"step": 830464, "time": 26355.316019296646, "episode/length": 163.0, "episode/score": 0.5819879661920595, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.09136296876192773}
{"step": 830672, "time": 26361.707065343857, "episode/length": 147.0, "episode/score": 0.5989295789992184, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.05830459639457786}
{"step": 831096, "time": 26374.558284044266, "episode/length": 102.0, "episode/score": 0.7229668091158032, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.04171682579811886}
{"step": 831096, "time": 26374.56553006172, "episode/length": 288.0, "episode/score": 0.041525639978146955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041525639978146955}
{"step": 831608, "time": 26390.466717004776, "episode/length": 288.0, "episode/score": 0.06874755407216071, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06874755407216071}
{"step": 831920, "time": 26400.34570837021, "episode/length": 288.0, "episode/score": 0.08863245550253396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08863245550253396}
{"step": 832168, "time": 26407.91016435623, "episode/length": 288.0, "episode/score": 0.028017903003274114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028017903003274114}
{"step": 832216, "time": 26409.39339709282, "episode/length": 5.0, "episode/score": 0.9927758994745091, "episode/reward_rate": 0.16666666666666666, "episode/intrinsic_return": 0.008400901104323566}
{"step": 832296, "time": 26411.867065906525, "episode/length": 288.0, "episode/score": 0.06777126984951565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06777126984951565}
{"step": 832448, "time": 26416.78243470192, "episode/length": 104.0, "episode/score": 0.717456706845951, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.04245670784712274}
{"step": 832776, "time": 26426.675528287888, "episode/length": 288.0, "episode/score": 0.04651783830485101, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04651783830485101}
{"step": 832984, "time": 26433.069635629654, "episode/length": 288.0, "episode/score": 0.038147510165742915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038147510165742915}
{"step": 833136, "time": 26438.08622789383, "episode/length": 151.0, "episode/score": 0.5919896335044541, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.06386464705519757}
{"step": 833408, "time": 26446.467797756195, "episode/length": 288.0, "episode/score": 0.1052203067197297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1052203067197297}
{"step": 833408, "time": 26446.474932193756, "episode/length": 288.0, "episode/score": 0.11958823861880319, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11958823861880319}
{"step": 833544, "time": 26450.436145544052, "episode/length": 69.0, "episode/score": 0.8062736945125835, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.02189868422146901}
{"step": 833760, "time": 26457.348747968674, "episode/length": 122.0, "episode/score": 0.694285551835037, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.07553557730670946}
{"step": 833840, "time": 26459.814150333405, "episode/length": 53.0, "episode/score": 0.8520492479715358, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.01767420777332518}
{"step": 833880, "time": 26460.850010871887, "episode/length": 92.0, "episode/score": 0.7441883605147268, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.03168838668489116}
{"step": 834080, "time": 26467.376606941223, "episode/length": 203.0, "episode/score": 0.4478317985785907, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.08220681746115588}
{"step": 834168, "time": 26469.865704774857, "episode/length": 35.0, "episode/score": 0.913373547637093, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.02274856055919372}
{"step": 834528, "time": 26481.185386896133, "episode/length": 288.0, "episode/score": 0.04607500698057265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04607500698057265}
{"step": 834536, "time": 26481.218323946, "episode/length": 56.0, "episode/score": 0.8538037630805775, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.02880377581641369}
{"step": 834608, "time": 26483.648022651672, "episode/length": 288.0, "episode/score": 0.03138186738897275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03138186738897275}
{"step": 834744, "time": 26487.670496463776, "episode/length": 166.0, "episode/score": 0.5670591621299081, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.08580915973175252}
{"step": 834776, "time": 26488.681353330612, "episode/length": 126.0, "episode/score": 0.660105392800233, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.053855405536069156}
{"step": 834848, "time": 26491.182284593582, "episode/length": 125.0, "episode/score": 0.6805493172921615, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.07117430297307692}
{"step": 835368, "time": 26507.33793735504, "episode/length": 103.0, "episode/score": 0.7247868355093487, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.04666182458959156}
{"step": 835560, "time": 26513.343410730362, "episode/length": 88.0, "episode/score": 0.7547074642588996, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.029707411778872483}
{"step": 835560, "time": 26513.34947705269, "episode/length": 97.0, "episode/score": 0.7638309151607245, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.06695592468349787}
{"step": 835696, "time": 26518.321602344513, "episode/length": 118.0, "episode/score": 0.6951093245033917, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0638593135836345}
{"step": 835856, "time": 26523.340843439102, "episode/length": 288.0, "episode/score": 0.10234905259835614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10234905259835614}
{"step": 835880, "time": 26523.874005794525, "episode/length": 63.0, "episode/score": 0.8573527708251731, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.054227727658371805}
{"step": 836136, "time": 26532.014882802963, "episode/length": 71.0, "episode/score": 0.8066172290202758, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.028492241377762184}
{"step": 836160, "time": 26532.996470212936, "episode/length": 74.0, "episode/score": 0.7953830399183062, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.02663302843393467}
{"step": 836480, "time": 26542.838226795197, "episode/length": 288.0, "episode/score": 0.0501434147429336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0501434147429336}
{"step": 836728, "time": 26550.24143719673, "episode/length": 274.0, "episode/score": 0.20539246914245268, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.06164247270476153}
{"step": 836920, "time": 26556.266924142838, "episode/length": 288.0, "episode/score": 0.08364253180991454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08364253180991454}
{"step": 836976, "time": 26558.203607559204, "episode/length": 159.0, "episode/score": 0.5621777366345668, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.059052725528545125}
{"step": 836976, "time": 26558.20912218094, "episode/length": 101.0, "episode/score": 0.7548132924628135, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.07043830519864969}
{"step": 837192, "time": 26564.606990098953, "episode/length": 88.0, "episode/score": 0.7487073419403032, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0237073037793607}
{"step": 837216, "time": 26565.565211057663, "episode/length": 29.0, "episode/score": 0.9248352174872707, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.015460176171472995}
{"step": 837272, "time": 26567.07954478264, "episode/length": 67.0, "episode/score": 0.827385749786572, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0367607593093453}
{"step": 837776, "time": 26582.71604824066, "episode/length": 69.0, "episode/score": 0.8028377170944623, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.018462691785771312}
{"step": 838048, "time": 26591.136795520782, "episode/length": 106.0, "episode/score": 0.7056249682315183, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.03687497197427092}
{"step": 838168, "time": 26594.568821191788, "episode/length": 288.0, "episode/score": 0.04333664192870401, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04333664192870401}
{"step": 838192, "time": 26595.54950118065, "episode/length": 288.0, "episode/score": 0.034439903242969194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034439903242969194}
{"step": 838200, "time": 26595.58046603203, "episode/length": 52.0, "episode/score": 0.8661452730630117, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.028645288726693252}
{"step": 838448, "time": 26603.412435293198, "episode/length": 288.0, "episode/score": 0.07472709594219396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07472709594219396}
{"step": 838752, "time": 26612.742998361588, "episode/length": 37.0, "episode/score": 0.9054899025989016, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.021114897045890757}
{"step": 838856, "time": 26615.850868463516, "episode/length": 81.0, "episode/score": 0.7746893503566525, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.02781433893630947}
{"step": 838856, "time": 26615.85736465454, "episode/length": 197.0, "episode/score": 0.46794711056941196, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.08357209744940519}
{"step": 838984, "time": 26619.782016277313, "episode/length": 116.0, "episode/score": 0.684981197877164, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.047481201619916646}
{"step": 839232, "time": 26627.657120227814, "episode/length": 288.0, "episode/score": 0.058814793242731866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058814793242731866}
{"step": 839240, "time": 26627.690789222717, "episode/length": 133.0, "episode/score": 0.6197761809966096, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.03540117729460235}
{"step": 839288, "time": 26629.17024731636, "episode/length": 288.0, "episode/score": 0.05656241061376477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05656241061376477}
{"step": 839600, "time": 26639.180298805237, "episode/length": 105.0, "episode/score": 0.720396839023806, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.04852183946036348}
{"step": 839768, "time": 26644.12997865677, "episode/length": 113.0, "episode/score": 0.6828540515266468, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.03597905184096817}
{"step": 839992, "time": 26651.139313936234, "episode/length": 87.0, "episode/score": 0.758580272736026, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.030455289418341636}
{"step": 840008, "time": 26652.05704689026, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 840008, "time": 26652.339977025986, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 840008, "time": 26652.59221792221, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 840008, "time": 26652.830439567566, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 840008, "time": 26653.176466464996, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 840008, "time": 26653.212914943695, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 840008, "time": 26653.68123269081, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 840008, "time": 26654.060522794724, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 840024, "time": 26654.559514522552, "episode/length": 129.0, "episode/score": 0.6202123183010144, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.02333729206100088}
{"step": 840504, "time": 26669.316154956818, "episode/length": 288.0, "episode/score": 0.06202353279059025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06202353279059025}
{"step": 840504, "time": 26669.32294869423, "episode/length": 63.0, "episode/score": 0.8243836146773447, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.021258614991666036}
{"step": 840576, "time": 26671.7471203804, "episode/length": 8.0, "episode/score": 0.9799203748809759, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.004920354415162365}
{"step": 840736, "time": 26676.7726790905, "episode/length": 88.0, "episode/score": 0.7462628054430525, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.02126279973288092}
{"step": 840768, "time": 26677.777003765106, "episode/length": 124.0, "episode/score": 0.6776946944602287, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.06519469764418773}
{"step": 841168, "time": 26690.017645597458, "episode/length": 288.0, "episode/score": 0.06536473093660788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06536473093660788}
{"step": 841544, "time": 26701.297477960587, "episode/length": 288.0, "episode/score": 0.03543309940477002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03543309940477002}
{"step": 841552, "time": 26701.790437221527, "episode/length": 288.0, "episode/score": 0.06250068383712915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06250068383712915}
{"step": 841696, "time": 26706.309505224228, "episode/length": 148.0, "episode/score": 0.5806444950243304, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.043144484351955725}
{"step": 841736, "time": 26707.339297533035, "episode/length": 144.0, "episode/score": 0.5988795331752499, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.04887953635920894}
{"step": 841912, "time": 26712.742211818695, "episode/length": 288.0, "episode/score": 0.06818559081210651, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06818559081210651}
{"step": 842104, "time": 26718.64932823181, "episode/length": 116.0, "episode/score": 0.6594943644590785, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.02199437659828618}
{"step": 842192, "time": 26721.588628530502, "episode/length": 79.0, "episode/score": 0.7900797388261367, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.03695472045870929}
{"step": 842384, "time": 26727.494511842728, "episode/length": 104.0, "episode/score": 0.713067332797209, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0380673242523244}
{"step": 842416, "time": 26728.482833623886, "episode/length": 89.0, "episode/score": 0.752958030166667, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.031083021621782336}
{"step": 842552, "time": 26732.470362186432, "episode/length": 55.0, "episode/score": 0.8411405707115591, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.013015551386615698}
{"step": 842664, "time": 26736.03747868538, "episode/length": 58.0, "episode/score": 0.8396301311634033, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.02088012049102872}
{"step": 842712, "time": 26737.54544687271, "episode/length": 99.0, "episode/score": 0.7536325766441223, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.06300755133543134}
{"step": 842960, "time": 26745.421819210052, "episode/length": 71.0, "episode/score": 0.8041385759375999, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.026013564517256782}
{"step": 843000, "time": 26746.452075958252, "episode/length": 35.0, "episode/score": 0.9090387574674423, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.01841373214710984}
{"step": 843008, "time": 26746.921499490738, "episode/length": 56.0, "episode/score": 0.8329299428731929, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.007929955230679298}
{"step": 843048, "time": 26747.935132741928, "episode/length": 288.0, "episode/score": 0.03844538941746123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03844538941746123}
{"step": 843080, "time": 26748.92545557022, "episode/length": 288.0, "episode/score": 0.0787166312379668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0787166312379668}
{"step": 843384, "time": 26758.268554210663, "episode/length": 120.0, "episode/score": 0.673312506337254, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.04831252446894041}
{"step": 843448, "time": 26760.217705726624, "episode/length": 54.0, "episode/score": 0.8480318461423622, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.01678182083367119}
{"step": 843456, "time": 26760.684707164764, "episode/length": 46.0, "episode/score": 0.8785187147128681, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.022268753045523226}
{"step": 843632, "time": 26766.231347322464, "episode/length": 83.0, "episode/score": 0.781781680615893, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.04115664338627312}
{"step": 843696, "time": 26768.222203969955, "episode/length": 86.0, "episode/score": 0.762774003279219, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0315240383085893}
{"step": 843744, "time": 26769.71826672554, "episode/length": 134.0, "episode/score": 0.6408827771936672, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.059632765491016926}
{"step": 844024, "time": 26778.671080589294, "episode/length": 79.0, "episode/score": 0.76961677275699, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.016491756746972897}
{"step": 844048, "time": 26779.634586811066, "episode/length": 288.0, "episode/score": 0.06312077660101068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06312077660101068}
{"step": 844120, "time": 26781.655657052994, "episode/length": 133.0, "episode/score": 0.6344675304668499, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.05009253078117126}
{"step": 844224, "time": 26785.073209524155, "episode/length": 95.0, "episode/score": 0.7535136956673796, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.05038870774546922}
{"step": 844376, "time": 26789.51132583618, "episode/length": 115.0, "episode/score": 0.6871482264871247, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.04652321932758241}
{"step": 844392, "time": 26790.00393152237, "episode/length": 86.0, "episode/score": 0.7531139474447173, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.021863951187469866}
{"step": 844544, "time": 26794.877123355865, "episode/length": 52.0, "episode/score": 0.8628320843035908, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.025332120223538368}
{"step": 844576, "time": 26795.944692373276, "episode/length": 65.0, "episode/score": 0.811505598478675, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.014630624890401123}
{"step": 844744, "time": 26800.88267469406, "episode/length": 89.0, "episode/score": 0.7633522243277184, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.04147723254664015}
{"step": 844792, "time": 26802.37538433075, "episode/length": 70.0, "episode/score": 0.7918848624901784, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.010634847297978922}
{"step": 844888, "time": 26805.35044360161, "episode/length": 61.0, "episode/score": 0.8280609851211693, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.018686015173784654}
{"step": 844952, "time": 26807.33957004547, "episode/length": 46.0, "episode/score": 0.8762650045269424, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.02001501666615013}
{"step": 845088, "time": 26811.7523021698, "episode/length": 24.0, "episode/score": 0.9388361769062499, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0138361891415002}
{"step": 845256, "time": 26816.73792243004, "episode/length": 88.0, "episode/score": 0.7691273572691557, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.04412732003953579}
{"step": 845544, "time": 26825.73809814453, "episode/length": 73.0, "episode/score": 0.8209435950480497, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.049068599524218826}
{"step": 845640, "time": 26828.704977989197, "episode/length": 105.0, "episode/score": 0.7329865464221257, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.06111154664040441}
{"step": 845672, "time": 26829.6927587986, "episode/length": 115.0, "episode/score": 0.6839379109341053, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.04331288849505199}
{"step": 845760, "time": 26832.6459608078, "episode/length": 172.0, "episode/score": 0.5468278123555024, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.08432779821686154}
{"step": 845944, "time": 26838.09253668785, "episode/length": 288.0, "episode/score": 0.06872235065986843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06872235065986843}
{"step": 845968, "time": 26839.051496744156, "episode/length": 36.0, "episode/score": 0.9087033017908084, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.021203325789826977}
{"step": 846056, "time": 26841.55138874054, "episode/length": 288.0, "episode/score": 0.08827497754180058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08827497754180058}
{"step": 846208, "time": 26846.445900440216, "episode/length": 32.0, "episode/score": 0.9282042973970874, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.028204314079403048}
{"step": 846224, "time": 26846.942672014236, "episode/length": 141.0, "episode/score": 0.6173670983924922, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.057992103153878816}
{"step": 846288, "time": 26848.910166740417, "episode/length": 92.0, "episode/score": 0.7777481285909289, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.06524816560227009}
{"step": 846768, "time": 26863.74174976349, "episode/length": 125.0, "episode/score": 0.6924075271844004, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.08303255029284173}
{"step": 847128, "time": 26874.538412570953, "episode/length": 114.0, "episode/score": 0.6921320668832891, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.04838208328038718}
{"step": 847144, "time": 26875.033243894577, "episode/length": 135.0, "episode/score": 0.6517722815910929, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.07364730173094358}
{"step": 847152, "time": 26875.52174425125, "episode/length": 107.0, "episode/score": 0.7153749476178746, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0497499673706443}
{"step": 847264, "time": 26878.961398124695, "episode/length": 61.0, "episode/score": 0.8305308989272362, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.02115592292625479}
{"step": 847288, "time": 26879.486429452896, "episode/length": 132.0, "episode/score": 0.660224774433118, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.07272480165102024}
{"step": 847568, "time": 26888.436287879944, "episode/length": 288.0, "episode/score": 0.052094140899441754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052094140899441754}
{"step": 847672, "time": 26891.44850540161, "episode/length": 65.0, "episode/score": 0.827253483154152, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.030378483314223104}
{"step": 847800, "time": 26895.38481593132, "episode/length": 66.0, "episode/score": 0.8259024235645143, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.032152453617129595}
{"step": 847848, "time": 26896.854157686234, "episode/length": 89.0, "episode/score": 0.7617342015464033, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.03985921584802554}
{"step": 847952, "time": 26900.280376434326, "episode/length": 288.0, "episode/score": 0.07713800782278213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07713800782278213}
{"step": 848120, "time": 26905.244473457336, "episode/length": 103.0, "episode/score": 0.7079355101756732, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.029810486552094062}
{"step": 848280, "time": 26910.187009096146, "episode/length": 288.0, "episode/score": 0.07412173152340529, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07412173152340529}
{"step": 848288, "time": 26910.65759205818, "episode/length": 89.0, "episode/score": 0.7718021000908948, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.049927108309816504}
{"step": 848416, "time": 26914.59100461006, "episode/length": 70.0, "episode/score": 0.8259309983695289, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.044681012528542396}
{"step": 848704, "time": 26923.598914384842, "episode/length": 35.0, "episode/score": 0.9054300264143649, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.014805052636916116}
{"step": 848944, "time": 26930.974905014038, "episode/length": 102.0, "episode/score": 0.7087845856275976, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.027534627601141892}
{"step": 849032, "time": 26933.44844341278, "episode/length": 134.0, "episode/score": 0.6620286825121298, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.08077867396724514}
{"step": 849104, "time": 26935.89121365547, "episode/length": 49.0, "episode/score": 0.8709026173623897, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.024027615511386102}
{"step": 849464, "time": 26946.96711874008, "episode/length": 288.0, "episode/score": 0.0572877778001839, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0572877778001839}
{"step": 849568, "time": 26950.435495853424, "episode/length": 160.0, "episode/score": 0.5739840793036137, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.07398407952189245}
{"step": 849712, "time": 26954.95365524292, "episode/length": 84.0, "episode/score": 0.7892853051094448, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.05178531960024202}
{"step": 849752, "time": 26955.987756729126, "episode/length": 35.0, "episode/score": 0.907779563083011, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0171545478908115}
{"step": 849984, "time": 26963.4883351326, "episode/length": 288.0, "episode/score": 0.08318234637403066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08318234637403066}
{"step": 850056, "time": 26965.544502735138, "episode/length": 118.0, "episode/score": 0.6858238141389847, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.05457380842881321}
{"step": 850072, "time": 26966.051743507385, "episode/length": 62.0, "episode/score": 0.8253452795318594, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.01909531344364268}
{"step": 850096, "time": 26967.568397521973, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 850096, "time": 26967.622709274292, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 850096, "time": 26967.836894989014, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 850096, "time": 26967.98847937584, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 850096, "time": 26968.301398038864, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 850096, "time": 26968.562322616577, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 850096, "time": 26968.599469661713, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 850096, "time": 26968.84467768669, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 850112, "time": 26969.34899520874, "episode/length": 288.0, "episode/score": 0.104304047447215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.104304047447215}
{"step": 850232, "time": 26972.88143181801, "episode/length": 59.0, "episode/score": 0.8391055022576666, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.023480503258838326}
{"step": 850312, "time": 26975.479135751724, "episode/length": 40.0, "episode/score": 0.9186943883763661, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.043694390704672514}
{"step": 850496, "time": 26981.380806684494, "episode/length": 54.0, "episode/score": 0.8783964665650501, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.047146456273935655}
{"step": 850600, "time": 26984.372831583023, "episode/length": 288.0, "episode/score": 0.0921083241676115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0921083241676115}
{"step": 850616, "time": 26984.870502233505, "episode/length": 67.0, "episode/score": 0.8396126005199562, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.04898759572364497}
{"step": 850680, "time": 26986.856510162354, "episode/length": 70.0, "episode/score": 0.8186647572492802, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.03741477017138095}
{"step": 850688, "time": 26987.32441496849, "episode/length": 121.0, "episode/score": 0.7199229921579331, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.09804800570867656}
{"step": 850840, "time": 26991.75745844841, "episode/length": 75.0, "episode/score": 0.8166339645395055, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.05100893590133637}
{"step": 851072, "time": 26999.096373081207, "episode/length": 94.0, "episode/score": 0.7384591126337909, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.032209084356509265}
{"step": 851256, "time": 27004.52406167984, "episode/length": 288.0, "episode/score": 0.06957938544275066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06957938544275066}
{"step": 851432, "time": 27010.01430773735, "episode/length": 93.0, "episode/score": 0.7377850760203728, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.028410035822162172}
{"step": 851472, "time": 27011.486753463745, "episode/length": 121.0, "episode/score": 0.7095139510706758, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.08763896531991122}
{"step": 851496, "time": 27012.008075475693, "episode/length": 100.0, "episode/score": 0.7434173099914005, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.05591731162121505}
{"step": 851720, "time": 27018.91561794281, "episode/length": 35.0, "episode/score": 0.9094295972281543, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.01880461015025503}
{"step": 851784, "time": 27020.881709575653, "episode/length": 88.0, "episode/score": 0.7913096832639894, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.06630967234423224}
{"step": 851960, "time": 27026.33159518242, "episode/length": 169.0, "episode/score": 0.5818677427291732, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.10999273243805874}
{"step": 852016, "time": 27028.77025461197, "episode/length": 94.0, "episode/score": 0.7682380242499676, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.061988013958853116}
{"step": 852192, "time": 27034.21989250183, "episode/length": 86.0, "episode/score": 0.7729779827714083, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.04172797833598452}
{"step": 852528, "time": 27044.691596746445, "episode/length": 131.0, "episode/score": 0.6577400877099535, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.06711510044578972}
{"step": 852600, "time": 27046.70257472992, "episode/length": 79.0, "episode/score": 0.788597249151735, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.03547223804571331}
{"step": 852928, "time": 27057.027903079987, "episode/length": 288.0, "episode/score": 0.0904754398084151, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0904754398084151}
{"step": 852960, "time": 27058.01571416855, "episode/length": 117.0, "episode/score": 0.6813986993051913, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.04702370679069645}
{"step": 853152, "time": 27063.940118551254, "episode/length": 288.0, "episode/score": 0.09772773959025471, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09772773959025471}
{"step": 853248, "time": 27067.004802703857, "episode/length": 80.0, "episode/score": 0.8007961806279127, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.050796182257727196}
{"step": 853432, "time": 27072.433668375015, "episode/length": 112.0, "episode/score": 0.6969368851664512, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.04693689468922457}
{"step": 853536, "time": 27075.845523118973, "episode/length": 75.0, "episode/score": 0.7963203533590786, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.030695339039993996}
{"step": 853848, "time": 27085.250164985657, "episode/length": 110.0, "episode/score": 0.7256631057164213, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.06941308936006862}
{"step": 853848, "time": 27085.25584936142, "episode/length": 86.0, "episode/score": 0.805177937666258, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.07392792094901779}
{"step": 854032, "time": 27091.160997629166, "episode/length": 288.0, "episode/score": 0.09989495196282405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09989495196282405}
{"step": 854096, "time": 27093.11141037941, "episode/length": 288.0, "episode/score": 0.07434342400870264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07434342400870264}
{"step": 854096, "time": 27093.11684370041, "episode/length": 82.0, "episode/score": 0.7747606323971468, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.031010626844135913}
{"step": 854312, "time": 27099.615839004517, "episode/length": 132.0, "episode/score": 0.6420524302793638, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.054552454936128925}
{"step": 854504, "time": 27105.495777130127, "episode/length": 288.0, "episode/score": 0.06465992199946413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06465992199946413}
{"step": 854600, "time": 27108.451110363007, "episode/length": 35.0, "episode/score": 0.9162958881418035, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.02567088895671077}
{"step": 854608, "time": 27108.920889616013, "episode/length": 94.0, "episode/score": 0.745632065930522, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.039382034684649625}
{"step": 854624, "time": 27109.417288780212, "episode/length": 65.0, "episode/score": 0.8140743997569189, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.017199370362050104}
{"step": 854696, "time": 27111.42720389366, "episode/length": 144.0, "episode/score": 0.6141376274792947, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.06413760123928114}
{"step": 855304, "time": 27130.165385723114, "episode/length": 86.0, "episode/score": 0.7625536956077212, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.031303691172297476}
{"step": 855464, "time": 27135.0749232769, "episode/length": 104.0, "episode/score": 0.7134349457776352, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.03843493429326372}
{"step": 855544, "time": 27137.54741001129, "episode/length": 117.0, "episode/score": 0.6987500163797904, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.06437502386529559}
{"step": 855696, "time": 27142.469448804855, "episode/length": 207.0, "episode/score": 0.45319834288989114, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.10007334339047702}
{"step": 855800, "time": 27145.45088481903, "episode/length": 137.0, "episode/score": 0.6334930728178279, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.061618080303333045}
{"step": 855872, "time": 27147.87078666687, "episode/length": 50.0, "episode/score": 0.8713643570868044, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.02761434276771979}
{"step": 856160, "time": 27156.815735578537, "episode/length": 288.0, "episode/score": 0.09380688145006388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09380688145006388}
{"step": 856304, "time": 27161.25566148758, "episode/length": 94.0, "episode/score": 0.7461012541111813, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.03985122880249037}
{"step": 856304, "time": 27161.26518368721, "episode/length": 124.0, "episode/score": 0.6835819836114752, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.07108194229567744}
{"step": 856408, "time": 27164.22001862526, "episode/length": 288.0, "episode/score": 0.05091760761661135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05091760761661135}
{"step": 856496, "time": 27167.1627702713, "episode/length": 41.0, "episode/score": 0.9076268248006727, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.035751822402517064}
{"step": 856800, "time": 27176.497712135315, "episode/length": 124.0, "episode/score": 0.6656568123128181, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.05315678106694577}
{"step": 856816, "time": 27176.995532989502, "episode/length": 288.0, "episode/score": 0.11168260951444609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11168260951444609}
{"step": 856888, "time": 27178.995809316635, "episode/length": 126.0, "episode/score": 0.6475931205143297, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.04134312425708231}
{"step": 857024, "time": 27183.39253592491, "episode/length": 65.0, "episode/score": 0.8350647994143401, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.03818979123616373}
{"step": 857064, "time": 27184.401702165604, "episode/length": 94.0, "episode/score": 0.7615645846558436, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0553145655753724}
{"step": 857128, "time": 27186.513667821884, "episode/length": 102.0, "episode/score": 0.7544340626300254, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.07318406714693992}
{"step": 857392, "time": 27194.858452558517, "episode/length": 122.0, "episode/score": 0.6755311970880484, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.05678119758863431}
{"step": 857792, "time": 27207.16491627693, "episode/length": 112.0, "episode/score": 0.7137839105141666, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.06378391799967176}
{"step": 857832, "time": 27208.176839351654, "episode/length": 128.0, "episode/score": 0.6563129174130609, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.05631286417633419}
{"step": 857936, "time": 27211.616014003754, "episode/length": 113.0, "episode/score": 0.739250995903376, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.09237594872024602}
{"step": 858008, "time": 27213.610283374786, "episode/length": 288.0, "episode/score": 0.10392352625081003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10392352625081003}
{"step": 858080, "time": 27216.18123936653, "episode/length": 118.0, "episode/score": 0.6862127873250756, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.05496278362306839}
{"step": 858136, "time": 27217.69084095955, "episode/length": 164.0, "episode/score": 0.6057796030530653, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.11827957681305179}
{"step": 858312, "time": 27223.100346803665, "episode/length": 46.0, "episode/score": 0.8831833745645099, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.026933414803465894}
{"step": 858520, "time": 27229.47985458374, "episode/length": 85.0, "episode/score": 0.8036764613491414, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.06930148148899207}
{"step": 858552, "time": 27230.46121573448, "episode/length": 94.0, "episode/score": 0.7557996478363975, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.049549654047154945}
{"step": 858656, "time": 27233.85848069191, "episode/length": 64.0, "episode/score": 0.8271036229837136, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.027103585742452196}
{"step": 858785, "time": 27238.34588098526, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.144573059082031, "train/action_min": 0.0, "train/action_std": 1.7355298233032226, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009644246596144513, "train/actor_opt_grad_steps": 52575.0, "train/actor_opt_loss": -11.00556792318821, "train/adv_mag": 1.065808199942112, "train/adv_max": 0.32452906787395475, "train/adv_mean": 0.0014425253818939154, "train/adv_min": -1.032291187942028, "train/adv_std": 0.03178600777639076, "train/cont_avg": 0.9950634765625, "train/cont_loss_mean": 0.017680561707820744, "train/cont_loss_std": 0.24849507882492616, "train/cont_neg_acc": 0.30132756687700746, "train/cont_neg_loss": 2.92535440067295, "train/cont_pos_acc": 0.9999509662389755, "train/cont_pos_loss": 0.0032079823268577456, "train/cont_pred": 0.9953793188929558, "train/cont_rate": 0.9950634765625, "train/dyn_loss_mean": 1.0001915371418, "train/dyn_loss_std": 0.005302299163304269, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12036097311414778, "train/extr_critic_critic_opt_grad_steps": 52575.0, "train/extr_critic_critic_opt_loss": 13397.82416015625, "train/extr_critic_mag": 1.4723351001739502, "train/extr_critic_max": 1.4723351001739502, "train/extr_critic_mean": 1.3709506618976592, "train/extr_critic_min": 1.162516610622406, "train/extr_critic_std": 0.022785393092781304, "train/extr_return_normed_mag": 1.0676487946510316, "train/extr_return_normed_max": 0.30591671884059907, "train/extr_return_normed_mean": 0.03850392890628427, "train/extr_return_normed_min": -1.0207966214418411, "train/extr_return_normed_std": 0.039567787973210214, "train/extr_return_rate": 0.9994303813576698, "train/extr_return_raw_mag": 1.6398060262203216, "train/extr_return_raw_max": 1.6398060262203216, "train/extr_return_raw_mean": 1.3723933136463164, "train/extr_return_raw_min": 0.3130926859378815, "train/extr_return_raw_std": 0.039567787945270536, "train/extr_reward_mag": 0.32875764966011045, "train/extr_reward_max": 0.32875764966011045, "train/extr_reward_mean": 0.002268346557102632, "train/extr_reward_min": 5.435347557067871e-06, "train/extr_reward_std": 0.01001804822939448, "train/image_loss_mean": 0.10193909492343664, "train/image_loss_std": 0.10803450312465429, "train/model_loss_mean": 0.7458602917194367, "train/model_loss_std": 0.4163820767775178, "train/model_opt_grad_norm": 18.201406590938568, "train/model_opt_grad_steps": 52527.525, "train/model_opt_loss": 3823.7092553710936, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5125.0, "train/policy_entropy_mag": 1.278183245062828, "train/policy_entropy_max": 1.278183245062828, "train/policy_entropy_mean": 0.10070291195064783, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12775405060499906, "train/policy_logprob_mag": 6.55108026266098, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10025512360036373, "train/policy_logprob_min": -6.55108026266098, "train/policy_logprob_std": 0.6358607399463654, "train/policy_randomness_mag": 0.6568562889099121, "train/policy_randomness_max": 0.6568562889099121, "train/policy_randomness_mean": 0.05175106083974242, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06565259877592325, "train/post_ent_mag": 2.910302453041077, "train/post_ent_max": 2.910302453041077, "train/post_ent_mean": 2.9050059711933134, "train/post_ent_min": 2.9018254387378692, "train/post_ent_std": 0.0018293340550735594, "train/prior_ent_mag": 3.8147678399086, "train/prior_ent_max": 3.8147678399086, "train/prior_ent_mean": 2.818332930803299, "train/prior_ent_min": 2.8112288069725038, "train/prior_ent_std": 0.038248637332580986, "train/rep_loss_mean": 1.0001915371418, "train/rep_loss_std": 0.005302299163304269, "train/reward_avg": 0.0017733084010251332, "train/reward_loss_mean": 0.026125691710039974, "train/reward_loss_std": 0.1774191713705659, "train/reward_max_data": 0.6714533777721227, "train/reward_max_pred": 0.19844245076179504, "train/reward_neg_acc": 0.9997944688796997, "train/reward_neg_loss": 0.017908247993327676, "train/reward_pos_acc": 0.1968411806632172, "train/reward_pos_loss": 4.1011156419461425, "train/reward_pred": 0.001383566267322749, "train/reward_rate": 0.0020166015625, "train_stats/mean_log_entropy": 0.07857040108545967, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.008421634323894978, "report/cont_loss_std": 0.11052031069993973, "report/cont_neg_acc": 0.8571429252624512, "report/cont_neg_loss": 0.5540673732757568, "report/cont_pos_acc": 0.9990166425704956, "report/cont_pos_loss": 0.004665961489081383, "report/cont_pred": 0.9905794858932495, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08295729756355286, "report/image_loss_std": 0.08893992006778717, "report/model_loss_mean": 0.7199834585189819, "report/model_loss_std": 0.28511953353881836, "report/post_ent_mag": 2.913496971130371, "report/post_ent_max": 2.913496971130371, "report/post_ent_mean": 2.9082586765289307, "report/post_ent_min": 2.9055628776550293, "report/post_ent_std": 0.0014841201482340693, "report/prior_ent_mag": 2.8656065464019775, "report/prior_ent_max": 2.8656065464019775, "report/prior_ent_mean": 2.8133082389831543, "report/prior_ent_min": 2.811063766479492, "report/prior_ent_std": 0.0037884097546339035, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0017529537435621023, "report/reward_loss_mean": 0.02860451489686966, "report/reward_loss_std": 0.148251473903656, "report/reward_max_data": 0.6493750214576721, "report/reward_max_pred": 0.396487832069397, "report/reward_neg_acc": 0.9990215301513672, "report/reward_neg_loss": 0.02292645536363125, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.9300947189331055, "report/reward_pred": 0.001753443037159741, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02752738818526268, "eval/cont_loss_std": 0.4576227366924286, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.880776882171631, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004452218767255545, "eval/cont_pred": 0.9958562850952148, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16618895530700684, "eval/image_loss_std": 0.13795094192028046, "eval/model_loss_mean": 0.8019828200340271, "eval/model_loss_std": 0.5389633774757385, "eval/post_ent_mag": 2.91308856010437, "eval/post_ent_max": 2.91308856010437, "eval/post_ent_mean": 2.9082541465759277, "eval/post_ent_min": 2.9057841300964355, "eval/post_ent_std": 0.0014178940327838063, "eval/prior_ent_mag": 2.9096479415893555, "eval/prior_ent_max": 2.9096479415893555, "eval/prior_ent_mean": 2.8127479553222656, "eval/prior_ent_min": 2.8110833168029785, "eval/prior_ent_std": 0.004186330363154411, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007965088007040322, "eval/reward_loss_mean": 0.008266443386673927, "eval/reward_loss_std": 0.1527586728334427, "eval/reward_max_data": 0.815625011920929, "eval/reward_max_pred": 0.03332114219665527, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.003491831012070179, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.89269495010376, "eval/reward_pred": 0.0006680524675175548, "eval/reward_rate": 0.0009765625, "replay/size": 858281.0, "replay/inserts": 31968.0, "replay/samples": 31968.0, "replay/insert_wait_avg": 1.1748499101823992e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.574160297115047e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3520.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0411847721446644e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9998366832733, "timer/env.step_count": 3996.0, "timer/env.step_total": 34.350181341171265, "timer/env.step_frac": 0.03435018695113136, "timer/env.step_avg": 0.008596141476769585, "timer/env.step_min": 0.007152080535888672, "timer/env.step_max": 0.049445152282714844, "timer/replay._sample_count": 31968.0, "timer/replay._sample_total": 15.929719924926758, "timer/replay._sample_frac": 0.015929722526516896, "timer/replay._sample_avg": 0.0004983020497036648, "timer/replay._sample_min": 0.00034356117248535156, "timer/replay._sample_max": 0.021686792373657227, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4436.0, "timer/agent.policy_total": 37.9749550819397, "timer/agent.policy_frac": 0.03797496128388607, "timer/agent.policy_avg": 0.008560630090608588, "timer/agent.policy_min": 0.007405519485473633, "timer/agent.policy_max": 0.08346152305603027, "timer/dataset_train_count": 1998.0, "timer/dataset_train_total": 0.20823073387145996, "timer/dataset_train_frac": 0.00020823076787902738, "timer/dataset_train_avg": 0.00010421958652225223, "timer/dataset_train_min": 8.726119995117188e-05, "timer/dataset_train_max": 0.0003204345703125, "timer/agent.train_count": 1998.0, "timer/agent.train_total": 883.5439329147339, "timer/agent.train_frac": 0.8835440772122605, "timer/agent.train_avg": 0.44221418063800494, "timer/agent.train_min": 0.43176746368408203, "timer/agent.train_max": 0.5954062938690186, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4701714515686035, "timer/agent.report_frac": 0.00047017152835547853, "timer/agent.report_avg": 0.23508572578430176, "timer/agent.report_min": 0.22826194763183594, "timer/agent.report_max": 0.24190950393676758, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.1709676199228337e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 31.967425672206513}
{"step": 858936, "time": 27242.988792657852, "episode/length": 77.0, "episode/score": 0.8023395392996235, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.042964578246369456}
{"step": 859320, "time": 27254.866368055344, "episode/length": 99.0, "episode/score": 0.7493365406742214, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.05871151536553043}
{"step": 859376, "time": 27256.796204805374, "episode/length": 288.0, "episode/score": 0.08372074059911938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08372074059911938}
{"step": 859480, "time": 27259.78472352028, "episode/length": 67.0, "episode/score": 0.8107731509694531, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.020148198967490316}
{"step": 859704, "time": 27266.663390159607, "episode/length": 288.0, "episode/score": 0.1082463213047049, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1082463213047049}
{"step": 859752, "time": 27268.137137413025, "episode/length": 53.0, "episode/score": 0.8576905756167434, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.02331556687977354}
{"step": 860080, "time": 27279.194741010666, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 860080, "time": 27279.262338638306, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 860080, "time": 27279.43913459778, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 860080, "time": 27279.554604530334, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 860080, "time": 27279.593223571777, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 860080, "time": 27279.906000375748, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 860080, "time": 27280.160144090652, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 860080, "time": 27280.197460889816, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 860080, "time": 27280.202474832535, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 860096, "time": 27280.697988033295, "episode/length": 48.0, "episode/score": 0.8678534466012024, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.01785344917107068}
{"step": 860280, "time": 27286.65322494507, "episode/length": 112.0, "episode/score": 0.6810178317307418, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.03101787868104111}
{"step": 860320, "time": 27288.10761976242, "episode/length": 288.0, "episode/score": 0.07106602488227054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07106602488227054}
{"step": 860368, "time": 27289.59046602249, "episode/length": 110.0, "episode/score": 0.7077432504854642, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.051493250922021616}
{"step": 860392, "time": 27290.117113113403, "episode/length": 288.0, "episode/score": 0.03464894107457894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03464894107457894}
{"step": 860552, "time": 27295.07812166214, "episode/length": 33.0, "episode/score": 0.9255636473134246, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.02868860414662322}
{"step": 860808, "time": 27302.98509120941, "episode/length": 54.0, "episode/score": 0.8506084498774271, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0193584662745252}
{"step": 860864, "time": 27304.936946868896, "episode/length": 288.0, "episode/score": 0.0713867044860308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0713867044860308}
{"step": 860864, "time": 27304.94256234169, "episode/length": 67.0, "episode/score": 0.8176273023364047, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.027002329554306925}
{"step": 860920, "time": 27306.53875541687, "episode/length": 102.0, "episode/score": 0.7499422939969236, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.06869229449750947}
{"step": 860968, "time": 27308.021245479584, "episode/length": 288.0, "episode/score": 0.06398954379778843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06398954379778843}
{"step": 861000, "time": 27309.024632930756, "episode/length": 155.0, "episode/score": 0.6025290926260141, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.08690409306257152}
{"step": 861720, "time": 27331.424299955368, "episode/length": 99.0, "episode/score": 0.7304945907351339, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.039869562457852226}
{"step": 861864, "time": 27335.966267347336, "episode/length": 107.0, "episode/score": 0.7341162914152619, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.06849131688693433}
{"step": 862256, "time": 27348.251535654068, "episode/length": 48.0, "episode/score": 0.8771248096354611, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.027124798715703946}
{"step": 862624, "time": 27359.592613697052, "episode/length": 112.0, "episode/score": 0.7124887994600613, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.062488824116826436}
{"step": 862704, "time": 27362.094525814056, "episode/length": 288.0, "episode/score": 0.05853606468565431, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05853606468565431}
{"step": 862864, "time": 27367.246428489685, "episode/length": 288.0, "episode/score": 0.07527252456816313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07527252456816313}
{"step": 862952, "time": 27369.78764486313, "episode/length": 40.0, "episode/score": 0.9005520631758372, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.025552048856752663}
{"step": 863120, "time": 27375.315808057785, "episode/length": 288.0, "episode/score": 0.0936526500885293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0936526500885293}
{"step": 863176, "time": 27376.87202858925, "episode/length": 288.0, "episode/score": 0.05655647737967229, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05655647737967229}
{"step": 863176, "time": 27376.879502773285, "episode/length": 288.0, "episode/score": 0.09260567813362286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09260567813362286}
{"step": 863280, "time": 27380.37220811844, "episode/length": 288.0, "episode/score": 0.061852996232687474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061852996232687474}
{"step": 863312, "time": 27381.39793395996, "episode/length": 131.0, "episode/score": 0.6693491564392389, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.07872416998998233}
{"step": 863488, "time": 27386.897844076157, "episode/length": 45.0, "episode/score": 0.8714721671321968, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.01209714780725335}
{"step": 863680, "time": 27392.898188591003, "episode/length": 62.0, "episode/score": 0.8411660644273979, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.03491608989907036}
{"step": 863688, "time": 27392.944453716278, "episode/length": 91.0, "episode/score": 0.7434357078464018, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.027810696426058712}
{"step": 863776, "time": 27396.0295689106, "episode/length": 61.0, "episode/score": 0.8593127105154963, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.04993769379825608}
{"step": 863936, "time": 27401.001282691956, "episode/length": 94.0, "episode/score": 0.7686962689417669, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.062446259349144384}
{"step": 864224, "time": 27409.90181159973, "episode/length": 67.0, "episode/score": 0.8375979105949227, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.046972935251687886}
{"step": 864328, "time": 27412.902242183685, "episode/length": 104.0, "episode/score": 0.7190920286564051, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.04409198809730697}
{"step": 864688, "time": 27424.250968694687, "episode/length": 57.0, "episode/score": 0.8602979084248545, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.03842290362854328}
{"step": 864800, "time": 27427.842268943787, "episode/length": 107.0, "episode/score": 0.720494330586007, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.054869355242772144}
{"step": 864944, "time": 27432.29229927063, "episode/length": 145.0, "episode/score": 0.6222131211561646, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.07533813407826528}
{"step": 865000, "time": 27433.805450439453, "episode/length": 163.0, "episode/score": 0.5536514799341603, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.063026487058778}
{"step": 865016, "time": 27434.305711746216, "episode/length": 288.0, "episode/score": 0.05972915308757365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05972915308757365}
{"step": 865080, "time": 27436.307653188705, "episode/length": 93.0, "episode/score": 0.7566335240344415, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.04725850100749085}
{"step": 865176, "time": 27439.285474300385, "episode/length": 288.0, "episode/score": 0.07630901153993364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07630901153993364}
{"step": 865616, "time": 27453.12866449356, "episode/length": 83.0, "episode/score": 0.7767521789373859, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.03612714077644341}
{"step": 865624, "time": 27453.163014173508, "episode/length": 288.0, "episode/score": 0.03207586881762836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03207586881762836}
{"step": 865664, "time": 27454.61825823784, "episode/length": 72.0, "episode/score": 0.7951129375524033, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.020112947075176635}
{"step": 865960, "time": 27463.681889533997, "episode/length": 144.0, "episode/score": 0.6232661277840634, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.07326610154404989}
{"step": 865992, "time": 27464.67949295044, "episode/length": 45.0, "episode/score": 0.8890393523940929, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.029664353209000183}
{"step": 866104, "time": 27468.15820980072, "episode/length": 137.0, "episode/score": 0.6233794780837343, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.05150447858432017}
{"step": 866160, "time": 27470.104946136475, "episode/length": 122.0, "episode/score": 0.65864015926104, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.03989016674654522}
{"step": 866160, "time": 27470.110340595245, "episode/length": 67.0, "episode/score": 0.8145037559372668, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0238787511409555}
{"step": 866336, "time": 27475.560733795166, "episode/length": 164.0, "episode/score": 0.5582546821804044, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.07075467107438271}
{"step": 866648, "time": 27485.114189386368, "episode/length": 67.0, "episode/score": 0.821051686055398, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.03042669057231251}
{"step": 866776, "time": 27489.070868730545, "episode/length": 97.0, "episode/score": 0.7479585273745215, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.05108355203128667}
{"step": 866960, "time": 27494.9749045372, "episode/length": 99.0, "episode/score": 0.7444887657859454, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.05386373454007298}
{"step": 867000, "time": 27496.01026558876, "episode/length": 288.0, "episode/score": 0.046810560885433006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046810560885433006}
{"step": 867384, "time": 27507.86728334427, "episode/length": 130.0, "episode/score": 0.6369147395137134, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.04316472315736064}
{"step": 867456, "time": 27510.30401778221, "episode/length": 100.0, "episode/score": 0.7153302595049809, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.02783024611721885}
{"step": 867456, "time": 27510.309272050858, "episode/length": 61.0, "episode/score": 0.8335797873135107, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.024204769839570872}
{"step": 867488, "time": 27511.31930041313, "episode/length": 165.0, "episode/score": 0.5598523730461693, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.07547736486799295}
{"step": 867544, "time": 27512.827524662018, "episode/length": 67.0, "episode/score": 0.8150294615409166, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.024404462041502484}
{"step": 867896, "time": 27523.80027103424, "episode/length": 139.0, "episode/score": 0.6113562661514607, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.045731246052355345}
{"step": 867976, "time": 27526.28934764862, "episode/length": 288.0, "episode/score": 0.08732241315806277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08732241315806277}
{"step": 868088, "time": 27529.726226329803, "episode/length": 67.0, "episode/score": 0.8137027349107484, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.023077735411334288}
{"step": 868272, "time": 27535.637771606445, "episode/length": 288.0, "episode/score": 0.05696170705573422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05696170705573422}
{"step": 868312, "time": 27536.649816036224, "episode/length": 51.0, "episode/score": 0.8691925112332228, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.028567523590709243}
{"step": 868472, "time": 27542.056306123734, "episode/length": 126.0, "episode/score": 0.6468564557010268, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.040606454234193734}
{"step": 868512, "time": 27543.51428604126, "episode/length": 140.0, "episode/score": 0.6398932216877711, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.07739322212432853}
{"step": 868856, "time": 27553.9713037014, "episode/length": 109.0, "episode/score": 0.7022535544422226, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.04287853434311728}
{"step": 868864, "time": 27554.44388604164, "episode/length": 43.0, "episode/score": 0.8720558943205106, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0064308906185033266}
{"step": 869016, "time": 27558.926871061325, "episode/length": 67.0, "episode/score": 0.8305592837900804, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.039934284290666255}
{"step": 869168, "time": 27563.827365875244, "episode/length": 111.0, "episode/score": 0.728842778602143, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.07571777713530992}
{"step": 869336, "time": 27568.798795223236, "episode/length": 59.0, "episode/score": 0.8439680584676807, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.02834306668660247}
{"step": 869352, "time": 27569.296091079712, "episode/length": 41.0, "episode/score": 0.8834776300241174, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.011602633766869985}
{"step": 869768, "time": 27582.26946234703, "episode/length": 288.0, "episode/score": 0.053246487005253584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053246487005253584}
{"step": 869800, "time": 27583.261526346207, "episode/length": 288.0, "episode/score": 0.07682450135655472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07682450135655472}
{"step": 870064, "time": 27592.51376390457, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 870064, "time": 27592.64261841774, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 870064, "time": 27592.663354873657, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 870064, "time": 27592.777220487595, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 870064, "time": 27593.788759231567, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 870064, "time": 27594.688423871994, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 870064, "time": 27594.756893873215, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 870064, "time": 27595.185768842697, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 870136, "time": 27597.191814422607, "episode/length": 99.0, "episode/score": 0.7656652789985401, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.07504029123379041}
{"step": 870160, "time": 27598.16268014908, "episode/length": 44.0, "episode/score": 0.8917556923340726, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.029255651018274875}
{"step": 870400, "time": 27605.756135463715, "episode/length": 288.0, "episode/score": 0.047194701015200735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047194701015200735}
{"step": 870624, "time": 27612.631976366043, "episode/length": 288.0, "episode/score": 0.065068171040366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.065068171040366}
{"step": 871016, "time": 27624.44767832756, "episode/length": 76.0, "episode/score": 0.8265833076794706, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.06408330621263758}
{"step": 871072, "time": 27626.374778032303, "episode/length": 113.0, "episode/score": 0.7207776880705978, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0739026408874679}
{"step": 871176, "time": 27629.347791194916, "episode/length": 288.0, "episode/score": 0.05159361332141543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05159361332141543}
{"step": 871344, "time": 27634.711072444916, "episode/length": 89.0, "episode/score": 0.7847423451659097, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.06286733368153818}
{"step": 871480, "time": 27638.776079654694, "episode/length": 288.0, "episode/score": 0.09194359429613996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09194359429613996}
{"step": 871664, "time": 27644.617507457733, "episode/length": 288.0, "episode/score": 0.11819905943025333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11819905943025333}
{"step": 871840, "time": 27650.011340618134, "episode/length": 102.0, "episode/score": 0.7632205646144712, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.08197061261250838}
{"step": 871840, "time": 27650.016837358475, "episode/length": 95.0, "episode/score": 0.7365820438383253, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.03345706799450454}
{"step": 872080, "time": 27657.407547712326, "episode/length": 288.0, "episode/score": 0.08347328975764867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08347328975764867}
{"step": 872448, "time": 27668.976931095123, "episode/length": 288.0, "episode/score": 0.08932327730656198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08932327730656198}
{"step": 872456, "time": 27669.010801553726, "episode/length": 76.0, "episode/score": 0.8113620225116165, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.04886202727300315}
{"step": 872840, "time": 27680.991961717606, "episode/length": 48.0, "episode/score": 0.8814654209128321, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.03146542538900121}
{"step": 872944, "time": 27684.489728450775, "episode/length": 107.0, "episode/score": 0.7164824727709629, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.05085749998886513}
{"step": 873488, "time": 27701.485209465027, "episode/length": 288.0, "episode/score": 0.10838400250008817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10838400250008817}
{"step": 873656, "time": 27706.452782154083, "episode/length": 288.0, "episode/score": 0.11942541919790983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11942541919790983}
{"step": 873744, "time": 27709.39061164856, "episode/length": 99.0, "episode/score": 0.7414631424333038, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.050838101117506085}
{"step": 873792, "time": 27710.874662399292, "episode/length": 288.0, "episode/score": 0.10454489358255614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10454489358255614}
{"step": 873832, "time": 27711.886579990387, "episode/length": 42.0, "episode/score": 0.8982659334574237, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.02951594391151957}
{"step": 873976, "time": 27716.32288646698, "episode/length": 288.0, "episode/score": 0.10052114117365818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10052114117365818}
{"step": 874144, "time": 27721.738609552383, "episode/length": 60.0, "episode/score": 0.849638389934853, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.03713838175667661}
{"step": 874152, "time": 27721.773630857468, "episode/length": 288.0, "episode/score": 0.11008473605579638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11008473605579638}
{"step": 874256, "time": 27725.315163373947, "episode/length": 52.0, "episode/score": 0.8742220078643186, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0367220245466342}
{"step": 874472, "time": 27731.743059396744, "episode/length": 84.0, "episode/score": 0.7829024835725704, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.04540249580782074}
{"step": 874616, "time": 27736.19119286537, "episode/length": 79.0, "episode/score": 0.7876999329776027, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.034574924432718035}
{"step": 874768, "time": 27741.14182972908, "episode/length": 288.0, "episode/score": 0.07655379589800759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07655379589800759}
{"step": 874824, "time": 27742.67281103134, "episode/length": 134.0, "episode/score": 0.6457108034842349, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.06446076624297348}
{"step": 875152, "time": 27753.194627523422, "episode/length": 84.0, "episode/score": 0.7832649696028966, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.04576498599999468}
{"step": 875152, "time": 27753.20253920555, "episode/length": 288.0, "episode/score": 0.1011458674536243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1011458674536243}
{"step": 875248, "time": 27756.259125471115, "episode/length": 78.0, "episode/score": 0.8011473857243345, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.04489739020050365}
{"step": 875528, "time": 27764.664049625397, "episode/length": 94.0, "episode/score": 0.7595143164750198, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.05326432469394149}
{"step": 875672, "time": 27769.116085529327, "episode/length": 64.0, "episode/score": 0.8302549307022673, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.03025489346100585}
{"step": 875784, "time": 27772.570088624954, "episode/length": 119.0, "episode/score": 0.6746158521312964, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.04649084042864615}
{"step": 875824, "time": 27774.052984952927, "episode/length": 36.0, "episode/score": 0.9108047996093092, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.023304839848265146}
{"step": 876400, "time": 27791.852435350418, "episode/length": 76.0, "episode/score": 0.8114105428355174, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.04891056792592963}
{"step": 876456, "time": 27793.380104780197, "episode/length": 288.0, "episode/score": 0.10435705896230729, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10435705896230729}
{"step": 876464, "time": 27793.853654146194, "episode/length": 288.0, "episode/score": 0.07670380710754898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07670380710754898}
{"step": 876568, "time": 27797.326263189316, "episode/length": 288.0, "episode/score": 0.0824616143406729, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0824616143406729}
{"step": 876632, "time": 27799.313228845596, "episode/length": 28.0, "episode/score": 0.9404548460163937, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.027954805818183104}
{"step": 876792, "time": 27804.24791455269, "episode/length": 120.0, "episode/score": 0.6868998626722487, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.06189988281209935}
{"step": 877464, "time": 27825.170544862747, "episode/length": 288.0, "episode/score": 0.06265997957160607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06265997957160607}
{"step": 877560, "time": 27828.15616464615, "episode/length": 288.0, "episode/score": 0.11888910961943111, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11888910961943111}
{"step": 877568, "time": 27828.630863904953, "episode/length": 137.0, "episode/score": 0.6264994788677427, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.054624520841286994}
{"step": 877744, "time": 27834.062597990036, "episode/length": 118.0, "episode/score": 0.6621615817854263, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.030911584355294508}
{"step": 877768, "time": 27834.581615924835, "episode/length": 141.0, "episode/score": 0.6517638268248334, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.09238885687744869}
{"step": 877984, "time": 27841.5107049942, "episode/length": 288.0, "episode/score": 0.07147815877067387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07147815877067387}
{"step": 878184, "time": 27847.53120946884, "episode/length": 76.0, "episode/score": 0.8126509277283276, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.05015094197756298}
{"step": 878384, "time": 27853.92528653145, "episode/length": 49.0, "episode/score": 0.8882744887087028, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.04139947911608033}
{"step": 878456, "time": 27855.930640220642, "episode/length": 249.0, "episode/score": 0.3195326246534478, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.09765762926349453}
{"step": 878880, "time": 27869.17272257805, "episode/length": 288.0, "episode/score": 0.08962063714068336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08962063714068336}
{"step": 878904, "time": 27869.693172216415, "episode/length": 55.0, "episode/score": 0.8642557817329362, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.03613075309476699}
{"step": 879176, "time": 27878.202224493027, "episode/length": 98.0, "episode/score": 0.7660124135845763, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.07226239137253287}
{"step": 879360, "time": 27884.089126348495, "episode/length": 198.0, "episode/score": 0.4634145771129283, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.08216458540169924}
{"step": 879480, "time": 27887.578874111176, "episode/length": 71.0, "episode/score": 0.843122993277575, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.06499800682831847}
{"step": 879536, "time": 27889.554577112198, "episode/length": 81.0, "episode/score": 0.8000683025425133, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.05319332738554294}
{"step": 879720, "time": 27895.120334625244, "episode/length": 29.0, "episode/score": 0.9466982381400157, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.03732322854739323}
{"step": 879776, "time": 27897.106636285782, "episode/length": 288.0, "episode/score": 0.10695129302456508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10695129302456508}
{"step": 879808, "time": 27898.133091688156, "episode/length": 78.0, "episode/score": 0.823915791289437, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.06766576977588556}
{"step": 879872, "time": 27900.13241672516, "episode/length": 288.0, "episode/score": 0.09789413517802359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09789413517802359}
{"step": 880048, "time": 27906.564079284668, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 880048, "time": 27906.90977549553, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 880048, "time": 27907.16219496727, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 880048, "time": 27907.325783491135, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 880048, "time": 27907.364802837372, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 880048, "time": 27907.790677070618, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 880048, "time": 27908.017458200455, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 880048, "time": 27908.20953965187, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 880056, "time": 27908.24198293686, "episode/length": 288.0, "episode/score": 0.13457024206138612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13457024206138612}
{"step": 880360, "time": 27917.609716415405, "episode/length": 102.0, "episode/score": 0.7777472431616843, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.09649726863335673}
{"step": 880384, "time": 27918.571299791336, "episode/length": 75.0, "episode/score": 0.8366865571560993, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0710615587859138}
{"step": 880496, "time": 27922.032465219498, "episode/length": 288.0, "episode/score": 0.15902768251135058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15902768251135058}
{"step": 880712, "time": 27928.499150037766, "episode/length": 123.0, "episode/score": 0.6872801258723484, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.07165510366030503}
{"step": 880752, "time": 27930.000619649887, "episode/length": 109.0, "episode/score": 0.7494315193134753, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.09005647875437717}
{"step": 880888, "time": 27934.037633895874, "episode/length": 103.0, "episode/score": 0.7253563366070921, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0472313256873349}
{"step": 881008, "time": 27938.109330415726, "episode/length": 149.0, "episode/score": 0.6320937039936325, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.09771866343453439}
{"step": 881232, "time": 27944.981427669525, "episode/length": 59.0, "episode/score": 0.8646261944772959, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.04900119547846771}
{"step": 881272, "time": 27945.991883039474, "episode/length": 238.0, "episode/score": 0.39410920131240346, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.1378592080877752}
{"step": 881296, "time": 27946.9473464489, "episode/length": 99.0, "episode/score": 0.7458342025829552, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.05520916202385706}
{"step": 881520, "time": 27953.798984527588, "episode/length": 78.0, "episode/score": 0.8043476332104547, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.04809759301224403}
{"step": 881576, "time": 27955.311051368713, "episode/length": 70.0, "episode/score": 0.8323291683850584, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.05107918130715916}
{"step": 881616, "time": 27956.755601644516, "episode/length": 112.0, "episode/score": 0.7437617710352242, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.09376179569198939}
{"step": 881792, "time": 27962.14931869507, "episode/length": 61.0, "episode/score": 0.8744951405278698, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.06512013609244605}
{"step": 881808, "time": 27962.64426612854, "episode/length": 23.0, "episode/score": 0.9484655824940091, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.020340571574251953}
{"step": 881936, "time": 27966.695242643356, "episode/length": 17.0, "episode/score": 0.964020206513851, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.01714523117061617}
{"step": 882000, "time": 27968.66167116165, "episode/length": 95.0, "episode/score": 0.7644790086606008, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.06135399434151623}
{"step": 882152, "time": 27973.119849443436, "episode/length": 78.0, "episode/score": 0.8099205082448862, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.05367048521793549}
{"step": 882256, "time": 27976.554671287537, "episode/length": 39.0, "episode/score": 0.9066736810625571, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.02854865482254354}
{"step": 882432, "time": 27981.98228287697, "episode/length": 144.0, "episode/score": 0.6650035097127329, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.11500348347271938}
{"step": 882536, "time": 27984.97886109352, "episode/length": 47.0, "episode/score": 0.8937457655244998, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.040620773010004996}
{"step": 882672, "time": 27989.380643844604, "episode/length": 288.0, "episode/score": 0.1326590281296376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1326590281296376}
{"step": 882696, "time": 27989.901663780212, "episode/length": 288.0, "episode/score": 0.08057640632205221, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08057640632205221}
{"step": 882752, "time": 27991.84825849533, "episode/length": 39.0, "episode/score": 0.9041315433639738, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.026006517123960293}
{"step": 883200, "time": 28005.765857219696, "episode/length": 62.0, "episode/score": 0.8508278645531391, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.044577869070053566}
{"step": 883304, "time": 28008.72267150879, "episode/length": 95.0, "episode/score": 0.7793340763178094, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.07620905699286595}
{"step": 883696, "time": 28021.03562283516, "episode/length": 61.0, "episode/score": 0.843935370844747, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.03456035942440394}
{"step": 883848, "time": 28025.59579181671, "episode/length": 67.0, "episode/score": 0.8305619603818286, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.039936960882414496}
{"step": 883888, "time": 28027.067667722702, "episode/length": 288.0, "episode/score": 0.11644258971955423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11644258971955423}
{"step": 884120, "time": 28034.044069767, "episode/length": 288.0, "episode/score": 0.10263934597583102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10263934597583102}
{"step": 884192, "time": 28036.4885058403, "episode/length": 42.0, "episode/score": 0.9032670997401056, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.034517109262878876}
{"step": 884288, "time": 28039.48090529442, "episode/length": 11.0, "episode/score": 0.976424314424321, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.010799296950381176}
{"step": 884312, "time": 28040.00454068184, "episode/length": 288.0, "episode/score": 0.09399447497276014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09399447497276014}
{"step": 884456, "time": 28044.44929790497, "episode/length": 17.0, "episode/score": 0.960458666257864, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.013583670774778511}
{"step": 884568, "time": 28047.894035816193, "episode/length": 288.0, "episode/score": 0.06550114472133828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06550114472133828}
{"step": 884624, "time": 28049.862976789474, "episode/length": 115.0, "episode/score": 0.7093705887289161, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.06874555933404736}
{"step": 884656, "time": 28050.848415851593, "episode/length": 66.0, "episode/score": 0.8301490332576122, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.03639903179077919}
{"step": 884720, "time": 28052.81376671791, "episode/length": 103.0, "episode/score": 0.7541110299730462, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.07598600656774579}
{"step": 884824, "time": 28056.42036962509, "episode/length": 45.0, "episode/score": 0.8937084812821467, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.03433345794087472}
{"step": 884896, "time": 28058.876189231873, "episode/length": 75.0, "episode/score": 0.8121709539375388, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.046545924542670036}
{"step": 884984, "time": 28061.393304347992, "episode/length": 288.0, "episode/score": 0.09056866542550779, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09056866542550779}
{"step": 885064, "time": 28063.85618519783, "episode/length": 288.0, "episode/score": 0.08712775306889853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08712775306889853}
{"step": 885080, "time": 28064.373329877853, "episode/length": 52.0, "episode/score": 0.8715847543048767, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.034084802302913886}
{"step": 885104, "time": 28065.343572616577, "episode/length": 59.0, "episode/score": 0.8606702440449681, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.04504520272917034}
{"step": 885368, "time": 28073.267018795013, "episode/length": 47.0, "episode/score": 0.8889485381074564, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.03582354856155234}
{"step": 885440, "time": 28075.721350431442, "episode/length": 108.0, "episode/score": 0.7203886781435358, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.05788864612350153}
{"step": 885560, "time": 28079.22980737686, "episode/length": 61.0, "episode/score": 0.8456636094591659, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.036288607061010225}
{"step": 885768, "time": 28085.77289557457, "episode/length": 82.0, "episode/score": 0.7894241551680352, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0456742031660724}
{"step": 885944, "time": 28091.167896270752, "episode/length": 71.0, "episode/score": 0.8185568444782803, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.04043188055538849}
{"step": 886280, "time": 28101.437470912933, "episode/length": 149.0, "episode/score": 0.6069755674737962, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.07260057970904654}
{"step": 886344, "time": 28103.393409490585, "episode/length": 97.0, "episode/score": 0.7342605584585726, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.03738556891266853}
{"step": 886408, "time": 28105.374905109406, "episode/length": 57.0, "episode/score": 0.8609181318591936, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.039043148541509254}
{"step": 886744, "time": 28115.791568756104, "episode/length": 49.0, "episode/score": 0.8806542985314536, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.03377927945098236}
{"step": 886760, "time": 28116.28832602501, "episode/length": 123.0, "episode/score": 0.6553583893323776, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.03973338563037032}
{"step": 886832, "time": 28118.735465765, "episode/length": 68.0, "episode/score": 0.8266943814986689, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.03919436103285534}
{"step": 886984, "time": 28123.174154043198, "episode/length": 71.0, "episode/score": 0.807754330123089, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.029629318702745877}
{"step": 887032, "time": 28124.674185037613, "episode/length": 288.0, "episode/score": 0.09383863226048561, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09383863226048561}
{"step": 887136, "time": 28128.102824687958, "episode/length": 288.0, "episode/score": 0.06920020288703199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06920020288703199}
{"step": 887208, "time": 28130.117193222046, "episode/length": 288.0, "episode/score": 0.0988354468416901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0988354468416901}
{"step": 887256, "time": 28131.59716486931, "episode/length": 63.0, "episode/score": 0.8425975827838101, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.03947256231799656}
{"step": 887728, "time": 28146.511812210083, "episode/length": 73.0, "episode/score": 0.8199501477876083, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.048075152263777454}
{"step": 887752, "time": 28147.038511037827, "episode/length": 288.0, "episode/score": 0.06561248061279912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06561248061279912}
{"step": 888440, "time": 28168.338179826736, "episode/length": 85.0, "episode/score": 0.7894564735328231, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.05508149367267379}
{"step": 888512, "time": 28170.780898571014, "episode/length": 156.0, "episode/score": 0.5802830805955637, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.06778308433831626}
{"step": 888800, "time": 28179.78869986534, "episode/length": 35.0, "episode/score": 0.9210131596603333, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.030388183816512537}
{"step": 888952, "time": 28184.264955997467, "episode/length": 63.0, "episode/score": 0.8319793614422224, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.028854355732050863}
{"step": 889072, "time": 28188.191673994064, "episode/length": 288.0, "episode/score": 0.07915512214276532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07915512214276532}
{"step": 889144, "time": 28190.18689608574, "episode/length": 288.0, "episode/score": 0.04929204561904044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04929204561904044}
{"step": 889296, "time": 28195.10818696022, "episode/length": 288.0, "episode/score": 0.048305431037647395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048305431037647395}
{"step": 889344, "time": 28196.587238788605, "episode/length": 288.0, "episode/score": 0.05096827166721596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05096827166721596}
{"step": 889520, "time": 28202.02727651596, "episode/length": 288.0, "episode/score": 0.08142928070765265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08142928070765265}
{"step": 889520, "time": 28202.03265976906, "episode/length": 55.0, "episode/score": 0.8500345338799207, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.021909562197947707}
{"step": 889920, "time": 28214.419687509537, "episode/length": 96.0, "episode/score": 0.73085550157748, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.030855541816436016}
{"step": 890032, "time": 28218.319799423218, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 890032, "time": 28218.535816669464, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 890032, "time": 28219.000513792038, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 890032, "time": 28219.188996315002, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 890032, "time": 28219.256217479706, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 890032, "time": 28219.41318511963, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 890032, "time": 28219.418434858322, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 890032, "time": 28220.0953476429, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 890040, "time": 28220.12939810753, "episode/length": 288.0, "episode/score": 0.0739264074793482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0739264074793482}
{"step": 890088, "time": 28221.603909254074, "episode/length": 92.0, "episode/score": 0.7546593475366308, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.042159371596767414}
{"step": 890144, "time": 28223.54453921318, "episode/length": 105.0, "episode/score": 0.7095359325619484, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.037660947666836364}
{"step": 890208, "time": 28225.53286600113, "episode/length": 85.0, "episode/score": 0.7954767510575493, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.06110175443359367}
{"step": 890264, "time": 28227.03170466423, "episode/length": 27.0, "episode/score": 0.9358958445280905, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.020270881539431684}
{"step": 890368, "time": 28230.466819047928, "episode/length": 105.0, "episode/score": 0.7000478756378925, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.028172869191394057}
{"step": 890592, "time": 28237.467419862747, "episode/length": 55.0, "episode/score": 0.8566374037089872, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.028512423848837898}
{"step": 890601, "time": 28238.497960090637, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1623780523712313, "train/action_min": 0.0, "train/action_std": 1.7439822216129781, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009244949415316759, "train/actor_opt_grad_steps": 54570.0, "train/actor_opt_loss": -12.77520727751842, "train/adv_mag": 0.9488620440564562, "train/adv_max": 0.2780315941901662, "train/adv_mean": -2.3730331236609472e-05, "train/adv_min": -0.903595009041791, "train/adv_std": 0.026445386308858444, "train/cont_avg": 0.9952791300251256, "train/cont_loss_mean": 0.017140349686782266, "train/cont_loss_std": 0.23802299238273397, "train/cont_neg_acc": 0.28226573727457654, "train/cont_neg_loss": 2.942974739303212, "train/cont_pos_acc": 0.9998620380109279, "train/cont_pos_loss": 0.0034039053526571275, "train/cont_pred": 0.9953485969922051, "train/cont_rate": 0.9952791300251256, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09011402314800264, "train/extr_critic_critic_opt_grad_steps": 54570.0, "train/extr_critic_critic_opt_loss": 13441.918366245289, "train/extr_critic_mag": 1.4642574871005725, "train/extr_critic_max": 1.4642574871005725, "train/extr_critic_mean": 1.3768790235471486, "train/extr_critic_min": 1.2261432307449418, "train/extr_critic_std": 0.02005153651531767, "train/extr_return_normed_mag": 0.9579100500998186, "train/extr_return_normed_max": 0.27849887962916386, "train/extr_return_normed_mean": 0.03503803900868899, "train/extr_return_normed_min": -0.8952266085686995, "train/extr_return_normed_std": 0.03411570761408938, "train/extr_return_rate": 0.9995649184413891, "train/extr_return_raw_mag": 1.6203159369415974, "train/extr_return_raw_max": 1.6203159369415974, "train/extr_return_raw_mean": 1.3768551679112804, "train/extr_return_raw_min": 0.44659044874373394, "train/extr_return_raw_std": 0.034115707726409684, "train/extr_reward_mag": 0.29165634078596103, "train/extr_reward_max": 0.29165634078596103, "train/extr_reward_mean": 0.0020378363443346666, "train/extr_reward_min": 4.714457832988183e-06, "train/extr_reward_std": 0.007732715331317492, "train/image_loss_mean": 0.09957903241691878, "train/image_loss_std": 0.10670073266754199, "train/model_loss_mean": 0.7427826092470831, "train/model_loss_std": 0.4081832091862233, "train/model_opt_grad_norm": 17.526404021373345, "train/model_opt_grad_steps": 54520.56281407035, "train/model_opt_loss": 3731.7690208856784, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5025.125628140703, "train/policy_entropy_mag": 1.2788818787090743, "train/policy_entropy_max": 1.2788818787090743, "train/policy_entropy_mean": 0.09682052447717993, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12201853556998411, "train/policy_logprob_mag": 6.551080260444526, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09655519282847792, "train/policy_logprob_min": -6.551080260444526, "train/policy_logprob_std": 0.6330780006533292, "train/policy_randomness_mag": 0.6572153175895538, "train/policy_randomness_max": 0.6572153175895538, "train/policy_randomness_mean": 0.049755908473951733, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0627051272134685, "train/post_ent_mag": 2.888364391710291, "train/post_ent_max": 2.888364391710291, "train/post_ent_mean": 2.8845393382125164, "train/post_ent_min": 2.882432560225827, "train/post_ent_std": 0.0012664491929062385, "train/prior_ent_mag": 2.9219994413193744, "train/prior_ent_max": 2.9219994413193744, "train/prior_ent_mean": 2.8144428634164322, "train/prior_ent_min": 2.811074134692475, "train/prior_ent_std": 0.006780328257149787, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.001792618090634342, "train/reward_loss_mean": 0.026063205402849905, "train/reward_loss_std": 0.17775807407071542, "train/reward_max_data": 0.6789535233568419, "train/reward_max_pred": 0.20722178298624316, "train/reward_neg_acc": 0.9997540556605736, "train/reward_neg_loss": 0.017764523728334126, "train/reward_pos_acc": 0.208820347674191, "train/reward_pos_loss": 3.969049822539091, "train/reward_pred": 0.0014507392469334916, "train/reward_rate": 0.0020954381281407036, "train_stats/mean_log_entropy": 0.07062350333752958, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.026133054867386818, "report/cont_loss_std": 0.3717265725135803, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.845691204071045, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0033112557139247656, "report/cont_pred": 0.996741771697998, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10210896283388138, "report/image_loss_std": 0.1032867357134819, "report/model_loss_mean": 0.7494996786117554, "report/model_loss_std": 0.45809316635131836, "report/post_ent_mag": 2.8583366870880127, "report/post_ent_max": 2.8583366870880127, "report/post_ent_mean": 2.856365203857422, "report/post_ent_min": 2.8552889823913574, "report/post_ent_std": 0.0005730455159209669, "report/prior_ent_mag": 2.976898670196533, "report/prior_ent_max": 2.976898670196533, "report/prior_ent_mean": 2.815556049346924, "report/prior_ent_min": 2.811084508895874, "report/prior_ent_std": 0.009741583839058876, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0009308313019573689, "report/reward_loss_mean": 0.021257635205984116, "report/reward_loss_std": 0.14827725291252136, "report/reward_max_data": 0.6070833206176758, "report/reward_max_pred": 0.12363433837890625, "report/reward_neg_acc": 0.9980449676513672, "report/reward_neg_loss": 0.016693441197276115, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.690427780151367, "report/reward_pred": 0.001644415082409978, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.021288778632879257, "eval/cont_loss_std": 0.3586554527282715, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.34328556060791, "eval/cont_pos_acc": 0.9970645904541016, "eval/cont_pos_loss": 0.006960018537938595, "eval/cont_pred": 0.9954937696456909, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1504010111093521, "eval/image_loss_std": 0.12990714609622955, "eval/model_loss_mean": 0.7788978815078735, "eval/model_loss_std": 0.41825413703918457, "eval/post_ent_mag": 2.858272075653076, "eval/post_ent_max": 2.858272075653076, "eval/post_ent_mean": 2.8564252853393555, "eval/post_ent_min": 2.8554067611694336, "eval/post_ent_std": 0.0006328604067675769, "eval/prior_ent_mag": 3.07240629196167, "eval/prior_ent_max": 3.07240629196167, "eval/prior_ent_mean": 2.81497859954834, "eval/prior_ent_min": 2.811103343963623, "eval/prior_ent_std": 0.009712237864732742, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.007208042312413454, "eval/reward_loss_std": 0.0915667787194252, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.6316732168197632, "eval/reward_neg_acc": 0.9970703125, "eval/reward_neg_loss": 0.007208042778074741, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0020491734612733126, "eval/reward_rate": 0.0, "replay/size": 890097.0, "replay/inserts": 31816.0, "replay/samples": 31824.0, "replay/insert_wait_avg": 1.1828831760674108e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.635328025300039e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4960.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.611248970031738e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1328203678131, "timer/env.step_count": 3977.0, "timer/env.step_total": 34.07372045516968, "timer/env.step_frac": 0.03406919537210926, "timer/env.step_avg": 0.008567694356341382, "timer/env.step_min": 0.007154703140258789, "timer/env.step_max": 0.038895368576049805, "timer/replay._sample_count": 31824.0, "timer/replay._sample_total": 15.879368543624878, "timer/replay._sample_frac": 0.015877259720148983, "timer/replay._sample_avg": 0.000498974627439193, "timer/replay._sample_min": 0.00039005279541015625, "timer/replay._sample_max": 0.012630462646484375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4597.0, "timer/agent.policy_total": 38.52734184265137, "timer/agent.policy_frac": 0.03852222530651717, "timer/agent.policy_avg": 0.008380974949456464, "timer/agent.policy_min": 0.007426023483276367, "timer/agent.policy_max": 0.06579899787902832, "timer/dataset_train_count": 1989.0, "timer/dataset_train_total": 0.20751094818115234, "timer/dataset_train_frac": 0.00020748339016095607, "timer/dataset_train_avg": 0.0001043292851589504, "timer/dataset_train_min": 8.797645568847656e-05, "timer/dataset_train_max": 0.0002911090850830078, "timer/agent.train_count": 1989.0, "timer/agent.train_total": 882.4438664913177, "timer/agent.train_frac": 0.8823266755377415, "timer/agent.train_avg": 0.44366207465626833, "timer/agent.train_min": 0.43193483352661133, "timer/agent.train_max": 0.6075379848480225, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47931551933288574, "timer/agent.report_frac": 0.00047925186492391145, "timer/agent.report_avg": 0.23965775966644287, "timer/agent.report_min": 0.23223304748535156, "timer/agent.report_max": 0.24708247184753418, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8606429975636314e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 31.811207352629136}
{"step": 890880, "time": 28247.05241394043, "episode/length": 98.0, "episode/score": 0.7321760111948379, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.038425962032647476}
{"step": 891064, "time": 28252.49235868454, "episode/length": 99.0, "episode/score": 0.7431288639845661, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.05250387019532354}
{"step": 891112, "time": 28253.966089963913, "episode/length": 288.0, "episode/score": 0.07924819808590655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07924819808590655}
{"step": 891264, "time": 28258.86448597908, "episode/length": 288.0, "episode/score": 0.08610788444048012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08610788444048012}
{"step": 891384, "time": 28262.336613178253, "episode/length": 98.0, "episode/score": 0.7363871129138602, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.04263706573073023}
{"step": 891480, "time": 28265.40543794632, "episode/length": 194.0, "episode/score": 0.4494465813159536, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.05569656983158211}
{"step": 891504, "time": 28266.363770484924, "episode/length": 77.0, "episode/score": 0.8089115148308679, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.049536513352393285}
{"step": 891936, "time": 28279.631264686584, "episode/length": 102.0, "episode/score": 0.7384504636012821, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.057200462122807494}
{"step": 891944, "time": 28279.66471171379, "episode/length": 109.0, "episode/score": 0.713949694067253, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.05457465275145523}
{"step": 892072, "time": 28283.606825590134, "episode/length": 73.0, "episode/score": 0.806818352098901, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.03494331486928104}
{"step": 892504, "time": 28296.99574303627, "episode/length": 69.0, "episode/score": 0.8168541580744204, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.03247916926193284}
{"step": 892504, "time": 28297.00340270996, "episode/length": 124.0, "episode/score": 0.6726623066272737, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.06016231781478609}
{"step": 892520, "time": 28297.506684541702, "episode/length": 288.0, "episode/score": 0.07441467390560774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07441467390560774}
{"step": 892592, "time": 28299.958960056305, "episode/length": 165.0, "episode/score": 0.5251143276640278, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.04073932782409884}
{"step": 892680, "time": 28302.445590257645, "episode/length": 288.0, "episode/score": 0.08995459392167504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08995459392167504}
{"step": 893064, "time": 28314.703978061676, "episode/length": 58.0, "episode/score": 0.8467163162258089, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.027966269944897704}
{"step": 893080, "time": 28315.218111038208, "episode/length": 125.0, "episode/score": 0.6609989449329419, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.05162396908912115}
{"step": 893152, "time": 28317.645480632782, "episode/length": 151.0, "episode/score": 0.5989040026798875, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.07077898928048398}
{"step": 893160, "time": 28317.678772687912, "episode/length": 79.0, "episode/score": 0.7872272968838843, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.03410229813243859}
{"step": 893272, "time": 28321.136261701584, "episode/length": 95.0, "episode/score": 0.7625333692563458, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.05940838436123386}
{"step": 893392, "time": 28325.232118844986, "episode/length": 110.0, "episode/score": 0.7093733622630225, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.05312337543250578}
{"step": 893480, "time": 28327.749907016754, "episode/length": 10.0, "episode/score": 0.9778675246310513, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.009117502191998028}
{"step": 893560, "time": 28330.22488307953, "episode/length": 109.0, "episode/score": 0.6979684742332211, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.03859348646847138}
{"step": 893680, "time": 28334.122584104538, "episode/length": 74.0, "episode/score": 0.7972329504778486, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.02848296687494667}
{"step": 893696, "time": 28334.617176771164, "episode/length": 288.0, "episode/score": 0.07583593771289543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07583593771289543}
{"step": 893696, "time": 28334.622504472733, "episode/length": 78.0, "episode/score": 0.7829941763484953, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.026744167611525427}
{"step": 893944, "time": 28341.99691081047, "episode/length": 98.0, "episode/score": 0.7198124934861312, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.026062463197774832}
{"step": 894016, "time": 28344.41721725464, "episode/length": 56.0, "episode/score": 0.8452154407199828, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.02021547278076241}
{"step": 894080, "time": 28346.392225027084, "episode/length": 47.0, "episode/score": 0.878907159624589, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.025782209878173035}
{"step": 894104, "time": 28346.913552999496, "episode/length": 117.0, "episode/score": 0.6939146027983725, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.05953963871832002}
{"step": 894112, "time": 28347.38310456276, "episode/length": 51.0, "episode/score": 0.8661362764559613, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.02551129175293454}
{"step": 894136, "time": 28347.90689611435, "episode/length": 107.0, "episode/score": 0.708056714741474, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.04243173213683349}
{"step": 894352, "time": 28354.78266811371, "episode/length": 83.0, "episode/score": 0.7775290847977203, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.03690408717841365}
{"step": 894400, "time": 28356.360486984253, "episode/length": 114.0, "episode/score": 0.7025413928433295, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.05879140403084193}
{"step": 894576, "time": 28361.75261449814, "episode/length": 58.0, "episode/score": 0.839440065624558, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.020690016462367566}
{"step": 894640, "time": 28363.71715116501, "episode/length": 77.0, "episode/score": 0.7840634216746594, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.02468843907001883}
{"step": 894816, "time": 28369.10615992546, "episode/length": 51.0, "episode/score": 0.8518500736998362, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.011225081531677006}
{"step": 894872, "time": 28370.62134051323, "episode/length": 98.0, "episode/score": 0.748708142908356, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.054958133225511574}
{"step": 895160, "time": 28379.445481300354, "episode/length": 151.0, "episode/score": 0.5927861085713744, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.06466113465131684}
{"step": 895200, "time": 28380.889300107956, "episode/length": 132.0, "episode/score": 0.6208650525463781, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.033365053949182766}
{"step": 895232, "time": 28381.868633270264, "episode/length": 109.0, "episode/score": 0.7104461866273368, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.05107115226735459}
{"step": 895608, "time": 28393.285751342773, "episode/length": 98.0, "episode/score": 0.7350458971759508, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.04129587349416397}
{"step": 895672, "time": 28395.26766729355, "episode/length": 58.0, "episode/score": 0.8361853436711044, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.017435320047525238}
{"step": 895712, "time": 28396.71558713913, "episode/length": 59.0, "episode/score": 0.8416168589684503, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.025991860217004614}
{"step": 895840, "time": 28400.641033649445, "episode/length": 20.0, "episode/score": 0.9539843907600698, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.01648441717179594}
{"step": 895848, "time": 28400.67365503311, "episode/length": 85.0, "episode/score": 0.7605800113234977, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.026205021393423067}
{"step": 896264, "time": 28413.399369239807, "episode/length": 51.0, "episode/score": 0.8517503538366213, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.011125375827475636}
{"step": 896408, "time": 28417.972491264343, "episode/length": 220.0, "episode/score": 0.3629210768048097, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.05042106210737529}
{"step": 896424, "time": 28418.474966287613, "episode/length": 288.0, "episode/score": 0.06792569924226655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06792569924226655}
{"step": 896624, "time": 28424.891526460648, "episode/length": 218.0, "episode/score": 0.36253825190487987, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0437882514188459}
{"step": 896888, "time": 28432.78923201561, "episode/length": 288.0, "episode/score": 0.06363758210642345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06363758210642345}
{"step": 896904, "time": 28433.283964395523, "episode/length": 132.0, "episode/score": 0.6303297419696037, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0428297433724083}
{"step": 897024, "time": 28437.176404476166, "episode/length": 74.0, "episode/score": 0.8244389335932851, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.055688917583267994}
{"step": 897040, "time": 28437.67145705223, "episode/length": 96.0, "episode/score": 0.734559962035064, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.034559974072408295}
{"step": 897216, "time": 28443.075840711594, "episode/length": 73.0, "episode/score": 0.8041909637798312, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.03231593547053535}
{"step": 897448, "time": 28450.104145526886, "episode/length": 69.0, "episode/score": 0.8160754195637878, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0317004197209485}
{"step": 897504, "time": 28452.035630464554, "episode/length": 136.0, "episode/score": 0.6462011358815403, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.07120112536341594}
{"step": 897760, "time": 28459.899648189545, "episode/length": 106.0, "episode/score": 0.7008342035291548, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.03208421559560293}
{"step": 897800, "time": 28460.90904736519, "episode/length": 94.0, "episode/score": 0.7482743028527352, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.04202430509081978}
{"step": 897856, "time": 28462.834236860275, "episode/length": 50.0, "episode/score": 0.8587621366676217, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.015012136813140842}
{"step": 897864, "time": 28462.867260932922, "episode/length": 104.0, "episode/score": 0.7182599351000931, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0432599345878657}
{"step": 897920, "time": 28464.813366413116, "episode/length": 288.0, "episode/score": 0.05116676242812446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05116676242812446}
{"step": 898024, "time": 28467.779839515686, "episode/length": 288.0, "episode/score": 0.09133281271624583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09133281271624583}
{"step": 898112, "time": 28470.692226409912, "episode/length": 38.0, "episode/score": 0.8969496723963744, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.015699620440216222}
{"step": 898152, "time": 28471.697231292725, "episode/length": 116.0, "episode/score": 0.695618646074081, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.05811868421756117}
{"step": 898312, "time": 28476.72556424141, "episode/length": 48.0, "episode/score": 0.8735053078008264, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.02350528407538377}
{"step": 898352, "time": 28478.19186282158, "episode/length": 40.0, "episode/score": 0.8880609504569748, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.01306096052690009}
{"step": 898472, "time": 28481.628571033478, "episode/length": 75.0, "episode/score": 0.7859412077428942, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.02031621680873741}
{"step": 898480, "time": 28482.099090576172, "episode/length": 121.0, "episode/score": 0.6540933381130571, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.03221834358748765}
{"step": 898656, "time": 28487.49516248703, "episode/length": 99.0, "episode/score": 0.7383980143937379, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.04777301455089855}
{"step": 898688, "time": 28488.49713754654, "episode/length": 66.0, "episode/score": 0.8074783221527468, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.013728348232689314}
{"step": 898736, "time": 28489.974894285202, "episode/length": 47.0, "episode/score": 0.8842153515133191, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.03109037551524807}
{"step": 898800, "time": 28491.93691420555, "episode/length": 129.0, "episode/score": 0.6620099994977409, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.06513498310937393}
{"step": 899104, "time": 28501.2705681324, "episode/length": 77.0, "episode/score": 0.7837854538498732, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.024410477808146425}
{"step": 899392, "time": 28510.227377414703, "episode/length": 114.0, "episode/score": 0.6845869131109907, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.04083691833221792}
{"step": 899448, "time": 28511.724812746048, "episode/length": 42.0, "episode/score": 0.8783413153474271, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.00959132399708551}
{"step": 899584, "time": 28516.111044168472, "episode/length": 115.0, "episode/score": 0.6754490225859513, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.03482401299623916}
{"step": 899600, "time": 28516.606757879257, "episode/length": 107.0, "episode/score": 0.6977054109462983, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.032080434933675406}
{"step": 899704, "time": 28519.59294605255, "episode/length": 126.0, "episode/score": 0.6669387393439479, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.06068876840703297}
{"step": 899864, "time": 28524.49714922905, "episode/length": 51.0, "episode/score": 0.8697574304987938, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.029132468642274034}
{"step": 900016, "time": 28530.17924427986, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 900016, "time": 28530.435389518738, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 900016, "time": 28530.98906469345, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 900016, "time": 28531.035658597946, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 900016, "time": 28531.502205371857, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 900016, "time": 28531.632989645004, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 900016, "time": 28531.76261305809, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 900016, "time": 28531.766632318497, "eval_episode/length": 7.0, "eval_episode/score": 0.9781249761581421, "eval_episode/reward_rate": 0.125}
{"step": 900096, "time": 28534.220811605453, "episode/length": 87.0, "episode/score": 0.7640420546653104, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.03591707862358362}
{"step": 900320, "time": 28541.238110542297, "episode/length": 56.0, "episode/score": 0.8404969427699029, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.015496945101119763}
{"step": 900424, "time": 28544.200506210327, "episode/length": 288.0, "episode/score": 0.07430684248828356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07430684248828356}
{"step": 900600, "time": 28549.62438082695, "episode/length": 126.0, "episode/score": 0.62769833475204, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.021448323455388163}
{"step": 900624, "time": 28550.57995080948, "episode/length": 288.0, "episode/score": 0.0782146720214314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0782146720214314}
{"step": 900672, "time": 28552.048481225967, "episode/length": 71.0, "episode/score": 0.8083979971490294, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.030272993877758836}
{"step": 900688, "time": 28552.543174266815, "episode/length": 122.0, "episode/score": 0.6589780980577871, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.040228133308346514}
{"step": 901024, "time": 28562.86675810814, "episode/length": 87.0, "episode/score": 0.7499820188426156, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.021857050738958606}
{"step": 901112, "time": 28565.44189119339, "episode/length": 288.0, "episode/score": 0.06557436126962557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06557436126962557}
{"step": 901200, "time": 28568.83242201805, "episode/length": 71.0, "episode/score": 0.8122558916377898, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.03413091161320381}
{"step": 901240, "time": 28569.862573623657, "episode/length": 68.0, "episode/score": 0.7963976174103209, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.008897576972003662}
{"step": 901336, "time": 28572.802108049393, "episode/length": 113.0, "episode/score": 0.6718158854009744, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.024940871629041794}
{"step": 901656, "time": 28582.61685347557, "episode/length": 131.0, "episode/score": 0.6355212409071669, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.04489624151398175}
{"step": 901688, "time": 28583.603621006012, "episode/length": 71.0, "episode/score": 0.8108528920063804, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.032727901591727004}
{"step": 901696, "time": 28584.07346391678, "episode/length": 56.0, "episode/score": 0.8329391015191163, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.007939096843585958}
{"step": 901912, "time": 28590.50420665741, "episode/length": 288.0, "episode/score": 0.044333757463277834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044333757463277834}
{"step": 902072, "time": 28595.519726276398, "episode/length": 108.0, "episode/score": 0.7073708946286956, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.04487086631939974}
{"step": 902080, "time": 28595.990845680237, "episode/length": 131.0, "episode/score": 0.6442619766368125, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.053636966307863077}
{"step": 902184, "time": 28598.97592306137, "episode/length": 188.0, "episode/score": 0.45351960111730705, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.04101961463021553}
{"step": 902208, "time": 28599.952623605728, "episode/length": 108.0, "episode/score": 0.6974701039941351, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.03497008026869253}
{"step": 902576, "time": 28611.24068546295, "episode/length": 45.0, "episode/score": 0.8742853480396775, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.014910343572239526}
{"step": 902672, "time": 28614.18726873398, "episode/length": 73.0, "episode/score": 0.7814597392180644, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.009584726930427223}
{"step": 902744, "time": 28616.173047304153, "episode/length": 130.0, "episode/score": 0.6326249271535858, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0388749372235111}
{"step": 902816, "time": 28618.587814807892, "episode/length": 78.0, "episode/score": 0.7813776891863995, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.02512767441038477}
{"step": 902832, "time": 28619.1007502079, "episode/length": 94.0, "episode/score": 0.761249460987159, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.05499946620838614}
{"step": 903168, "time": 28629.482325077057, "episode/length": 73.0, "episode/score": 0.7943195585720559, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.022444520200110674}
{"step": 903384, "time": 28635.880903720856, "episode/length": 88.0, "episode/score": 0.7504678857895897, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.025467873953061826}
{"step": 903880, "time": 28651.04118180275, "episode/length": 61.0, "episode/score": 0.8384131235843881, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.02903812591560495}
{"step": 903880, "time": 28651.046988248825, "episode/length": 132.0, "episode/score": 0.6273619026407573, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.039861898368314996}
{"step": 903968, "time": 28653.977859973907, "episode/length": 288.0, "episode/score": 0.07724035578237931, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07724035578237931}
{"step": 904000, "time": 28655.016232728958, "episode/length": 288.0, "episode/score": 0.01967902814556055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01967902814556055}
{"step": 904008, "time": 28655.08309173584, "episode/length": 104.0, "episode/score": 0.7034795986508584, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.028479572199842096}
{"step": 904224, "time": 28661.97410082817, "episode/length": 288.0, "episode/score": 0.04423882111638022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04423882111638022}
{"step": 904544, "time": 28671.906363010406, "episode/length": 82.0, "episode/score": 0.7630040982932655, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.01925413120096664}
{"step": 904944, "time": 28684.25301027298, "episode/length": 121.0, "episode/score": 0.6534453857137521, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0315703788990902}
{"step": 905008, "time": 28686.32195162773, "episode/length": 124.0, "episode/score": 0.6546391194521277, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.04213911558568384}
{"step": 905008, "time": 28686.327449798584, "episode/length": 97.0, "episode/score": 0.7319276972420425, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.03505269296960023}
{"step": 905056, "time": 28687.804297208786, "episode/length": 288.0, "episode/score": 0.07756545484082267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07756545484082267}
{"step": 905120, "time": 28689.790412187576, "episode/length": 71.0, "episode/score": 0.8131069828211537, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.03498199027464466}
{"step": 905144, "time": 28690.313841581345, "episode/length": 288.0, "episode/score": 0.0403986975291275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0403986975291275}
{"step": 905400, "time": 28698.17688679695, "episode/length": 48.0, "episode/score": 0.8684137691170122, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.018413723025275885}
{"step": 905416, "time": 28698.668444156647, "episode/length": 50.0, "episode/score": 0.8648159762327623, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.02106596664305016}
{"step": 905808, "time": 28710.877655744553, "episode/length": 82.0, "episode/score": 0.7588938393920728, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.015143871288415767}
{"step": 905848, "time": 28711.883372068405, "episode/length": 98.0, "episode/score": 0.732570556674915, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.038820521518942996}
{"step": 906192, "time": 28722.78882241249, "episode/length": 288.0, "episode/score": 0.02797472086160724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02797472086160724}
{"step": 906312, "time": 28726.23733496666, "episode/length": 288.0, "episode/score": 0.020816536248787543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020816536248787543}
{"step": 906336, "time": 28727.19299554825, "episode/length": 114.0, "episode/score": 0.6819941141334596, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.03824409262281847}
{"step": 906368, "time": 28728.191764593124, "episode/length": 64.0, "episode/score": 0.8216732371654984, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.021673236798790185}
{"step": 906480, "time": 28731.615442037582, "episode/length": 134.0, "episode/score": 0.6095918082843355, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.02834178432169665}
{"step": 906640, "time": 28736.509529829025, "episode/length": 37.0, "episode/score": 0.9016982974644634, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.017323302570730448}
{"step": 906960, "time": 28746.414808511734, "episode/length": 80.0, "episode/score": 0.7805200860692594, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.03052009762348007}
{"step": 907000, "time": 28747.440901517868, "episode/length": 78.0, "episode/score": 0.7744776746359321, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.018227641204362044}
{"step": 907160, "time": 28752.344212293625, "episode/length": 120.0, "episode/score": 0.6579808580673046, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.03298086889392948}
{"step": 907200, "time": 28753.783009052277, "episode/length": 89.0, "episode/score": 0.7428808692512234, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.02100585741033001}
{"step": 907256, "time": 28755.274394750595, "episode/length": 288.0, "episode/score": 0.04063440036236443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04063440036236443}
{"step": 907432, "time": 28760.67370915413, "episode/length": 288.0, "episode/score": 0.05004096607410702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05004096607410702}
{"step": 907520, "time": 28763.602615833282, "episode/length": 64.0, "episode/score": 0.8264375760943494, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.02643757572764116}
{"step": 907528, "time": 28763.634932279587, "episode/length": 45.0, "episode/score": 0.884428097842374, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.025053108668998902}
{"step": 907552, "time": 28764.590504169464, "episode/length": 113.0, "episode/score": 0.6878120900965996, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.04093709283381486}
{"step": 907632, "time": 28767.051823616028, "episode/length": 83.0, "episode/score": 0.7864889750277655, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.045863941596195446}
{"step": 908104, "time": 28781.481154441833, "episode/length": 72.0, "episode/score": 0.7912610064892363, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.016261002020343085}
{"step": 908120, "time": 28782.00684571266, "episode/length": 288.0, "episode/score": 0.05043599613082961, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05043599613082961}
{"step": 908136, "time": 28782.50896501541, "episode/length": 109.0, "episode/score": 0.6933469792008395, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.033971975334395665}
{"step": 908584, "time": 28796.245574951172, "episode/length": 128.0, "episode/score": 0.6318897070846958, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.03188968119829383}
{"step": 909040, "time": 28810.53931427002, "episode/length": 112.0, "episode/score": 0.684330901385124, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.034330922891399496}
{"step": 909496, "time": 28824.745569229126, "episode/length": 56.0, "episode/score": 0.8420462034306126, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.017046198755082287}
{"step": 909504, "time": 28825.215487718582, "episode/length": 114.0, "episode/score": 0.6779566559202408, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.03420664166372944}
{"step": 909512, "time": 28825.24900841713, "episode/length": 288.0, "episode/score": 0.045571946931517004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045571946931517004}
{"step": 909744, "time": 28832.5745780468, "episode/length": 288.0, "episode/score": 0.09344103213717858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09344103213717858}
{"step": 909840, "time": 28835.622165441513, "episode/length": 288.0, "episode/score": 0.021779403810313624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021779403810313624}
{"step": 909888, "time": 28837.111998319626, "episode/length": 46.0, "episode/score": 0.8672717034220625, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.011021715415751032}
{"step": 909944, "time": 28838.606857299805, "episode/length": 288.0, "episode/score": 0.052320703321925066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052320703321925066}
{"step": 910000, "time": 28841.602930545807, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 910000, "time": 28841.60763859749, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 910000, "time": 28841.644431114197, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 910000, "time": 28841.712124347687, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 910000, "time": 28842.373599290848, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 910000, "time": 28842.395751714706, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 910000, "time": 28842.431796312332, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 910000, "time": 28842.51486492157, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 910008, "time": 28842.544726371765, "episode/length": 62.0, "episode/score": 0.8238392735489981, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.017589286964408757}
{"step": 910160, "time": 28847.419893980026, "episode/length": 82.0, "episode/score": 0.7723499065361068, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.02859991906385062}
{"step": 910416, "time": 28855.290982484818, "episode/length": 288.0, "episode/score": 0.08404919356897267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08404919356897267}
{"step": 910432, "time": 28855.784891843796, "episode/length": 288.0, "episode/score": 0.04439729669167036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04439729669167036}
{"step": 910464, "time": 28856.765724897385, "episode/length": 56.0, "episode/score": 0.8394083426448447, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.014408354638533183}
{"step": 910520, "time": 28858.28795027733, "episode/length": 78.0, "episode/score": 0.7810235052899941, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.024773466918048825}
{"step": 910624, "time": 28861.67882990837, "episode/length": 109.0, "episode/score": 0.6712823262236896, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.011907340881833761}
{"step": 910888, "time": 28869.674006938934, "episode/length": 32.0, "episode/score": 0.9070596797800476, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.007059701577361466}
{"step": 911128, "time": 28877.01341867447, "episode/length": 88.0, "episode/score": 0.756826770631676, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.03182673009877135}
{"step": 911208, "time": 28879.486804008484, "episode/length": 96.0, "episode/score": 0.7523732680294586, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.052373256732806794}
{"step": 911296, "time": 28882.39308667183, "episode/length": 141.0, "episode/score": 0.605533630767809, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.04615864064419384}
{"step": 911368, "time": 28884.39798641205, "episode/length": 112.0, "episode/score": 0.6665519365379851, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.01655194584975561}
{"step": 911584, "time": 28891.234770536423, "episode/length": 56.0, "episode/score": 0.8386151655210767, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.013615199648228327}
{"step": 911832, "time": 28898.73209476471, "episode/length": 77.0, "episode/score": 0.7986745949848455, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.03929964540577657}
{"step": 912152, "time": 28908.55286049843, "episode/length": 288.0, "episode/score": 0.03912191546797317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03912191546797317}
{"step": 912152, "time": 28908.558752059937, "episode/length": 97.0, "episode/score": 0.7355899705785021, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.038715006425690035}
{"step": 912208, "time": 28910.51653265953, "episode/length": 77.0, "episode/score": 0.7724462899148818, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.013071301715029904}
{"step": 912256, "time": 28912.020553588867, "episode/length": 288.0, "episode/score": 0.050367435969491225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050367435969491225}
{"step": 912584, "time": 28921.98530817032, "episode/length": 93.0, "episode/score": 0.7251240986838354, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.015749093424773264}
{"step": 912776, "time": 28927.959595918655, "episode/length": 77.0, "episode/score": 0.7698310616797812, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.010456091560683944}
{"step": 912832, "time": 28929.884467840195, "episode/length": 288.0, "episode/score": 0.04323382646862228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04323382646862228}
{"step": 913200, "time": 28941.130682706833, "episode/length": 288.0, "episode/score": 0.060127499731436274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060127499731436274}
{"step": 913232, "time": 28942.13316679001, "episode/length": 49.0, "episode/score": 0.8600658127431018, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.013190790395725571}
{"step": 913456, "time": 28948.97109413147, "episode/length": 31.0, "episode/score": 0.9137930567978003, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.010668074757774093}
{"step": 913608, "time": 28953.40616250038, "episode/length": 288.0, "episode/score": 0.054810091149022355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054810091149022355}
{"step": 913720, "time": 28956.92849469185, "episode/length": 141.0, "episode/score": 0.582656540518002, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.023281535747884163}
{"step": 913896, "time": 28962.321436405182, "episode/length": 82.0, "episode/score": 0.7592506088635389, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.01550062227894955}
{"step": 914464, "time": 28979.942729473114, "episode/length": 288.0, "episode/score": 0.015100553344893797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.015100553344893797}
{"step": 914480, "time": 28980.44035077095, "episode/length": 127.0, "episode/score": 0.639473644749927, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.03634869079800751}
{"step": 914520, "time": 28981.46996998787, "episode/length": 288.0, "episode/score": 0.05939375003930536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05939375003930536}
{"step": 914568, "time": 28982.942318439484, "episode/length": 288.0, "episode/score": 0.022570753805155164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022570753805155164}
{"step": 914752, "time": 28988.923857688904, "episode/length": 35.0, "episode/score": 0.9085533056687325, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.017928332247805656}
{"step": 914760, "time": 28988.95637178421, "episode/length": 107.0, "episode/score": 0.6955694585700485, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.02994448248466597}
{"step": 915080, "time": 28998.765817165375, "episode/length": 40.0, "episode/score": 0.8978025390206028, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.022802557603398554}
{"step": 915088, "time": 28999.23612499237, "episode/length": 288.0, "episode/score": 0.0349617176177901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0349617176177901}
{"step": 915336, "time": 29006.629736423492, "episode/length": 30.0, "episode/score": 0.9177176200694248, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.01146762610846963}
{"step": 915496, "time": 29011.533166646957, "episode/length": 126.0, "episode/score": 0.6480401923849115, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.04179020934080313}
{"step": 915632, "time": 29016.013174772263, "episode/length": 108.0, "episode/score": 0.6968112147103795, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.034311188823977545}
{"step": 915744, "time": 29019.444195985794, "episode/length": 82.0, "episode/score": 0.7660020118538569, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.02225201159774315}
{"step": 915920, "time": 29024.842461824417, "episode/length": 288.0, "episode/score": 0.039123124642372886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039123124642372886}
{"step": 916032, "time": 29028.293593883514, "episode/length": 288.0, "episode/score": 0.05061371207997922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05061371207997922}
{"step": 916144, "time": 29031.73877978325, "episode/length": 100.0, "episode/score": 0.7102308129802566, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.02273084243333301}
{"step": 916528, "time": 29043.535330295563, "episode/length": 75.0, "episode/score": 0.7805759183696068, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.014950890058855748}
{"step": 916720, "time": 29049.529695510864, "episode/length": 85.0, "episode/score": 0.7487843642625478, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.014409393715624219}
{"step": 916752, "time": 29050.529607772827, "episode/length": 125.0, "episode/score": 0.623062209976041, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.013687220802665934}
{"step": 916832, "time": 29052.97913336754, "episode/length": 288.0, "episode/score": 0.031213063653638073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031213063653638073}
{"step": 916880, "time": 29054.459337472916, "episode/length": 288.0, "episode/score": 0.06004097983111478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06004097983111478}
{"step": 916976, "time": 29057.431239128113, "episode/length": 103.0, "episode/score": 0.7006600025498813, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.02253495039727227}
{"step": 917024, "time": 29058.906795740128, "episode/length": 61.0, "episode/score": 0.822767524025096, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.01339255452882071}
{"step": 917680, "time": 29079.639713048935, "episode/length": 115.0, "episode/score": 0.6600954012514819, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.019470387194331806}
{"step": 917808, "time": 29083.574640512466, "episode/length": 288.0, "episode/score": 0.03222134834584267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03222134834584267}
{"step": 917816, "time": 29083.607001781464, "episode/length": 104.0, "episode/score": 0.7067242455176768, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.031724252179543555}
{"step": 917824, "time": 29084.07327389717, "episode/length": 99.0, "episode/score": 0.7137272547249154, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.023102270372589828}
{"step": 917928, "time": 29087.049926042557, "episode/length": 136.0, "episode/score": 0.6047266754127065, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.02972667834055187}
{"step": 917944, "time": 29087.546327114105, "episode/length": 288.0, "episode/score": 0.023234776824750725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023234776824750725}
{"step": 918024, "time": 29090.00127005577, "episode/length": 142.0, "episode/score": 0.5726745395450621, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.01642454932976989}
{"step": 918216, "time": 29095.914970874786, "episode/length": 35.0, "episode/score": 0.8939917303567029, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.003366730414910535}
{"step": 918448, "time": 29103.246510744095, "episode/length": 79.0, "episode/score": 0.7762830736186004, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.023158061770431004}
{"step": 918672, "time": 29110.291153907776, "episode/length": 123.0, "episode/score": 0.6619464615017137, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.046321448486480676}
{"step": 918696, "time": 29110.81998538971, "episode/length": 109.0, "episode/score": 0.6821100317844468, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.022734997140702262}
{"step": 918992, "time": 29120.247497558594, "episode/length": 67.0, "episode/score": 0.7974070320644842, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.006782036574122685}
{"step": 919032, "time": 29121.271054029465, "episode/length": 288.0, "episode/score": 0.03139010695167599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03139010695167599}
{"step": 919344, "time": 29131.221801042557, "episode/length": 140.0, "episode/score": 0.630670197580173, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.06817018326108837}
{"step": 919688, "time": 29141.689363241196, "episode/length": 123.0, "episode/score": 0.6460909211355101, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.03046587796870881}
{"step": 919792, "time": 29145.111582279205, "episode/length": 139.0, "episode/score": 0.6003203426317612, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.03469531138588877}
{"step": 919848, "time": 29146.840606212616, "episode/length": 252.0, "episode/score": 0.2340315316153294, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.021531532115915297}
{"step": 919984, "time": 29151.242563009262, "episode/length": 118.0, "episode/score": 0.6461932724363635, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.01494322525323355}
{"step": 920088, "time": 29155.471789836884, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 920088, "time": 29155.651041269302, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 920088, "time": 29155.687644720078, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 920088, "time": 29155.856546640396, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 920088, "time": 29155.975034713745, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 920088, "time": 29156.529320716858, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 920088, "time": 29156.597121477127, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 920088, "time": 29156.870388507843, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 920256, "time": 29162.247012853622, "episode/length": 288.0, "episode/score": 0.025496421609148, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025496421609148}
{"step": 920336, "time": 29164.727234840393, "episode/length": 288.0, "episode/score": 0.018796281790002922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018796281790002922}
{"step": 920360, "time": 29165.373176813126, "episode/length": 83.0, "episode/score": 0.7652157958527823, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.024590757691839826}
{"step": 920848, "time": 29180.58437848091, "episode/length": 131.0, "episode/score": 0.6227985914733836, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.032173595216136164}
{"step": 921184, "time": 29190.860693216324, "episode/length": 105.0, "episode/score": 0.6937578845600001, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.021882861218728067}
{"step": 921304, "time": 29194.352077007294, "episode/length": 288.0, "episode/score": 0.054056222088007644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054056222088007644}
{"step": 921656, "time": 29205.36239027977, "episode/length": 288.0, "episode/score": 0.05094667643788853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05094667643788853}
{"step": 921920, "time": 29213.82185268402, "episode/length": 76.0, "episode/score": 0.7947824544064588, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.03228245200830315}
{"step": 922160, "time": 29221.26809668541, "episode/length": 288.0, "episode/score": 0.055205114986961235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055205114986961235}
{"step": 922200, "time": 29222.314391851425, "episode/length": 126.0, "episode/score": 0.6455931789084843, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.03934318265123693}
{"step": 922288, "time": 29225.40927219391, "episode/length": 78.0, "episode/score": 0.7816165810677376, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.025366540869526943}
{"step": 922296, "time": 29225.445437669754, "episode/length": 288.0, "episode/score": 0.01638310056125647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01638310056125647}
{"step": 922480, "time": 29231.376368522644, "episode/length": 39.0, "episode/score": 0.8877702564617493, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.009645244977377843}
{"step": 922568, "time": 29233.90664100647, "episode/length": 288.0, "episode/score": 0.05152621347747299, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05152621347747299}
{"step": 922672, "time": 29237.384964227676, "episode/length": 288.0, "episode/score": 0.022193400392211515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022193400392211515}
{"step": 922697, "time": 29238.925377368927, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.0878790860152363, "train/action_min": 0.0, "train/action_std": 1.773660824073488, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011893938656951954, "train/actor_opt_grad_steps": 56570.0, "train/actor_opt_loss": -12.7853132717645, "train/adv_mag": 0.9994158771500659, "train/adv_max": 0.2727216333892215, "train/adv_mean": 0.002019739928779126, "train/adv_min": -0.9606756081628562, "train/adv_std": 0.02955477072658082, "train/cont_avg": 0.9948839785447762, "train/cont_loss_mean": 0.018043688747485107, "train/cont_loss_std": 0.2469041079597835, "train/cont_neg_acc": 0.3182738165184855, "train/cont_neg_loss": 2.8403482593782248, "train/cont_pos_acc": 0.9998632556763455, "train/cont_pos_loss": 0.003514059835498161, "train/cont_pred": 0.9950090700121068, "train/cont_rate": 0.9948839785447762, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11366627595169627, "train/extr_critic_critic_opt_grad_steps": 56570.0, "train/extr_critic_critic_opt_loss": 12958.983150652984, "train/extr_critic_mag": 1.5132071236472817, "train/extr_critic_max": 1.5132071236472817, "train/extr_critic_mean": 1.4074120960425383, "train/extr_critic_min": 1.2739343726219823, "train/extr_critic_std": 0.022259037311545653, "train/extr_return_normed_mag": 1.013305037175838, "train/extr_return_normed_max": 0.3139465133942182, "train/extr_return_normed_mean": 0.04289535171727636, "train/extr_return_normed_min": -0.9444752320721375, "train/extr_return_normed_std": 0.0380974561439373, "train/extr_return_rate": 0.9994869777812293, "train/extr_return_raw_mag": 1.6804828566698293, "train/extr_return_raw_max": 1.6804828566698293, "train/extr_return_raw_mean": 1.4094317641424303, "train/extr_return_raw_min": 0.4220611112034736, "train/extr_return_raw_std": 0.038097456042001494, "train/extr_reward_mag": 0.3218967446047275, "train/extr_reward_max": 0.3218967446047275, "train/extr_reward_mean": 0.0022800312909200342, "train/extr_reward_min": 4.546559272120841e-06, "train/extr_reward_std": 0.009301835009642871, "train/image_loss_mean": 0.09892948942991038, "train/image_loss_std": 0.10602756978860542, "train/model_loss_mean": 0.7434168968034621, "train/model_loss_std": 0.42213961808242606, "train/model_opt_grad_norm": 17.719905796335706, "train/model_opt_grad_steps": 56518.60199004975, "train/model_opt_loss": 3807.7193718905473, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5124.378109452737, "train/policy_entropy_mag": 1.2859093039783078, "train/policy_entropy_max": 1.2859093039783078, "train/policy_entropy_mean": 0.09669853157516736, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12196727286079037, "train/policy_logprob_mag": 6.551080286206298, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0966225078153373, "train/policy_logprob_min": -6.551080286206298, "train/policy_logprob_std": 0.6334042136941976, "train/policy_randomness_mag": 0.6608266981680002, "train/policy_randomness_max": 0.6608266981680002, "train/policy_randomness_mean": 0.04969321717670308, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0626787825195647, "train/post_ent_mag": 2.8456704118358553, "train/post_ent_max": 2.8456704118358553, "train/post_ent_mean": 2.844221940681116, "train/post_ent_min": 2.8435281876900897, "train/post_ent_std": 0.0004180321885899534, "train/prior_ent_mag": 2.9694489009344758, "train/prior_ent_max": 2.9694489009344758, "train/prior_ent_mean": 2.815514982043214, "train/prior_ent_min": 2.8110988768772107, "train/prior_ent_std": 0.009231831554082496, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0018424588828683548, "train/reward_loss_mean": 0.02644369843883894, "train/reward_loss_std": 0.18601801354827277, "train/reward_max_data": 0.7057231858659961, "train/reward_max_pred": 0.2400486125281794, "train/reward_neg_acc": 0.999741827374074, "train/reward_neg_loss": 0.017754492841067896, "train/reward_pos_acc": 0.2278711497783661, "train/reward_pos_loss": 3.979879792998819, "train/reward_pred": 0.0015705040620120974, "train/reward_rate": 0.0021814754353233832, "train_stats/mean_log_entropy": 0.07652543711229268, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.01137632131576538, "report/cont_loss_std": 0.19500179588794708, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.1907689571380615, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0028296844102442265, "report/cont_pred": 0.9954431056976318, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07643358409404755, "report/image_loss_std": 0.09385434538125992, "report/model_loss_mean": 0.705173134803772, "report/model_loss_std": 0.22441373765468597, "report/post_ent_mag": 2.83187198638916, "report/post_ent_max": 2.83187198638916, "report/post_ent_mean": 2.8309192657470703, "report/post_ent_min": 2.830566883087158, "report/post_ent_std": 0.00020916970970574766, "report/prior_ent_mag": 2.9850165843963623, "report/prior_ent_max": 2.9850165843963623, "report/prior_ent_mean": 2.8145017623901367, "report/prior_ent_min": 2.811044216156006, "report/prior_ent_std": 0.007878141477704048, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004050815769005567, "report/reward_loss_mean": 0.01736317202448845, "report/reward_loss_std": 0.027276821434497833, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.09344804286956787, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01736317202448845, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.000992123386822641, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.01706700213253498, "eval/cont_loss_std": 0.2523413896560669, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.58975887298584, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0036310807336121798, "eval/cont_pred": 0.9964491128921509, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1556386798620224, "eval/image_loss_std": 0.13405273854732513, "eval/model_loss_mean": 0.7804940938949585, "eval/model_loss_std": 0.36308202147483826, "eval/post_ent_mag": 2.83187198638916, "eval/post_ent_max": 2.83187198638916, "eval/post_ent_mean": 2.8309974670410156, "eval/post_ent_min": 2.83058762550354, "eval/post_ent_std": 0.00024366858997382224, "eval/prior_ent_mag": 2.961392879486084, "eval/prior_ent_max": 2.961392879486084, "eval/prior_ent_mean": 2.8154613971710205, "eval/prior_ent_min": 2.811103343963623, "eval/prior_ent_std": 0.008260251022875309, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008026122814044356, "eval/reward_loss_mean": 0.007788378279656172, "eval/reward_loss_std": 0.13571199774742126, "eval/reward_max_data": 0.8218749761581421, "eval/reward_max_pred": 0.06200242042541504, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.003550320165231824, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.343321800231934, "eval/reward_pred": 0.0009305428247898817, "eval/reward_rate": 0.0009765625, "replay/size": 922193.0, "replay/inserts": 32096.0, "replay/samples": 32096.0, "replay/insert_wait_avg": 1.1854594274389662e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.522189367566246e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3200.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0250508785247804e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4099514484406, "timer/env.step_count": 4012.0, "timer/env.step_total": 34.83283805847168, "timer/env.step_frac": 0.03481856413767082, "timer/env.step_avg": 0.008682163025541296, "timer/env.step_min": 0.007167339324951172, "timer/env.step_max": 0.03869009017944336, "timer/replay._sample_count": 32096.0, "timer/replay._sample_total": 16.081528902053833, "timer/replay._sample_frac": 0.016074938957544593, "timer/replay._sample_avg": 0.000501044644256413, "timer/replay._sample_min": 0.0003609657287597656, "timer/replay._sample_max": 0.011082649230957031, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4412.0, "timer/agent.policy_total": 37.777334690093994, "timer/agent.policy_frac": 0.03776185416328395, "timer/agent.policy_avg": 0.008562405868108339, "timer/agent.policy_min": 0.007467746734619141, "timer/agent.policy_max": 0.07599782943725586, "timer/dataset_train_count": 2006.0, "timer/dataset_train_total": 0.2115311622619629, "timer/dataset_train_frac": 0.00021144448029100283, "timer/dataset_train_avg": 0.00010544923343068938, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.0002493858337402344, "timer/agent.train_count": 2006.0, "timer/agent.train_total": 883.3186633586884, "timer/agent.train_frac": 0.8829566939830797, "timer/agent.train_avg": 0.4403383167291567, "timer/agent.train_min": 0.4291224479675293, "timer/agent.train_max": 0.6206753253936768, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4783949851989746, "timer/agent.report_frac": 0.0004781989468480715, "timer/agent.report_avg": 0.2391974925994873, "timer/agent.report_min": 0.23337650299072266, "timer/agent.report_max": 0.24501848220825195, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.336492307567677e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 32.082278553423215}
{"step": 922712, "time": 29238.989790678024, "episode/length": 63.0, "episode/score": 0.8177996761751274, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.01467464415509312}
{"step": 922744, "time": 29240.437680482864, "episode/length": 55.0, "episode/score": 0.8436004731152025, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.015475443720333715}
{"step": 922840, "time": 29243.47780418396, "episode/length": 33.0, "episode/score": 0.9181812500812612, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.02130623916150398}
{"step": 923136, "time": 29252.740355730057, "episode/length": 52.0, "episode/score": 0.8796778147363966, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.04217784020806903}
{"step": 923160, "time": 29253.28633570671, "episode/length": 288.0, "episode/score": 0.045374749154461824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045374749154461824}
{"step": 923392, "time": 29260.728105306625, "episode/length": 80.0, "episode/score": 0.7906234900478921, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.04062349086279937}
{"step": 923392, "time": 29260.734596014023, "episode/length": 68.0, "episode/score": 0.8379885661001936, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.050488513620166486}
{"step": 923776, "time": 29272.530612945557, "episode/length": 76.0, "episode/score": 0.8212051693606099, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.05870519420363962}
{"step": 923856, "time": 29274.99697804451, "episode/length": 57.0, "episode/score": 0.8591959115412919, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.037320906744980675}
{"step": 923984, "time": 29278.921614408493, "episode/length": 73.0, "episode/score": 0.8295669698238726, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.05769195890411538}
{"step": 924232, "time": 29286.42929172516, "episode/length": 288.0, "episode/score": 0.08607471421726132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08607471421726132}
{"step": 924480, "time": 29294.226932525635, "episode/length": 77.0, "episode/score": 0.8210517155043817, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.06167674016114688}
{"step": 924600, "time": 29297.682030916214, "episode/length": 288.0, "episode/score": 0.1084291595157083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1084291595157083}
{"step": 924656, "time": 29299.607316493988, "episode/length": 83.0, "episode/score": 0.7958282809181583, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.05520326999840108}
{"step": 924792, "time": 29303.5603992939, "episode/length": 288.0, "episode/score": 0.1025455833646447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1025455833646447}
{"step": 924808, "time": 29304.056609869003, "episode/length": 25.0, "episode/score": 0.9466942817393829, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.024819282554290112}
{"step": 924984, "time": 29309.457966566086, "episode/length": 288.0, "episode/score": 0.0895413947483803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0895413947483803}
{"step": 925448, "time": 29323.84653878212, "episode/length": 288.0, "episode/score": 0.1344220711739581, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1344220711739581}
{"step": 925472, "time": 29324.81135416031, "episode/length": 123.0, "episode/score": 0.6952109093738272, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.07958586917561661}
{"step": 925528, "time": 29326.31595659256, "episode/length": 91.0, "episode/score": 0.7969680915618937, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.08134308712646998}
{"step": 925600, "time": 29328.762180805206, "episode/length": 98.0, "episode/score": 0.7798910715609964, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.08614102839419502}
{"step": 925840, "time": 29336.624007701874, "episode/length": 200.0, "episode/score": 0.5278613032505746, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.15286131372795353}
{"step": 926008, "time": 29341.5720205307, "episode/length": 66.0, "episode/score": 0.8370904254802554, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.04334043821609157}
{"step": 926080, "time": 29344.018909454346, "episode/length": 8.0, "episode/score": 0.98488741842948, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.009887378231269395}
{"step": 926088, "time": 29344.05219268799, "episode/length": 288.0, "episode/score": 0.12462966260159192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12462966260159192}
{"step": 926208, "time": 29348.076419830322, "episode/length": 45.0, "episode/score": 0.8922380436915773, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.032863020350305305}
{"step": 926376, "time": 29353.009474992752, "episode/length": 105.0, "episode/score": 0.7738373634301752, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.10196236386673263}
{"step": 926760, "time": 29364.77196598053, "episode/length": 84.0, "episode/score": 0.7973091921815012, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.05980916594148766}
{"step": 926864, "time": 29368.188678979874, "episode/length": 96.0, "episode/score": 0.7739703260400574, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.07397032160463368}
{"step": 926872, "time": 29368.22123837471, "episode/length": 158.0, "episode/score": 0.6169716439702597, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.11072160580931723}
{"step": 926904, "time": 29369.205936193466, "episode/length": 86.0, "episode/score": 0.7932722026276906, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.062022195223676135}
{"step": 926968, "time": 29371.16527557373, "episode/length": 288.0, "episode/score": 0.1057568726844238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1057568726844238}
{"step": 927296, "time": 29381.580481290817, "episode/length": 288.0, "episode/score": 0.08246999701339064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08246999701339064}
{"step": 927440, "time": 29386.01162290573, "episode/length": 84.0, "episode/score": 0.796691166229607, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.05919115474523551}
{"step": 927680, "time": 29393.368292331696, "episode/length": 96.0, "episode/score": 0.7721267941863061, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.07212678678229167}
{"step": 927760, "time": 29395.810708522797, "episode/length": 288.0, "episode/score": 0.07836971581582475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07836971581582475}
{"step": 927832, "time": 29397.816700458527, "episode/length": 119.0, "episode/score": 0.7002929395596311, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.07216790831375874}
{"step": 927904, "time": 29400.236630916595, "episode/length": 116.0, "episode/score": 0.7091453317265177, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.07164531425257792}
{"step": 927912, "time": 29400.271286725998, "episode/length": 76.0, "episode/score": 0.8062347067335622, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.043734699329547766}
{"step": 928176, "time": 29408.71775174141, "episode/length": 61.0, "episode/score": 0.8536177680595074, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.04424276659267434}
{"step": 928296, "time": 29412.188745498657, "episode/length": 106.0, "episode/score": 0.7225980446534095, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0538480570108959}
{"step": 928568, "time": 29420.53335905075, "episode/length": 100.0, "episode/score": 0.7503894903593391, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.06288949079589656}
{"step": 928688, "time": 29424.438725471497, "episode/length": 288.0, "episode/score": 0.0753767365550857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0753767365550857}
{"step": 928880, "time": 29430.357484817505, "episode/length": 121.0, "episode/score": 0.6680321565668237, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.046157160309576284}
{"step": 928896, "time": 29430.854377031326, "episode/length": 89.0, "episode/score": 0.7819228794196533, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.06004789165490365}
{"step": 929176, "time": 29439.359804868698, "episode/length": 288.0, "episode/score": 0.06665991770080382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06665991770080382}
{"step": 929440, "time": 29447.68135547638, "episode/length": 142.0, "episode/score": 0.6153277007679208, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.05907772504633613}
{"step": 929696, "time": 29455.534566879272, "episode/length": 140.0, "episode/score": 0.6160653628120372, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.053565349424275155}
{"step": 929856, "time": 29460.455370426178, "episode/length": 19.0, "episode/score": 0.964065341873038, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.023440322792566803}
{"step": 929856, "time": 29460.46271276474, "episode/length": 121.0, "episode/score": 0.6753658241248104, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.05349085618559002}
{"step": 929976, "time": 29463.947281122208, "episode/length": 66.0, "episode/score": 0.8191848984193939, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0254349021621465}
{"step": 930072, "time": 29467.686443805695, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 930072, "time": 29467.846536636353, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 930072, "time": 29468.008502960205, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 930072, "time": 29468.01416349411, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 930072, "time": 29468.19625020027, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 930072, "time": 29468.28107213974, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 930072, "time": 29468.455473423004, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 930072, "time": 29468.679518461227, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 930144, "time": 29471.100332975388, "episode/length": 288.0, "episode/score": 0.08184312232344837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08184312232344837}
{"step": 930224, "time": 29473.575882673264, "episode/length": 288.0, "episode/score": 0.07718135107779744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07718135107779744}
{"step": 930304, "time": 29476.03409075737, "episode/length": 55.0, "episode/score": 0.8642532474689233, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.03612823929074693}
{"step": 930736, "time": 29489.297578811646, "episode/length": 109.0, "episode/score": 0.6985548130141979, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.039179793933726614}
{"step": 930752, "time": 29489.79053425789, "episode/length": 55.0, "episode/score": 0.8623919197884788, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.03426689039361008}
{"step": 931000, "time": 29497.32567501068, "episode/length": 288.0, "episode/score": 0.06598441583912518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06598441583912518}
{"step": 931200, "time": 29503.68085694313, "episode/length": 57.0, "episode/score": 0.8513018671659438, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.029426883848259422}
{"step": 931208, "time": 29503.71427989006, "episode/length": 288.0, "episode/score": 0.0678450431763622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0678450431763622}
{"step": 931488, "time": 29512.570012569427, "episode/length": 288.0, "episode/score": 0.07461422589631184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07461422589631184}
{"step": 931632, "time": 29517.052996873856, "episode/length": 52.0, "episode/score": 0.8549820808324284, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.01748209649610999}
{"step": 932008, "time": 29528.49826169014, "episode/length": 156.0, "episode/score": 0.5695872927875598, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.057087296530312415}
{"step": 932288, "time": 29537.30728983879, "episode/length": 288.0, "episode/score": 0.04448132986993869, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04448132986993869}
{"step": 932296, "time": 29537.340218305588, "episode/length": 100.0, "episode/score": 0.7364499657127226, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.04894995753454623}
{"step": 932352, "time": 29539.2689743042, "episode/length": 89.0, "episode/score": 0.7622067731437028, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.040331789540800855}
{"step": 932456, "time": 29542.255756139755, "episode/length": 288.0, "episode/score": 0.042698269030609026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042698269030609026}
{"step": 932536, "time": 29544.71049928665, "episode/length": 288.0, "episode/score": 0.07033203821328016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07033203821328016}
{"step": 932544, "time": 29545.180496931076, "episode/length": 167.0, "episode/score": 0.5498394103498185, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0717144029050587}
{"step": 932600, "time": 29546.69287753105, "episode/length": 73.0, "episode/score": 0.8040726489245458, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0321976534007149}
{"step": 932656, "time": 29548.625247240067, "episode/length": 45.0, "episode/score": 0.868103112762924, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.008728136919103235}
{"step": 932840, "time": 29554.038491010666, "episode/length": 60.0, "episode/score": 0.8456443882631106, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.03314441658113765}
{"step": 932880, "time": 29555.59096813202, "episode/length": 42.0, "episode/score": 0.8874551437198761, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.018705142241401518}
{"step": 933040, "time": 29560.495743751526, "episode/length": 92.0, "episode/score": 0.7471689733289395, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.03466899001125512}
{"step": 933304, "time": 29568.383227825165, "episode/length": 52.0, "episode/score": 0.8556829896518252, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.018183016869727453}
{"step": 933312, "time": 29568.85250401497, "episode/length": 288.0, "episode/score": 0.06527579116789184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06527579116789184}
{"step": 933560, "time": 29576.248529434204, "episode/length": 137.0, "episode/score": 0.6135690699965721, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.04169411197011641}
{"step": 933608, "time": 29577.721633672714, "episode/length": 36.0, "episode/score": 0.9079957985976534, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.020495813894626735}
{"step": 933608, "time": 29577.72759437561, "episode/length": 95.0, "episode/score": 0.7400137221754335, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.03688875049346052}
{"step": 934008, "time": 29590.620004177094, "episode/length": 168.0, "episode/score": 0.5573996156242629, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.08239961192225564}
{"step": 934112, "time": 29594.025097370148, "episode/length": 68.0, "episode/score": 0.8248311805614321, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.037331176859424886}
{"step": 934200, "time": 29596.514222860336, "episode/length": 111.0, "episode/score": 0.7012563899146471, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.048131419967262445}
{"step": 934320, "time": 29600.389392852783, "episode/length": 159.0, "episode/score": 0.5573250955052913, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.05420009868925035}
{"step": 934544, "time": 29607.25100517273, "episode/length": 116.0, "episode/score": 0.6818975716983573, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.04439758383756498}
{"step": 934728, "time": 29612.665301322937, "episode/length": 76.0, "episode/score": 0.7897985600814081, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.02729859013402347}
{"step": 934784, "time": 29614.598916053772, "episode/length": 57.0, "episode/score": 0.8488632442372932, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.02698826829742984}
{"step": 934856, "time": 29616.719237565994, "episode/length": 288.0, "episode/score": 0.04707190909419978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04707190909419978}
{"step": 934912, "time": 29618.67159795761, "episode/length": 288.0, "episode/score": 0.053139449640639214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053139449640639214}
{"step": 935000, "time": 29621.163731336594, "episode/length": 123.0, "episode/score": 0.6659396864165501, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.050314665950736526}
{"step": 935112, "time": 29624.58828186989, "episode/length": 70.0, "episode/score": 0.8112636443447627, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.030013644563041453}
{"step": 935400, "time": 29633.440245628357, "episode/length": 76.0, "episode/score": 0.791420175782207, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.028920162382803483}
{"step": 935456, "time": 29635.36523079872, "episode/length": 67.0, "episode/score": 0.8196764671934602, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.02905149125359685}
{"step": 935576, "time": 29638.838433027267, "episode/length": 71.0, "episode/score": 0.821193365313718, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.043068395366333334}
{"step": 935664, "time": 29641.76818871498, "episode/length": 100.0, "episode/score": 0.7248149336911638, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.03731494686064707}
{"step": 935672, "time": 29641.800362586975, "episode/length": 69.0, "episode/score": 0.8020703235564497, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.017695305189022292}
{"step": 935920, "time": 29649.73081278801, "episode/length": 288.0, "episode/score": 0.033748896396673445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033748896396673445}
{"step": 936024, "time": 29652.697613954544, "episode/length": 55.0, "episode/score": 0.8608110406113951, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.03268604082967386}
{"step": 936080, "time": 29654.634896993637, "episode/length": 168.0, "episode/score": 0.5055041768797537, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.030504168142783783}
{"step": 936120, "time": 29655.661195993423, "episode/length": 89.0, "episode/score": 0.7800903269325659, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.058215289691304406}
{"step": 936216, "time": 29658.58776307106, "episode/length": 23.0, "episode/score": 0.9341483619489281, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.006023361215511613}
{"step": 936304, "time": 29661.524914503098, "episode/length": 47.0, "episode/score": 0.8821058551902752, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.02898090214057447}
{"step": 936352, "time": 29662.987543582916, "episode/length": 85.0, "episode/score": 0.767350565141669, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.032975591553395134}
{"step": 936400, "time": 29664.45658135414, "episode/length": 90.0, "episode/score": 0.7382688869986396, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.01951886455958629}
{"step": 936512, "time": 29667.90074491501, "episode/length": 288.0, "episode/score": 0.02035682210134837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02035682210134837}
{"step": 936872, "time": 29678.832850933075, "episode/length": 64.0, "episode/score": 0.8193258865680946, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.019325897755607002}
{"step": 936944, "time": 29681.26759672165, "episode/length": 67.0, "episode/score": 0.8209389355411645, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.03031395960130112}
{"step": 937024, "time": 29683.712332725525, "episode/length": 89.0, "episode/score": 0.7452534427440014, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.023378408384019167}
{"step": 937200, "time": 29689.097128391266, "episode/length": 85.0, "episode/score": 0.7556127431598725, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.021237736713374034}
{"step": 937344, "time": 29693.502999544144, "episode/length": 39.0, "episode/score": 0.8998541782537472, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.021729192555369536}
{"step": 937416, "time": 29695.508130788803, "episode/length": 58.0, "episode/score": 0.8348169621775128, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.01606693188915642}
{"step": 937696, "time": 29704.309186935425, "episode/length": 102.0, "episode/score": 0.7082706145591828, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.027020661509482125}
{"step": 937768, "time": 29706.448570728302, "episode/length": 288.0, "episode/score": 0.03230978786848482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03230978786848482}
{"step": 937800, "time": 29707.436341047287, "episode/length": 74.0, "episode/score": 0.7965248312563062, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.027774796896324006}
{"step": 938016, "time": 29714.26650071144, "episode/length": 39.0, "episode/score": 0.8946548095158278, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.016529791148400363}
{"step": 938392, "time": 29725.56632709503, "episode/length": 130.0, "episode/score": 0.6539874530803331, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.060237453298611854}
{"step": 938392, "time": 29725.573479890823, "episode/length": 288.0, "episode/score": 0.06787853906598684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06787853906598684}
{"step": 938432, "time": 29727.019140720367, "episode/length": 288.0, "episode/score": 0.026491127324618446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026491127324618446}
{"step": 938528, "time": 29729.962616443634, "episode/length": 288.0, "episode/score": 0.06236567972075591, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06236567972075591}
{"step": 938608, "time": 29732.414754867554, "episode/length": 73.0, "episode/score": 0.8118772972129591, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0400022509320479}
{"step": 938920, "time": 29741.880338191986, "episode/length": 48.0, "episode/score": 0.8614708805968121, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.011470850308455738}
{"step": 938968, "time": 29743.35548734665, "episode/length": 71.0, "episode/score": 0.8135442227345493, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.035419234815549316}
{"step": 939032, "time": 29745.329557657242, "episode/length": 79.0, "episode/score": 0.7673816098411521, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.014256609998312797}
{"step": 939304, "time": 29753.649102449417, "episode/length": 86.0, "episode/score": 0.7677680389145962, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.03651802839647189}
{"step": 939520, "time": 29760.499549388885, "episode/length": 68.0, "episode/score": 0.8296229800546939, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.042122968290925655}
{"step": 939728, "time": 29766.95858693123, "episode/length": 288.0, "episode/score": 0.021035133857310484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021035133857310484}
{"step": 939856, "time": 29770.897352933884, "episode/length": 15.0, "episode/score": 0.9683136330738193, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.015188659296370588}
{"step": 940056, "time": 29777.589827775955, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 940056, "time": 29777.84888625145, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 940056, "time": 29777.93306541443, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 940056, "time": 29777.937290906906, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 940056, "time": 29778.44546508789, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 940056, "time": 29778.69614982605, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 940056, "time": 29778.99624300003, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 940056, "time": 29779.466102838516, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 940080, "time": 29780.425039052963, "episode/length": 288.0, "episode/score": 0.0379317319067809, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0379317319067809}
{"step": 940112, "time": 29781.42537164688, "episode/length": 100.0, "episode/score": 0.7205031420434125, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.03300314218893163}
{"step": 940112, "time": 29781.43208217621, "episode/length": 288.0, "episode/score": 0.044602117872614144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044602117872614144}
{"step": 940352, "time": 29788.766138076782, "episode/length": 103.0, "episode/score": 0.713070557594051, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.034945533897712266}
{"step": 940368, "time": 29789.26167535782, "episode/length": 63.0, "episode/score": 0.8197842503392394, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.016659252909107636}
{"step": 940744, "time": 29800.67706155777, "episode/length": 288.0, "episode/score": 0.06026931151592407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06026931151592407}
{"step": 940832, "time": 29803.606391191483, "episode/length": 93.0, "episode/score": 0.7403222192805288, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.030947180246471362}
{"step": 940840, "time": 29803.638839006424, "episode/length": 90.0, "episode/score": 0.756196503051001, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.037446515129090585}
{"step": 941048, "time": 29810.014471292496, "episode/length": 86.0, "episode/score": 0.7471187985963752, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.015868824676317672}
{"step": 941232, "time": 29815.871967554092, "episode/length": 288.0, "episode/score": 0.06170098443055849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06170098443055849}
{"step": 941256, "time": 29816.392827510834, "episode/length": 110.0, "episode/score": 0.6955250656764065, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.039275077754496124}
{"step": 941264, "time": 29816.863649845123, "episode/length": 143.0, "episode/score": 0.5916630502064208, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.03853802227547476}
{"step": 941344, "time": 29819.325199842453, "episode/length": 288.0, "episode/score": 0.05324606200679227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05324606200679227}
{"step": 941400, "time": 29820.831629514694, "episode/length": 70.0, "episode/score": 0.7939355672527313, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.012685567398250441}
{"step": 941584, "time": 29826.793378591537, "episode/length": 39.0, "episode/score": 0.8990717058428004, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.02094667872967193}
{"step": 941616, "time": 29827.774508953094, "episode/length": 47.0, "episode/score": 0.8730960208832244, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.019971056803171905}
{"step": 941624, "time": 29827.805591106415, "episode/length": 97.0, "episode/score": 0.7339031634201092, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.03702818742203817}
{"step": 941672, "time": 29829.268683195114, "episode/length": 51.0, "episode/score": 0.8543318826772861, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.01370689474373421}
{"step": 941744, "time": 29831.690836668015, "episode/length": 124.0, "episode/score": 0.6685319138878185, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.05603190212696063}
{"step": 941792, "time": 29833.15920472145, "episode/length": 92.0, "episode/score": 0.7305203810703915, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.018020405057768585}
{"step": 941880, "time": 29835.65419960022, "episode/length": 36.0, "episode/score": 0.8997541267210067, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.012254152800949214}
{"step": 942192, "time": 29845.888083457947, "episode/length": 71.0, "episode/score": 0.8177102105471477, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.03958522261359576}
{"step": 942208, "time": 29846.37960577011, "episode/length": 57.0, "episode/score": 0.8344796334855005, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.01260466873605992}
{"step": 942224, "time": 29846.869280338287, "episode/length": 68.0, "episode/score": 0.8048302631219144, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.017330250688758042}
{"step": 942432, "time": 29853.224130630493, "episode/length": 100.0, "episode/score": 0.7163277351519923, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.028827746560693868}
{"step": 942592, "time": 29858.23521590233, "episode/length": 49.0, "episode/score": 0.8592995529413088, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.012424551090305158}
{"step": 942736, "time": 29862.638783693314, "episode/length": 63.0, "episode/score": 0.8355501157093386, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.032425087400042685}
{"step": 943024, "time": 29871.470424175262, "episode/length": 153.0, "episode/score": 0.5800379132134026, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.05816288953161575}
{"step": 943112, "time": 29873.94603419304, "episode/length": 84.0, "episode/score": 0.7805048917830391, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.04300490608466134}
{"step": 943280, "time": 29879.308916807175, "episode/length": 31.0, "episode/score": 0.9247505636878941, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.021625589767836573}
{"step": 943312, "time": 29880.307112932205, "episode/length": 137.0, "episode/score": 0.61121276463399, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.03933778863591897}
{"step": 943512, "time": 29886.400182962418, "episode/length": 96.0, "episode/score": 0.7368560334815015, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.03685607162498172}
{"step": 943656, "time": 29890.892663002014, "episode/length": 288.0, "episode/score": 0.06743336090409002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06743336090409002}
{"step": 943712, "time": 29892.85134625435, "episode/length": 288.0, "episode/score": 0.05730840780114477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05730840780114477}
{"step": 943928, "time": 29899.31113219261, "episode/length": 101.0, "episode/score": 0.7271292906839903, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.04275431267484464}
{"step": 943976, "time": 29900.802475452423, "episode/length": 86.0, "episode/score": 0.792036149157525, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.06078616122397307}
{"step": 944064, "time": 29903.708981990814, "episode/length": 68.0, "episode/score": 0.8316832795079563, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.04418325581161753}
{"step": 944192, "time": 29907.65114712715, "episode/length": 288.0, "episode/score": 0.05271673231686691, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05271673231686691}
{"step": 944320, "time": 29911.58525276184, "episode/length": 48.0, "episode/score": 0.872517732516144, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.022517693482086543}
{"step": 944400, "time": 29914.030505418777, "episode/length": 135.0, "episode/score": 0.6454520198929004, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.06732700470070085}
{"step": 944496, "time": 29917.073849916458, "episode/length": 97.0, "episode/score": 0.7420573894684139, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.04518239811807234}
{"step": 944664, "time": 29922.018570423126, "episode/length": 85.0, "episode/score": 0.780100857272032, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.04572586868073358}
{"step": 944904, "time": 29929.361099243164, "episode/length": 288.0, "episode/score": 0.04828490248593198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04828490248593198}
{"step": 944904, "time": 29929.366985559464, "episode/length": 72.0, "episode/score": 0.7924981946054004, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.017498229855959835}
{"step": 945088, "time": 29935.24000310898, "episode/length": 85.0, "episode/score": 0.7671791753269872, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.03280417085954923}
{"step": 945144, "time": 29936.73871064186, "episode/length": 118.0, "episode/score": 0.6796947593617233, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.04844472032766589}
{"step": 945200, "time": 29938.66980934143, "episode/length": 87.0, "episode/score": 0.7640545769674532, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.03592961087923641}
{"step": 945320, "time": 29942.143981456757, "episode/length": 156.0, "episode/score": 0.574023400424096, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.06152340787758703}
{"step": 945456, "time": 29946.683396100998, "episode/length": 68.0, "episode/score": 0.813569130278438, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.026069106552995436}
{"step": 945560, "time": 29951.97970843315, "episode/length": 44.0, "episode/score": 0.878302881080856, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.01580287922985235}
{"step": 945640, "time": 29954.42754507065, "episode/length": 61.0, "episode/score": 0.8546900480019417, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.04531506898871385}
{"step": 945784, "time": 29958.851179361343, "episode/length": 109.0, "episode/score": 0.710775073363834, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.051400071512830436}
{"step": 945968, "time": 29964.721104860306, "episode/length": 288.0, "episode/score": 0.06633936781832972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06633936781832972}
{"step": 946064, "time": 29967.67564558983, "episode/length": 34.0, "episode/score": 0.9240224567490714, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.030272416713842176}
{"step": 946128, "time": 29969.64466905594, "episode/length": 129.0, "episode/score": 0.651436379648942, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0545613767938562}
{"step": 946240, "time": 29973.106187582016, "episode/length": 97.0, "episode/score": 0.7425208064752837, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.04564582584970367}
{"step": 946264, "time": 29973.62673664093, "episode/length": 87.0, "episode/score": 0.7716826777183314, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.04355771870234548}
{"step": 946408, "time": 29978.17899107933, "episode/length": 17.0, "episode/score": 0.9579874095195464, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.011112403668221305}
{"step": 946832, "time": 29991.476429462433, "episode/length": 87.0, "episode/score": 0.784205282262775, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.05608030843293932}
{"step": 946872, "time": 29992.486750602722, "episode/length": 100.0, "episode/score": 0.7367402076580163, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.04924022058011701}
{"step": 946896, "time": 29993.4438495636, "episode/length": 81.0, "episode/score": 0.7982794528117836, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.05140446706101898}
{"step": 946976, "time": 29995.892065763474, "episode/length": 288.0, "episode/score": 0.0638932175035336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0638932175035336}
{"step": 947144, "time": 30000.817718744278, "episode/length": 20.0, "episode/score": 0.9498011444011354, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.012301145216042642}
{"step": 947472, "time": 30011.20214176178, "episode/length": 132.0, "episode/score": 0.6595037367381167, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.07200374626089001}
{"step": 947480, "time": 30011.235716819763, "episode/length": 188.0, "episode/score": 0.5243232469727275, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.11182325456300646}
{"step": 947632, "time": 30016.105568885803, "episode/length": 288.0, "episode/score": 0.12022764684556364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12022764684556364}
{"step": 947656, "time": 30016.62524676323, "episode/length": 102.0, "episode/score": 0.7312747470532486, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.050024742256937316}
{"step": 947784, "time": 30020.53121972084, "episode/length": 113.0, "episode/score": 0.7308266845520848, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.08395166234004137}
{"step": 947800, "time": 30021.047144651413, "episode/length": 81.0, "episode/score": 0.7930854861715488, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.046210511014578515}
{"step": 947888, "time": 30023.964783668518, "episode/length": 123.0, "episode/score": 0.6895216062202962, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.07389659530053905}
{"step": 947952, "time": 30025.94145846367, "episode/length": 288.0, "episode/score": 0.07369459320972283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07369459320972283}
{"step": 948160, "time": 30032.344972848892, "episode/length": 85.0, "episode/score": 0.7844676920267375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.050092693656552}
{"step": 948288, "time": 30036.460340976715, "episode/length": 60.0, "episode/score": 0.8518899509399489, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.039389963862049626}
{"step": 948312, "time": 30036.987662792206, "episode/length": 52.0, "episode/score": 0.8722864635437872, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.03478650030774588}
{"step": 948464, "time": 30041.963334083557, "episode/length": 100.0, "episode/score": 0.7282079241276733, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.04070790980858874}
{"step": 948584, "time": 30045.416219472885, "episode/length": 33.0, "episode/score": 0.9256953431640795, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.028820302965868905}
{"step": 948760, "time": 30050.828052520752, "episode/length": 100.0, "episode/score": 0.7585709606350974, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.07107093729382541}
{"step": 948792, "time": 30051.808566570282, "episode/length": 40.0, "episode/score": 0.8897626504704021, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.014762634114049433}
{"step": 949072, "time": 30060.611411571503, "episode/length": 60.0, "episode/score": 0.8453959107569062, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.03289588136203747}
{"step": 949240, "time": 30065.635959863663, "episode/length": 134.0, "episode/score": 0.66264218914921, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.08139215388700904}
{"step": 949360, "time": 30069.528393268585, "episode/length": 70.0, "episode/score": 0.8139149744556562, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.03266494506078743}
{"step": 949600, "time": 30076.906484365463, "episode/length": 65.0, "episode/score": 0.8396874951793052, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0428124808602206}
{"step": 949656, "time": 30078.401676654816, "episode/length": 111.0, "episode/score": 0.7223867475063344, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.06926174010231989}
{"step": 949792, "time": 30082.852387428284, "episode/length": 288.0, "episode/score": 0.11657385583862379, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11657385583862379}
{"step": 949912, "time": 30086.381460666656, "episode/length": 68.0, "episode/score": 0.8276999046524907, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.040199861485689325}
{"step": 949944, "time": 30087.38583278656, "episode/length": 288.0, "episode/score": 0.09808917980808474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09808917980808474}
{"step": 950040, "time": 30091.76460957527, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 950040, "time": 30091.80272626877, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 950040, "time": 30092.03722834587, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 950040, "time": 30092.07586121559, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 950040, "time": 30092.644233226776, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 950040, "time": 30092.859280109406, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 950040, "time": 30092.898438215256, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 950040, "time": 30093.853494644165, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 950096, "time": 30095.928009986877, "episode/length": 106.0, "episode/score": 0.7237719656077388, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.05502197796522523}
{"step": 950096, "time": 30095.935512304306, "episode/length": 288.0, "episode/score": 0.10751027453625284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10751027453625284}
{"step": 950184, "time": 30098.457033872604, "episode/length": 65.0, "episode/score": 0.8498578016735792, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.052982778332307134}
{"step": 950576, "time": 30111.243078947067, "episode/length": 97.0, "episode/score": 0.7537144838261156, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.05683947827310476}
{"step": 950600, "time": 30111.765136003494, "episode/length": 288.0, "episode/score": 0.07528296020495873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07528296020495873}
{"step": 950696, "time": 30114.718000411987, "episode/length": 74.0, "episode/score": 0.7903547638945838, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.02160472863238283}
{"step": 950752, "time": 30116.656839609146, "episode/length": 100.0, "episode/score": 0.7299230332855586, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.04242301989779662}
{"step": 950800, "time": 30118.145264148712, "episode/length": 87.0, "episode/score": 0.7762839007962157, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.04815890129680156}
{"step": 951240, "time": 30131.570766687393, "episode/length": 54.0, "episode/score": 0.8574315185524028, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.026181498453297536}
{"step": 951288, "time": 30133.04309797287, "episode/length": 66.0, "episode/score": 0.8188480366336535, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.025098048991139876}
{"step": 951480, "time": 30138.953265428543, "episode/length": 161.0, "episode/score": 0.5687953238400496, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.07192033657588581}
{"step": 951544, "time": 30140.909238815308, "episode/length": 105.0, "episode/score": 0.7105977480728143, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.038722734685052274}
{"step": 951768, "time": 30147.763129472733, "episode/length": 145.0, "episode/score": 0.59436883991998, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.04749382653221801}
{"step": 951912, "time": 30152.1804394722, "episode/length": 288.0, "episode/score": 0.059585495820329015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059585495820329015}
{"step": 951912, "time": 30152.185855150223, "episode/length": 77.0, "episode/score": 0.7843428809528632, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.024967890475636523}
{"step": 952008, "time": 30155.263145446777, "episode/length": 65.0, "episode/score": 0.8384057634525561, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.04153074709620341}
{"step": 952224, "time": 30162.102966547012, "episode/length": 288.0, "episode/score": 0.06888803294361878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06888803294361878}
{"step": 952288, "time": 30164.07963514328, "episode/length": 92.0, "episode/score": 0.7414738658204669, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.028973890098882293}
{"step": 952720, "time": 30177.303639888763, "episode/length": 100.0, "episode/score": 0.7253197322222604, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.037819756378439706}
{"step": 952720, "time": 30177.309474229813, "episode/length": 118.0, "episode/score": 0.6801856511192454, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.04893562011784525}
{"step": 952872, "time": 30181.76791858673, "episode/length": 119.0, "episode/score": 0.6666506953209819, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.03852570353990359}
{"step": 952880, "time": 30182.234892368317, "episode/length": 81.0, "episode/score": 0.7782016000869589, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.03132660382971153}
{"step": 952888, "time": 30182.268399715424, "episode/length": 288.0, "episode/score": 0.05874830042432677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05874830042432677}
{"step": 953072, "time": 30188.283408164978, "episode/length": 97.0, "episode/score": 0.7512138529883714, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.054338894961915685}
{"step": 953080, "time": 30188.316304683685, "episode/length": 133.0, "episode/score": 0.639816933103134, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0554419273929625}
{"step": 953160, "time": 30190.768847465515, "episode/length": 54.0, "episode/score": 0.8578276685734636, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.02657765687081337}
{"step": 953440, "time": 30199.570546388626, "episode/length": 44.0, "episode/score": 0.8900846422599216, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.027584611014049187}
{"step": 953504, "time": 30201.525324106216, "episode/length": 97.0, "episode/score": 0.7409662905270125, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.044091342686897406}
{"step": 953552, "time": 30203.0162255764, "episode/length": 288.0, "episode/score": 0.08101126397309599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08101126397309599}
{"step": 953576, "time": 30203.537462234497, "episode/length": 87.0, "episode/score": 0.7497958620854206, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.02167090606712918}
{"step": 953672, "time": 30206.463136434555, "episode/length": 20.0, "episode/score": 0.9490606777212633, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.011560681097307679}
{"step": 953816, "time": 30210.873908996582, "episode/length": 92.0, "episode/score": 0.7727055751056469, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.060205599384062225}
{"step": 954096, "time": 30219.843162298203, "episode/length": 150.0, "episode/score": 0.573138684634273, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.04188871295230001}
{"step": 954104, "time": 30219.87631392479, "episode/length": 117.0, "episode/score": 0.6758184293979639, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.041443427919489295}
{"step": 954240, "time": 30224.2727227211, "episode/length": 85.0, "episode/score": 0.7635664849051409, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0291914595848084}
{"step": 954600, "time": 30235.090611696243, "episode/length": 44.0, "episode/score": 0.8886196119386796, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.02611958662998859}
{"step": 954648, "time": 30236.56332707405, "episode/length": 103.0, "episode/score": 0.7154806756993821, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.037355666962412215}
{"step": 954697, "time": 30239.052738666534, "train_stats/mean_log_entropy": 0.07154482293633684, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1136181640625, "train/action_min": 0.0, "train/action_std": 1.7927355527877809, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012193129302468152, "train/actor_opt_grad_steps": 58575.0, "train/actor_opt_loss": -14.586878283023834, "train/adv_mag": 1.0807243660092354, "train/adv_max": 0.28625009655952455, "train/adv_mean": 0.00017287007853155955, "train/adv_min": -1.0532220700383186, "train/adv_std": 0.0328726798016578, "train/cont_avg": 0.9951220703125, "train/cont_loss_mean": 0.017909702957840636, "train/cont_loss_std": 0.23868645881302655, "train/cont_neg_acc": 0.27978946496943136, "train/cont_neg_loss": 2.919540982363493, "train/cont_pos_acc": 0.9998477494716644, "train/cont_pos_loss": 0.0038181797618744894, "train/cont_pred": 0.9950082287192344, "train/cont_rate": 0.9951220703125, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09833100852556527, "train/extr_critic_critic_opt_grad_steps": 58575.0, "train/extr_critic_critic_opt_loss": 12312.673930664063, "train/extr_critic_mag": 1.5403488230705262, "train/extr_critic_max": 1.5403488230705262, "train/extr_critic_mean": 1.4412178373336793, "train/extr_critic_min": 1.3109944295883178, "train/extr_critic_std": 0.022232000827789308, "train/extr_return_normed_mag": 1.085747230052948, "train/extr_return_normed_max": 0.3206156104803085, "train/extr_return_normed_mean": 0.04020386124495417, "train/extr_return_normed_min": -1.0388813549280167, "train/extr_return_normed_std": 0.04074341011233628, "train/extr_return_rate": 0.9992764094471931, "train/extr_return_raw_mag": 1.7218024468421935, "train/extr_return_raw_max": 1.7218024468421935, "train/extr_return_raw_mean": 1.4413907676935196, "train/extr_return_raw_min": 0.3623054814338684, "train/extr_return_raw_std": 0.040743410121649504, "train/extr_reward_mag": 0.3430119466781616, "train/extr_reward_max": 0.3430119466781616, "train/extr_reward_mean": 0.002408457460696809, "train/extr_reward_min": 4.8679113388061524e-06, "train/extr_reward_std": 0.009524973593652248, "train/image_loss_mean": 0.09622694753110408, "train/image_loss_std": 0.10494788978248834, "train/model_loss_mean": 0.7413536328077316, "train/model_loss_std": 0.429241725243628, "train/model_opt_grad_norm": 17.479330439567565, "train/model_opt_grad_steps": 58521.845, "train/model_opt_loss": 4209.062038574219, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5675.0, "train/policy_entropy_mag": 1.3011920768022538, "train/policy_entropy_max": 1.3011920768022538, "train/policy_entropy_mean": 0.09548446476459503, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12054540205746889, "train/policy_logprob_mag": 6.551080288887024, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09569550678133965, "train/policy_logprob_min": -6.551080288887024, "train/policy_logprob_std": 0.6347147685289383, "train/policy_randomness_mag": 0.6686804929375648, "train/policy_randomness_max": 0.6686804929375648, "train/policy_randomness_mean": 0.049069310314953325, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06194808578118682, "train/post_ent_mag": 2.82673730134964, "train/post_ent_max": 2.82673730134964, "train/post_ent_mean": 2.826097853183746, "train/post_ent_min": 2.8257914221286775, "train/post_ent_std": 0.00017271803113544593, "train/prior_ent_mag": 3.001551991701126, "train/prior_ent_max": 3.001551991701126, "train/prior_ent_mean": 2.815849730968475, "train/prior_ent_min": 2.811096383333206, "train/prior_ent_std": 0.010362029946409166, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00189591788846883, "train/reward_loss_mean": 0.02721696165855974, "train/reward_loss_std": 0.19657306117936968, "train/reward_max_data": 0.6971530493465252, "train/reward_max_pred": 0.19376395642757416, "train/reward_neg_acc": 0.9997259142994881, "train/reward_neg_loss": 0.017854763129726052, "train/reward_pos_acc": 0.1456284168802324, "train/reward_pos_loss": 4.311053743127917, "train/reward_pred": 0.001610011862940155, "train/reward_rate": 0.00224609375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.01890178769826889, "report/cont_loss_std": 0.28406190872192383, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 3.815237522125244, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004014195408672094, "report/cont_pred": 0.9951372742652893, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0813026875257492, "report/image_loss_std": 0.08910775184631348, "report/model_loss_mean": 0.7217122316360474, "report/model_loss_std": 0.3752405345439911, "report/post_ent_mag": 2.8199143409729004, "report/post_ent_max": 2.8199143409729004, "report/post_ent_mean": 2.819563388824463, "report/post_ent_min": 2.81929349899292, "report/post_ent_std": 9.775318176252767e-05, "report/prior_ent_mag": 2.882101535797119, "report/prior_ent_max": 2.882101535797119, "report/prior_ent_mean": 2.815592050552368, "report/prior_ent_min": 2.8110833168029785, "report/prior_ent_std": 0.007561128120869398, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.001089668134227395, "report/reward_loss_mean": 0.02150772511959076, "report/reward_loss_std": 0.13123655319213867, "report/reward_max_data": 0.7283172607421875, "report/reward_max_pred": 0.03182077407836914, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.017477944493293762, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.143973350524902, "report/reward_pred": 0.001524313585832715, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.04736589640378952, "eval/cont_loss_std": 0.5950197577476501, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.450788497924805, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.003291205270215869, "eval/cont_pred": 0.9967490434646606, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.15945148468017578, "eval/image_loss_std": 0.13323917984962463, "eval/model_loss_mean": 0.8387414216995239, "eval/model_loss_std": 0.9268583059310913, "eval/post_ent_mag": 2.8199052810668945, "eval/post_ent_max": 2.8199052810668945, "eval/post_ent_mean": 2.819589138031006, "eval/post_ent_min": 2.819324016571045, "eval/post_ent_std": 0.00010640519758453593, "eval/prior_ent_mag": 3.405884265899658, "eval/prior_ent_max": 3.405884265899658, "eval/prior_ent_mean": 2.8166160583496094, "eval/prior_ent_min": 2.811202049255371, "eval/prior_ent_std": 0.01999983936548233, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0038482663221657276, "eval/reward_loss_mean": 0.031924061477184296, "eval/reward_loss_std": 0.3993968665599823, "eval/reward_max_data": 0.859375, "eval/reward_max_pred": 0.054860711097717285, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00457100011408329, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.606478691101074, "eval/reward_pred": 0.0014010875020176172, "eval/reward_rate": 0.0048828125, "replay/size": 954193.0, "replay/inserts": 32000.0, "replay/samples": 32000.0, "replay/insert_wait_avg": 1.1880919337272644e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.687062025070191e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3856.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0113003837617107e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1087415218353, "timer/env.step_count": 4000.0, "timer/env.step_total": 34.39054203033447, "timer/env.step_frac": 0.034386802757071615, "timer/env.step_avg": 0.008597635507583619, "timer/env.step_min": 0.007147312164306641, "timer/env.step_max": 0.03839421272277832, "timer/replay._sample_count": 32000.0, "timer/replay._sample_total": 16.033719301223755, "timer/replay._sample_frac": 0.016031975959759862, "timer/replay._sample_avg": 0.0005010537281632424, "timer/replay._sample_min": 0.0004146099090576172, "timer/replay._sample_max": 0.011086225509643555, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4482.0, "timer/agent.policy_total": 37.66169571876526, "timer/agent.policy_frac": 0.03765760077394843, "timer/agent.policy_avg": 0.00840287722417788, "timer/agent.policy_min": 0.007439374923706055, "timer/agent.policy_max": 0.08681011199951172, "timer/dataset_train_count": 2000.0, "timer/dataset_train_total": 0.20954346656799316, "timer/dataset_train_frac": 0.00020952068297007103, "timer/dataset_train_avg": 0.00010477173328399658, "timer/dataset_train_min": 8.821487426757812e-05, "timer/dataset_train_max": 0.0003151893615722656, "timer/agent.train_count": 2000.0, "timer/agent.train_total": 882.8763267993927, "timer/agent.train_frac": 0.8827803319226531, "timer/agent.train_avg": 0.4414381633996963, "timer/agent.train_min": 0.42920422554016113, "timer/agent.train_max": 2.752016067504883, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47910523414611816, "timer/agent.report_frac": 0.0004790531411785064, "timer/agent.report_avg": 0.23955261707305908, "timer/agent.report_min": 0.23212194442749023, "timer/agent.report_max": 0.24698328971862793, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8845511366484953e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 31.995956519904805}
{"step": 954752, "time": 30240.73938846588, "episode/length": 81.0, "episode/score": 0.7890027446399017, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.04212777670068135}
{"step": 954792, "time": 30241.75149655342, "episode/length": 151.0, "episode/score": 0.5934165667508751, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.06529158204784835}
{"step": 954928, "time": 30246.322989702225, "episode/length": 102.0, "episode/score": 0.7221483614878252, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.040898388705727484}
{"step": 955000, "time": 30248.330882549286, "episode/length": 43.0, "episode/score": 0.888459607943787, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.022834570714167057}
{"step": 955088, "time": 30251.24279689789, "episode/length": 60.0, "episode/score": 0.8414591832839733, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.02895919645345657}
{"step": 955192, "time": 30254.223084926605, "episode/length": 288.0, "episode/score": 0.06739352797160336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06739352797160336}
{"step": 955600, "time": 30266.95977473259, "episode/length": 100.0, "episode/score": 0.7157095471433195, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.028209562248207476}
{"step": 955640, "time": 30268.00691819191, "episode/length": 79.0, "episode/score": 0.795044740489061, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.04191970324779959}
{"step": 955752, "time": 30271.49275279045, "episode/length": 288.0, "episode/score": 0.06963582069022323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06963582069022323}
{"step": 955920, "time": 30277.08229446411, "episode/length": 90.0, "episode/score": 0.7475283753295798, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.028778393461266205}
{"step": 955984, "time": 30279.07805776596, "episode/length": 288.0, "episode/score": 0.0578521602191131, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0578521602191131}
{"step": 956040, "time": 30280.579209804535, "episode/length": 118.0, "episode/score": 0.6678658804906945, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.03661585020233815}
{"step": 956216, "time": 30285.97097158432, "episode/length": 76.0, "episode/score": 0.8026662920574381, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0401663322963941}
{"step": 956280, "time": 30287.947707653046, "episode/length": 36.0, "episode/score": 0.9074646772553479, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.019964715588002946}
{"step": 956568, "time": 30296.76432967186, "episode/length": 101.0, "episode/score": 0.7136321565288881, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.029257194861543212}
{"step": 956800, "time": 30304.13230919838, "episode/length": 28.0, "episode/score": 0.9306528582304736, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.01815285854479498}
{"step": 956816, "time": 30304.63000893593, "episode/length": 74.0, "episode/score": 0.8035025468864205, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.034752559121670856}
{"step": 957032, "time": 30311.149787425995, "episode/length": 138.0, "episode/score": 0.6144227794304697, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.04567273314955855}
{"step": 957064, "time": 30312.134128332138, "episode/length": 288.0, "episode/score": 0.0701920758211827, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0701920758211827}
{"step": 957104, "time": 30313.600666999817, "episode/length": 102.0, "episode/score": 0.7262926576103155, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.04504268161224445}
{"step": 957128, "time": 30314.1231610775, "episode/length": 135.0, "episode/score": 0.6540297415639316, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.07590476170378224}
{"step": 957240, "time": 30317.580029010773, "episode/length": 288.0, "episode/score": 0.07663222029555072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07663222029555072}
{"step": 957504, "time": 30325.890873670578, "episode/length": 87.0, "episode/score": 0.7605763500066587, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.03245138701799988}
{"step": 957736, "time": 30332.8104596138, "episode/length": 78.0, "episode/score": 0.7875834208894616, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.03133341120661726}
{"step": 957896, "time": 30337.86232972145, "episode/length": 81.0, "episode/score": 0.7921271011313706, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.04525213319215027}
{"step": 957952, "time": 30339.830187559128, "episode/length": 288.0, "episode/score": 0.04169430622619075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04169430622619075}
{"step": 958392, "time": 30353.107338905334, "episode/length": 110.0, "episode/score": 0.7029333118208569, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.04668333196070762}
{"step": 958504, "time": 30357.031150341034, "episode/length": 95.0, "episode/score": 0.7397655812139874, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.03664060762571353}
{"step": 958648, "time": 30361.466913461685, "episode/length": 93.0, "episode/score": 0.7640852201873258, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.05471018918592563}
{"step": 958792, "time": 30366.000450134277, "episode/length": 246.0, "episode/score": 0.33358732556871473, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.10233732110418714}
{"step": 958824, "time": 30366.98064303398, "episode/length": 108.0, "episode/score": 0.7224613455385906, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.059961341836583415}
{"step": 958944, "time": 30370.88156747818, "episode/length": 68.0, "episode/score": 0.8359887838030318, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.04848878306961524}
{"step": 959200, "time": 30378.74511885643, "episode/length": 86.0, "episode/score": 0.7888807724530125, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.057630797543424706}
{"step": 959320, "time": 30382.2220556736, "episode/length": 65.0, "episode/score": 0.8444676790304584, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.04759268240650272}
{"step": 959344, "time": 30383.181422472, "episode/length": 288.0, "episode/score": 0.0844812597457576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0844812597457576}
{"step": 959376, "time": 30384.170186042786, "episode/length": 288.0, "episode/score": 0.08966145415212168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08966145415212168}
{"step": 959440, "time": 30386.14478135109, "episode/length": 288.0, "episode/score": 0.06719556631270507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06719556631270507}
{"step": 959664, "time": 30393.035333156586, "episode/length": 104.0, "episode/score": 0.7561292268399029, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.08112923305066033}
{"step": 959672, "time": 30393.06727862358, "episode/length": 28.0, "episode/score": 0.9340175964365471, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.02151757597073356}
{"step": 959808, "time": 30397.572960615158, "episode/length": 53.0, "episode/score": 0.8611694904832348, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.02679446019487841}
{"step": 959936, "time": 30401.499183177948, "episode/length": 76.0, "episode/score": 0.808811178014821, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.04631120806743638}
{"step": 960024, "time": 30404.784654855728, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 960024, "time": 30405.08743596077, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 960024, "time": 30405.123804807663, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 960024, "time": 30405.221114635468, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 960024, "time": 30405.3486661911, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 960024, "time": 30405.553807735443, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 960024, "time": 30405.72944831848, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 960024, "time": 30406.183954954147, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 960136, "time": 30409.64032149315, "episode/length": 98.0, "episode/score": 0.7497181489413833, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.05596812531780415}
{"step": 960336, "time": 30416.003196001053, "episode/length": 65.0, "episode/score": 0.8368111938808624, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.039936208985750454}
{"step": 960360, "time": 30416.52195739746, "episode/length": 86.0, "episode/score": 0.793044316810267, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.061794328949474675}
{"step": 960576, "time": 30423.382786273956, "episode/length": 54.0, "episode/score": 0.8648715289822348, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.03362151727958462}
{"step": 960608, "time": 30424.38600230217, "episode/length": 83.0, "episode/score": 0.800478637775484, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.059853627103109375}
{"step": 960696, "time": 30426.962500810623, "episode/length": 186.0, "episode/score": 0.5092282831984676, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.09047828842551553}
{"step": 960936, "time": 30434.337104320526, "episode/length": 44.0, "episode/score": 0.8780226143061896, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.015522617490148605}
{"step": 960960, "time": 30435.29681992531, "episode/length": 288.0, "episode/score": 0.09626976437419899, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09626976437419899}
{"step": 961080, "time": 30438.78244328499, "episode/length": 92.0, "episode/score": 0.7323262924904839, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.019826342744067915}
{"step": 961184, "time": 30442.182806253433, "episode/length": 102.0, "episode/score": 0.7222917099332449, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.04104175688354417}
{"step": 961256, "time": 30444.19970846176, "episode/length": 288.0, "episode/score": 0.07724462194619264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07724462194619264}
{"step": 961352, "time": 30447.145624399185, "episode/length": 81.0, "episode/score": 0.7770357140804549, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.03016074110627187}
{"step": 961744, "time": 30459.528153657913, "episode/length": 97.0, "episode/score": 0.7391979574422294, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.042323004392528674}
{"step": 961744, "time": 30459.53483223915, "episode/length": 100.0, "episode/score": 0.7276221979931279, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.040122193904039705}
{"step": 961768, "time": 30460.058441877365, "episode/length": 63.0, "episode/score": 0.8327807567247874, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.029655755991370825}
{"step": 961800, "time": 30461.043017864227, "episode/length": 76.0, "episode/score": 0.796535423467617, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.034035428942047474}
{"step": 961984, "time": 30466.92540383339, "episode/length": 288.0, "episode/score": 0.09289562098825854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09289562098825854}
{"step": 962064, "time": 30469.401339530945, "episode/length": 122.0, "episode/score": 0.6677937623573484, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.049043809307647734}
{"step": 962096, "time": 30470.38760662079, "episode/length": 36.0, "episode/score": 0.8996393044350839, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.012139328434102481}
{"step": 962144, "time": 30471.857537984848, "episode/length": 49.0, "episode/score": 0.8728158176604666, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.02594080165044943}
{"step": 962224, "time": 30474.329240322113, "episode/length": 59.0, "episode/score": 0.8411313470932669, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.025506361394889154}
{"step": 962664, "time": 30487.739055395126, "episode/length": 84.0, "episode/score": 0.7771263359786644, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.039626319968647294}
{"step": 962752, "time": 30490.674375772476, "episode/length": 81.0, "episode/score": 0.8090293868777394, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.06215439235216991}
{"step": 962840, "time": 30493.164917469025, "episode/length": 86.0, "episode/score": 0.7782214891896615, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.04697147867153717}
{"step": 962920, "time": 30495.624121665955, "episode/length": 86.0, "episode/score": 0.7847335619937326, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.05348357407473259}
{"step": 962920, "time": 30495.63117837906, "episode/length": 288.0, "episode/score": 0.07198934165541004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07198934165541004}
{"step": 963360, "time": 30509.418036460876, "episode/length": 54.0, "episode/score": 0.8612435660301117, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.029993525471013527}
{"step": 963360, "time": 30509.423308610916, "episode/length": 54.0, "episode/score": 0.8649991792255491, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.03374913866645102}
{"step": 963624, "time": 30517.398294448853, "episode/length": 97.0, "episode/score": 0.7639739505858074, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.06709897675597176}
{"step": 963664, "time": 30518.86610198021, "episode/length": 288.0, "episode/score": 0.043685321222938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043685321222938}
{"step": 963872, "time": 30525.25423669815, "episode/length": 150.0, "episode/score": 0.6181754552634402, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.08692546818554092}
{"step": 964016, "time": 30529.693923711777, "episode/length": 81.0, "episode/score": 0.7946372493097442, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0477622741527739}
{"step": 964080, "time": 30531.660168409348, "episode/length": 288.0, "episode/score": 0.0729193721378465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0729193721378465}
{"step": 964248, "time": 30536.620344877243, "episode/length": 77.0, "episode/score": 0.7980489039005079, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.03867389910419661}
{"step": 964368, "time": 30540.544703245163, "episode/length": 61.0, "episode/score": 0.8415883213019697, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.03221334614499938}
{"step": 964376, "time": 30540.579286575317, "episode/length": 288.0, "episode/score": 0.11121265900368371, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11121265900368371}
{"step": 964616, "time": 30548.086441516876, "episode/length": 118.0, "episode/score": 0.6783992354976363, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.04714922457787907}
{"step": 964672, "time": 30550.035049676895, "episode/length": 163.0, "episode/score": 0.5748753080679307, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.08425029970931064}
{"step": 964776, "time": 30553.019154787064, "episode/length": 49.0, "episode/score": 0.8786014575998706, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.031726458601042395}
{"step": 965024, "time": 30560.845246315002, "episode/length": 117.0, "episode/score": 0.6670521800683673, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0326771875538725}
{"step": 965064, "time": 30561.86038994789, "episode/length": 288.0, "episode/score": 0.08534497513807082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08534497513807082}
{"step": 965160, "time": 30564.82213282585, "episode/length": 60.0, "episode/score": 0.8563463265422797, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.04384629790411054}
{"step": 965216, "time": 30566.751695156097, "episode/length": 54.0, "episode/score": 0.8573151769860488, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.026065150746035215}
{"step": 965280, "time": 30568.73935198784, "episode/length": 157.0, "episode/score": 0.5594187812489508, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.05004378873445603}
{"step": 965360, "time": 30571.193972587585, "episode/length": 92.0, "episode/score": 0.7420522499492108, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.029552259471984144}
{"step": 965712, "time": 30582.169037103653, "episode/length": 85.0, "episode/score": 0.7866277068601448, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.05225271978224555}
{"step": 965776, "time": 30584.13417983055, "episode/length": 69.0, "episode/score": 0.8291474275056316, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.04477241639960994}
{"step": 966096, "time": 30593.969186782837, "episode/length": 116.0, "episode/score": 0.6925283870123167, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.05502838257689291}
{"step": 966224, "time": 30597.916963338852, "episode/length": 55.0, "episode/score": 0.8844910774178061, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.056366061061453365}
{"step": 966384, "time": 30602.84765267372, "episode/length": 164.0, "episode/score": 0.589988658292441, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.10248865981748168}
{"step": 966480, "time": 30605.890053749084, "episode/length": 149.0, "episode/score": 0.6285233105627412, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.09414831156391301}
{"step": 966544, "time": 30607.86660003662, "episode/length": 103.0, "episode/score": 0.7388665916460013, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.06074155348505883}
{"step": 966560, "time": 30608.36355304718, "episode/length": 288.0, "episode/score": 0.09379490671540225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09379490671540225}
{"step": 966624, "time": 30610.327008724213, "episode/length": 157.0, "episode/score": 0.602430348745429, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0930553562309342}
{"step": 966632, "time": 30610.3593814373, "episode/length": 66.0, "episode/score": 0.8364255531066647, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.042675548671240904}
{"step": 966680, "time": 30612.34243440628, "episode/length": 288.0, "episode/score": 0.11112468964370237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11112468964370237}
{"step": 967080, "time": 30624.680055379868, "episode/length": 49.0, "episode/score": 0.8825681803778025, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.03569315210052082}
{"step": 967232, "time": 30629.58201289177, "episode/length": 93.0, "episode/score": 0.781265937984017, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0718908998230745}
{"step": 967264, "time": 30630.5659635067, "episode/length": 87.0, "episode/score": 0.8085370408230119, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.08041204533992641}
{"step": 967296, "time": 30631.548066854477, "episode/length": 83.0, "episode/score": 0.7868196509825793, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.046194607815778}
{"step": 967648, "time": 30642.452793598175, "episode/length": 157.0, "episode/score": 0.5897830045062165, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.08040800500680234}
{"step": 967664, "time": 30642.94548559189, "episode/length": 139.0, "episode/score": 0.6572717693686627, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.09164673812279034}
{"step": 967848, "time": 30648.35872244835, "episode/length": 24.0, "episode/score": 0.9466463640230813, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.021646352538709834}
{"step": 967872, "time": 30649.31624865532, "episode/length": 98.0, "episode/score": 0.7593554098195909, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.06560535658286426}
{"step": 967872, "time": 30649.322797060013, "episode/length": 205.0, "episode/score": 0.47180039523300366, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.11242538091391907}
{"step": 968136, "time": 30657.23224878311, "episode/length": 58.0, "episode/score": 0.8494027821730015, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.030652759960958065}
{"step": 968448, "time": 30667.172363996506, "episode/length": 74.0, "episode/score": 0.8124525359212385, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.04370253692241022}
{"step": 968576, "time": 30671.07721233368, "episode/length": 87.0, "episode/score": 0.7924613352756751, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0643363607473475}
{"step": 968776, "time": 30676.99133825302, "episode/length": 112.0, "episode/score": 0.7143968357822814, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.06439686125395383}
{"step": 968912, "time": 30681.37723183632, "episode/length": 57.0, "episode/score": 0.8510779073203594, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.029202944084318005}
{"step": 968944, "time": 30682.357612609863, "episode/length": 288.0, "episode/score": 0.11603162898450137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11603162898450137}
{"step": 968952, "time": 30682.389588832855, "episode/length": 101.0, "episode/score": 0.7542254718837285, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.06985048543447192}
{"step": 969232, "time": 30691.193559408188, "episode/length": 34.0, "episode/score": 0.9243378573974042, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.030587858398575918}
{"step": 969384, "time": 30695.74457383156, "episode/length": 58.0, "episode/score": 0.8526333225981944, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.03388331167843717}
{"step": 969512, "time": 30699.68368124962, "episode/length": 34.0, "episode/score": 0.912956617254622, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.01920658897734029}
{"step": 969544, "time": 30700.67431998253, "episode/length": 288.0, "episode/score": 0.08924932068748603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08924932068748603}
{"step": 969576, "time": 30701.681889295578, "episode/length": 288.0, "episode/score": 0.08948330647353941, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08948330647353941}
{"step": 969608, "time": 30702.677608966827, "episode/length": 288.0, "episode/score": 0.10979569632786479, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10979569632786479}
{"step": 969960, "time": 30713.47591972351, "episode/length": 71.0, "episode/score": 0.8241967006333653, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.04607171336920146}
{"step": 970008, "time": 30715.868012666702, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 970008, "time": 30716.07474374771, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 970008, "time": 30716.17209982872, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 970008, "time": 30717.080161094666, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 970008, "time": 30717.177405834198, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 970008, "time": 30717.827687501907, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 970008, "time": 30718.250311374664, "eval_episode/length": 173.0, "eval_episode/score": 0.4593749940395355, "eval_episode/reward_rate": 0.005747126436781609}
{"step": 970008, "time": 30718.392263889313, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 970208, "time": 30724.85418868065, "episode/length": 82.0, "episode/score": 0.7854026008030814, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.04165260531999593}
{"step": 970264, "time": 30726.50392961502, "episode/length": 164.0, "episode/score": 0.5701075694482824, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.08260756398840385}
{"step": 970344, "time": 30728.997265815735, "episode/length": 47.0, "episode/score": 0.8800488958304413, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.026923932594399957}
{"step": 970528, "time": 30734.937451839447, "episode/length": 114.0, "episode/score": 0.6754315346720432, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.03168149335624548}
{"step": 970560, "time": 30735.92456293106, "episode/length": 130.0, "episode/score": 0.6806457040115674, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.08689569062380542}
{"step": 970888, "time": 30745.793796539307, "episode/length": 288.0, "episode/score": 0.0998681801818293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0998681801818293}
{"step": 970920, "time": 30746.775416135788, "episode/length": 71.0, "episode/score": 0.8291536248873399, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.05102863913657529}
{"step": 970952, "time": 30747.75946879387, "episode/length": 92.0, "episode/score": 0.7920153478580687, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.07951537402823305}
{"step": 971088, "time": 30752.160386562347, "episode/length": 288.0, "episode/score": 0.08876125323945416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08876125323945416}
{"step": 971136, "time": 30753.636261224747, "episode/length": 75.0, "episode/score": 0.8187179342887703, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.05309293591858477}
{"step": 971432, "time": 30762.633205652237, "episode/length": 108.0, "episode/score": 0.7195566981313277, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.057056687211570534}
{"step": 971512, "time": 30765.102419376373, "episode/length": 52.0, "episode/score": 0.8715579497429644, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.034057986506923044}
{"step": 971536, "time": 30766.06040930748, "episode/length": 76.0, "episode/score": 0.7814791792734468, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.018979174838023027}
{"step": 971552, "time": 30766.55327296257, "episode/length": 82.0, "episode/score": 0.7915696710470002, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.04781967853250535}
{"step": 971888, "time": 30776.843247652054, "episode/length": 288.0, "episode/score": 0.07003925200592676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07003925200592676}
{"step": 972024, "time": 30780.805223703384, "episode/length": 73.0, "episode/score": 0.8309398214523753, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.05906481053261814}
{"step": 972136, "time": 30784.254058361053, "episode/length": 74.0, "episode/score": 0.8045337662829297, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.03578375599181527}
{"step": 972192, "time": 30786.315566539764, "episode/length": 84.0, "episode/score": 0.7819886480451714, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.044488607486073306}
{"step": 972320, "time": 30790.253454446793, "episode/length": 170.0, "episode/score": 0.5499646862435839, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.08121469916568458}
{"step": 972576, "time": 30798.087718725204, "episode/length": 288.0, "episode/score": 0.08256209223100086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08256209223100086}
{"step": 972616, "time": 30799.121610879898, "episode/length": 90.0, "episode/score": 0.7790131653332537, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.06026313669508454}
{"step": 972680, "time": 30801.086182117462, "episode/length": 44.0, "episode/score": 0.8858537753035307, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.02335374702624904}
{"step": 972944, "time": 30809.44228410721, "episode/length": 114.0, "episode/score": 0.7242241834346714, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0804741844358432}
{"step": 973192, "time": 30816.969387054443, "episode/length": 71.0, "episode/score": 0.811198512692954, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.03307350825753019}
{"step": 973344, "time": 30821.855358600616, "episode/length": 82.0, "episode/score": 0.7864371822734029, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.04268720693016803}
{"step": 973448, "time": 30824.833786964417, "episode/length": 108.0, "episode/score": 0.7207995953060617, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.05829955714511925}
{"step": 973448, "time": 30824.8418738842, "episode/length": 288.0, "episode/score": 0.09244605577418952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09244605577418952}
{"step": 973480, "time": 30825.825986146927, "episode/length": 66.0, "episode/score": 0.8302350321739596, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.036485024769945085}
{"step": 973864, "time": 30837.610353708267, "episode/length": 288.0, "episode/score": 0.0489462708130759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0489462708130759}
{"step": 974192, "time": 30848.027599334717, "episode/length": 92.0, "episode/score": 0.7657839598984992, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.05328396441541372}
{"step": 974224, "time": 30849.009768009186, "episode/length": 128.0, "episode/score": 0.6642928629105427, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.06429282474960019}
{"step": 974296, "time": 30850.998381137848, "episode/length": 105.0, "episode/score": 0.7381192064417519, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.06624421936385261}
{"step": 974448, "time": 30855.90204501152, "episode/length": 288.0, "episode/score": 0.09320212626130342, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09320212626130342}
{"step": 974504, "time": 30857.407362937927, "episode/length": 288.0, "episode/score": 0.06774295231593896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06774295231593896}
{"step": 975024, "time": 30874.123456954956, "episode/length": 71.0, "episode/score": 0.8148558981934002, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.03673091055088662}
{"step": 975176, "time": 30878.685602903366, "episode/length": 122.0, "episode/score": 0.6681679431528664, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.04941795063837162}
{"step": 975208, "time": 30879.66852402687, "episode/length": 122.0, "episode/score": 0.6939171554754466, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.07516716499821996}
{"step": 975248, "time": 30881.11635160446, "episode/length": 92.0, "episode/score": 0.7696489271731934, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.05714893169010793}
{"step": 975656, "time": 30893.40952539444, "episode/length": 288.0, "episode/score": 0.10468682112946226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10468682112946226}
{"step": 975792, "time": 30897.803512334824, "episode/length": 288.0, "episode/score": 0.08030821330714843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08030821330714843}
{"step": 976000, "time": 30904.178688764572, "episode/length": 42.0, "episode/score": 0.8976204217524355, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.02887042626934999}
{"step": 976072, "time": 30906.2829785347, "episode/length": 102.0, "episode/score": 0.7205486595039474, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.03929865395093657}
{"step": 976176, "time": 30909.706560611725, "episode/length": 288.0, "episode/score": 0.04583021662324427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04583021662324427}
{"step": 976264, "time": 30912.215165138245, "episode/length": 135.0, "episode/score": 0.6298221798085706, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.05169718024512804}
{"step": 976472, "time": 30918.620705366135, "episode/length": 58.0, "episode/score": 0.8457208884519787, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.026970845285177347}
{"step": 976608, "time": 30923.025290727615, "episode/length": 288.0, "episode/score": 0.07072189087068637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07072189087068637}
{"step": 976840, "time": 30929.92532491684, "episode/length": 82.0, "episode/score": 0.7818173137427493, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.03806733802116469}
{"step": 976864, "time": 30930.883711338043, "episode/length": 98.0, "episode/score": 0.7242106070016234, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.03046057498158916}
{"step": 977088, "time": 30937.89167380333, "episode/length": 76.0, "episode/score": 0.8048013414762636, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.04230133407224912}
{"step": 977336, "time": 30945.274547815323, "episode/length": 288.0, "episode/score": 0.06237144401632122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06237144401632122}
{"step": 977520, "time": 30951.139755249023, "episode/length": 288.0, "episode/score": 0.08655487865166833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08655487865166833}
{"step": 977640, "time": 30954.677993774414, "episode/length": 96.0, "episode/score": 0.7468587651854932, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.046858769946879875}
{"step": 977856, "time": 30961.550861358643, "episode/length": 126.0, "episode/score": 0.6612362266102991, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.05498622514346607}
{"step": 978080, "time": 30968.54449224472, "episode/length": 54.0, "episode/score": 0.8422540639038516, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.011004076139101926}
{"step": 978104, "time": 30969.066880702972, "episode/length": 288.0, "episode/score": 0.027741215741571068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027741215741571068}
{"step": 978200, "time": 30972.016711711884, "episode/length": 107.0, "episode/score": 0.7096694625336113, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.044044510531648484}
{"step": 978576, "time": 30983.843305826187, "episode/length": 288.0, "episode/score": 0.046837762987934184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046837762987934184}
{"step": 978728, "time": 30988.28093314171, "episode/length": 108.0, "episode/score": 0.7027147032262064, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.04021470770237556}
{"step": 978736, "time": 30988.749890327454, "episode/length": 66.0, "episode/score": 0.8349478720525667, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.04119788441005312}
{"step": 978872, "time": 30992.7071352005, "episode/length": 98.0, "episode/score": 0.7457757226139847, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.052025669377258055}
{"step": 978920, "time": 30994.179560899734, "episode/length": 288.0, "episode/score": 0.049972050991186734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049972050991186734}
{"step": 979232, "time": 31004.107261896133, "episode/length": 61.0, "episode/score": 0.8452510849975852, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.035876088740337764}
{"step": 979400, "time": 31009.05853486061, "episode/length": 288.0, "episode/score": 0.04918390086641011, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04918390086641011}
{"step": 979448, "time": 31010.52752828598, "episode/length": 89.0, "episode/score": 0.7505126770947754, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.028637668549890805}
{"step": 979616, "time": 31015.903033971786, "episode/length": 92.0, "episode/score": 0.7338091658491521, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.02130918253146774}
{"step": 979728, "time": 31019.36281633377, "episode/length": 34.0, "episode/score": 0.9096302817932838, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.015880288004041176}
{"step": 979736, "time": 31019.395536661148, "episode/length": 101.0, "episode/score": 0.7239734435697756, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.039598473622390884}
{"step": 979792, "time": 31021.34711456299, "episode/length": 151.0, "episode/score": 0.596637774279543, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.06851278641875069}
{"step": 979832, "time": 31022.357355594635, "episode/length": 288.0, "episode/score": 0.08014022564975676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08014022564975676}
{"step": 979936, "time": 31025.930686473846, "episode/length": 66.0, "episode/score": 0.8244870690269863, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.03073710108776595}
{"step": 980024, "time": 31028.428859233856, "episode/length": 98.0, "episode/score": 0.7540590782143681, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.06030907250419659}
{"step": 980096, "time": 31032.067711114883, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 980096, "time": 31032.216705083847, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 980096, "time": 31032.716454982758, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 980096, "time": 31032.942275047302, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 980096, "time": 31032.980822324753, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 980096, "time": 31033.01814889908, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 980096, "time": 31033.644722223282, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 980096, "time": 31034.07198047638, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 980200, "time": 31037.062683582306, "episode/length": 50.0, "episode/score": 0.8671134261993529, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.023363418021176585}
{"step": 980352, "time": 31041.960757017136, "episode/length": 51.0, "episode/score": 0.8664422128082379, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.02581721655099045}
{"step": 980376, "time": 31042.48252224922, "episode/length": 80.0, "episode/score": 0.7799318359421932, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.029931810621860677}
{"step": 980416, "time": 31043.93482518196, "episode/length": 288.0, "episode/score": 0.06564935851747578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06564935851747578}
{"step": 980440, "time": 31044.477410316467, "episode/length": 87.0, "episode/score": 0.7498586111008763, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.021733648112217452}
{"step": 980616, "time": 31049.90165925026, "episode/length": 51.0, "episode/score": 0.865139854080553, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.024514858841939713}
{"step": 980672, "time": 31051.84021115303, "episode/length": 104.0, "episode/score": 0.7082742434295142, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.033274257920311356}
{"step": 980816, "time": 31056.38709640503, "episode/length": 98.0, "episode/score": 0.7270448309440098, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.033294833513878075}
{"step": 981016, "time": 31062.3158326149, "episode/length": 71.0, "episode/score": 0.7955639935496492, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.01743899902407975}
{"step": 981040, "time": 31063.278568029404, "episode/length": 82.0, "episode/score": 0.7633891727999753, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.01963917420277994}
{"step": 981192, "time": 31067.736626148224, "episode/length": 71.0, "episode/score": 0.8085772824986179, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.030452314559397564}
{"step": 981304, "time": 31071.199165821075, "episode/length": 78.0, "episode/score": 0.7778845001797663, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.02163450049408766}
{"step": 981424, "time": 31075.105462789536, "episode/length": 50.0, "episode/score": 0.8700996619273837, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.026349690245410784}
{"step": 981616, "time": 31081.01734972, "episode/length": 71.0, "episode/score": 0.8003491908896194, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.022224214888638016}
{"step": 981888, "time": 31089.60862994194, "episode/length": 57.0, "episode/score": 0.8301643158674779, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.008289339869406831}
{"step": 981896, "time": 31089.643168210983, "episode/length": 134.0, "episode/score": 0.6522633261655528, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.07101330779812542}
{"step": 981928, "time": 31090.64368367195, "episode/length": 288.0, "episode/score": 0.055278826386711444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055278826386711444}
{"step": 981952, "time": 31091.616765499115, "episode/length": 94.0, "episode/score": 0.744318573870089, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.03806853662882759}
{"step": 982104, "time": 31096.069682121277, "episode/length": 21.0, "episode/score": 0.9509371392828712, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.016562143025623755}
{"step": 982488, "time": 31107.862744808197, "episode/length": 66.0, "episode/score": 0.8105878426183608, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.016837867708773047}
{"step": 982576, "time": 31110.811235904694, "episode/length": 85.0, "episode/score": 0.7726226149699755, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.03824760781043324}
{"step": 982664, "time": 31113.294932603836, "episode/length": 288.0, "episode/score": 0.01830463552494166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01830463552494166}
{"step": 982712, "time": 31114.884229660034, "episode/length": 101.0, "episode/score": 0.717860117296425, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.03348514935720459}
{"step": 982728, "time": 31115.465131044388, "episode/length": 138.0, "episode/score": 0.6168944948364015, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.048144497217094795}
{"step": 982728, "time": 31115.473249673843, "episode/length": 288.0, "episode/score": 0.06900621152584563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06900621152584563}
{"step": 983024, "time": 31124.798978805542, "episode/length": 55.0, "episode/score": 0.8514230126127131, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.023298026771726654}
{"step": 983064, "time": 31126.281923532486, "episode/length": 71.0, "episode/score": 0.813488783207049, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.035363795288049005}
{"step": 983144, "time": 31128.74151945114, "episode/length": 129.0, "episode/score": 0.6330206575356101, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.03614565702338268}
{"step": 983264, "time": 31132.651746034622, "episode/length": 66.0, "episode/score": 0.8107440785708491, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.01699410559666603}
{"step": 983568, "time": 31142.05603003502, "episode/length": 62.0, "episode/score": 0.8465169662214294, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0402669614251181}
{"step": 983568, "time": 31142.06157207489, "episode/length": 104.0, "episode/score": 0.710080503216659, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.035080471970786675}
{"step": 983616, "time": 31143.54267859459, "episode/length": 288.0, "episode/score": 0.05048317142285441, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05048317142285441}
{"step": 983808, "time": 31149.598197698593, "episode/length": 82.0, "episode/score": 0.778733446932506, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.034983483696464646}
{"step": 983816, "time": 31149.630313158035, "episode/length": 137.0, "episode/score": 0.6265991196439131, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.05472414430067829}
{"step": 983928, "time": 31153.062148571014, "episode/length": 157.0, "episode/score": 0.5673401854341478, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.05796521009091293}
{"step": 984184, "time": 31160.934753656387, "episode/length": 114.0, "episode/score": 0.676553188553612, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.03280316231359848}
{"step": 984208, "time": 31161.895732164383, "episode/length": 147.0, "episode/score": 0.5864918282901499, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.04586685294691506}
{"step": 984400, "time": 31167.784126758575, "episode/length": 23.0, "episode/score": 0.9434303285261194, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.015305305499168753}
{"step": 984416, "time": 31168.27676653862, "episode/length": 105.0, "episode/score": 0.708628593802132, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.03675357447718852}
{"step": 984472, "time": 31169.791833162308, "episode/length": 106.0, "episode/score": 0.7170756735440591, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.04832566910863534}
{"step": 984552, "time": 31172.246307611465, "episode/length": 91.0, "episode/score": 0.740482018711873, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.02485700123793322}
{"step": 984552, "time": 31172.251735925674, "episode/length": 92.0, "episode/score": 0.7389246291124891, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.026424623559478277}
{"step": 985048, "time": 31187.55392765999, "episode/length": 107.0, "episode/score": 0.737731181799063, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.07210618928456825}
{"step": 985264, "time": 31194.40843605995, "episode/length": 105.0, "episode/score": 0.7012078353855031, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.029332816060559708}
{"step": 985328, "time": 31196.368476867676, "episode/length": 174.0, "episode/score": 0.5051836726149759, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.048933671171425885}
{"step": 985424, "time": 31199.3298265934, "episode/length": 108.0, "episode/score": 0.7042568501706228, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.041756839250865596}
{"step": 985480, "time": 31200.839202165604, "episode/length": 115.0, "episode/score": 0.6663594653380187, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.025734465774576165}
{"step": 985648, "time": 31206.349990844727, "episode/length": 39.0, "episode/score": 0.9067239218745726, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.028598910768550923}
{"step": 985672, "time": 31206.870441675186, "episode/length": 50.0, "episode/score": 0.8581357364278119, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.014385728249635577}
{"step": 985792, "time": 31210.7673099041, "episode/length": 92.0, "episode/score": 0.7440198189901821, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.03151984326859747}
{"step": 985880, "time": 31213.260644435883, "episode/length": 288.0, "episode/score": 0.04964555723722697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04964555723722697}
{"step": 985992, "time": 31216.700448989868, "episode/length": 42.0, "episode/score": 0.8773824673019135, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.008632483984229111}
{"step": 986064, "time": 31219.144414186478, "episode/length": 72.0, "episode/score": 0.7885356526649048, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.013535647111893923}
{"step": 986216, "time": 31223.606168031693, "episode/length": 98.0, "episode/score": 0.7228732204537209, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.029123183224101012}
{"step": 986288, "time": 31226.029005289078, "episode/length": 50.0, "episode/score": 0.8679668061186021, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.024216834436629142}
{"step": 986328, "time": 31227.03909444809, "episode/length": 66.0, "episode/score": 0.8150627861798512, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.021312774759508102}
{"step": 986696, "time": 31238.421614408493, "episode/length": 127.0, "episode/score": 0.6490854610201495, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.04596046553706401}
{"step": 986697, "time": 31239.430598020554, "train_stats/mean_log_entropy": 0.06988188588330822, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.11598876953125, "train/action_min": 0.0, "train/action_std": 1.7978300601243973, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0114064386615064, "train/actor_opt_grad_steps": 60575.0, "train/actor_opt_loss": -14.991401357650757, "train/adv_mag": 1.0111364245414733, "train/adv_max": 0.2904425406455994, "train/adv_mean": 0.0008012141348879709, "train/adv_min": -0.9533876770734787, "train/adv_std": 0.028958800244145096, "train/cont_avg": 0.9949560546875, "train/cont_loss_mean": 0.018628829409135506, "train/cont_loss_std": 0.24574559224769474, "train/cont_neg_acc": 0.2781054709275164, "train/cont_neg_loss": 2.9209523752762294, "train/cont_pos_acc": 0.9998723903298378, "train/cont_pos_loss": 0.003693827565293759, "train/cont_pred": 0.9950479635596275, "train/cont_rate": 0.9949560546875, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08804957581683993, "train/extr_critic_critic_opt_grad_steps": 60575.0, "train/extr_critic_critic_opt_loss": 11202.174692382812, "train/extr_critic_mag": 1.5538686680793763, "train/extr_critic_max": 1.5538686680793763, "train/extr_critic_mean": 1.4662987613677978, "train/extr_critic_min": 1.2560806000232696, "train/extr_critic_std": 0.022143426053225994, "train/extr_return_normed_mag": 1.024460579752922, "train/extr_return_normed_max": 0.3109189558029175, "train/extr_return_normed_mean": 0.042127784909680485, "train/extr_return_normed_min": -0.9452888977527618, "train/extr_return_normed_std": 0.03751350094564259, "train/extr_return_rate": 0.9995534214377403, "train/extr_return_raw_mag": 1.7358910572528838, "train/extr_return_raw_max": 1.7358910572528838, "train/extr_return_raw_mean": 1.4670999592542648, "train/extr_return_raw_min": 0.4796832036972046, "train/extr_return_raw_std": 0.03751350088045001, "train/extr_reward_mag": 0.3207838290929794, "train/extr_reward_max": 0.3207838290929794, "train/extr_reward_mean": 0.0023614449583692475, "train/extr_reward_min": 4.581809043884278e-06, "train/extr_reward_std": 0.008487941436469556, "train/image_loss_mean": 0.09565948463976383, "train/image_loss_std": 0.10493049453943967, "train/model_loss_mean": 0.7428339740633965, "train/model_loss_std": 0.44452070698142054, "train/model_opt_grad_norm": 17.00481556892395, "train/model_opt_grad_steps": 60520.06, "train/model_opt_loss": 4121.826009521485, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5550.0, "train/policy_entropy_mag": 1.2756307423114777, "train/policy_entropy_max": 1.2756307423114777, "train/policy_entropy_mean": 0.09157757632434368, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1122133169695735, "train/policy_logprob_mag": 6.55108026266098, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09147772204130888, "train/policy_logprob_min": -6.55108026266098, "train/policy_logprob_std": 0.6287913143634796, "train/policy_randomness_mag": 0.6555445620417595, "train/policy_randomness_max": 0.6555445620417595, "train/policy_randomness_mean": 0.047061566561460495, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05766624098643661, "train/post_ent_mag": 2.815969762802124, "train/post_ent_max": 2.815969762802124, "train/post_ent_mean": 2.8157220208644866, "train/post_ent_min": 2.815575054883957, "train/post_ent_std": 6.877046246700047e-05, "train/prior_ent_mag": 3.1797316777706146, "train/prior_ent_max": 3.1797316777706146, "train/prior_ent_mean": 2.8169236540794373, "train/prior_ent_min": 2.811103105545044, "train/prior_ent_std": 0.01692734835203737, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.002124549038489931, "train/reward_loss_mean": 0.02854563627857715, "train/reward_loss_std": 0.2048121652752161, "train/reward_max_data": 0.7459058731701225, "train/reward_max_pred": 0.2062411415576935, "train/reward_neg_acc": 0.9997894099354744, "train/reward_neg_loss": 0.018118266630917788, "train/reward_pos_acc": 0.14979736713018824, "train/reward_pos_loss": 4.088578216255979, "train/reward_pred": 0.001668992064660415, "train/reward_rate": 0.002529296875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02136600762605667, "report/cont_loss_std": 0.2609105706214905, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.146858215332031, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.005187606438994408, "report/cont_pred": 0.9948481321334839, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07811105251312256, "report/image_loss_std": 0.09497057646512985, "report/model_loss_mean": 0.7397980093955994, "report/model_loss_std": 0.6287908554077148, "report/post_ent_mag": 2.8126168251037598, "report/post_ent_max": 2.8126168251037598, "report/post_ent_mean": 2.812467098236084, "report/post_ent_min": 2.8123791217803955, "report/post_ent_std": 4.565769631881267e-05, "report/prior_ent_mag": 2.999995231628418, "report/prior_ent_max": 2.999995231628418, "report/prior_ent_mean": 2.816526412963867, "report/prior_ent_min": 2.8111624717712402, "report/prior_ent_std": 0.01111098937690258, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002689184620976448, "report/reward_loss_mean": 0.04032091423869133, "report/reward_loss_std": 0.33821120858192444, "report/reward_max_data": 0.7977083325386047, "report/reward_max_pred": 0.060361504554748535, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.019493235275149345, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.351378440856934, "report/reward_pred": 0.0021162093617022038, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.03435415029525757, "eval/cont_loss_std": 0.4251774251461029, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.146823406219482, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0042217206209897995, "eval/cont_pred": 0.9957519769668579, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13271227478981018, "eval/image_loss_std": 0.11768097430467606, "eval/model_loss_mean": 0.7937011122703552, "eval/model_loss_std": 0.7190943956375122, "eval/post_ent_mag": 2.8126168251037598, "eval/post_ent_max": 2.8126168251037598, "eval/post_ent_mean": 2.812485694885254, "eval/post_ent_min": 2.8123791217803955, "eval/post_ent_std": 5.667483856086619e-05, "eval/prior_ent_mag": 2.8835630416870117, "eval/prior_ent_max": 2.8835630416870117, "eval/prior_ent_mean": 2.817206621170044, "eval/prior_ent_min": 2.8111624717712402, "eval/prior_ent_std": 0.00885112676769495, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0029754638671875, "eval/reward_loss_mean": 0.026634670794010162, "eval/reward_loss_std": 0.3514743447303772, "eval/reward_max_data": 0.887499988079071, "eval/reward_max_pred": 0.04608500003814697, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.004701155237853527, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.6196818351745605, "eval/reward_pred": 0.0015958243748173118, "eval/reward_rate": 0.00390625, "replay/size": 986193.0, "replay/inserts": 32000.0, "replay/samples": 32000.0, "replay/insert_wait_avg": 1.1876299977302552e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.700771093368531e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4192.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.57314294713144e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3611922264099, "timer/env.step_count": 4000.0, "timer/env.step_total": 34.359050035476685, "timer/env.step_frac": 0.034346644294554224, "timer/env.step_avg": 0.008589762508869172, "timer/env.step_min": 0.007150173187255859, "timer/env.step_max": 0.03949618339538574, "timer/replay._sample_count": 32000.0, "timer/replay._sample_total": 15.9723060131073, "timer/replay._sample_frac": 0.015966539023329403, "timer/replay._sample_avg": 0.0004991345629096031, "timer/replay._sample_min": 0.00041031837463378906, "timer/replay._sample_max": 0.011261224746704102, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4524.0, "timer/agent.policy_total": 38.48519515991211, "timer/agent.policy_frac": 0.038471299625547475, "timer/agent.policy_avg": 0.00850689548185502, "timer/agent.policy_min": 0.007427692413330078, "timer/agent.policy_max": 0.07661938667297363, "timer/dataset_train_count": 2000.0, "timer/dataset_train_total": 0.20686912536621094, "timer/dataset_train_frac": 0.00020679443282460984, "timer/dataset_train_avg": 0.00010343456268310547, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.0002579689025878906, "timer/agent.train_count": 2000.0, "timer/agent.train_total": 882.7108347415924, "timer/agent.train_frac": 0.8823921215666372, "timer/agent.train_avg": 0.4413554173707962, "timer/agent.train_min": 0.43293285369873047, "timer/agent.train_max": 0.6004641056060791, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4791221618652344, "timer/agent.report_frac": 0.00047894916914849247, "timer/agent.report_avg": 0.2395610809326172, "timer/agent.report_min": 0.23301959037780762, "timer/agent.report_max": 0.24610257148742676, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.883823192609395e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 31.987888695098448}
{"step": 986712, "time": 31239.502080202103, "episode/length": 288.0, "episode/score": 0.08398830253054257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08398830253054257}
{"step": 986784, "time": 31242.286292552948, "episode/length": 288.0, "episode/score": 0.05539208588663769, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05539208588663769}
{"step": 987016, "time": 31249.193176031113, "episode/length": 118.0, "episode/score": 0.6775538703166148, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.046303827149813515}
{"step": 987024, "time": 31249.663770198822, "episode/length": 91.0, "episode/score": 0.7345428125859144, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.018917848663022596}
{"step": 987072, "time": 31251.14660716057, "episode/length": 35.0, "episode/score": 0.8998697136896681, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.009244717065712393}
{"step": 987176, "time": 31254.121740579605, "episode/length": 119.0, "episode/score": 0.653988676714448, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.025863656615342734}
{"step": 987264, "time": 31257.02874469757, "episode/length": 158.0, "episode/score": 0.5512276164116656, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.04497759300636517}
{"step": 987456, "time": 31262.919708013535, "episode/length": 92.0, "episode/score": 0.7537473813146107, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.04124740559302609}
{"step": 987472, "time": 31263.438507080078, "episode/length": 55.0, "episode/score": 0.8552005930165478, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.027075579628785817}
{"step": 987520, "time": 31264.940022468567, "episode/length": 148.0, "episode/score": 0.5750011292676618, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.03750112556565455}
{"step": 987848, "time": 31274.870159864426, "episode/length": 103.0, "episode/score": 0.7164639711232894, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.038338923940159475}
{"step": 987880, "time": 31275.85723423958, "episode/length": 76.0, "episode/score": 0.7888686571608332, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.026368672457806497}
{"step": 987896, "time": 31276.352154254913, "episode/length": 89.0, "episode/score": 0.7638814427698435, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.042006422670738175}
{"step": 988104, "time": 31282.730929136276, "episode/length": 80.0, "episode/score": 0.7902427475959257, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.04024273941774936}
{"step": 988384, "time": 31291.549136161804, "episode/length": 66.0, "episode/score": 0.8322060624303731, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.03845604903096955}
{"step": 988392, "time": 31291.582100868225, "episode/length": 114.0, "episode/score": 0.6789192478315726, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.03516925404233007}
{"step": 988424, "time": 31292.564266443253, "episode/length": 67.0, "episode/score": 0.8054974826078478, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0148725265895564}
{"step": 988800, "time": 31304.429762363434, "episode/length": 50.0, "episode/score": 0.8643734475826932, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.02062345095873752}
{"step": 988864, "time": 31306.397212028503, "episode/length": 120.0, "episode/score": 0.6649375437885965, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.03993756392844716}
{"step": 989008, "time": 31310.826251506805, "episode/length": 288.0, "episode/score": 0.0706785007300823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0706785007300823}
{"step": 989072, "time": 31312.808525562286, "episode/length": 85.0, "episode/score": 0.755560517458207, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.02118553062769024}
{"step": 989280, "time": 31319.194658517838, "episode/length": 146.0, "episode/score": 0.5880585330446593, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.04430851964525573}
{"step": 989288, "time": 31319.226928710938, "episode/length": 107.0, "episode/score": 0.6984759543602195, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.03285097104253509}
{"step": 989384, "time": 31322.170801877975, "episode/length": 288.0, "episode/score": 0.03714211985709426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03714211985709426}
{"step": 989624, "time": 31329.663570404053, "episode/length": 76.0, "episode/score": 0.79179384984036, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.029293888173015148}
{"step": 989704, "time": 31332.121735811234, "episode/length": 39.0, "episode/score": 0.8885801012504544, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.010455082169983143}
{"step": 989776, "time": 31334.561472654343, "episode/length": 18.0, "episode/score": 0.9538245799311653, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.010074571194195414}
{"step": 989792, "time": 31335.055871486664, "episode/length": 89.0, "episode/score": 0.7657595393902739, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.04388452768762363}
{"step": 989832, "time": 31336.065378427505, "episode/length": 288.0, "episode/score": 0.06859006970751125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06859006970751125}
{"step": 989840, "time": 31336.53533768654, "episode/length": 69.0, "episode/score": 0.7983021737572926, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.013927188248089806}
{"step": 990080, "time": 31344.77640938759, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 990080, "time": 31344.98166537285, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 990080, "time": 31345.15733885765, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 990080, "time": 31345.27277112007, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 990080, "time": 31345.277794122696, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 990080, "time": 31345.994893550873, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 990080, "time": 31346.23642206192, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 990080, "time": 31346.581349611282, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 990152, "time": 31348.572412490845, "episode/length": 107.0, "episode/score": 0.7070859138888181, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.04146093794895478}
{"step": 990240, "time": 31351.50658917427, "episode/length": 50.0, "episode/score": 0.8717722368943441, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.02802226105052341}
{"step": 990472, "time": 31358.56126356125, "episode/length": 84.0, "episode/score": 0.7602008626157613, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.022700874851011577}
{"step": 990504, "time": 31359.544278383255, "episode/length": 32.0, "episode/score": 0.9270652042322354, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.02706522091455099}
{"step": 990568, "time": 31361.53267097473, "episode/length": 98.0, "episode/score": 0.7277560295639205, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.03400597632719382}
{"step": 990584, "time": 31362.02687239647, "episode/length": 109.0, "episode/score": 0.6931409422777506, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.03376595867484866}
{"step": 990648, "time": 31363.99098777771, "episode/length": 61.0, "episode/score": 0.8426105500120684, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.033235565309041704}
{"step": 990656, "time": 31364.4624478817, "episode/length": 18.0, "episode/score": 0.9601474317522616, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.016397394522641662}
{"step": 990800, "time": 31368.91169500351, "episode/length": 119.0, "episode/score": 0.6971976104950954, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.06907260195021081}
{"step": 991112, "time": 31378.350575208664, "episode/length": 288.0, "episode/score": 0.03563027083998804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03563027083998804}
{"step": 991160, "time": 31379.85453748703, "episode/length": 85.0, "episode/score": 0.7963434300290828, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.06196843235738925}
{"step": 991176, "time": 31380.35487794876, "episode/length": 288.0, "episode/score": 0.05523466646388897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05523466646388897}
{"step": 991464, "time": 31389.825996398926, "episode/length": 109.0, "episode/score": 0.7373174109578713, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.07794240136524877}
{"step": 991744, "time": 31398.661395311356, "episode/length": 117.0, "episode/score": 0.7230285289767835, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0886535544484559}
{"step": 991840, "time": 31401.639533758163, "episode/length": 90.0, "episode/score": 0.8063098235797952, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0875598252096097}
{"step": 992040, "time": 31407.584429979324, "episode/length": 107.0, "episode/score": 0.7496354500653979, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.08401044526908663}
{"step": 992256, "time": 31414.444570541382, "episode/length": 98.0, "episode/score": 0.7585363804582812, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.06478632797825412}
{"step": 992320, "time": 31416.56201195717, "episode/length": 34.0, "episode/score": 0.9280104583631328, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.034260448072018335}
{"step": 992608, "time": 31425.425818920135, "episode/length": 95.0, "episode/score": 0.7986202361462347, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.09549523777604918}
{"step": 992880, "time": 31433.78179001808, "episode/length": 288.0, "episode/score": 0.1382153702446658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1382153702446658}
{"step": 992960, "time": 31436.26753258705, "episode/length": 288.0, "episode/score": 0.10841684419949615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10841684419949615}
{"step": 992968, "time": 31436.301897525787, "episode/length": 288.0, "episode/score": 0.12295067011211813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12295067011211813}
{"step": 993088, "time": 31440.218960762024, "episode/length": 103.0, "episode/score": 0.7508239133567258, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.07269889114468242}
{"step": 993472, "time": 31452.160782814026, "episode/length": 288.0, "episode/score": 0.14627550250133936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14627550250133936}
{"step": 993608, "time": 31456.148875951767, "episode/length": 79.0, "episode/score": 0.8027518900325958, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.049626849473497714}
{"step": 993912, "time": 31465.514449119568, "episode/length": 198.0, "episode/score": 0.4758686160575962, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.09461862434636714}
{"step": 994056, "time": 31469.966017007828, "episode/length": 288.0, "episode/score": 0.10957357300912918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10957357300912918}
{"step": 994176, "time": 31473.887962579727, "episode/length": 135.0, "episode/score": 0.682564062450183, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.10443906477848941}
{"step": 994192, "time": 31474.402575969696, "episode/length": 89.0, "episode/score": 0.7994509227542039, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.07757591246308948}
{"step": 994224, "time": 31475.512789011, "episode/length": 157.0, "episode/score": 0.6028937257478901, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.09351876251184876}
{"step": 994824, "time": 31493.789500951767, "episode/length": 113.0, "episode/score": 0.7285642070551148, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.08168915457508774}
{"step": 994920, "time": 31496.757343053818, "episode/length": 288.0, "episode/score": 0.09625534328597496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09625534328597496}
{"step": 995192, "time": 31505.29395723343, "episode/length": 288.0, "episode/score": 0.0955997333257983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0955997333257983}
{"step": 995448, "time": 31513.169780492783, "episode/length": 173.0, "episode/score": 0.5932778514147685, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.13390285819014025}
{"step": 995456, "time": 31513.645176410675, "episode/length": 153.0, "episode/score": 0.6118761388520397, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0900010986538291}
{"step": 995624, "time": 31518.607027053833, "episode/length": 87.0, "episode/score": 0.7757929606991638, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.04766796818466901}
{"step": 995752, "time": 31522.611262321472, "episode/length": 37.0, "episode/score": 0.9160585715342222, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.03168359770438656}
{"step": 995920, "time": 31528.101964473724, "episode/length": 288.0, "episode/score": 0.08657279252929584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08657279252929584}
{"step": 996312, "time": 31540.054872512817, "episode/length": 69.0, "episode/score": 0.8402093038919247, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.05583429360081027}
{"step": 996488, "time": 31545.453439235687, "episode/length": 288.0, "episode/score": 0.0700370941572146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0700370941572146}
{"step": 996504, "time": 31545.952098608017, "episode/length": 288.0, "episode/score": 0.08501638422626456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08501638422626456}
{"step": 996576, "time": 31548.385253429413, "episode/length": 118.0, "episode/score": 0.7037699189174873, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.07251990799773012}
{"step": 996752, "time": 31553.81442952156, "episode/length": 103.0, "episode/score": 0.7298214470056337, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.051696436085876485}
{"step": 996776, "time": 31554.333786725998, "episode/length": 24.0, "episode/score": 0.9560399927459002, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.031039981639878533}
{"step": 996832, "time": 31556.26252245903, "episode/length": 40.0, "episode/score": 0.9168676015456185, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.04186758518926581}
{"step": 996888, "time": 31557.76331138611, "episode/length": 71.0, "episode/score": 0.8415913900093983, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.06346638761124268}
{"step": 997136, "time": 31565.71658539772, "episode/length": 288.0, "episode/score": 0.10464848581477781, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10464848581477781}
{"step": 997456, "time": 31575.56151866913, "episode/length": 120.0, "episode/score": 0.7080725549233193, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.08307253559837591}
{"step": 997504, "time": 31577.03522324562, "episode/length": 288.0, "episode/score": 0.06540842717072337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06540842717072337}
{"step": 997712, "time": 31583.446038007736, "episode/length": 109.0, "episode/score": 0.7431666340992251, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.08379162380811067}
{"step": 997744, "time": 31584.442925691605, "episode/length": 29.0, "episode/score": 0.9437689180147117, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.03439387745561362}
{"step": 997760, "time": 31584.937235355377, "episode/length": 77.0, "episode/score": 0.8079761754652282, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.04860119974364352}
{"step": 997768, "time": 31584.97043323517, "episode/length": 288.0, "episode/score": 0.07438090060463765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07438090060463765}
{"step": 997824, "time": 31586.896782636642, "episode/length": 133.0, "episode/score": 0.6687784124392238, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0844033894122731}
{"step": 997976, "time": 31591.34469485283, "episode/length": 135.0, "episode/score": 0.6765777422813244, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.09845274271788185}
{"step": 998184, "time": 31597.85356760025, "episode/length": 52.0, "episode/score": 0.8778438094011562, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.04034381688666144}
{"step": 998264, "time": 31600.333327770233, "episode/length": 61.0, "episode/score": 0.8534301816816878, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.044055206524717505}
{"step": 998520, "time": 31608.191804647446, "episode/length": 96.0, "episode/score": 0.7461049192868359, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.046104914851412104}
{"step": 998552, "time": 31609.17427253723, "episode/length": 45.0, "episode/score": 0.9017760787703537, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.04240106241400099}
{"step": 998640, "time": 31612.08809542656, "episode/length": 82.0, "episode/score": 0.804043018713628, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.06029302323054253}
{"step": 998640, "time": 31612.097853422165, "episode/length": 115.0, "episode/score": 0.6988620142085438, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.058236994883600346}
{"step": 998936, "time": 31620.970262765884, "episode/length": 138.0, "episode/score": 0.6301316091460194, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.061381561962889464}
{"step": 999088, "time": 31625.980548143387, "episode/length": 288.0, "episode/score": 0.08096778723597708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08096778723597708}
{"step": 999256, "time": 31630.906894207, "episode/length": 87.0, "episode/score": 0.7821480698858068, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.054023085549488314}
{"step": 999256, "time": 31630.912293434143, "episode/length": 39.0, "episode/score": 0.9102874016097076, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.03216239012533606}
{"step": 999408, "time": 31635.79787325859, "episode/length": 110.0, "episode/score": 0.7157575133828686, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.05950749004159661}
{"step": 999768, "time": 31647.11518907547, "episode/length": 288.0, "episode/score": 0.05334693449810857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05334693449810857}
{"step": 999904, "time": 31651.504652500153, "episode/length": 101.0, "episode/score": 0.7391900890189618, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.05481508458353801}
{"step": 1000064, "time": 31657.43830394745, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 1000064, "time": 31657.628989219666, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1000064, "time": 31657.88349199295, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1000064, "time": 31657.935904979706, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1000064, "time": 31658.560884952545, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1000064, "time": 31658.875153303146, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 1000064, "time": 31659.116452217102, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 1000064, "time": 31659.58424949646, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 1000128, "time": 31661.565555095673, "episode/length": 108.0, "episode/score": 0.7297933379621782, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.06729330073255824}
{"step": 1000184, "time": 31663.063440322876, "episode/length": 34.0, "episode/score": 0.9213332597956878, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.02758324831131631}
{"step": 1000200, "time": 31663.55804347992, "episode/length": 53.0, "episode/score": 0.8613958774002413, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.027020839239298766}
{"step": 1000504, "time": 31672.889530420303, "episode/length": 37.0, "episode/score": 0.913523012472524, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.029148016989438474}
{"step": 1000576, "time": 31675.31094932556, "episode/length": 288.0, "episode/score": 0.08780625101758233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08780625101758233}
{"step": 1000656, "time": 31677.78527379036, "episode/length": 174.0, "episode/score": 0.5765949500020042, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.12034494454212563}
{"step": 1000952, "time": 31686.803828954697, "episode/length": 288.0, "episode/score": 0.08046735185405396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08046735185405396}
{"step": 1000952, "time": 31686.811136245728, "episode/length": 288.0, "episode/score": 0.08983881079973344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08983881079973344}
{"step": 1001112, "time": 31691.735904216766, "episode/length": 66.0, "episode/score": 0.8318689196548803, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.038118902180940495}
{"step": 1001160, "time": 31693.218142986298, "episode/length": 62.0, "episode/score": 0.8491149691683404, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.042864979622436294}
{"step": 1001368, "time": 31699.62361431122, "episode/length": 154.0, "episode/score": 0.603057537452969, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0843075496882193}
{"step": 1001440, "time": 31702.076402902603, "episode/length": 116.0, "episode/score": 0.7404915129416167, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.10299151668436934}
{"step": 1001520, "time": 31704.528874635696, "episode/length": 50.0, "episode/score": 0.8833649919776008, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.03961499241415822}
{"step": 1001568, "time": 31706.024990797043, "episode/length": 50.0, "episode/score": 0.8782532344968104, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0345032051019416}
{"step": 1001720, "time": 31710.48977303505, "episode/length": 288.0, "episode/score": 0.09435258388373313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09435258388373313}
{"step": 1001784, "time": 31712.4640250206, "episode/length": 103.0, "episode/score": 0.7452775685040933, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0671525312744734}
{"step": 1001912, "time": 31716.531059026718, "episode/length": 119.0, "episode/score": 0.7199577999082294, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.09183278082775814}
{"step": 1001984, "time": 31718.96297645569, "episode/length": 76.0, "episode/score": 0.8365577405195381, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.07405777659664636}
{"step": 1002168, "time": 31724.422298908234, "episode/length": 74.0, "episode/score": 0.8071790941219206, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.03842911051901865}
{"step": 1002344, "time": 31729.851848125458, "episode/length": 69.0, "episode/score": 0.8244606563653178, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.040085664584239566}
{"step": 1002496, "time": 31734.750718832016, "episode/length": 288.0, "episode/score": 0.05408479377376807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05408479377376807}
{"step": 1002536, "time": 31735.7845556736, "episode/length": 126.0, "episode/score": 0.6953255996456846, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.08907563170646426}
{"step": 1002848, "time": 31745.764008760452, "episode/length": 62.0, "episode/score": 0.8468297825356785, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.040579783036264416}
{"step": 1002880, "time": 31746.745278835297, "episode/length": 88.0, "episode/score": 0.7813739989649093, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.05637397555960888}
{"step": 1003000, "time": 31750.226397514343, "episode/length": 135.0, "episode/score": 0.6529133509160374, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.07478834273786106}
{"step": 1003488, "time": 31765.464032649994, "episode/length": 118.0, "episode/score": 0.684022914627576, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.05277289416176245}
{"step": 1003752, "time": 31773.350014209747, "episode/length": 288.0, "episode/score": 0.03517534222407903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03517534222407903}
{"step": 1003840, "time": 31776.42056107521, "episode/length": 123.0, "episode/score": 0.680843393579039, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.06521838987703177}
{"step": 1003968, "time": 31780.37583374977, "episode/length": 247.0, "episode/score": 0.3364346177610287, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.10830961331396338}
{"step": 1004032, "time": 31782.346873998642, "episode/length": 288.0, "episode/score": 0.10339804265356634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10339804265356634}
{"step": 1004040, "time": 31782.379885196686, "episode/length": 68.0, "episode/score": 0.818453217700835, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.03095318047121509}
{"step": 1004248, "time": 31788.78782439232, "episode/length": 155.0, "episode/score": 0.5965377958206091, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.08091277050027657}
{"step": 1004440, "time": 31794.71843290329, "episode/length": 242.0, "episode/score": 0.33837829000174224, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.09462827839513466}
{"step": 1004456, "time": 31795.216790676117, "episode/length": 60.0, "episode/score": 0.8553708058888105, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.04287082602866121}
{"step": 1004464, "time": 31795.688449382782, "episode/length": 88.0, "episode/score": 0.7770072330944231, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.05200721262860952}
{"step": 1005128, "time": 31816.038227558136, "episode/length": 82.0, "episode/score": 0.7875260764941459, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.04377609317646147}
{"step": 1005168, "time": 31817.483695030212, "episode/length": 114.0, "episode/score": 0.7132012447050329, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.06945126110213096}
{"step": 1005192, "time": 31818.00914311409, "episode/length": 288.0, "episode/score": 0.08844278879212197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08844278879212197}
{"step": 1005568, "time": 31829.780883550644, "episode/length": 49.0, "episode/score": 0.8712895634063216, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.024414543307216263}
{"step": 1005704, "time": 31833.741847276688, "episode/length": 208.0, "episode/score": 0.3980972467185211, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.04809724703284246}
{"step": 1006152, "time": 31847.67914414406, "episode/length": 288.0, "episode/score": 0.044425748884975746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044425748884975746}
{"step": 1006352, "time": 31854.0689599514, "episode/length": 288.0, "episode/score": 0.08430401916507435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08430401916507435}
{"step": 1006352, "time": 31854.074561357498, "episode/length": 97.0, "episode/score": 0.7313981431599359, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.03452317037783814}
{"step": 1006656, "time": 31863.42940402031, "episode/length": 62.0, "episode/score": 0.8482087952770598, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.04195883725060412}
{"step": 1006752, "time": 31866.51640510559, "episode/length": 288.0, "episode/score": 0.1016010556445508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1016010556445508}
{"step": 1006768, "time": 31867.011501789093, "episode/length": 288.0, "episode/score": 0.07822301913751062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07822301913751062}
{"step": 1006784, "time": 31867.519347429276, "episode/length": 53.0, "episode/score": 0.8668755597087738, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0325005539986023}
{"step": 1006856, "time": 31869.53548336029, "episode/length": 24.0, "episode/score": 0.952676195413801, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.027676201624558416}
{"step": 1007216, "time": 31880.80979990959, "episode/length": 57.0, "episode/score": 0.8511458849115456, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.029270901593861254}
{"step": 1007384, "time": 31885.745902061462, "episode/length": 76.0, "episode/score": 0.8275035627090688, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.06500354930966523}
{"step": 1007440, "time": 31887.67933487892, "episode/length": 72.0, "episode/score": 0.8122248432558763, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.03722484177740171}
{"step": 1007440, "time": 31887.686458826065, "episode/length": 288.0, "episode/score": 0.10266484569496015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10266484569496015}
{"step": 1007504, "time": 31889.681954860687, "episode/length": 288.0, "episode/score": 0.09960858879099987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09960858879099987}
{"step": 1007640, "time": 31894.133810281754, "episode/length": 106.0, "episode/score": 0.7275846881692587, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.05883472840821469}
{"step": 1007952, "time": 31904.06998205185, "episode/length": 70.0, "episode/score": 0.8173396870640204, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.03608968728229911}
{"step": 1007960, "time": 31904.103612184525, "episode/length": 92.0, "episode/score": 0.756372491887987, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.043872528899328245}
{"step": 1008016, "time": 31906.050146102905, "episode/length": 288.0, "episode/score": 0.07648578333242995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07648578333242995}
{"step": 1008160, "time": 31910.476435422897, "episode/length": 64.0, "episode/score": 0.8370127706116932, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.037012773795652265}
{"step": 1008416, "time": 31918.32543873787, "episode/length": 56.0, "episode/score": 0.8550786746749282, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.03007870472754348}
{"step": 1008472, "time": 31919.85020828247, "episode/length": 56.0, "episode/score": 0.8562355449520282, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.031235583284683344}
{"step": 1008664, "time": 31925.882838010788, "episode/length": 288.0, "episode/score": 0.10217752609560193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10217752609560193}
{"step": 1008992, "time": 31936.161597013474, "episode/length": 71.0, "episode/score": 0.813625663561595, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.035500688652007284}
{"step": 1009032, "time": 31937.17000436783, "episode/length": 69.0, "episode/score": 0.8317639525354821, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0473889607544038}
{"step": 1009240, "time": 31943.564499139786, "episode/length": 71.0, "episode/score": 0.7972582962212869, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.01913333455394195}
{"step": 1009360, "time": 31947.450706243515, "episode/length": 45.0, "episode/score": 0.8919510678578035, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.03257604253747104}
{"step": 1009752, "time": 31959.397112607956, "episode/length": 288.0, "episode/score": 0.08095523345127731, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08095523345127731}
{"step": 1009752, "time": 31959.404027700424, "episode/length": 288.0, "episode/score": 0.08474745542827122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08474745542827122}
{"step": 1009816, "time": 31961.363859653473, "episode/length": 288.0, "episode/score": 0.08305280921439362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08305280921439362}
{"step": 1010048, "time": 31969.27116060257, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 1010048, "time": 31969.769611358643, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1010048, "time": 31969.82073378563, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1010048, "time": 31969.84059906006, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1010048, "time": 31969.860910892487, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1010048, "time": 31970.404372692108, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1010048, "time": 31970.698304891586, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1010048, "time": 31970.85635662079, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 1010064, "time": 31971.35088801384, "episode/length": 128.0, "episode/score": 0.660802339532097, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.06080230924374064}
{"step": 1010160, "time": 31974.2787194252, "episode/length": 99.0, "episode/score": 0.7405314848202806, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0499064504602984}
{"step": 1010264, "time": 31977.27123618126, "episode/length": 288.0, "episode/score": 0.08993546921595907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08993546921595907}
{"step": 1010328, "time": 31979.2327105999, "episode/length": 135.0, "episode/score": 0.6224977267786471, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.044372744910333495}
{"step": 1010440, "time": 31982.694234609604, "episode/length": 85.0, "episode/score": 0.7821922619222619, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0478172578331737}
{"step": 1010472, "time": 31983.69139623642, "episode/length": 288.0, "episode/score": 0.07622808475343845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07622808475343845}
{"step": 1010472, "time": 31983.69667172432, "episode/length": 50.0, "episode/score": 0.8690623557580466, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.02531237886648796}
{"step": 1010728, "time": 31991.665786504745, "episode/length": 70.0, "episode/score": 0.8099611052034561, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.028711079883123602}
{"step": 1010840, "time": 31995.10098028183, "episode/length": 71.0, "episode/score": 0.8131103138700269, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.03498530335190253}
{"step": 1011048, "time": 32001.47456049919, "episode/length": 89.0, "episode/score": 0.7732374983113459, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.05136248230132878}
{"step": 1011248, "time": 32007.838183164597, "episode/length": 50.0, "episode/score": 0.8675587755172955, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.023808788686778826}
{"step": 1011400, "time": 32012.282935380936, "episode/length": 83.0, "episode/score": 0.7989564667559534, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.058331466022536915}
{"step": 1011920, "time": 32028.544774532318, "episode/length": 108.0, "episode/score": 0.7063376924334079, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.04383768176103331}
{"step": 1012064, "time": 32032.96580696106, "episode/length": 288.0, "episode/score": 0.02895844172070383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02895844172070383}
{"step": 1012128, "time": 32034.94099187851, "episode/length": 288.0, "episode/score": 0.07899604608718391, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07899604608718391}
{"step": 1012192, "time": 32036.916360855103, "episode/length": 117.0, "episode/score": 0.6870517465534363, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.05267674507496167}
{"step": 1012336, "time": 32041.358994722366, "episode/length": 33.0, "episode/score": 0.9147756560282119, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.017900647291241967}
{"step": 1012432, "time": 32044.324425697327, "episode/length": 128.0, "episode/score": 0.6496502432161719, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.04965021528522584}
{"step": 1012496, "time": 32046.38696360588, "episode/length": 45.0, "episode/score": 0.8768045194108254, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.017429534515713385}
{"step": 1012736, "time": 32053.7501142025, "episode/length": 37.0, "episode/score": 0.9036810626745932, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.01930609968593444}
{"step": 1012752, "time": 32054.26931810379, "episode/length": 288.0, "episode/score": 0.10308550435348707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10308550435348707}
{"step": 1012784, "time": 32055.261540412903, "episode/length": 288.0, "episode/score": 0.03776093134376879, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03776093134376879}
{"step": 1012784, "time": 32055.275071382523, "episode/length": 288.0, "episode/score": 0.07961036141159639, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07961036141159639}
{"step": 1013080, "time": 32064.181355714798, "episode/length": 110.0, "episode/score": 0.6919826774200146, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.03573270052845601}
{"step": 1013312, "time": 32071.721606492996, "episode/length": 69.0, "episode/score": 0.8121597292947627, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.02778474378555984}
{"step": 1013576, "time": 32079.845055103302, "episode/length": 61.0, "episode/score": 0.8444703989706, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.03509540680244072}
{"step": 1013600, "time": 32080.82224059105, "episode/length": 101.0, "episode/score": 0.7157136831764319, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.03133869100827269}
{"step": 1013624, "time": 32081.353870868683, "episode/length": 104.0, "episode/score": 0.7212954363174049, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.04629541794997749}
{"step": 1013744, "time": 32085.347645044327, "episode/length": 125.0, "episode/score": 0.6788423990996648, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.06946739265316637}
{"step": 1014048, "time": 32094.69364118576, "episode/length": 37.0, "episode/score": 0.9096612857389346, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.025286305491704297}
{"step": 1014232, "time": 32100.119157791138, "episode/length": 75.0, "episode/score": 0.7974982072963144, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.031873184857261094}
{"step": 1014232, "time": 32100.127351522446, "episode/length": 288.0, "episode/score": 0.0615345349758627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0615345349758627}
{"step": 1014504, "time": 32108.583836078644, "episode/length": 115.0, "episode/score": 0.6956526640035463, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.05502766414906546}
{"step": 1014648, "time": 32112.995798110962, "episode/length": 288.0, "episode/score": 0.05514329700270082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05514329700270082}
{"step": 1014664, "time": 32113.48988366127, "episode/length": 132.0, "episode/score": 0.6464610029905771, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.058961026977954134}
{"step": 1014792, "time": 32117.42472219467, "episode/length": 69.0, "episode/score": 0.8033531409029138, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.01897814106007445}
{"step": 1014808, "time": 32117.923626184464, "episode/length": 288.0, "episode/score": 0.04172688046702433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04172688046702433}
{"step": 1014992, "time": 32123.798179388046, "episode/length": 60.0, "episode/score": 0.8411556664069053, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.028655662317817132}
{"step": 1015032, "time": 32124.80455684662, "episode/length": 29.0, "episode/score": 0.937858661076973, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.028483661234133706}
{"step": 1015160, "time": 32128.724210500717, "episode/length": 43.0, "episode/score": 0.8858157486839673, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.020190725002180443}
{"step": 1015536, "time": 32140.61191058159, "episode/length": 62.0, "episode/score": 0.840411012161951, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.03416101356475565}
{"step": 1015624, "time": 32143.095266342163, "episode/length": 288.0, "episode/score": 0.035537944164389046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035537944164389046}
{"step": 1015656, "time": 32144.100139141083, "episode/length": 123.0, "episode/score": 0.6467791924334847, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.031154168751697853}
{"step": 1015672, "time": 32144.595378637314, "episode/length": 84.0, "episode/score": 0.7781900978501426, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.040690100088227155}
{"step": 1015872, "time": 32151.40683245659, "episode/length": 24.0, "episode/score": 0.9410505226887267, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.016050510913316884}
{"step": 1016208, "time": 32161.719135284424, "episode/length": 130.0, "episode/score": 0.6374422086007598, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.04369220874627899}
{"step": 1016360, "time": 32166.27798986435, "episode/length": 288.0, "episode/score": 0.08369119996149266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08369119996149266}
{"step": 1016544, "time": 32172.153787374496, "episode/length": 288.0, "episode/score": 0.01592627134232316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01592627134232316}
{"step": 1016600, "time": 32173.668083667755, "episode/length": 90.0, "episode/score": 0.7656012622367712, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.04685127639578468}
{"step": 1016640, "time": 32175.118832349777, "episode/length": 122.0, "episode/score": 0.66001220149559, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.041262210145248446}
{"step": 1016696, "time": 32176.62002515793, "episode/length": 41.0, "episode/score": 0.9065175723171137, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.03464259631613231}
{"step": 1016832, "time": 32181.01490831375, "episode/length": 77.0, "episode/score": 0.808505926077487, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0491309761418961}
{"step": 1016960, "time": 32184.94605588913, "episode/length": 288.0, "episode/score": 0.027323665612470904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027323665612470904}
{"step": 1017184, "time": 32191.818033218384, "episode/length": 72.0, "episode/score": 0.7891854794798405, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.014185517480711951}
{"step": 1017376, "time": 32197.837816238403, "episode/length": 91.0, "episode/score": 0.7408298425150974, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.02520486450595172}
{"step": 1017672, "time": 32206.71612071991, "episode/length": 104.0, "episode/score": 0.7185160833532791, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.04351605624015065}
{"step": 1017704, "time": 32207.70063996315, "episode/length": 64.0, "episode/score": 0.8187063928295402, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.018706392317312748}
{"step": 1017760, "time": 32209.655572891235, "episode/length": 132.0, "episode/score": 0.626867444385482, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.039367463759901966}
{"step": 1017768, "time": 32209.688164949417, "episode/length": 152.0, "episode/score": 0.6037408827864965, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.07874092078736794}
{"step": 1017840, "time": 32212.103474140167, "episode/length": 109.0, "episode/score": 0.7169116790408907, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0575366672654809}
{"step": 1017848, "time": 32212.137808561325, "episode/length": 288.0, "episode/score": 0.06344561304354102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06344561304354102}
{"step": 1017904, "time": 32214.111771583557, "episode/length": 65.0, "episode/score": 0.8329767292554209, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.03610170114112066}
{"step": 1017936, "time": 32215.100352048874, "episode/length": 288.0, "episode/score": 0.0272366410335394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0272366410335394}
{"step": 1018248, "time": 32224.46619129181, "episode/length": 49.0, "episode/score": 0.8706713065281235, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.023796304677119906}
{"step": 1018280, "time": 32225.57615494728, "episode/length": 71.0, "episode/score": 0.8175628324729587, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.039437829201688146}
{"step": 1018424, "time": 32230.012844085693, "episode/length": 82.0, "episode/score": 0.7988469366142397, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.055096974615111094}
{"step": 1018456, "time": 32230.996918201447, "episode/length": 85.0, "episode/score": 0.7775269204011579, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.04315192054667705}
{"step": 1018616, "time": 32235.895605564117, "episode/length": 84.0, "episode/score": 0.7627722696893215, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.025272242576193094}
{"step": 1018648, "time": 32236.872713565826, "episode/length": 121.0, "episode/score": 0.695639605252552, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.07376462724340627}
{"step": 1018664, "time": 32237.362879753113, "episode/length": 51.0, "episode/score": 0.8630222731964068, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.02239725700303552}
{"step": 1018713, "time": 32239.866541862488, "train_stats/mean_log_entropy": 0.06990742964385929, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.158668212890625, "train/action_min": 0.0, "train/action_std": 1.8107178103923798, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012340104683535174, "train/actor_opt_grad_steps": 62575.0, "train/actor_opt_loss": -15.716574878692628, "train/adv_mag": 1.0572249829769134, "train/adv_max": 0.3510517168045044, "train/adv_mean": 0.0005399675700209628, "train/adv_min": -1.009848530292511, "train/adv_std": 0.032405172642320394, "train/cont_avg": 0.9947900390625, "train/cont_loss_mean": 0.018937294490169735, "train/cont_loss_std": 0.25384606268256904, "train/cont_neg_acc": 0.2831912134685109, "train/cont_neg_loss": 2.939451814016056, "train/cont_pos_acc": 0.9998430380225182, "train/cont_pos_loss": 0.00382700449321419, "train/cont_pred": 0.9948459541797638, "train/cont_rate": 0.9947900390625, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11057922769803553, "train/extr_critic_critic_opt_grad_steps": 62575.0, "train/extr_critic_critic_opt_loss": 10624.397216796875, "train/extr_critic_mag": 1.5821132969856262, "train/extr_critic_max": 1.5821132969856262, "train/extr_critic_mean": 1.4770378428697586, "train/extr_critic_min": 1.210271641612053, "train/extr_critic_std": 0.024103884389624, "train/extr_return_normed_mag": 1.0908264112472534, "train/extr_return_normed_max": 0.35046991527080534, "train/extr_return_normed_mean": 0.04340003272518515, "train/extr_return_normed_min": -1.0192282432317734, "train/extr_return_normed_std": 0.04162744987756014, "train/extr_return_rate": 0.9994762775301933, "train/extr_return_raw_mag": 1.7846476119756698, "train/extr_return_raw_max": 1.7846476119756698, "train/extr_return_raw_mean": 1.4775777971744537, "train/extr_return_raw_min": 0.41494945347309115, "train/extr_return_raw_std": 0.04162744983099401, "train/extr_reward_mag": 0.36066353261470796, "train/extr_reward_max": 0.36066353261470796, "train/extr_reward_mean": 0.0025406716531142593, "train/extr_reward_min": 4.286766052246094e-06, "train/extr_reward_std": 0.009766712142154575, "train/image_loss_mean": 0.09409178581088781, "train/image_loss_std": 0.10482807256281376, "train/model_loss_mean": 0.7406214952468873, "train/model_loss_std": 0.4390062815323472, "train/model_opt_grad_norm": 16.98886188983917, "train/model_opt_grad_steps": 62518.15, "train/model_opt_loss": 3829.536809082031, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5200.0, "train/policy_entropy_mag": 1.2664007955789567, "train/policy_entropy_max": 1.2664007955789567, "train/policy_entropy_mean": 0.09060390900820493, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11065609946846962, "train/policy_logprob_mag": 6.551080250740052, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09091716278344393, "train/policy_logprob_min": -6.551080250740052, "train/policy_logprob_std": 0.6296726581454277, "train/policy_randomness_mag": 0.6508013060688973, "train/policy_randomness_max": 0.6508013060688973, "train/policy_randomness_mean": 0.04656120002269745, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05686598950996995, "train/post_ent_mag": 2.811537297964096, "train/post_ent_max": 2.811537297964096, "train/post_ent_mean": 2.8114783895015716, "train/post_ent_min": 2.8114351642131807, "train/post_ent_std": 2.0217191863594053e-05, "train/prior_ent_mag": 3.1357533884048463, "train/prior_ent_max": 3.1357533884048463, "train/prior_ent_mean": 2.8177926790714265, "train/prior_ent_min": 2.8111099398136137, "train/prior_ent_std": 0.016703817083034665, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0020235671593400186, "train/reward_loss_mean": 0.027592390310019255, "train/reward_loss_std": 0.19545522356405853, "train/reward_max_data": 0.723595711356029, "train/reward_max_pred": 0.2551990056037903, "train/reward_neg_acc": 0.9996867644786834, "train/reward_neg_loss": 0.018092555524781347, "train/reward_pos_acc": 0.22258105564941752, "train/reward_pos_loss": 3.9226768590668413, "train/reward_pred": 0.0017812791973119602, "train/reward_rate": 0.002412109375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 0.01911958120763302, "report/cont_loss_std": 0.23514650762081146, "report/cont_neg_acc": 0.4444444477558136, "report/cont_neg_loss": 1.845175862312317, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002927950816228986, "report/cont_pred": 0.9930893182754517, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11289405077695847, "report/image_loss_std": 0.11310186982154846, "report/model_loss_mean": 0.7682101726531982, "report/model_loss_std": 0.48708659410476685, "report/post_ent_mag": 2.8111026287078857, "report/post_ent_max": 2.8111026287078857, "report/post_ent_mean": 2.811091899871826, "report/post_ent_min": 2.811063766479492, "report/post_ent_std": 9.73886653810041e-06, "report/prior_ent_mag": 2.9267220497131348, "report/prior_ent_max": 2.9267220497131348, "report/prior_ent_mean": 2.817213296890259, "report/prior_ent_min": 2.811122417449951, "report/prior_ent_std": 0.009597170166671276, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.005445870570838451, "report/reward_loss_mean": 0.036196518689394, "report/reward_loss_std": 0.24302151799201965, "report/reward_max_data": 0.9485416412353516, "report/reward_max_pred": 0.8096878528594971, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.019731730222702026, "report/reward_pos_acc": 0.4285714626312256, "report/reward_pos_loss": 2.428295612335205, "report/reward_pred": 0.0037115083541721106, "report/reward_rate": 0.0068359375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020246971398591995, "eval/cont_loss_std": 0.3329978585243225, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.932681083679199, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0028744942974299192, "eval/cont_pred": 0.9971926212310791, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13430552184581757, "eval/image_loss_std": 0.12396504729986191, "eval/model_loss_mean": 0.7626020908355713, "eval/model_loss_std": 0.43182364106178284, "eval/post_ent_mag": 2.8111026287078857, "eval/post_ent_max": 2.8111026287078857, "eval/post_ent_mean": 2.811091661453247, "eval/post_ent_min": 2.8110830783843994, "eval/post_ent_std": 9.692776075098664e-06, "eval/prior_ent_mag": 2.8944365978240967, "eval/prior_ent_max": 2.8944365978240967, "eval/prior_ent_mean": 2.816516399383545, "eval/prior_ent_min": 2.8111424446105957, "eval/prior_ent_std": 0.008772848173975945, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0005645751953125, "eval/reward_loss_mean": 0.008049579337239265, "eval/reward_loss_std": 0.14593686163425446, "eval/reward_max_data": 0.578125, "eval/reward_max_pred": 0.044440507888793945, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.003495821263641119, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.666543960571289, "eval/reward_pred": 0.0008951625786721706, "eval/reward_rate": 0.0009765625, "replay/size": 1000000.0, "replay/inserts": 32016.0, "replay/samples": 32016.0, "replay/insert_wait_avg": 1.1633554736951897e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.819200026756641e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3960.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.498812935569069e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3970692157745, "timer/env.step_count": 4002.0, "timer/env.step_total": 34.399046659469604, "timer/env.step_frac": 0.03438539327832648, "timer/env.step_avg": 0.00859546393290095, "timer/env.step_min": 0.007207632064819336, "timer/env.step_max": 0.038098812103271484, "timer/replay._sample_count": 32016.0, "timer/replay._sample_total": 16.154951095581055, "timer/replay._sample_frac": 0.0161485390078613, "timer/replay._sample_avg": 0.0005045899267735212, "timer/replay._sample_min": 0.00040841102600097656, "timer/replay._sample_max": 0.024877309799194336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4497.0, "timer/agent.policy_total": 37.6938750743866, "timer/agent.policy_frac": 0.03767891393757817, "timer/agent.policy_avg": 0.008382004686321236, "timer/agent.policy_min": 0.007428169250488281, "timer/agent.policy_max": 0.07165646553039551, "timer/dataset_train_count": 2001.0, "timer/dataset_train_total": 0.21174359321594238, "timer/dataset_train_frac": 0.0002116595497245221, "timer/dataset_train_avg": 0.000105818887164389, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0004112720489501953, "timer/agent.train_count": 2001.0, "timer/agent.train_total": 883.463570356369, "timer/agent.train_frac": 0.8831129134044031, "timer/agent.train_avg": 0.4415110296633528, "timer/agent.train_min": 0.4320034980773926, "timer/agent.train_max": 0.6075971126556396, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4748842716217041, "timer/agent.report_frac": 0.0004746957845388058, "timer/agent.report_avg": 0.23744213581085205, "timer/agent.report_min": 0.23193693161010742, "timer/agent.report_max": 0.24294734001159668, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8122225863814795e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 32.00277581525809}
{"step": 1018728, "time": 32239.933767795563, "episode/length": 102.0, "episode/score": 0.7253518476284739, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.04410188154025718}
{"step": 1019088, "time": 32251.608431339264, "episode/length": 78.0, "episode/score": 0.7888278845051104, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0325778325489523}
{"step": 1019088, "time": 32251.61497926712, "episode/length": 155.0, "episode/score": 0.5803689314239477, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.06474394558296126}
{"step": 1019112, "time": 32252.138251066208, "episode/length": 55.0, "episode/score": 0.8530647842640633, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.02493975614976307}
{"step": 1019336, "time": 32259.183345794678, "episode/length": 89.0, "episode/score": 0.7658052532973443, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.043930226184215826}
{"step": 1019368, "time": 32260.177132368088, "episode/length": 89.0, "episode/score": 0.7595256051625938, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.037650604650366404}
{"step": 1019376, "time": 32260.6682574749, "episode/length": 118.0, "episode/score": 0.6919271669763134, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.06067715220029868}
{"step": 1019624, "time": 32268.107530593872, "episode/length": 31.0, "episode/score": 0.9149237891215307, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.011798772928159451}
{"step": 1019648, "time": 32269.095426797867, "episode/length": 66.0, "episode/score": 0.8102830015904772, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.016532985397105904}
{"step": 1019712, "time": 32271.083226442337, "episode/length": 41.0, "episode/score": 0.8904778068742587, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.018602814327749684}
