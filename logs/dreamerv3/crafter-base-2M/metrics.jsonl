{"step": 1016, "time": 110.42664885520935, "episode/length": 126.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 1088, "time": 112.05949020385742, "episode/length": 135.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 1168, "time": 113.67218041419983, "episode/length": 145.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 1240, "time": 115.33431005477905, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 1368, "time": 117.17559242248535, "episode/length": 170.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 1408, "time": 118.72248339653015, "episode/length": 175.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 1448, "time": 120.28368711471558, "episode/length": 180.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 1512, "time": 121.8974084854126, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 135.95535230636597, "eval_episode/length": 36.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8648648648648649}
{"step": 1560, "time": 139.8013927936554, "eval_episode/length": 122.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.943089430894309}
{"step": 1560, "time": 141.84951996803284, "eval_episode/length": 148.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 1560, "time": 143.48890352249146, "eval_episode/length": 159.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.99375}
{"step": 1560, "time": 145.35524797439575, "eval_episode/length": 172.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 1560, "time": 146.85996413230896, "eval_episode/length": 175.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 1560, "time": 148.3611397743225, "eval_episode/length": 181.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 1560, "time": 149.87211990356445, "eval_episode/length": 186.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 1560, "time": 151.4363133907318, "train_stats/sum_log_reward": 1.4749999772757292, "train_stats/max_log_achievement_collect_sapling": 1.0, "train_stats/max_log_achievement_place_plant": 0.875, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/max_log_achievement_collect_wood": 0.3333333333333333, "train_stats/max_log_achievement_place_table": 0.16666666666666666, "eval_stats/sum_log_reward": 1.3499999642372131, "eval_stats/max_log_achievement_collect_sapling": 0.625, "eval_stats/max_log_achievement_collect_wood": 0.25, "eval_stats/max_log_achievement_place_plant": 0.625, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/max_log_achievement_collect_drink": 1.6666666666666667}
{"step": 1560, "time": 191.93976998329163, "eval_episode/length": 162.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 1560, "time": 194.19023489952087, "eval_episode/length": 177.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 1560, "time": 196.06687927246094, "eval_episode/length": 180.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.994475138121547}
{"step": 1560, "time": 197.83480644226074, "eval_episode/length": 181.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 1560, "time": 199.90448546409607, "eval_episode/length": 190.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 1560, "time": 201.90801739692688, "eval_episode/length": 198.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 1560, "time": 204.07129859924316, "eval_episode/length": 199.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.995}
{"step": 1560, "time": 208.59826636314392, "eval_episode/length": 240.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.991701244813278}
{"step": 1561, "time": 333.71989941596985, "eval_stats/sum_log_reward": 2.724999964237213, "eval_stats/max_log_achievement_collect_drink": 0.875, "eval_stats/max_log_achievement_collect_sapling": 0.75, "eval_stats/max_log_achievement_collect_wood": 1.5, "eval_stats/max_log_achievement_place_plant": 0.625, "eval_stats/max_log_achievement_place_table": 0.375, "eval_stats/max_log_achievement_wake_up": 2.375, "eval_stats/max_log_achievement_eat_cow": 1.0, "eval_stats/max_log_achievement_make_wood_sword": 2.0, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 7.3302001953125, "train/action_min": 0.0, "train/action_std": 4.888550758361816, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00032659099088050425, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -2.0526037216186523, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.9970703125, "train/cont_loss_mean": 0.6669867634773254, "train/cont_loss_std": 0.26520687341690063, "train/cont_neg_acc": 0.3333333432674408, "train/cont_neg_loss": 1.5049197673797607, "train/cont_pos_acc": 0.591576874256134, "train/cont_pos_loss": 0.6645246148109436, "train/cont_pred": 0.5316348075866699, "train/cont_rate": 0.9970703125, "train/dyn_loss_mean": 10.87511157989502, "train/dyn_loss_std": 0.5229759812355042, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 7.183383464813232, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 29482.91015625, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 3690.3876953125, "train/image_loss_std": 146.08734130859375, "train/model_loss_mean": 3703.120849609375, "train/model_loss_std": 145.97079467773438, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 37031208.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 2.7737810611724854, "train/policy_entropy_max": 2.7737810611724854, "train/policy_entropy_mean": 2.5709667205810547, "train/policy_entropy_min": 1.8983094692230225, "train/policy_entropy_std": 0.08706492930650711, "train/policy_logprob_mag": 5.664838790893555, "train/policy_logprob_max": -0.6335747838020325, "train/policy_logprob_mean": -2.5572144985198975, "train/policy_logprob_min": -5.664838790893555, "train/policy_logprob_std": 0.677849531173706, "train/policy_randomness_mag": 0.9790229797363281, "train/policy_randomness_max": 0.9790229797363281, "train/policy_randomness_mean": 0.9074385166168213, "train/policy_randomness_min": 0.6700199246406555, "train/policy_randomness_std": 0.030730096623301506, "train/post_ent_mag": 106.26691436767578, "train/post_ent_max": 106.26691436767578, "train/post_ent_mean": 105.62818145751953, "train/post_ent_min": 104.88150787353516, "train/post_ent_std": 0.24500803649425507, "train/prior_ent_mag": 106.3969955444336, "train/prior_ent_max": 106.3969955444336, "train/prior_ent_mean": 105.53196716308594, "train/prior_ent_min": 104.51580810546875, "train/prior_ent_std": 0.3121412992477417, "train/rep_loss_mean": 10.87511157989502, "train/rep_loss_std": 0.5229759812355042, "train/reward_avg": 0.00839843787252903, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 0.9999999403953552, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.541263580322266, "train/reward_pred": 0.0, "train/reward_rate": 0.0126953125, "train/params_agent/wm/model_opt": 181569923.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9464849.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.689244270324707, "report/cont_loss_std": 0.28497570753097534, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.658134937286377, "report/cont_pos_acc": 0.5592555999755859, "report/cont_pos_loss": 0.6893357038497925, "report/cont_pred": 0.5210942029953003, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 10.865865707397461, "report/dyn_loss_std": 0.48052728176116943, "report/image_loss_mean": 3697.63720703125, "report/image_loss_std": 150.81016540527344, "report/model_loss_mean": 3710.38720703125, "report/model_loss_std": 150.73440551757812, "report/post_ent_mag": 106.23313903808594, "report/post_ent_max": 106.23313903808594, "report/post_ent_mean": 105.62924194335938, "report/post_ent_min": 104.8705062866211, "report/post_ent_std": 0.2586594820022583, "report/prior_ent_mag": 106.45674133300781, "report/prior_ent_max": 106.45674133300781, "report/prior_ent_mean": 105.53876495361328, "report/prior_ent_min": 104.53294372558594, "report/prior_ent_std": 0.2954866886138916, "report/rep_loss_mean": 10.865865707397461, "report/rep_loss_std": 0.48052728176116943, "report/reward_avg": 0.00839843787252903, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.541263580322266, "report/reward_pred": 0.0, "report/reward_rate": 0.0126953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.6599055528640747, "eval/cont_loss_std": 0.26516884565353394, "eval/cont_neg_acc": 0.25, "eval/cont_neg_loss": 0.9366621971130371, "eval/cont_pos_acc": 0.6107842922210693, "eval/cont_pos_loss": 0.6588202714920044, "eval/cont_pred": 0.5348227024078369, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 10.944266319274902, "eval/dyn_loss_std": 0.478680819272995, "eval/image_loss_mean": 3651.56640625, "eval/image_loss_std": 164.3854522705078, "eval/model_loss_mean": 3664.333984375, "eval/model_loss_std": 164.2317657470703, "eval/post_ent_mag": 106.19123840332031, "eval/post_ent_max": 106.19123840332031, "eval/post_ent_mean": 105.56137084960938, "eval/post_ent_min": 104.97785949707031, "eval/post_ent_std": 0.24295341968536377, "eval/prior_ent_mag": 106.31730651855469, "eval/prior_ent_max": 106.31730651855469, "eval/prior_ent_mean": 105.51820373535156, "eval/prior_ent_min": 104.49566650390625, "eval/prior_ent_std": 0.2682751417160034, "eval/rep_loss_mean": 10.944266319274902, "eval/rep_loss_std": 0.478680819272995, "eval/reward_avg": 0.00917968712747097, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541263580322266, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0126953125, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.6547196748240894e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.64318002973284e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2984.0, "eval_replay/inserts": 2984.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 2.854870727170888e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0047640119280134e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 238.43572735786438, "timer/env.step_count": 196.0, "timer/env.step_total": 27.854180097579956, "timer/env.step_frac": 0.11682049668577588, "timer/env.step_avg": 0.14211316376316305, "timer/env.step_min": 0.022943496704101562, "timer/env.step_max": 11.671579837799072, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.12547636032104492, "timer/replay._sample_frac": 0.0005262481496018399, "timer/replay._sample_avg": 0.0011203246457236154, "timer/replay._sample_min": 0.00045037269592285156, "timer/replay._sample_max": 0.012595176696777344, "timer/agent.save_count": 1.0, "timer/agent.save_total": 9.467351198196411, "timer/agent.save_frac": 0.03970609313925096, "timer/agent.save_avg": 9.467351198196411, "timer/agent.save_min": 9.467351198196411, "timer/agent.save_max": 9.467351198196411, "timer/agent.policy_count": 242.0, "timer/agent.policy_total": 22.7784104347229, "timer/agent.policy_frac": 0.09553270681006269, "timer/agent.policy_avg": 0.09412566295340041, "timer/agent.policy_min": 0.010217428207397461, "timer/agent.policy_max": 15.696244478225708, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.409385681152344e-05, "timer/dataset_train_frac": 1.4298971546471521e-07, "timer/dataset_train_avg": 3.409385681152344e-05, "timer/dataset_train_min": 3.409385681152344e-05, "timer/dataset_train_max": 3.409385681152344e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 96.57599925994873, "timer/agent.train_frac": 0.40503996750033755, "timer/agent.train_avg": 96.57599925994873, "timer/agent.train_min": 96.57599925994873, "timer/agent.train_max": 96.57599925994873, "timer/agent.report_count": 2.0, "timer/agent.report_total": 25.82882523536682, "timer/agent.report_frac": 0.10832615364139934, "timer/agent.report_avg": 12.91441261768341, "timer/agent.report_min": 0.24547815322875977, "timer/agent.report_max": 25.58334708213806, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.981590270996094e-05, "timer/dataset_eval_frac": 1.6698798938886322e-07, "timer/dataset_eval_avg": 3.981590270996094e-05, "timer/dataset_eval_min": 3.981590270996094e-05, "timer/dataset_eval_max": 3.981590270996094e-05}
{"step": 2000, "time": 348.73895931243896, "episode/length": 68.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.927536231884058, "episode/intrinsic_return": 0.0}
{"step": 2432, "time": 365.2630133628845, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 2496, "time": 369.06517338752747, "episode/length": 184.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 2528, "time": 371.7974820137024, "episode/length": 169.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 2592, "time": 375.56572008132935, "episode/length": 152.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 2768, "time": 383.34256076812744, "episode/length": 190.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 2904, "time": 389.4592034816742, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 3424, "time": 409.3350827693939, "episode/length": 177.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 3592, "time": 416.6679675579071, "episode/length": 144.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 4112, "time": 436.5379343032837, "episode/length": 197.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 4136, "time": 438.79556941986084, "episode/length": 153.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 4144, "time": 440.8732523918152, "episode/length": 205.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 4248, "time": 445.85941457748413, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 4280, "time": 448.7352104187012, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 4584, "time": 460.61014771461487, "episode/length": 396.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9949622166246851, "episode/intrinsic_return": 0.0}
{"step": 5056, "time": 478.7339940071106, "episode/length": 182.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 5152, "time": 483.5384621620178, "episode/length": 215.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 5384, "time": 492.78093791007996, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 5528, "time": 499.50602293014526, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 5632, "time": 504.96167635917664, "episode/length": 168.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 5632, "time": 504.97091460227966, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 5712, "time": 511.0565867424011, "episode/length": 199.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 5816, "time": 516.0415120124817, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 5976, "time": 523.0770173072815, "episode/length": 42.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 6344, "time": 537.458580493927, "episode/length": 148.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 6368, "time": 540.1585502624512, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 6720, "time": 553.8048946857452, "episode/length": 166.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 562.674637556076, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 6968, "time": 565.4263696670532, "episode/length": 143.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 7224, "time": 575.9282386302948, "episode/length": 198.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 7272, "time": 579.2259395122528, "episode/length": 217.0, "episode/score": 0.09999999403953552, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 7488, "time": 588.5221116542816, "episode/length": 142.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 7504, "time": 590.7763941287994, "episode/length": 190.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 7704, "time": 598.8664040565491, "episode/length": 166.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 8128, "time": 615.0887122154236, "episode/length": 175.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 8432, "time": 628.4258263111115, "episode/length": 150.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 8616, "time": 636.0748720169067, "episode/length": 205.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 8816, "time": 644.724752664566, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 8880, "time": 648.7225289344788, "episode/length": 93.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9468085106382979, "episode/intrinsic_return": 0.0}
{"step": 9080, "time": 657.0229842662811, "episode/length": 196.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 9256, "time": 664.6087527275085, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 9504, "time": 674.7439641952515, "episode/length": 52.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9245283018867925, "episode/intrinsic_return": 0.0}
{"step": 9760, "time": 685.1843554973602, "episode/length": 352.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9971671388101983, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 714.6155188083649, "eval_episode/length": 79.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.925}
{"step": 10088, "time": 717.7675325870514, "eval_episode/length": 113.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.956140350877193}
{"step": 10088, "time": 721.359777212143, "eval_episode/length": 155.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 10088, "time": 723.356064081192, "eval_episode/length": 163.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 10088, "time": 725.5799670219421, "eval_episode/length": 179.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 10088, "time": 727.4678020477295, "eval_episode/length": 185.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 10088, "time": 731.402003288269, "eval_episode/length": 229.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 10088, "time": 733.4297926425934, "eval_episode/length": 239.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 10160, "time": 736.1522681713104, "episode/length": 192.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 10264, "time": 741.1732807159424, "episode/length": 180.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 10376, "time": 746.6269090175629, "episode/length": 242.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 10496, "time": 752.5385568141937, "episode/length": 402.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9776674937965261, "episode/intrinsic_return": 0.0}
{"step": 10568, "time": 756.5061941146851, "episode/length": 210.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 10800, "time": 766.5389833450317, "episode/length": 192.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 10824, "time": 768.771683216095, "episode/length": 164.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 10896, "time": 773.1975545883179, "episode/length": 49.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 11032, "time": 779.2619409561157, "episode/length": 95.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9479166666666666, "episode/intrinsic_return": 0.0}
{"step": 11408, "time": 793.9447226524353, "episode/length": 205.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 11784, "time": 808.3126487731934, "episode/length": 46.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8936170212765957, "episode/intrinsic_return": 0.0}
{"step": 11800, "time": 810.4755392074585, "episode/length": 204.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 11936, "time": 817.0214660167694, "episode/length": 141.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 12016, "time": 821.5529296398163, "episode/length": 180.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 12080, "time": 825.8490028381348, "episode/length": 212.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 12096, "time": 828.3055708408356, "episode/length": 158.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 12808, "time": 853.9922668933868, "episode/length": 238.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9874476987447699, "episode/intrinsic_return": 0.0}
{"step": 12904, "time": 859.0344622135162, "episode/length": 137.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 12976, "time": 863.2687385082245, "episode/length": 242.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 13040, "time": 867.0607089996338, "episode/length": 117.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9576271186440678, "episode/intrinsic_return": 0.0}
{"step": 13216, "time": 874.7008776664734, "episode/length": 159.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 13272, "time": 878.1465690135956, "episode/length": 156.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 13440, "time": 885.7830605506897, "episode/length": 66.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9253731343283582, "episode/intrinsic_return": 0.0}
{"step": 13472, "time": 888.6141767501831, "episode/length": 173.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 13664, "time": 896.7748563289642, "episode/length": 234.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9872340425531915, "episode/intrinsic_return": 0.0}
{"step": 14040, "time": 911.035261631012, "episode/length": 153.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 14272, "time": 920.9313607215881, "episode/length": 161.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 14472, "time": 929.1356060504913, "episode/length": 156.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 14528, "time": 932.9559288024902, "episode/length": 156.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 14592, "time": 936.8218939304352, "episode/length": 193.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 14752, "time": 943.9668598175049, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 15056, "time": 956.0936727523804, "episode/length": 173.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 15072, "time": 958.2631299495697, "episode/length": 199.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 15344, "time": 969.2514538764954, "episode/length": 162.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 15608, "time": 979.7816786766052, "episode/length": 141.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 15776, "time": 987.3635127544403, "episode/length": 89.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 16136, "time": 1001.0648446083069, "episode/length": 232.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 16216, "time": 1005.5271880626678, "episode/length": 202.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 16344, "time": 1011.6778333187103, "episode/length": 226.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 16440, "time": 1017.9497952461243, "episode/length": 210.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 16680, "time": 1027.8440790176392, "episode/length": 200.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 17032, "time": 1041.7082738876343, "episode/length": 210.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 17088, "time": 1045.5028038024902, "episode/length": 118.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9663865546218487, "episode/intrinsic_return": 0.0}
{"step": 17304, "time": 1054.366596698761, "episode/length": 211.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 17632, "time": 1067.5530660152435, "episode/length": 231.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 17656, "time": 1069.7647459506989, "episode/length": 121.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 17896, "time": 1079.7330396175385, "episode/length": 193.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 17928, "time": 1082.4456667900085, "episode/length": 213.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 18256, "time": 1095.4923448562622, "episode/length": 226.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.986784140969163, "episode/intrinsic_return": 0.0}
{"step": 18744, "time": 1113.8765037059784, "episode/length": 213.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 19064, "time": 1126.6218073368073, "episode/length": 246.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 19096, "time": 1129.4540514945984, "episode/length": 182.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 19224, "time": 1135.4097156524658, "episode/length": 161.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 19272, "time": 1138.6778690814972, "episode/length": 201.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 19544, "time": 1149.621942281723, "episode/length": 205.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 19568, "time": 1152.231345653534, "episode/length": 163.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 20000, "time": 1168.486121416092, "episode/length": 156.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 20016, "time": 1170.690987110138, "episode/length": 338.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 1194.7311046123505, "eval_episode/length": 152.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 20072, "time": 1196.787903547287, "eval_episode/length": 153.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 20072, "time": 1198.9325556755066, "eval_episode/length": 155.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 20072, "time": 1201.8903098106384, "eval_episode/length": 171.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 20072, "time": 1204.0950665473938, "eval_episode/length": 175.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 20072, "time": 1207.3926248550415, "eval_episode/length": 210.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.981042654028436}
{"step": 20072, "time": 1209.5267441272736, "eval_episode/length": 43.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9090909090909091}
{"step": 20072, "time": 1212.1691966056824, "eval_episode/length": 240.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9875518672199171}
{"step": 20456, "time": 1225.3652369976044, "episode/length": 173.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 20504, "time": 1228.6327936649323, "episode/length": 159.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 20712, "time": 1237.3262722492218, "episode/length": 179.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 20736, "time": 1240.1347737312317, "episode/length": 204.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 20936, "time": 1248.4493641853333, "episode/length": 173.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 21256, "time": 1260.9439418315887, "episode/length": 210.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 21312, "time": 1264.7870495319366, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 21320, "time": 1266.4305124282837, "episode/length": 162.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 21768, "time": 1283.539088010788, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 21864, "time": 1288.4903099536896, "episode/length": 169.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 21936, "time": 1292.6735634803772, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 21952, "time": 1294.8502507209778, "episode/length": 151.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 22280, "time": 1307.4075474739075, "episode/length": 167.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 22281, "time": 1310.1037237644196, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.760308317435804, "train/action_min": 0.0, "train/action_std": 2.236481600953627, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013815338960704358, "train/actor_opt_grad_steps": 650.0, "train/actor_opt_loss": 177.67631798381953, "train/adv_mag": 2.231944011708418, "train/adv_max": 2.2288526585650477, "train/adv_mean": 0.028258199206338618, "train/adv_min": -0.385297296602029, "train/adv_std": 0.17069158206969975, "train/cont_avg": 0.994640261627907, "train/cont_loss_mean": 0.028267361512479855, "train/cont_loss_std": 0.26437348935955257, "train/cont_neg_acc": 0.045017451567705286, "train/cont_neg_loss": 3.497919991958973, "train/cont_pos_acc": 0.9969340470410133, "train/cont_pos_loss": 0.010042262153497846, "train/cont_pred": 0.9911912037420643, "train/cont_rate": 0.994640261627907, "train/dyn_loss_mean": 5.016211910765301, "train/dyn_loss_std": 7.880444479774135, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.517704737278843, "train/extr_critic_critic_opt_grad_steps": 650.0, "train/extr_critic_critic_opt_loss": 21960.147195978683, "train/extr_critic_mag": 0.31040280364280526, "train/extr_critic_max": 0.31040280179459917, "train/extr_critic_mean": 0.09091170008969762, "train/extr_critic_min": -0.01644737221473871, "train/extr_critic_std": 0.0764745171456571, "train/extr_return_normed_mag": 2.5642904432494076, "train/extr_return_normed_max": 2.5642904432494076, "train/extr_return_normed_mean": 0.19452015888541505, "train/extr_return_normed_min": -0.2430183181879625, "train/extr_return_normed_std": 0.21507735803042893, "train/extr_return_rate": 0.03745306644258414, "train/extr_return_raw_mag": 2.505901351249813, "train/extr_return_raw_max": 2.505901351249813, "train/extr_return_raw_mean": 0.11923362978809882, "train/extr_return_raw_min": -0.3211643868079725, "train/extr_return_raw_std": 0.21668044647315604, "train/extr_reward_mag": 0.5629399441933447, "train/extr_reward_max": 0.5628831340361011, "train/extr_reward_mean": 0.007910871647917412, "train/extr_reward_min": -0.07113063520239304, "train/extr_reward_std": 0.03998020727664947, "train/image_loss_mean": 95.39815360076668, "train/image_loss_std": 52.71857518927995, "train/model_loss_mean": 98.76779081655103, "train/model_loss_std": 54.24035566906596, "train/model_opt_grad_norm": 439.7649203160012, "train/model_opt_grad_steps": 641.0, "train/model_opt_loss": 2053.3884480794272, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 23.921996124031008, "train/policy_entropy_mag": 2.0579561327779015, "train/policy_entropy_max": 2.0579561327779015, "train/policy_entropy_mean": 0.9328122642613197, "train/policy_entropy_min": 0.6541621560274169, "train/policy_entropy_std": 0.22840220330990563, "train/policy_logprob_mag": 6.773564213006071, "train/policy_logprob_max": -0.30188034411317616, "train/policy_logprob_mean": -0.932728146109008, "train/policy_logprob_min": -6.773564213006071, "train/policy_logprob_std": 0.8871377607186636, "train/policy_randomness_mag": 0.7263682028350904, "train/policy_randomness_max": 0.7263682028350904, "train/policy_randomness_mean": 0.32924179083039595, "train/policy_randomness_min": 0.23089053351865257, "train/policy_randomness_std": 0.08061595426605249, "train/post_ent_mag": 53.534887890483056, "train/post_ent_max": 53.534887890483056, "train/post_ent_mean": 33.28203706963118, "train/post_ent_min": 16.779639343882717, "train/post_ent_std": 6.947101412933002, "train/prior_ent_mag": 57.299041925474654, "train/prior_ent_max": 57.299041925474654, "train/prior_ent_mean": 38.88108972061512, "train/prior_ent_min": 20.746365406716517, "train/prior_ent_std": 6.619535938598389, "train/rep_loss_mean": 5.016211910765301, "train/rep_loss_std": 7.880444479774135, "train/reward_avg": 0.007673207304509024, "train/reward_loss_mean": 0.33163943314968153, "train/reward_loss_std": 0.6767438968847481, "train/reward_max_data": 1.0170542676319447, "train/reward_max_pred": 0.6790165734845538, "train/reward_neg_acc": 0.9970545574676158, "train/reward_neg_loss": 0.2938858670897262, "train/reward_pos_acc": 0.45034992218364117, "train/reward_pos_loss": 3.1543190959812133, "train/reward_pred": 0.005277246292752697, "train/reward_rate": 0.012566618217054263, "train_stats/sum_log_reward": 0.8807017323479318, "train_stats/max_log_achievement_collect_drink": 2.9473684210526314, "train_stats/max_log_achievement_collect_sapling": 10.18421052631579, "train_stats/max_log_achievement_collect_wood": 0.24561403508771928, "train_stats/max_log_achievement_eat_cow": 0.043859649122807015, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.3333333333333333, "train_stats/max_log_achievement_place_table": 0.06140350877192982, "train_stats/max_log_achievement_wake_up": 0.43859649122807015, "train_stats/mean_log_entropy": 0.9519646049460821, "eval_stats/sum_log_reward": 0.6624999758787453, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 12.9375, "eval_stats/max_log_achievement_collect_wood": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.125, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.19718309859154928, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.021178778260946274, "report/cont_loss_std": 0.2575451135635376, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.512937307357788, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004045520909130573, "report/cont_pred": 0.9958620071411133, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 5.919042587280273, "report/dyn_loss_std": 5.348754405975342, "report/image_loss_mean": 23.673168182373047, "report/image_loss_std": 19.437847137451172, "report/model_loss_mean": 27.356891632080078, "report/model_loss_std": 20.805421829223633, "report/post_ent_mag": 47.24793243408203, "report/post_ent_max": 47.24793243408203, "report/post_ent_mean": 31.006160736083984, "report/post_ent_min": 15.22597885131836, "report/post_ent_std": 4.390288352966309, "report/prior_ent_mag": 53.28871154785156, "report/prior_ent_max": 53.28871154785156, "report/prior_ent_mean": 38.46709442138672, "report/prior_ent_min": 19.887672424316406, "report/prior_ent_std": 4.99868631362915, "report/rep_loss_mean": 5.919042587280273, "report/rep_loss_std": 5.348754405975342, "report/reward_avg": 0.00595703162252903, "report/reward_loss_mean": 0.11111985146999359, "report/reward_loss_std": 0.48829013109207153, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.989770770072937, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.09732301533222198, "report/reward_pos_acc": 0.9000000357627869, "report/reward_pos_loss": 1.510118842124939, "report/reward_pred": 0.004789645317941904, "report/reward_rate": 0.009765625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0524006113409996, "eval/cont_loss_std": 0.686484158039093, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.735308647155762, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001224333536811173, "eval/cont_pred": 0.9988231658935547, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 8.530722618103027, "eval/dyn_loss_std": 7.545868873596191, "eval/image_loss_mean": 47.850364685058594, "eval/image_loss_std": 47.21134948730469, "eval/model_loss_mean": 53.220943450927734, "eval/model_loss_std": 49.1303596496582, "eval/post_ent_mag": 43.09435272216797, "eval/post_ent_max": 43.09435272216797, "eval/post_ent_mean": 30.327409744262695, "eval/post_ent_min": 14.06804084777832, "eval/post_ent_std": 5.576062202453613, "eval/prior_ent_mag": 56.282135009765625, "eval/prior_ent_max": 56.282135009765625, "eval/prior_ent_mean": 36.582035064697266, "eval/prior_ent_min": 18.87750244140625, "eval/prior_ent_std": 6.928088665008545, "eval/rep_loss_mean": 8.530722618103027, "eval/rep_loss_std": 7.545868873596191, "eval/reward_avg": 0.01357421837747097, "eval/reward_loss_mean": 0.1997460573911667, "eval/reward_loss_std": 0.8928667306900024, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9908844232559204, "eval/reward_neg_acc": 0.9970179796218872, "eval/reward_neg_loss": 0.14440351724624634, "eval/reward_pos_acc": 0.5555555820465088, "eval/reward_pos_loss": 3.2927803993225098, "eval/reward_pred": 0.008693192154169083, "eval/reward_rate": 0.017578125, "replay/size": 21777.0, "replay/inserts": 20720.0, "replay/samples": 20720.0, "replay/insert_wait_avg": 1.5332662000619306e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.029388324634449e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6832.0, "eval_replay/inserts": 3848.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.4734491241201294e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1473894119262695e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 976.3600480556488, "timer/env.step_count": 2590.0, "timer/env.step_total": 260.591933965683, "timer/env.step_frac": 0.2669014719361297, "timer/env.step_avg": 0.10061464631879652, "timer/env.step_min": 0.023823261260986328, "timer/env.step_max": 3.3586249351501465, "timer/replay._sample_count": 20720.0, "timer/replay._sample_total": 11.75196886062622, "timer/replay._sample_frac": 0.012036511411983137, "timer/replay._sample_avg": 0.0005671799643159373, "timer/replay._sample_min": 0.0003783702850341797, "timer/replay._sample_max": 0.009750127792358398, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3071.0, "timer/agent.policy_total": 55.56684350967407, "timer/agent.policy_frac": 0.05691224627670035, "timer/agent.policy_avg": 0.018094055196898103, "timer/agent.policy_min": 0.010144710540771484, "timer/agent.policy_max": 0.09598326683044434, "timer/dataset_train_count": 1295.0, "timer/dataset_train_total": 0.15962815284729004, "timer/dataset_train_frac": 0.00016349312240415622, "timer/dataset_train_avg": 0.00012326498289366025, "timer/dataset_train_min": 8.702278137207031e-05, "timer/dataset_train_max": 0.0010807514190673828, "timer/agent.train_count": 1295.0, "timer/agent.train_total": 588.9995541572571, "timer/agent.train_frac": 0.603260605890427, "timer/agent.train_avg": 0.45482591054614446, "timer/agent.train_min": 0.4407777786254883, "timer/agent.train_max": 1.3557484149932861, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.483217716217041, "timer/agent.report_frac": 0.0004949175431536087, "timer/agent.report_avg": 0.2416088581085205, "timer/agent.report_min": 0.23201870918273926, "timer/agent.report_max": 0.25119900703430176, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.19890535509955e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 21.221121230180174}
{"step": 22640, "time": 1322.439789533615, "episode/length": 87.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 22656, "time": 1324.6793444156647, "episode/length": 167.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 22848, "time": 1332.8319220542908, "episode/length": 198.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 23016, "time": 1340.0216348171234, "episode/length": 155.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 23152, "time": 1346.6964514255524, "episode/length": 228.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 23224, "time": 1350.567251443863, "episode/length": 169.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 23304, "time": 1354.8130209445953, "episode/length": 168.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 23536, "time": 1364.507008075714, "episode/length": 156.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 24048, "time": 1383.6305243968964, "episode/length": 175.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 24176, "time": 1389.648715019226, "episode/length": 165.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 24456, "time": 1400.6320042610168, "episode/length": 162.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 24488, "time": 1403.3740799427032, "episode/length": 228.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9868995633187773, "episode/intrinsic_return": 0.0}
{"step": 24512, "time": 1406.038340806961, "episode/length": 186.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 24576, "time": 1410.005226135254, "episode/length": 168.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 24968, "time": 1425.7798991203308, "episode/length": 178.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 25552, "time": 1447.542332649231, "episode/length": 171.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 25688, "time": 1453.5498533248901, "episode/length": 204.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 25720, "time": 1456.5238592624664, "episode/length": 301.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 25768, "time": 1459.7534897327423, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 25912, "time": 1466.2673728466034, "episode/length": 166.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 25992, "time": 1470.5029623508453, "episode/length": 184.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 26136, "time": 1477.102963924408, "episode/length": 145.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 26352, "time": 1486.5003983974457, "episode/length": 236.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 26936, "time": 1507.610286474228, "episode/length": 155.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 26976, "time": 1510.8498587608337, "episode/length": 156.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 27008, "time": 1513.5883440971375, "episode/length": 181.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 27208, "time": 1521.7680706977844, "episode/length": 133.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9626865671641791, "episode/intrinsic_return": 0.0}
{"step": 27216, "time": 1523.9737865924835, "episode/length": 152.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 27224, "time": 1525.7209842205048, "episode/length": 181.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 27816, "time": 1547.4282298088074, "episode/length": 182.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 28144, "time": 1560.3694887161255, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 28256, "time": 1565.862862586975, "episode/length": 159.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 28280, "time": 1568.0728211402893, "episode/length": 132.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9699248120300752, "episode/intrinsic_return": 0.0}
{"step": 28616, "time": 1581.1533861160278, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 28672, "time": 1584.841590166092, "episode/length": 65.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 28904, "time": 1594.137577533722, "episode/length": 211.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 29000, "time": 1599.0156812667847, "episode/length": 147.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 29024, "time": 1601.6735854148865, "episode/length": 388.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9948586118251928, "episode/intrinsic_return": 0.0}
{"step": 29024, "time": 1601.6841487884521, "episode/length": 224.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 29312, "time": 1615.0548448562622, "episode/length": 35.0, "episode/score": -0.9000000283122063, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 29488, "time": 1622.5169522762299, "episode/length": 153.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 29912, "time": 1638.1956861019135, "episode/length": 161.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 29912, "time": 1638.2049753665924, "episode/length": 154.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 29912, "time": 1638.213100194931, "episode/length": 203.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1669.929889202118, "eval_episode/length": 143.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9652777777777778}
{"step": 30056, "time": 1671.6526656150818, "eval_episode/length": 145.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 30056, "time": 1671.6594970226288, "eval_episode/length": 145.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 30056, "time": 1675.1529421806335, "eval_episode/length": 146.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 30056, "time": 1677.0342984199524, "eval_episode/length": 152.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 30056, "time": 1678.628203868866, "eval_episode/length": 153.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 30056, "time": 1681.9626219272614, "eval_episode/length": 187.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 30056, "time": 1684.162588596344, "eval_episode/length": 200.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9800995024875622}
{"step": 30128, "time": 1686.8403499126434, "episode/length": 152.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 30200, "time": 1690.8848624229431, "episode/length": 149.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 30256, "time": 1694.6376903057098, "episode/length": 153.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 30384, "time": 1700.7469775676727, "episode/length": 58.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9322033898305084, "episode/intrinsic_return": 0.0}
{"step": 30832, "time": 1717.7341887950897, "episode/length": 167.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 30848, "time": 1719.892805814743, "episode/length": 191.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 31216, "time": 1734.8757140636444, "episode/length": 162.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 31336, "time": 1740.3498899936676, "episode/length": 177.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 31536, "time": 1749.5233507156372, "episode/length": 159.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 31744, "time": 1758.4357204437256, "episode/length": 201.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 31888, "time": 1764.8904087543488, "episode/length": 129.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 31960, "time": 1768.831195116043, "episode/length": 219.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 32000, "time": 1772.0646755695343, "episode/length": 201.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 32064, "time": 1775.9188258647919, "episode/length": 153.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 32704, "time": 1799.2234752178192, "episode/length": 185.0, "episode/score": 1.100000023841858, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 32712, "time": 1800.7866206169128, "episode/length": 171.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 32984, "time": 1812.8187766075134, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 33064, "time": 1817.2946631908417, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 33184, "time": 1823.163565158844, "episode/length": 161.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 33304, "time": 1828.6061217784882, "episode/length": 167.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 33368, "time": 1832.459021806717, "episode/length": 162.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 33768, "time": 1847.6495280265808, "episode/length": 97.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9489795918367347, "episode/intrinsic_return": 0.0}
{"step": 34264, "time": 1866.0250399112701, "episode/length": 282.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9929328621908127, "episode/intrinsic_return": 0.0}
{"step": 34400, "time": 1872.6171374320984, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 34488, "time": 1877.1793096065521, "episode/length": 222.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 34512, "time": 1879.7906193733215, "episode/length": 224.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 34544, "time": 1882.61598777771, "episode/length": 96.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9484536082474226, "episode/intrinsic_return": 0.0}
{"step": 34616, "time": 1886.540052652359, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 34744, "time": 1892.4345955848694, "episode/length": 194.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 35384, "time": 1915.9234595298767, "episode/length": 259.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9884615384615385, "episode/intrinsic_return": 0.0}
{"step": 35616, "time": 1925.5546562671661, "episode/length": 151.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 35760, "time": 1932.1087164878845, "episode/length": 158.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 35800, "time": 1934.8248281478882, "episode/length": 51.0, "episode/score": 0.10000002384185791, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 35816, "time": 1937.2302916049957, "episode/length": 193.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 35856, "time": 1940.6165518760681, "episode/length": 163.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 35920, "time": 1944.4985666275024, "episode/length": 162.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 35992, "time": 1948.3130373954773, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 36224, "time": 1958.0700950622559, "episode/length": 184.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 36344, "time": 1963.6177916526794, "episode/length": 65.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9242424242424242, "episode/intrinsic_return": 0.0}
{"step": 36984, "time": 1987.053956270218, "episode/length": 132.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9548872180451128, "episode/intrinsic_return": 0.0}
{"step": 37008, "time": 1989.6297047138214, "episode/length": 173.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 37056, "time": 1992.8638424873352, "episode/length": 161.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 37352, "time": 2004.7560527324677, "episode/length": 169.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 37376, "time": 2007.4853012561798, "episode/length": 143.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 37384, "time": 2009.2282440662384, "episode/length": 190.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 37576, "time": 2017.347246170044, "episode/length": 153.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 38296, "time": 2043.358036518097, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 38448, "time": 2050.294882774353, "episode/length": 173.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 38504, "time": 2053.5491087436676, "episode/length": 140.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 38584, "time": 2057.9040553569794, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 38840, "time": 2068.2998399734497, "episode/length": 67.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 38872, "time": 2070.9476161003113, "episode/length": 232.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 38896, "time": 2073.5723934173584, "episode/length": 164.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 38952, "time": 2076.8857460021973, "episode/length": 195.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 39248, "time": 2088.864651441574, "episode/length": 430.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 2134.353436231613, "eval_episode/length": 82.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9397590361445783}
{"step": 40040, "time": 2139.049575805664, "eval_episode/length": 151.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.993421052631579}
{"step": 40040, "time": 2140.842983484268, "eval_episode/length": 156.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9745222929936306}
{"step": 40040, "time": 2142.9625058174133, "eval_episode/length": 168.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 40040, "time": 2144.75248503685, "eval_episode/length": 173.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 40040, "time": 2147.034648656845, "eval_episode/length": 183.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 40040, "time": 2151.2553679943085, "eval_episode/length": 155.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 40040, "time": 2153.8576300144196, "eval_episode/length": 260.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9808429118773946}
{"step": 40040, "time": 2153.864047050476, "eval_episode/length": 103.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9519230769230769}
{"step": 40192, "time": 2159.2277414798737, "episode/length": 217.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 40216, "time": 2161.3644876480103, "episode/length": 171.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 40248, "time": 2164.0719769001007, "episode/length": 161.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 40392, "time": 2170.5486323833466, "episode/length": 186.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 40632, "time": 2180.4060859680176, "episode/length": 219.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 40640, "time": 2182.438278913498, "episode/length": 266.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 40688, "time": 2185.6393167972565, "episode/length": 262.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 40944, "time": 2195.994941473007, "episode/length": 68.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9420289855072463, "episode/intrinsic_return": 0.0}
{"step": 41136, "time": 2205.4347879886627, "episode/length": 117.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 41328, "time": 2213.5908052921295, "episode/length": 138.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 41472, "time": 2219.9117505550385, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 41872, "time": 2235.153255224228, "episode/length": 327.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 42016, "time": 2241.7956149578094, "episode/length": 85.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9418604651162791, "episode/intrinsic_return": 0.0}
{"step": 42184, "time": 2248.9487960338593, "episode/length": 186.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 42232, "time": 2252.2782905101776, "episode/length": 198.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 42280, "time": 2255.493733882904, "episode/length": 205.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 42400, "time": 2261.378412246704, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 42512, "time": 2266.853368997574, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 42784, "time": 2277.718273162842, "episode/length": 163.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 43128, "time": 2291.2673671245575, "episode/length": 90.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9560439560439561, "episode/intrinsic_return": 0.0}
{"step": 43296, "time": 2298.929146051407, "episode/length": 159.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 43440, "time": 2305.421666622162, "episode/length": 195.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 43440, "time": 2305.43009018898, "episode/length": 156.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 43465, "time": 2310.490769147873, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 7.018941090519267, "train/action_min": 0.0, "train/action_std": 2.6993322054246316, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03527331695877912, "train/actor_opt_grad_steps": 1960.0, "train/actor_opt_loss": 25.016954576610622, "train/adv_mag": 2.021883153377619, "train/adv_max": 2.019945131208664, "train/adv_mean": 0.029120931786544537, "train/adv_min": -0.587388835455242, "train/adv_std": 0.17228187609435922, "train/cont_avg": 0.9944636983082706, "train/cont_loss_mean": 0.0061609687584274426, "train/cont_loss_std": 0.08496661220840879, "train/cont_neg_acc": 0.7103443208493685, "train/cont_neg_loss": 0.7800825958466683, "train/cont_pos_acc": 0.9996602875845773, "train/cont_pos_loss": 0.001994998828984918, "train/cont_pred": 0.9944556848447126, "train/cont_rate": 0.9944636983082706, "train/dyn_loss_mean": 6.506140916867364, "train/dyn_loss_std": 6.0808488515982955, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.6102427593747477, "train/extr_critic_critic_opt_grad_steps": 1960.0, "train/extr_critic_critic_opt_loss": 17703.406683211935, "train/extr_critic_mag": 1.3525214975041555, "train/extr_critic_max": 1.3525214975041555, "train/extr_critic_mean": 0.3992290111622752, "train/extr_critic_min": -0.3906507079762624, "train/extr_critic_std": 0.5555586169536849, "train/extr_return_normed_mag": 2.7671394760447336, "train/extr_return_normed_max": 2.7671394760447336, "train/extr_return_normed_mean": 0.43616881294358045, "train/extr_return_normed_min": -0.317095099115058, "train/extr_return_normed_std": 0.37463050643752394, "train/extr_return_rate": 0.35465961701719834, "train/extr_return_raw_mag": 4.6470899725318855, "train/extr_return_raw_max": 4.6470899725318855, "train/extr_return_raw_mean": 0.45039007323969127, "train/extr_return_raw_min": -0.9185610816891032, "train/extr_return_raw_std": 0.6966135766273155, "train/extr_reward_mag": 0.9895016833355552, "train/extr_reward_max": 0.9895016833355552, "train/extr_reward_mean": 0.01592228049237309, "train/extr_reward_min": -0.33762932092623604, "train/extr_reward_std": 0.09134230968591414, "train/image_loss_mean": 18.953175738341827, "train/image_loss_std": 18.3083366809931, "train/model_loss_mean": 22.942062736453867, "train/model_loss_std": 20.072273756328382, "train/model_opt_grad_norm": 142.08658278615852, "train/model_opt_grad_steps": 1951.0, "train/model_opt_loss": 1318.4171105865248, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 56.97838345864662, "train/policy_entropy_mag": 1.9868185296094507, "train/policy_entropy_max": 1.9868185296094507, "train/policy_entropy_mean": 0.28814815931526344, "train/policy_entropy_min": 0.07943986003336154, "train/policy_entropy_std": 0.31186559628275107, "train/policy_logprob_mag": 7.438096064373963, "train/policy_logprob_max": -0.00946505473492513, "train/policy_logprob_mean": -0.2878633172328311, "train/policy_logprob_min": -7.438096064373963, "train/policy_logprob_std": 0.9221323621004147, "train/policy_randomness_mag": 0.7012597537578497, "train/policy_randomness_max": 0.7012597537578497, "train/policy_randomness_mean": 0.1017036545545535, "train/policy_randomness_min": 0.028038784455423963, "train/policy_randomness_std": 0.11007486981920954, "train/post_ent_mag": 45.08285370446686, "train/post_ent_max": 45.08285370446686, "train/post_ent_mean": 31.999360306818684, "train/post_ent_min": 15.263768934665766, "train/post_ent_std": 4.200003849832635, "train/prior_ent_mag": 54.561877429933475, "train/prior_ent_max": 54.561877429933475, "train/prior_ent_mean": 38.676787584347835, "train/prior_ent_min": 20.25418092254409, "train/prior_ent_std": 4.982738276173298, "train/rep_loss_mean": 6.506140916867364, "train/rep_loss_std": 6.0808488515982955, "train/reward_avg": 0.006462934593708583, "train/reward_loss_mean": 0.07904158529818506, "train/reward_loss_std": 0.38449023159823026, "train/reward_max_data": 1.0090225585421224, "train/reward_max_pred": 0.9912144142882269, "train/reward_neg_acc": 0.9956735256022977, "train/reward_neg_loss": 0.06299753481508198, "train/reward_pos_acc": 0.8480182738232434, "train/reward_pos_loss": 1.4553198267642717, "train/reward_pred": 0.006079186873573502, "train/reward_rate": 0.011439732142857142, "train_stats/sum_log_reward": 1.7393442113868525, "train_stats/max_log_achievement_collect_drink": 18.92622950819672, "train_stats/max_log_achievement_collect_sapling": 2.319672131147541, "train_stats/max_log_achievement_collect_wood": 0.1721311475409836, "train_stats/max_log_achievement_defeat_zombie": 0.09016393442622951, "train_stats/max_log_achievement_eat_cow": 0.09016393442622951, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.3114754098360655, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 1.180327868852459, "train_stats/mean_log_entropy": 0.3136887590660424, "eval_stats/sum_log_reward": 2.39411760077757, "eval_stats/max_log_achievement_collect_drink": 9.058823529411764, "eval_stats/max_log_achievement_collect_sapling": 2.5294117647058822, "eval_stats/max_log_achievement_collect_wood": 0.47058823529411764, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.11764705882352941, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.9411764705882353, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.588235294117647, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_defeat_skeleton": 0.013888888888888888, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "report/cont_avg": 0.98828125, "report/cont_loss_mean": 0.0010654764482751489, "report/cont_loss_std": 0.02093401923775673, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0852886438369751, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.678278441540897e-05, "report/cont_pred": 0.9890331029891968, "report/cont_rate": 0.98828125, "report/dyn_loss_mean": 8.245957374572754, "report/dyn_loss_std": 7.241949558258057, "report/image_loss_mean": 24.653013229370117, "report/image_loss_std": 20.57334327697754, "report/model_loss_mean": 29.670352935791016, "report/model_loss_std": 22.70398712158203, "report/post_ent_mag": 45.47686004638672, "report/post_ent_max": 45.47686004638672, "report/post_ent_mean": 33.065677642822266, "report/post_ent_min": 21.028594970703125, "report/post_ent_std": 3.906359910964966, "report/prior_ent_mag": 55.917503356933594, "report/prior_ent_max": 55.917503356933594, "report/prior_ent_mean": 41.190773010253906, "report/prior_ent_min": 26.78907012939453, "report/prior_ent_std": 5.211143970489502, "report/rep_loss_mean": 8.245957374572754, "report/rep_loss_std": 7.241949558258057, "report/reward_avg": 0.0072265625931322575, "report/reward_loss_mean": 0.06870036572217941, "report/reward_loss_std": 0.3075011968612671, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 0.9959729909896851, "report/reward_neg_acc": 0.9940416812896729, "report/reward_neg_loss": 0.04691708832979202, "report/reward_pos_acc": 0.9411764740943909, "report/reward_pos_loss": 1.359039306640625, "report/reward_pred": 0.005714233964681625, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0008945178706198931, "eval/cont_loss_std": 0.014816949144005775, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.08354692161083221, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0005703908391296864, "eval/cont_pred": 0.9958718419075012, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 11.892999649047852, "eval/dyn_loss_std": 9.13386058807373, "eval/image_loss_mean": 50.6960334777832, "eval/image_loss_std": 56.286285400390625, "eval/model_loss_mean": 58.00190734863281, "eval/model_loss_std": 57.92882537841797, "eval/post_ent_mag": 43.14086151123047, "eval/post_ent_max": 43.14086151123047, "eval/post_ent_mean": 31.162677764892578, "eval/post_ent_min": 15.941869735717773, "eval/post_ent_std": 4.949674129486084, "eval/prior_ent_mag": 62.096221923828125, "eval/prior_ent_max": 62.096221923828125, "eval/prior_ent_mean": 38.82257843017578, "eval/prior_ent_min": 16.030826568603516, "eval/prior_ent_std": 8.067702293395996, "eval/rep_loss_mean": 11.892999649047852, "eval/rep_loss_std": 9.13386058807373, "eval/reward_avg": 0.015332031063735485, "eval/reward_loss_mean": 0.16917824745178223, "eval/reward_loss_std": 0.9729840159416199, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9987362623214722, "eval/reward_neg_acc": 0.9990040063858032, "eval/reward_neg_loss": 0.0980185717344284, "eval/reward_pos_acc": 0.5, "eval/reward_pos_loss": 3.74139404296875, "eval/reward_pred": 0.0032158829271793365, "eval/reward_rate": 0.01953125, "replay/size": 42961.0, "replay/inserts": 21184.0, "replay/samples": 21184.0, "replay/insert_wait_avg": 1.4641066152163503e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.897004621626748e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10528.0, "eval_replay/inserts": 3696.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3613597655193115e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.519918441772461e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3805541992188, "timer/env.step_count": 2648.0, "timer/env.step_total": 276.3862090110779, "timer/env.step_frac": 0.276281069090071, "timer/env.step_avg": 0.10437545657518046, "timer/env.step_min": 0.02326655387878418, "timer/env.step_max": 5.509887456893921, "timer/replay._sample_count": 21184.0, "timer/replay._sample_total": 11.446813344955444, "timer/replay._sample_frac": 0.01144245886918339, "timer/replay._sample_avg": 0.0005403518384136822, "timer/replay._sample_min": 0.0004029273986816406, "timer/replay._sample_max": 0.00897979736328125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3110.0, "timer/agent.policy_total": 55.481937408447266, "timer/agent.policy_frac": 0.05546083155610643, "timer/agent.policy_avg": 0.017839851256735456, "timer/agent.policy_min": 0.009569406509399414, "timer/agent.policy_max": 0.12407898902893066, "timer/dataset_train_count": 1324.0, "timer/dataset_train_total": 0.16024446487426758, "timer/dataset_train_frac": 0.00016018350636827356, "timer/dataset_train_avg": 0.00012103056259385769, "timer/dataset_train_min": 0.00010418891906738281, "timer/dataset_train_max": 0.0010936260223388672, "timer/agent.train_count": 1324.0, "timer/agent.train_total": 599.783772945404, "timer/agent.train_frac": 0.5995556095405282, "timer/agent.train_avg": 0.4530088919527221, "timer/agent.train_min": 0.4389331340789795, "timer/agent.train_max": 1.3661751747131348, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48168087005615234, "timer/agent.report_frac": 0.00048149763410957805, "timer/agent.report_avg": 0.24084043502807617, "timer/agent.report_min": 0.23130226135253906, "timer/agent.report_max": 0.2503786087036133, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.220008850097656e-05, "timer/dataset_eval_frac": 4.21840351892453e-08, "timer/dataset_eval_avg": 4.220008850097656e-05, "timer/dataset_eval_min": 4.220008850097656e-05, "timer/dataset_eval_max": 4.220008850097656e-05, "fps": 21.17567145071403}
{"step": 43496, "time": 2311.260917186737, "episode/length": 151.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 43768, "time": 2322.248795747757, "episode/length": 191.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 43832, "time": 2326.244264602661, "episode/length": 164.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 44352, "time": 2345.6127088069916, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 44360, "time": 2347.3611567020416, "episode/length": 196.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 44520, "time": 2354.396113395691, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 44904, "time": 2369.1153745651245, "episode/length": 182.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 45152, "time": 2379.55753159523, "episode/length": 213.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 45200, "time": 2382.921412229538, "episode/length": 212.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 45456, "time": 2393.337970495224, "episode/length": 136.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 45712, "time": 2403.737314224243, "episode/length": 234.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 45744, "time": 2406.487897634506, "episode/length": 173.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 45792, "time": 2409.814101457596, "episode/length": 252.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9841897233201581, "episode/intrinsic_return": 0.0}
{"step": 45816, "time": 2411.9580404758453, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 46128, "time": 2424.395289182663, "episode/length": 83.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9404761904761905, "episode/intrinsic_return": 0.0}
{"step": 46488, "time": 2437.9728672504425, "episode/length": 44.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 46520, "time": 2440.7006380558014, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 46616, "time": 2445.532402276993, "episode/length": 182.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 46808, "time": 2453.771781206131, "episode/length": 237.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 46992, "time": 2461.921281337738, "episode/length": 149.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 47216, "time": 2471.1189165115356, "episode/length": 174.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 47240, "time": 2473.3950986862183, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 47624, "time": 2488.2290983200073, "episode/length": 234.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 47904, "time": 2499.69123506546, "episode/length": 160.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 48024, "time": 2505.2191290855408, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 48288, "time": 2516.2454359531403, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 48296, "time": 2517.919206380844, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 48632, "time": 2531.0657184123993, "episode/length": 176.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 49024, "time": 2546.3675088882446, "episode/length": 174.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 49152, "time": 2552.5227813720703, "episode/length": 238.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 49328, "time": 2561.489244699478, "episode/length": 354.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9971830985915493, "episode/intrinsic_return": 0.0}
{"step": 49472, "time": 2568.1764023303986, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 49528, "time": 2571.469549179077, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 49544, "time": 2573.5660049915314, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 49616, "time": 2577.9675755500793, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 49880, "time": 2588.4567382335663, "episode/length": 155.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 49912, "time": 2591.0162076950073, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 2611.8820972442627, "eval_episode/length": 44.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 50024, "time": 2618.637617588043, "eval_episode/length": 159.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.99375}
{"step": 50024, "time": 2620.386117696762, "eval_episode/length": 161.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 50024, "time": 2622.2985434532166, "eval_episode/length": 168.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 50024, "time": 2624.0656349658966, "eval_episode/length": 171.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 50024, "time": 2626.602937936783, "eval_episode/length": 27.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8214285714285714}
{"step": 50024, "time": 2626.611931324005, "eval_episode/length": 189.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9631578947368421}
{"step": 50024, "time": 2630.170511484146, "eval_episode/length": 192.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 50168, "time": 2635.0525012016296, "episode/length": 35.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 50408, "time": 2644.749307155609, "episode/length": 107.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 50664, "time": 2655.0071017742157, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 50952, "time": 2666.632889032364, "episode/length": 202.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 51160, "time": 2675.288563489914, "episode/length": 210.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 51176, "time": 2677.436037540436, "episode/length": 205.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 51216, "time": 2680.636059522629, "episode/length": 199.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 51256, "time": 2683.4203972816467, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 51560, "time": 2695.416988134384, "episode/length": 173.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 51664, "time": 2700.693270921707, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 52424, "time": 2728.0768620967865, "episode/length": 219.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 52560, "time": 2734.6226160526276, "episode/length": 162.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 52800, "time": 2744.493620634079, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 52960, "time": 2751.6717987060547, "episode/length": 224.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 53000, "time": 2754.374003648758, "episode/length": 179.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 53248, "time": 2764.560069799423, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 53320, "time": 2768.3445904254913, "episode/length": 267.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 53920, "time": 2790.8420367240906, "episode/length": 139.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 54176, "time": 2801.1830599308014, "episode/length": 218.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 54296, "time": 2806.8571400642395, "episode/length": 166.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 54320, "time": 2809.5301394462585, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 54640, "time": 2821.9278264045715, "episode/length": 259.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 54816, "time": 2829.532521724701, "episode/length": 195.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 54928, "time": 2834.96497631073, "episode/length": 496.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9919517102615694, "episode/intrinsic_return": 0.0}
{"step": 55176, "time": 2845.04647397995, "episode/length": 156.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 55232, "time": 2848.791497707367, "episode/length": 131.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 55336, "time": 2853.8148531913757, "episode/length": 251.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 56032, "time": 2879.411790370941, "episode/length": 213.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 56072, "time": 2882.229543685913, "episode/length": 178.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 56120, "time": 2885.4180369377136, "episode/length": 227.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 56168, "time": 2888.571277141571, "episode/length": 154.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 56472, "time": 2900.6897287368774, "episode/length": 37.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 56472, "time": 2900.6977138519287, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 56568, "time": 2907.6762323379517, "episode/length": 218.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 56584, "time": 2909.7203969955444, "episode/length": 155.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 56696, "time": 2915.25342464447, "episode/length": 71.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9305555555555556, "episode/intrinsic_return": 0.0}
{"step": 56920, "time": 2924.583936691284, "episode/length": 110.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.963963963963964, "episode/intrinsic_return": 0.0}
{"step": 57176, "time": 2934.9998354911804, "episode/length": 249.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 57848, "time": 2961.1429991722107, "episode/length": 159.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 57912, "time": 2964.9491119384766, "episode/length": 179.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 57992, "time": 2969.3338882923126, "episode/length": 239.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 58280, "time": 2980.943035364151, "episode/length": 225.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 58288, "time": 2983.104156732559, "episode/length": 212.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 58360, "time": 2987.1266028881073, "episode/length": 179.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 58440, "time": 2991.491138458252, "episode/length": 217.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 58496, "time": 2995.2064027786255, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 59016, "time": 3014.3101377487183, "episode/length": 145.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 59184, "time": 3021.9123046398163, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 59200, "time": 3024.0324878692627, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9536423841059603, "episode/intrinsic_return": 0.0}
{"step": 59488, "time": 3035.4504742622375, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 59496, "time": 3037.0301156044006, "episode/length": 36.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 59680, "time": 3045.1756076812744, "episode/length": 164.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 59744, "time": 3049.108444929123, "episode/length": 155.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 59840, "time": 3054.0315482616425, "episode/length": 194.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9641025641025641, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 3082.1258878707886, "eval_episode/length": 157.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 60008, "time": 3083.9962849617004, "eval_episode/length": 161.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 60008, "time": 3086.782143354416, "eval_episode/length": 184.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 60008, "time": 3089.022442340851, "eval_episode/length": 197.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 60008, "time": 3090.964396715164, "eval_episode/length": 202.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 60008, "time": 3093.7093770504, "eval_episode/length": 223.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 60008, "time": 3096.2011919021606, "eval_episode/length": 237.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 60008, "time": 3098.2576537132263, "eval_episode/length": 249.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.98}
{"step": 60296, "time": 3108.1733877658844, "episode/length": 159.0, "episode/score": 3.1000000461935997, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 60440, "time": 3114.6675000190735, "episode/length": 86.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9425287356321839, "episode/intrinsic_return": 0.0}
{"step": 60728, "time": 3126.0821421146393, "episode/length": 35.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 60752, "time": 3128.7173936367035, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 60848, "time": 3133.6345551013947, "episode/length": 168.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 61008, "time": 3140.866142511368, "episode/length": 320.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 61416, "time": 3156.4150784015656, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 61448, "time": 3159.1997327804565, "episode/length": 220.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 61480, "time": 3161.9448280334473, "episode/length": 248.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 61768, "time": 3173.570071220398, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 61824, "time": 3177.3253672122955, "episode/length": 46.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 61952, "time": 3183.2240817546844, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 62112, "time": 3190.282265663147, "episode/length": 42.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 62176, "time": 3194.0521228313446, "episode/length": 145.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 62808, "time": 3217.106173992157, "episode/length": 78.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9240506329113924, "episode/intrinsic_return": 0.0}
{"step": 62832, "time": 3219.8101840019226, "episode/length": 168.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 62928, "time": 3224.798139810562, "episode/length": 271.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9889705882352942, "episode/intrinsic_return": 0.0}
{"step": 63144, "time": 3233.7418208122253, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 63176, "time": 3236.909538269043, "episode/length": 132.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9699248120300752, "episode/intrinsic_return": 0.0}
{"step": 63184, "time": 3238.9768166542053, "episode/length": 220.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 64032, "time": 3269.771307706833, "episode/length": 152.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 64112, "time": 3274.0800998210907, "episode/length": 407.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9877450980392157, "episode/intrinsic_return": 0.0}
{"step": 64168, "time": 3277.4869096279144, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 64256, "time": 3282.8446362018585, "episode/length": 287.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 64528, "time": 3293.9940946102142, "episode/length": 167.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 64624, "time": 3298.929489850998, "episode/length": 223.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 64905, "time": 3310.8336272239685, "train_stats/sum_log_reward": 2.843589670000932, "train_stats/max_log_achievement_collect_drink": 7.897435897435898, "train_stats/max_log_achievement_collect_sapling": 2.1880341880341883, "train_stats/max_log_achievement_collect_wood": 1.0085470085470085, "train_stats/max_log_achievement_defeat_skeleton": 0.017094017094017096, "train_stats/max_log_achievement_defeat_zombie": 0.1111111111111111, "train_stats/max_log_achievement_eat_cow": 0.09401709401709402, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.9401709401709402, "train_stats/max_log_achievement_place_table": 0.08547008547008547, "train_stats/max_log_achievement_wake_up": 1.7863247863247864, "train_stats/mean_log_entropy": 0.8452848915615653, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.643899490584189, "train/action_min": 0.0, "train/action_std": 3.339855686942143, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048947184749726036, "train/actor_opt_grad_steps": 3295.0, "train/actor_opt_loss": 24.017394646223803, "train/adv_mag": 1.6440751868397443, "train/adv_max": 1.6428142047640104, "train/adv_mean": 0.009848082950794826, "train/adv_min": -0.6058345977494966, "train/adv_std": 0.1200063566663372, "train/cont_avg": 0.9945997551305971, "train/cont_loss_mean": 0.0008311144201933761, "train/cont_loss_std": 0.019986439757072975, "train/cont_neg_acc": 0.9732202113564334, "train/cont_neg_loss": 0.08432411603611562, "train/cont_pos_acc": 0.9998826175483305, "train/cont_pos_loss": 0.0004281197631333927, "train/cont_pred": 0.9945823697011862, "train/cont_rate": 0.9945997551305971, "train/dyn_loss_mean": 7.202038544327466, "train/dyn_loss_std": 6.851287471714304, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.183630339245298, "train/extr_critic_critic_opt_grad_steps": 3295.0, "train/extr_critic_critic_opt_loss": 14334.459122842818, "train/extr_critic_mag": 1.7392144719166542, "train/extr_critic_max": 1.7392144719166542, "train/extr_critic_mean": 0.45783785552676043, "train/extr_critic_min": -0.18343429778938863, "train/extr_critic_std": 0.5589703719562559, "train/extr_return_normed_mag": 2.541149898251491, "train/extr_return_normed_max": 2.541149898251491, "train/extr_return_normed_mean": 0.34535310028204275, "train/extr_return_normed_min": -0.27255474789929923, "train/extr_return_normed_std": 0.3691642831510572, "train/extr_return_rate": 0.32076533105391175, "train/extr_return_raw_mag": 4.075238468042061, "train/extr_return_raw_max": 4.075238468042061, "train/extr_return_raw_mean": 0.47355622231070676, "train/extr_return_raw_min": -0.5459427486604719, "train/extr_return_raw_std": 0.6080154305073753, "train/extr_reward_mag": 1.0036876539685833, "train/extr_reward_max": 1.0036876539685833, "train/extr_reward_mean": 0.011785451639026626, "train/extr_reward_min": -0.36637233709221456, "train/extr_reward_std": 0.08605303776575558, "train/image_loss_mean": 18.04090356115085, "train/image_loss_std": 20.033076969545277, "train/model_loss_mean": 22.41531619740956, "train/model_loss_std": 22.45166477516516, "train/model_opt_grad_norm": 127.6432731115996, "train/model_opt_grad_steps": 3286.0, "train/model_opt_loss": 3040.030542174382, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 133.51212686567163, "train/policy_entropy_mag": 2.3973945948615003, "train/policy_entropy_max": 2.3973945948615003, "train/policy_entropy_mean": 0.754653717599698, "train/policy_entropy_min": 0.0795064512362231, "train/policy_entropy_std": 0.5281210744114064, "train/policy_logprob_mag": 7.437397483569472, "train/policy_logprob_max": -0.009474125614306375, "train/policy_logprob_mean": -0.754536533978448, "train/policy_logprob_min": -7.437397483569472, "train/policy_logprob_std": 1.2050957866569063, "train/policy_randomness_mag": 0.8461750856976011, "train/policy_randomness_max": 0.8461750856976011, "train/policy_randomness_mean": 0.2663596485977742, "train/policy_randomness_min": 0.028062288246270436, "train/policy_randomness_std": 0.18640356444155992, "train/post_ent_mag": 45.64841082558703, "train/post_ent_max": 45.64841082558703, "train/post_ent_mean": 32.92380472439439, "train/post_ent_min": 15.580548101396703, "train/post_ent_std": 4.575966530771398, "train/prior_ent_mag": 58.148291032705735, "train/prior_ent_max": 58.148291032705735, "train/prior_ent_mean": 40.26656683167415, "train/prior_ent_min": 19.077106853029623, "train/prior_ent_std": 6.179253368235346, "train/rep_loss_mean": 7.202038544327466, "train/rep_loss_std": 6.851287471714304, "train/reward_avg": 0.009294105562079115, "train/reward_loss_mean": 0.05235837397179497, "train/reward_loss_std": 0.2879354569004543, "train/reward_max_data": 1.005970150677126, "train/reward_max_pred": 0.9992663486679988, "train/reward_neg_acc": 0.994841403480786, "train/reward_neg_loss": 0.035689965244938636, "train/reward_pos_acc": 0.9100696306620071, "train/reward_pos_loss": 1.2090265982186617, "train/reward_pred": 0.008424562933757457, "train/reward_rate": 0.014233034048507462, "eval_stats/sum_log_reward": 2.7874999344348907, "eval_stats/max_log_achievement_collect_drink": 7.5, "eval_stats/max_log_achievement_collect_sapling": 1.9375, "eval_stats/max_log_achievement_collect_wood": 0.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.6875, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 1.8125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.0008346919785253704, "report/cont_loss_std": 0.024126389995217323, "report/cont_neg_acc": 0.875, "report/cont_neg_loss": 0.10572122782468796, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.813780368654989e-06, "report/cont_pred": 0.9927754402160645, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 8.13507080078125, "report/dyn_loss_std": 7.387168884277344, "report/image_loss_mean": 17.165359497070312, "report/image_loss_std": 16.663869857788086, "report/model_loss_mean": 22.115314483642578, "report/model_loss_std": 19.622650146484375, "report/post_ent_mag": 49.317138671875, "report/post_ent_max": 49.317138671875, "report/post_ent_mean": 33.78842544555664, "report/post_ent_min": 16.09502410888672, "report/post_ent_std": 4.901988983154297, "report/prior_ent_mag": 58.536529541015625, "report/prior_ent_max": 58.536529541015625, "report/prior_ent_mean": 42.67254638671875, "report/prior_ent_min": 18.344087600708008, "report/prior_ent_std": 7.048554420471191, "report/rep_loss_mean": 8.13507080078125, "report/rep_loss_std": 7.387168884277344, "report/reward_avg": 0.009765625, "report/reward_loss_mean": 0.06807751953601837, "report/reward_loss_std": 0.3883439004421234, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0074803829193115, "report/reward_neg_acc": 0.995029866695404, "report/reward_neg_loss": 0.042727019637823105, "report/reward_pos_acc": 0.8333333134651184, "report/reward_pos_loss": 1.4848886728286743, "report/reward_pred": 0.008603712543845177, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0008665515924803913, "eval/cont_loss_std": 0.025941776111721992, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.21671900153160095, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.00715603568824e-05, "eval/cont_pred": 0.996660053730011, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 13.813243865966797, "eval/dyn_loss_std": 9.331414222717285, "eval/image_loss_mean": 39.61787796020508, "eval/image_loss_std": 34.441287994384766, "eval/model_loss_mean": 48.058128356933594, "eval/model_loss_std": 37.511634826660156, "eval/post_ent_mag": 46.32308578491211, "eval/post_ent_max": 46.32308578491211, "eval/post_ent_mean": 32.276039123535156, "eval/post_ent_min": 16.74647331237793, "eval/post_ent_std": 5.233517169952393, "eval/prior_ent_mag": 60.70874786376953, "eval/prior_ent_max": 60.70874786376953, "eval/prior_ent_mean": 42.925071716308594, "eval/prior_ent_min": 20.07529067993164, "eval/prior_ent_std": 7.715660095214844, "eval/rep_loss_mean": 13.813243865966797, "eval/rep_loss_std": 9.331414222717285, "eval/reward_avg": 0.0107421875, "eval/reward_loss_mean": 0.1514391005039215, "eval/reward_loss_std": 0.797116219997406, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0061752796173096, "eval/reward_neg_acc": 0.99702388048172, "eval/reward_neg_loss": 0.11418865621089935, "eval/reward_pos_acc": 0.625, "eval/reward_pos_loss": 2.498218059539795, "eval/reward_pred": 0.004773344378918409, "eval/reward_rate": 0.015625, "replay/size": 64401.0, "replay/inserts": 21440.0, "replay/samples": 21440.0, "replay/insert_wait_avg": 1.475303920347299e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.635379954950133e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 14072.0, "eval_replay/inserts": 3544.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.418267631100209e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3312880992889, "timer/env.step_count": 2680.0, "timer/env.step_total": 269.3868546485901, "timer/env.step_frac": 0.26929763954544206, "timer/env.step_avg": 0.10051748307783212, "timer/env.step_min": 0.024370908737182617, "timer/env.step_max": 3.674100875854492, "timer/replay._sample_count": 21440.0, "timer/replay._sample_total": 12.01748538017273, "timer/replay._sample_frac": 0.012013505448786804, "timer/replay._sample_avg": 0.0005605170419856684, "timer/replay._sample_min": 0.0003848075866699219, "timer/replay._sample_max": 0.016387224197387695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3123.0, "timer/agent.policy_total": 55.772804737091064, "timer/agent.policy_frac": 0.055754333989756474, "timer/agent.policy_avg": 0.017858727101213917, "timer/agent.policy_min": 0.009889602661132812, "timer/agent.policy_max": 0.11387014389038086, "timer/dataset_train_count": 1340.0, "timer/dataset_train_total": 0.16260480880737305, "timer/dataset_train_frac": 0.00016255095760958898, "timer/dataset_train_avg": 0.00012134687224430825, "timer/dataset_train_min": 0.00010395050048828125, "timer/dataset_train_max": 0.00047469139099121094, "timer/agent.train_count": 1340.0, "timer/agent.train_total": 606.5017733573914, "timer/agent.train_frac": 0.6063009130802999, "timer/agent.train_avg": 0.4526132636995458, "timer/agent.train_min": 0.43840599060058594, "timer/agent.train_max": 1.485323429107666, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4759700298309326, "timer/agent.report_frac": 0.0004758123988457009, "timer/agent.report_avg": 0.2379850149154663, "timer/agent.report_min": 0.22948622703552246, "timer/agent.report_max": 0.24648380279541016, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.504753112792969e-05, "timer/dataset_eval_frac": 3.503592414321345e-08, "timer/dataset_eval_avg": 3.504753112792969e-05, "timer/dataset_eval_min": 3.504753112792969e-05, "timer/dataset_eval_max": 3.504753112792969e-05, "fps": 21.432637191229798}
{"step": 65280, "time": 3323.9779641628265, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 65504, "time": 3333.2745492458344, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 65752, "time": 3344.6923167705536, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 65984, "time": 3354.612538576126, "episode/length": 354.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746478873239437, "episode/intrinsic_return": 0.0}
{"step": 66016, "time": 3357.468640089035, "episode/length": 219.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 66032, "time": 3359.736197948456, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 66152, "time": 3365.1894030570984, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 66528, "time": 3380.0337603092194, "episode/length": 61.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 66584, "time": 3383.2515058517456, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 66608, "time": 3385.8821971416473, "episode/length": 137.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 66632, "time": 3388.1367189884186, "episode/length": 431.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 67096, "time": 3405.568014383316, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 67248, "time": 3412.777145385742, "episode/length": 136.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9708029197080292, "episode/intrinsic_return": 0.0}
{"step": 67248, "time": 3412.7853672504425, "episode/length": 153.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 67728, "time": 3432.5389862060547, "episode/length": 217.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 68008, "time": 3443.576128721237, "episode/length": 177.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 68184, "time": 3451.2142190933228, "episode/length": 206.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 68272, "time": 3456.0197036266327, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 68568, "time": 3467.5563616752625, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 68808, "time": 3477.5249099731445, "episode/length": 194.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 68840, "time": 3480.342536211014, "episode/length": 217.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 68840, "time": 3480.3512740135193, "episode/length": 278.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.985663082437276, "episode/intrinsic_return": 0.0}
{"step": 69104, "time": 3492.8550646305084, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 69424, "time": 3505.470669031143, "episode/length": 106.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9439252336448598, "episode/intrinsic_return": 0.0}
{"step": 69512, "time": 3509.9877252578735, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 69960, "time": 3527.1721048355103, "episode/length": 143.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 3551.465080022812, "eval_episode/length": 88.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9550561797752809}
{"step": 70096, "time": 3556.0129804611206, "eval_episode/length": 149.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 70096, "time": 3559.062559366226, "eval_episode/length": 177.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9662921348314607}
{"step": 70096, "time": 3560.8496181964874, "eval_episode/length": 180.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.994475138121547}
{"step": 70096, "time": 3563.3954498767853, "eval_episode/length": 48.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 70096, "time": 3565.7328107357025, "eval_episode/length": 201.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 70096, "time": 3572.64004945755, "eval_episode/length": 182.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 70096, "time": 3574.4676728248596, "eval_episode/length": 274.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 70208, "time": 3578.2982833385468, "episode/length": 170.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 70328, "time": 3583.754230260849, "episode/length": 289.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 70424, "time": 3588.6771771907806, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 70968, "time": 3608.670319080353, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 71360, "time": 3624.063364505768, "episode/length": 174.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 71456, "time": 3628.907856941223, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 71672, "time": 3637.8396565914154, "episode/length": 269.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9851851851851852, "episode/intrinsic_return": 0.0}
{"step": 71672, "time": 3637.8505749702454, "episode/length": 424.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9788235294117648, "episode/intrinsic_return": 0.0}
{"step": 71680, "time": 3641.780190706253, "episode/length": 88.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 72040, "time": 3655.692080259323, "episode/length": 399.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775, "episode/intrinsic_return": 0.0}
{"step": 72192, "time": 3662.6615657806396, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 72688, "time": 3681.170219898224, "episode/length": 165.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 72888, "time": 3689.445603609085, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 72928, "time": 3692.7300474643707, "episode/length": 183.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 73168, "time": 3702.5834798812866, "episode/length": 140.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 73232, "time": 3706.5262281894684, "episode/length": 37.0, "episode/score": -0.9000000283122063, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 73376, "time": 3713.1918892860413, "episode/length": 212.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 73544, "time": 3720.760651111603, "episode/length": 401.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9975124378109452, "episode/intrinsic_return": 0.0}
{"step": 73896, "time": 3735.840898036957, "episode/length": 277.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 73960, "time": 3739.7870564460754, "episode/length": 220.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 74200, "time": 3749.6240384578705, "episode/length": 163.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 74216, "time": 3751.829037666321, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 74568, "time": 3765.3335740566254, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9580838323353293, "episode/intrinsic_return": 0.0}
{"step": 74592, "time": 3768.1640367507935, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 74928, "time": 3781.177006483078, "episode/length": 219.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 75008, "time": 3785.5273399353027, "episode/length": 182.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 75256, "time": 3795.2890286445618, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 75440, "time": 3803.608369588852, "episode/length": 152.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 75648, "time": 3812.3220026493073, "episode/length": 210.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 75808, "time": 3819.2983169555664, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 75928, "time": 3824.7932624816895, "episode/length": 114.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9478260869565217, "episode/intrinsic_return": 0.0}
{"step": 76136, "time": 3833.7282025814056, "episode/length": 150.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9536423841059603, "episode/intrinsic_return": 0.0}
{"step": 76152, "time": 3835.8816726207733, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 76312, "time": 3842.982410430908, "episode/length": 263.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.0}
{"step": 76496, "time": 3851.079609632492, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 76808, "time": 3863.2127532958984, "episode/length": 38.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8974358974358975, "episode/intrinsic_return": 0.0}
{"step": 76880, "time": 3867.4534158706665, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 77104, "time": 3877.218377828598, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 77480, "time": 3891.68319439888, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 77632, "time": 3898.666891813278, "episode/length": 184.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 77680, "time": 3901.8084845542908, "episode/length": 233.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 77872, "time": 3909.9107921123505, "episode/length": 216.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 78232, "time": 3923.676018714905, "episode/length": 168.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 78488, "time": 3934.031710624695, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 78576, "time": 3938.876125097275, "episode/length": 282.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9929328621908127, "episode/intrinsic_return": 0.0}
{"step": 78840, "time": 3949.3939735889435, "episode/length": 169.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 78952, "time": 3954.7156722545624, "episode/length": 267.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9813432835820896, "episode/intrinsic_return": 0.0}
{"step": 79024, "time": 3958.986356496811, "episode/length": 167.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 79144, "time": 3964.423446416855, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 79312, "time": 3972.042290687561, "episode/length": 209.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 79528, "time": 3980.776503801346, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 79776, "time": 3990.8585045337677, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 79960, "time": 3998.606648206711, "episode/length": 183.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 4019.7915086746216, "eval_episode/length": 34.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8571428571428571}
{"step": 80080, "time": 4022.146313905716, "eval_episode/length": 49.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.98}
{"step": 80080, "time": 4028.27108836174, "eval_episode/length": 148.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 80080, "time": 4030.1876769065857, "eval_episode/length": 154.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 80080, "time": 4031.920213699341, "eval_episode/length": 156.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 80080, "time": 4036.4973871707916, "eval_episode/length": 215.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9861111111111112}
{"step": 80080, "time": 4038.491413116455, "eval_episode/length": 222.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 80080, "time": 4042.184975385666, "eval_episode/length": 233.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 80120, "time": 4043.337054491043, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 80448, "time": 4056.162671804428, "episode/length": 162.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 80808, "time": 4069.889382123947, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 80832, "time": 4072.600316286087, "episode/length": 234.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 80856, "time": 4074.7720024585724, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 81064, "time": 4083.4849956035614, "episode/length": 160.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 81272, "time": 4092.0505986213684, "episode/length": 25.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 81288, "time": 4094.2406148910522, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 81320, "time": 4097.094273328781, "episode/length": 286.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9860627177700348, "episode/intrinsic_return": 0.0}
{"step": 81544, "time": 4106.131917476654, "episode/length": 88.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 81680, "time": 4112.577021360397, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 81848, "time": 4119.543154478073, "episode/length": 129.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 82200, "time": 4134.740259885788, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 82320, "time": 4140.569493770599, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 82488, "time": 4147.641433000565, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 82784, "time": 4159.666460752487, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 82816, "time": 4162.407733917236, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 82920, "time": 4167.2359874248505, "episode/length": 199.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.985, "episode/intrinsic_return": 0.0}
{"step": 83208, "time": 4178.6110582351685, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 83232, "time": 4181.332740545273, "episode/length": 55.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 83392, "time": 4188.481662750244, "episode/length": 148.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 83456, "time": 4192.225992202759, "episode/length": 221.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 83576, "time": 4197.498951911926, "episode/length": 81.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9390243902439024, "episode/intrinsic_return": 0.0}
{"step": 83680, "time": 4202.908705711365, "episode/length": 148.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 83848, "time": 4210.100697278976, "episode/length": 190.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 84032, "time": 4218.3129761219025, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 84464, "time": 4234.658504009247, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 84520, "time": 4237.91965842247, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 85008, "time": 4256.525181770325, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 85248, "time": 4266.236608982086, "episode/length": 223.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 85336, "time": 4270.7173807621, "episode/length": 162.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 85448, "time": 4276.146636247635, "episode/length": 256.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 85448, "time": 4276.167911052704, "episode/length": 199.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 85480, "time": 4280.721856832504, "episode/length": 224.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 85928, "time": 4297.441937923431, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 86032, "time": 4302.835279941559, "episode/length": 188.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 86201, "time": 4311.033980131149, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.698294503348214, "train/action_min": 0.0, "train/action_std": 3.165875182115942, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0562222678550428, "train/actor_opt_grad_steps": 4630.0, "train/actor_opt_loss": 45.7951036608757, "train/adv_mag": 1.5327147075108118, "train/adv_max": 1.5273721621448832, "train/adv_mean": 0.015007621303412546, "train/adv_min": -0.6031572276488283, "train/adv_std": 0.12114457287510536, "train/cont_avg": 0.9946472626879699, "train/cont_loss_mean": 0.0006141421371384945, "train/cont_loss_std": 0.016279603954249718, "train/cont_neg_acc": 0.9788459270520318, "train/cont_neg_loss": 0.07199426150249141, "train/cont_pos_acc": 0.999933513931762, "train/cont_pos_loss": 0.00026993483005030507, "train/cont_pred": 0.9946424947645431, "train/cont_rate": 0.9946472626879699, "train/dyn_loss_mean": 9.077381144788928, "train/dyn_loss_std": 7.650013869866393, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.306007687310527, "train/extr_critic_critic_opt_grad_steps": 4630.0, "train/extr_critic_critic_opt_loss": 14649.843074483082, "train/extr_critic_mag": 2.4347454049533472, "train/extr_critic_max": 2.4347454049533472, "train/extr_critic_mean": 0.6741006226467907, "train/extr_critic_min": -0.12033049773452874, "train/extr_critic_std": 0.6437455648766425, "train/extr_return_normed_mag": 2.5576673073876175, "train/extr_return_normed_max": 2.5576673073876175, "train/extr_return_normed_mean": 0.3600579252592603, "train/extr_return_normed_min": -0.26425891251940475, "train/extr_return_normed_std": 0.36729766305227923, "train/extr_return_rate": 0.4111695455429249, "train/extr_return_raw_mag": 4.974679833964298, "train/extr_return_raw_max": 4.974679833964298, "train/extr_return_raw_mean": 0.7032178844276228, "train/extr_return_raw_min": -0.5192217160212366, "train/extr_return_raw_std": 0.7200593139444079, "train/extr_reward_mag": 1.0074449912049717, "train/extr_reward_max": 1.0074449912049717, "train/extr_reward_mean": 0.014476939342579896, "train/extr_reward_min": -0.3584447471719039, "train/extr_reward_std": 0.09798095946697365, "train/image_loss_mean": 19.18987919513444, "train/image_loss_std": 21.063762657624437, "train/model_loss_mean": 24.68941352958966, "train/model_loss_std": 24.164301205398445, "train/model_opt_grad_norm": 124.68278457526874, "train/model_opt_grad_steps": 4621.0, "train/model_opt_loss": 9073.479064482495, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 372.41541353383457, "train/policy_entropy_mag": 2.4729749851657035, "train/policy_entropy_max": 2.4729749851657035, "train/policy_entropy_mean": 0.8065716619778397, "train/policy_entropy_min": 0.0794040576967978, "train/policy_entropy_std": 0.5384234465602645, "train/policy_logprob_mag": 7.438033071675695, "train/policy_logprob_max": -0.009460249677636569, "train/policy_logprob_mean": -0.8068892014654059, "train/policy_logprob_min": -7.438033071675695, "train/policy_logprob_std": 1.2187297066351526, "train/policy_randomness_mag": 0.872851648725065, "train/policy_randomness_max": 0.872851648725065, "train/policy_randomness_mean": 0.2846844010335162, "train/policy_randomness_min": 0.028026147780561804, "train/policy_randomness_std": 0.19003984892278686, "train/post_ent_mag": 48.13206430306112, "train/post_ent_max": 48.13206430306112, "train/post_ent_mean": 34.504803822452864, "train/post_ent_min": 18.04403136547347, "train/post_ent_std": 4.743062474673852, "train/prior_ent_mag": 60.90650590021807, "train/prior_ent_max": 60.90650590021807, "train/prior_ent_mean": 43.768739026291925, "train/prior_ent_min": 21.51138046092557, "train/prior_ent_std": 7.009865258869372, "train/rep_loss_mean": 9.077381144788928, "train/rep_loss_std": 7.650013869866393, "train/reward_avg": 0.012520559196871586, "train/reward_loss_mean": 0.05249151307389252, "train/reward_loss_std": 0.2855689080810188, "train/reward_max_data": 1.0120300780561633, "train/reward_max_pred": 1.0024592329684954, "train/reward_neg_acc": 0.994691090476244, "train/reward_neg_loss": 0.03310210096012605, "train/reward_pos_acc": 0.9126051023490447, "train/reward_pos_loss": 1.1624824471939774, "train/reward_pred": 0.011113510949404113, "train/reward_rate": 0.017240366541353382, "train_stats/sum_log_reward": 3.430434735443281, "train_stats/max_log_achievement_collect_drink": 10.321739130434782, "train_stats/max_log_achievement_collect_sapling": 2.747826086956522, "train_stats/max_log_achievement_collect_wood": 1.7826086956521738, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.20869565217391303, "train_stats/max_log_achievement_eat_cow": 0.09565217391304348, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.4434782608695653, "train_stats/max_log_achievement_place_table": 0.1391304347826087, "train_stats/max_log_achievement_wake_up": 1.808695652173913, "train_stats/mean_log_entropy": 0.8196923502113508, "eval_stats/sum_log_reward": 3.287500012665987, "eval_stats/max_log_achievement_collect_drink": 8.125, "eval_stats/max_log_achievement_collect_sapling": 3.3125, "eval_stats/max_log_achievement_collect_wood": 2.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.375, "eval_stats/max_log_achievement_place_table": 0.1875, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.03076923076923077, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.061474540620111e-05, "report/cont_loss_std": 0.00015578322927467525, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.001881660777144134, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.433949250895239e-06, "report/cont_pred": 0.9951250553131104, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 8.4909029006958, "report/dyn_loss_std": 7.936326026916504, "report/image_loss_mean": 12.92678451538086, "report/image_loss_std": 15.98637866973877, "report/model_loss_mean": 18.052820205688477, "report/model_loss_std": 19.737112045288086, "report/post_ent_mag": 52.15066909790039, "report/post_ent_max": 52.15066909790039, "report/post_ent_mean": 34.756263732910156, "report/post_ent_min": 19.404884338378906, "report/post_ent_std": 4.381443977355957, "report/prior_ent_mag": 61.08293914794922, "report/prior_ent_max": 61.08293914794922, "report/prior_ent_mean": 43.49565887451172, "report/prior_ent_min": 20.9434814453125, "report/prior_ent_std": 7.276454448699951, "report/rep_loss_mean": 8.4909029006958, "report/rep_loss_std": 7.936326026916504, "report/reward_avg": 0.009863280691206455, "report/reward_loss_mean": 0.03148335963487625, "report/reward_loss_std": 0.14565889537334442, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.003793478012085, "report/reward_neg_acc": 0.9900990128517151, "report/reward_neg_loss": 0.020902369171380997, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7948263883590698, "report/reward_pred": 0.010992519557476044, "report/reward_rate": 0.013671875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.009846811182796955, "eval/cont_loss_std": 0.3143004775047302, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 2.0146238803863525, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.82877281785477e-06, "eval/cont_pred": 0.9960943460464478, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 15.429220199584961, "eval/dyn_loss_std": 9.25406551361084, "eval/image_loss_mean": 31.553232192993164, "eval/image_loss_std": 26.06552505493164, "eval/model_loss_mean": 40.9500846862793, "eval/model_loss_std": 29.860172271728516, "eval/post_ent_mag": 47.01001739501953, "eval/post_ent_max": 47.01001739501953, "eval/post_ent_mean": 34.053382873535156, "eval/post_ent_min": 18.847034454345703, "eval/post_ent_std": 4.434167385101318, "eval/prior_ent_mag": 61.346824645996094, "eval/prior_ent_max": 61.346824645996094, "eval/prior_ent_mean": 45.61744689941406, "eval/prior_ent_min": 21.37905502319336, "eval/prior_ent_std": 7.696063041687012, "eval/rep_loss_mean": 15.429220199584961, "eval/rep_loss_std": 9.25406551361084, "eval/reward_avg": 0.009179688058793545, "eval/reward_loss_mean": 0.12947353720664978, "eval/reward_loss_std": 0.8905352354049683, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018682479858398, "eval/reward_neg_acc": 0.996039628982544, "eval/reward_neg_loss": 0.06850643455982208, "eval/reward_pos_acc": 0.5, "eval/reward_pos_loss": 4.5278143882751465, "eval/reward_pred": 0.003273101057857275, "eval/reward_rate": 0.013671875, "replay/size": 85697.0, "replay/inserts": 21296.0, "replay/samples": 21296.0, "replay/insert_wait_avg": 1.433702181551709e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.688574890549428e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 18424.0, "eval_replay/inserts": 4352.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2959079707370085e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1872570514679, "timer/env.step_count": 2662.0, "timer/env.step_total": 265.0853855609894, "timer/env.step_frac": 0.2650357557468347, "timer/env.step_avg": 0.09958128683733636, "timer/env.step_min": 0.02429986000061035, "timer/env.step_max": 3.530743360519409, "timer/replay._sample_count": 21296.0, "timer/replay._sample_total": 11.679477214813232, "timer/replay._sample_frac": 0.011677290559813867, "timer/replay._sample_avg": 0.0005484352561426198, "timer/replay._sample_min": 0.0003905296325683594, "timer/replay._sample_max": 0.011638164520263672, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3206.0, "timer/agent.policy_total": 57.526408433914185, "timer/agent.policy_frac": 0.05751563822508686, "timer/agent.policy_avg": 0.01794335883777735, "timer/agent.policy_min": 0.009691238403320312, "timer/agent.policy_max": 0.14132404327392578, "timer/dataset_train_count": 1331.0, "timer/dataset_train_total": 0.15423369407653809, "timer/dataset_train_frac": 0.00015420481813697162, "timer/dataset_train_avg": 0.00011587805715742906, "timer/dataset_train_min": 9.942054748535156e-05, "timer/dataset_train_max": 0.0005273818969726562, "timer/agent.train_count": 1331.0, "timer/agent.train_total": 604.232185125351, "timer/agent.train_frac": 0.60411905957152, "timer/agent.train_avg": 0.4539685838657783, "timer/agent.train_min": 0.43987131118774414, "timer/agent.train_max": 1.513563632965088, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4725489616394043, "timer/agent.report_frac": 0.00047246049008109665, "timer/agent.report_avg": 0.23627448081970215, "timer/agent.report_min": 0.2291698455810547, "timer/agent.report_max": 0.2433791160583496, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.979674273750694e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 21.291762571192525}
{"step": 86592, "time": 4324.3855102062225, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 86696, "time": 4329.292448759079, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 86792, "time": 4334.086238384247, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 86872, "time": 4338.507453680038, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 87040, "time": 4346.136296272278, "episode/length": 253.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 87176, "time": 4352.100239038467, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 87856, "time": 4377.026454210281, "episode/length": 144.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 87888, "time": 4379.567638874054, "episode/length": 231.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 88192, "time": 4391.339048862457, "episode/length": 143.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 88328, "time": 4397.423157691956, "episode/length": 181.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 88336, "time": 4399.5794513225555, "episode/length": 192.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 88416, "time": 4403.799134492874, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 88936, "time": 4422.66668009758, "episode/length": 435.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9793577981651376, "episode/intrinsic_return": 0.0}
{"step": 89088, "time": 4429.934543132782, "episode/length": 149.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 89352, "time": 4440.1631898880005, "episode/length": 186.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 89368, "time": 4442.279718399048, "episode/length": 273.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9744525547445255, "episode/intrinsic_return": 0.0}
{"step": 89544, "time": 4449.804759025574, "episode/length": 151.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 89552, "time": 4451.97061419487, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 90000, "time": 4469.022337436676, "episode/length": 207.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 90056, "time": 4472.307521820068, "episode/length": 204.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 4495.106617927551, "eval_episode/length": 161.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 90064, "time": 4497.423881292343, "eval_episode/length": 166.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 90064, "time": 4499.56320476532, "eval_episode/length": 168.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 90064, "time": 4501.941259145737, "eval_episode/length": 173.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 90064, "time": 4504.737379550934, "eval_episode/length": 188.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 90064, "time": 4507.0730566978455, "eval_episode/length": 194.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 90064, "time": 4509.261446714401, "eval_episode/length": 196.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 90064, "time": 4511.947726488113, "eval_episode/length": 209.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 90288, "time": 4521.054789543152, "episode/length": 35.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8611111111111112, "episode/intrinsic_return": 0.0}
{"step": 90296, "time": 4522.73130941391, "episode/length": 169.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 90688, "time": 4537.760569095612, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 90744, "time": 4540.934341430664, "episode/length": 206.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 90784, "time": 4544.107276678085, "episode/length": 154.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 90800, "time": 4546.441788673401, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 90880, "time": 4550.691969871521, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 91136, "time": 4560.906700849533, "episode/length": 48.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 91352, "time": 4569.591007947922, "episode/length": 26.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8518518518518519, "episode/intrinsic_return": 0.0}
{"step": 91616, "time": 4580.471932888031, "episode/length": 165.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 91648, "time": 4583.181341648102, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 91720, "time": 4587.047541379929, "episode/length": 177.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 91760, "time": 4590.253066778183, "episode/length": 121.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9508196721311475, "episode/intrinsic_return": 0.0}
{"step": 92056, "time": 4601.719630718231, "episode/length": 36.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 92456, "time": 4617.0891852378845, "episode/length": 220.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9864253393665159, "episode/intrinsic_return": 0.0}
{"step": 92464, "time": 4619.148371934891, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 92536, "time": 4622.994275331497, "episode/length": 206.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 92616, "time": 4627.246292829514, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 92928, "time": 4639.750803470612, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 93336, "time": 4654.845049381256, "episode/length": 159.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 93936, "time": 4677.179151296616, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 94072, "time": 4683.319670200348, "episode/length": 201.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 94096, "time": 4685.944778680801, "episode/length": 184.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9567567567567568, "episode/intrinsic_return": 0.0}
{"step": 94336, "time": 4695.74009847641, "episode/length": 224.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 94456, "time": 4701.434939861298, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 94512, "time": 4705.011081933975, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 94928, "time": 4720.826478719711, "episode/length": 413.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 95176, "time": 4730.727807760239, "episode/length": 431.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 95296, "time": 4736.608276605606, "episode/length": 152.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 95368, "time": 4740.3892385959625, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 95720, "time": 4753.93324637413, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 95808, "time": 4759.490153551102, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 96128, "time": 4772.129310369492, "episode/length": 149.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 96160, "time": 4774.917266130447, "episode/length": 227.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 96168, "time": 4776.592146158218, "episode/length": 55.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9107142857142857, "episode/intrinsic_return": 0.0}
{"step": 96592, "time": 4792.970223426819, "episode/length": 176.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 96744, "time": 4799.443578720093, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 96904, "time": 4806.507028579712, "episode/length": 305.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9869281045751634, "episode/intrinsic_return": 0.0}
{"step": 96960, "time": 4810.182316541672, "episode/length": 207.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 97352, "time": 4824.708366632462, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 97600, "time": 4834.97882437706, "episode/length": 183.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 97624, "time": 4837.1385951042175, "episode/length": 182.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 97920, "time": 4849.0449430942535, "episode/length": 146.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 97944, "time": 4851.278033018112, "episode/length": 221.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 97976, "time": 4853.991425037384, "episode/length": 133.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 98032, "time": 4857.693621397018, "episode/length": 84.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9529411764705882, "episode/intrinsic_return": 0.0}
{"step": 98424, "time": 4873.675600528717, "episode/length": 182.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 98728, "time": 4885.64946603775, "episode/length": 266.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 98944, "time": 4894.769376277924, "episode/length": 164.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 99408, "time": 4912.266188621521, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 99440, "time": 4915.027478456497, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 99664, "time": 4924.07461977005, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 99776, "time": 4929.513334989548, "episode/length": 228.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9868995633187773, "episode/intrinsic_return": 0.0}
{"step": 99792, "time": 4931.66730093956, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 100000, "time": 4940.271390914917, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 4964.2729370594025, "eval_episode/length": 168.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9822485207100592}
{"step": 100048, "time": 4965.958020448685, "eval_episode/length": 170.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 100048, "time": 4968.167309761047, "eval_episode/length": 176.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 100048, "time": 4970.195723056793, "eval_episode/length": 183.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 100048, "time": 4972.157729148865, "eval_episode/length": 191.0, "eval_episode/score": 5.099999964237213, "eval_episode/reward_rate": 0.96875}
{"step": 100048, "time": 4974.793145895004, "eval_episode/length": 212.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9765258215962441}
{"step": 100048, "time": 4976.449174880981, "eval_episode/length": 214.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9720930232558139}
{"step": 100048, "time": 4980.080179452896, "eval_episode/length": 257.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9806201550387597}
{"step": 100272, "time": 4987.637797117233, "episode/length": 165.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 100296, "time": 4989.926793575287, "episode/length": 336.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9881305637982196, "episode/intrinsic_return": 0.0}
{"step": 100776, "time": 5007.728977918625, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 100824, "time": 5010.927783727646, "episode/length": 172.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 101144, "time": 5023.408653497696, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 101160, "time": 5025.5338797569275, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 101272, "time": 5031.125102996826, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 101856, "time": 5052.674196958542, "episode/length": 231.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9698275862068966, "episode/intrinsic_return": 0.0}
{"step": 101936, "time": 5057.226560592651, "episode/length": 204.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 102232, "time": 5068.6704251766205, "episode/length": 175.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 102360, "time": 5074.556933641434, "episode/length": 260.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 102368, "time": 5076.630393981934, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9536423841059603, "episode/intrinsic_return": 0.0}
{"step": 102520, "time": 5083.105465888977, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 102576, "time": 5086.987561225891, "episode/length": 162.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 103144, "time": 5107.51330947876, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 103312, "time": 5115.068465709686, "episode/length": 270.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.981549815498155, "episode/intrinsic_return": 0.0}
{"step": 103432, "time": 5121.152488946915, "episode/length": 186.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 103880, "time": 5137.914171218872, "episode/length": 169.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 103936, "time": 5141.734485626221, "episode/length": 196.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 103968, "time": 5144.424110412598, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 104064, "time": 5149.45943069458, "episode/length": 93.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9361702127659575, "episode/intrinsic_return": 0.0}
{"step": 104328, "time": 5159.72229552269, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 104504, "time": 5167.342968702316, "episode/length": 283.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9823943661971831, "episode/intrinsic_return": 0.0}
{"step": 105104, "time": 5189.574150562286, "episode/length": 244.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 105184, "time": 5193.890834331512, "episode/length": 162.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 105440, "time": 5204.399839401245, "episode/length": 187.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 105472, "time": 5207.228772640228, "episode/length": 175.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 105512, "time": 5209.943224191666, "episode/length": 259.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 105568, "time": 5213.67632484436, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 105616, "time": 5216.935799837112, "episode/length": 205.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 105928, "time": 5228.872135400772, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 106640, "time": 5256.171125173569, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 106736, "time": 5261.141482830048, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 106824, "time": 5265.430564403534, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 106904, "time": 5270.045943260193, "episode/length": 178.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 106968, "time": 5273.839217185974, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 107128, "time": 5280.883282184601, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 107264, "time": 5287.372451782227, "episode/length": 44.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 107296, "time": 5289.931608915329, "episode/length": 209.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 107632, "time": 5303.006274223328, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 107801, "time": 5311.059875488281, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.7105884693287035, "train/action_min": 0.0, "train/action_std": 3.0000378908934415, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05137345710838283, "train/actor_opt_grad_steps": 5970.0, "train/actor_opt_loss": 6.902071043407475, "train/adv_mag": 1.2576813287205166, "train/adv_max": 1.254271607045774, "train/adv_mean": 0.0076433136154971885, "train/adv_min": -0.5633596625592974, "train/adv_std": 0.0997612405706335, "train/cont_avg": 0.9943142361111111, "train/cont_loss_mean": 0.0007357612031211357, "train/cont_loss_std": 0.01871937080634409, "train/cont_neg_acc": 0.9739535587805289, "train/cont_neg_loss": 0.08172917254587278, "train/cont_pos_acc": 0.9999199783360516, "train/cont_pos_loss": 0.0002615783880946344, "train/cont_pred": 0.9943527084809762, "train/cont_rate": 0.9943142361111111, "train/dyn_loss_mean": 10.747898243091724, "train/dyn_loss_std": 8.180660827071579, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.341394008088995, "train/extr_critic_critic_opt_grad_steps": 5970.0, "train/extr_critic_critic_opt_loss": 14773.491811342592, "train/extr_critic_mag": 3.3761943146034525, "train/extr_critic_max": 3.3761943146034525, "train/extr_critic_mean": 0.7684256065774847, "train/extr_critic_min": -0.17464954411541975, "train/extr_critic_std": 0.7721793366803064, "train/extr_return_normed_mag": 2.3702828177699335, "train/extr_return_normed_max": 2.3702828177699335, "train/extr_return_normed_mean": 0.35100100426762193, "train/extr_return_normed_min": -0.22046604184088883, "train/extr_return_normed_std": 0.34864600974100607, "train/extr_return_rate": 0.4529895093705919, "train/extr_return_raw_mag": 5.622800298973366, "train/extr_return_raw_max": 5.622800298973366, "train/extr_return_raw_mean": 0.7868288245466021, "train/extr_return_raw_min": -0.5812480757633846, "train/extr_return_raw_std": 0.8343481399394848, "train/extr_reward_mag": 1.0102154078306975, "train/extr_reward_max": 1.0102154078306975, "train/extr_reward_mean": 0.015136332404627292, "train/extr_reward_min": -0.3724498139487373, "train/extr_reward_std": 0.1037361469257761, "train/image_loss_mean": 16.234569938094527, "train/image_loss_std": 17.444759001555266, "train/model_loss_mean": 22.735782722190574, "train/model_loss_std": 20.945227114359536, "train/model_opt_grad_norm": 101.10989049275716, "train/model_opt_grad_steps": 5960.62962962963, "train/model_opt_loss": 15677.982371238426, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 685.1851851851852, "train/policy_entropy_mag": 2.505283389268098, "train/policy_entropy_max": 2.505283389268098, "train/policy_entropy_mean": 0.7405415137608846, "train/policy_entropy_min": 0.0793887628449334, "train/policy_entropy_std": 0.5583677483929528, "train/policy_logprob_mag": 7.438277862690113, "train/policy_logprob_max": -0.009458086694832201, "train/policy_logprob_mean": -0.7398717222390352, "train/policy_logprob_min": -7.438277862690113, "train/policy_logprob_std": 1.1935041286327221, "train/policy_randomness_mag": 0.8842550966474745, "train/policy_randomness_max": 0.8842550966474745, "train/policy_randomness_mean": 0.261378656162156, "train/policy_randomness_min": 0.028020749379087377, "train/policy_randomness_std": 0.19707931335325593, "train/post_ent_mag": 49.07632166544597, "train/post_ent_max": 49.07632166544597, "train/post_ent_mean": 35.50503890426071, "train/post_ent_min": 19.632473910296405, "train/post_ent_std": 4.8446247206793895, "train/prior_ent_mag": 62.6423183299877, "train/prior_ent_max": 62.6423183299877, "train/prior_ent_mean": 46.39348189742477, "train/prior_ent_min": 23.716239872685186, "train/prior_ent_std": 7.088020829801207, "train/rep_loss_mean": 10.747898243091724, "train/rep_loss_std": 8.180660827071579, "train/reward_avg": 0.013980758169458972, "train/reward_loss_mean": 0.05173807911298893, "train/reward_loss_std": 0.2723023290987368, "train/reward_max_data": 1.0140740774295949, "train/reward_max_pred": 1.003942985004849, "train/reward_neg_acc": 0.9943421284357706, "train/reward_neg_loss": 0.03217201431592306, "train/reward_pos_acc": 0.9303672781697025, "train/reward_pos_loss": 1.0571135935959992, "train/reward_pred": 0.012837392481526842, "train/reward_rate": 0.01908275462962963, "train_stats/sum_log_reward": 3.865217311291591, "train_stats/max_log_achievement_collect_drink": 7.660869565217391, "train_stats/max_log_achievement_collect_sapling": 2.582608695652174, "train_stats/max_log_achievement_collect_wood": 1.9652173913043478, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.2608695652173913, "train_stats/max_log_achievement_eat_cow": 0.06956521739130435, "train_stats/max_log_achievement_make_wood_pickaxe": 0.008695652173913044, "train_stats/max_log_achievement_make_wood_sword": 0.008695652173913044, "train_stats/max_log_achievement_place_plant": 2.417391304347826, "train_stats/max_log_achievement_place_table": 0.41739130434782606, "train_stats/max_log_achievement_wake_up": 1.5130434782608695, "train_stats/mean_log_entropy": 0.7585868299007416, "eval_stats/sum_log_reward": 4.474999845027924, "eval_stats/max_log_achievement_collect_drink": 6.375, "eval_stats/max_log_achievement_collect_sapling": 2.8125, "eval_stats/max_log_achievement_collect_wood": 2.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.6875, "eval_stats/max_log_achievement_place_table": 0.4375, "eval_stats/max_log_achievement_wake_up": 1.8125, "eval_stats/mean_log_entropy": 0.0, "eval_stats/max_log_achievement_collect_stone": 1.0, "train_stats/max_log_achievement_collect_stone": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 8.515786612406373e-05, "report/cont_loss_std": 0.0023274102713912725, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00027128393412567675, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.406085544265807e-05, "report/cont_pred": 0.9940613508224487, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 11.673163414001465, "report/dyn_loss_std": 8.202620506286621, "report/image_loss_mean": 15.664247512817383, "report/image_loss_std": 17.3568172454834, "report/model_loss_mean": 22.71607208251953, "report/model_loss_std": 20.838790893554688, "report/post_ent_mag": 48.21091079711914, "report/post_ent_max": 48.21091079711914, "report/post_ent_mean": 36.42328643798828, "report/post_ent_min": 19.904626846313477, "report/post_ent_std": 4.900790691375732, "report/prior_ent_mag": 62.71186828613281, "report/prior_ent_max": 62.71186828613281, "report/prior_ent_mean": 48.193199157714844, "report/prior_ent_min": 22.411739349365234, "report/prior_ent_std": 7.038763046264648, "report/rep_loss_mean": 11.673163414001465, "report/rep_loss_std": 8.202620506286621, "report/reward_avg": 0.01376953162252903, "report/reward_loss_mean": 0.047840364277362823, "report/reward_loss_std": 0.23315754532814026, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.003098726272583, "report/reward_neg_acc": 0.9960159659385681, "report/reward_neg_loss": 0.02934408001601696, "report/reward_pos_acc": 0.9000000357627869, "report/reward_pos_loss": 0.9763540625572205, "report/reward_pred": 0.012169891968369484, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 3.1142408261075616e-05, "eval/cont_loss_std": 0.00040208332939073443, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 8.99873975868104e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.125105649814941e-05, "eval/cont_pred": 0.9950862526893616, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.385963439941406, "eval/dyn_loss_std": 10.98800277709961, "eval/image_loss_mean": 31.129579544067383, "eval/image_loss_std": 29.001745223999023, "eval/model_loss_mean": 41.718570709228516, "eval/model_loss_std": 33.7557373046875, "eval/post_ent_mag": 47.75821304321289, "eval/post_ent_max": 47.75821304321289, "eval/post_ent_mean": 33.810638427734375, "eval/post_ent_min": 21.061752319335938, "eval/post_ent_std": 4.705805778503418, "eval/prior_ent_mag": 62.71186828613281, "eval/prior_ent_max": 62.71186828613281, "eval/prior_ent_mean": 47.15208435058594, "eval/prior_ent_min": 24.179277420043945, "eval/prior_ent_std": 8.273454666137695, "eval/rep_loss_mean": 17.385963439941406, "eval/rep_loss_std": 10.98800277709961, "eval/reward_avg": 0.014453125186264515, "eval/reward_loss_mean": 0.15738022327423096, "eval/reward_loss_std": 0.8532808423042297, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0116100311279297, "eval/reward_neg_acc": 0.9930348992347717, "eval/reward_neg_loss": 0.09865265339612961, "eval/reward_pos_acc": 0.6315789222717285, "eval/reward_pos_loss": 3.2637598514556885, "eval/reward_pred": 0.009637190960347652, "eval/reward_rate": 0.0185546875, "replay/size": 107297.0, "replay/inserts": 21600.0, "replay/samples": 21600.0, "replay/insert_wait_avg": 1.4300809966193306e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.833518734684697e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 22168.0, "eval_replay/inserts": 3744.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3415502686785837e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0140571594238, "timer/env.step_count": 2700.0, "timer/env.step_total": 260.8460216522217, "timer/env.step_frac": 0.2608423549496537, "timer/env.step_avg": 0.09660963764897099, "timer/env.step_min": 0.023646116256713867, "timer/env.step_max": 2.3459079265594482, "timer/replay._sample_count": 21600.0, "timer/replay._sample_total": 12.005594968795776, "timer/replay._sample_frac": 0.012005426206605638, "timer/replay._sample_avg": 0.0005558145818886933, "timer/replay._sample_min": 0.0003879070281982422, "timer/replay._sample_max": 0.03342294692993164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3168.0, "timer/agent.policy_total": 54.70642280578613, "timer/agent.policy_frac": 0.05470565379968929, "timer/agent.policy_avg": 0.01726844154223047, "timer/agent.policy_min": 0.009674310684204102, "timer/agent.policy_max": 0.0939490795135498, "timer/dataset_train_count": 1350.0, "timer/dataset_train_total": 0.15587568283081055, "timer/dataset_train_frac": 0.00015587349169228788, "timer/dataset_train_avg": 0.00011546346876356337, "timer/dataset_train_min": 0.00010156631469726562, "timer/dataset_train_max": 0.0004773139953613281, "timer/agent.train_count": 1350.0, "timer/agent.train_total": 612.4310467243195, "timer/agent.train_frac": 0.6124224378044765, "timer/agent.train_avg": 0.4536526272031996, "timer/agent.train_min": 0.43966245651245117, "timer/agent.train_max": 1.5301129817962646, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4684758186340332, "timer/agent.report_frac": 0.00046846923328733574, "timer/agent.report_avg": 0.2342379093170166, "timer/agent.report_min": 0.22320246696472168, "timer/agent.report_max": 0.24527335166931152, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.1470810051212165e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 21.599411394328364}
{"step": 108152, "time": 5322.811563253403, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 108200, "time": 5326.150365829468, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 108224, "time": 5328.89143705368, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9542857142857143, "episode/intrinsic_return": 0.0}
{"step": 108376, "time": 5335.394705057144, "episode/length": 216.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 108496, "time": 5341.332991838455, "episode/length": 36.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 108552, "time": 5344.655752658844, "episode/length": 177.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 108616, "time": 5348.396683692932, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 108624, "time": 5350.478849887848, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 109200, "time": 5371.731612205505, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 109472, "time": 5382.620013475418, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 109592, "time": 5388.117172956467, "episode/length": 179.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 109704, "time": 5393.475349664688, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 109808, "time": 5399.000033378601, "episode/length": 156.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 109824, "time": 5401.126456975937, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 109824, "time": 5401.134474515915, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 5428.945818424225, "eval_episode/length": 92.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.946236559139785}
{"step": 110032, "time": 5433.23694062233, "eval_episode/length": 151.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 110032, "time": 5434.896398305893, "eval_episode/length": 152.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 110032, "time": 5436.727470636368, "eval_episode/length": 158.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 110032, "time": 5438.886413574219, "eval_episode/length": 169.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 110032, "time": 5440.722442626953, "eval_episode/length": 174.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 110032, "time": 5443.059145689011, "eval_episode/length": 192.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 110032, "time": 5445.243780136108, "eval_episode/length": 32.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 110128, "time": 5448.608459234238, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 110488, "time": 5461.974835634232, "episode/length": 160.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 110752, "time": 5472.77664232254, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 110872, "time": 5478.3571009635925, "episode/length": 130.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9465648854961832, "episode/intrinsic_return": 0.0}
{"step": 110936, "time": 5482.123201847076, "episode/length": 138.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 111080, "time": 5488.5716717243195, "episode/length": 40.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 111112, "time": 5491.341357469559, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 111256, "time": 5497.8276262283325, "episode/length": 207.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 111336, "time": 5502.131069421768, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 111392, "time": 5505.882811784744, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 112272, "time": 5537.370751142502, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 112344, "time": 5541.175048351288, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 112640, "time": 5553.126098871231, "episode/length": 45.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 112648, "time": 5554.725485086441, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 112656, "time": 5556.822110414505, "episode/length": 192.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 112672, "time": 5559.0568063259125, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 112712, "time": 5561.721650123596, "episode/length": 277.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9856115107913669, "episode/intrinsic_return": 0.0}
{"step": 112712, "time": 5561.730369567871, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 112968, "time": 5573.920713663101, "episode/length": 38.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 113120, "time": 5580.892724990845, "episode/length": 280.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9857651245551602, "episode/intrinsic_return": 0.0}
{"step": 113696, "time": 5601.810870409012, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 114288, "time": 5624.068342447281, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 114304, "time": 5626.352554559708, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 114312, "time": 5628.039571762085, "episode/length": 199.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 114344, "time": 5630.69983959198, "episode/length": 152.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 114376, "time": 5633.324897289276, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 114400, "time": 5636.01176071167, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 114472, "time": 5639.8618104457855, "episode/length": 224.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 114656, "time": 5647.755078315735, "episode/length": 34.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 115104, "time": 5665.845530509949, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 115112, "time": 5667.518613576889, "episode/length": 56.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9122807017543859, "episode/intrinsic_return": 0.0}
{"step": 115632, "time": 5687.084876775742, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 115632, "time": 5687.092516422272, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 115696, "time": 5692.915652751923, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 115816, "time": 5698.27108335495, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 116024, "time": 5706.903057575226, "episode/length": 216.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9861751152073732, "episode/intrinsic_return": 0.0}
{"step": 116104, "time": 5711.261786937714, "episode/length": 35.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8611111111111112, "episode/intrinsic_return": 0.0}
{"step": 116224, "time": 5717.207279682159, "episode/length": 238.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 116400, "time": 5724.773542404175, "episode/length": 46.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8936170212765957, "episode/intrinsic_return": 0.0}
{"step": 116408, "time": 5726.521545886993, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 116656, "time": 5736.695136547089, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 116768, "time": 5742.142931938171, "episode/length": 133.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 116824, "time": 5745.409624814987, "episode/length": 148.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9530201342281879, "episode/intrinsic_return": 0.0}
{"step": 116872, "time": 5748.852408885956, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 117544, "time": 5773.378186225891, "episode/length": 141.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 117776, "time": 5783.179794311523, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 117792, "time": 5785.371945619583, "episode/length": 141.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 117808, "time": 5787.56746172905, "episode/length": 175.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 117864, "time": 5790.890031337738, "episode/length": 219.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 118128, "time": 5801.622705221176, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 118360, "time": 5811.092457532883, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 118376, "time": 5813.174647808075, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 118992, "time": 5835.917269229889, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 119144, "time": 5842.680918455124, "episode/length": 170.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 119152, "time": 5844.8685920238495, "episode/length": 160.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 119240, "time": 5849.123633861542, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 119464, "time": 5858.601905345917, "episode/length": 39.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 119752, "time": 5870.10653424263, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 119784, "time": 5872.936912536621, "episode/length": 279.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 119832, "time": 5876.120434045792, "episode/length": 73.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.918918918918919, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 5884.076058387756, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 5905.764931201935, "eval_episode/length": 132.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9924812030075187}
{"step": 120016, "time": 5908.998588085175, "eval_episode/length": 168.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 120016, "time": 5911.248314380646, "eval_episode/length": 180.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 120016, "time": 5912.931123256683, "eval_episode/length": 182.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 120016, "time": 5915.167388677597, "eval_episode/length": 196.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 120016, "time": 5918.959562540054, "eval_episode/length": 247.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9798387096774194}
{"step": 120016, "time": 5921.498580217361, "eval_episode/length": 265.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9962406015037594}
{"step": 120016, "time": 5924.580966949463, "eval_episode/length": 52.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 120104, "time": 5929.005923986435, "episode/length": 246.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 120432, "time": 5941.90399813652, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 120496, "time": 5945.641939640045, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 120768, "time": 5956.661933898926, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 121160, "time": 5971.330315589905, "episode/length": 171.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 121264, "time": 5976.659923553467, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 121264, "time": 5976.667970895767, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 121480, "time": 5987.295902013779, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 121552, "time": 5991.655554771423, "episode/length": 35.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 121648, "time": 5996.565887928009, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 121888, "time": 6006.3168132305145, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 122048, "time": 6013.250064134598, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 122112, "time": 6017.019041776657, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 122328, "time": 6025.804370880127, "episode/length": 34.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 122480, "time": 6032.696359395981, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 122776, "time": 6044.142197370529, "episode/length": 36.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 122952, "time": 6053.256852865219, "episode/length": 104.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9428571428571428, "episode/intrinsic_return": 0.0}
{"step": 122960, "time": 6055.841572999954, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 123088, "time": 6062.24512052536, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 123104, "time": 6064.429193735123, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 123200, "time": 6069.44669675827, "episode/length": 254.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 123336, "time": 6075.425339221954, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 123720, "time": 6090.138939380646, "episode/length": 94.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 123896, "time": 6097.549320936203, "episode/length": 195.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 124176, "time": 6109.057921886444, "episode/length": 34.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8857142857142857, "episode/intrinsic_return": 0.0}
{"step": 124184, "time": 6110.580147266388, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 124464, "time": 6121.8280255794525, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 124512, "time": 6125.205976486206, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 124528, "time": 6127.498949050903, "episode/length": 42.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9069767441860465, "episode/intrinsic_return": 0.0}
{"step": 124960, "time": 6143.872707366943, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 125008, "time": 6147.157782316208, "episode/length": 225.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 125040, "time": 6149.889061927795, "episode/length": 107.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 125064, "time": 6152.064719676971, "episode/length": 246.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 125232, "time": 6159.642574071884, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 125536, "time": 6171.579664707184, "episode/length": 133.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9552238805970149, "episode/intrinsic_return": 0.0}
{"step": 125808, "time": 6182.452951192856, "episode/length": 159.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 126104, "time": 6193.989181518555, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 126248, "time": 6200.66445350647, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 126360, "time": 6206.107670783997, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 126512, "time": 6213.0261054039, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 126568, "time": 6216.336290597916, "episode/length": 187.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 126736, "time": 6223.730362415314, "episode/length": 115.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9568965517241379, "episode/intrinsic_return": 0.0}
{"step": 126872, "time": 6229.8002846241, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 126880, "time": 6231.933030843735, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 128152, "time": 6276.440722942352, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 128216, "time": 6280.280505895615, "episode/length": 263.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.0}
{"step": 128256, "time": 6283.474182605743, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 128288, "time": 6286.437792778015, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 128296, "time": 6288.000613689423, "episode/length": 255.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 128632, "time": 6301.663824558258, "episode/length": 257.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 128680, "time": 6304.847314596176, "episode/length": 270.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 128793, "time": 6311.2804844379425, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.384938014372614, "train/action_min": 0.0, "train/action_std": 2.717416333788224, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05079252682341874, "train/actor_opt_grad_steps": 7300.0, "train/actor_opt_loss": 8.01579820245277, "train/adv_mag": 1.000021530016688, "train/adv_max": 0.998206561758318, "train/adv_mean": 0.006535996316158668, "train/adv_min": -0.5537268694575507, "train/adv_std": 0.08921279960119997, "train/cont_avg": 0.9941704437022901, "train/cont_loss_mean": 0.0004801590294257997, "train/cont_loss_std": 0.012676245605057687, "train/cont_neg_acc": 0.981094756426702, "train/cont_neg_loss": 0.05494352154701535, "train/cont_pos_acc": 0.9999399904076379, "train/cont_pos_loss": 0.00015360827515781739, "train/cont_pred": 0.9942180396036338, "train/cont_rate": 0.9941704437022901, "train/dyn_loss_mean": 11.94495411501586, "train/dyn_loss_std": 8.672018866502603, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.23659983254571, "train/extr_critic_critic_opt_grad_steps": 7300.0, "train/extr_critic_critic_opt_loss": 15150.552488370706, "train/extr_critic_mag": 3.9875936435379145, "train/extr_critic_max": 3.9875936435379145, "train/extr_critic_mean": 0.8806251885781762, "train/extr_critic_min": -0.20800333441668795, "train/extr_critic_std": 0.8779092886065709, "train/extr_return_normed_mag": 2.1446259194658004, "train/extr_return_normed_max": 2.1446259194658004, "train/extr_return_normed_mean": 0.3646189855937739, "train/extr_return_normed_min": -0.2187065750872361, "train/extr_return_normed_std": 0.35307557437256093, "train/extr_return_rate": 0.521145464354799, "train/extr_return_raw_mag": 5.5685477165775445, "train/extr_return_raw_max": 5.5685477165775445, "train/extr_return_raw_mean": 0.8977295346842468, "train/extr_return_raw_min": -0.6336846475610296, "train/extr_return_raw_std": 0.927400671343767, "train/extr_reward_mag": 1.0119469411500537, "train/extr_reward_max": 1.0119469411500537, "train/extr_reward_mean": 0.017562872680430195, "train/extr_reward_min": -0.38034949593871603, "train/extr_reward_std": 0.11519904309556685, "train/image_loss_mean": 14.394668484462127, "train/image_loss_std": 15.866111078335129, "train/model_loss_mean": 21.61442182264255, "train/model_loss_std": 19.64668201126215, "train/model_opt_grad_norm": 89.79212002353813, "train/model_opt_grad_steps": 7289.412213740458, "train/model_opt_loss": 13809.312015446088, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 644.0839694656488, "train/policy_entropy_mag": 2.3897121717001646, "train/policy_entropy_max": 2.3897121717001646, "train/policy_entropy_mean": 0.6271467980082709, "train/policy_entropy_min": 0.07937908451293262, "train/policy_entropy_std": 0.4942912245524749, "train/policy_logprob_mag": 7.438338894880455, "train/policy_logprob_max": -0.009456608600857603, "train/policy_logprob_mean": -0.6261068227636906, "train/policy_logprob_min": -7.438338894880455, "train/policy_logprob_std": 1.1147430552781084, "train/policy_randomness_mag": 0.8434635277922827, "train/policy_randomness_max": 0.8434635277922827, "train/policy_randomness_mean": 0.221355298775753, "train/policy_randomness_min": 0.028017333374564884, "train/policy_randomness_std": 0.17446311091193717, "train/post_ent_mag": 50.771272178824624, "train/post_ent_max": 50.771272178824624, "train/post_ent_mean": 36.49995241820357, "train/post_ent_min": 20.160435341696704, "train/post_ent_std": 5.2280493947385835, "train/prior_ent_mag": 64.09991070696415, "train/prior_ent_max": 64.09991070696415, "train/prior_ent_mean": 48.647374742813696, "train/prior_ent_min": 25.214030971963897, "train/prior_ent_std": 7.053733388886197, "train/rep_loss_mean": 11.94495411501586, "train/rep_loss_std": 8.672018866502603, "train/reward_avg": 0.014463561416411672, "train/reward_loss_mean": 0.05230073256858887, "train/reward_loss_std": 0.2681658959570732, "train/reward_max_data": 1.011450384409373, "train/reward_max_pred": 1.004291231395634, "train/reward_neg_acc": 0.9940811231846117, "train/reward_neg_loss": 0.03332381460190047, "train/reward_pos_acc": 0.9362670933927288, "train/reward_pos_loss": 1.0042199419654962, "train/reward_pred": 0.013772226976699957, "train/reward_rate": 0.019650524809160304, "train_stats/sum_log_reward": 3.879527493138013, "train_stats/max_log_achievement_collect_drink": 6.275590551181103, "train_stats/max_log_achievement_collect_sapling": 2.5196850393700787, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.4803149606299213, "train_stats/max_log_achievement_defeat_skeleton": 0.007874015748031496, "train_stats/max_log_achievement_defeat_zombie": 0.15748031496062992, "train_stats/max_log_achievement_eat_cow": 0.07874015748031496, "train_stats/max_log_achievement_make_wood_pickaxe": 0.015748031496062992, "train_stats/max_log_achievement_make_wood_sword": 0.007874015748031496, "train_stats/max_log_achievement_place_plant": 2.2992125984251968, "train_stats/max_log_achievement_place_table": 0.8818897637795275, "train_stats/max_log_achievement_wake_up": 1.236220472440945, "train_stats/mean_log_entropy": 0.5992603834689133, "eval_stats/sum_log_reward": 3.912499975413084, "eval_stats/max_log_achievement_collect_drink": 5.5, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5625, "eval_stats/max_log_achievement_place_table": 0.8125, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.00014298688620328903, "report/cont_loss_std": 0.0030868661124259233, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003150994598399848, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00014180222933646291, "report/cont_pred": 0.9930300712585449, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.384615898132324, "report/dyn_loss_std": 9.261778831481934, "report/image_loss_mean": 15.209156036376953, "report/image_loss_std": 20.769739151000977, "report/model_loss_mean": 23.30236053466797, "report/model_loss_std": 24.769065856933594, "report/post_ent_mag": 51.5308837890625, "report/post_ent_max": 51.5308837890625, "report/post_ent_mean": 38.67546844482422, "report/post_ent_min": 21.341094970703125, "report/post_ent_std": 4.999044418334961, "report/prior_ent_mag": 65.622314453125, "report/prior_ent_max": 65.622314453125, "report/prior_ent_mean": 52.32172775268555, "report/prior_ent_min": 34.0588493347168, "report/prior_ent_std": 5.800812721252441, "report/rep_loss_mean": 13.384615898132324, "report/rep_loss_std": 9.261778831481934, "report/reward_avg": 0.01494140550494194, "report/reward_loss_mean": 0.06229381263256073, "report/reward_loss_std": 0.30228593945503235, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0031254291534424, "report/reward_neg_acc": 0.9980059862136841, "report/reward_neg_loss": 0.041996609419584274, "report/reward_pos_acc": 0.9523809552192688, "report/reward_pos_loss": 1.0317269563674927, "report/reward_pred": 0.010821053758263588, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.007842330262064934, "eval/cont_loss_std": 0.24381081759929657, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0002596910926513374, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.00786461029201746, "eval/cont_pred": 0.9958820939064026, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.461999893188477, "eval/dyn_loss_std": 9.714521408081055, "eval/image_loss_mean": 33.51148223876953, "eval/image_loss_std": 34.14152908325195, "eval/model_loss_mean": 43.54234313964844, "eval/model_loss_std": 38.068634033203125, "eval/post_ent_mag": 50.338409423828125, "eval/post_ent_max": 50.338409423828125, "eval/post_ent_mean": 36.852054595947266, "eval/post_ent_min": 21.881103515625, "eval/post_ent_std": 5.645697116851807, "eval/prior_ent_mag": 65.622314453125, "eval/prior_ent_max": 65.622314453125, "eval/prior_ent_mean": 50.61194610595703, "eval/prior_ent_min": 26.69568634033203, "eval/prior_ent_std": 7.740251064300537, "eval/rep_loss_mean": 16.461999893188477, "eval/rep_loss_std": 9.714521408081055, "eval/reward_avg": 0.01181640662252903, "eval/reward_loss_mean": 0.14581964910030365, "eval/reward_loss_std": 0.9446657299995422, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.003204107284546, "eval/reward_neg_acc": 0.9960356950759888, "eval/reward_neg_loss": 0.06999137252569199, "eval/reward_pos_acc": 0.40000003576278687, "eval/reward_pos_loss": 5.246535301208496, "eval/reward_pred": 0.003744592657312751, "eval/reward_rate": 0.0146484375, "replay/size": 128289.0, "replay/inserts": 20992.0, "replay/samples": 20992.0, "replay/insert_wait_avg": 1.4268770450498999e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.047798812389374e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 26240.0, "eval_replay/inserts": 4072.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3268766796659159e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2030658721924, "timer/env.step_count": 2624.0, "timer/env.step_total": 279.8205952644348, "timer/env.step_frac": 0.2797637847874691, "timer/env.step_avg": 0.10663894636601937, "timer/env.step_min": 0.023452281951904297, "timer/env.step_max": 3.67789626121521, "timer/replay._sample_count": 20992.0, "timer/replay._sample_total": 11.7926607131958, "timer/replay._sample_frac": 0.011790266512443071, "timer/replay._sample_avg": 0.0005617692794014768, "timer/replay._sample_min": 0.00039076805114746094, "timer/replay._sample_max": 0.012471914291381836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3133.0, "timer/agent.policy_total": 55.14377999305725, "timer/agent.policy_frac": 0.05513258444671036, "timer/agent.policy_avg": 0.017600951162801547, "timer/agent.policy_min": 0.009624719619750977, "timer/agent.policy_max": 0.13310456275939941, "timer/dataset_train_count": 1312.0, "timer/dataset_train_total": 0.15232038497924805, "timer/dataset_train_frac": 0.00015228946018718944, "timer/dataset_train_avg": 0.00011609785440491467, "timer/dataset_train_min": 0.0001010894775390625, "timer/dataset_train_max": 0.00027632713317871094, "timer/agent.train_count": 1312.0, "timer/agent.train_total": 595.3034100532532, "timer/agent.train_frac": 0.5951825487898694, "timer/agent.train_avg": 0.45373735522351616, "timer/agent.train_min": 0.43947553634643555, "timer/agent.train_max": 1.375011682510376, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47435879707336426, "timer/agent.report_frac": 0.0004742624905470732, "timer/agent.report_avg": 0.23717939853668213, "timer/agent.report_min": 0.22973871231079102, "timer/agent.report_max": 0.24462008476257324, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.8366050736252526e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 20.987467115733494}
{"step": 128832, "time": 6312.699289560318, "episode/length": 308.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 129240, "time": 6327.9498970508575, "episode/length": 135.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 129480, "time": 6337.726509332657, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 129560, "time": 6342.1897802352905, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 129584, "time": 6344.916100025177, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 129656, "time": 6348.796464681625, "episode/length": 170.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 129816, "time": 6355.783947229385, "episode/length": 147.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 6384.021612167358, "eval_episode/length": 152.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 130000, "time": 6387.047640323639, "eval_episode/length": 184.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 130000, "time": 6388.773354053497, "eval_episode/length": 186.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9625668449197861}
{"step": 130000, "time": 6391.4342250823975, "eval_episode/length": 207.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 130000, "time": 6393.785432577133, "eval_episode/length": 221.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 130000, "time": 6395.494097709656, "eval_episode/length": 37.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 130000, "time": 6397.685105085373, "eval_episode/length": 238.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.99581589958159}
{"step": 130000, "time": 6400.5928835868835, "eval_episode/length": 267.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9888059701492538}
{"step": 130224, "time": 6408.338272809982, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 130648, "time": 6424.0241487026215, "episode/length": 245.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 130840, "time": 6432.205593109131, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 130872, "time": 6434.823676109314, "episode/length": 203.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 130920, "time": 6438.243538856506, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 131120, "time": 6448.210832357407, "episode/length": 182.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 132024, "time": 6480.295279502869, "episode/length": 317.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9842767295597484, "episode/intrinsic_return": 0.0}
{"step": 132224, "time": 6489.043778657913, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 132240, "time": 6491.666016340256, "episode/length": 174.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 132240, "time": 6491.674244642258, "episode/length": 170.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 132456, "time": 6502.098463058472, "episode/length": 278.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.0}
{"step": 132512, "time": 6505.744923114777, "episode/length": 33.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 132600, "time": 6510.095140695572, "episode/length": 243.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 132696, "time": 6514.8044974803925, "episode/length": 359.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 133480, "time": 6543.122043371201, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 133624, "time": 6549.680269002914, "episode/length": 312.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9840255591054313, "episode/intrinsic_return": 0.0}
{"step": 133752, "time": 6555.670698165894, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 133792, "time": 6558.952055215836, "episode/length": 193.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 133944, "time": 6565.451313018799, "episode/length": 178.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 134128, "time": 6573.568274736404, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 134288, "time": 6580.581348180771, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 134704, "time": 6596.433480024338, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 134872, "time": 6603.584347724915, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 134960, "time": 6608.285385131836, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 135360, "time": 6623.474328756332, "episode/length": 195.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 135472, "time": 6628.841381549835, "episode/length": 430.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 135536, "time": 6632.666544914246, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 135960, "time": 6648.597723484039, "episode/length": 228.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 136032, "time": 6652.894678354263, "episode/length": 217.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 136104, "time": 6656.664125919342, "episode/length": 174.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 136432, "time": 6669.625261068344, "episode/length": 183.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 136640, "time": 6678.3757247924805, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 136688, "time": 6681.605410814285, "episode/length": 226.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 136840, "time": 6688.30068731308, "episode/length": 170.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 136952, "time": 6693.86953163147, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 137440, "time": 6712.401120185852, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 137544, "time": 6717.288182258606, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 137696, "time": 6724.218672275543, "episode/length": 207.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 137808, "time": 6729.6618666648865, "episode/length": 139.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 137816, "time": 6731.226054906845, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 137824, "time": 6733.319010019302, "episode/length": 47.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 137896, "time": 6737.315103054047, "episode/length": 24.0, "episode/score": 2.1000000163912773, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 138152, "time": 6747.587493896484, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 138208, "time": 6751.348358392715, "episode/length": 156.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 138448, "time": 6760.997092247009, "episode/length": 225.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 139096, "time": 6784.3148493766785, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 139352, "time": 6795.954945325851, "episode/length": 225.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 139440, "time": 6801.253070116043, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 139608, "time": 6808.325674057007, "episode/length": 222.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 139896, "time": 6819.706359624863, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 139928, "time": 6822.39114522934, "episode/length": 253.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 139928, "time": 6822.4008684158325, "episode/length": 264.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9773584905660377, "episode/intrinsic_return": 0.0}
{"step": 139976, "time": 6827.520082950592, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9909502262443439, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 6852.7529220581055, "eval_episode/length": 146.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9659863945578231}
{"step": 140088, "time": 6857.220633029938, "eval_episode/length": 205.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.970873786407767}
{"step": 140088, "time": 6859.550416231155, "eval_episode/length": 220.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9728506787330317}
{"step": 140088, "time": 6861.524873018265, "eval_episode/length": 227.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 140088, "time": 6864.109211206436, "eval_episode/length": 249.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.98}
{"step": 140088, "time": 6865.792196035385, "eval_episode/length": 251.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 140088, "time": 6867.631988286972, "eval_episode/length": 34.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 140088, "time": 6869.811831712723, "eval_episode/length": 268.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9962825278810409}
{"step": 140664, "time": 6889.322271823883, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 141088, "time": 6905.351497888565, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 141160, "time": 6909.165286779404, "episode/length": 257.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 141168, "time": 6911.322282791138, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 141224, "time": 6914.578587770462, "episode/length": 161.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 141496, "time": 6925.41526222229, "episode/length": 189.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 141504, "time": 6927.5022575855255, "episode/length": 200.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 141856, "time": 6940.8685567379, "episode/length": 280.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9857651245551602, "episode/intrinsic_return": 0.0}
{"step": 142048, "time": 6949.020193338394, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 142480, "time": 6965.129929304123, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 142904, "time": 6981.003979444504, "episode/length": 217.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 142960, "time": 6984.622777938843, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 143080, "time": 6990.201461076736, "episode/length": 238.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 143256, "time": 6997.720772266388, "episode/length": 253.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 143256, "time": 6997.729112863541, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 143400, "time": 7006.176931619644, "episode/length": 237.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 143472, "time": 7010.5312666893005, "episode/length": 177.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 143504, "time": 7013.278408765793, "episode/length": 74.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 143768, "time": 7023.337870597839, "episode/length": 160.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 143824, "time": 7027.009933710098, "episode/length": 43.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 144696, "time": 7057.668463945389, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 144824, "time": 7063.763897418976, "episode/length": 131.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 144840, "time": 7065.96862411499, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 145024, "time": 7074.2362060546875, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 145136, "time": 7079.57519865036, "episode/length": 216.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 145168, "time": 7082.2522695064545, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 145384, "time": 7091.050542116165, "episode/length": 265.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 145448, "time": 7094.8688135147095, "episode/length": 310.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9903536977491961, "episode/intrinsic_return": 0.0}
{"step": 146432, "time": 7130.178985357285, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 146480, "time": 7133.3857798576355, "episode/length": 181.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 146496, "time": 7135.423902511597, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 146504, "time": 7137.043086767197, "episode/length": 166.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 146592, "time": 7141.807594060898, "episode/length": 236.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 146848, "time": 7152.19335436821, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 147184, "time": 7165.265867471695, "episode/length": 294.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9864406779661017, "episode/intrinsic_return": 0.0}
{"step": 147640, "time": 7183.621002435684, "episode/length": 56.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9122807017543859, "episode/intrinsic_return": 0.0}
{"step": 147648, "time": 7185.811099052429, "episode/length": 151.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 147720, "time": 7189.844289064407, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 147784, "time": 7193.589567422867, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 147992, "time": 7202.220724821091, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 148216, "time": 7211.418904066086, "episode/length": 27.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8214285714285714, "episode/intrinsic_return": 0.0}
{"step": 148584, "time": 7225.378402709961, "episode/length": 45.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9130434782608695, "episode/intrinsic_return": 0.0}
{"step": 148784, "time": 7233.94348025322, "episode/length": 241.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 148800, "time": 7236.067309856415, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 148896, "time": 7241.385134458542, "episode/length": 146.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 148912, "time": 7243.598717451096, "episode/length": 301.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9867549668874173, "episode/intrinsic_return": 0.0}
{"step": 149152, "time": 7253.498487472534, "episode/length": 470.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9872611464968153, "episode/intrinsic_return": 0.0}
{"step": 149216, "time": 7257.205956220627, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 149272, "time": 7260.5522582530975, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 149944, "time": 7284.897637844086, "episode/length": 90.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9340659340659341, "episode/intrinsic_return": 0.0}
{"step": 150024, "time": 7289.258355140686, "episode/length": 140.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 7312.320548772812, "eval_episode/length": 148.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 150072, "time": 7314.289662599564, "eval_episode/length": 156.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 150072, "time": 7316.801536560059, "eval_episode/length": 176.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 150072, "time": 7318.673615932465, "eval_episode/length": 181.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 150072, "time": 7321.002126932144, "eval_episode/length": 197.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9797979797979798}
{"step": 150072, "time": 7323.218013525009, "eval_episode/length": 211.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9716981132075472}
{"step": 150072, "time": 7324.810366392136, "eval_episode/length": 212.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9906103286384976}
{"step": 150072, "time": 7333.053475856781, "eval_episode/length": 176.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 150073, "time": 7334.074900150299, "train_stats/sum_log_reward": 4.307207152650163, "train_stats/max_log_achievement_collect_drink": 6.7657657657657655, "train_stats/max_log_achievement_collect_sapling": 3.72972972972973, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.6486486486486487, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.24324324324324326, "train_stats/max_log_achievement_eat_cow": 0.0990990990990991, "train_stats/max_log_achievement_make_wood_pickaxe": 0.05405405405405406, "train_stats/max_log_achievement_make_wood_sword": 0.009009009009009009, "train_stats/max_log_achievement_place_plant": 3.3873873873873874, "train_stats/max_log_achievement_place_table": 0.9819819819819819, "train_stats/max_log_achievement_wake_up": 1.5675675675675675, "train_stats/mean_log_entropy": 0.6067350407441457, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.257711998502114, "train/action_min": 0.0, "train/action_std": 2.7340195178985596, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04718612467772082, "train/actor_opt_grad_steps": 8620.0, "train/actor_opt_loss": -4.569836935042439, "train/adv_mag": 0.9189638974971341, "train/adv_max": 0.9105561931330458, "train/adv_mean": 0.004310561632959626, "train/adv_min": -0.5389989011717918, "train/adv_std": 0.0839468503468915, "train/cont_avg": 0.994390272556391, "train/cont_loss_mean": 0.0003020556118638736, "train/cont_loss_std": 0.007813913814211822, "train/cont_neg_acc": 0.9941528389851252, "train/cont_neg_loss": 0.03158021651273829, "train/cont_pos_acc": 0.9999777988383645, "train/cont_pos_loss": 0.00011432415342307523, "train/cont_pred": 0.9943901990589342, "train/cont_rate": 0.994390272556391, "train/dyn_loss_mean": 13.074263357578364, "train/dyn_loss_std": 8.975544578150698, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1825422205423053, "train/extr_critic_critic_opt_grad_steps": 8620.0, "train/extr_critic_critic_opt_loss": 15032.142688263628, "train/extr_critic_mag": 4.414635511269247, "train/extr_critic_max": 4.414635511269247, "train/extr_critic_mean": 0.8531216376258018, "train/extr_critic_min": -0.23230529369268202, "train/extr_critic_std": 0.9015356813158307, "train/extr_return_normed_mag": 2.0229738681836236, "train/extr_return_normed_max": 2.0229738681836236, "train/extr_return_normed_mean": 0.33701440445462566, "train/extr_return_normed_min": -0.1933355868086779, "train/extr_return_normed_std": 0.33754026049509983, "train/extr_return_rate": 0.48447537388568535, "train/extr_return_raw_mag": 5.582365878542563, "train/extr_return_raw_max": 5.582365878542563, "train/extr_return_raw_mean": 0.8651841802704603, "train/extr_return_raw_min": -0.6177272460514441, "train/extr_return_raw_std": 0.9442137022663776, "train/extr_reward_mag": 1.010275015257355, "train/extr_reward_max": 1.010275015257355, "train/extr_reward_mean": 0.01585020338836357, "train/extr_reward_min": -0.4009160645922324, "train/extr_reward_std": 0.11118673331531367, "train/image_loss_mean": 12.69100930995511, "train/image_loss_std": 14.593978985807949, "train/model_loss_mean": 20.588787222267094, "train/model_loss_std": 18.49092662065549, "train/model_opt_grad_norm": 82.00129478856137, "train/model_opt_grad_steps": 8608.052631578947, "train/model_opt_loss": 7975.79269340343, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 390.0375939849624, "train/policy_entropy_mag": 2.490816607511133, "train/policy_entropy_max": 2.490816607511133, "train/policy_entropy_mean": 0.6300049650489836, "train/policy_entropy_min": 0.07937643368889515, "train/policy_entropy_std": 0.5303701440194496, "train/policy_logprob_mag": 7.438367108653362, "train/policy_logprob_max": -0.009456070532139978, "train/policy_logprob_mean": -0.6305366496842607, "train/policy_logprob_min": -7.438367108653362, "train/policy_logprob_std": 1.128534301779324, "train/policy_randomness_mag": 0.8791489542875075, "train/policy_randomness_max": 0.8791489542875075, "train/policy_randomness_mean": 0.22236410578838864, "train/policy_randomness_min": 0.02801639777153058, "train/policy_randomness_std": 0.18719738744255296, "train/post_ent_mag": 52.287552769022774, "train/post_ent_max": 52.287552769022774, "train/post_ent_mean": 37.30790899749985, "train/post_ent_min": 20.917529615244472, "train/post_ent_std": 5.494201782054471, "train/prior_ent_mag": 65.207005923852, "train/prior_ent_max": 65.207005923852, "train/prior_ent_mean": 50.57066207541559, "train/prior_ent_min": 27.311204437026404, "train/prior_ent_std": 6.893792030506564, "train/rep_loss_mean": 13.074263357578364, "train/rep_loss_std": 8.975544578150698, "train/reward_avg": 0.0161624764292711, "train/reward_loss_mean": 0.052917878514617905, "train/reward_loss_std": 0.2672244617365357, "train/reward_max_data": 1.0127819579346735, "train/reward_max_pred": 1.004124224634099, "train/reward_neg_acc": 0.9936720661650923, "train/reward_neg_loss": 0.03232883736211106, "train/reward_pos_acc": 0.9402470333235604, "train/reward_pos_loss": 0.9977884601829643, "train/reward_pred": 0.014959200781672016, "train/reward_rate": 0.02132283834586466, "eval_stats/sum_log_reward": 4.516666616002719, "eval_stats/max_log_achievement_collect_drink": 7.5, "eval_stats/max_log_achievement_collect_sapling": 4.041666666666667, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 0.3333333333333333, "eval_stats/max_log_achievement_eat_cow": 0.08333333333333333, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 3.75, "eval_stats/max_log_achievement_place_table": 0.875, "eval_stats/max_log_achievement_wake_up": 1.4583333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 2.1141840989002958e-05, "report/cont_loss_std": 0.00039928723708726466, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004755346162710339, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.0252620743121952e-05, "report/cont_pred": 0.9980276823043823, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 14.34855842590332, "report/dyn_loss_std": 9.413713455200195, "report/image_loss_mean": 11.093475341796875, "report/image_loss_std": 12.954057693481445, "report/model_loss_mean": 19.738563537597656, "report/model_loss_std": 17.253250122070312, "report/post_ent_mag": 50.46591567993164, "report/post_ent_max": 50.46591567993164, "report/post_ent_mean": 37.429969787597656, "report/post_ent_min": 22.018169403076172, "report/post_ent_std": 5.406027793884277, "report/prior_ent_mag": 65.5255126953125, "report/prior_ent_max": 65.5255126953125, "report/prior_ent_mean": 51.68625259399414, "report/prior_ent_min": 24.52115249633789, "report/prior_ent_std": 6.345498561859131, "report/rep_loss_mean": 14.34855842590332, "report/rep_loss_std": 9.413713455200195, "report/reward_avg": 0.01406249962747097, "report/reward_loss_mean": 0.03593314811587334, "report/reward_loss_std": 0.1694411188364029, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0014054775238037, "report/reward_neg_acc": 0.9960278272628784, "report/reward_neg_loss": 0.021016251295804977, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.9195399284362793, "report/reward_pred": 0.012014380656182766, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.003670762525871396, "eval/cont_loss_std": 0.11619050055742264, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00020511655020527542, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.0036843528505414724, "eval/cont_pred": 0.9951047301292419, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 13.745196342468262, "eval/dyn_loss_std": 8.713632583618164, "eval/image_loss_mean": 14.207633972167969, "eval/image_loss_std": 20.8703670501709, "eval/model_loss_mean": 22.520841598510742, "eval/model_loss_std": 24.293668746948242, "eval/post_ent_mag": 49.541526794433594, "eval/post_ent_max": 49.541526794433594, "eval/post_ent_mean": 38.61189270019531, "eval/post_ent_min": 20.69508934020996, "eval/post_ent_std": 4.85506010055542, "eval/prior_ent_mag": 65.5255126953125, "eval/prior_ent_max": 65.5255126953125, "eval/prior_ent_mean": 50.80323028564453, "eval/prior_ent_min": 30.469505310058594, "eval/prior_ent_std": 5.307417869567871, "eval/rep_loss_mean": 13.745196342468262, "eval/rep_loss_std": 8.713632583618164, "eval/reward_avg": 0.009374999441206455, "eval/reward_loss_mean": 0.062417592853307724, "eval/reward_loss_std": 0.5056033730506897, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0072612762451172, "eval/reward_neg_acc": 0.9970325827598572, "eval/reward_neg_loss": 0.029530474916100502, "eval/reward_pos_acc": 0.692307710647583, "eval/reward_pos_loss": 2.620023488998413, "eval/reward_pred": 0.006590697914361954, "eval/reward_rate": 0.0126953125, "replay/size": 149569.0, "replay/inserts": 21280.0, "replay/samples": 21280.0, "replay/insert_wait_avg": 1.445569490131579e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.04478076705359e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 33144.0, "eval_replay/inserts": 6904.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2875777407012974e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1022.7815923690796, "timer/env.step_count": 2660.0, "timer/env.step_total": 253.1398606300354, "timer/env.step_frac": 0.24750138496693602, "timer/env.step_avg": 0.09516536113911105, "timer/env.step_min": 0.02370476722717285, "timer/env.step_max": 3.562805414199829, "timer/replay._sample_count": 21280.0, "timer/replay._sample_total": 12.002640724182129, "timer/replay._sample_frac": 0.011735292083601434, "timer/replay._sample_avg": 0.0005640338686175812, "timer/replay._sample_min": 0.0004296302795410156, "timer/replay._sample_max": 0.018537521362304688, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3523.0, "timer/agent.policy_total": 62.00430774688721, "timer/agent.policy_frac": 0.06062321438858318, "timer/agent.policy_avg": 0.017599860274449958, "timer/agent.policy_min": 0.00962686538696289, "timer/agent.policy_max": 0.1330866813659668, "timer/dataset_train_count": 1330.0, "timer/dataset_train_total": 0.15385746955871582, "timer/dataset_train_frac": 0.00015043042493787374, "timer/dataset_train_avg": 0.00011568230793888408, "timer/dataset_train_min": 0.00010037422180175781, "timer/dataset_train_max": 0.00058746337890625, "timer/agent.train_count": 1330.0, "timer/agent.train_total": 603.8336327075958, "timer/agent.train_frac": 0.5903837507565323, "timer/agent.train_avg": 0.4540102501560871, "timer/agent.train_min": 0.4391348361968994, "timer/agent.train_max": 1.6407349109649658, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46634912490844727, "timer/agent.report_frac": 0.0004559615937438197, "timer/agent.report_avg": 0.23317456245422363, "timer/agent.report_min": 0.22255349159240723, "timer/agent.report_max": 0.24379563331604004, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.913850093710025e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 20.805734937237503}
{"step": 150080, "time": 7334.088988304138, "episode/length": 186.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 150240, "time": 7341.656821012497, "episode/length": 165.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 150504, "time": 7352.115579128265, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 150616, "time": 7357.519547224045, "episode/length": 167.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 151072, "time": 7374.9618704319, "episode/length": 140.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9858156028368794, "episode/intrinsic_return": 0.0}
{"step": 151184, "time": 7380.364687919617, "episode/length": 253.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.984251968503937, "episode/intrinsic_return": 0.0}
{"step": 151208, "time": 7382.459951162338, "episode/length": 302.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.0}
{"step": 151760, "time": 7402.979871273041, "episode/length": 189.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 151928, "time": 7410.134923458099, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 152336, "time": 7425.7515342235565, "episode/length": 228.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 152584, "time": 7435.607846021652, "episode/length": 174.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 153224, "time": 7458.920352458954, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 153240, "time": 7461.101067066193, "episode/length": 401.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 153320, "time": 7465.396236896515, "episode/length": 263.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 153536, "time": 7474.512632846832, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 153648, "time": 7479.904526948929, "episode/length": 445.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9977578475336323, "episode/intrinsic_return": 0.0}
{"step": 153664, "time": 7482.0637719631195, "episode/length": 323.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 153728, "time": 7485.94328212738, "episode/length": 60.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 153816, "time": 7490.386152982712, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 153848, "time": 7493.059304714203, "episode/length": 239.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9708333333333333, "episode/intrinsic_return": 0.0}
{"step": 154392, "time": 7512.986822843552, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 154832, "time": 7530.011572122574, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 154928, "time": 7534.939337968826, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 155128, "time": 7543.149096727371, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 155184, "time": 7546.89307808876, "episode/length": 189.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 155312, "time": 7552.7552218437195, "episode/length": 221.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 155752, "time": 7570.478577136993, "episode/length": 241.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 155768, "time": 7572.583988666534, "episode/length": 239.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 155928, "time": 7579.776356220245, "episode/length": 124.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 155984, "time": 7583.575877904892, "episode/length": 143.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 156272, "time": 7594.791553497314, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 156456, "time": 7602.3662004470825, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 156720, "time": 7613.182346343994, "episode/length": 91.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 156728, "time": 7614.829208135605, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 156944, "time": 7623.914957284927, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 157224, "time": 7634.799036502838, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 157608, "time": 7649.398616075516, "episode/length": 309.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 157864, "time": 7659.619068145752, "episode/length": 142.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 157888, "time": 7662.194843530655, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 158032, "time": 7668.757500171661, "episode/length": 262.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771863117870723, "episode/intrinsic_return": 0.0}
{"step": 158128, "time": 7673.589277982712, "episode/length": 231.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 158232, "time": 7678.402104854584, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 158464, "time": 7688.06778883934, "episode/length": 106.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9439252336448598, "episode/intrinsic_return": 0.0}
{"step": 159184, "time": 7714.076349496841, "episode/length": 244.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 159392, "time": 7722.6295437812805, "episode/length": 332.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.993993993993994, "episode/intrinsic_return": 0.0}
{"step": 159544, "time": 7729.2869992256165, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 159632, "time": 7734.158258199692, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 159664, "time": 7736.827742815018, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 159744, "time": 7741.203047037125, "episode/length": 188.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 159872, "time": 7747.13338637352, "episode/length": 175.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 160024, "time": 7753.460449695587, "episode/length": 269.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 7771.565304756165, "eval_episode/length": 47.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 160056, "time": 7775.872065544128, "eval_episode/length": 62.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9523809523809523}
{"step": 160056, "time": 7779.186064720154, "eval_episode/length": 151.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 160056, "time": 7781.322501420975, "eval_episode/length": 162.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 160056, "time": 7784.423869371414, "eval_episode/length": 180.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.994475138121547}
{"step": 160056, "time": 7787.342002630234, "eval_episode/length": 195.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 160056, "time": 7789.3670399188995, "eval_episode/length": 54.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 160056, "time": 7791.542897462845, "eval_episode/length": 219.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 160616, "time": 7810.29238319397, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 160928, "time": 7822.6627860069275, "episode/length": 161.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 161128, "time": 7830.781601428986, "episode/length": 197.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 161152, "time": 7833.423451900482, "episode/length": 140.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 161200, "time": 7836.658535718918, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 161352, "time": 7843.103047847748, "episode/length": 210.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.985781990521327, "episode/intrinsic_return": 0.0}
{"step": 161392, "time": 7846.45418214798, "episode/length": 249.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 162016, "time": 7868.927432537079, "episode/length": 101.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9509803921568627, "episode/intrinsic_return": 0.0}
{"step": 162232, "time": 7877.691654205322, "episode/length": 294.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 162296, "time": 7881.482492208481, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 162352, "time": 7885.115440368652, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 162392, "time": 7887.828525304794, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 162672, "time": 7899.150293827057, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 162776, "time": 7904.004643201828, "episode/length": 230.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 162840, "time": 7907.811292648315, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 163552, "time": 7933.601492166519, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 163576, "time": 7935.818845272064, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 163664, "time": 7940.631536483765, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 164016, "time": 7955.650899648666, "episode/length": 202.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 164240, "time": 7964.928396940231, "episode/length": 174.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 164392, "time": 7971.506189823151, "episode/length": 254.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 164456, "time": 7975.2217609882355, "episode/length": 222.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 164912, "time": 7992.395399093628, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 164928, "time": 7994.517392396927, "episode/length": 268.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 165168, "time": 8004.222744703293, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 165232, "time": 8008.138650417328, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 165744, "time": 8027.223239898682, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 165760, "time": 8029.349093675613, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 165936, "time": 8037.067235708237, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 166032, "time": 8041.919605731964, "episode/length": 139.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 166088, "time": 8045.160848140717, "episode/length": 106.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.0}
{"step": 166288, "time": 8053.728100299835, "episode/length": 338.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9941002949852508, "episode/intrinsic_return": 0.0}
{"step": 166576, "time": 8065.068578958511, "episode/length": 35.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 166648, "time": 8068.867852449417, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 166840, "time": 8077.032525777817, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 167128, "time": 8088.406344175339, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 167248, "time": 8094.172114849091, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 167392, "time": 8100.612249612808, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 167616, "time": 8109.757134437561, "episode/length": 190.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 167944, "time": 8122.481148481369, "episode/length": 272.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9706959706959707, "episode/intrinsic_return": 0.0}
{"step": 168224, "time": 8133.803426027298, "episode/length": 196.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 168496, "time": 8144.588984489441, "episode/length": 239.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 168792, "time": 8156.087134599686, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 168856, "time": 8159.7963654994965, "episode/length": 215.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 168912, "time": 8163.488079786301, "episode/length": 189.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 168928, "time": 8165.648411273956, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 169184, "time": 8175.846312761307, "episode/length": 154.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 169384, "time": 8184.068480014801, "episode/length": 317.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 169928, "time": 8203.862775087357, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 169944, "time": 8206.120620727539, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 169976, "time": 8208.885462284088, "episode/length": 147.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 8228.062507390976, "eval_episode/length": 48.0, "eval_episode/score": 0.09999997913837433, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 170040, "time": 8233.572317123413, "eval_episode/length": 141.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9577464788732394}
{"step": 170040, "time": 8235.802349090576, "eval_episode/length": 157.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 170040, "time": 8237.713824748993, "eval_episode/length": 161.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 170040, "time": 8240.660703659058, "eval_episode/length": 194.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9692307692307692}
{"step": 170040, "time": 8243.819969177246, "eval_episode/length": 226.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9823788546255506}
{"step": 170040, "time": 8245.89984202385, "eval_episode/length": 236.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 170040, "time": 8248.36295390129, "eval_episode/length": 62.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9206349206349206}
{"step": 170040, "time": 8248.370888471603, "eval_episode/length": 257.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9844961240310077}
{"step": 170280, "time": 8256.419866800308, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 170432, "time": 8263.427986621857, "episode/length": 187.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 170456, "time": 8265.680673360825, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 170496, "time": 8268.945809364319, "episode/length": 138.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 170712, "time": 8277.672246694565, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 171392, "time": 8302.613273143768, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 171656, "time": 8313.051818847656, "episode/length": 149.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 171664, "time": 8315.149139404297, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 171824, "time": 8322.157581567764, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 171888, "time": 8325.916203022003, "episode/length": 238.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 171992, "time": 8330.88492321968, "episode/length": 213.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 172017, "time": 8334.081061124802, "train_stats/sum_log_reward": 4.976106128861419, "train_stats/max_log_achievement_collect_drink": 6.761061946902655, "train_stats/max_log_achievement_collect_sapling": 3.336283185840708, "train_stats/max_log_achievement_collect_stone": 0.13274336283185842, "train_stats/max_log_achievement_collect_wood": 3.8672566371681416, "train_stats/max_log_achievement_defeat_skeleton": 0.008849557522123894, "train_stats/max_log_achievement_defeat_zombie": 0.4247787610619469, "train_stats/max_log_achievement_eat_cow": 0.12389380530973451, "train_stats/max_log_achievement_make_wood_pickaxe": 0.04424778761061947, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 3.1150442477876106, "train_stats/max_log_achievement_place_table": 1.5663716814159292, "train_stats/max_log_achievement_wake_up": 1.5398230088495575, "train_stats/mean_log_entropy": 0.6149948969878981, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.190337466497491, "train/action_min": 0.0, "train/action_std": 2.794538132465669, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05048198935433026, "train/actor_opt_grad_steps": 9970.0, "train/actor_opt_loss": 0.20594097597755656, "train/adv_mag": 0.879609878045799, "train/adv_max": 0.8753970648250441, "train/adv_mean": 0.00519137959965028, "train/adv_min": -0.5033948760833183, "train/adv_std": 0.08422091236188464, "train/cont_avg": 0.9947465214416058, "train/cont_loss_mean": 0.000716049147936545, "train/cont_loss_std": 0.019697913909514322, "train/cont_neg_acc": 0.9800312845376287, "train/cont_neg_loss": 0.07631972118646325, "train/cont_pos_acc": 0.9998924432009676, "train/cont_pos_loss": 0.0003342657029197875, "train/cont_pred": 0.9947223467548398, "train/cont_rate": 0.9947465214416058, "train/dyn_loss_mean": 13.813217413686488, "train/dyn_loss_std": 9.174165335884929, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.112377821964069, "train/extr_critic_critic_opt_grad_steps": 9970.0, "train/extr_critic_critic_opt_loss": 15292.3257370552, "train/extr_critic_mag": 4.17693411694826, "train/extr_critic_max": 4.17693411694826, "train/extr_critic_mean": 0.8695979405493632, "train/extr_critic_min": -0.23747707196395762, "train/extr_critic_std": 0.9249817315679397, "train/extr_return_normed_mag": 1.9609186457891534, "train/extr_return_normed_max": 1.9609186457891534, "train/extr_return_normed_mean": 0.3390498301626122, "train/extr_return_normed_min": -0.18094368393186236, "train/extr_return_normed_std": 0.3396574563353601, "train/extr_return_rate": 0.48634525785480975, "train/extr_return_raw_mag": 5.511634924115926, "train/extr_return_raw_max": 5.511634924115926, "train/extr_return_raw_mean": 0.884417416623039, "train/extr_return_raw_min": -0.5997527709407527, "train/extr_return_raw_std": 0.969923856484629, "train/extr_reward_mag": 1.0127707676295816, "train/extr_reward_max": 1.0127707676295816, "train/extr_reward_mean": 0.01889406923327024, "train/extr_reward_min": -0.3698499307145167, "train/extr_reward_std": 0.12227397977653211, "train/image_loss_mean": 11.77365246654427, "train/image_loss_std": 14.232103713237457, "train/model_loss_mean": 20.113115721375404, "train/model_loss_std": 18.178312259868985, "train/model_opt_grad_norm": 77.95802003623795, "train/model_opt_grad_steps": 9957.766423357663, "train/model_opt_loss": 15420.424006329837, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 766.4233576642335, "train/policy_entropy_mag": 2.4557759361545535, "train/policy_entropy_max": 2.4557759361545535, "train/policy_entropy_mean": 0.612677505851662, "train/policy_entropy_min": 0.0793766922106708, "train/policy_entropy_std": 0.5200245456538931, "train/policy_logprob_mag": 7.438371449491403, "train/policy_logprob_max": -0.0094561523207239, "train/policy_logprob_mean": -0.6121359045488121, "train/policy_logprob_min": -7.438371449491403, "train/policy_logprob_std": 1.1075164327656266, "train/policy_randomness_mag": 0.866781139025723, "train/policy_randomness_max": 0.866781139025723, "train/policy_randomness_mean": 0.21624827102152971, "train/policy_randomness_min": 0.02801648899912834, "train/policy_randomness_std": 0.18354584407197297, "train/post_ent_mag": 53.97890391663043, "train/post_ent_max": 53.97890391663043, "train/post_ent_mean": 37.792791102054345, "train/post_ent_min": 21.01152901753892, "train/post_ent_std": 5.74565616663355, "train/prior_ent_mag": 66.20666760075702, "train/prior_ent_max": 66.20666760075702, "train/prior_ent_mean": 51.73631626324062, "train/prior_ent_min": 28.78413445410067, "train/prior_ent_std": 6.788663411662526, "train/rep_loss_mean": 13.813217413686488, "train/rep_loss_std": 9.174165335884929, "train/reward_avg": 0.017565294230071297, "train/reward_loss_mean": 0.05081667424771037, "train/reward_loss_std": 0.26677149381950827, "train/reward_max_data": 1.0094890533572567, "train/reward_max_pred": 1.004439571478071, "train/reward_neg_acc": 0.9936692692937642, "train/reward_neg_loss": 0.02971433572144839, "train/reward_pos_acc": 0.9467144177777924, "train/reward_pos_loss": 0.9885725017881741, "train/reward_pred": 0.016817145790551265, "train/reward_rate": 0.02220432253649635, "eval_stats/sum_log_reward": 4.217646998517654, "eval_stats/max_log_achievement_collect_drink": 5.0588235294117645, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.588235294117647, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.29411764705882354, "eval_stats/max_log_achievement_eat_cow": 0.058823529411764705, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.8823529411764706, "eval_stats/max_log_achievement_place_table": 1.5294117647058822, "eval_stats/max_log_achievement_wake_up": 1.2941176470588236, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_collect_coal": 0.047619047619047616, "eval_stats/max_log_achievement_collect_coal": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.430403325590305e-05, "report/cont_loss_std": 0.0013379111187532544, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003927957732230425, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.2643132221419364e-05, "report/cont_pred": 0.9950675964355469, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.370399475097656, "report/dyn_loss_std": 9.033563613891602, "report/image_loss_mean": 11.630581855773926, "report/image_loss_std": 12.50834846496582, "report/model_loss_mean": 20.307090759277344, "report/model_loss_std": 16.295976638793945, "report/post_ent_mag": 56.258758544921875, "report/post_ent_max": 56.258758544921875, "report/post_ent_mean": 38.834190368652344, "report/post_ent_min": 21.73570442199707, "report/post_ent_std": 6.650214672088623, "report/prior_ent_mag": 66.26774597167969, "report/prior_ent_max": 66.26774597167969, "report/prior_ent_mean": 53.153839111328125, "report/prior_ent_min": 30.29619598388672, "report/prior_ent_std": 7.307839393615723, "report/rep_loss_mean": 14.370399475097656, "report/rep_loss_std": 9.033563613891602, "report/reward_avg": 0.01816406100988388, "report/reward_loss_mean": 0.05421508848667145, "report/reward_loss_std": 0.32056519389152527, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0037240982055664, "report/reward_neg_acc": 0.9950049519538879, "report/reward_neg_loss": 0.024681678041815758, "report/reward_pos_acc": 0.8260869979858398, "report/reward_pos_loss": 1.339560627937317, "report/reward_pred": 0.015075894072651863, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 4.286683542886749e-05, "eval/cont_loss_std": 0.00061049620853737, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0007270695641636848, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.883420504280366e-05, "eval/cont_pred": 0.9941064119338989, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 17.696861267089844, "eval/dyn_loss_std": 8.514053344726562, "eval/image_loss_mean": 17.066190719604492, "eval/image_loss_std": 18.23249626159668, "eval/model_loss_mean": 27.738985061645508, "eval/model_loss_std": 21.209184646606445, "eval/post_ent_mag": 50.872039794921875, "eval/post_ent_max": 50.872039794921875, "eval/post_ent_mean": 37.465328216552734, "eval/post_ent_min": 19.273469924926758, "eval/post_ent_std": 5.23334264755249, "eval/prior_ent_mag": 66.26774597167969, "eval/prior_ent_max": 66.26774597167969, "eval/prior_ent_mean": 52.40586471557617, "eval/prior_ent_min": 29.869794845581055, "eval/prior_ent_std": 5.325405597686768, "eval/rep_loss_mean": 17.696861267089844, "eval/rep_loss_std": 8.514053344726562, "eval/reward_avg": 0.005566406063735485, "eval/reward_loss_mean": 0.054632775485515594, "eval/reward_loss_std": 0.4380684494972229, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0039405822753906, "eval/reward_neg_acc": 0.9970385432243347, "eval/reward_neg_loss": 0.029011651873588562, "eval/reward_pos_acc": 0.7272727489471436, "eval/reward_pos_loss": 2.4141054153442383, "eval/reward_pred": 0.0035493141040205956, "eval/reward_rate": 0.0107421875, "replay/size": 171513.0, "replay/inserts": 21944.0, "replay/samples": 21936.0, "replay/insert_wait_avg": 1.3998508279531314e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.89906911063942e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 36968.0, "eval_replay/inserts": 3824.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3195944630451282e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1324882507324219e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9920451641083, "timer/env.step_count": 2743.0, "timer/env.step_total": 258.1204936504364, "timer/env.step_frac": 0.2581225469729375, "timer/env.step_avg": 0.09410152885542705, "timer/env.step_min": 0.023565053939819336, "timer/env.step_max": 1.8495125770568848, "timer/replay._sample_count": 21936.0, "timer/replay._sample_total": 11.82522439956665, "timer/replay._sample_frac": 0.01182531846803443, "timer/replay._sample_avg": 0.0005390784281348765, "timer/replay._sample_min": 0.00037360191345214844, "timer/replay._sample_max": 0.029610872268676758, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3221.0, "timer/agent.policy_total": 54.04376244544983, "timer/agent.policy_frac": 0.05404419235813094, "timer/agent.policy_avg": 0.016778566422058314, "timer/agent.policy_min": 0.009313344955444336, "timer/agent.policy_max": 0.09827375411987305, "timer/dataset_train_count": 1371.0, "timer/dataset_train_total": 0.17330169677734375, "timer/dataset_train_frac": 0.0001733030753748679, "timer/dataset_train_avg": 0.00012640532223001002, "timer/dataset_train_min": 0.00010037422180175781, "timer/dataset_train_max": 0.017731666564941406, "timer/agent.train_count": 1371.0, "timer/agent.train_total": 618.9774377346039, "timer/agent.train_frac": 0.6189823616377106, "timer/agent.train_avg": 0.45147880214048425, "timer/agent.train_min": 0.44029808044433594, "timer/agent.train_max": 1.5754520893096924, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4724736213684082, "timer/agent.report_frac": 0.00047247737984842746, "timer/agent.report_avg": 0.2362368106842041, "timer/agent.report_min": 0.22696328163146973, "timer/agent.report_max": 0.24551033973693848, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.3378866597624785e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 21.94377319086662}
{"step": 172152, "time": 8340.305532693863, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 172720, "time": 8361.287539482117, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 173056, "time": 8374.37129855156, "episode/length": 174.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 173200, "time": 8380.681243181229, "episode/length": 345.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9971098265895953, "episode/intrinsic_return": 0.0}
{"step": 173240, "time": 8383.499754667282, "episode/length": 196.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 173392, "time": 8390.516608715057, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 173680, "time": 8401.851547956467, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 173688, "time": 8403.534037828445, "episode/length": 211.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 173960, "time": 8414.180394887924, "episode/length": 266.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 173984, "time": 8416.968919754028, "episode/length": 36.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 174088, "time": 8421.86356830597, "episode/length": 128.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 174296, "time": 8430.477465391159, "episode/length": 136.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 174512, "time": 8439.60580611229, "episode/length": 68.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 174528, "time": 8441.784791231155, "episode/length": 225.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 174808, "time": 8452.63843178749, "episode/length": 140.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 175224, "time": 8468.229201078415, "episode/length": 247.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 175328, "time": 8473.536223649979, "episode/length": 154.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 175656, "time": 8485.913912296295, "episode/length": 282.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 175776, "time": 8491.743569850922, "episode/length": 155.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 176000, "time": 8500.979893922806, "episode/length": 212.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 176064, "time": 8504.701966047287, "episode/length": 259.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 176112, "time": 8508.026992321014, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 176632, "time": 8526.908940553665, "episode/length": 162.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 176632, "time": 8526.917034387589, "episode/length": 175.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 176728, "time": 8533.62061715126, "episode/length": 133.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9626865671641791, "episode/intrinsic_return": 0.0}
{"step": 176808, "time": 8538.023708820343, "episode/length": 286.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9930313588850174, "episode/intrinsic_return": 0.0}
{"step": 177288, "time": 8555.961471796036, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 177296, "time": 8558.115513563156, "episode/length": 189.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 177648, "time": 8571.744529485703, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 177720, "time": 8575.493246793747, "episode/length": 206.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 177872, "time": 8582.405670404434, "episode/length": 154.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 178104, "time": 8591.558408498764, "episode/length": 171.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.0}
{"step": 178440, "time": 8604.619075536728, "episode/length": 225.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 178688, "time": 8614.75264596939, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 178832, "time": 8621.238035917282, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 179064, "time": 8630.664795398712, "episode/length": 281.0, "episode/score": 3.099999964237213, "episode/reward_rate": 0.9822695035460993, "episode/intrinsic_return": 0.0}
{"step": 179192, "time": 8636.570829868317, "episode/length": 192.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 179200, "time": 8638.6488199234, "episode/length": 184.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9837837837837838, "episode/intrinsic_return": 0.0}
{"step": 179256, "time": 8641.89817404747, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 179448, "time": 8649.944673538208, "episode/length": 167.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 179928, "time": 8667.86317539215, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 8692.859409093857, "eval_episode/length": 151.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 180024, "time": 8695.055824041367, "eval_episode/length": 164.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 180024, "time": 8698.07582783699, "eval_episode/length": 196.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 180024, "time": 8700.162838459015, "eval_episode/length": 205.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.970873786407767}
{"step": 180024, "time": 8702.348849058151, "eval_episode/length": 216.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9769585253456221}
{"step": 180024, "time": 8704.434122562408, "eval_episode/length": 225.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9823008849557522}
{"step": 180024, "time": 8707.820128440857, "eval_episode/length": 48.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9183673469387755}
{"step": 180024, "time": 8710.463581085205, "eval_episode/length": 290.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9862542955326461}
{"step": 180040, "time": 8711.009282827377, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 180072, "time": 8713.662780284882, "episode/length": 125.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 180168, "time": 8718.640288829803, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 180224, "time": 8722.68671965599, "episode/length": 96.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 180424, "time": 8732.409967422485, "episode/length": 153.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 180672, "time": 8742.678512573242, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 180848, "time": 8750.279309749603, "episode/length": 21.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8181818181818182, "episode/intrinsic_return": 0.0}
{"step": 181000, "time": 8756.699073553085, "episode/length": 133.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 181144, "time": 8763.235851287842, "episode/length": 235.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 181648, "time": 8782.47027873993, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 182128, "time": 8800.169548988342, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 182168, "time": 8802.834525585175, "episode/length": 249.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.984, "episode/intrinsic_return": 0.0}
{"step": 182208, "time": 8806.054776906967, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 182336, "time": 8812.070063829422, "episode/length": 282.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 182976, "time": 8834.999558925629, "episode/length": 343.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 182992, "time": 8837.304079294205, "episode/length": 107.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 183200, "time": 8845.810014724731, "episode/length": 256.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766536964980544, "episode/intrinsic_return": 0.0}
{"step": 183312, "time": 8851.16376876831, "episode/length": 142.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 183344, "time": 8853.844068288803, "episode/length": 364.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9917808219178083, "episode/intrinsic_return": 0.0}
{"step": 183528, "time": 8861.560639619827, "episode/length": 164.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 183560, "time": 8864.22538948059, "episode/length": 30.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.8387096774193549, "episode/intrinsic_return": 0.0}
{"step": 183560, "time": 8864.230858564377, "episode/length": 26.0, "episode/score": -0.9000000208616257, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 183576, "time": 8868.26162147522, "episode/length": 154.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 183888, "time": 8880.575451135635, "episode/length": 113.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.956140350877193, "episode/intrinsic_return": 0.0}
{"step": 183984, "time": 8885.50943350792, "episode/length": 291.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9897260273972602, "episode/intrinsic_return": 0.0}
{"step": 184176, "time": 8893.657016992569, "episode/length": 35.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8611111111111112, "episode/intrinsic_return": 0.0}
{"step": 184552, "time": 8907.793242692947, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 185136, "time": 8930.153520345688, "episode/length": 143.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 185200, "time": 8934.065298318863, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 185248, "time": 8937.256027460098, "episode/length": 255.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.97265625, "episode/intrinsic_return": 0.0}
{"step": 185352, "time": 8942.084577798843, "episode/length": 227.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 185472, "time": 8948.000118970871, "episode/length": 238.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 185608, "time": 8954.00390458107, "episode/length": 255.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 185888, "time": 8965.327622652054, "episode/length": 166.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 186456, "time": 8985.81793498993, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 186528, "time": 8990.181351661682, "episode/length": 293.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 186728, "time": 8998.22325205803, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 186784, "time": 9001.865668535233, "episode/length": 163.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 186824, "time": 9004.550380706787, "episode/length": 151.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 187288, "time": 9021.850881576538, "episode/length": 241.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 187312, "time": 9024.44062781334, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 187320, "time": 9026.050779104233, "episode/length": 258.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 187744, "time": 9042.146609544754, "episode/length": 160.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 188040, "time": 9053.715741634369, "episode/length": 156.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 188168, "time": 9059.642739534378, "episode/length": 167.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 188288, "time": 9065.4532725811, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 188456, "time": 9073.936391592026, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 188584, "time": 9079.916259288788, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 188592, "time": 9082.024132013321, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 188984, "time": 9096.571278095245, "episode/length": 48.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9183673469387755, "episode/intrinsic_return": 0.0}
{"step": 189112, "time": 9102.460400819778, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9590643274853801, "episode/intrinsic_return": 0.0}
{"step": 189280, "time": 9110.218111515045, "episode/length": 244.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 189296, "time": 9112.435141324997, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 189544, "time": 9122.190129041672, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 189960, "time": 9137.856404066086, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 9141.028811454773, "episode/length": 177.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 9162.21339392662, "eval_episode/length": 155.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 190008, "time": 9164.37000322342, "eval_episode/length": 160.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9565217391304348}
{"step": 190008, "time": 9166.203183174133, "eval_episode/length": 162.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 190008, "time": 9167.82544875145, "eval_episode/length": 163.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 190008, "time": 9169.70290517807, "eval_episode/length": 169.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 190008, "time": 9172.35649561882, "eval_episode/length": 193.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 190008, "time": 9172.364047765732, "eval_episode/length": 193.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9639175257731959}
{"step": 190008, "time": 9176.978100299835, "eval_episode/length": 55.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 190064, "time": 9180.616852998734, "episode/length": 134.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9703703703703703, "episode/intrinsic_return": 0.0}
{"step": 190312, "time": 9190.214610338211, "episode/length": 231.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 190336, "time": 9193.063861131668, "episode/length": 152.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 190480, "time": 9199.661211013794, "episode/length": 149.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 190632, "time": 9206.238468170166, "episode/length": 39.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 190808, "time": 9213.722544431686, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 190992, "time": 9221.723137378693, "episode/length": 211.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 191240, "time": 9231.467211484909, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 191296, "time": 9235.18188881874, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 191664, "time": 9249.137583494186, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 191832, "time": 9256.32036447525, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 191872, "time": 9259.442529201508, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 191896, "time": 9261.76009941101, "episode/length": 176.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 192088, "time": 9269.847286462784, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 192440, "time": 9283.271122455597, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 192752, "time": 9295.674625873566, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 193472, "time": 9321.504841089249, "episode/length": 271.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 193504, "time": 9324.255865097046, "episode/length": 203.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 193712, "time": 9332.946756839752, "episode/length": 226.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 193713, "time": 9335.213249444962, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.4645825554342835, "train/action_min": 0.0, "train/action_std": 2.9437156810480007, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04713465908870978, "train/actor_opt_grad_steps": 11335.0, "train/actor_opt_loss": -10.091843383496299, "train/adv_mag": 0.8249622083762113, "train/adv_max": 0.8131663067375913, "train/adv_mean": 0.0030113535145467134, "train/adv_min": -0.5110950949875748, "train/adv_std": 0.07901522062499733, "train/cont_avg": 0.9943416819852942, "train/cont_loss_mean": 0.0005622355521185461, "train/cont_loss_std": 0.016274024847891658, "train/cont_neg_acc": 0.9819400381158899, "train/cont_neg_loss": 0.05324023037114279, "train/cont_pos_acc": 0.9999132997849408, "train/cont_pos_loss": 0.00025001877060440924, "train/cont_pred": 0.9943309636677012, "train/cont_rate": 0.9943416819852942, "train/dyn_loss_mean": 14.166116384898915, "train/dyn_loss_std": 9.20535288137548, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.07814741572913, "train/extr_critic_critic_opt_grad_steps": 11335.0, "train/extr_critic_critic_opt_loss": 15381.996021943934, "train/extr_critic_mag": 4.3097922591602105, "train/extr_critic_max": 4.3097922591602105, "train/extr_critic_mean": 0.8584984017207342, "train/extr_critic_min": -0.28432827311403613, "train/extr_critic_std": 0.978009782731533, "train/extr_return_normed_mag": 1.887264212264734, "train/extr_return_normed_max": 1.887264212264734, "train/extr_return_normed_mean": 0.31939843307961435, "train/extr_return_normed_min": -0.2071350699509768, "train/extr_return_normed_std": 0.33259888135773297, "train/extr_return_rate": 0.4625536368831116, "train/extr_return_raw_mag": 5.654753667466781, "train/extr_return_raw_max": 5.654753667466781, "train/extr_return_raw_mean": 0.8677189255900243, "train/extr_return_raw_min": -0.741546515156241, "train/extr_return_raw_std": 1.015353123054785, "train/extr_reward_mag": 1.0124482950743507, "train/extr_reward_max": 1.0124482950743507, "train/extr_reward_mean": 0.019213892933775616, "train/extr_reward_min": -0.441629500950084, "train/extr_reward_std": 0.12548161473344355, "train/image_loss_mean": 10.737924098968506, "train/image_loss_std": 13.08651365252102, "train/model_loss_mean": 19.291176669737872, "train/model_loss_std": 17.009721040725708, "train/model_opt_grad_norm": 74.88649276450828, "train/model_opt_grad_steps": 11321.60294117647, "train/model_opt_loss": 13381.32131060432, "train/model_opt_model_opt_grad_overflow": 0.007352941176470588, "train/model_opt_model_opt_grad_scale": 689.3382352941177, "train/policy_entropy_mag": 2.4616052613538852, "train/policy_entropy_max": 2.4616052613538852, "train/policy_entropy_mean": 0.6227215188829338, "train/policy_entropy_min": 0.07937610971138757, "train/policy_entropy_std": 0.568192246643936, "train/policy_logprob_mag": 7.438373835647807, "train/policy_logprob_max": -0.009455997983048506, "train/policy_logprob_mean": -0.6227299001287011, "train/policy_logprob_min": -7.438373835647807, "train/policy_logprob_std": 1.1231960584135616, "train/policy_randomness_mag": 0.8688386319314733, "train/policy_randomness_max": 0.8688386319314733, "train/policy_randomness_mean": 0.21979336944573066, "train/policy_randomness_min": 0.028016283395974076, "train/policy_randomness_std": 0.20054693136583357, "train/post_ent_mag": 55.27348420199226, "train/post_ent_max": 55.27348420199226, "train/post_ent_mean": 38.41070192000445, "train/post_ent_min": 21.00705330512103, "train/post_ent_std": 6.127577171606176, "train/prior_ent_mag": 66.81924264571246, "train/prior_ent_max": 66.81924264571246, "train/prior_ent_mean": 52.75272459142349, "train/prior_ent_min": 30.815686352112714, "train/prior_ent_std": 6.485459948287291, "train/rep_loss_mean": 14.166116384898915, "train/rep_loss_std": 9.20535288137548, "train/reward_avg": 0.01870907047379981, "train/reward_loss_mean": 0.05302060153061414, "train/reward_loss_std": 0.26854541174629154, "train/reward_max_data": 1.0154411801520515, "train/reward_max_pred": 1.0059197404805351, "train/reward_neg_acc": 0.9936786386020043, "train/reward_neg_loss": 0.03006491595057442, "train/reward_pos_acc": 0.9391170836546842, "train/reward_pos_loss": 0.9937431895557571, "train/reward_pred": 0.01760301592088688, "train/reward_rate": 0.023674460018382353, "train_stats/sum_log_reward": 4.539655116675743, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.275862068965517, "train_stats/max_log_achievement_collect_sapling": 3.2241379310344827, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.327586206896552, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.3103448275862069, "train_stats/max_log_achievement_eat_cow": 0.1206896551724138, "train_stats/max_log_achievement_make_wood_pickaxe": 0.017241379310344827, "train_stats/max_log_achievement_make_wood_sword": 0.0603448275862069, "train_stats/max_log_achievement_place_plant": 2.956896551724138, "train_stats/max_log_achievement_place_table": 1.793103448275862, "train_stats/max_log_achievement_wake_up": 1.5258620689655173, "train_stats/mean_log_entropy": 0.580811371063364, "eval_stats/sum_log_reward": 4.4749999195337296, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.25, "eval_stats/max_log_achievement_collect_sapling": 2.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.6875, "eval_stats/max_log_achievement_place_table": 1.6875, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.00016816736024338752, "report/cont_loss_std": 0.004098895005881786, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.016482092440128326, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.971125988755375e-05, "report/cont_pred": 0.9922696352005005, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 15.01294231414795, "report/dyn_loss_std": 8.509225845336914, "report/image_loss_mean": 10.023284912109375, "report/image_loss_std": 12.691287994384766, "report/model_loss_mean": 19.099754333496094, "report/model_loss_std": 15.923929214477539, "report/post_ent_mag": 52.514305114746094, "report/post_ent_max": 52.514305114746094, "report/post_ent_mean": 37.62795639038086, "report/post_ent_min": 20.422901153564453, "report/post_ent_std": 6.005983352661133, "report/prior_ent_mag": 66.9508285522461, "report/prior_ent_max": 66.9508285522461, "report/prior_ent_mean": 53.61650085449219, "report/prior_ent_min": 31.514453887939453, "report/prior_ent_std": 5.316263198852539, "report/rep_loss_mean": 15.01294231414795, "report/rep_loss_std": 8.509225845336914, "report/reward_avg": 0.02021484449505806, "report/reward_loss_mean": 0.06853624433279037, "report/reward_loss_std": 0.33738330006599426, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0052225589752197, "report/reward_neg_acc": 0.9939759969711304, "report/reward_neg_loss": 0.03941025584936142, "report/reward_pos_acc": 0.9285714626312256, "report/reward_pos_loss": 1.1045892238616943, "report/reward_pred": 0.01711105741560459, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.00029206444742158055, "eval/cont_loss_std": 0.006367371417582035, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.03127143159508705, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00010947488044621423, "eval/cont_pred": 0.9942066669464111, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 14.860156059265137, "eval/dyn_loss_std": 9.81734561920166, "eval/image_loss_mean": 20.74942398071289, "eval/image_loss_std": 28.4768009185791, "eval/model_loss_mean": 29.731775283813477, "eval/model_loss_std": 32.49750900268555, "eval/post_ent_mag": 52.44406509399414, "eval/post_ent_max": 52.44406509399414, "eval/post_ent_mean": 39.484649658203125, "eval/post_ent_min": 22.73196792602539, "eval/post_ent_std": 5.495916843414307, "eval/prior_ent_mag": 66.9508285522461, "eval/prior_ent_max": 66.9508285522461, "eval/prior_ent_mean": 52.5340461730957, "eval/prior_ent_min": 31.863178253173828, "eval/prior_ent_std": 5.8886260986328125, "eval/rep_loss_mean": 14.860156059265137, "eval/rep_loss_std": 9.81734561920166, "eval/reward_avg": 0.01259765587747097, "eval/reward_loss_mean": 0.06596554815769196, "eval/reward_loss_std": 0.3658895194530487, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0010414123535156, "eval/reward_neg_acc": 0.9900695085525513, "eval/reward_neg_loss": 0.042979758232831955, "eval/reward_pos_acc": 0.9411764740943909, "eval/reward_pos_loss": 1.4275355339050293, "eval/reward_pred": 0.012351496145129204, "eval/reward_rate": 0.0166015625, "replay/size": 193209.0, "replay/inserts": 21696.0, "replay/samples": 21696.0, "replay/insert_wait_avg": 1.3778629028691656e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.720366124909888e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 41104.0, "eval_replay/inserts": 4136.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.317931328336321e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.1126506328583, "timer/env.step_count": 2712.0, "timer/env.step_total": 264.0748767852783, "timer/env.step_frac": 0.26378138026558956, "timer/env.step_avg": 0.0973727421774625, "timer/env.step_min": 0.023526430130004883, "timer/env.step_max": 3.5256307125091553, "timer/replay._sample_count": 21696.0, "timer/replay._sample_total": 11.553518533706665, "timer/replay._sample_frac": 0.011540677791258608, "timer/replay._sample_avg": 0.0005325183689945919, "timer/replay._sample_min": 0.00039196014404296875, "timer/replay._sample_max": 0.029564380645751953, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3229.0, "timer/agent.policy_total": 54.70773458480835, "timer/agent.policy_frac": 0.05464693164173341, "timer/agent.policy_avg": 0.016942624523012807, "timer/agent.policy_min": 0.009453773498535156, "timer/agent.policy_max": 0.11931729316711426, "timer/dataset_train_count": 1356.0, "timer/dataset_train_total": 0.15239715576171875, "timer/dataset_train_frac": 0.00015222777942660112, "timer/dataset_train_avg": 0.00011238728301011707, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.0004265308380126953, "timer/agent.train_count": 1356.0, "timer/agent.train_total": 612.9667663574219, "timer/agent.train_frac": 0.6122855065011235, "timer/agent.train_avg": 0.4520403881691902, "timer/agent.train_min": 0.4395110607147217, "timer/agent.train_max": 1.6849703788757324, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47738170623779297, "timer/agent.report_frac": 0.00047685113751785456, "timer/agent.report_avg": 0.23869085311889648, "timer/agent.report_min": 0.2317519187927246, "timer/agent.report_max": 0.24562978744506836, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.1696090698242188e-05, "timer/dataset_eval_frac": 2.1671977358918498e-08, "timer/dataset_eval_avg": 2.1696090698242188e-05, "timer/dataset_eval_min": 2.1696090698242188e-05, "timer/dataset_eval_max": 2.1696090698242188e-05, "fps": 21.671586660302562}
{"step": 193720, "time": 9335.23930311203, "episode/length": 256.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 194192, "time": 9353.624989509583, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 194288, "time": 9358.366677045822, "episode/length": 306.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9804560260586319, "episode/intrinsic_return": 0.0}
{"step": 194424, "time": 9364.20182967186, "episode/length": 291.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 194968, "time": 9384.179239988327, "episode/length": 315.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9968354430379747, "episode/intrinsic_return": 0.0}
{"step": 195096, "time": 9390.072444438934, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 195200, "time": 9395.323446512222, "episode/length": 185.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 195280, "time": 9399.688767433167, "episode/length": 38.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.8974358974358975, "episode/intrinsic_return": 0.0}
{"step": 195344, "time": 9403.576909780502, "episode/length": 202.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9901477832512315, "episode/intrinsic_return": 0.0}
{"step": 195464, "time": 9409.265492200851, "episode/length": 248.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 195864, "time": 9424.4200527668, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 196096, "time": 9434.02094078064, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 196112, "time": 9436.217140436172, "episode/length": 239.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9708333333333333, "episode/intrinsic_return": 0.0}
{"step": 196576, "time": 9453.3515894413, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 196784, "time": 9463.507413864136, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 196808, "time": 9465.724430322647, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 196840, "time": 9468.555117607117, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 196888, "time": 9471.8296585083, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 197176, "time": 9483.095331668854, "episode/length": 48.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8979591836734694, "episode/intrinsic_return": 0.0}
{"step": 197208, "time": 9485.682653427124, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 197592, "time": 9500.23861026764, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 197840, "time": 9510.425964355469, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 198208, "time": 9524.414745092392, "episode/length": 164.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 198272, "time": 9528.20429801941, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 198376, "time": 9533.175968647003, "episode/length": 149.0, "episode/score": 6.100000038743019, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 198384, "time": 9535.356056451797, "episode/length": 283.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 198392, "time": 9537.008211612701, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 198512, "time": 9542.81091761589, "episode/length": 37.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.8947368421052632, "episode/intrinsic_return": 0.0}
{"step": 198848, "time": 9555.677930116653, "episode/length": 254.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 199072, "time": 9564.973995685577, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 199456, "time": 9579.512015104294, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 199680, "time": 9588.718138933182, "episode/length": 145.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 199920, "time": 9598.39178442955, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 199920, "time": 9598.399956226349, "episode/length": 191.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 199992, "time": 9603.842696666718, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 200000, "time": 9605.95534992218, "episode/length": 200.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 9625.427839279175, "eval_episode/length": 25.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8461538461538461}
{"step": 200096, "time": 9632.425242424011, "eval_episode/length": 149.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 200096, "time": 9634.250263214111, "eval_episode/length": 153.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.974025974025974}
{"step": 200096, "time": 9636.027579069138, "eval_episode/length": 157.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9620253164556962}
{"step": 200096, "time": 9638.032426595688, "eval_episode/length": 166.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 200096, "time": 9640.368547677994, "eval_episode/length": 185.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 200096, "time": 9642.308824300766, "eval_episode/length": 194.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 200096, "time": 9644.740926980972, "eval_episode/length": 211.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9669811320754716}
{"step": 200440, "time": 9656.199803352356, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 200664, "time": 9665.307129383087, "episode/length": 198.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 200864, "time": 9673.807921409607, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 200880, "time": 9676.058368206024, "episode/length": 149.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 201096, "time": 9684.776227235794, "episode/length": 146.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 201304, "time": 9693.912429332733, "episode/length": 162.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 201776, "time": 9711.634998559952, "episode/length": 166.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 201848, "time": 9715.389828443527, "episode/length": 147.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 201912, "time": 9719.119785308838, "episode/length": 239.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 201944, "time": 9721.80950808525, "episode/length": 132.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 202064, "time": 9727.554593801498, "episode/length": 149.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 202280, "time": 9736.317408323288, "episode/length": 147.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 202808, "time": 9755.542262077332, "episode/length": 360.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9916897506925207, "episode/intrinsic_return": 0.0}
{"step": 202888, "time": 9759.882458209991, "episode/length": 197.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 203264, "time": 9774.525668382645, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 203720, "time": 9791.231008768082, "episode/length": 233.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 203760, "time": 9794.4526181221, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 203872, "time": 9800.012882232666, "episode/length": 261.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 203872, "time": 9800.02182006836, "episode/length": 244.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 203880, "time": 9803.569453716278, "episode/length": 226.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 204280, "time": 9818.67060828209, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 204496, "time": 9827.875514030457, "episode/length": 153.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 204768, "time": 9838.604714632034, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 205048, "time": 9850.664769172668, "episode/length": 146.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 205104, "time": 9854.335936069489, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 205320, "time": 9862.975687742233, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 205512, "time": 9871.111335754395, "episode/length": 204.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 205840, "time": 9884.058752298355, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 206048, "time": 9892.742095708847, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 206696, "time": 9915.931840658188, "episode/length": 147.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 206728, "time": 9918.811543226242, "episode/length": 355.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9915730337078652, "episode/intrinsic_return": 0.0}
{"step": 207024, "time": 9930.567286014557, "episode/length": 281.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 207152, "time": 9936.558834791183, "episode/length": 228.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 207160, "time": 9938.224331140518, "episode/length": 263.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 207168, "time": 9940.334135055542, "episode/length": 257.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 207400, "time": 9949.593999624252, "episode/length": 46.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 207464, "time": 9953.294102430344, "episode/length": 202.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 208112, "time": 9976.995115756989, "episode/length": 257.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9844961240310077, "episode/intrinsic_return": 0.0}
{"step": 208160, "time": 9980.262990474701, "episode/length": 182.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 208352, "time": 9988.26814866066, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 208352, "time": 9988.275290966034, "episode/length": 147.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 208552, "time": 9998.209095954895, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 208552, "time": 9998.21765422821, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 208760, "time": 10008.751836061478, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 208952, "time": 10016.795557975769, "episode/length": 74.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9466666666666667, "episode/intrinsic_return": 0.0}
{"step": 209384, "time": 10032.920251369476, "episode/length": 247.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 209504, "time": 10038.823912858963, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 209976, "time": 10056.055256605148, "episode/length": 202.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 10076.679564714432, "eval_episode/length": 46.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 210080, "time": 10079.099057674408, "eval_episode/length": 68.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.927536231884058}
{"step": 210080, "time": 10083.909267663956, "eval_episode/length": 141.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 210080, "time": 10086.501910209656, "eval_episode/length": 163.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 210080, "time": 10088.512917757034, "eval_episode/length": 174.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 210080, "time": 10092.124065876007, "eval_episode/length": 216.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9769585253456221}
{"step": 210080, "time": 10094.083571195602, "eval_episode/length": 174.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 210080, "time": 10095.82637000084, "eval_episode/length": 224.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 210128, "time": 10097.553683280945, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 210136, "time": 10099.19707942009, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 210312, "time": 10106.856786966324, "episode/length": 268.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 210328, "time": 10109.015892028809, "episode/length": 171.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 210352, "time": 10111.630859851837, "episode/length": 224.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 210400, "time": 10114.920496702194, "episode/length": 126.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 210808, "time": 10130.163548469543, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 211296, "time": 10148.42060136795, "episode/length": 144.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9517241379310345, "episode/intrinsic_return": 0.0}
{"step": 211400, "time": 10153.317835569382, "episode/length": 73.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9324324324324325, "episode/intrinsic_return": 0.0}
{"step": 211544, "time": 10159.885298252106, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 211568, "time": 10162.656102657318, "episode/length": 151.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 211752, "time": 10170.25557923317, "episode/length": 221.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 211912, "time": 10177.246594429016, "episode/length": 42.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 212144, "time": 10187.047233343124, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 212296, "time": 10193.590094327927, "episode/length": 247.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 212416, "time": 10199.544508934021, "episode/length": 260.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 212848, "time": 10215.753726005554, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 212864, "time": 10218.055141448975, "episode/length": 195.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.0}
{"step": 213128, "time": 10229.81477355957, "episode/length": 151.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 213328, "time": 10238.309200525284, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 213400, "time": 10242.15074133873, "episode/length": 249.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 213688, "time": 10254.28402018547, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 213744, "time": 10257.909858226776, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 213824, "time": 10262.25761270523, "episode/length": 61.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 213944, "time": 10267.611915826797, "episode/length": 136.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 214408, "time": 10284.991502285004, "episode/length": 248.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 214528, "time": 10290.842757463455, "episode/length": 97.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 214528, "time": 10290.851239442825, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 214560, "time": 10295.368992567062, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 215104, "time": 10315.348779678345, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 215136, "time": 10318.0198636055, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 215240, "time": 10322.914472341537, "episode/length": 193.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 215480, "time": 10332.642886400223, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 215481, "time": 10335.213346004486, "train_stats/sum_log_reward": 4.835042640566826, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.0256410256410255, "train_stats/max_log_achievement_collect_sapling": 3.5982905982905984, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.247863247863248, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.49572649572649574, "train_stats/max_log_achievement_eat_cow": 0.1623931623931624, "train_stats/max_log_achievement_make_wood_pickaxe": 0.02564102564102564, "train_stats/max_log_achievement_make_wood_sword": 0.03418803418803419, "train_stats/max_log_achievement_place_plant": 3.341880341880342, "train_stats/max_log_achievement_place_table": 1.7179487179487178, "train_stats/max_log_achievement_wake_up": 1.6495726495726495, "train_stats/mean_log_entropy": 0.5990749112306497, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.545649808995864, "train/action_min": 0.0, "train/action_std": 2.994898555909886, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04938723675577956, "train/actor_opt_grad_steps": 12695.0, "train/actor_opt_loss": -2.1564658334040465, "train/adv_mag": 0.8367428571424064, "train/adv_max": 0.8298460453310433, "train/adv_mean": 0.004532423738456761, "train/adv_min": -0.4992073572733823, "train/adv_std": 0.08227759698296294, "train/cont_avg": 0.9947581571691176, "train/cont_loss_mean": 0.0004460053606192021, "train/cont_loss_std": 0.012743856567453804, "train/cont_neg_acc": 0.9883774276132937, "train/cont_neg_loss": 0.0383503892356573, "train/cont_pos_acc": 0.9998989289297777, "train/cont_pos_loss": 0.00022980874357121894, "train/cont_pred": 0.9947336929685929, "train/cont_rate": 0.9947581571691176, "train/dyn_loss_mean": 14.022353831459494, "train/dyn_loss_std": 9.24899020615746, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0922379165011293, "train/extr_critic_critic_opt_grad_steps": 12695.0, "train/extr_critic_critic_opt_loss": 15437.28547219669, "train/extr_critic_mag": 4.408650685759151, "train/extr_critic_max": 4.408650685759151, "train/extr_critic_mean": 0.8276972415692666, "train/extr_critic_min": -0.2500193460899241, "train/extr_critic_std": 0.9633986735168625, "train/extr_return_normed_mag": 1.942369941402884, "train/extr_return_normed_max": 1.942369941402884, "train/extr_return_normed_mean": 0.3119684693348758, "train/extr_return_normed_min": -0.16849180072655573, "train/extr_return_normed_std": 0.3361593771945028, "train/extr_return_rate": 0.4359078412765966, "train/extr_return_raw_mag": 5.71078567645129, "train/extr_return_raw_max": 5.71078567645129, "train/extr_return_raw_mean": 0.8412227698546999, "train/extr_return_raw_min": -0.5932660343892434, "train/extr_return_raw_std": 1.003869063275702, "train/extr_reward_mag": 1.0118573307991028, "train/extr_reward_max": 1.0118573307991028, "train/extr_reward_mean": 0.02073665749391212, "train/extr_reward_min": -0.3920520210967344, "train/extr_reward_std": 0.13085125753765597, "train/image_loss_mean": 9.797502282787772, "train/image_loss_std": 12.447852853466483, "train/model_loss_mean": 18.261350246036756, "train/model_loss_std": 16.372678798787735, "train/model_opt_grad_norm": 75.09767156488755, "train/model_opt_grad_steps": 12680.77205882353, "train/model_opt_loss": 16223.413251091451, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 891.5441176470588, "train/policy_entropy_mag": 2.493057750603732, "train/policy_entropy_max": 2.493057750603732, "train/policy_entropy_mean": 0.6623085474266726, "train/policy_entropy_min": 0.07937568075516645, "train/policy_entropy_std": 0.6516555994749069, "train/policy_logprob_mag": 7.438377566197339, "train/policy_logprob_max": -0.009455923525178257, "train/policy_logprob_mean": -0.6620012609397664, "train/policy_logprob_min": -7.438377566197339, "train/policy_logprob_std": 1.155766669441672, "train/policy_randomness_mag": 0.8799399803666508, "train/policy_randomness_max": 0.8799399803666508, "train/policy_randomness_mean": 0.2337658563080956, "train/policy_randomness_min": 0.02801613202866386, "train/policy_randomness_std": 0.23000583184116027, "train/post_ent_mag": 55.855052162619195, "train/post_ent_max": 55.855052162619195, "train/post_ent_mean": 38.950928912443274, "train/post_ent_min": 21.418050064760095, "train/post_ent_std": 6.382635972079108, "train/prior_ent_mag": 67.26045675838695, "train/prior_ent_max": 67.26045675838695, "train/prior_ent_mean": 53.14732554379631, "train/prior_ent_min": 31.99799644245821, "train/prior_ent_std": 6.212563332389383, "train/rep_loss_mean": 14.022353831459494, "train/rep_loss_std": 9.24899020615746, "train/reward_avg": 0.018618594807134393, "train/reward_loss_mean": 0.04998965885983232, "train/reward_loss_std": 0.2541821193607414, "train/reward_max_data": 1.0117647086872774, "train/reward_max_pred": 1.005105989820817, "train/reward_neg_acc": 0.9938229063854498, "train/reward_neg_loss": 0.028847201213733676, "train/reward_pos_acc": 0.9510134892428622, "train/reward_pos_loss": 0.9410174094578799, "train/reward_pred": 0.01794781954959035, "train/reward_rate": 0.023279526654411766, "eval_stats/sum_log_reward": 4.474999964237213, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.1875, "eval_stats/max_log_achievement_collect_sapling": 4.1875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 4.0, "eval_stats/max_log_achievement_place_table": 1.0625, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_eat_plant": 0.0196078431372549, "eval_stats/max_log_achievement_eat_plant": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.005117469932883978, "report/cont_loss_std": 0.16353890299797058, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0009804057190194726, "report/cont_pos_acc": 0.9990195631980896, "report/cont_pos_loss": 0.005133694037795067, "report/cont_pred": 0.9951257109642029, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.414624214172363, "report/dyn_loss_std": 8.480939865112305, "report/image_loss_mean": 9.852882385253906, "report/image_loss_std": 10.690373420715332, "report/model_loss_mean": 17.950668334960938, "report/model_loss_std": 13.783720970153809, "report/post_ent_mag": 58.44908905029297, "report/post_ent_max": 58.44908905029297, "report/post_ent_mean": 40.244285583496094, "report/post_ent_min": 23.178611755371094, "report/post_ent_std": 7.029990196228027, "report/prior_ent_mag": 68.38740539550781, "report/prior_ent_max": 68.38740539550781, "report/prior_ent_mean": 54.1539306640625, "report/prior_ent_min": 36.607608795166016, "report/prior_ent_std": 5.581634521484375, "report/rep_loss_mean": 13.414624214172363, "report/rep_loss_std": 8.480939865112305, "report/reward_avg": 0.02099609375, "report/reward_loss_mean": 0.0438942015171051, "report/reward_loss_std": 0.18926480412483215, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0158402919769287, "report/reward_neg_acc": 0.9919840097427368, "report/reward_neg_loss": 0.022672565653920174, "report/reward_pos_acc": 0.9615384936332703, "report/reward_pos_loss": 0.8584786653518677, "report/reward_pred": 0.0196731798350811, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00014809711137786508, "eval/cont_loss_std": 0.004218806512653828, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004331925883889198, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.00013168992882128805, "eval/cont_pred": 0.9959878325462341, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.973163604736328, "eval/dyn_loss_std": 9.46264362335205, "eval/image_loss_mean": 22.753747940063477, "eval/image_loss_std": 30.766029357910156, "eval/model_loss_mean": 33.0135498046875, "eval/model_loss_std": 33.99517822265625, "eval/post_ent_mag": 51.891143798828125, "eval/post_ent_max": 51.891143798828125, "eval/post_ent_mean": 38.60420227050781, "eval/post_ent_min": 22.246105194091797, "eval/post_ent_std": 5.363442897796631, "eval/prior_ent_mag": 68.38740539550781, "eval/prior_ent_max": 68.38740539550781, "eval/prior_ent_mean": 52.25600051879883, "eval/prior_ent_min": 28.758071899414062, "eval/prior_ent_std": 6.7543253898620605, "eval/rep_loss_mean": 16.973163604736328, "eval/rep_loss_std": 9.46264362335205, "eval/reward_avg": 0.01542968675494194, "eval/reward_loss_mean": 0.07575549185276031, "eval/reward_loss_std": 0.5500994324684143, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0069787502288818, "eval/reward_neg_acc": 0.9930348992347717, "eval/reward_neg_loss": 0.04402456060051918, "eval/reward_pos_acc": 0.7894737124443054, "eval/reward_pos_loss": 1.7541545629501343, "eval/reward_pred": 0.013367557898163795, "eval/reward_rate": 0.0185546875, "replay/size": 214977.0, "replay/inserts": 21768.0, "replay/samples": 21776.0, "replay/insert_wait_avg": 1.3858244200919929e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.361182783913034e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 44600.0, "eval_replay/inserts": 3496.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3096654442409628e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9884843826294, "timer/env.step_count": 2721.0, "timer/env.step_total": 264.9754264354706, "timer/env.step_frac": 0.2649784778262327, "timer/env.step_avg": 0.09738163411814428, "timer/env.step_min": 0.023661136627197266, "timer/env.step_max": 3.5292601585388184, "timer/replay._sample_count": 21776.0, "timer/replay._sample_total": 11.280648946762085, "timer/replay._sample_frac": 0.011280778851894985, "timer/replay._sample_avg": 0.0005180312705162603, "timer/replay._sample_min": 0.0003829002380371094, "timer/replay._sample_max": 0.010080099105834961, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3158.0, "timer/agent.policy_total": 53.02184534072876, "timer/agent.policy_frac": 0.053022455927043265, "timer/agent.policy_avg": 0.01678969136818517, "timer/agent.policy_min": 0.009533405303955078, "timer/agent.policy_max": 0.1002204418182373, "timer/dataset_train_count": 1361.0, "timer/dataset_train_total": 0.15315985679626465, "timer/dataset_train_frac": 0.00015316162054688272, "timer/dataset_train_avg": 0.0001125347955887323, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.0008714199066162109, "timer/agent.train_count": 1361.0, "timer/agent.train_total": 614.9330129623413, "timer/agent.train_frac": 0.614940094377174, "timer/agent.train_avg": 0.45182440335219787, "timer/agent.train_min": 0.4379756450653076, "timer/agent.train_max": 1.5357213020324707, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47336673736572266, "timer/agent.report_frac": 0.00047337218853871975, "timer/agent.report_avg": 0.23668336868286133, "timer/agent.report_min": 0.22450566291809082, "timer/agent.report_max": 0.24886107444763184, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.838539123535156e-05, "timer/dataset_eval_frac": 3.8385833271919976e-08, "timer/dataset_eval_avg": 3.838539123535156e-05, "timer/dataset_eval_min": 3.838539123535156e-05, "timer/dataset_eval_max": 3.838539123535156e-05, "fps": 21.767983926905103}
{"step": 215608, "time": 10339.456080198288, "episode/length": 149.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 216336, "time": 10365.563112258911, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 216424, "time": 10370.056343078613, "episode/length": 160.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 216544, "time": 10375.85799574852, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 216560, "time": 10377.964342832565, "episode/length": 253.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 216704, "time": 10384.424494504929, "episode/length": 271.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 216840, "time": 10390.392857074738, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 216864, "time": 10392.91103720665, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 217368, "time": 10411.297390460968, "episode/length": 265.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9849624060150376, "episode/intrinsic_return": 0.0}
{"step": 217496, "time": 10417.229255914688, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 217704, "time": 10425.777136564255, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 217952, "time": 10435.99888253212, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 218000, "time": 10439.230998516083, "episode/length": 161.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 218192, "time": 10447.37369441986, "episode/length": 168.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 218336, "time": 10453.679057836533, "episode/length": 47.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 218568, "time": 10462.857987642288, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 218800, "time": 10472.678704738617, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 218936, "time": 10478.501779556274, "episode/length": 313.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9872611464968153, "episode/intrinsic_return": 0.0}
{"step": 219064, "time": 10484.48502779007, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 219232, "time": 10492.123881816864, "episode/length": 129.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 219280, "time": 10495.246103048325, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 219648, "time": 10509.743671178818, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 219696, "time": 10512.949693441391, "episode/length": 248.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 219784, "time": 10517.270185470581, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 10549.070987939835, "eval_episode/length": 169.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 220064, "time": 10550.971959114075, "eval_episode/length": 174.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 220064, "time": 10552.923117399216, "eval_episode/length": 182.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 220064, "time": 10552.931818008423, "eval_episode/length": 182.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.994535519125683}
{"step": 220064, "time": 10557.326936483383, "eval_episode/length": 206.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.966183574879227}
{"step": 220064, "time": 10559.895505905151, "eval_episode/length": 230.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9783549783549783}
{"step": 220064, "time": 10561.764978170395, "eval_episode/length": 238.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9790794979079498}
{"step": 220064, "time": 10567.106931209564, "eval_episode/length": 158.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9748427672955975}
{"step": 220144, "time": 10569.803583621979, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 220168, "time": 10572.052498102188, "episode/length": 137.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9492753623188406, "episode/intrinsic_return": 0.0}
{"step": 220536, "time": 10586.06526851654, "episode/length": 93.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9468085106382979, "episode/intrinsic_return": 0.0}
{"step": 220552, "time": 10588.20634675026, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 220744, "time": 10596.271441936493, "episode/length": 74.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 220792, "time": 10599.474613666534, "episode/length": 231.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 221048, "time": 10609.681173324585, "episode/length": 37.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 221256, "time": 10619.680920362473, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 221528, "time": 10630.36661696434, "episode/length": 228.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 221616, "time": 10635.147364139557, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 221840, "time": 10644.340892076492, "episode/length": 162.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 221944, "time": 10649.111428499222, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 222112, "time": 10656.55643939972, "episode/length": 164.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 222240, "time": 10662.453904867172, "episode/length": 88.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9550561797752809, "episode/intrinsic_return": 0.0}
{"step": 222608, "time": 10676.478570461273, "episode/length": 415.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 222888, "time": 10687.390440225601, "episode/length": 203.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 222904, "time": 10689.504687786102, "episode/length": 160.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 223176, "time": 10700.334332227707, "episode/length": 265.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 223304, "time": 10706.167922258377, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9562841530054644, "episode/intrinsic_return": 0.0}
{"step": 223336, "time": 10708.879321813583, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 223752, "time": 10724.370849609375, "episode/length": 188.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 223864, "time": 10729.931268930435, "episode/length": 156.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 224016, "time": 10736.86202955246, "episode/length": 258.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 224272, "time": 10747.569127321243, "episode/length": 172.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 224568, "time": 10758.89220738411, "episode/length": 153.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 224608, "time": 10762.056977033615, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 224616, "time": 10763.704502820969, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 225240, "time": 10786.228019714355, "episode/length": 291.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 225296, "time": 10789.99024105072, "episode/length": 178.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 225320, "time": 10792.20479464531, "episode/length": 195.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 225600, "time": 10803.54303264618, "episode/length": 165.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9819277108433735, "episode/intrinsic_return": 0.0}
{"step": 225752, "time": 10810.040355205536, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 225848, "time": 10814.738193035126, "episode/length": 159.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 226144, "time": 10826.656558036804, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 226464, "time": 10839.052631855011, "episode/length": 152.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 226488, "time": 10841.255433559418, "episode/length": 145.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 226504, "time": 10843.401195049286, "episode/length": 235.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 227088, "time": 10864.85295176506, "episode/length": 77.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9358974358974359, "episode/intrinsic_return": 0.0}
{"step": 227328, "time": 10874.582425832748, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 227416, "time": 10879.071017503738, "episode/length": 226.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 227728, "time": 10891.343357086182, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 227768, "time": 10894.124440670013, "episode/length": 159.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 227904, "time": 10900.479501724243, "episode/length": 268.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 227976, "time": 10904.283684492111, "episode/length": 334.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791044776119403, "episode/intrinsic_return": 0.0}
{"step": 228392, "time": 10919.885682106018, "episode/length": 235.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 228440, "time": 10923.06935429573, "episode/length": 138.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 228720, "time": 10934.234304189682, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9656862745098039, "episode/intrinsic_return": 0.0}
{"step": 229224, "time": 10952.68781709671, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 229232, "time": 10954.940093517303, "episode/length": 98.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9494949494949495, "episode/intrinsic_return": 0.0}
{"step": 229552, "time": 10968.879467487335, "episode/length": 205.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 229592, "time": 10971.47236442566, "episode/length": 232.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 11003.865539073944, "eval_episode/length": 44.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 230048, "time": 11008.962732553482, "eval_episode/length": 122.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.943089430894309}
{"step": 230048, "time": 11012.053264856339, "eval_episode/length": 155.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 230048, "time": 11014.376054286957, "eval_episode/length": 171.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 230048, "time": 11016.046679496765, "eval_episode/length": 174.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 230048, "time": 11020.990154266357, "eval_episode/length": 216.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9723502304147466}
{"step": 230048, "time": 11022.952221870422, "eval_episode/length": 225.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.995575221238938}
{"step": 230048, "time": 11024.673414945602, "eval_episode/length": 184.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 230168, "time": 11028.610503435135, "episode/length": 299.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.0}
{"step": 230216, "time": 11031.84475016594, "episode/length": 186.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 230304, "time": 11036.630610227585, "episode/length": 238.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 230512, "time": 11045.247069835663, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 230792, "time": 11055.892352819443, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 230992, "time": 11064.565389156342, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 231000, "time": 11066.054423809052, "episode/length": 377.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 231472, "time": 11083.731148004532, "episode/length": 162.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 231584, "time": 11089.127660751343, "episode/length": 248.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 231688, "time": 11094.056909561157, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 231744, "time": 11097.733863830566, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 232248, "time": 11116.156601190567, "episode/length": 156.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 232368, "time": 11122.028991937637, "episode/length": 268.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702602230483272, "episode/intrinsic_return": 0.0}
{"step": 232872, "time": 11140.3999209404, "episode/length": 259.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 232888, "time": 11142.5718126297, "episode/length": 235.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 232968, "time": 11147.041565656662, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 233016, "time": 11150.235862255096, "episode/length": 165.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 233192, "time": 11157.797029733658, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 233736, "time": 11177.661671638489, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 234024, "time": 11188.74153470993, "episode/length": 206.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 234232, "time": 11197.392294168472, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 234704, "time": 11215.065388202667, "episode/length": 389.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.0}
{"step": 234840, "time": 11220.939289808273, "episode/length": 233.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 234896, "time": 11224.611046075821, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 234936, "time": 11227.33959197998, "episode/length": 255.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 235264, "time": 11240.196101665497, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 235392, "time": 11246.105292081833, "episode/length": 314.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 235512, "time": 11251.430674791336, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 235640, "time": 11257.270244121552, "episode/length": 46.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9148936170212766, "episode/intrinsic_return": 0.0}
{"step": 235984, "time": 11270.661925315857, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 236080, "time": 11275.495122909546, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 236232, "time": 11281.96034026146, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 236248, "time": 11284.092039346695, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 236304, "time": 11287.707826852798, "episode/length": 98.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9494949494949495, "episode/intrinsic_return": 0.0}
{"step": 236336, "time": 11290.491319179535, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 236608, "time": 11301.478976249695, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 236984, "time": 11315.461173534393, "episode/length": 46.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9148936170212766, "episode/intrinsic_return": 0.0}
{"step": 237160, "time": 11323.318618059158, "episode/length": 146.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 237433, "time": 11335.232183933258, "train_stats/sum_log_reward": 4.923008798497968, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.628318584070796, "train_stats/max_log_achievement_collect_sapling": 2.893805309734513, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.31858407079646, "train_stats/max_log_achievement_defeat_skeleton": 0.008849557522123894, "train_stats/max_log_achievement_defeat_zombie": 0.4336283185840708, "train_stats/max_log_achievement_eat_cow": 0.13274336283185842, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.02654867256637168, "train_stats/max_log_achievement_make_wood_sword": 0.017699115044247787, "train_stats/max_log_achievement_place_plant": 2.7168141592920354, "train_stats/max_log_achievement_place_table": 2.1327433628318584, "train_stats/max_log_achievement_wake_up": 1.592920353982301, "train_stats/mean_log_entropy": 0.5934019392043088, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.320254137916287, "train/action_min": 0.0, "train/action_std": 2.769687964098297, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05120028955114149, "train/actor_opt_grad_steps": 14060.0, "train/actor_opt_loss": -0.24838434002042686, "train/adv_mag": 0.7710048364896844, "train/adv_max": 0.7583820811153328, "train/adv_mean": 0.004545601294078544, "train/adv_min": -0.5308410788539553, "train/adv_std": 0.08038049346230326, "train/cont_avg": 0.9943544708029197, "train/cont_loss_mean": 0.00038811161285808623, "train/cont_loss_std": 0.011110262243698881, "train/cont_neg_acc": 0.9870148318527389, "train/cont_neg_loss": 0.03386229963387759, "train/cont_pos_acc": 0.9999354655725242, "train/cont_pos_loss": 0.00019763565463212885, "train/cont_pred": 0.9943464102536222, "train/cont_rate": 0.9943544708029197, "train/dyn_loss_mean": 14.232213027285834, "train/dyn_loss_std": 9.374012418036914, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0059991557232655, "train/extr_critic_critic_opt_grad_steps": 14060.0, "train/extr_critic_critic_opt_loss": 15662.489514427463, "train/extr_critic_mag": 4.5839815696660615, "train/extr_critic_max": 4.5839815696660615, "train/extr_critic_mean": 0.891967596146312, "train/extr_critic_min": -0.24966121851092707, "train/extr_critic_std": 0.9966019039606526, "train/extr_return_normed_mag": 1.9249963751674568, "train/extr_return_normed_max": 1.9249963751674568, "train/extr_return_normed_mean": 0.3198439234147107, "train/extr_return_normed_min": -0.1711789142802684, "train/extr_return_normed_std": 0.33283347456994716, "train/extr_return_rate": 0.4810703950424264, "train/extr_return_raw_mag": 5.921638328663624, "train/extr_return_raw_max": 5.921638328663624, "train/extr_return_raw_mean": 0.906213543275847, "train/extr_return_raw_min": -0.6247865925305081, "train/extr_return_raw_std": 1.0400167103231388, "train/extr_reward_mag": 1.016142634579735, "train/extr_reward_max": 1.016142634579735, "train/extr_reward_mean": 0.021563839106174716, "train/extr_reward_min": -0.3912334433437264, "train/extr_reward_std": 0.13421088750780064, "train/image_loss_mean": 9.475557219373048, "train/image_loss_std": 12.39611302675122, "train/model_loss_mean": 18.069135749427073, "train/model_loss_std": 16.402015442395733, "train/model_opt_grad_norm": 70.45347539525832, "train/model_opt_grad_steps": 14044.569343065694, "train/model_opt_loss": 12073.327497718978, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 666.0583941605839, "train/policy_entropy_mag": 2.467317396706908, "train/policy_entropy_max": 2.467317396706908, "train/policy_entropy_mean": 0.6239747744407097, "train/policy_entropy_min": 0.0793754773309631, "train/policy_entropy_std": 0.604056402497048, "train/policy_logprob_mag": 7.438380892259361, "train/policy_logprob_max": -0.009455898402761804, "train/policy_logprob_mean": -0.6239991684029572, "train/policy_logprob_min": -7.438380892259361, "train/policy_logprob_std": 1.134965464146468, "train/policy_randomness_mag": 0.8708547671345899, "train/policy_randomness_max": 0.8708547671345899, "train/policy_randomness_mean": 0.2202357134244738, "train/policy_randomness_min": 0.028016060196461468, "train/policy_randomness_std": 0.21320540300250923, "train/post_ent_mag": 56.88675675775013, "train/post_ent_max": 56.88675675775013, "train/post_ent_mean": 39.390124495012046, "train/post_ent_min": 21.168715442184116, "train/post_ent_std": 6.663460700181279, "train/prior_ent_mag": 67.66077489922516, "train/prior_ent_max": 67.66077489922516, "train/prior_ent_mean": 53.73695234312628, "train/prior_ent_min": 32.95018594282387, "train/prior_ent_std": 6.002476048295516, "train/rep_loss_mean": 14.232213027285834, "train/rep_loss_std": 9.374012418036914, "train/reward_avg": 0.01925752718803765, "train/reward_loss_mean": 0.05386270619384999, "train/reward_loss_std": 0.2699767314169529, "train/reward_max_data": 1.0087591261759292, "train/reward_max_pred": 1.0048583946088805, "train/reward_neg_acc": 0.9935762264432698, "train/reward_neg_loss": 0.031549210116321585, "train/reward_pos_acc": 0.9435357260007928, "train/reward_pos_loss": 0.951719241420718, "train/reward_pred": 0.018483678983646806, "train/reward_rate": 0.02432139598540146, "eval_stats/sum_log_reward": 4.9749999940395355, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.75, "eval_stats/max_log_achievement_collect_sapling": 2.9375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.875, "eval_stats/max_log_achievement_place_table": 1.875, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.000593815406318754, "report/cont_loss_std": 0.014955548569560051, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.06546246260404587, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.303870708914474e-05, "report/cont_pred": 0.9925251007080078, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 15.037054061889648, "report/dyn_loss_std": 10.249255180358887, "report/image_loss_mean": 9.029367446899414, "report/image_loss_std": 11.991822242736816, "report/model_loss_mean": 18.11077117919922, "report/model_loss_std": 16.781675338745117, "report/post_ent_mag": 56.00726318359375, "report/post_ent_max": 56.00726318359375, "report/post_ent_mean": 39.000247955322266, "report/post_ent_min": 19.862215042114258, "report/post_ent_std": 6.879265308380127, "report/prior_ent_mag": 68.38335418701172, "report/prior_ent_max": 68.38335418701172, "report/prior_ent_mean": 53.83803176879883, "report/prior_ent_min": 32.174049377441406, "report/prior_ent_std": 5.942529201507568, "report/rep_loss_mean": 15.037054061889648, "report/rep_loss_std": 10.249255180358887, "report/reward_avg": 0.02421875111758709, "report/reward_loss_mean": 0.05857624113559723, "report/reward_loss_std": 0.24752187728881836, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0042827129364014, "report/reward_neg_acc": 0.9899396300315857, "report/reward_neg_loss": 0.03442436084151268, "report/reward_pos_acc": 0.9333333969116211, "report/reward_pos_loss": 0.8588085770606995, "report/reward_pred": 0.02548643946647644, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.1713453861593734e-06, "eval/cont_loss_std": 3.222511077183299e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.7406018741894513e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.126581193806487e-06, "eval/cont_pred": 0.9970682859420776, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.241350173950195, "eval/dyn_loss_std": 10.489018440246582, "eval/image_loss_mean": 25.89773941040039, "eval/image_loss_std": 29.24636459350586, "eval/model_loss_mean": 37.54665756225586, "eval/model_loss_std": 33.92900848388672, "eval/post_ent_mag": 55.59457015991211, "eval/post_ent_max": 55.59457015991211, "eval/post_ent_mean": 40.0280647277832, "eval/post_ent_min": 20.631427764892578, "eval/post_ent_std": 6.3970465660095215, "eval/prior_ent_mag": 68.38335418701172, "eval/prior_ent_max": 68.38335418701172, "eval/prior_ent_mean": 55.51092529296875, "eval/prior_ent_min": 34.64117431640625, "eval/prior_ent_std": 5.592017650604248, "eval/rep_loss_mean": 19.241350173950195, "eval/rep_loss_std": 10.489018440246582, "eval/reward_avg": 0.02099609375, "eval/reward_loss_mean": 0.10410512983798981, "eval/reward_loss_std": 0.7454450130462646, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0010666847229004, "eval/reward_neg_acc": 0.9920000433921814, "eval/reward_neg_loss": 0.030066637322306633, "eval/reward_pos_acc": 0.625, "eval/reward_pos_loss": 3.189042568206787, "eval/reward_pred": 0.010795976966619492, "eval/reward_rate": 0.0234375, "replay/size": 236929.0, "replay/inserts": 21952.0, "replay/samples": 21952.0, "replay/insert_wait_avg": 1.4037719273358671e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.062049529295274e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 49072.0, "eval_replay/inserts": 4472.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.279367317240652e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0104722976685, "timer/env.step_count": 2744.0, "timer/env.step_total": 257.0151710510254, "timer/env.step_frac": 0.25701247953983514, "timer/env.step_avg": 0.0936644209369626, "timer/env.step_min": 0.02384209632873535, "timer/env.step_max": 2.182638645172119, "timer/replay._sample_count": 21952.0, "timer/replay._sample_total": 11.059113502502441, "timer/replay._sample_frac": 0.011058997689386724, "timer/replay._sample_avg": 0.000503786147162101, "timer/replay._sample_min": 0.00038552284240722656, "timer/replay._sample_max": 0.010788440704345703, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3303.0, "timer/agent.policy_total": 56.79139471054077, "timer/agent.policy_frac": 0.056790799980378545, "timer/agent.policy_avg": 0.017193882746152217, "timer/agent.policy_min": 0.009433984756469727, "timer/agent.policy_max": 0.12825298309326172, "timer/dataset_train_count": 1372.0, "timer/dataset_train_total": 0.15232276916503906, "timer/dataset_train_frac": 0.0001523211740123636, "timer/dataset_train_avg": 0.00011102242650513051, "timer/dataset_train_min": 9.655952453613281e-05, "timer/dataset_train_max": 0.0010762214660644531, "timer/agent.train_count": 1372.0, "timer/agent.train_total": 617.0223987102509, "timer/agent.train_frac": 0.617015937135691, "timer/agent.train_avg": 0.44972478040105746, "timer/agent.train_min": 0.43697285652160645, "timer/agent.train_max": 1.5602161884307861, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4825398921966553, "timer/agent.report_frac": 0.00048253483894818643, "timer/agent.report_avg": 0.24126994609832764, "timer/agent.report_min": 0.23489785194396973, "timer/agent.report_max": 0.24764204025268555, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.2649765014648438e-05, "timer/dataset_eval_frac": 2.2649527822051036e-08, "timer/dataset_eval_avg": 2.2649765014648438e-05, "timer/dataset_eval_min": 2.2649765014648438e-05, "timer/dataset_eval_max": 2.2649765014648438e-05, "fps": 21.951513616093063}
{"step": 237616, "time": 11342.969501256943, "episode/length": 172.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.953757225433526, "episode/intrinsic_return": 0.0}
{"step": 237648, "time": 11345.757250547409, "episode/length": 250.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 237656, "time": 11347.386795759201, "episode/length": 175.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 237816, "time": 11354.377698898315, "episode/length": 188.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 237848, "time": 11357.037955284119, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683257918552036, "episode/intrinsic_return": 0.0}
{"step": 237944, "time": 11361.85779094696, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 238224, "time": 11373.054248332977, "episode/length": 154.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 238896, "time": 11397.242585897446, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 238920, "time": 11399.528982400894, "episode/length": 219.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 238928, "time": 11401.64397740364, "episode/length": 138.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 239160, "time": 11410.741052389145, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 239168, "time": 11412.736043691635, "episode/length": 164.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 239184, "time": 11414.935719966888, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 239272, "time": 11419.41959643364, "episode/length": 165.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 239512, "time": 11429.009824514389, "episode/length": 29.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 239664, "time": 11435.903836488724, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 11468.832315206528, "eval_episode/length": 138.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 240032, "time": 11471.192843675613, "eval_episode/length": 156.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9745222929936306}
{"step": 240032, "time": 11472.795910835266, "eval_episode/length": 158.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 240032, "time": 11475.53340291977, "eval_episode/length": 184.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 240032, "time": 11477.470353603363, "eval_episode/length": 48.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 240032, "time": 11479.558867931366, "eval_episode/length": 198.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 240032, "time": 11481.645236730576, "eval_episode/length": 210.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.981042654028436}
{"step": 240032, "time": 11483.426043748856, "eval_episode/length": 215.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 240280, "time": 11491.53482890129, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 240376, "time": 11496.337347507477, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 240384, "time": 11498.418602705002, "episode/length": 108.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.963302752293578, "episode/intrinsic_return": 0.0}
{"step": 240608, "time": 11507.754220247269, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 240688, "time": 11512.080019950867, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 240768, "time": 11517.020384550095, "episode/length": 60.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 240768, "time": 11517.029344558716, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 240856, "time": 11523.181068181992, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 241072, "time": 11532.337109327316, "episode/length": 238.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 241792, "time": 11557.961661338806, "episode/length": 127.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9609375, "episode/intrinsic_return": 0.0}
{"step": 241952, "time": 11565.017210006714, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 242192, "time": 11575.294868469238, "episode/length": 225.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9646017699115044, "episode/intrinsic_return": 0.0}
{"step": 242336, "time": 11581.775783061981, "episode/length": 184.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 242368, "time": 11584.488134384155, "episode/length": 248.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 242384, "time": 11586.547273159027, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 242544, "time": 11593.64213180542, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 242664, "time": 11599.132230997086, "episode/length": 236.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 242688, "time": 11601.783139944077, "episode/length": 43.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 242752, "time": 11605.593494176865, "episode/length": 45.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 243568, "time": 11634.654320955276, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 243744, "time": 11642.154328346252, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 243792, "time": 11645.383613586426, "episode/length": 249.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.984, "episode/intrinsic_return": 0.0}
{"step": 243896, "time": 11650.406964063644, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 243992, "time": 11655.194134235382, "episode/length": 202.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9901477832512315, "episode/intrinsic_return": 0.0}
{"step": 244112, "time": 11661.306937217712, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 244160, "time": 11664.425013780594, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 244184, "time": 11666.60889172554, "episode/length": 178.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 245072, "time": 11698.261761665344, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 245216, "time": 11704.711062431335, "episode/length": 177.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 245808, "time": 11727.845645666122, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 245872, "time": 11731.659041166306, "episode/length": 234.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 246064, "time": 11739.778304338455, "episode/length": 243.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 246152, "time": 11744.11991906166, "episode/length": 281.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9858156028368794, "episode/intrinsic_return": 0.0}
{"step": 246296, "time": 11750.53402709961, "episode/length": 318.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9843260188087775, "episode/intrinsic_return": 0.0}
{"step": 246848, "time": 11770.802842378616, "episode/length": 332.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.996996996996997, "episode/intrinsic_return": 0.0}
{"step": 246856, "time": 11772.493978500366, "episode/length": 222.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 247424, "time": 11793.498139381409, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 247864, "time": 11809.687771558762, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 247984, "time": 11815.496357917786, "episode/length": 271.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 248000, "time": 11817.655380010605, "episode/length": 212.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 248208, "time": 11826.343964338303, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 248208, "time": 11826.35189461708, "episode/length": 168.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 248416, "time": 11836.726968765259, "episode/length": 317.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 248576, "time": 11843.798115968704, "episode/length": 45.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 249184, "time": 11866.420846939087, "episode/length": 149.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 249312, "time": 11872.263124704361, "episode/length": 511.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.986328125, "episode/intrinsic_return": 0.0}
{"step": 249360, "time": 11875.577603816986, "episode/length": 241.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 249432, "time": 11879.291783809662, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 249600, "time": 11886.742197036743, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 249624, "time": 11888.905085086823, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 249656, "time": 11891.527963638306, "episode/length": 154.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 249712, "time": 11895.287976264954, "episode/length": 49.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 11923.53109884262, "eval_episode/length": 47.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 250016, "time": 11925.72561097145, "eval_episode/length": 58.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 250016, "time": 11930.870575666428, "eval_episode/length": 135.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9485294117647058}
{"step": 250016, "time": 11932.794345855713, "eval_episode/length": 143.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9652777777777778}
{"step": 250016, "time": 11935.10385465622, "eval_episode/length": 157.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9620253164556962}
{"step": 250016, "time": 11938.167448997498, "eval_episode/length": 189.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9789473684210527}
{"step": 250016, "time": 11940.216829538345, "eval_episode/length": 200.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 250016, "time": 11942.132500171661, "eval_episode/length": 159.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.99375}
{"step": 250400, "time": 11955.1256711483, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 250488, "time": 11959.59884428978, "episode/length": 238.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 250696, "time": 11968.239305734634, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 250896, "time": 11976.790838003159, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 250912, "time": 11978.902072191238, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 250984, "time": 11982.805459022522, "episode/length": 165.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 251064, "time": 11987.26691865921, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 251200, "time": 11993.75365805626, "episode/length": 199.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 251528, "time": 12006.003739833832, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 251664, "time": 12012.445941925049, "episode/length": 84.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 251936, "time": 12023.113335132599, "episode/length": 180.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 252072, "time": 12029.120047569275, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 252240, "time": 12036.654973506927, "episode/length": 167.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 252344, "time": 12041.53645825386, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 252440, "time": 12046.33171081543, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 252808, "time": 12060.155317544937, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 253168, "time": 12074.13048362732, "episode/length": 204.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 253168, "time": 12074.13822555542, "episode/length": 153.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 253312, "time": 12082.425895929337, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 253520, "time": 12090.932992458344, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 253600, "time": 12095.199777841568, "episode/length": 35.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 254088, "time": 12114.593453645706, "episode/length": 230.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 254160, "time": 12118.775522470474, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 254448, "time": 12130.014583826065, "episode/length": 250.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 254464, "time": 12132.138197422028, "episode/length": 46.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 254608, "time": 12138.605527639389, "episode/length": 224.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 254800, "time": 12146.798329591751, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 254816, "time": 12148.893891096115, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9611650485436893, "episode/intrinsic_return": 0.0}
{"step": 254920, "time": 12153.68890118599, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 255752, "time": 12183.354227781296, "episode/length": 278.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.985663082437276, "episode/intrinsic_return": 0.0}
{"step": 255784, "time": 12186.151292562485, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 255856, "time": 12190.433909654617, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 256008, "time": 12196.971351623535, "episode/length": 135.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 256176, "time": 12204.472884893417, "episode/length": 195.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 256200, "time": 12206.711870193481, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 256616, "time": 12222.130140066147, "episode/length": 224.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 256624, "time": 12224.251297473907, "episode/length": 104.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 256848, "time": 12233.410524606705, "episode/length": 335.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 256888, "time": 12236.093997955322, "episode/length": 33.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 257144, "time": 12246.253560066223, "episode/length": 173.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 257152, "time": 12248.343540668488, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 257368, "time": 12257.01521229744, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 257720, "time": 12270.44458079338, "episode/length": 136.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 257736, "time": 12272.614046096802, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 258344, "time": 12294.612607479095, "episode/length": 148.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 258440, "time": 12299.419786691666, "episode/length": 279.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 258680, "time": 12308.917047977448, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 258792, "time": 12314.260595560074, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 258944, "time": 12321.845918178558, "episode/length": 152.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 259200, "time": 12332.166509151459, "episode/length": 288.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9896193771626297, "episode/intrinsic_return": 0.0}
{"step": 259225, "time": 12335.397490978241, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.562046724207261, "train/action_min": 0.0, "train/action_std": 3.1137636759701897, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.047004374483709824, "train/actor_opt_grad_steps": 15425.0, "train/actor_opt_loss": -5.785417675369365, "train/adv_mag": 0.7075191543382757, "train/adv_max": 0.6923618575229364, "train/adv_mean": 0.0032890173980671105, "train/adv_min": -0.5016772374510765, "train/adv_std": 0.07422253333360833, "train/cont_avg": 0.9945571001838235, "train/cont_loss_mean": 0.0003073396771688157, "train/cont_loss_std": 0.008940855026045991, "train/cont_neg_acc": 0.9904027055810999, "train/cont_neg_loss": 0.032787319763722025, "train/cont_pos_acc": 0.9999565876582089, "train/cont_pos_loss": 0.00010566830434252824, "train/cont_pred": 0.9945757730918772, "train/cont_rate": 0.9945571001838235, "train/dyn_loss_mean": 14.246744457413168, "train/dyn_loss_std": 9.23510608252357, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9911310230107868, "train/extr_critic_critic_opt_grad_steps": 15425.0, "train/extr_critic_critic_opt_loss": 15534.353975183823, "train/extr_critic_mag": 4.782297327237971, "train/extr_critic_max": 4.782297327237971, "train/extr_critic_mean": 0.9339950917398229, "train/extr_critic_min": -0.2573687714688918, "train/extr_critic_std": 1.0808197974282152, "train/extr_return_normed_mag": 1.8628009733031778, "train/extr_return_normed_max": 1.8628009733031778, "train/extr_return_normed_mean": 0.31147310093921776, "train/extr_return_normed_min": -0.14918318201842554, "train/extr_return_normed_std": 0.33068640705417185, "train/extr_return_rate": 0.48127587577875924, "train/extr_return_raw_mag": 6.1942998696776, "train/extr_return_raw_max": 6.1942998696776, "train/extr_return_raw_mean": 0.9451303780078888, "train/extr_return_raw_min": -0.6134260281482163, "train/extr_return_raw_std": 1.1190309901447857, "train/extr_reward_mag": 1.0128324925899506, "train/extr_reward_max": 1.0128324925899506, "train/extr_reward_mean": 0.022612441858441076, "train/extr_reward_min": -0.38924967892029705, "train/extr_reward_std": 0.13744173642686186, "train/image_loss_mean": 8.774112077320323, "train/image_loss_std": 11.712299606379341, "train/model_loss_mean": 17.374740334118115, "train/model_loss_std": 15.630652098094716, "train/model_opt_grad_norm": 67.91870111577651, "train/model_opt_grad_steps": 15408.5, "train/model_opt_loss": 13122.8592672909, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 749.0808823529412, "train/policy_entropy_mag": 2.509306102991104, "train/policy_entropy_max": 2.509306102991104, "train/policy_entropy_mean": 0.6491024527041351, "train/policy_entropy_min": 0.07937536081847023, "train/policy_entropy_std": 0.633844727102448, "train/policy_logprob_mag": 7.438380332554088, "train/policy_logprob_max": -0.009455894120037556, "train/policy_logprob_mean": -0.6496991517350954, "train/policy_logprob_min": -7.438380332554088, "train/policy_logprob_std": 1.1393545050831402, "train/policy_randomness_mag": 0.8856749385595322, "train/policy_randomness_max": 0.8856749385595322, "train/policy_randomness_mean": 0.22910468061180675, "train/policy_randomness_min": 0.02801601911949761, "train/policy_randomness_std": 0.22371937312624035, "train/post_ent_mag": 57.22496349671308, "train/post_ent_max": 57.22496349671308, "train/post_ent_mean": 39.63568530363195, "train/post_ent_min": 21.425271833644192, "train/post_ent_std": 6.805663652279797, "train/prior_ent_mag": 68.12109380609849, "train/prior_ent_max": 68.12109380609849, "train/prior_ent_mean": 54.03263142529656, "train/prior_ent_min": 34.3321650168475, "train/prior_ent_std": 5.749804644023671, "train/rep_loss_mean": 14.246744457413168, "train/rep_loss_std": 9.23510608252357, "train/reward_avg": 0.019434311783269924, "train/reward_loss_mean": 0.052274163045427376, "train/reward_loss_std": 0.25455397542785196, "train/reward_max_data": 1.0117647086872774, "train/reward_max_pred": 1.0048897240091772, "train/reward_neg_acc": 0.9933310782208162, "train/reward_neg_loss": 0.030989461126463377, "train/reward_pos_acc": 0.9575485153233304, "train/reward_pos_loss": 0.9041102138512275, "train/reward_pred": 0.018907679648905554, "train/reward_rate": 0.02446432674632353, "train_stats/sum_log_reward": 4.752542331814766, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.5508474576271185, "train_stats/max_log_achievement_collect_sapling": 2.6186440677966103, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 6.762711864406779, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.3898305084745763, "train_stats/max_log_achievement_eat_cow": 0.1016949152542373, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.025423728813559324, "train_stats/max_log_achievement_make_wood_sword": 0.059322033898305086, "train_stats/max_log_achievement_place_plant": 2.406779661016949, "train_stats/max_log_achievement_place_table": 2.635593220338983, "train_stats/max_log_achievement_wake_up": 1.5338983050847457, "train_stats/mean_log_entropy": 0.5695131941367004, "eval_stats/sum_log_reward": 4.349999889731407, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.5625, "eval_stats/max_log_achievement_collect_sapling": 1.8125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_table": 2.0, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 5.9217854868620634e-05, "report/cont_loss_std": 0.0010721118887886405, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.003006188664585352, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.893388930009678e-05, "report/cont_pred": 0.9931461811065674, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.720941543579102, "report/dyn_loss_std": 9.814562797546387, "report/image_loss_mean": 7.508478164672852, "report/image_loss_std": 11.089797973632812, "report/model_loss_mean": 15.790964126586914, "report/model_loss_std": 15.46772289276123, "report/post_ent_mag": 55.432315826416016, "report/post_ent_max": 55.432315826416016, "report/post_ent_mean": 39.60304641723633, "report/post_ent_min": 22.43259048461914, "report/post_ent_std": 6.852369785308838, "report/prior_ent_mag": 68.20015716552734, "report/prior_ent_max": 68.20015716552734, "report/prior_ent_mean": 53.31824493408203, "report/prior_ent_min": 35.196746826171875, "report/prior_ent_std": 5.021961212158203, "report/rep_loss_mean": 13.720941543579102, "report/rep_loss_std": 9.814562797546387, "report/reward_avg": 0.01699218526482582, "report/reward_loss_mean": 0.04986198619008064, "report/reward_loss_std": 0.22545160353183746, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0000128746032715, "report/reward_neg_acc": 0.9900099635124207, "report/reward_neg_loss": 0.034864623099565506, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.702573299407959, "report/reward_pred": 0.01880502514541149, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.9041937523288652e-05, "eval/cont_loss_std": 0.0008511642226949334, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.007153383456170559, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.1033444025088102e-06, "eval/cont_pred": 0.9961203336715698, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 19.24286460876465, "eval/dyn_loss_std": 9.251107215881348, "eval/image_loss_mean": 23.39690399169922, "eval/image_loss_std": 27.562143325805664, "eval/model_loss_mean": 35.00150680541992, "eval/model_loss_std": 31.15934181213379, "eval/post_ent_mag": 57.38319396972656, "eval/post_ent_max": 57.38319396972656, "eval/post_ent_mean": 39.77137756347656, "eval/post_ent_min": 22.942108154296875, "eval/post_ent_std": 6.081801891326904, "eval/prior_ent_mag": 68.20015716552734, "eval/prior_ent_max": 68.20015716552734, "eval/prior_ent_mean": 55.58304214477539, "eval/prior_ent_min": 35.11157989501953, "eval/prior_ent_std": 4.790670871734619, "eval/rep_loss_mean": 19.24286460876465, "eval/rep_loss_std": 9.251107215881348, "eval/reward_avg": 0.007910155691206455, "eval/reward_loss_mean": 0.05885254591703415, "eval/reward_loss_std": 0.4366181790828705, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9991661310195923, "eval/reward_neg_acc": 0.9920792579650879, "eval/reward_neg_loss": 0.031543176621198654, "eval/reward_pos_acc": 0.785714328289032, "eval/reward_pos_loss": 2.0290286540985107, "eval/reward_pred": 0.006933653727173805, "eval/reward_rate": 0.013671875, "replay/size": 258721.0, "replay/inserts": 21792.0, "replay/samples": 21792.0, "replay/insert_wait_avg": 1.4255881834660333e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.216863511767506e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 52464.0, "eval_replay/inserts": 3392.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2962604468723513e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1542501449585, "timer/env.step_count": 2724.0, "timer/env.step_total": 267.54721760749817, "timer/env.step_frac": 0.26750595477519684, "timer/env.step_avg": 0.09821850866648243, "timer/env.step_min": 0.023565053939819336, "timer/env.step_max": 3.497974157333374, "timer/replay._sample_count": 21792.0, "timer/replay._sample_total": 11.063523530960083, "timer/replay._sample_frac": 0.011061817244046684, "timer/replay._sample_avg": 0.0005076873866997102, "timer/replay._sample_min": 0.0004162788391113281, "timer/replay._sample_max": 0.008620262145996094, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3148.0, "timer/agent.policy_total": 52.90923476219177, "timer/agent.policy_frac": 0.05290107476374101, "timer/agent.policy_avg": 0.01680725373640145, "timer/agent.policy_min": 0.009557962417602539, "timer/agent.policy_max": 0.10153436660766602, "timer/dataset_train_count": 1362.0, "timer/dataset_train_total": 0.15071821212768555, "timer/dataset_train_frac": 0.0001506949674071185, "timer/dataset_train_avg": 0.00011065948026996002, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.0010981559753417969, "timer/agent.train_count": 1362.0, "timer/agent.train_total": 613.9750084877014, "timer/agent.train_frac": 0.6138803173597615, "timer/agent.train_avg": 0.4507892867016897, "timer/agent.train_min": 0.4354512691497803, "timer/agent.train_max": 1.5663907527923584, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.483440637588501, "timer/agent.report_frac": 0.00048336607830085505, "timer/agent.report_avg": 0.2417203187942505, "timer/agent.report_min": 0.2350454330444336, "timer/agent.report_max": 0.24839520454406738, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9559344275454384e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 21.788383546322112}
{"step": 259264, "time": 12336.76236653328, "episode/length": 236.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 259392, "time": 12342.683188915253, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 259960, "time": 12363.292510509491, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 12386.374969244003, "eval_episode/length": 150.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 260000, "time": 12388.277181625366, "eval_episode/length": 158.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9748427672955975}
{"step": 260000, "time": 12390.740032196045, "eval_episode/length": 178.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 260000, "time": 12392.297211885452, "eval_episode/length": 179.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 260000, "time": 12394.374835252762, "eval_episode/length": 189.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 260000, "time": 12397.349736452103, "eval_episode/length": 223.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9776785714285714}
{"step": 260000, "time": 12399.004415988922, "eval_episode/length": 225.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.995575221238938}
{"step": 260000, "time": 12400.984386205673, "eval_episode/length": 233.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 260056, "time": 12402.636588096619, "episode/length": 157.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 260192, "time": 12409.152998209, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 260328, "time": 12415.005381345749, "episode/length": 247.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 260696, "time": 12429.068973064423, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 261032, "time": 12442.364303350449, "episode/length": 228.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 261224, "time": 12450.422192811966, "episode/length": 228.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 261512, "time": 12461.756773471832, "episode/length": 181.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 261760, "time": 12471.989304304123, "episode/length": 178.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 261800, "time": 12474.62870335579, "episode/length": 229.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 261808, "time": 12476.568066596985, "episode/length": 201.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 262072, "time": 12486.986579418182, "episode/length": 171.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 262480, "time": 12504.178391933441, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 262768, "time": 12515.44411110878, "episode/length": 540.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9944547134935305, "episode/intrinsic_return": 0.0}
{"step": 263216, "time": 12532.165811538696, "episode/length": 272.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 263240, "time": 12534.255764484406, "episode/length": 179.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 263440, "time": 12542.721886634827, "episode/length": 240.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 263528, "time": 12547.496735811234, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 263696, "time": 12555.015650510788, "episode/length": 202.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 263704, "time": 12556.766293287277, "episode/length": 152.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 264120, "time": 12572.353920459747, "episode/length": 168.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 264320, "time": 12581.04720711708, "episode/length": 319.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 264448, "time": 12586.993553638458, "episode/length": 153.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 264688, "time": 12596.631674289703, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 264832, "time": 12602.960823059082, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 265080, "time": 12612.598595619202, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 265272, "time": 12620.717573165894, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 265384, "time": 12626.153918743134, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 265600, "time": 12635.295640230179, "episode/length": 159.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 265760, "time": 12642.240302562714, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 266080, "time": 12654.712290525436, "episode/length": 244.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 266264, "time": 12662.318525791168, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 266288, "time": 12664.925575256348, "episode/length": 181.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 266328, "time": 12667.61742401123, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9551282051282052, "episode/intrinsic_return": 0.0}
{"step": 266416, "time": 12672.351080417633, "episode/length": 41.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 267152, "time": 12698.7466173172, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 267200, "time": 12701.864749670029, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 267432, "time": 12711.183173179626, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 267768, "time": 12723.983691692352, "episode/length": 311.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775641025641025, "episode/intrinsic_return": 0.0}
{"step": 267880, "time": 12729.493772506714, "episode/length": 201.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 268160, "time": 12740.809399604797, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 268552, "time": 12755.296421289444, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 268568, "time": 12757.409708976746, "episode/length": 141.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 268576, "time": 12759.447896718979, "episode/length": 280.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9786476868327402, "episode/intrinsic_return": 0.0}
{"step": 268584, "time": 12761.018108129501, "episode/length": 352.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9943342776203966, "episode/intrinsic_return": 0.0}
{"step": 268648, "time": 12764.774072647095, "episode/length": 180.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 268896, "time": 12775.132499217987, "episode/length": 38.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 269160, "time": 12785.32747554779, "episode/length": 159.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 269616, "time": 12802.612848997116, "episode/length": 230.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 269864, "time": 12812.357488632202, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 269928, "time": 12816.124895334244, "episode/length": 171.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 270072, "time": 12822.611877202988, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 12844.224892377853, "eval_episode/length": 143.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 270088, "time": 12846.045880317688, "eval_episode/length": 148.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 270088, "time": 12847.933699131012, "eval_episode/length": 153.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 270088, "time": 12849.890275716782, "eval_episode/length": 161.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 270088, "time": 12852.324012994766, "eval_episode/length": 178.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 270088, "time": 12854.169460058212, "eval_episode/length": 182.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 270088, "time": 12856.830006361008, "eval_episode/length": 203.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 270088, "time": 12860.397014856339, "eval_episode/length": 248.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9799196787148594}
{"step": 270352, "time": 12871.041014432907, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 270560, "time": 12879.667214155197, "episode/length": 174.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 270928, "time": 12893.701315641403, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 270976, "time": 12896.961899280548, "episode/length": 259.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 271016, "time": 12899.646465063095, "episode/length": 304.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9868852459016394, "episode/intrinsic_return": 0.0}
{"step": 271240, "time": 12908.733361244202, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 271640, "time": 12923.79263496399, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 271704, "time": 12927.50590968132, "episode/length": 168.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 271936, "time": 12937.078182935715, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 272192, "time": 12947.263894081116, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 272224, "time": 12949.93047118187, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 272480, "time": 12960.212758541107, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 273000, "time": 12979.00145816803, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 273104, "time": 12984.362485408783, "episode/length": 260.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 273432, "time": 12996.949391841888, "episode/length": 150.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 273432, "time": 12996.9599006176, "episode/length": 445.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9932735426008968, "episode/intrinsic_return": 0.0}
{"step": 273632, "time": 13007.526959180832, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 273656, "time": 13009.819400072098, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 273792, "time": 13016.202264547348, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 273992, "time": 13024.32366681099, "episode/length": 285.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9965034965034965, "episode/intrinsic_return": 0.0}
{"step": 274608, "time": 13046.810308933258, "episode/length": 187.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 274784, "time": 13054.28681588173, "episode/length": 222.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 274872, "time": 13058.698634147644, "episode/length": 32.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8787878787878788, "episode/intrinsic_return": 0.0}
{"step": 274888, "time": 13060.962604999542, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 275112, "time": 13070.243559837341, "episode/length": 209.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 275320, "time": 13078.847868919373, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 275368, "time": 13082.0853266716, "episode/length": 171.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 275512, "time": 13088.588911771774, "episode/length": 234.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 275736, "time": 13097.849252939224, "episode/length": 242.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9711934156378601, "episode/intrinsic_return": 0.0}
{"step": 275856, "time": 13104.36476278305, "episode/length": 66.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9402985074626866, "episode/intrinsic_return": 0.0}
{"step": 275888, "time": 13107.076395988464, "episode/length": 46.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 276056, "time": 13114.139333248138, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 276320, "time": 13124.798705816269, "episode/length": 150.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 276376, "time": 13128.205731153488, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 276504, "time": 13134.121630430222, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 276560, "time": 13137.824818611145, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 277272, "time": 13163.264315366745, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 277272, "time": 13163.272350549698, "episode/length": 176.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 277360, "time": 13169.821569681168, "episode/length": 162.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 277504, "time": 13176.23168349266, "episode/length": 201.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 277544, "time": 13178.871261358261, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 277936, "time": 13193.92591381073, "episode/length": 48.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8979591836734694, "episode/intrinsic_return": 0.0}
{"step": 278008, "time": 13197.728264093399, "episode/length": 203.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 278272, "time": 13208.34296798706, "episode/length": 220.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 278720, "time": 13226.470400810242, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 278824, "time": 13231.355265378952, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 278880, "time": 13235.074435472488, "episode/length": 189.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 279168, "time": 13246.500888109207, "episode/length": 236.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 279424, "time": 13256.57295536995, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 279616, "time": 13264.695107460022, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 279712, "time": 13270.151537895203, "episode/length": 393.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9974619289340102, "episode/intrinsic_return": 0.0}
{"step": 280032, "time": 13282.916315078735, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 13307.095700025558, "eval_episode/length": 145.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9726027397260274}
{"step": 280072, "time": 13310.859591007233, "eval_episode/length": 193.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 280072, "time": 13313.564765453339, "eval_episode/length": 218.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 280072, "time": 13315.431874036789, "eval_episode/length": 223.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 280072, "time": 13317.53452539444, "eval_episode/length": 235.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9957627118644068}
{"step": 280072, "time": 13319.251063108444, "eval_episode/length": 239.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9708333333333333}
{"step": 280072, "time": 13323.79261636734, "eval_episode/length": 305.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 280072, "time": 13328.042569875717, "eval_episode/length": 203.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 280224, "time": 13333.376023054123, "episode/length": 276.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9819494584837545, "episode/intrinsic_return": 0.0}
{"step": 280225, "time": 13335.593404769897, "train_stats/sum_log_reward": 4.894392443594532, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.457943925233645, "train_stats/max_log_achievement_collect_sapling": 2.9626168224299065, "train_stats/max_log_achievement_collect_stone": 0.018691588785046728, "train_stats/max_log_achievement_collect_wood": 6.4485981308411215, "train_stats/max_log_achievement_defeat_skeleton": 0.018691588785046728, "train_stats/max_log_achievement_defeat_zombie": 0.38317757009345793, "train_stats/max_log_achievement_eat_cow": 0.12149532710280374, "train_stats/max_log_achievement_eat_plant": 0.009345794392523364, "train_stats/max_log_achievement_make_wood_pickaxe": 0.018691588785046728, "train_stats/max_log_achievement_make_wood_sword": 0.037383177570093455, "train_stats/max_log_achievement_place_plant": 2.869158878504673, "train_stats/max_log_achievement_place_table": 2.3738317757009346, "train_stats/max_log_achievement_wake_up": 1.7476635514018692, "train_stats/mean_log_entropy": 0.5653992401105221, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.451407163197757, "train/action_min": 0.0, "train/action_std": 3.0147277307874374, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04831707343914127, "train/actor_opt_grad_steps": 16760.0, "train/actor_opt_loss": -6.864347296589203, "train/adv_mag": 0.7328596995532057, "train/adv_max": 0.7137423760563363, "train/adv_mean": 0.0036825735041929875, "train/adv_min": -0.5031534476589611, "train/adv_std": 0.07541173605518486, "train/cont_avg": 0.9947519083969466, "train/cont_loss_mean": 0.00023626640895647578, "train/cont_loss_std": 0.006934626445418864, "train/cont_neg_acc": 0.990185388626943, "train/cont_neg_loss": 0.015143567434188992, "train/cont_pos_acc": 0.9999550398979479, "train/cont_pos_loss": 0.00015561344771925157, "train/cont_pred": 0.9947478771209717, "train/cont_rate": 0.9947519083969466, "train/dyn_loss_mean": 13.979011943322101, "train/dyn_loss_std": 9.168884408382969, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9627828957470319, "train/extr_critic_critic_opt_grad_steps": 16760.0, "train/extr_critic_critic_opt_loss": 15599.051332895993, "train/extr_critic_mag": 4.855678376350694, "train/extr_critic_max": 4.855678376350694, "train/extr_critic_mean": 0.8982532702329504, "train/extr_critic_min": -0.2506938626748005, "train/extr_critic_std": 1.0946171174522574, "train/extr_return_normed_mag": 1.8905382784268328, "train/extr_return_normed_max": 1.8905382784268328, "train/extr_return_normed_mean": 0.2991912939393793, "train/extr_return_normed_min": -0.15794025480974722, "train/extr_return_normed_std": 0.3357738180242422, "train/extr_return_rate": 0.44211844178556486, "train/extr_return_raw_mag": 6.283205156107895, "train/extr_return_raw_max": 6.283205156107895, "train/extr_return_raw_mean": 0.9106665738211334, "train/extr_return_raw_min": -0.6333984964676486, "train/extr_return_raw_std": 1.1342990839754352, "train/extr_reward_mag": 1.0135757340729692, "train/extr_reward_max": 1.0135757340729692, "train/extr_reward_mean": 0.024115225385504823, "train/extr_reward_min": -0.4160104525908259, "train/extr_reward_std": 0.142343798325262, "train/image_loss_mean": 8.245115775188417, "train/image_loss_std": 11.111987448830641, "train/model_loss_mean": 16.683555624867214, "train/model_loss_std": 14.962796618920246, "train/model_opt_grad_norm": 67.21668297279882, "train/model_opt_grad_steps": 16742.26717557252, "train/model_opt_loss": 10669.234557639551, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 639.3129770992366, "train/policy_entropy_mag": 2.5017606411271425, "train/policy_entropy_max": 2.5017606411271425, "train/policy_entropy_mean": 0.6160826428245952, "train/policy_entropy_min": 0.07937530126735454, "train/policy_entropy_std": 0.6191821341751186, "train/policy_logprob_mag": 7.438381937623934, "train/policy_logprob_max": -0.009455877868103162, "train/policy_logprob_mean": -0.6145855661566931, "train/policy_logprob_min": -7.438381937623934, "train/policy_logprob_std": 1.1179454981825734, "train/policy_randomness_mag": 0.883011721927701, "train/policy_randomness_max": 0.883011721927701, "train/policy_randomness_mean": 0.2174501358780242, "train/policy_randomness_min": 0.028015998156584856, "train/policy_randomness_std": 0.21854412112072225, "train/post_ent_mag": 58.18409370830041, "train/post_ent_max": 58.18409370830041, "train/post_ent_mean": 40.23485431234345, "train/post_ent_min": 21.375320449130225, "train/post_ent_std": 6.970782596646375, "train/prior_ent_mag": 68.27115130242501, "train/prior_ent_max": 68.27115130242501, "train/prior_ent_mean": 54.34644731128489, "train/prior_ent_min": 35.24689779208817, "train/prior_ent_std": 5.56480491070347, "train/rep_loss_mean": 13.979011943322101, "train/rep_loss_std": 9.168884408382969, "train/reward_avg": 0.02028342659179946, "train/reward_loss_mean": 0.05079651136264091, "train/reward_loss_std": 0.24636714228691944, "train/reward_max_data": 1.0099236664881233, "train/reward_max_pred": 1.0063863892591636, "train/reward_neg_acc": 0.9934292003398634, "train/reward_neg_loss": 0.029272786220748914, "train/reward_pos_acc": 0.9622326124715441, "train/reward_pos_loss": 0.8925158240412938, "train/reward_pred": 0.01958809206475511, "train/reward_rate": 0.025114802003816793, "eval_stats/sum_log_reward": 4.9333332777023315, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.708333333333333, "eval_stats/max_log_achievement_collect_sapling": 2.4583333333333335, "eval_stats/max_log_achievement_collect_stone": 0.08333333333333333, "eval_stats/max_log_achievement_collect_wood": 9.083333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4166666666666667, "eval_stats/max_log_achievement_eat_cow": 0.08333333333333333, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.25, "eval_stats/max_log_achievement_place_table": 3.1666666666666665, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_place_stone": 0.01098901098901099, "eval_stats/max_log_achievement_place_stone": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 8.451321627944708e-05, "report/cont_loss_std": 0.0021788696758449078, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.013709280639886856, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.210068709653569e-06, "report/cont_pred": 0.9942144751548767, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.533554077148438, "report/dyn_loss_std": 9.519468307495117, "report/image_loss_mean": 9.06360912322998, "report/image_loss_std": 10.888558387756348, "report/model_loss_mean": 17.24777603149414, "report/model_loss_std": 14.914604187011719, "report/post_ent_mag": 61.50447463989258, "report/post_ent_max": 61.50447463989258, "report/post_ent_mean": 41.348487854003906, "report/post_ent_min": 19.37770652770996, "report/post_ent_std": 7.885684490203857, "report/prior_ent_mag": 68.64205932617188, "report/prior_ent_max": 68.64205932617188, "report/prior_ent_mean": 54.79906463623047, "report/prior_ent_min": 36.42212677001953, "report/prior_ent_std": 5.650482654571533, "report/rep_loss_mean": 13.533554077148438, "report/rep_loss_std": 9.519468307495117, "report/reward_avg": 0.02216796949505806, "report/reward_loss_mean": 0.06394893676042557, "report/reward_loss_std": 0.2651568353176117, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9999856948852539, "report/reward_neg_acc": 0.9869346618652344, "report/reward_neg_loss": 0.03653555363416672, "report/reward_pos_acc": 0.8965517282485962, "report/reward_pos_loss": 1.0045115947723389, "report/reward_pred": 0.020711343735456467, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.9912109375, "eval/cont_loss_mean": 0.0037917676381766796, "eval/cont_loss_std": 0.10022586584091187, "eval/cont_neg_acc": 0.8888888955116272, "eval/cont_neg_loss": 0.08418132364749908, "eval/cont_pos_acc": 0.9990147948265076, "eval/cont_pos_loss": 0.0030789535958319902, "eval/cont_pred": 0.9908035397529602, "eval/cont_rate": 0.9912109375, "eval/dyn_loss_mean": 17.96872329711914, "eval/dyn_loss_std": 9.265010833740234, "eval/image_loss_mean": 15.366724014282227, "eval/image_loss_std": 19.043306350708008, "eval/model_loss_mean": 26.24738883972168, "eval/model_loss_std": 22.212305068969727, "eval/post_ent_mag": 58.273990631103516, "eval/post_ent_max": 58.273990631103516, "eval/post_ent_mean": 40.72370529174805, "eval/post_ent_min": 22.166664123535156, "eval/post_ent_std": 6.956632137298584, "eval/prior_ent_mag": 68.64205932617188, "eval/prior_ent_max": 68.64205932617188, "eval/prior_ent_mean": 55.80415344238281, "eval/prior_ent_min": 36.427406311035156, "eval/prior_ent_std": 5.055983543395996, "eval/rep_loss_mean": 17.96872329711914, "eval/rep_loss_std": 9.265010833740234, "eval/reward_avg": 0.03388671576976776, "eval/reward_loss_mean": 0.09564003348350525, "eval/reward_loss_std": 0.47222504019737244, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9997913837432861, "eval/reward_neg_acc": 0.9908443689346313, "eval/reward_neg_loss": 0.03509107232093811, "eval/reward_pos_acc": 0.8048779964447021, "eval/reward_pos_loss": 1.5473384857177734, "eval/reward_pred": 0.025940686464309692, "eval/reward_rate": 0.0400390625, "replay/size": 279721.0, "replay/inserts": 21000.0, "replay/samples": 20992.0, "replay/insert_wait_avg": 1.396292731875465e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.470605967975244e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 59128.0, "eval_replay/inserts": 6664.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2659726022672253e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1324882507324219e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1829733848572, "timer/env.step_count": 2625.0, "timer/env.step_total": 246.15499234199524, "timer/env.step_frac": 0.24610996076942618, "timer/env.step_avg": 0.09377333041599818, "timer/env.step_min": 0.023793697357177734, "timer/env.step_max": 3.527174234390259, "timer/replay._sample_count": 20992.0, "timer/replay._sample_total": 10.798243522644043, "timer/replay._sample_frac": 0.010796268092927254, "timer/replay._sample_avg": 0.0005143980336625402, "timer/replay._sample_min": 0.0003514289855957031, "timer/replay._sample_max": 0.010902881622314453, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3458.0, "timer/agent.policy_total": 59.74283456802368, "timer/agent.policy_frac": 0.05973190521914177, "timer/agent.policy_avg": 0.017276701725859944, "timer/agent.policy_min": 0.009543180465698242, "timer/agent.policy_max": 0.12960290908813477, "timer/dataset_train_count": 1312.0, "timer/dataset_train_total": 0.17058730125427246, "timer/dataset_train_frac": 0.00017055609402844005, "timer/dataset_train_avg": 0.00013002080888282962, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.02367568016052246, "timer/agent.train_count": 1312.0, "timer/agent.train_total": 591.7204096317291, "timer/agent.train_frac": 0.5916121603522269, "timer/agent.train_avg": 0.45100640978028134, "timer/agent.train_min": 0.4334135055541992, "timer/agent.train_max": 1.5629546642303467, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47139835357666016, "timer/agent.report_frac": 0.0004713121160034708, "timer/agent.report_avg": 0.23569917678833008, "timer/agent.report_min": 0.22156453132629395, "timer/agent.report_max": 0.2498338222503662, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.1942245018918326e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 20.99590279686825}
{"step": 280664, "time": 13350.528314590454, "episode/length": 186.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 281008, "time": 13363.846345424652, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 281024, "time": 13365.965642929077, "episode/length": 274.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 281032, "time": 13367.792024612427, "episode/length": 268.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 281248, "time": 13376.787838935852, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 281336, "time": 13381.19278383255, "episode/length": 238.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 281672, "time": 13393.983471632004, "episode/length": 41.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 281696, "time": 13396.678241729736, "episode/length": 83.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 281744, "time": 13399.886308908463, "episode/length": 253.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 281840, "time": 13404.750648498535, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 282296, "time": 13421.514619588852, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 282344, "time": 13424.724783658981, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 282560, "time": 13433.915110111237, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 282784, "time": 13443.081570386887, "episode/length": 60.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 283160, "time": 13457.273667097092, "episode/length": 238.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 283208, "time": 13460.486320734024, "episode/length": 170.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 283264, "time": 13464.182400465012, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 283304, "time": 13466.880364179611, "episode/length": 203.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 283672, "time": 13480.793838739395, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 283720, "time": 13483.98702096939, "episode/length": 252.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9841897233201581, "episode/intrinsic_return": 0.0}
{"step": 283792, "time": 13488.369763374329, "episode/length": 125.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 283920, "time": 13494.219668388367, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 284256, "time": 13507.079293489456, "episode/length": 136.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 284640, "time": 13521.83785033226, "episode/length": 47.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 284704, "time": 13525.61175942421, "episode/length": 186.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 284704, "time": 13525.619834184647, "episode/length": 174.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 284776, "time": 13531.216663122177, "episode/length": 131.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 285112, "time": 13544.114598989487, "episode/length": 164.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 285160, "time": 13547.457703828812, "episode/length": 236.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 285624, "time": 13564.562917470932, "episode/length": 212.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 285832, "time": 13572.975097179413, "episode/length": 269.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 286112, "time": 13584.285269737244, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 286184, "time": 13588.222994089127, "episode/length": 175.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 286264, "time": 13592.496581315994, "episode/length": 194.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 286608, "time": 13605.791208028793, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 286696, "time": 13610.275391101837, "episode/length": 63.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 286696, "time": 13610.283813476562, "episode/length": 197.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 286744, "time": 13616.656548261642, "episode/length": 262.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771863117870723, "episode/intrinsic_return": 0.0}
{"step": 287184, "time": 13633.270342588425, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9897435897435898, "episode/intrinsic_return": 0.0}
{"step": 287264, "time": 13637.617804765701, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 287536, "time": 13648.31984424591, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 287872, "time": 13661.384185552597, "episode/length": 200.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 287944, "time": 13665.235216379166, "episode/length": 166.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 287992, "time": 13668.600758552551, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 288016, "time": 13671.329717159271, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 288160, "time": 13677.614980220795, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9890710382513661, "episode/intrinsic_return": 0.0}
{"step": 288616, "time": 13694.207701444626, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 288792, "time": 13701.702310562134, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 289048, "time": 13712.108334064484, "episode/length": 146.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 289104, "time": 13715.87726020813, "episode/length": 239.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 289480, "time": 13730.055441617966, "episode/length": 191.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 289496, "time": 13732.152139663696, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 289512, "time": 13734.258486270905, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 289744, "time": 13743.862516880035, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 289840, "time": 13748.664900541306, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 13772.234779596329, "eval_episode/length": 38.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 290056, "time": 13774.076402902603, "eval_episode/length": 44.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 290056, "time": 13780.590390205383, "eval_episode/length": 160.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 290056, "time": 13783.081796646118, "eval_episode/length": 182.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.994535519125683}
{"step": 290056, "time": 13785.373050451279, "eval_episode/length": 158.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 290056, "time": 13787.210701465607, "eval_episode/length": 199.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.975}
{"step": 290056, "time": 13789.24368095398, "eval_episode/length": 209.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 290056, "time": 13790.949565410614, "eval_episode/length": 211.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 290304, "time": 13799.49189901352, "episode/length": 188.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 290384, "time": 13803.914259672165, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 290848, "time": 13821.151139736176, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 290952, "time": 13825.993454694748, "episode/length": 230.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 291080, "time": 13831.830781936646, "episode/length": 195.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 291400, "time": 13844.191187620163, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 291448, "time": 13847.564951896667, "episode/length": 245.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 291488, "time": 13850.750058889389, "episode/length": 205.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 291528, "time": 13853.536569833755, "episode/length": 142.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 291800, "time": 13864.388117313385, "episode/length": 186.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 292096, "time": 13876.374894618988, "episode/length": 155.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 292424, "time": 13888.74453997612, "episode/length": 183.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 292704, "time": 13899.969404697418, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 292816, "time": 13905.27861046791, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 292896, "time": 13909.7162027359, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 292912, "time": 13911.95168018341, "episode/length": 182.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 293152, "time": 13921.548934221268, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 293648, "time": 13939.955796480179, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 294128, "time": 13957.726241588593, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 294344, "time": 13966.467100858688, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9658536585365853, "episode/intrinsic_return": 0.0}
{"step": 294624, "time": 13977.844830989838, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 294648, "time": 13980.08049583435, "episode/length": 277.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9856115107913669, "episode/intrinsic_return": 0.0}
{"step": 294792, "time": 13986.462357521057, "episode/length": 423.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9787735849056604, "episode/intrinsic_return": 0.0}
{"step": 294928, "time": 13994.252524852753, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.95625, "episode/intrinsic_return": 0.0}
{"step": 294984, "time": 13997.52998638153, "episode/length": 228.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 295120, "time": 14004.000252485275, "episode/length": 287.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9826388888888888, "episode/intrinsic_return": 0.0}
{"step": 295744, "time": 14026.544249296188, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 295984, "time": 14036.139884471893, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 296128, "time": 14042.545190095901, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 296352, "time": 14051.654610872269, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 296520, "time": 14058.837497472763, "episode/length": 174.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 296680, "time": 14065.957179069519, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 296784, "time": 14071.23588848114, "episode/length": 231.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 297184, "time": 14086.373967409134, "episode/length": 49.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 297432, "time": 14096.034644126892, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 297536, "time": 14101.268245220184, "episode/length": 425.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9976525821596244, "episode/intrinsic_return": 0.0}
{"step": 297592, "time": 14104.498481988907, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 297848, "time": 14114.787764310837, "episode/length": 232.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 298224, "time": 14129.345341682434, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 298256, "time": 14132.02075958252, "episode/length": 82.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.927710843373494, "episode/intrinsic_return": 0.0}
{"step": 298584, "time": 14144.340449333191, "episode/length": 354.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9887323943661972, "episode/intrinsic_return": 0.0}
{"step": 298960, "time": 14158.799366235733, "episode/length": 138.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 299000, "time": 14161.6315472126, "episode/length": 51.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9038461538461539, "episode/intrinsic_return": 0.0}
{"step": 299120, "time": 14167.52745461464, "episode/length": 304.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 299136, "time": 14169.738105297089, "episode/length": 212.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 299416, "time": 14180.560150146484, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 299736, "time": 14192.857763528824, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 14220.580023527145, "eval_episode/length": 58.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 300040, "time": 14222.481351137161, "eval_episode/length": 67.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9852941176470589}
{"step": 300040, "time": 14228.726644515991, "eval_episode/length": 172.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 300040, "time": 14230.740692615509, "eval_episode/length": 173.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 300040, "time": 14232.882573127747, "eval_episode/length": 185.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 300040, "time": 14236.260845661163, "eval_episode/length": 222.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9730941704035875}
{"step": 300040, "time": 14239.723914384842, "eval_episode/length": 203.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 300040, "time": 14242.057616710663, "eval_episode/length": 281.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9858156028368794}
{"step": 300280, "time": 14250.10886311531, "episode/length": 256.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 300408, "time": 14256.101484775543, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 300488, "time": 14260.461333274841, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 300872, "time": 14275.061991930008, "episode/length": 238.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 300904, "time": 14277.820467710495, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 300984, "time": 14282.176410675049, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 301256, "time": 14292.941766738892, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 301392, "time": 14299.425768852234, "episode/length": 525.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 301608, "time": 14308.109107017517, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 301632, "time": 14310.684390544891, "episode/length": 46.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8936170212765957, "episode/intrinsic_return": 0.0}
{"step": 301816, "time": 14318.257739305496, "episode/length": 175.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 302056, "time": 14327.983437538147, "episode/length": 55.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 302217, "time": 14336.097072601318, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.610865053923233, "train/action_min": 0.0, "train/action_std": 3.2078904967377153, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04872638188248527, "train/actor_opt_grad_steps": 18105.0, "train/actor_opt_loss": -4.251028817039037, "train/adv_mag": 0.740765587143276, "train/adv_max": 0.7302835039470507, "train/adv_mean": 0.003977196482478378, "train/adv_min": -0.5074054654957592, "train/adv_std": 0.07529444641609123, "train/cont_avg": 0.994735054347826, "train/cont_loss_mean": 0.00042514656980134646, "train/cont_loss_std": 0.012463005359824121, "train/cont_neg_acc": 0.9878505567709605, "train/cont_neg_loss": 0.03592216231995933, "train/cont_pos_acc": 0.9999217416929163, "train/cont_pos_loss": 0.0002543823487747883, "train/cont_pred": 0.994709016620249, "train/cont_rate": 0.994735054347826, "train/dyn_loss_mean": 13.948876311813576, "train/dyn_loss_std": 9.207024076710576, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9406891102376191, "train/extr_critic_critic_opt_grad_steps": 18105.0, "train/extr_critic_critic_opt_loss": 15720.368482506794, "train/extr_critic_mag": 4.971092763154403, "train/extr_critic_max": 4.971092763154403, "train/extr_critic_mean": 0.8982392266608666, "train/extr_critic_min": -0.23777017645213916, "train/extr_critic_std": 1.114119599694791, "train/extr_return_normed_mag": 1.8858828829682392, "train/extr_return_normed_max": 1.8858828829682392, "train/extr_return_normed_mean": 0.2915842535271161, "train/extr_return_normed_min": -0.14523885701445566, "train/extr_return_normed_std": 0.33711853321047797, "train/extr_return_rate": 0.4292803864548172, "train/extr_return_raw_mag": 6.368503888448079, "train/extr_return_raw_max": 6.368503888448079, "train/extr_return_raw_mean": 0.9118319566267125, "train/extr_return_raw_min": -0.5834464454564495, "train/extr_return_raw_std": 1.1541846968989442, "train/extr_reward_mag": 1.0133235990137295, "train/extr_reward_max": 1.0133235990137295, "train/extr_reward_mean": 0.024409426254746708, "train/extr_reward_min": -0.36873726050059, "train/extr_reward_std": 0.14346607596330022, "train/image_loss_mean": 7.971439085144928, "train/image_loss_std": 10.883635759353638, "train/model_loss_mean": 16.392145861750063, "train/model_loss_std": 14.794259845346645, "train/model_opt_grad_norm": 61.06259895937286, "train/model_opt_grad_steps": 18086.355072463768, "train/model_opt_loss": 13683.666567595108, "train/model_opt_model_opt_grad_overflow": 0.007246376811594203, "train/model_opt_model_opt_grad_scale": 828.804347826087, "train/policy_entropy_mag": 2.5171541407488394, "train/policy_entropy_max": 2.5171541407488394, "train/policy_entropy_mean": 0.6366326128659041, "train/policy_entropy_min": 0.07937527966240178, "train/policy_entropy_std": 0.6535047115623087, "train/policy_logprob_mag": 7.438382591026417, "train/policy_logprob_max": -0.009455882120823515, "train/policy_logprob_mean": -0.6356779090736223, "train/policy_logprob_min": -7.438382591026417, "train/policy_logprob_std": 1.1320771669995957, "train/policy_randomness_mag": 0.8884449501832327, "train/policy_randomness_max": 0.8884449501832327, "train/policy_randomness_mean": 0.22470337498015253, "train/policy_randomness_min": 0.028015990539089493, "train/policy_randomness_std": 0.23065848389397497, "train/post_ent_mag": 58.40628950146661, "train/post_ent_max": 58.40628950146661, "train/post_ent_mean": 40.482284352399304, "train/post_ent_min": 21.504594865052596, "train/post_ent_std": 7.078192406806393, "train/prior_ent_mag": 68.5368826492973, "train/prior_ent_max": 68.5368826492973, "train/prior_ent_mean": 54.53480491085329, "train/prior_ent_min": 36.29145243547965, "train/prior_ent_std": 5.382905631825544, "train/rep_loss_mean": 13.948876311813576, "train/rep_loss_std": 9.207024076710576, "train/reward_avg": 0.020952219123263723, "train/reward_loss_mean": 0.050956000573933125, "train/reward_loss_std": 0.24794050360071487, "train/reward_max_data": 1.0123188435167507, "train/reward_max_pred": 1.0078762778337451, "train/reward_neg_acc": 0.9932116926580236, "train/reward_neg_loss": 0.028377604846289192, "train/reward_pos_acc": 0.9545428459195123, "train/reward_pos_loss": 0.907892121784929, "train/reward_pred": 0.02031020793820853, "train/reward_rate": 0.02570906929347826, "train_stats/sum_log_reward": 5.205263097035258, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 7.175438596491228, "train_stats/max_log_achievement_collect_sapling": 3.0701754385964914, "train_stats/max_log_achievement_collect_stone": 0.017543859649122806, "train_stats/max_log_achievement_collect_wood": 7.228070175438597, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.4824561403508772, "train_stats/max_log_achievement_eat_cow": 0.12280701754385964, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07017543859649122, "train_stats/max_log_achievement_make_wood_sword": 0.017543859649122806, "train_stats/max_log_achievement_place_plant": 2.8771929824561404, "train_stats/max_log_achievement_place_stone": 0.008771929824561403, "train_stats/max_log_achievement_place_table": 2.543859649122807, "train_stats/max_log_achievement_wake_up": 1.5789473684210527, "train_stats/mean_log_entropy": 0.5702071285300088, "eval_stats/sum_log_reward": 4.724999934434891, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.75, "eval_stats/max_log_achievement_collect_sapling": 2.8125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 0.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 4.003814319730736e-05, "report/cont_loss_std": 0.000929621106479317, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.001292204251512885, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.5127690352965146e-05, "report/cont_pred": 0.996064305305481, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 11.238988876342773, "report/dyn_loss_std": 9.64619255065918, "report/image_loss_mean": 6.1641130447387695, "report/image_loss_std": 9.072431564331055, "report/model_loss_mean": 12.9413423538208, "report/model_loss_std": 13.411020278930664, "report/post_ent_mag": 57.633338928222656, "report/post_ent_max": 57.633338928222656, "report/post_ent_mean": 42.50237274169922, "report/post_ent_min": 20.252437591552734, "report/post_ent_std": 7.052191734313965, "report/prior_ent_mag": 68.45199584960938, "report/prior_ent_max": 68.45199584960938, "report/prior_ent_mean": 53.53086853027344, "report/prior_ent_min": 38.286277770996094, "report/prior_ent_std": 5.106472969055176, "report/rep_loss_mean": 11.238988876342773, "report/rep_loss_std": 9.64619255065918, "report/reward_avg": 0.008984374813735485, "report/reward_loss_mean": 0.03379608690738678, "report/reward_loss_std": 0.15333417057991028, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0348424911499023, "report/reward_neg_acc": 0.9950495362281799, "report/reward_neg_loss": 0.021824045106768608, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8974935412406921, "report/reward_pred": 0.007536770775914192, "report/reward_rate": 0.013671875, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 1.6177336874534376e-06, "eval/cont_loss_std": 3.8940812373766676e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0012407655594870448, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.0644525256539055e-07, "eval/cont_pred": 0.9990243315696716, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 17.141496658325195, "eval/dyn_loss_std": 10.629448890686035, "eval/image_loss_mean": 17.134899139404297, "eval/image_loss_std": 22.143722534179688, "eval/model_loss_mean": 27.492542266845703, "eval/model_loss_std": 26.489370346069336, "eval/post_ent_mag": 58.347434997558594, "eval/post_ent_max": 58.347434997558594, "eval/post_ent_mean": 40.67544174194336, "eval/post_ent_min": 22.120500564575195, "eval/post_ent_std": 6.55700159072876, "eval/prior_ent_mag": 68.45199584960938, "eval/prior_ent_max": 68.45199584960938, "eval/prior_ent_mean": 55.192726135253906, "eval/prior_ent_min": 36.14286804199219, "eval/prior_ent_std": 5.3559064865112305, "eval/rep_loss_mean": 17.141496658325195, "eval/rep_loss_std": 10.629448890686035, "eval/reward_avg": 0.02304687537252903, "eval/reward_loss_mean": 0.07274506241083145, "eval/reward_loss_std": 0.5381113290786743, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9981344938278198, "eval/reward_neg_acc": 0.9929929971694946, "eval/reward_neg_loss": 0.014691726304590702, "eval/reward_pos_acc": 0.6800000071525574, "eval/reward_pos_loss": 2.3925564289093018, "eval/reward_pred": 0.015940211713314056, "eval/reward_rate": 0.0244140625, "replay/size": 301713.0, "replay/inserts": 21992.0, "replay/samples": 22000.0, "replay/insert_wait_avg": 1.3912339867917612e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.576241406527432e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 63080.0, "eval_replay/inserts": 3952.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.268770530638907e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4898910522461, "timer/env.step_count": 2749.0, "timer/env.step_total": 258.58683228492737, "timer/env.step_frac": 0.2584602149382675, "timer/env.step_avg": 0.09406578111492447, "timer/env.step_min": 0.024080753326416016, "timer/env.step_max": 3.4134857654571533, "timer/replay._sample_count": 22000.0, "timer/replay._sample_total": 11.394177436828613, "timer/replay._sample_frac": 0.011388598264441238, "timer/replay._sample_avg": 0.0005179171562194825, "timer/replay._sample_min": 0.0003807544708251953, "timer/replay._sample_max": 0.011043310165405273, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3243.0, "timer/agent.policy_total": 54.500996828079224, "timer/agent.policy_frac": 0.05447431035086106, "timer/agent.policy_avg": 0.016805734452074998, "timer/agent.policy_min": 0.00964212417602539, "timer/agent.policy_max": 0.10280370712280273, "timer/dataset_train_count": 1375.0, "timer/dataset_train_total": 0.15451502799987793, "timer/dataset_train_frac": 0.00015443936953462838, "timer/dataset_train_avg": 0.00011237456581809304, "timer/dataset_train_min": 9.846687316894531e-05, "timer/dataset_train_max": 0.0011267662048339844, "timer/agent.train_count": 1375.0, "timer/agent.train_total": 619.330584526062, "timer/agent.train_frac": 0.6190273285766965, "timer/agent.train_avg": 0.45042224329168146, "timer/agent.train_min": 0.4389832019805908, "timer/agent.train_max": 1.575587511062622, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4850738048553467, "timer/agent.report_frac": 0.0004848362878961022, "timer/agent.report_avg": 0.24253690242767334, "timer/agent.report_min": 0.23701882362365723, "timer/agent.report_max": 0.24805498123168945, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.193450927734375e-05, "timer/dataset_eval_frac": 2.1923769019069796e-08, "timer/dataset_eval_avg": 2.193450927734375e-05, "timer/dataset_eval_min": 2.193450927734375e-05, "timer/dataset_eval_max": 2.193450927734375e-05, "fps": 21.980935968821743}
{"step": 302256, "time": 14337.483187437057, "episode/length": 172.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9826589595375722, "episode/intrinsic_return": 0.0}
{"step": 302448, "time": 14345.566479206085, "episode/length": 48.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 302560, "time": 14350.935668230057, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 302728, "time": 14358.12267947197, "episode/length": 166.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 302776, "time": 14361.361346006393, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 302792, "time": 14363.442096948624, "episode/length": 287.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 302896, "time": 14368.884978055954, "episode/length": 55.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 303248, "time": 14383.793891429901, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 303328, "time": 14388.125653505325, "episode/length": 211.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 303552, "time": 14397.190916776657, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 303808, "time": 14407.446361541748, "episode/length": 155.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 303816, "time": 14409.128858804703, "episode/length": 60.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9344262295081968, "episode/intrinsic_return": 0.0}
{"step": 304072, "time": 14419.41240477562, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 304192, "time": 14425.399778604507, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 304648, "time": 14442.045811891556, "episode/length": 218.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 304984, "time": 14454.973853826523, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 305008, "time": 14457.548084020615, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 305008, "time": 14457.557238578796, "episode/length": 278.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 305032, "time": 14461.459737300873, "episode/length": 222.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 305568, "time": 14481.416759967804, "episode/length": 219.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 305776, "time": 14490.007537603378, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 306312, "time": 14509.513276100159, "episode/length": 207.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 306336, "time": 14512.11989736557, "episode/length": 165.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 306408, "time": 14515.877575159073, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 306848, "time": 14532.889941453934, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 307128, "time": 14543.76058626175, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 307496, "time": 14557.73719072342, "episode/length": 313.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777070063694268, "episode/intrinsic_return": 0.0}
{"step": 307920, "time": 14573.921524524689, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 307920, "time": 14573.93020439148, "episode/length": 197.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 307984, "time": 14579.400373458862, "episode/length": 473.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9978902953586498, "episode/intrinsic_return": 0.0}
{"step": 308096, "time": 14584.863738298416, "episode/length": 315.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9841772151898734, "episode/intrinsic_return": 0.0}
{"step": 308432, "time": 14597.799068927765, "episode/length": 197.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 308632, "time": 14605.90574836731, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 309352, "time": 14631.976924657822, "episode/length": 178.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 309416, "time": 14635.673742055893, "episode/length": 387.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9974226804123711, "episode/intrinsic_return": 0.0}
{"step": 309496, "time": 14639.960424900055, "episode/length": 196.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 309560, "time": 14643.83788561821, "episode/length": 182.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 309800, "time": 14653.406995534897, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9532163742690059, "episode/intrinsic_return": 0.0}
{"step": 309928, "time": 14659.418493509293, "episode/length": 242.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 14685.33457994461, "eval_episode/length": 166.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 310024, "time": 14687.881206035614, "eval_episode/length": 184.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 310024, "time": 14690.082558393478, "eval_episode/length": 195.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 310024, "time": 14691.668091058731, "eval_episode/length": 196.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 310024, "time": 14693.341213703156, "eval_episode/length": 197.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 310024, "time": 14695.171768903732, "eval_episode/length": 36.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.8918918918918919}
{"step": 310024, "time": 14701.137450695038, "eval_episode/length": 262.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9961977186311787}
{"step": 310024, "time": 14704.268050193787, "eval_episode/length": 293.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 310280, "time": 14712.822113513947, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 310360, "time": 14717.242500782013, "episode/length": 53.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 310512, "time": 14724.238543510437, "episode/length": 376.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9893899204244032, "episode/intrinsic_return": 0.0}
{"step": 310760, "time": 14734.409558534622, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 311080, "time": 14746.84040927887, "episode/length": 189.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 311128, "time": 14750.14563703537, "episode/length": 45.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 311216, "time": 14754.894661664963, "episode/length": 232.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 311272, "time": 14758.073690414429, "episode/length": 231.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 311352, "time": 14763.884430408478, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 311488, "time": 14770.303439378738, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 312080, "time": 14791.959210157394, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 312344, "time": 14802.09028339386, "episode/length": 247.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 312400, "time": 14805.660094499588, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 312520, "time": 14811.227446079254, "episode/length": 162.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 312808, "time": 14822.321696043015, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 312816, "time": 14824.411866426468, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 313464, "time": 14847.564084291458, "episode/length": 246.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 313624, "time": 14854.654358148575, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 313952, "time": 14867.600094556808, "episode/length": 141.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 314032, "time": 14871.876770019531, "episode/length": 210.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 314456, "time": 14887.408730268478, "episode/length": 241.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 314576, "time": 14893.235253810883, "episode/length": 430.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 314584, "time": 14894.900714874268, "episode/length": 312.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9904153354632588, "episode/intrinsic_return": 0.0}
{"step": 314976, "time": 14909.948244810104, "episode/length": 270.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 315160, "time": 14917.51785159111, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 315240, "time": 14921.920597314835, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 315744, "time": 14940.842753887177, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 315792, "time": 14944.092864274979, "episode/length": 229.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 315888, "time": 14948.895074129105, "episode/length": 231.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 316048, "time": 14955.913791418076, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 316504, "time": 14972.912788391113, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 316696, "time": 14980.936668872833, "episode/length": 279.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 316744, "time": 14984.083070278168, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 316752, "time": 14986.267687559128, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 317080, "time": 14998.756988286972, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 317848, "time": 15026.194822311401, "episode/length": 224.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9688888888888889, "episode/intrinsic_return": 0.0}
{"step": 318000, "time": 15033.120518922806, "episode/length": 186.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 318056, "time": 15036.435607910156, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 318136, "time": 15040.679663658142, "episode/length": 179.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 318432, "time": 15052.376328229904, "episode/length": 209.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 318824, "time": 15067.00347328186, "episode/length": 366.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945504087193461, "episode/intrinsic_return": 0.0}
{"step": 319328, "time": 15085.760991573334, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 319368, "time": 15088.559004545212, "episode/length": 446.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 319384, "time": 15090.627586126328, "episode/length": 172.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 319672, "time": 15103.322033405304, "episode/length": 154.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 319712, "time": 15106.683247804642, "episode/length": 40.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 319808, "time": 15111.50872516632, "episode/length": 340.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9882697947214076, "episode/intrinsic_return": 0.0}
{"step": 319824, "time": 15113.662556171417, "episode/length": 61.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 15137.283903121948, "eval_episode/length": 64.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9384615384615385}
{"step": 320008, "time": 15142.612447977066, "eval_episode/length": 152.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 320008, "time": 15144.60513305664, "eval_episode/length": 160.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 320008, "time": 15147.299093484879, "eval_episode/length": 180.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 320008, "time": 15149.539683103561, "eval_episode/length": 195.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 320008, "time": 15151.188663005829, "eval_episode/length": 197.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 320008, "time": 15153.289674520493, "eval_episode/length": 46.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 320008, "time": 15156.918289899826, "eval_episode/length": 57.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 320112, "time": 15160.616765022278, "episode/length": 160.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 320608, "time": 15178.669379711151, "episode/length": 318.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.987460815047022, "episode/intrinsic_return": 0.0}
{"step": 320752, "time": 15185.124816894531, "episode/length": 326.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 320912, "time": 15192.076339006424, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 321016, "time": 15196.992953300476, "episode/length": 205.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9611650485436893, "episode/intrinsic_return": 0.0}
{"step": 321152, "time": 15203.507668733597, "episode/length": 165.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 321384, "time": 15212.788962364197, "episode/length": 213.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 321472, "time": 15217.634269952774, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 322240, "time": 15246.273943185806, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 322256, "time": 15248.428223371506, "episode/length": 305.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 322512, "time": 15258.752924919128, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 322744, "time": 15267.801881790161, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 323016, "time": 15278.595940113068, "episode/length": 203.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 323344, "time": 15291.60283946991, "episode/length": 233.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9700854700854701, "episode/intrinsic_return": 0.0}
{"step": 323592, "time": 15301.326264619827, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 323720, "time": 15307.179319143295, "episode/length": 320.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 323984, "time": 15318.026518583298, "episode/length": 421.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 324304, "time": 15330.570324659348, "episode/length": 223.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 324312, "time": 15332.175260305405, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 324361, "time": 15336.38329076767, "train_stats/sum_log_reward": 5.137735778430723, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 7.877358490566038, "train_stats/max_log_achievement_collect_sapling": 3.2641509433962264, "train_stats/max_log_achievement_collect_stone": 0.009433962264150943, "train_stats/max_log_achievement_collect_wood": 6.726415094339623, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.49056603773584906, "train_stats/max_log_achievement_eat_cow": 0.1509433962264151, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.03773584905660377, "train_stats/max_log_achievement_make_wood_sword": 0.10377358490566038, "train_stats/max_log_achievement_place_plant": 3.0943396226415096, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.5377358490566038, "train_stats/max_log_achievement_wake_up": 1.7735849056603774, "train_stats/mean_log_entropy": 0.6092676635620728, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.538477800894475, "train/action_min": 0.0, "train/action_std": 3.182648097259411, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04991236223798731, "train/actor_opt_grad_steps": 19485.0, "train/actor_opt_loss": -6.402709694660229, "train/adv_mag": 0.7241517024627631, "train/adv_max": 0.7036620769379796, "train/adv_mean": 0.00348503501379088, "train/adv_min": -0.5187137571797855, "train/adv_std": 0.0753790539405916, "train/cont_avg": 0.994522758152174, "train/cont_loss_mean": 0.00043542414476335176, "train/cont_loss_std": 0.011729409414296444, "train/cont_neg_acc": 0.9893436471041102, "train/cont_neg_loss": 0.033214455034476155, "train/cont_pos_acc": 0.9999217062756636, "train/cont_pos_loss": 0.00024208096449817657, "train/cont_pred": 0.9945157753384631, "train/cont_rate": 0.994522758152174, "train/dyn_loss_mean": 14.059654933818873, "train/dyn_loss_std": 9.146671495575836, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9215995742790941, "train/extr_critic_critic_opt_grad_steps": 19485.0, "train/extr_critic_critic_opt_loss": 15990.378467504528, "train/extr_critic_mag": 5.072231078493422, "train/extr_critic_max": 5.072231078493422, "train/extr_critic_mean": 0.9241552331309387, "train/extr_critic_min": -0.2524223198061404, "train/extr_critic_std": 1.1276845098405643, "train/extr_return_normed_mag": 1.8560029250988062, "train/extr_return_normed_max": 1.8560029250988062, "train/extr_return_normed_mean": 0.2947500259547994, "train/extr_return_normed_min": -0.1600783285347448, "train/extr_return_normed_std": 0.3361173449219137, "train/extr_return_rate": 0.44262343645095825, "train/extr_return_raw_mag": 6.352555043455483, "train/extr_return_raw_max": 6.352555043455483, "train/extr_return_raw_mean": 0.9362686406011167, "train/extr_return_raw_min": -0.6414369720479717, "train/extr_return_raw_std": 1.1660154561201732, "train/extr_reward_mag": 1.016657779182213, "train/extr_reward_max": 1.016657779182213, "train/extr_reward_mean": 0.024777966079072677, "train/extr_reward_min": -0.42744494693866675, "train/extr_reward_std": 0.14577114436289537, "train/image_loss_mean": 7.880130988964136, "train/image_loss_std": 11.282307524611985, "train/model_loss_mean": 16.368182465650033, "train/model_loss_std": 15.14592668975609, "train/model_opt_grad_norm": 65.90840447467306, "train/model_opt_grad_steps": 19465.572463768116, "train/model_opt_loss": 15230.638954936594, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 928.4420289855072, "train/policy_entropy_mag": 2.513738665027895, "train/policy_entropy_max": 2.513738665027895, "train/policy_entropy_mean": 0.616982450303824, "train/policy_entropy_min": 0.07937525941625885, "train/policy_entropy_std": 0.6472696039987647, "train/policy_logprob_mag": 7.438382632490518, "train/policy_logprob_max": -0.00945582812436033, "train/policy_logprob_mean": -0.6175380420425663, "train/policy_logprob_min": -7.438382632490518, "train/policy_logprob_std": 1.1319497331329014, "train/policy_randomness_mag": 0.8872394380362137, "train/policy_randomness_max": 0.8872394380362137, "train/policy_randomness_mean": 0.21776772992334503, "train/policy_randomness_min": 0.028015983196488327, "train/policy_randomness_std": 0.22845776487087857, "train/post_ent_mag": 58.277481466099836, "train/post_ent_max": 58.277481466099836, "train/post_ent_mean": 40.57517159503439, "train/post_ent_min": 21.54815762284873, "train/post_ent_std": 7.05018068742061, "train/prior_ent_mag": 68.76212205748627, "train/prior_ent_max": 68.76212205748627, "train/prior_ent_mean": 54.74577151865199, "train/prior_ent_min": 37.44399747986724, "train/prior_ent_std": 5.134366636690886, "train/rep_loss_mean": 14.059654933818873, "train/rep_loss_std": 9.146671495575836, "train/reward_avg": 0.0218849068817993, "train/reward_loss_mean": 0.051823190764348576, "train/reward_loss_std": 0.2553247842343821, "train/reward_max_data": 1.0217391356177952, "train/reward_max_pred": 1.0087271617806477, "train/reward_neg_acc": 0.9939261800137119, "train/reward_neg_loss": 0.02850579932682972, "train/reward_pos_acc": 0.9576970118543376, "train/reward_pos_loss": 0.905959661456122, "train/reward_pred": 0.020931369992836877, "train/reward_rate": 0.026721014492753624, "eval_stats/sum_log_reward": 4.599999949336052, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.5625, "eval_stats/max_log_achievement_collect_sapling": 2.5625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.1875, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.456838698592037e-05, "report/cont_loss_std": 0.0016261314740404487, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003920028102584183, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.2912673709215596e-05, "report/cont_pred": 0.995067834854126, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.248218536376953, "report/dyn_loss_std": 8.841571807861328, "report/image_loss_mean": 7.0308403968811035, "report/image_loss_std": 8.386616706848145, "report/model_loss_mean": 15.63951301574707, "report/model_loss_std": 12.041817665100098, "report/post_ent_mag": 60.6156120300293, "report/post_ent_max": 60.6156120300293, "report/post_ent_mean": 40.4192008972168, "report/post_ent_min": 20.865253448486328, "report/post_ent_std": 7.450639724731445, "report/prior_ent_mag": 68.70511627197266, "report/prior_ent_max": 68.70511627197266, "report/prior_ent_mean": 54.644779205322266, "report/prior_ent_min": 35.2413330078125, "report/prior_ent_std": 5.425976276397705, "report/rep_loss_mean": 14.248218536376953, "report/rep_loss_std": 8.841571807861328, "report/reward_avg": 0.03066406212747097, "report/reward_loss_mean": 0.059687480330467224, "report/reward_loss_std": 0.29671168327331543, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.01882004737854, "report/reward_neg_acc": 0.9939271211624146, "report/reward_neg_loss": 0.03142590820789337, "report/reward_pos_acc": 0.9722222089767456, "report/reward_pos_loss": 0.8353107571601868, "report/reward_pred": 0.029616380110383034, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0001829313114285469, "eval/cont_loss_std": 0.004114246461540461, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.014291209168732166, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00011370520951459184, "eval/cont_pred": 0.9950772523880005, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.084774017333984, "eval/dyn_loss_std": 10.10637378692627, "eval/image_loss_mean": 16.115947723388672, "eval/image_loss_std": 18.15594482421875, "eval/model_loss_mean": 26.43951416015625, "eval/model_loss_std": 22.290119171142578, "eval/post_ent_mag": 57.360801696777344, "eval/post_ent_max": 57.360801696777344, "eval/post_ent_mean": 41.627410888671875, "eval/post_ent_min": 20.754886627197266, "eval/post_ent_std": 6.3334808349609375, "eval/prior_ent_mag": 68.70511627197266, "eval/prior_ent_max": 68.70511627197266, "eval/prior_ent_mean": 55.27912139892578, "eval/prior_ent_min": 36.757652282714844, "eval/prior_ent_std": 5.389814853668213, "eval/rep_loss_mean": 17.084774017333984, "eval/rep_loss_std": 10.10637378692627, "eval/reward_avg": 0.021484375, "eval/reward_loss_mean": 0.07252001762390137, "eval/reward_loss_std": 0.4657478630542755, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.00294828414917, "eval/reward_neg_acc": 0.9889668822288513, "eval/reward_neg_loss": 0.03517135605216026, "eval/reward_pos_acc": 0.8518518805503845, "eval/reward_pos_loss": 1.4516539573669434, "eval/reward_pred": 0.023176606744527817, "eval/reward_rate": 0.0263671875, "replay/size": 323857.0, "replay/inserts": 22144.0, "replay/samples": 22144.0, "replay/insert_wait_avg": 1.4013874565245788e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.583241115415716e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 67480.0, "eval_replay/inserts": 4400.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3339519500732421e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2720739841461, "timer/env.step_count": 2768.0, "timer/env.step_total": 247.59020829200745, "timer/env.step_frac": 0.24752286376029692, "timer/env.step_avg": 0.0894473295852628, "timer/env.step_min": 0.023868799209594727, "timer/env.step_max": 3.3534622192382812, "timer/replay._sample_count": 22144.0, "timer/replay._sample_total": 11.525269508361816, "timer/replay._sample_frac": 0.011522134635285727, "timer/replay._sample_avg": 0.0005204691793877265, "timer/replay._sample_min": 0.0003943443298339844, "timer/replay._sample_max": 0.00986790657043457, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3318.0, "timer/agent.policy_total": 57.65558218955994, "timer/agent.policy_frac": 0.05763989987235588, "timer/agent.policy_avg": 0.017376607049294737, "timer/agent.policy_min": 0.009456634521484375, "timer/agent.policy_max": 0.13061833381652832, "timer/dataset_train_count": 1384.0, "timer/dataset_train_total": 0.15673065185546875, "timer/dataset_train_frac": 0.00015668802112129432, "timer/dataset_train_avg": 0.00011324469064701499, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.001100778579711914, "timer/agent.train_count": 1384.0, "timer/agent.train_total": 624.866117477417, "timer/agent.train_frac": 0.624696153905943, "timer/agent.train_avg": 0.4514928594490007, "timer/agent.train_min": 0.43645334243774414, "timer/agent.train_max": 1.5752604007720947, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48438048362731934, "timer/agent.report_frac": 0.0004842487321454468, "timer/agent.report_avg": 0.24219024181365967, "timer/agent.report_min": 0.23286819458007812, "timer/agent.report_max": 0.2515122890472412, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.1701045990623546e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 22.137682224083868}
{"step": 324688, "time": 15347.539237499237, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 324888, "time": 15355.540861845016, "episode/length": 328.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9878419452887538, "episode/intrinsic_return": 0.0}
{"step": 325040, "time": 15362.456982374191, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 325048, "time": 15364.060735225677, "episode/length": 253.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 325256, "time": 15372.769649744034, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 325368, "time": 15378.364296197891, "episode/length": 39.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 325432, "time": 15382.582783222198, "episode/length": 92.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.956989247311828, "episode/intrinsic_return": 0.0}
{"step": 325496, "time": 15386.284062385559, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 325640, "time": 15392.83892583847, "episode/length": 33.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8529411764705882, "episode/intrinsic_return": 0.0}
{"step": 325728, "time": 15397.594513654709, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 326152, "time": 15413.365875720978, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 326488, "time": 15426.210492372513, "episode/length": 131.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.946969696969697, "episode/intrinsic_return": 0.0}
{"step": 326800, "time": 15438.65775513649, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 326856, "time": 15442.053159236908, "episode/length": 226.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 327088, "time": 15451.65644812584, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 327320, "time": 15460.917800426483, "episode/length": 145.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 327344, "time": 15463.690239667892, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 327440, "time": 15468.808143615723, "episode/length": 318.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9780564263322884, "episode/intrinsic_return": 0.0}
{"step": 327568, "time": 15474.628451108932, "episode/length": 229.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 327784, "time": 15484.688452243805, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 328528, "time": 15511.59589767456, "episode/length": 208.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 328632, "time": 15516.667925834656, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 328656, "time": 15519.423862934113, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 328816, "time": 15526.48328948021, "episode/length": 171.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 328912, "time": 15531.356783151627, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 328936, "time": 15533.509853839874, "episode/length": 266.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 329000, "time": 15537.197517871857, "episode/length": 45.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 329248, "time": 15547.538040399551, "episode/length": 240.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 15597.755258321762, "eval_episode/length": 157.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 330096, "time": 15599.899738073349, "eval_episode/length": 160.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 330096, "time": 15602.221382141113, "eval_episode/length": 168.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 330096, "time": 15604.390508413315, "eval_episode/length": 181.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 330096, "time": 15607.033529520035, "eval_episode/length": 205.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 330096, "time": 15609.044243812561, "eval_episode/length": 215.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 330096, "time": 15610.763944149017, "eval_episode/length": 217.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.981651376146789}
{"step": 330096, "time": 15613.626516103745, "eval_episode/length": 40.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.975609756097561}
{"step": 330440, "time": 15625.126754283905, "episode/length": 190.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 330448, "time": 15627.159056425095, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 330480, "time": 15629.830083847046, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 330624, "time": 15636.368292570114, "episode/length": 225.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 330648, "time": 15638.602249622345, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 330728, "time": 15642.874334096909, "episode/length": 184.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 330784, "time": 15646.728394031525, "episode/length": 374.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.0}
{"step": 331168, "time": 15661.255729198456, "episode/length": 329.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.996969696969697, "episode/intrinsic_return": 0.0}
{"step": 331208, "time": 15664.073968410492, "episode/length": 90.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.945054945054945, "episode/intrinsic_return": 0.0}
{"step": 331784, "time": 15685.121568918228, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 331856, "time": 15689.35205578804, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 332296, "time": 15705.721508026123, "episode/length": 205.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 332368, "time": 15710.134478330612, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 332384, "time": 15712.37686419487, "episode/length": 241.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 332672, "time": 15723.761666297913, "episode/length": 187.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 332880, "time": 15732.199571371078, "episode/length": 63.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 333064, "time": 15739.75666642189, "episode/length": 284.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 333072, "time": 15741.905547857285, "episode/length": 49.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 333088, "time": 15744.01465845108, "episode/length": 162.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 333096, "time": 15745.673735141754, "episode/length": 235.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 333704, "time": 15767.816196918488, "episode/length": 230.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 334336, "time": 15790.801518678665, "episode/length": 243.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 334608, "time": 15801.598926067352, "episode/length": 188.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 335264, "time": 15825.41773891449, "episode/length": 274.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9672727272727273, "episode/intrinsic_return": 0.0}
{"step": 335408, "time": 15832.041925668716, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 335728, "time": 15844.367015600204, "episode/length": 428.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9976689976689976, "episode/intrinsic_return": 0.0}
{"step": 335816, "time": 15848.74407339096, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 335832, "time": 15850.92999958992, "episode/length": 344.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9971014492753624, "episode/intrinsic_return": 0.0}
{"step": 335928, "time": 15857.497839450836, "episode/length": 354.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9887323943661972, "episode/intrinsic_return": 0.0}
{"step": 335944, "time": 15859.537134170532, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 336232, "time": 15870.841140985489, "episode/length": 49.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 336336, "time": 15876.214983224869, "episode/length": 431.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 336528, "time": 15884.316065073013, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 336664, "time": 15890.293069839478, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 336720, "time": 15893.942843914032, "episode/length": 60.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 337016, "time": 15905.15113401413, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 337288, "time": 15915.830322265625, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 337376, "time": 15920.73464512825, "episode/length": 105.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 337560, "time": 15928.245107412338, "episode/length": 201.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 338232, "time": 15952.575667381287, "episode/length": 236.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 338400, "time": 15959.962027311325, "episode/length": 172.0, "episode/score": 4.1000000312924385, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 338424, "time": 15962.1676902771, "episode/length": 325.0, "episode/score": 7.0999999567866325, "episode/reward_rate": 0.9969325153374233, "episode/intrinsic_return": 0.0}
{"step": 338504, "time": 15966.426599502563, "episode/length": 222.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 338656, "time": 15973.2914352417, "episode/length": 248.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 338680, "time": 15975.472253799438, "episode/length": 139.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 338792, "time": 15980.976139068604, "episode/length": 187.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 339416, "time": 16003.317707061768, "episode/length": 147.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 339648, "time": 16013.072825670242, "episode/length": 283.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753521126760564, "episode/intrinsic_return": 0.0}
{"step": 339864, "time": 16021.711547136307, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 339880, "time": 16023.793067216873, "episode/length": 184.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 16047.273136854172, "eval_episode/length": 37.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.8947368421052632}
{"step": 340080, "time": 16054.488347291946, "eval_episode/length": 165.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 340080, "time": 16056.624269485474, "eval_episode/length": 175.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 340080, "time": 16058.433964729309, "eval_episode/length": 178.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 340080, "time": 16060.164186954498, "eval_episode/length": 182.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.994535519125683}
{"step": 340080, "time": 16062.664319753647, "eval_episode/length": 164.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 340080, "time": 16064.550801992416, "eval_episode/length": 208.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 340080, "time": 16067.236295938492, "eval_episode/length": 232.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9742489270386266}
{"step": 340256, "time": 16073.107024908066, "episode/length": 199.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 340272, "time": 16075.413530111313, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 340472, "time": 16083.459998369217, "episode/length": 255.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 340768, "time": 16095.204448223114, "episode/length": 246.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 341560, "time": 16123.192881345749, "episode/length": 209.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 341680, "time": 16129.154995203018, "episode/length": 150.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 341792, "time": 16134.565740585327, "episode/length": 189.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 341864, "time": 16138.306471347809, "episode/length": 249.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 341896, "time": 16140.998831510544, "episode/length": 204.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 342224, "time": 16153.749234437943, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 342336, "time": 16159.041036128998, "episode/length": 335.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9851190476190477, "episode/intrinsic_return": 0.0}
{"step": 342848, "time": 16177.664352178574, "episode/length": 428.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9906759906759907, "episode/intrinsic_return": 0.0}
{"step": 343232, "time": 16192.208596944809, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 343408, "time": 16200.383373498917, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 343648, "time": 16210.123296499252, "episode/length": 231.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 343784, "time": 16216.113638162613, "episode/length": 194.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 343936, "time": 16223.016559839249, "episode/length": 199.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 344112, "time": 16232.246179819107, "episode/length": 318.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9905956112852664, "episode/intrinsic_return": 0.0}
{"step": 344392, "time": 16243.051008224487, "episode/length": 56.0, "episode/score": 0.10000002384185791, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 344624, "time": 16252.7857568264, "episode/length": 173.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 344752, "time": 16258.610028505325, "episode/length": 167.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 345000, "time": 16268.288544893265, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 345120, "time": 16274.30505156517, "episode/length": 283.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9823943661971831, "episode/intrinsic_return": 0.0}
{"step": 345216, "time": 16279.113842248917, "episode/length": 418.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9785202863961814, "episode/intrinsic_return": 0.0}
{"step": 345344, "time": 16285.065020561218, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 345792, "time": 16301.538429498672, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 346184, "time": 16316.146220684052, "episode/length": 48.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 346392, "time": 16324.665035009384, "episode/length": 173.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 346544, "time": 16331.646065235138, "episode/length": 44.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 346617, "time": 16336.479378938675, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.733317642760792, "train/action_min": 0.0, "train/action_std": 3.3456549644470215, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04994001279739167, "train/actor_opt_grad_steps": 20870.0, "train/actor_opt_loss": -2.712769513507541, "train/adv_mag": 0.7068842823128049, "train/adv_max": 0.6988681164576853, "train/adv_mean": 0.00427516951139224, "train/adv_min": -0.48441566323204865, "train/adv_std": 0.07477379909200634, "train/cont_avg": 0.9947659060251799, "train/cont_loss_mean": 0.00023422362333644822, "train/cont_loss_std": 0.006246894308037139, "train/cont_neg_acc": 0.9929779171943665, "train/cont_neg_loss": 0.015659034967899534, "train/cont_pos_acc": 0.9999505401515275, "train/cont_pos_loss": 0.0001457122612827589, "train/cont_pred": 0.9947517514228821, "train/cont_rate": 0.9947659060251799, "train/dyn_loss_mean": 13.8201783955526, "train/dyn_loss_std": 9.17438859390698, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8828646043221727, "train/extr_critic_critic_opt_grad_steps": 20870.0, "train/extr_critic_critic_opt_loss": 15760.505353529676, "train/extr_critic_mag": 5.088482160362409, "train/extr_critic_max": 5.088482160362409, "train/extr_critic_mean": 0.920276287005102, "train/extr_critic_min": -0.2310911151145002, "train/extr_critic_std": 1.1209770209497685, "train/extr_return_normed_mag": 1.8845375964967468, "train/extr_return_normed_max": 1.8845375964967468, "train/extr_return_normed_mean": 0.29571935437994895, "train/extr_return_normed_min": -0.1538905111684216, "train/extr_return_normed_std": 0.3407835424375191, "train/extr_return_rate": 0.4395856978438741, "train/extr_return_raw_mag": 6.3349274594149145, "train/extr_return_raw_max": 6.3349274594149145, "train/extr_return_raw_mean": 0.9347755737441907, "train/extr_return_raw_min": -0.5932107810065043, "train/extr_return_raw_std": 1.1582334461829644, "train/extr_reward_mag": 1.0153273026720226, "train/extr_reward_max": 1.0153273026720226, "train/extr_reward_mean": 0.025670840753336175, "train/extr_reward_min": -0.4075727720054791, "train/extr_reward_std": 0.14809602032676875, "train/image_loss_mean": 7.643129256131838, "train/image_loss_std": 11.114211984675565, "train/model_loss_mean": 15.987563435122263, "train/model_loss_std": 14.957108998470169, "train/model_opt_grad_norm": 64.89524429650615, "train/model_opt_grad_steps": 20849.56834532374, "train/model_opt_loss": 12714.278896414118, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 795.863309352518, "train/policy_entropy_mag": 2.5020265150413237, "train/policy_entropy_max": 2.5020265150413237, "train/policy_entropy_mean": 0.6713981287513705, "train/policy_entropy_min": 0.07937524687472007, "train/policy_entropy_std": 0.6851185380126075, "train/policy_logprob_mag": 7.438382934323318, "train/policy_logprob_max": -0.009455839661117509, "train/policy_logprob_mean": -0.672248165384471, "train/policy_logprob_min": -7.438382934323318, "train/policy_logprob_std": 1.1632008788396986, "train/policy_randomness_mag": 0.8831055618876176, "train/policy_randomness_max": 0.8831055618876176, "train/policy_randomness_mean": 0.23697407661582068, "train/policy_randomness_min": 0.028015978580756152, "train/policy_randomness_std": 0.2418167779771544, "train/post_ent_mag": 58.76606769698987, "train/post_ent_max": 58.76606769698987, "train/post_ent_mean": 41.02326238069603, "train/post_ent_min": 21.67604541092468, "train/post_ent_std": 7.176136174647928, "train/prior_ent_mag": 68.91817265791859, "train/prior_ent_max": 68.91817265791859, "train/prior_ent_mean": 54.89724292343469, "train/prior_ent_min": 38.15360002037433, "train/prior_ent_std": 5.066425645951744, "train/rep_loss_mean": 13.8201783955526, "train/rep_loss_std": 9.17438859390698, "train/reward_avg": 0.022726506055098215, "train/reward_loss_mean": 0.0520931354609968, "train/reward_loss_std": 0.2504686818277235, "train/reward_max_data": 1.015827341903028, "train/reward_max_pred": 1.0077137063733108, "train/reward_neg_acc": 0.9934544824867797, "train/reward_neg_loss": 0.028427655694724843, "train/reward_pos_acc": 0.9585338252053844, "train/reward_pos_loss": 0.8935526167746071, "train/reward_pred": 0.021820223267129856, "train/reward_rate": 0.02742103192446043, "train_stats/sum_log_reward": 5.305607411488194, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.308411214953271, "train_stats/max_log_achievement_collect_sapling": 2.8411214953271027, "train_stats/max_log_achievement_collect_stone": 0.056074766355140186, "train_stats/max_log_achievement_collect_wood": 7.635514018691588, "train_stats/max_log_achievement_defeat_skeleton": 0.018691588785046728, "train_stats/max_log_achievement_defeat_zombie": 0.4953271028037383, "train_stats/max_log_achievement_eat_cow": 0.08411214953271028, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.18691588785046728, "train_stats/max_log_achievement_make_wood_sword": 0.3177570093457944, "train_stats/max_log_achievement_place_plant": 2.6728971962616823, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.663551401869159, "train_stats/max_log_achievement_wake_up": 1.8504672897196262, "train_stats/mean_log_entropy": 0.6351621552048442, "eval_stats/sum_log_reward": 4.787499904632568, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 7.375, "eval_stats/max_log_achievement_collect_sapling": 2.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.0, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.004467936232686043, "report/cont_loss_std": 0.1427118331193924, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0006768849561922252, "report/cont_pos_acc": 0.9990177154541016, "report/cont_pos_loss": 0.00449028005823493, "report/cont_pred": 0.9931761622428894, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 14.616377830505371, "report/dyn_loss_std": 9.46048355102539, "report/image_loss_mean": 6.930871963500977, "report/image_loss_std": 8.903192520141602, "report/model_loss_mean": 15.773295402526855, "report/model_loss_std": 13.008179664611816, "report/post_ent_mag": 55.72574234008789, "report/post_ent_max": 55.72574234008789, "report/post_ent_mean": 40.120460510253906, "report/post_ent_min": 20.872127532958984, "report/post_ent_std": 7.100128650665283, "report/prior_ent_mag": 69.05792236328125, "report/prior_ent_max": 69.05792236328125, "report/prior_ent_mean": 54.683834075927734, "report/prior_ent_min": 36.60967254638672, "report/prior_ent_std": 5.013848304748535, "report/rep_loss_mean": 14.616377830505371, "report/rep_loss_std": 9.46048355102539, "report/reward_avg": 0.02275390550494194, "report/reward_loss_mean": 0.06812886148691177, "report/reward_loss_std": 0.39601612091064453, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0013830661773682, "report/reward_neg_acc": 0.9879518747329712, "report/reward_neg_loss": 0.03660625219345093, "report/reward_pos_acc": 0.9285714626312256, "report/reward_pos_loss": 1.1894333362579346, "report/reward_pred": 0.02285926789045334, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 4.271430498192785e-06, "eval/cont_loss_std": 6.541605398524553e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0005593766691163182, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.094546971420641e-06, "eval/cont_pred": 0.9960939288139343, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.894832611083984, "eval/dyn_loss_std": 10.228524208068848, "eval/image_loss_mean": 12.861183166503906, "eval/image_loss_std": 16.194271087646484, "eval/model_loss_mean": 23.053497314453125, "eval/model_loss_std": 20.24358558654785, "eval/post_ent_mag": 59.23274230957031, "eval/post_ent_max": 59.23274230957031, "eval/post_ent_mean": 41.74687194824219, "eval/post_ent_min": 21.920900344848633, "eval/post_ent_std": 7.250595569610596, "eval/prior_ent_mag": 69.05792236328125, "eval/prior_ent_max": 69.05792236328125, "eval/prior_ent_mean": 56.22477340698242, "eval/prior_ent_min": 41.17985916137695, "eval/prior_ent_std": 5.505603313446045, "eval/rep_loss_mean": 16.894832611083984, "eval/rep_loss_std": 10.228524208068848, "eval/reward_avg": 0.01962890475988388, "eval/reward_loss_mean": 0.05541156977415085, "eval/reward_loss_std": 0.36144983768463135, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.00205659866333, "eval/reward_neg_acc": 0.9930069446563721, "eval/reward_neg_loss": 0.019658571109175682, "eval/reward_pos_acc": 0.782608687877655, "eval/reward_pos_loss": 1.6114442348480225, "eval/reward_pred": 0.01558458898216486, "eval/reward_rate": 0.0224609375, "replay/size": 346113.0, "replay/inserts": 22256.0, "replay/samples": 22256.0, "replay/insert_wait_avg": 1.4184062897430574e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.807325431719519e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 71320.0, "eval_replay/inserts": 3840.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2785817186037698e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1324882507324219e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0802903175354, "timer/env.step_count": 2782.0, "timer/env.step_total": 249.84678101539612, "timer/env.step_frac": 0.24982672234852993, "timer/env.step_avg": 0.08980833250014239, "timer/env.step_min": 0.023239612579345703, "timer/env.step_max": 2.232119083404541, "timer/replay._sample_count": 22256.0, "timer/replay._sample_total": 11.70602536201477, "timer/replay._sample_frac": 0.011705085556978622, "timer/replay._sample_avg": 0.0005259716643608362, "timer/replay._sample_min": 0.00037741661071777344, "timer/replay._sample_max": 0.011405229568481445, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3262.0, "timer/agent.policy_total": 55.34770846366882, "timer/agent.policy_frac": 0.05534326493535372, "timer/agent.policy_avg": 0.016967415224913802, "timer/agent.policy_min": 0.009579896926879883, "timer/agent.policy_max": 0.10918045043945312, "timer/dataset_train_count": 1391.0, "timer/dataset_train_total": 0.15678000450134277, "timer/dataset_train_frac": 0.0001567674175956048, "timer/dataset_train_avg": 0.00011271028360987979, "timer/dataset_train_min": 0.00010037422180175781, "timer/dataset_train_max": 0.0002944469451904297, "timer/agent.train_count": 1391.0, "timer/agent.train_total": 626.59406208992, "timer/agent.train_frac": 0.6265437566927453, "timer/agent.train_avg": 0.45046302091295476, "timer/agent.train_min": 0.43365478515625, "timer/agent.train_max": 1.776587724685669, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4981999397277832, "timer/agent.report_frac": 0.0004981599423078319, "timer/agent.report_avg": 0.2490999698638916, "timer/agent.report_min": 0.22590303421020508, "timer/agent.report_max": 0.2722969055175781, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9084731428068835e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 22.253890739801793}
{"step": 346672, "time": 16338.413969993591, "episode/length": 255.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 346768, "time": 16343.356141805649, "episode/length": 205.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 346856, "time": 16347.825310707092, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 346992, "time": 16354.318016529083, "episode/length": 400.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9950124688279302, "episode/intrinsic_return": 0.0}
{"step": 347376, "time": 16368.89522409439, "episode/length": 327.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9969512195121951, "episode/intrinsic_return": 0.0}
{"step": 347712, "time": 16381.761140108109, "episode/length": 145.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 347720, "time": 16383.404836893082, "episode/length": 312.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9968051118210862, "episode/intrinsic_return": 0.0}
{"step": 347776, "time": 16387.092799663544, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 347912, "time": 16393.1089220047, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 348360, "time": 16410.019783258438, "episode/length": 198.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 348904, "time": 16429.963464975357, "episode/length": 255.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 349032, "time": 16435.954941749573, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 349072, "time": 16439.24719429016, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 349136, "time": 16442.971275806427, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 349192, "time": 16446.222361326218, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 349408, "time": 16455.4363219738, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 349504, "time": 16460.456658363342, "episode/length": 142.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 349528, "time": 16462.733435869217, "episode/length": 316.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9905362776025236, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 16497.838099956512, "eval_episode/length": 46.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 350064, "time": 16503.908493995667, "eval_episode/length": 149.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 350064, "time": 16506.03344655037, "eval_episode/length": 161.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 350064, "time": 16510.815298080444, "eval_episode/length": 187.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 350064, "time": 16514.194640159607, "eval_episode/length": 248.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9959839357429718}
{"step": 350064, "time": 16518.110310792923, "eval_episode/length": 286.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9965156794425087}
{"step": 350064, "time": 16521.019834041595, "eval_episode/length": 165.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 350064, "time": 16522.8195977211, "eval_episode/length": 157.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 350424, "time": 16534.711564302444, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 350464, "time": 16537.856326580048, "episode/length": 194.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 350576, "time": 16543.31380558014, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 350768, "time": 16551.521792411804, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 350816, "time": 16554.67876982689, "episode/length": 43.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 350856, "time": 16557.410482406616, "episode/length": 222.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 351024, "time": 16564.887253046036, "episode/length": 228.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 351352, "time": 16577.327821969986, "episode/length": 61.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 351536, "time": 16585.2624065876, "episode/length": 265.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9661654135338346, "episode/intrinsic_return": 0.0}
{"step": 351560, "time": 16587.95779275894, "episode/length": 256.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 351832, "time": 16598.729073762894, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 351904, "time": 16603.009602069855, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 352056, "time": 16609.62771010399, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 352360, "time": 16622.830261468887, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 352848, "time": 16641.19362640381, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 352904, "time": 16644.544987678528, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 353048, "time": 16650.898134708405, "episode/length": 185.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 353152, "time": 16656.160910844803, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 353256, "time": 16661.156834363937, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 353816, "time": 16681.67517185211, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 354024, "time": 16690.269023418427, "episode/length": 146.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 354248, "time": 16699.50239086151, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 354504, "time": 16709.686702489853, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 354512, "time": 16711.82199883461, "episode/length": 306.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9771986970684039, "episode/intrinsic_return": 0.0}
{"step": 354520, "time": 16713.404339551926, "episode/length": 183.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 354584, "time": 16717.193702697754, "episode/length": 41.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 354840, "time": 16727.578531742096, "episode/length": 435.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9931192660550459, "episode/intrinsic_return": 0.0}
{"step": 355304, "time": 16744.865474939346, "episode/length": 268.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 355320, "time": 16746.97366952896, "episode/length": 187.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 355536, "time": 16756.063744306564, "episode/length": 126.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 355816, "time": 16766.91427755356, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 355944, "time": 16772.834270000458, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 356024, "time": 16777.064200162888, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 356448, "time": 16793.276312351227, "episode/length": 232.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 356448, "time": 16793.284324884415, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 356672, "time": 16804.11447405815, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 356888, "time": 16812.756727457047, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.0}
{"step": 357296, "time": 16828.288247346878, "episode/length": 248.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 357424, "time": 16834.216638565063, "episode/length": 174.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 357552, "time": 16840.170291423798, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 358136, "time": 16861.725545167923, "episode/length": 273.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 358224, "time": 16866.446939706802, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 358248, "time": 16868.518270254135, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 358280, "time": 16871.24821138382, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 358600, "time": 16883.68702840805, "episode/length": 240.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 358624, "time": 16886.344196796417, "episode/length": 60.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9344262295081968, "episode/intrinsic_return": 0.0}
{"step": 358648, "time": 16888.56166243553, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 359128, "time": 16906.357232809067, "episode/length": 59.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 359208, "time": 16910.62811899185, "episode/length": 238.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 359448, "time": 16920.348883867264, "episode/length": 145.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 359528, "time": 16924.614234924316, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 359544, "time": 16926.784059524536, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 359904, "time": 16940.772507190704, "episode/length": 162.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 359960, "time": 16943.987614154816, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 359960, "time": 16943.998097658157, "episode/length": 300.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9900332225913622, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 16971.133178949356, "eval_episode/length": 154.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 360048, "time": 16972.948043823242, "eval_episode/length": 158.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 360048, "time": 16972.956088781357, "eval_episode/length": 158.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 360048, "time": 16976.94294857979, "eval_episode/length": 174.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 360048, "time": 16979.58173775673, "eval_episode/length": 199.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 360048, "time": 16982.313653945923, "eval_episode/length": 226.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9823788546255506}
{"step": 360048, "time": 16986.131144285202, "eval_episode/length": 277.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9820143884892086}
{"step": 360048, "time": 16988.43048810959, "eval_episode/length": 291.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9828767123287672}
{"step": 360208, "time": 16993.78940153122, "episode/length": 30.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8387096774193549, "episode/intrinsic_return": 0.0}
{"step": 360520, "time": 17007.12494778633, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 360688, "time": 17014.616109132767, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 360816, "time": 17020.630913496017, "episode/length": 158.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 361144, "time": 17033.307352781296, "episode/length": 154.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 361360, "time": 17042.456396102905, "episode/length": 174.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 361664, "time": 17054.35189151764, "episode/length": 37.0, "episode/score": 2.1000000163912773, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 361736, "time": 17058.181906700134, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 361776, "time": 17061.425191402435, "episode/length": 280.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9750889679715302, "episode/intrinsic_return": 0.0}
{"step": 361800, "time": 17063.652276277542, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 362016, "time": 17072.88717198372, "episode/length": 165.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 362368, "time": 17086.449138641357, "episode/length": 193.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 362384, "time": 17088.51124405861, "episode/length": 406.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9975429975429976, "episode/intrinsic_return": 0.0}
{"step": 362728, "time": 17101.419293165207, "episode/length": 88.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 362968, "time": 17111.095098257065, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 363144, "time": 17118.84024000168, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 363200, "time": 17122.59835243225, "episode/length": 174.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 363440, "time": 17132.222761154175, "episode/length": 221.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 363576, "time": 17138.207097291946, "episode/length": 105.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 363688, "time": 17143.59708237648, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 364336, "time": 17167.125359535217, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 364376, "time": 17169.897765636444, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 364392, "time": 17172.045619010925, "episode/length": 252.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9881422924901185, "episode/intrinsic_return": 0.0}
{"step": 364936, "time": 17191.978300094604, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 364968, "time": 17194.658628940582, "episode/length": 173.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 365096, "time": 17200.552505731583, "episode/length": 419.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9976190476190476, "episode/intrinsic_return": 0.0}
{"step": 365224, "time": 17206.514088869095, "episode/length": 222.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.968609865470852, "episode/intrinsic_return": 0.0}
{"step": 365568, "time": 17219.82977628708, "episode/length": 146.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 365608, "time": 17222.571382284164, "episode/length": 300.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9867109634551495, "episode/intrinsic_return": 0.0}
{"step": 365728, "time": 17228.49528646469, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 365744, "time": 17230.61883163452, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 365800, "time": 17233.859214305878, "episode/length": 107.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 366472, "time": 17258.09467935562, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 366704, "time": 17267.8413438797, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 366864, "time": 17274.91813802719, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 366864, "time": 17274.92483329773, "episode/length": 141.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 366872, "time": 17278.29994702339, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 367208, "time": 17291.225427389145, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 367536, "time": 17304.099506616592, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 367808, "time": 17314.839856863022, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 368120, "time": 17326.805315732956, "episode/length": 155.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 368136, "time": 17328.85256934166, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 368136, "time": 17328.861773490906, "episode/length": 178.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 368249, "time": 17336.93727040291, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.889968080873842, "train/action_min": 0.0, "train/action_std": 3.5032500249368175, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04936582642021003, "train/actor_opt_grad_steps": 22240.0, "train/actor_opt_loss": 5.5854459661024585, "train/adv_mag": 0.7847614882168946, "train/adv_max": 0.776760877724047, "train/adv_mean": 0.005714925158907944, "train/adv_min": -0.48393984017548736, "train/adv_std": 0.07637293438116709, "train/cont_avg": 0.9946108217592593, "train/cont_loss_mean": 0.00039043222399565516, "train/cont_loss_std": 0.011740808115660507, "train/cont_neg_acc": 0.9914550282337048, "train/cont_neg_loss": 0.03945538600715669, "train/cont_pos_acc": 0.9999418669276767, "train/cont_pos_loss": 0.00015102178461187644, "train/cont_pred": 0.9945886294047038, "train/cont_rate": 0.9946108217592593, "train/dyn_loss_mean": 13.784216082537617, "train/dyn_loss_std": 9.221213510301379, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9419800776022452, "train/extr_critic_critic_opt_grad_steps": 22240.0, "train/extr_critic_critic_opt_loss": 15861.961357060185, "train/extr_critic_mag": 5.164193983431216, "train/extr_critic_max": 5.164193983431216, "train/extr_critic_mean": 1.020502476559745, "train/extr_critic_min": -0.2091365063631976, "train/extr_critic_std": 1.1073129759894478, "train/extr_return_normed_mag": 1.8732933415306938, "train/extr_return_normed_max": 1.8732933415306938, "train/extr_return_normed_mean": 0.3157373712018684, "train/extr_return_normed_min": -0.14351843474087891, "train/extr_return_normed_std": 0.3313898137322179, "train/extr_return_rate": 0.5313426203197903, "train/extr_return_raw_mag": 6.420128073515715, "train/extr_return_raw_max": 6.420128073515715, "train/extr_return_raw_mean": 1.0402585281266106, "train/extr_return_raw_min": -0.5469157168158778, "train/extr_return_raw_std": 1.14492737143128, "train/extr_reward_mag": 1.0155873669518365, "train/extr_reward_max": 1.0155873669518365, "train/extr_reward_mean": 0.026475287173633223, "train/extr_reward_min": -0.42159711784786646, "train/extr_reward_std": 0.1494951652707877, "train/image_loss_mean": 7.53115851437604, "train/image_loss_std": 11.224268351660834, "train/model_loss_mean": 15.853728485107421, "train/model_loss_std": 15.083779320893465, "train/model_opt_grad_norm": 63.1604546017117, "train/model_opt_grad_steps": 22218.325925925925, "train/model_opt_loss": 10244.658253761574, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 643.5185185185185, "train/policy_entropy_mag": 2.4827921001999465, "train/policy_entropy_max": 2.4827921001999465, "train/policy_entropy_mean": 0.6711961574024624, "train/policy_entropy_min": 0.07937524246948736, "train/policy_entropy_std": 0.6502023030210424, "train/policy_logprob_mag": 7.438383024710196, "train/policy_logprob_max": -0.009455803878329418, "train/policy_logprob_mean": -0.6710346257245099, "train/policy_logprob_min": -7.438383024710196, "train/policy_logprob_std": 1.1535905811521743, "train/policy_randomness_mag": 0.8763166590973183, "train/policy_randomness_max": 0.8763166590973183, "train/policy_randomness_mean": 0.236902787177651, "train/policy_randomness_min": 0.02801597702006499, "train/policy_randomness_std": 0.22949287990729014, "train/post_ent_mag": 58.993537959346064, "train/post_ent_max": 58.993537959346064, "train/post_ent_mean": 41.218284635190614, "train/post_ent_min": 21.525641222353336, "train/post_ent_std": 7.252747157767967, "train/prior_ent_mag": 69.21707362422237, "train/prior_ent_max": 69.21707362422237, "train/prior_ent_mean": 55.06138432820638, "train/prior_ent_min": 38.90476653487594, "train/prior_ent_std": 4.968607552846273, "train/rep_loss_mean": 13.784216082537617, "train/rep_loss_std": 9.221213510301379, "train/reward_avg": 0.021875723140935104, "train/reward_loss_mean": 0.051649868571096, "train/reward_loss_std": 0.2475907911856969, "train/reward_max_data": 1.015555559264289, "train/reward_max_pred": 1.0068927526473999, "train/reward_neg_acc": 0.9934830603776155, "train/reward_neg_loss": 0.029172349355562968, "train/reward_pos_acc": 0.9637547435583892, "train/reward_pos_loss": 0.8771081769907916, "train/reward_pred": 0.021185294538736344, "train/reward_rate": 0.026663773148148148, "train_stats/sum_log_reward": 5.349999956529716, "train_stats/max_log_achievement_collect_coal": 0.017241379310344827, "train_stats/max_log_achievement_collect_drink": 4.387931034482759, "train_stats/max_log_achievement_collect_sapling": 2.456896551724138, "train_stats/max_log_achievement_collect_stone": 0.06896551724137931, "train_stats/max_log_achievement_collect_wood": 6.620689655172414, "train_stats/max_log_achievement_defeat_skeleton": 0.008620689655172414, "train_stats/max_log_achievement_defeat_zombie": 0.25862068965517243, "train_stats/max_log_achievement_eat_cow": 0.0603448275862069, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.46551724137931033, "train_stats/max_log_achievement_make_wood_sword": 0.28448275862068967, "train_stats/max_log_achievement_place_plant": 2.336206896551724, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.8793103448275863, "train_stats/max_log_achievement_wake_up": 1.9827586206896552, "train_stats/mean_log_entropy": 0.6411233896325375, "eval_stats/sum_log_reward": 5.599999934434891, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.1875, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 0.0625, "eval_stats/max_log_achievement_collect_wood": 6.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.375, "eval_stats/max_log_achievement_make_wood_sword": 0.1875, "eval_stats/max_log_achievement_place_plant": 2.0625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.0, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 2.3080820028553717e-06, "report/cont_loss_std": 1.1468417142168619e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.2283582691452466e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.2689623619953636e-06, "report/cont_pred": 0.9960916042327881, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.746565818786621, "report/dyn_loss_std": 8.829787254333496, "report/image_loss_mean": 6.947761535644531, "report/image_loss_std": 9.225506782531738, "report/model_loss_mean": 15.250568389892578, "report/model_loss_std": 13.178610801696777, "report/post_ent_mag": 56.03879928588867, "report/post_ent_max": 56.03879928588867, "report/post_ent_mean": 41.00867462158203, "report/post_ent_min": 18.67162322998047, "report/post_ent_std": 6.97318172454834, "report/prior_ent_mag": 69.36865234375, "report/prior_ent_max": 69.36865234375, "report/prior_ent_mean": 54.87486267089844, "report/prior_ent_min": 42.6453971862793, "report/prior_ent_std": 4.533407688140869, "report/rep_loss_mean": 13.746565818786621, "report/rep_loss_std": 8.829787254333496, "report/reward_avg": 0.01962890662252903, "report/reward_loss_mean": 0.05486542731523514, "report/reward_loss_std": 0.2643144130706787, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0754327774047852, "report/reward_neg_acc": 0.9909819960594177, "report/reward_neg_loss": 0.03255315124988556, "report/reward_pos_acc": 0.9230769872665405, "report/reward_pos_loss": 0.9113134741783142, "report/reward_pred": 0.019086815416812897, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.802156814141199e-06, "eval/cont_loss_std": 2.1723180907429196e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.539582990517374e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.7527698875928763e-06, "eval/cont_pred": 0.9960910081863403, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.629291534423828, "eval/dyn_loss_std": 10.142605781555176, "eval/image_loss_mean": 20.014049530029297, "eval/image_loss_std": 27.6207332611084, "eval/model_loss_mean": 31.300649642944336, "eval/model_loss_std": 31.430614471435547, "eval/post_ent_mag": 56.66134262084961, "eval/post_ent_max": 56.66134262084961, "eval/post_ent_mean": 40.857208251953125, "eval/post_ent_min": 23.553239822387695, "eval/post_ent_std": 6.719528675079346, "eval/prior_ent_mag": 69.36865234375, "eval/prior_ent_max": 69.36865234375, "eval/prior_ent_mean": 56.221466064453125, "eval/prior_ent_min": 39.619224548339844, "eval/prior_ent_std": 4.338002681732178, "eval/rep_loss_mean": 18.629291534423828, "eval/rep_loss_std": 10.142605781555176, "eval/reward_avg": 0.02597656100988388, "eval/reward_loss_mean": 0.1090225875377655, "eval/reward_loss_std": 0.6804909110069275, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023488998413086, "eval/reward_neg_acc": 0.9879153966903687, "eval/reward_neg_loss": 0.048280879855155945, "eval/reward_pos_acc": 0.7419354915618896, "eval/reward_pos_loss": 2.0547165870666504, "eval/reward_pred": 0.020886925980448723, "eval/reward_rate": 0.0302734375, "replay/size": 367745.0, "replay/inserts": 21632.0, "replay/samples": 21632.0, "replay/insert_wait_avg": 1.4052831033277794e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.834669223198524e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 76216.0, "eval_replay/inserts": 4896.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2813050762500637e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4440746307373, "timer/env.step_count": 2704.0, "timer/env.step_total": 262.1684989929199, "timer/env.step_frac": 0.26205212829081526, "timer/env.step_avg": 0.09695580584057689, "timer/env.step_min": 0.023834943771362305, "timer/env.step_max": 3.4822428226470947, "timer/replay._sample_count": 21632.0, "timer/replay._sample_total": 11.415648460388184, "timer/replay._sample_frac": 0.011410581310706134, "timer/replay._sample_avg": 0.0005277204354839212, "timer/replay._sample_min": 0.0003845691680908203, "timer/replay._sample_max": 0.03249406814575195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3316.0, "timer/agent.policy_total": 57.05250954627991, "timer/agent.policy_frac": 0.05702718522006132, "timer/agent.policy_avg": 0.01720522000792518, "timer/agent.policy_min": 0.009574413299560547, "timer/agent.policy_max": 0.12706470489501953, "timer/dataset_train_count": 1352.0, "timer/dataset_train_total": 0.15370583534240723, "timer/dataset_train_frac": 0.00015363760877802176, "timer/dataset_train_avg": 0.00011368774803432487, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0010066032409667969, "timer/agent.train_count": 1352.0, "timer/agent.train_total": 609.4035005569458, "timer/agent.train_frac": 0.6091330000448809, "timer/agent.train_avg": 0.4507422341397528, "timer/agent.train_min": 0.4374430179595947, "timer/agent.train_max": 1.5337576866149902, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4848976135253906, "timer/agent.report_frac": 0.0004846823783771879, "timer/agent.report_avg": 0.2424488067626953, "timer/agent.report_min": 0.2359790802001953, "timer/agent.report_max": 0.2489185333251953, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.288818359375e-05, "timer/dataset_eval_frac": 2.2878024043670808e-08, "timer/dataset_eval_avg": 2.288818359375e-05, "timer/dataset_eval_min": 2.288818359375e-05, "timer/dataset_eval_max": 2.288818359375e-05, "fps": 21.622105742508733}
{"step": 368336, "time": 17339.93509030342, "episode/length": 99.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.94, "episode/intrinsic_return": 0.0}
{"step": 368584, "time": 17349.571140289307, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9627906976744186, "episode/intrinsic_return": 0.0}
{"step": 368680, "time": 17355.873105049133, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 369208, "time": 17375.426926374435, "episode/length": 497.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9819277108433735, "episode/intrinsic_return": 0.0}
{"step": 369232, "time": 17378.118037700653, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 369656, "time": 17393.815087080002, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 369992, "time": 17406.700424432755, "episode/length": 233.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 370016, "time": 17409.363526582718, "episode/length": 178.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 17430.405689954758, "eval_episode/length": 125.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9603174603174603}
{"step": 370032, "time": 17432.206582784653, "eval_episode/length": 131.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9621212121212122}
{"step": 370032, "time": 17434.508235692978, "eval_episode/length": 148.0, "eval_episode/score": 6.1000000312924385, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 370032, "time": 17436.977642297745, "eval_episode/length": 167.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 370032, "time": 17438.799388885498, "eval_episode/length": 172.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 370032, "time": 17441.13133621216, "eval_episode/length": 189.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 370032, "time": 17444.916393756866, "eval_episode/length": 238.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9707112970711297}
{"step": 370032, "time": 17449.01986837387, "eval_episode/length": 291.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9965753424657534}
{"step": 370144, "time": 17452.767941474915, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 370200, "time": 17455.8855073452, "episode/length": 257.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 370576, "time": 17470.32087635994, "episode/length": 167.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 370720, "time": 17476.961218357086, "episode/length": 297.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9832214765100671, "episode/intrinsic_return": 0.0}
{"step": 370768, "time": 17480.09684896469, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 371176, "time": 17495.244781255722, "episode/length": 147.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 371272, "time": 17500.2198138237, "episode/length": 201.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 371280, "time": 17502.34213066101, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 371552, "time": 17513.177324295044, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 371760, "time": 17521.767813682556, "episode/length": 201.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 371896, "time": 17527.667290449142, "episode/length": 164.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 372184, "time": 17539.042341709137, "episode/length": 176.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 372536, "time": 17552.6536359787, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9556962025316456, "episode/intrinsic_return": 0.0}
{"step": 372864, "time": 17565.622628450394, "episode/length": 197.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 373024, "time": 17572.71015906334, "episode/length": 287.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9826388888888888, "episode/intrinsic_return": 0.0}
{"step": 373048, "time": 17574.903415203094, "episode/length": 160.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 373096, "time": 17578.083540201187, "episode/length": 239.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 373360, "time": 17588.77472782135, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 373808, "time": 17605.6032166481, "episode/length": 158.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 374048, "time": 17615.22655248642, "episode/length": 232.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 374200, "time": 17621.877220392227, "episode/length": 330.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9848942598187311, "episode/intrinsic_return": 0.0}
{"step": 374360, "time": 17628.93120598793, "episode/length": 157.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 374456, "time": 17633.928082704544, "episode/length": 198.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 374520, "time": 17637.736264705658, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 374576, "time": 17641.33141183853, "episode/length": 193.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 375048, "time": 17658.599553346634, "episode/length": 154.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 375464, "time": 17674.293701410294, "episode/length": 262.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9809885931558935, "episode/intrinsic_return": 0.0}
{"step": 375536, "time": 17679.09173488617, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 375792, "time": 17689.413687467575, "episode/length": 198.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 375888, "time": 17694.1868724823, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 376144, "time": 17704.56847333908, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 376312, "time": 17711.606868982315, "episode/length": 231.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 376384, "time": 17715.761370658875, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 376448, "time": 17719.64138650894, "episode/length": 240.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 376512, "time": 17723.41922068596, "episode/length": 45.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 377104, "time": 17746.46422815323, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 377264, "time": 17753.45037007332, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 377440, "time": 17760.948553800583, "episode/length": 123.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9516129032258065, "episode/intrinsic_return": 0.0}
{"step": 377640, "time": 17769.025516033173, "episode/length": 271.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 377656, "time": 17771.169592142105, "episode/length": 48.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 377856, "time": 17779.90078854561, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 377856, "time": 17779.907894849777, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 377880, "time": 17783.92712211609, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 377968, "time": 17788.59858226776, "episode/length": 38.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 378304, "time": 17801.46115756035, "episode/length": 301.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9867549668874173, "episode/intrinsic_return": 0.0}
{"step": 378480, "time": 17808.97543144226, "episode/length": 171.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 378936, "time": 17825.5956492424, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 379064, "time": 17831.481907844543, "episode/length": 150.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 379080, "time": 17833.70355939865, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 379184, "time": 17839.294999599457, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 379712, "time": 17858.71804666519, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 17885.79132938385, "eval_episode/length": 40.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8780487804878049}
{"step": 380016, "time": 17891.87517762184, "eval_episode/length": 143.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9652777777777778}
{"step": 380016, "time": 17894.815005779266, "eval_episode/length": 171.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9593023255813954}
{"step": 380016, "time": 17896.940045118332, "eval_episode/length": 180.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.994475138121547}
{"step": 380016, "time": 17898.51726436615, "eval_episode/length": 181.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 380016, "time": 17900.197845220566, "eval_episode/length": 183.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967391304347826}
{"step": 380016, "time": 17902.372113227844, "eval_episode/length": 195.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 380016, "time": 17904.862475156784, "eval_episode/length": 173.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 380080, "time": 17907.01468682289, "episode/length": 263.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 380608, "time": 17926.678144693375, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 380648, "time": 17929.532529592514, "episode/length": 213.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 381016, "time": 17943.331720113754, "episode/length": 243.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 381208, "time": 17951.394654273987, "episode/length": 186.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 381472, "time": 17962.33687186241, "episode/length": 285.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9755244755244755, "episode/intrinsic_return": 0.0}
{"step": 382032, "time": 17982.813296079636, "episode/length": 177.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 382056, "time": 17984.96919322014, "episode/length": 175.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 382416, "time": 17999.12070250511, "episode/length": 150.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 382520, "time": 18004.09615278244, "episode/length": 187.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 382576, "time": 18007.75140595436, "episode/length": 589.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9983050847457627, "episode/intrinsic_return": 0.0}
{"step": 382624, "time": 18010.864109277725, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 382720, "time": 18015.700917482376, "episode/length": 529.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 383560, "time": 18045.43552827835, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 383608, "time": 18049.243300914764, "episode/length": 440.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9886621315192744, "episode/intrinsic_return": 0.0}
{"step": 383824, "time": 18058.732051849365, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 383848, "time": 18060.948610305786, "episode/length": 223.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 383864, "time": 18063.024693250656, "episode/length": 142.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 384152, "time": 18074.280389785767, "episode/length": 35.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 384392, "time": 18084.301445007324, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 384432, "time": 18087.630702495575, "episode/length": 225.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 384840, "time": 18102.6932220459, "episode/length": 153.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 385120, "time": 18115.68056702614, "episode/length": 337.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 385208, "time": 18120.17702102661, "episode/length": 169.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 385656, "time": 18137.350567817688, "episode/length": 228.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 385752, "time": 18142.23558807373, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 385920, "time": 18149.863954782486, "episode/length": 185.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 386352, "time": 18166.092950105667, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 386480, "time": 18172.108932495117, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 386496, "time": 18174.26203942299, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 386680, "time": 18181.975464105606, "episode/length": 315.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 387008, "time": 18194.95625090599, "episode/length": 430.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 387048, "time": 18197.89836192131, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 387232, "time": 18206.010867595673, "episode/length": 184.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 387376, "time": 18212.473736286163, "episode/length": 127.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 387416, "time": 18215.192484140396, "episode/length": 186.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 387848, "time": 18231.566146612167, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 388000, "time": 18238.477248191833, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 388536, "time": 18258.11724257469, "episode/length": 190.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 388656, "time": 18264.14071702957, "episode/length": 177.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 389072, "time": 18279.93166089058, "episode/length": 321.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9906832298136646, "episode/intrinsic_return": 0.0}
{"step": 389168, "time": 18284.81840133667, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 389296, "time": 18290.891180038452, "episode/length": 239.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 389400, "time": 18295.819301128387, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 18334.407561779022, "eval_episode/length": 72.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9315068493150684}
{"step": 390000, "time": 18341.398089170456, "eval_episode/length": 160.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9751552795031055}
{"step": 390000, "time": 18343.38898253441, "eval_episode/length": 171.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 390000, "time": 18345.416695594788, "eval_episode/length": 181.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 390000, "time": 18347.513396263123, "eval_episode/length": 190.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 390000, "time": 18350.44976568222, "eval_episode/length": 46.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 390000, "time": 18352.433651685715, "eval_episode/length": 226.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 390000, "time": 18356.901401758194, "eval_episode/length": 288.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9965397923875432}
{"step": 390001, "time": 18357.48676276207, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.664159438189338, "train/action_min": 0.0, "train/action_std": 3.4456261887269863, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048664419227005803, "train/actor_opt_grad_steps": 23595.0, "train/actor_opt_loss": -1.5479786413009553, "train/adv_mag": 0.7041915585012997, "train/adv_max": 0.6906792021849576, "train/adv_mean": 0.004879370526235588, "train/adv_min": -0.4707171923535712, "train/adv_std": 0.07323101598440725, "train/cont_avg": 0.9946432674632353, "train/cont_loss_mean": 0.00034489109533578576, "train/cont_loss_std": 0.009245462601450741, "train/cont_neg_acc": 0.9894432789262604, "train/cont_neg_loss": 0.02887323160778391, "train/cont_pos_acc": 0.9999421918216873, "train/cont_pos_loss": 0.00016352320541118356, "train/cont_pred": 0.9946412926211077, "train/cont_rate": 0.9946432674632353, "train/dyn_loss_mean": 13.571529107935289, "train/dyn_loss_std": 9.124994726742015, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9002272000207621, "train/extr_critic_critic_opt_grad_steps": 23595.0, "train/extr_critic_critic_opt_loss": 15839.147216796875, "train/extr_critic_mag": 5.418955056106343, "train/extr_critic_max": 5.418955056106343, "train/extr_critic_mean": 1.1270165460951187, "train/extr_critic_min": -0.22217255480149212, "train/extr_critic_std": 1.1850630987216444, "train/extr_return_normed_mag": 1.8212777490124983, "train/extr_return_normed_max": 1.8212777490124983, "train/extr_return_normed_mean": 0.3201912592219956, "train/extr_return_normed_min": -0.14015293145990548, "train/extr_return_normed_std": 0.33334648762555685, "train/extr_return_rate": 0.5510479218381292, "train/extr_return_raw_mag": 6.6797190133263085, "train/extr_return_raw_max": 6.6797190133263085, "train/extr_return_raw_mean": 1.1449030497494865, "train/extr_return_raw_min": -0.5521971242611899, "train/extr_return_raw_std": 1.2294881356989635, "train/extr_reward_mag": 1.0131467843756956, "train/extr_reward_max": 1.0131467843756956, "train/extr_reward_mean": 0.027016115402254987, "train/extr_reward_min": -0.4031571158591439, "train/extr_reward_std": 0.152091085417744, "train/image_loss_mean": 7.257591205484727, "train/image_loss_std": 10.693549086065854, "train/model_loss_mean": 15.453407785471748, "train/model_loss_std": 14.513087146422443, "train/model_opt_grad_norm": 58.21126070375796, "train/model_opt_grad_steps": 23572.08088235294, "train/model_opt_loss": 11604.260666791131, "train/model_opt_model_opt_grad_overflow": 0.007352941176470588, "train/model_opt_model_opt_grad_scale": 744.4852941176471, "train/policy_entropy_mag": 2.5098242391558254, "train/policy_entropy_max": 2.5098242391558254, "train/policy_entropy_mean": 0.6374022857669521, "train/policy_entropy_min": 0.07937523235073861, "train/policy_entropy_std": 0.6394717117004535, "train/policy_logprob_mag": 7.438383162021637, "train/policy_logprob_max": -0.009455787148052716, "train/policy_logprob_mean": -0.6368385005523177, "train/policy_logprob_min": -7.438383162021637, "train/policy_logprob_std": 1.135323215933407, "train/policy_randomness_mag": 0.885857814375092, "train/policy_randomness_max": 0.885857814375092, "train/policy_randomness_mean": 0.22497503503280528, "train/policy_randomness_min": 0.028015973484691453, "train/policy_randomness_std": 0.2257054527016247, "train/post_ent_mag": 59.5691434916328, "train/post_ent_max": 59.5691434916328, "train/post_ent_mean": 41.64927443336038, "train/post_ent_min": 21.338719564325668, "train/post_ent_std": 7.311523637350867, "train/prior_ent_mag": 69.41667349198285, "train/prior_ent_max": 69.41667349198285, "train/prior_ent_mean": 55.25994945974911, "train/prior_ent_min": 39.46538634861217, "train/prior_ent_std": 4.940331076874452, "train/rep_loss_mean": 13.571529107935289, "train/rep_loss_std": 9.124994726742015, "train/reward_avg": 0.02169045838116504, "train/reward_loss_mean": 0.05255436270004686, "train/reward_loss_std": 0.252482239923933, "train/reward_max_data": 1.0110294143943226, "train/reward_max_pred": 1.0068507343530655, "train/reward_neg_acc": 0.9934548604137757, "train/reward_neg_loss": 0.02928723465404747, "train/reward_pos_acc": 0.9559608860050931, "train/reward_pos_loss": 0.9048104334403487, "train/reward_pred": 0.02073208207730204, "train/reward_rate": 0.026719037224264705, "train_stats/sum_log_reward": 5.818446549107727, "train_stats/max_log_achievement_collect_coal": 0.038834951456310676, "train_stats/max_log_achievement_collect_drink": 6.155339805825243, "train_stats/max_log_achievement_collect_sapling": 2.825242718446602, "train_stats/max_log_achievement_collect_stone": 0.23300970873786409, "train_stats/max_log_achievement_collect_wood": 7.310679611650485, "train_stats/max_log_achievement_defeat_skeleton": 0.019417475728155338, "train_stats/max_log_achievement_defeat_zombie": 0.4077669902912621, "train_stats/max_log_achievement_eat_cow": 0.11650485436893204, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.2524271844660194, "train_stats/max_log_achievement_make_wood_sword": 1.087378640776699, "train_stats/max_log_achievement_place_plant": 2.6116504854368934, "train_stats/max_log_achievement_place_stone": 0.009708737864077669, "train_stats/max_log_achievement_place_table": 2.029126213592233, "train_stats/max_log_achievement_wake_up": 2.233009708737864, "train_stats/mean_log_entropy": 0.6150830645584365, "eval_stats/sum_log_reward": 5.308333287636439, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.5, "eval_stats/max_log_achievement_collect_sapling": 2.1666666666666665, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.833333333333333, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5833333333333334, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.16666666666666666, "eval_stats/max_log_achievement_make_wood_sword": 0.6666666666666666, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.25, "eval_stats/max_log_achievement_wake_up": 1.6666666666666667, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_place_furnace": 0.029411764705882353, "eval_stats/max_log_achievement_place_furnace": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 6.317512452369556e-05, "report/cont_loss_std": 0.0019113820744678378, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.8326808609999716e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.318963278317824e-05, "report/cont_pred": 0.9989621639251709, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 14.107809066772461, "report/dyn_loss_std": 8.419370651245117, "report/image_loss_mean": 5.876508712768555, "report/image_loss_std": 8.577688217163086, "report/model_loss_mean": 14.378803253173828, "report/model_loss_std": 12.060141563415527, "report/post_ent_mag": 59.42760467529297, "report/post_ent_max": 59.42760467529297, "report/post_ent_mean": 40.33030700683594, "report/post_ent_min": 22.22226333618164, "report/post_ent_std": 7.512425899505615, "report/prior_ent_mag": 68.78868103027344, "report/prior_ent_max": 68.78868103027344, "report/prior_ent_mean": 54.857093811035156, "report/prior_ent_min": 39.935768127441406, "report/prior_ent_std": 4.3082685470581055, "report/rep_loss_mean": 14.107809066772461, "report/rep_loss_std": 8.419370651245117, "report/reward_avg": 0.01767578162252903, "report/reward_loss_mean": 0.037546683102846146, "report/reward_loss_std": 0.22953297197818756, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.003296136856079, "report/reward_neg_acc": 0.9910358786582947, "report/reward_neg_loss": 0.020539268851280212, "report/reward_pos_acc": 0.949999988079071, "report/reward_pos_loss": 0.8913190960884094, "report/reward_pred": 0.01792118512094021, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0006732794572599232, "eval/cont_loss_std": 0.014253217726945877, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 6.964453496038914e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0006750531028956175, "eval/cont_pred": 0.9964888095855713, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.497753143310547, "eval/dyn_loss_std": 11.440104484558105, "eval/image_loss_mean": 15.514328002929688, "eval/image_loss_std": 25.656368255615234, "eval/model_loss_mean": 26.131996154785156, "eval/model_loss_std": 30.131725311279297, "eval/post_ent_mag": 58.66268539428711, "eval/post_ent_max": 58.66268539428711, "eval/post_ent_mean": 40.621864318847656, "eval/post_ent_min": 22.19391632080078, "eval/post_ent_std": 7.3380560874938965, "eval/prior_ent_mag": 68.78868103027344, "eval/prior_ent_max": 68.78868103027344, "eval/prior_ent_mean": 55.81248474121094, "eval/prior_ent_min": 41.800270080566406, "eval/prior_ent_std": 4.548544406890869, "eval/rep_loss_mean": 17.497753143310547, "eval/rep_loss_std": 11.440104484558105, "eval/reward_avg": 0.03457031399011612, "eval/reward_loss_mean": 0.11834415793418884, "eval/reward_loss_std": 0.6839116811752319, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0092287063598633, "eval/reward_neg_acc": 0.9817259311676025, "eval/reward_neg_loss": 0.03954130411148071, "eval/reward_pos_acc": 0.7692307829856873, "eval/reward_pos_loss": 2.10862135887146, "eval/reward_pred": 0.02733916975557804, "eval/reward_rate": 0.0380859375, "replay/size": 389497.0, "replay/inserts": 21752.0, "replay/samples": 21744.0, "replay/insert_wait_avg": 1.402364227867337e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.891026178995768e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 82584.0, "eval_replay/inserts": 6368.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.280226899151826e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1020.5341639518738, "timer/env.step_count": 2719.0, "timer/env.step_total": 244.36059713363647, "timer/env.step_frac": 0.239443818507148, "timer/env.step_avg": 0.089871495819653, "timer/env.step_min": 0.02352166175842285, "timer/env.step_max": 3.438645839691162, "timer/replay._sample_count": 21744.0, "timer/replay._sample_total": 11.447830200195312, "timer/replay._sample_frac": 0.011217488453169675, "timer/replay._sample_avg": 0.0005264822571833753, "timer/replay._sample_min": 0.0004229545593261719, "timer/replay._sample_max": 0.00845646858215332, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3515.0, "timer/agent.policy_total": 60.620768785476685, "timer/agent.policy_frac": 0.059401018532031655, "timer/agent.policy_avg": 0.017246306909097207, "timer/agent.policy_min": 0.009531021118164062, "timer/agent.policy_max": 0.12587237358093262, "timer/dataset_train_count": 1359.0, "timer/dataset_train_total": 0.15409493446350098, "timer/dataset_train_frac": 0.00015099439088524995, "timer/dataset_train_avg": 0.00011338847274724134, "timer/dataset_train_min": 9.989738464355469e-05, "timer/dataset_train_max": 0.0004992485046386719, "timer/agent.train_count": 1359.0, "timer/agent.train_total": 614.3087232112885, "timer/agent.train_frac": 0.6019482197758721, "timer/agent.train_avg": 0.4520299655712203, "timer/agent.train_min": 0.44022512435913086, "timer/agent.train_max": 1.626319408416748, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4743766784667969, "timer/agent.report_frac": 0.00046483174716056586, "timer/agent.report_avg": 0.23718833923339844, "timer/agent.report_min": 0.22357583045959473, "timer/agent.report_max": 0.25080084800720215, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.2706990371556845e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 21.314011456829206}
{"step": 390224, "time": 18365.30249595642, "episode/length": 350.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9943019943019943, "episode/intrinsic_return": 0.0}
{"step": 390312, "time": 18369.620335817337, "episode/length": 154.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 390464, "time": 18376.72686481476, "episode/length": 426.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 390744, "time": 18387.709574222565, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 390800, "time": 18391.39195370674, "episode/length": 187.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 391232, "time": 18407.77573466301, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 391352, "time": 18413.12249493599, "episode/length": 336.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9881305637982196, "episode/intrinsic_return": 0.0}
{"step": 391696, "time": 18426.53446340561, "episode/length": 183.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 391864, "time": 18433.555896282196, "episode/length": 415.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 391952, "time": 18438.49618577957, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 392200, "time": 18448.376963377, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 392240, "time": 18451.365454912186, "episode/length": 67.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9117647058823529, "episode/intrinsic_return": 0.0}
{"step": 392256, "time": 18453.46386575699, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 392344, "time": 18457.846116781235, "episode/length": 48.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 392560, "time": 18467.086643218994, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 392696, "time": 18472.972331285477, "episode/length": 43.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 392968, "time": 18483.815553426743, "episode/length": 312.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9904153354632588, "episode/intrinsic_return": 0.0}
{"step": 393528, "time": 18505.971157312393, "episode/length": 271.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 393656, "time": 18511.89186811447, "episode/length": 174.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 393872, "time": 18521.03884410858, "episode/length": 250.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 393960, "time": 18525.411900043488, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9681818181818181, "episode/intrinsic_return": 0.0}
{"step": 394112, "time": 18532.456260681152, "episode/length": 176.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 394368, "time": 18542.723663330078, "episode/length": 225.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 394624, "time": 18552.829434871674, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 394720, "time": 18557.794382333755, "episode/length": 43.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 395048, "time": 18570.129998922348, "episode/length": 173.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 395216, "time": 18577.72331237793, "episode/length": 210.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 395456, "time": 18587.48388671875, "episode/length": 50.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 395696, "time": 18597.291306257248, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 395712, "time": 18599.45841407776, "episode/length": 199.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 395728, "time": 18601.613238096237, "episode/length": 435.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 396408, "time": 18626.013283491135, "episode/length": 316.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9842271293375394, "episode/intrinsic_return": 0.0}
{"step": 396712, "time": 18637.910842895508, "episode/length": 248.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 396872, "time": 18644.896435022354, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 397008, "time": 18651.99054479599, "episode/length": 297.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 397216, "time": 18660.64155960083, "episode/length": 185.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 397288, "time": 18664.51677751541, "episode/length": 196.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 397480, "time": 18672.669970989227, "episode/length": 32.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8484848484848485, "episode/intrinsic_return": 0.0}
{"step": 397856, "time": 18687.322954893112, "episode/length": 269.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 398200, "time": 18700.37979698181, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 398208, "time": 18702.517347812653, "episode/length": 373.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 398400, "time": 18710.63252902031, "episode/length": 173.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 398400, "time": 18710.641374349594, "episode/length": 190.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 398672, "time": 18723.125084400177, "episode/length": 58.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 398936, "time": 18733.451964616776, "episode/length": 205.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 399184, "time": 18743.708905935287, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 399392, "time": 18752.19390273094, "episode/length": 334.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.982089552238806, "episode/intrinsic_return": 0.0}
{"step": 399504, "time": 18757.537308216095, "episode/length": 252.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 399720, "time": 18766.294338464737, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 18796.292585611343, "eval_episode/length": 42.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 400088, "time": 18802.490545511246, "eval_episode/length": 149.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 400088, "time": 18804.821662902832, "eval_episode/length": 167.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 400088, "time": 18804.830451965332, "eval_episode/length": 167.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 400088, "time": 18808.53995323181, "eval_episode/length": 174.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.96}
{"step": 400088, "time": 18810.20776104927, "eval_episode/length": 176.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 400088, "time": 18816.163685798645, "eval_episode/length": 227.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9780701754385965}
{"step": 400088, "time": 18818.131286621094, "eval_episode/length": 277.0, "eval_episode/score": 8.100000068545341, "eval_episode/reward_rate": 0.9964028776978417}
{"step": 400200, "time": 18821.931123495102, "episode/length": 190.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 400224, "time": 18824.92582654953, "episode/length": 160.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 400392, "time": 18832.097609996796, "episode/length": 248.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 400712, "time": 18844.413897514343, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 400832, "time": 18850.289999961853, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 400976, "time": 18856.780611753464, "episode/length": 183.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 401400, "time": 18872.51962518692, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 401608, "time": 18882.728511571884, "episode/length": 172.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 401624, "time": 18884.882585287094, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 401784, "time": 18892.03195476532, "episode/length": 47.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 401856, "time": 18896.315308094025, "episode/length": 455.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 403200, "time": 18944.74478650093, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 403288, "time": 18949.242661476135, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 403312, "time": 18951.977710723877, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 403376, "time": 18955.668072462082, "episode/length": 317.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 403696, "time": 18967.895042181015, "episode/length": 412.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9927360774818402, "episode/intrinsic_return": 0.0}
{"step": 404224, "time": 18987.438472509384, "episode/length": 438.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9954441913439636, "episode/intrinsic_return": 0.0}
{"step": 404408, "time": 18994.997179746628, "episode/length": 428.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9953379953379954, "episode/intrinsic_return": 0.0}
{"step": 404784, "time": 19009.68618774414, "episode/length": 183.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 404808, "time": 19011.866765260696, "episode/length": 178.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 404864, "time": 19015.475098609924, "episode/length": 196.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 405000, "time": 19021.398525953293, "episode/length": 224.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 405128, "time": 19027.304198026657, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 405344, "time": 19036.468676805496, "episode/length": 466.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9978586723768736, "episode/intrinsic_return": 0.0}
{"step": 406016, "time": 19060.70563030243, "episode/length": 223.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 406384, "time": 19074.85921049118, "episode/length": 189.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 406656, "time": 19085.67837357521, "episode/length": 233.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 406856, "time": 19093.965271234512, "episode/length": 231.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 407192, "time": 19107.23879790306, "episode/length": 41.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9047619047619048, "episode/intrinsic_return": 0.0}
{"step": 407288, "time": 19112.102732896805, "episode/length": 112.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9911504424778761, "episode/intrinsic_return": 0.0}
{"step": 407368, "time": 19116.521507501602, "episode/length": 319.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 407488, "time": 19122.43392777443, "episode/length": 294.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9864406779661017, "episode/intrinsic_return": 0.0}
{"step": 407520, "time": 19125.154618024826, "episode/length": 187.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 407768, "time": 19134.967059612274, "episode/length": 419.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 408112, "time": 19148.32927083969, "episode/length": 181.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 408560, "time": 19165.075954675674, "episode/length": 401.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 408832, "time": 19176.053768634796, "episode/length": 192.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 408832, "time": 19176.061895608902, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 409144, "time": 19189.79525399208, "episode/length": 202.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 409192, "time": 19193.006494283676, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 409360, "time": 19200.528175115585, "episode/length": 155.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 409976, "time": 19224.336124897003, "episode/length": 176.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 19244.274386644363, "eval_episode/length": 39.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9}
{"step": 410072, "time": 19250.980410814285, "eval_episode/length": 151.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 410072, "time": 19253.73991894722, "eval_episode/length": 178.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 410072, "time": 19256.018311738968, "eval_episode/length": 190.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9685863874345549}
{"step": 410072, "time": 19258.903343439102, "eval_episode/length": 180.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.994475138121547}
{"step": 410072, "time": 19260.556815624237, "eval_episode/length": 221.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 410072, "time": 19262.265035390854, "eval_episode/length": 223.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 410072, "time": 19264.820127248764, "eval_episode/length": 244.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 410464, "time": 19278.355060577393, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 410480, "time": 19280.4719145298, "episode/length": 166.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 410528, "time": 19283.764853715897, "episode/length": 166.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 410560, "time": 19286.43411922455, "episode/length": 398.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 410680, "time": 19291.89003944397, "episode/length": 230.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 411144, "time": 19309.153063058853, "episode/length": 421.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9928909952606635, "episode/intrinsic_return": 0.0}
{"step": 411216, "time": 19313.428020715714, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 411256, "time": 19316.234971523285, "episode/length": 236.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 411616, "time": 19330.08738040924, "episode/length": 143.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 411840, "time": 19339.362786769867, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 412313, "time": 19357.731046676636, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.518926565987723, "train/action_min": 0.0, "train/action_std": 3.1238418221473694, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04822894715304885, "train/actor_opt_grad_steps": 24975.0, "train/actor_opt_loss": -0.46295535543135236, "train/adv_mag": 0.6960362683449473, "train/adv_max": 0.6760851085186005, "train/adv_mean": 0.004611005993034009, "train/adv_min": -0.4822063045842307, "train/adv_std": 0.07235539159072298, "train/cont_avg": 0.9946568080357143, "train/cont_loss_mean": 0.00025077185868513293, "train/cont_loss_std": 0.007269227262284669, "train/cont_neg_acc": 0.991140181603639, "train/cont_neg_loss": 0.021840576466736136, "train/cont_pos_acc": 0.9999508887529374, "train/cont_pos_loss": 0.00012751574661434362, "train/cont_pred": 0.9946650632790157, "train/cont_rate": 0.9946568080357143, "train/dyn_loss_mean": 13.539600542613439, "train/dyn_loss_std": 9.192655399867467, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8919081483568464, "train/extr_critic_critic_opt_grad_steps": 24975.0, "train/extr_critic_critic_opt_loss": 15993.994635881696, "train/extr_critic_mag": 5.5736334528241835, "train/extr_critic_max": 5.5736334528241835, "train/extr_critic_mean": 1.1825750385011946, "train/extr_critic_min": -0.21888838240078518, "train/extr_critic_std": 1.228692878144128, "train/extr_return_normed_mag": 1.8255856156349182, "train/extr_return_normed_max": 1.8255856156349182, "train/extr_return_normed_mean": 0.32369643918105534, "train/extr_return_normed_min": -0.14143200660390512, "train/extr_return_normed_std": 0.33632619881204195, "train/extr_return_rate": 0.5561849242874555, "train/extr_return_raw_mag": 6.8502665690013345, "train/extr_return_raw_max": 6.8502665690013345, "train/extr_return_raw_mean": 1.1998774949993407, "train/extr_return_raw_min": -0.5498583086899349, "train/extr_return_raw_std": 1.2652628349406378, "train/extr_reward_mag": 1.0180634890283857, "train/extr_reward_max": 1.0180634890283857, "train/extr_reward_mean": 0.02767923041912062, "train/extr_reward_min": -0.4192496027265276, "train/extr_reward_std": 0.1536397742905787, "train/image_loss_mean": 7.195758560725621, "train/image_loss_std": 10.808012754576547, "train/model_loss_mean": 15.371481949942453, "train/model_loss_std": 14.65551086153303, "train/model_opt_grad_norm": 62.825319222041536, "train/model_opt_grad_steps": 24951.22857142857, "train/model_opt_loss": 12312.505297851563, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 803.5714285714286, "train/policy_entropy_mag": 2.5368501203400746, "train/policy_entropy_max": 2.5368501203400746, "train/policy_entropy_mean": 0.5821321417178427, "train/policy_entropy_min": 0.07937521753566605, "train/policy_entropy_std": 0.6192535012960434, "train/policy_logprob_mag": 7.438383330617632, "train/policy_logprob_max": -0.009455784290496792, "train/policy_logprob_mean": -0.5831878987806184, "train/policy_logprob_min": -7.438383330617632, "train/policy_logprob_std": 1.1159201021705354, "train/policy_randomness_mag": 0.8953967647893089, "train/policy_randomness_max": 0.8953967647893089, "train/policy_randomness_mean": 0.20546710044145583, "train/policy_randomness_min": 0.028015968203544617, "train/policy_randomness_std": 0.21856931160603252, "train/post_ent_mag": 59.365967532566614, "train/post_ent_max": 59.365967532566614, "train/post_ent_mean": 41.76632137298584, "train/post_ent_min": 21.27129007066999, "train/post_ent_std": 7.274120593070984, "train/prior_ent_mag": 69.58713046482632, "train/prior_ent_max": 69.58713046482632, "train/prior_ent_mean": 55.347184480939596, "train/prior_ent_min": 40.09189761025565, "train/prior_ent_std": 4.838138621194022, "train/rep_loss_mean": 13.539600542613439, "train/rep_loss_std": 9.192655399867467, "train/reward_avg": 0.02278669074377311, "train/reward_loss_mean": 0.05171241048457367, "train/reward_loss_std": 0.2469903126358986, "train/reward_max_data": 1.0150000035762787, "train/reward_max_pred": 1.0065858278955733, "train/reward_neg_acc": 0.9937115741627557, "train/reward_neg_loss": 0.02870865008527679, "train/reward_pos_acc": 0.9658155232667923, "train/reward_pos_loss": 0.8663571608918054, "train/reward_pred": 0.022171753558463285, "train/reward_rate": 0.027559988839285714, "train_stats/sum_log_reward": 6.377227738352105, "train_stats/max_log_achievement_collect_coal": 0.10891089108910891, "train_stats/max_log_achievement_collect_drink": 9.415841584158416, "train_stats/max_log_achievement_collect_sapling": 2.5247524752475248, "train_stats/max_log_achievement_collect_stone": 1.0297029702970297, "train_stats/max_log_achievement_collect_wood": 7.3861386138613865, "train_stats/max_log_achievement_defeat_skeleton": 0.039603960396039604, "train_stats/max_log_achievement_defeat_zombie": 0.6039603960396039, "train_stats/max_log_achievement_eat_cow": 0.1188118811881188, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.8910891089108911, "train_stats/max_log_achievement_make_wood_sword": 0.7524752475247525, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.366336633663366, "train_stats/max_log_achievement_place_stone": 0.039603960396039604, "train_stats/max_log_achievement_place_table": 2.128712871287129, "train_stats/max_log_achievement_wake_up": 2.1386138613861387, "train_stats/mean_log_entropy": 0.5760032261657243, "eval_stats/sum_log_reward": 5.975000023841858, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 7.25, "eval_stats/max_log_achievement_collect_sapling": 2.25, "eval_stats/max_log_achievement_collect_stone": 0.1875, "eval_stats/max_log_achievement_collect_wood": 7.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.8125, "eval_stats/max_log_achievement_make_wood_sword": 0.4375, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.9375, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 8.498253123434552e-07, "report/cont_loss_std": 1.1029012057406362e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00013851094990968704, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.7435353072414728e-07, "report/cont_pred": 0.995117723941803, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.745081901550293, "report/dyn_loss_std": 8.687183380126953, "report/image_loss_mean": 6.996186256408691, "report/image_loss_std": 9.712170600891113, "report/model_loss_mean": 14.690070152282715, "report/model_loss_std": 13.343610763549805, "report/post_ent_mag": 59.783660888671875, "report/post_ent_max": 59.783660888671875, "report/post_ent_mean": 42.58881378173828, "report/post_ent_min": 21.545459747314453, "report/post_ent_std": 7.421688556671143, "report/prior_ent_mag": 70.08541107177734, "report/prior_ent_max": 70.08541107177734, "report/prior_ent_mean": 55.66610336303711, "report/prior_ent_min": 44.60020446777344, "report/prior_ent_std": 4.734790802001953, "report/rep_loss_mean": 12.745081901550293, "report/rep_loss_std": 8.687183380126953, "report/reward_avg": 0.02031249925494194, "report/reward_loss_mean": 0.046833597123622894, "report/reward_loss_std": 0.20219677686691284, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001131296157837, "report/reward_neg_acc": 0.9969940185546875, "report/reward_neg_loss": 0.027759548276662827, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7789835929870605, "report/reward_pred": 0.018885763362050056, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 8.736007544030144e-07, "eval/cont_loss_std": 1.3009052963752765e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00017437660426367074, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.9319678301599197e-07, "eval/cont_pred": 0.996094286441803, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.02849578857422, "eval/dyn_loss_std": 9.61989688873291, "eval/image_loss_mean": 10.146839141845703, "eval/image_loss_std": 13.015609741210938, "eval/model_loss_mean": 19.84453582763672, "eval/model_loss_std": 16.771516799926758, "eval/post_ent_mag": 61.22709274291992, "eval/post_ent_max": 61.22709274291992, "eval/post_ent_mean": 42.33007049560547, "eval/post_ent_min": 22.84513282775879, "eval/post_ent_std": 6.974034786224365, "eval/prior_ent_mag": 70.08541107177734, "eval/prior_ent_max": 70.08541107177734, "eval/prior_ent_mean": 56.46350860595703, "eval/prior_ent_min": 39.815555572509766, "eval/prior_ent_std": 4.706273555755615, "eval/rep_loss_mean": 16.02849578857422, "eval/rep_loss_std": 9.61989688873291, "eval/reward_avg": 0.03037109225988388, "eval/reward_loss_mean": 0.08059973269701004, "eval/reward_loss_std": 0.46638986468315125, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0009024143218994, "eval/reward_neg_acc": 0.9898989200592041, "eval/reward_neg_loss": 0.030352246016263962, "eval/reward_pos_acc": 0.8235294222831726, "eval/reward_pos_loss": 1.543688178062439, "eval/reward_pred": 0.026042230427265167, "eval/reward_rate": 0.033203125, "replay/size": 411809.0, "replay/inserts": 22312.0, "replay/samples": 22320.0, "replay/insert_wait_avg": 1.3953128909073067e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.905553475930272e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 86768.0, "eval_replay/inserts": 4184.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3120999527706928e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2303247451782, "timer/env.step_count": 2789.0, "timer/env.step_total": 242.10077500343323, "timer/env.step_frac": 0.24204502604448788, "timer/env.step_avg": 0.08680558444009796, "timer/env.step_min": 0.023962974548339844, "timer/env.step_max": 3.4105560779571533, "timer/replay._sample_count": 22320.0, "timer/replay._sample_total": 11.80311107635498, "timer/replay._sample_frac": 0.011800393153808826, "timer/replay._sample_avg": 0.0005288132202668002, "timer/replay._sample_min": 0.0003829002380371094, "timer/replay._sample_max": 0.010457754135131836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3312.0, "timer/agent.policy_total": 56.37949824333191, "timer/agent.policy_frac": 0.05636651563998055, "timer/agent.policy_avg": 0.017022795363324853, "timer/agent.policy_min": 0.00953054428100586, "timer/agent.policy_max": 0.11806201934814453, "timer/dataset_train_count": 1395.0, "timer/dataset_train_total": 0.1589672565460205, "timer/dataset_train_frac": 0.00015893065088435455, "timer/dataset_train_avg": 0.00011395502261363478, "timer/dataset_train_min": 0.00010061264038085938, "timer/dataset_train_max": 0.0005142688751220703, "timer/agent.train_count": 1395.0, "timer/agent.train_total": 631.934818983078, "timer/agent.train_frac": 0.6317893022730257, "timer/agent.train_avg": 0.4529998702387656, "timer/agent.train_min": 0.4392969608306885, "timer/agent.train_max": 1.6679868698120117, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.480027437210083, "timer/agent.report_frac": 0.000479916900472275, "timer/agent.report_avg": 0.2400137186050415, "timer/agent.report_min": 0.23406004905700684, "timer/agent.report_max": 0.24596738815307617, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 9.274482727050781e-05, "timer/dataset_eval_frac": 9.272347076073281e-08, "timer/dataset_eval_avg": 9.274482727050781e-05, "timer/dataset_eval_min": 9.274482727050781e-05, "timer/dataset_eval_max": 9.274482727050781e-05, "fps": 22.306533955077786}
{"step": 412400, "time": 19360.758884191513, "episode/length": 229.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 412488, "time": 19365.157737731934, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 412552, "time": 19369.052317142487, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 412776, "time": 19378.184674739838, "episode/length": 189.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 412864, "time": 19382.850035905838, "episode/length": 291.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 412952, "time": 19387.19598531723, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 413688, "time": 19413.5324447155, "episode/length": 230.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 414008, "time": 19425.845388174057, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 414080, "time": 19430.305280208588, "episode/length": 307.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 414192, "time": 19435.7143137455, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 414464, "time": 19446.286799907684, "episode/length": 188.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 415168, "time": 19471.405431509018, "episode/length": 144.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 415232, "time": 19475.0761551857, "episode/length": 295.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 415728, "time": 19493.40559887886, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 415944, "time": 19502.00475025177, "episode/length": 431.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 416224, "time": 19513.179668426514, "episode/length": 430.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 416448, "time": 19522.3853058815, "episode/length": 247.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 416464, "time": 19524.569980859756, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 416672, "time": 19533.110560655594, "episode/length": 372.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9892761394101877, "episode/intrinsic_return": 0.0}
{"step": 416688, "time": 19535.266232013702, "episode/length": 325.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9815950920245399, "episode/intrinsic_return": 0.0}
{"step": 417160, "time": 19552.64067721367, "episode/length": 116.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 417704, "time": 19572.480240106583, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 417968, "time": 19585.02152633667, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 418288, "time": 19597.325710058212, "episode/length": 39.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 418584, "time": 19608.771536827087, "episode/length": 266.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9737827715355806, "episode/intrinsic_return": 0.0}
{"step": 418656, "time": 19613.215502738953, "episode/length": 427.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 419000, "time": 19626.191514492035, "episode/length": 290.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 419104, "time": 19631.422744750977, "episode/length": 421.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9976303317535545, "episode/intrinsic_return": 0.0}
{"step": 419224, "time": 19637.023355722427, "episode/length": 257.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 419344, "time": 19642.96400284767, "episode/length": 204.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 419432, "time": 19647.174006938934, "episode/length": 342.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9912536443148688, "episode/intrinsic_return": 0.0}
{"step": 419800, "time": 19661.17693901062, "episode/length": 188.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 19691.661328554153, "eval_episode/length": 156.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 420056, "time": 19693.8163895607, "eval_episode/length": 166.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 420056, "time": 19695.39676642418, "eval_episode/length": 167.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 420056, "time": 19699.486401319504, "eval_episode/length": 217.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 420056, "time": 19703.595937728882, "eval_episode/length": 270.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9704797047970479}
{"step": 420056, "time": 19705.847301006317, "eval_episode/length": 282.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9752650176678446}
{"step": 420056, "time": 19710.504621982574, "eval_episode/length": 352.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9943342776203966}
{"step": 420056, "time": 19716.76105618477, "eval_episode/length": 197.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 420320, "time": 19725.863124608994, "episode/length": 164.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 420400, "time": 19730.315490722656, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 420488, "time": 19734.606452703476, "episode/length": 172.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 420704, "time": 19743.61847805977, "episode/length": 264.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 420848, "time": 19750.17133331299, "episode/length": 176.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 421176, "time": 19762.85205888748, "episode/length": 228.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 421184, "time": 19764.96372961998, "episode/length": 41.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9047619047619048, "episode/intrinsic_return": 0.0}
{"step": 421496, "time": 19776.99002099037, "episode/length": 283.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9823943661971831, "episode/intrinsic_return": 0.0}
{"step": 421728, "time": 19786.765314102173, "episode/length": 165.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 421976, "time": 19796.402263641357, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 422040, "time": 19800.22380399704, "episode/length": 38.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 422048, "time": 19802.323370218277, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 422312, "time": 19812.50635766983, "episode/length": 313.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9840764331210191, "episode/intrinsic_return": 0.0}
{"step": 422784, "time": 19830.237666606903, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 422792, "time": 19831.900592803955, "episode/length": 93.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 423136, "time": 19845.278681755066, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 423184, "time": 19848.67521429062, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 423544, "time": 19862.19241142273, "episode/length": 295.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 423584, "time": 19865.422725200653, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 423760, "time": 19872.98538994789, "episode/length": 429.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 424136, "time": 19887.06519818306, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.0}
{"step": 424168, "time": 19889.80200457573, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 424232, "time": 19893.53192281723, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 424352, "time": 19899.491717100143, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 424920, "time": 19920.045489549637, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 424920, "time": 19920.05581498146, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 425720, "time": 19950.43219614029, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 425728, "time": 19952.56238245964, "episode/length": 171.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 425736, "time": 19954.087361574173, "episode/length": 199.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 425768, "time": 19956.726469278336, "episode/length": 105.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9528301886792453, "episode/intrinsic_return": 0.0}
{"step": 426152, "time": 19973.063455820084, "episode/length": 370.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9919137466307277, "episode/intrinsic_return": 0.0}
{"step": 426160, "time": 19975.202580690384, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 426344, "time": 19982.739373207092, "episode/length": 271.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 426440, "time": 19987.45373439789, "episode/length": 334.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9940298507462687, "episode/intrinsic_return": 0.0}
{"step": 427032, "time": 20008.961661577225, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 427424, "time": 20023.93510365486, "episode/length": 210.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 427688, "time": 20034.681432962418, "episode/length": 190.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 427712, "time": 20037.26493549347, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 427736, "time": 20039.45523762703, "episode/length": 245.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 428176, "time": 20056.12789297104, "episode/length": 216.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 428336, "time": 20063.13980269432, "episode/length": 248.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9718875502008032, "episode/intrinsic_return": 0.0}
{"step": 428808, "time": 20080.377050876617, "episode/length": 221.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 428864, "time": 20084.04242491722, "episode/length": 179.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9611111111111111, "episode/intrinsic_return": 0.0}
{"step": 429160, "time": 20095.28613638878, "episode/length": 429.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 429528, "time": 20109.167914628983, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 429704, "time": 20116.780975341797, "episode/length": 170.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 429736, "time": 20119.41664338112, "episode/length": 252.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 20151.122050523758, "eval_episode/length": 146.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9659863945578231}
{"step": 430040, "time": 20153.470380306244, "eval_episode/length": 164.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 430040, "time": 20155.176235198975, "eval_episode/length": 166.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 430040, "time": 20157.13669538498, "eval_episode/length": 173.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 430040, "time": 20159.97008061409, "eval_episode/length": 202.0, "eval_episode/score": 7.100000061094761, "eval_episode/reward_rate": 0.9802955665024631}
{"step": 430040, "time": 20162.284541606903, "eval_episode/length": 218.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9817351598173516}
{"step": 430040, "time": 20165.08531975746, "eval_episode/length": 80.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9382716049382716}
{"step": 430040, "time": 20170.501979351044, "eval_episode/length": 335.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9851190476190477}
{"step": 430184, "time": 20175.292116642, "episode/length": 171.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 430512, "time": 20188.140951395035, "episode/length": 122.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.959349593495935, "episode/intrinsic_return": 0.0}
{"step": 430544, "time": 20190.8509452343, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 430672, "time": 20196.699980974197, "episode/length": 372.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758713136729222, "episode/intrinsic_return": 0.0}
{"step": 431000, "time": 20209.17586541176, "episode/length": 229.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 431120, "time": 20215.037080049515, "episode/length": 422.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 431152, "time": 20217.76345396042, "episode/length": 180.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 431376, "time": 20226.792279720306, "episode/length": 46.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9148936170212766, "episode/intrinsic_return": 0.0}
{"step": 431584, "time": 20235.411897420883, "episode/length": 174.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 431880, "time": 20246.792311906815, "episode/length": 150.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 432016, "time": 20253.187034606934, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 432056, "time": 20255.93732881546, "episode/length": 188.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 432368, "time": 20268.3335647583, "episode/length": 43.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 432544, "time": 20275.83660531044, "episode/length": 173.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 432952, "time": 20290.969851493835, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 433056, "time": 20296.29775285721, "episode/length": 414.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9783132530120482, "episode/intrinsic_return": 0.0}
{"step": 433248, "time": 20304.345481157303, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 433496, "time": 20314.04945373535, "episode/length": 264.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 433792, "time": 20325.80266714096, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9631336405529954, "episode/intrinsic_return": 0.0}
{"step": 433848, "time": 20329.599061489105, "episode/length": 184.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 433872, "time": 20332.35406112671, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 434256, "time": 20348.16575884819, "episode/length": 391.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9923469387755102, "episode/intrinsic_return": 0.0}
{"step": 434408, "time": 20354.652665376663, "episode/length": 181.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 434425, "time": 20357.891588449478, "train_stats/sum_log_reward": 6.776470626101775, "train_stats/max_log_achievement_collect_coal": 0.13725490196078433, "train_stats/max_log_achievement_collect_drink": 6.313725490196078, "train_stats/max_log_achievement_collect_sapling": 2.235294117647059, "train_stats/max_log_achievement_collect_stone": 2.0686274509803924, "train_stats/max_log_achievement_collect_wood": 9.186274509803921, "train_stats/max_log_achievement_defeat_skeleton": 0.0196078431372549, "train_stats/max_log_achievement_defeat_zombie": 0.5, "train_stats/max_log_achievement_eat_cow": 0.12745098039215685, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.9509803921568627, "train_stats/max_log_achievement_make_wood_sword": 0.20588235294117646, "train_stats/max_log_achievement_place_furnace": 0.00980392156862745, "train_stats/max_log_achievement_place_plant": 2.127450980392157, "train_stats/max_log_achievement_place_stone": 0.049019607843137254, "train_stats/max_log_achievement_place_table": 2.323529411764706, "train_stats/max_log_achievement_wake_up": 1.6568627450980393, "train_stats/mean_log_entropy": 0.5424519432526008, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.43124655018682, "train/action_min": 0.0, "train/action_std": 3.1717665506445845, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.047546548579913986, "train/actor_opt_grad_steps": 26365.0, "train/actor_opt_loss": -3.0501475618018405, "train/adv_mag": 0.6820481331020162, "train/adv_max": 0.6637262952500496, "train/adv_mean": 0.004031007915846599, "train/adv_min": -0.4518747595341309, "train/adv_std": 0.07201025211184785, "train/cont_avg": 0.9946642889492754, "train/cont_loss_mean": 0.0002593200043862161, "train/cont_loss_std": 0.007548458108946787, "train/cont_neg_acc": 0.9907004837540613, "train/cont_neg_loss": 0.0237969612780153, "train/cont_pos_acc": 0.9999786278475886, "train/cont_pos_loss": 0.00012369387683675657, "train/cont_pred": 0.9946800820205522, "train/cont_rate": 0.9946642889492754, "train/dyn_loss_mean": 13.384777428447336, "train/dyn_loss_std": 9.23895301680634, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.93160439228666, "train/extr_critic_critic_opt_grad_steps": 26365.0, "train/extr_critic_critic_opt_loss": 15875.20412279212, "train/extr_critic_mag": 5.640311538309291, "train/extr_critic_max": 5.640311538309291, "train/extr_critic_mean": 1.2738613019818845, "train/extr_critic_min": -0.2143382015435592, "train/extr_critic_std": 1.2245096676591514, "train/extr_return_normed_mag": 1.8393133982368137, "train/extr_return_normed_max": 1.8393133982368137, "train/extr_return_normed_mean": 0.3371816332573476, "train/extr_return_normed_min": -0.14566466198775216, "train/extr_return_normed_std": 0.33474013338918274, "train/extr_return_rate": 0.630771657694941, "train/extr_return_raw_mag": 6.947574532550314, "train/extr_return_raw_max": 6.947574532550314, "train/extr_return_raw_mean": 1.2889937045781508, "train/extr_return_raw_min": -0.5300102457404137, "train/extr_return_raw_std": 1.2611065200273541, "train/extr_reward_mag": 1.0202753509300342, "train/extr_reward_max": 1.0202753509300342, "train/extr_reward_mean": 0.026823828381526728, "train/extr_reward_min": -0.41423085720642755, "train/extr_reward_std": 0.1517621911522271, "train/image_loss_mean": 7.44745249333589, "train/image_loss_std": 11.484049524086108, "train/model_loss_mean": 15.532902524091195, "train/model_loss_std": 15.322474458943242, "train/model_opt_grad_norm": 59.20721246194148, "train/model_opt_grad_steps": 26340.231884057972, "train/model_opt_loss": 12351.914310178894, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 797.1014492753624, "train/policy_entropy_mag": 2.511413358259892, "train/policy_entropy_max": 2.511413358259892, "train/policy_entropy_mean": 0.6093042877273284, "train/policy_entropy_min": 0.07937519943368608, "train/policy_entropy_std": 0.6728282637786174, "train/policy_logprob_mag": 7.43838335811228, "train/policy_logprob_max": -0.009455771556636993, "train/policy_logprob_mean": -0.6093920978946962, "train/policy_logprob_min": -7.43838335811228, "train/policy_logprob_std": 1.126367962014848, "train/policy_randomness_mag": 0.8864187049692955, "train/policy_randomness_max": 0.8864187049692955, "train/policy_randomness_mean": 0.21505767841270004, "train/policy_randomness_min": 0.028015962005525395, "train/policy_randomness_std": 0.23747885065234225, "train/post_ent_mag": 59.72134308193041, "train/post_ent_max": 59.72134308193041, "train/post_ent_mean": 42.01666699285092, "train/post_ent_min": 21.423421548760455, "train/post_ent_std": 7.376487586809241, "train/prior_ent_mag": 69.79674220430678, "train/prior_ent_max": 69.79674220430678, "train/prior_ent_mean": 55.45301619819973, "train/prior_ent_min": 40.20903120179107, "train/prior_ent_std": 4.886198306429213, "train/rep_loss_mean": 13.384777428447336, "train/rep_loss_std": 9.23895301680634, "train/reward_avg": 0.022513303612156407, "train/reward_loss_mean": 0.05432433850955272, "train/reward_loss_std": 0.26018805521121924, "train/reward_max_data": 1.0166666706403096, "train/reward_max_pred": 1.0085148785425269, "train/reward_neg_acc": 0.9930214912131212, "train/reward_neg_loss": 0.03120114102932638, "train/reward_pos_acc": 0.9614037512869075, "train/reward_pos_loss": 0.8787305398263793, "train/reward_pred": 0.021766088275319857, "train/reward_rate": 0.027244678442028984, "eval_stats/sum_log_reward": 6.725000023841858, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 7.125, "eval_stats/max_log_achievement_collect_sapling": 3.0625, "eval_stats/max_log_achievement_collect_stone": 1.5625, "eval_stats/max_log_achievement_collect_wood": 9.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.8125, "eval_stats/max_log_achievement_make_wood_sword": 0.125, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.9375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.0625, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.0001378431188641116, "report/cont_loss_std": 0.004305137787014246, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.04678195342421532, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.889133257776848e-07, "report/cont_pred": 0.9971977472305298, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.780259132385254, "report/dyn_loss_std": 8.671918869018555, "report/image_loss_mean": 5.520585536956787, "report/image_loss_std": 9.659262657165527, "report/model_loss_mean": 13.236981391906738, "report/model_loss_std": 13.235947608947754, "report/post_ent_mag": 61.139488220214844, "report/post_ent_max": 61.139488220214844, "report/post_ent_mean": 42.20264434814453, "report/post_ent_min": 20.10378074645996, "report/post_ent_std": 7.846261978149414, "report/prior_ent_mag": 69.97593688964844, "report/prior_ent_max": 69.97593688964844, "report/prior_ent_mean": 55.574981689453125, "report/prior_ent_min": 40.54891586303711, "report/prior_ent_std": 4.93565559387207, "report/rep_loss_mean": 12.780259132385254, "report/rep_loss_std": 8.671918869018555, "report/reward_avg": 0.02294921875, "report/reward_loss_mean": 0.04810295253992081, "report/reward_loss_std": 0.21517373621463776, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002760648727417, "report/reward_neg_acc": 0.9979940056800842, "report/reward_neg_loss": 0.02699977345764637, "report/reward_pos_acc": 0.9629629850387573, "report/reward_pos_loss": 0.8273575305938721, "report/reward_pred": 0.02114289253950119, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.8102003852836788e-06, "eval/cont_loss_std": 4.4053907913621515e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0005490655894391239, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.2051401654389338e-06, "eval/cont_pred": 0.9970706701278687, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.9974365234375, "eval/dyn_loss_std": 11.080696105957031, "eval/image_loss_mean": 15.650257110595703, "eval/image_loss_std": 21.034666061401367, "eval/model_loss_mean": 27.752178192138672, "eval/model_loss_std": 25.39112091064453, "eval/post_ent_mag": 59.537166595458984, "eval/post_ent_max": 59.537166595458984, "eval/post_ent_mean": 39.76429748535156, "eval/post_ent_min": 22.36846923828125, "eval/post_ent_std": 7.047604084014893, "eval/prior_ent_mag": 69.97593688964844, "eval/prior_ent_max": 69.97593688964844, "eval/prior_ent_mean": 56.27391815185547, "eval/prior_ent_min": 40.87493133544922, "eval/prior_ent_std": 4.35620641708374, "eval/rep_loss_mean": 19.9974365234375, "eval/rep_loss_std": 11.080696105957031, "eval/reward_avg": 0.03056640736758709, "eval/reward_loss_mean": 0.10345546156167984, "eval/reward_loss_std": 0.6097151637077332, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012075901031494, "eval/reward_neg_acc": 0.9949442744255066, "eval/reward_neg_loss": 0.04591502621769905, "eval/reward_pos_acc": 0.8285714387893677, "eval/reward_pos_loss": 1.7293835878372192, "eval/reward_pred": 0.02301713265478611, "eval/reward_rate": 0.0341796875, "replay/size": 433921.0, "replay/inserts": 22112.0, "replay/samples": 22112.0, "replay/insert_wait_avg": 1.4243763366069876e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.918700790957328e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 92784.0, "eval_replay/inserts": 6016.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2989373917275286e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1503720283508, "timer/env.step_count": 2764.0, "timer/env.step_total": 241.03866529464722, "timer/env.step_frac": 0.24100242527112173, "timer/env.step_avg": 0.08720646356535718, "timer/env.step_min": 0.02376556396484375, "timer/env.step_max": 3.319748878479004, "timer/replay._sample_count": 22112.0, "timer/replay._sample_total": 11.777637004852295, "timer/replay._sample_frac": 0.011775866243959602, "timer/replay._sample_avg": 0.0005326355374842752, "timer/replay._sample_min": 0.0003600120544433594, "timer/replay._sample_max": 0.01124882698059082, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3516.0, "timer/agent.policy_total": 61.655444383621216, "timer/agent.policy_frac": 0.061646174523318074, "timer/agent.policy_avg": 0.01753567815233823, "timer/agent.policy_min": 0.009567499160766602, "timer/agent.policy_max": 0.2738940715789795, "timer/dataset_train_count": 1382.0, "timer/dataset_train_total": 0.15799307823181152, "timer/dataset_train_frac": 0.00015796932406413478, "timer/dataset_train_avg": 0.00011432205371332237, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.0008907318115234375, "timer/agent.train_count": 1382.0, "timer/agent.train_total": 622.1416440010071, "timer/agent.train_frac": 0.6220481053656715, "timer/agent.train_avg": 0.4501748509413944, "timer/agent.train_min": 0.4377920627593994, "timer/agent.train_max": 1.687047004699707, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4717872142791748, "timer/agent.report_frac": 0.00047171628134514283, "timer/agent.report_avg": 0.2358936071395874, "timer/agent.report_min": 0.22354364395141602, "timer/agent.report_max": 0.2482435703277588, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.265843442188728e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 22.108384950695246}
{"step": 434960, "time": 20376.08180809021, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 435056, "time": 20381.0197327137, "episode/length": 150.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 435232, "time": 20388.60537004471, "episode/length": 271.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 435272, "time": 20391.442311048508, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 435616, "time": 20404.89175915718, "episode/length": 295.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9763513513513513, "episode/intrinsic_return": 0.0}
{"step": 435728, "time": 20410.267868041992, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 435872, "time": 20416.755095243454, "episode/length": 74.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 436264, "time": 20431.293778181076, "episode/length": 231.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 436328, "time": 20435.056748867035, "episode/length": 353.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9858757062146892, "episode/intrinsic_return": 0.0}
{"step": 436536, "time": 20443.58400130272, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 436584, "time": 20446.801518917084, "episode/length": 39.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 436912, "time": 20459.54250907898, "episode/length": 243.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 437224, "time": 20471.32825398445, "episode/length": 200.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 437424, "time": 20480.018310546875, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 437624, "time": 20488.150396585464, "episode/length": 298.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.0}
{"step": 438184, "time": 20508.72163248062, "episode/length": 205.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 438376, "time": 20516.91394996643, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 438392, "time": 20519.039622068405, "episode/length": 314.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 438536, "time": 20525.50777029991, "episode/length": 113.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.956140350877193, "episode/intrinsic_return": 0.0}
{"step": 438792, "time": 20535.73424744606, "episode/length": 170.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 439288, "time": 20554.148621320724, "episode/length": 369.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9972972972972973, "episode/intrinsic_return": 0.0}
{"step": 439448, "time": 20561.245015382767, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 439496, "time": 20564.384269475937, "episode/length": 363.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9972527472527473, "episode/intrinsic_return": 0.0}
{"step": 439720, "time": 20573.582825660706, "episode/length": 311.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9967948717948718, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 20600.74826359749, "eval_episode/length": 43.0, "eval_episode/score": 2.100000023841858, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 440024, "time": 20605.646194458008, "eval_episode/length": 121.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9508196721311475}
{"step": 440024, "time": 20608.10577917099, "eval_episode/length": 143.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9583333333333334}
{"step": 440024, "time": 20609.93577671051, "eval_episode/length": 149.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 440024, "time": 20613.153626441956, "eval_episode/length": 184.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 440024, "time": 20615.464891672134, "eval_episode/length": 201.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.995049504950495}
{"step": 440024, "time": 20617.731430530548, "eval_episode/length": 215.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 440024, "time": 20621.397516727448, "eval_episode/length": 216.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 440368, "time": 20633.277740955353, "episode/length": 246.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 440400, "time": 20635.906477451324, "episode/length": 232.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 440512, "time": 20641.455883979797, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 440848, "time": 20654.3395318985, "episode/length": 308.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9870550161812298, "episode/intrinsic_return": 0.0}
{"step": 440984, "time": 20660.391228675842, "episode/length": 191.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 441120, "time": 20666.86940050125, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 441144, "time": 20669.021219730377, "episode/length": 205.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9854368932038835, "episode/intrinsic_return": 0.0}
{"step": 441688, "time": 20688.937716960907, "episode/length": 164.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 442120, "time": 20705.079448461533, "episode/length": 200.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 442256, "time": 20711.58736848831, "episode/length": 231.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 442472, "time": 20722.068973064423, "episode/length": 397.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9899497487437185, "episode/intrinsic_return": 0.0}
{"step": 442544, "time": 20726.37122273445, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 442824, "time": 20737.10042977333, "episode/length": 246.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 442872, "time": 20740.475472688675, "episode/length": 218.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 443192, "time": 20752.979889392853, "episode/length": 255.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 443640, "time": 20769.67007136345, "episode/length": 189.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 443816, "time": 20777.36029601097, "episode/length": 117.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9915254237288136, "episode/intrinsic_return": 0.0}
{"step": 443840, "time": 20780.05329656601, "episode/length": 268.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 444208, "time": 20794.074553012848, "episode/length": 243.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 444232, "time": 20796.232753276825, "episode/length": 219.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 444688, "time": 20813.401424884796, "episode/length": 59.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 444872, "time": 20820.98669075966, "episode/length": 209.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 444872, "time": 20820.99370741844, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 445008, "time": 20829.218614578247, "episode/length": 307.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9967532467532467, "episode/intrinsic_return": 0.0}
{"step": 445312, "time": 20841.04726791382, "episode/length": 37.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 445360, "time": 20844.2431306839, "episode/length": 316.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9905362776025236, "episode/intrinsic_return": 0.0}
{"step": 445776, "time": 20859.860122442245, "episode/length": 241.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 446400, "time": 20882.649040937424, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 446576, "time": 20890.122641801834, "episode/length": 292.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761092150170648, "episode/intrinsic_return": 0.0}
{"step": 446624, "time": 20893.304284095764, "episode/length": 241.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 446696, "time": 20897.508598089218, "episode/length": 359.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 446792, "time": 20902.35534119606, "episode/length": 126.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 446832, "time": 20905.572449207306, "episode/length": 244.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 447072, "time": 20915.29770541191, "episode/length": 213.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 447120, "time": 20918.44479060173, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9690265486725663, "episode/intrinsic_return": 0.0}
{"step": 447928, "time": 20947.06422996521, "episode/length": 168.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 448080, "time": 20954.120732307434, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 448176, "time": 20959.09052181244, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 448272, "time": 20964.040148973465, "episode/length": 233.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 448752, "time": 20981.78565597534, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 448808, "time": 20984.97505426407, "episode/length": 251.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 448888, "time": 20989.423364400864, "episode/length": 220.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 448952, "time": 20993.20030593872, "episode/length": 264.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 449272, "time": 21005.59708428383, "episode/length": 167.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 449448, "time": 21013.2184779644, "episode/length": 170.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 449720, "time": 21024.174121379852, "episode/length": 180.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.988950276243094, "episode/intrinsic_return": 0.0}
{"step": 449968, "time": 21034.2865960598, "episode/length": 134.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 21055.419075250626, "eval_episode/length": 113.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.956140350877193}
{"step": 450008, "time": 21057.729571580887, "eval_episode/length": 131.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9621212121212122}
{"step": 450008, "time": 21060.951496362686, "eval_episode/length": 166.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 450008, "time": 21063.215406894684, "eval_episode/length": 181.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 450008, "time": 21064.91475367546, "eval_episode/length": 183.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 450008, "time": 21066.979711294174, "eval_episode/length": 193.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 450008, "time": 21070.20379638672, "eval_episode/length": 224.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 450008, "time": 21073.425691843033, "eval_episode/length": 258.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9961389961389961}
{"step": 450064, "time": 21075.556010246277, "episode/length": 163.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 450136, "time": 21079.447135448456, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 450440, "time": 21091.14045715332, "episode/length": 46.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 450608, "time": 21100.320824861526, "episode/length": 303.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9901315789473685, "episode/intrinsic_return": 0.0}
{"step": 450632, "time": 21102.52853512764, "episode/length": 169.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 450672, "time": 21105.723524808884, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 450680, "time": 21107.54865860939, "episode/length": 215.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 451192, "time": 21126.110964536667, "episode/length": 152.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 451480, "time": 21137.502381324768, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 451648, "time": 21144.85266804695, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9536423841059603, "episode/intrinsic_return": 0.0}
{"step": 451992, "time": 21157.843096017838, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 452016, "time": 21160.423359155655, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 452072, "time": 21163.768438577652, "episode/length": 293.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9863945578231292, "episode/intrinsic_return": 0.0}
{"step": 452256, "time": 21171.826049804688, "episode/length": 205.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 453048, "time": 21199.99196434021, "episode/length": 128.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 453184, "time": 21206.444067001343, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 453200, "time": 21208.645522117615, "episode/length": 250.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 453576, "time": 21222.757553100586, "episode/length": 261.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 453688, "time": 21228.207951784134, "episode/length": 211.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 454528, "time": 21258.37128520012, "episode/length": 481.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9813278008298755, "episode/intrinsic_return": 0.0}
{"step": 454832, "time": 21270.326469182968, "episode/length": 344.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 455016, "time": 21277.82408952713, "episode/length": 165.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 455184, "time": 21285.278755426407, "episode/length": 365.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 455200, "time": 21287.623030662537, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 455368, "time": 21294.666347026825, "episode/length": 272.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 455728, "time": 21308.967111825943, "episode/length": 334.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9880597014925373, "episode/intrinsic_return": 0.0}
{"step": 456096, "time": 21322.980309963226, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 456424, "time": 21335.482885837555, "episode/length": 198.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 456600, "time": 21342.974405288696, "episode/length": 424.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788235294117648, "episode/intrinsic_return": 0.0}
{"step": 456632, "time": 21345.573088169098, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 456921, "time": 21358.003214597702, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.555785267065603, "train/action_min": 0.0, "train/action_std": 3.256580300364934, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04628151480821853, "train/actor_opt_grad_steps": 27760.0, "train/actor_opt_loss": -4.525082086417692, "train/adv_mag": 0.6304299313548609, "train/adv_max": 0.6169679957501432, "train/adv_mean": 0.003788079667142064, "train/adv_min": -0.45172195400752074, "train/adv_std": 0.06858311117963588, "train/cont_avg": 0.9949994459219859, "train/cont_loss_mean": 0.000327784507473862, "train/cont_loss_std": 0.009835220891036184, "train/cont_neg_acc": 0.9841607576566385, "train/cont_neg_loss": 0.039481368774341455, "train/cont_pos_acc": 0.9999512839824596, "train/cont_pos_loss": 0.00013290559990957154, "train/cont_pred": 0.9950149342523399, "train/cont_rate": 0.9949994459219859, "train/dyn_loss_mean": 13.390429253273822, "train/dyn_loss_std": 9.23858616876264, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9365496356436547, "train/extr_critic_critic_opt_grad_steps": 27760.0, "train/extr_critic_critic_opt_loss": 15888.285073138299, "train/extr_critic_mag": 5.829290461032949, "train/extr_critic_max": 5.829290461032949, "train/extr_critic_mean": 1.3345850925919012, "train/extr_critic_min": -0.21561304051825342, "train/extr_critic_std": 1.2716378206056906, "train/extr_return_normed_mag": 1.8051573088828554, "train/extr_return_normed_max": 1.8051573088828554, "train/extr_return_normed_mean": 0.33408877538873794, "train/extr_return_normed_min": -0.1405639148561667, "train/extr_return_normed_std": 0.32762230594530173, "train/extr_return_rate": 0.6608710468660856, "train/extr_return_raw_mag": 7.234727873024365, "train/extr_return_raw_max": 7.234727873024365, "train/extr_return_raw_mean": 1.349710984432951, "train/extr_return_raw_min": -0.5492816528318621, "train/extr_return_raw_std": 1.3109967936860754, "train/extr_reward_mag": 1.015592891273769, "train/extr_reward_max": 1.015592891273769, "train/extr_reward_mean": 0.02713441117567585, "train/extr_reward_min": -0.4083665744632694, "train/extr_reward_std": 0.15214125489723598, "train/image_loss_mean": 7.363490960276719, "train/image_loss_std": 11.58290436589126, "train/model_loss_mean": 15.449707382959676, "train/model_loss_std": 15.453940263031223, "train/model_opt_grad_norm": 61.104262805154136, "train/model_opt_grad_steps": 27734.58865248227, "train/model_opt_loss": 15389.255374556738, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 992.9078014184397, "train/policy_entropy_mag": 2.525082361613605, "train/policy_entropy_max": 2.525082361613605, "train/policy_entropy_mean": 0.5869739469906963, "train/policy_entropy_min": 0.07937517746331844, "train/policy_entropy_std": 0.6867588572468318, "train/policy_logprob_mag": 7.43838359616327, "train/policy_logprob_max": -0.009455760742755646, "train/policy_logprob_mean": -0.5865692980323277, "train/policy_logprob_min": -7.43838359616327, "train/policy_logprob_std": 1.1174132663307461, "train/policy_randomness_mag": 0.8912432662984158, "train/policy_randomness_max": 0.8912432662984158, "train/policy_randomness_mean": 0.20717604394922864, "train/policy_randomness_min": 0.028015954327498767, "train/policy_randomness_std": 0.24239573928904026, "train/post_ent_mag": 59.28579609106618, "train/post_ent_max": 59.28579609106618, "train/post_ent_mean": 42.12970479329427, "train/post_ent_min": 21.250423972488296, "train/post_ent_std": 7.32526499497975, "train/prior_ent_mag": 69.94811584256219, "train/prior_ent_max": 69.94811584256219, "train/prior_ent_mean": 55.563059543041476, "train/prior_ent_min": 40.902604637416545, "train/prior_ent_std": 4.778695461597849, "train/rep_loss_mean": 13.390429253273822, "train/rep_loss_std": 9.23858616876264, "train/reward_avg": 0.02298038541042107, "train/reward_loss_mean": 0.05163124024022556, "train/reward_loss_std": 0.24911762890240824, "train/reward_max_data": 1.0113475204359554, "train/reward_max_pred": 1.0062667351242498, "train/reward_neg_acc": 0.9933126323612024, "train/reward_neg_loss": 0.028019159484046992, "train/reward_pos_acc": 0.9609732057185884, "train/reward_pos_loss": 0.8886302375624365, "train/reward_pred": 0.022286848452417775, "train/reward_rate": 0.02750997340425532, "train_stats/sum_log_reward": 7.0306931580647385, "train_stats/max_log_achievement_collect_coal": 0.4158415841584158, "train_stats/max_log_achievement_collect_drink": 7.356435643564357, "train_stats/max_log_achievement_collect_sapling": 2.277227722772277, "train_stats/max_log_achievement_collect_stone": 3.1386138613861387, "train_stats/max_log_achievement_collect_wood": 10.405940594059405, "train_stats/max_log_achievement_defeat_skeleton": 0.019801980198019802, "train_stats/max_log_achievement_defeat_zombie": 0.5148514851485149, "train_stats/max_log_achievement_eat_cow": 0.07920792079207921, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.891089108910891, "train_stats/max_log_achievement_make_wood_sword": 0.06930693069306931, "train_stats/max_log_achievement_place_furnace": 0.0297029702970297, "train_stats/max_log_achievement_place_plant": 2.1485148514851486, "train_stats/max_log_achievement_place_stone": 0.039603960396039604, "train_stats/max_log_achievement_place_table": 2.722772277227723, "train_stats/max_log_achievement_wake_up": 1.3267326732673268, "train_stats/mean_log_entropy": 0.5405702348982934, "eval_stats/sum_log_reward": 6.662500023841858, "eval_stats/max_log_achievement_collect_coal": 0.1875, "eval_stats/max_log_achievement_collect_drink": 5.1875, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 1.625, "eval_stats/max_log_achievement_collect_wood": 10.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.75, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.8125, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.2744693776767235e-05, "report/cont_loss_std": 0.00031919803586788476, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003039501898456365, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.1315814845147543e-05, "report/cont_pred": 0.9951075315475464, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 10.644330024719238, "report/dyn_loss_std": 8.606905937194824, "report/image_loss_mean": 6.889634132385254, "report/image_loss_std": 8.029128074645996, "report/model_loss_mean": 13.327444076538086, "report/model_loss_std": 11.368857383728027, "report/post_ent_mag": 61.95583724975586, "report/post_ent_max": 61.95583724975586, "report/post_ent_mean": 45.402503967285156, "report/post_ent_min": 20.0456485748291, "report/post_ent_std": 8.30307388305664, "report/prior_ent_mag": 70.68836975097656, "report/prior_ent_max": 70.68836975097656, "report/prior_ent_mean": 56.07142639160156, "report/prior_ent_min": 42.29051971435547, "report/prior_ent_std": 4.783614635467529, "report/rep_loss_mean": 10.644330024719238, "report/rep_loss_std": 8.606905937194824, "report/reward_avg": 0.02041015587747097, "report/reward_loss_mean": 0.05119892582297325, "report/reward_loss_std": 0.2776206433773041, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0029914379119873, "report/reward_neg_acc": 0.9979979991912842, "report/reward_neg_loss": 0.02518707700073719, "report/reward_pos_acc": 0.9199999570846558, "report/reward_pos_loss": 1.0906323194503784, "report/reward_pred": 0.016162265092134476, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 8.6929154349491e-05, "eval/cont_loss_std": 0.0021443713922053576, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0033361390233039856, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.098602509358898e-05, "eval/cont_pred": 0.9950648546218872, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.12899398803711, "eval/dyn_loss_std": 10.394143104553223, "eval/image_loss_mean": 15.145691871643066, "eval/image_loss_std": 23.005664825439453, "eval/model_loss_mean": 25.553619384765625, "eval/model_loss_std": 26.756315231323242, "eval/post_ent_mag": 63.43062973022461, "eval/post_ent_max": 63.43062973022461, "eval/post_ent_mean": 42.21009826660156, "eval/post_ent_min": 23.14318084716797, "eval/post_ent_std": 7.981645584106445, "eval/prior_ent_mag": 70.68836975097656, "eval/prior_ent_max": 70.68836975097656, "eval/prior_ent_mean": 57.453121185302734, "eval/prior_ent_min": 41.78183364868164, "eval/prior_ent_std": 4.476583003997803, "eval/rep_loss_mean": 17.12899398803711, "eval/rep_loss_std": 10.394143104553223, "eval/reward_avg": 0.03496093675494194, "eval/reward_loss_mean": 0.13044355809688568, "eval/reward_loss_std": 0.8053635358810425, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0016684532165527, "eval/reward_neg_acc": 0.9928862452507019, "eval/reward_neg_loss": 0.031800054013729095, "eval/reward_pos_acc": 0.7250000238418579, "eval/reward_pos_loss": 2.5570738315582275, "eval/reward_pred": 0.022824494168162346, "eval/reward_rate": 0.0390625, "replay/size": 456417.0, "replay/inserts": 22496.0, "replay/samples": 22496.0, "replay/insert_wait_avg": 1.431062584411708e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.008949545674439e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 96944.0, "eval_replay/inserts": 4160.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3058002178485577e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0900754928589, "timer/env.step_count": 2812.0, "timer/env.step_total": 241.0256266593933, "timer/env.step_frac": 0.2410039181126884, "timer/env.step_avg": 0.08571323849907302, "timer/env.step_min": 0.023580551147460938, "timer/env.step_max": 3.465742349624634, "timer/replay._sample_count": 22496.0, "timer/replay._sample_total": 12.009884357452393, "timer/replay._sample_frac": 0.012008802658634271, "timer/replay._sample_avg": 0.0005338675478952877, "timer/replay._sample_min": 0.00042366981506347656, "timer/replay._sample_max": 0.01104879379272461, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3332.0, "timer/agent.policy_total": 56.57916235923767, "timer/agent.policy_frac": 0.05657406642232165, "timer/agent.policy_avg": 0.016980540924140957, "timer/agent.policy_min": 0.009434223175048828, "timer/agent.policy_max": 0.12136363983154297, "timer/dataset_train_count": 1406.0, "timer/dataset_train_total": 0.16009235382080078, "timer/dataset_train_frac": 0.00016007793472193487, "timer/dataset_train_avg": 0.00011386369404039885, "timer/dataset_train_min": 9.870529174804688e-05, "timer/dataset_train_max": 0.0006823539733886719, "timer/agent.train_count": 1406.0, "timer/agent.train_total": 633.6286990642548, "timer/agent.train_frac": 0.6335716297874402, "timer/agent.train_avg": 0.45066052565025233, "timer/agent.train_min": 0.4338674545288086, "timer/agent.train_max": 1.7292191982269287, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4772474765777588, "timer/agent.report_frac": 0.00047720449214793407, "timer/agent.report_avg": 0.2386237382888794, "timer/agent.report_min": 0.2336258888244629, "timer/agent.report_max": 0.2436215877532959, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9084446854505678e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 22.493658619539882}
{"step": 457088, "time": 21363.65777039528, "episode/length": 60.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 457176, "time": 21367.933000326157, "episode/length": 180.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 457224, "time": 21371.082793951035, "episode/length": 231.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 457464, "time": 21380.809131622314, "episode/length": 305.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9967320261437909, "episode/intrinsic_return": 0.0}
{"step": 457848, "time": 21395.228021860123, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 458040, "time": 21403.17418885231, "episode/length": 242.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 458120, "time": 21407.573236227036, "episode/length": 185.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 458288, "time": 21415.020196914673, "episode/length": 149.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 458592, "time": 21426.960186243057, "episode/length": 423.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9976415094339622, "episode/intrinsic_return": 0.0}
{"step": 458640, "time": 21430.068150520325, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 458824, "time": 21439.511917114258, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 458976, "time": 21446.459799528122, "episode/length": 224.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 459960, "time": 21481.14549255371, "episode/length": 170.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 21503.827913999557, "eval_episode/length": 57.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 460096, "time": 21512.803084611893, "eval_episode/length": 183.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 460096, "time": 21514.941541671753, "eval_episode/length": 193.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 460096, "time": 21517.22897529602, "eval_episode/length": 208.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 460096, "time": 21519.22993159294, "eval_episode/length": 157.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 460096, "time": 21521.31881594658, "eval_episode/length": 227.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 460096, "time": 21523.392971992493, "eval_episode/length": 236.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9957805907172996}
{"step": 460096, "time": 21525.31895017624, "eval_episode/length": 57.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 460120, "time": 21525.940333604813, "episode/length": 283.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 460288, "time": 21533.631675720215, "episode/length": 205.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 460368, "time": 21537.86688709259, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 460504, "time": 21543.821142673492, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 460576, "time": 21548.03147149086, "episode/length": 76.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 460904, "time": 21560.445405960083, "episode/length": 66.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9253731343283582, "episode/intrinsic_return": 0.0}
{"step": 460984, "time": 21564.741091012955, "episode/length": 336.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9881305637982196, "episode/intrinsic_return": 0.0}
{"step": 461080, "time": 21569.624309301376, "episode/length": 62.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 461216, "time": 21575.917018175125, "episode/length": 396.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9773299748110831, "episode/intrinsic_return": 0.0}
{"step": 461352, "time": 21581.919016122818, "episode/length": 403.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9975247524752475, "episode/intrinsic_return": 0.0}
{"step": 461896, "time": 21601.847249507904, "episode/length": 173.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 461984, "time": 21606.547359466553, "episode/length": 211.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 462320, "time": 21619.39957165718, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 462424, "time": 21624.32913994789, "episode/length": 150.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 462600, "time": 21631.908224344254, "episode/length": 189.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 462760, "time": 21638.799491882324, "episode/length": 175.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 462800, "time": 21642.00838494301, "episode/length": 334.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.991044776119403, "episode/intrinsic_return": 0.0}
{"step": 463064, "time": 21652.2737493515, "episode/length": 269.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9740740740740741, "episode/intrinsic_return": 0.0}
{"step": 463464, "time": 21667.188462257385, "episode/length": 184.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 463840, "time": 21681.77635741234, "episode/length": 176.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 463864, "time": 21684.140724658966, "episode/length": 192.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 464280, "time": 21699.7225151062, "episode/length": 184.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 464360, "time": 21703.970302820206, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 464432, "time": 21708.504051923752, "episode/length": 316.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9968454258675079, "episode/intrinsic_return": 0.0}
{"step": 464808, "time": 21722.526008844376, "episode/length": 275.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 464872, "time": 21726.222607135773, "episode/length": 263.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 465080, "time": 21734.886065483093, "episode/length": 33.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 465584, "time": 21753.80135345459, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 465776, "time": 21761.88573360443, "episode/length": 176.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 465792, "time": 21764.168402194977, "episode/length": 290.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 465808, "time": 21766.45571398735, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 466408, "time": 21788.261574983597, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 466688, "time": 21799.696993350983, "episode/length": 34.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 466704, "time": 21801.880252838135, "episode/length": 302.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735973597359736, "episode/intrinsic_return": 0.0}
{"step": 466968, "time": 21813.758830308914, "episode/length": 387.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9768041237113402, "episode/intrinsic_return": 0.0}
{"step": 466992, "time": 21816.361762285233, "episode/length": 264.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 467248, "time": 21826.71678853035, "episode/length": 181.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 467984, "time": 21853.03370141983, "episode/length": 271.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742647058823529, "episode/intrinsic_return": 0.0}
{"step": 468112, "time": 21859.137199878693, "episode/length": 142.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 468152, "time": 21861.95629954338, "episode/length": 296.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9831649831649831, "episode/intrinsic_return": 0.0}
{"step": 468304, "time": 21869.007435321808, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 468568, "time": 21879.292457818985, "episode/length": 232.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 468944, "time": 21893.858572483063, "episode/length": 46.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 469112, "time": 21900.820368766785, "episode/length": 440.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 469192, "time": 21905.136472702026, "episode/length": 129.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 469328, "time": 21911.567687749863, "episode/length": 167.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 469480, "time": 21918.175539016724, "episode/length": 278.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.992831541218638, "episode/intrinsic_return": 0.0}
{"step": 469608, "time": 21924.07169818878, "episode/length": 51.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9423076923076923, "episode/intrinsic_return": 0.0}
{"step": 469832, "time": 21933.155834913254, "episode/length": 392.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 21964.53223800659, "eval_episode/length": 174.0, "eval_episode/score": 9.099999964237213, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 470080, "time": 21966.42771601677, "eval_episode/length": 180.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.994475138121547}
{"step": 470080, "time": 21968.84891986847, "eval_episode/length": 197.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 470080, "time": 21970.5740172863, "eval_episode/length": 201.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.995049504950495}
{"step": 470080, "time": 21973.017964363098, "eval_episode/length": 43.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 470080, "time": 21975.97106528282, "eval_episode/length": 246.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.9959514170040485}
{"step": 470080, "time": 21979.059777259827, "eval_episode/length": 277.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9964028776978417}
{"step": 470080, "time": 21985.71042585373, "eval_episode/length": 212.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 470384, "time": 21995.993425130844, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 470432, "time": 21999.32737660408, "episode/length": 265.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 470560, "time": 22005.174555063248, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 470920, "time": 22018.898213863373, "episode/length": 198.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 470936, "time": 22021.001722812653, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 471056, "time": 22026.77691411972, "episode/length": 367.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 471184, "time": 22032.743378400803, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 471280, "time": 22037.673671007156, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 471568, "time": 22048.919059038162, "episode/length": 47.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 471664, "time": 22053.676545619965, "episode/length": 47.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 471896, "time": 22062.599601507187, "episode/length": 188.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 472064, "time": 22070.205934286118, "episode/length": 187.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 472096, "time": 22072.810525894165, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 472368, "time": 22083.576666116714, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 472784, "time": 22099.360125541687, "episode/length": 215.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 472856, "time": 22103.07740330696, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 473160, "time": 22115.127808332443, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 473328, "time": 22122.631779909134, "episode/length": 298.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765886287625418, "episode/intrinsic_return": 0.0}
{"step": 473464, "time": 22128.700193166733, "episode/length": 174.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 473648, "time": 22136.702310800552, "episode/length": 39.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 473824, "time": 22144.160576820374, "episode/length": 181.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 474288, "time": 22161.443350553513, "episode/length": 178.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 474528, "time": 22171.313246011734, "episode/length": 217.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 474544, "time": 22173.392132759094, "episode/length": 359.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 474816, "time": 22184.244928836823, "episode/length": 168.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 474928, "time": 22189.726905107498, "episode/length": 159.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 475016, "time": 22194.158671617508, "episode/length": 231.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 475184, "time": 22203.32731819153, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 475352, "time": 22210.298637151718, "episode/length": 406.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9926289926289926, "episode/intrinsic_return": 0.0}
{"step": 475608, "time": 22220.53733897209, "episode/length": 132.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 476024, "time": 22236.22888326645, "episode/length": 125.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 476344, "time": 22248.775250196457, "episode/length": 256.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 476696, "time": 22262.214102745056, "episode/length": 220.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 476720, "time": 22264.92390704155, "episode/length": 237.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 477360, "time": 22288.091681480408, "episode/length": 271.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 477400, "time": 22290.900973796844, "episode/length": 223.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 477944, "time": 22310.884829998016, "episode/length": 239.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 478248, "time": 22322.66372036934, "episode/length": 110.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.963963963963964, "episode/intrinsic_return": 0.0}
{"step": 478472, "time": 22331.84924721718, "episode/length": 221.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 478512, "time": 22335.029402017593, "episode/length": 223.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 478608, "time": 22340.058187246323, "episode/length": 509.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 478624, "time": 22342.245792388916, "episode/length": 284.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 478952, "time": 22354.652495622635, "episode/length": 449.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9977777777777778, "episode/intrinsic_return": 0.0}
{"step": 478985, "time": 22358.265510559082, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.429398246433424, "train/action_min": 0.0, "train/action_std": 3.251732852147973, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.043855171677642975, "train/actor_opt_grad_steps": 29155.0, "train/actor_opt_loss": -0.89202411170455, "train/adv_mag": 0.6198283209316973, "train/adv_max": 0.5945559804854186, "train/adv_mean": 0.004778794167749225, "train/adv_min": -0.44798931263495184, "train/adv_std": 0.06708836374615414, "train/cont_avg": 0.994919044384058, "train/cont_loss_mean": 0.0003365140670315787, "train/cont_loss_std": 0.008950492329289034, "train/cont_neg_acc": 0.9928832119398744, "train/cont_neg_loss": 0.01758329618859116, "train/cont_pos_acc": 0.9999217667441437, "train/cont_pos_loss": 0.00024246023695131112, "train/cont_pred": 0.9948812943437825, "train/cont_rate": 0.994919044384058, "train/dyn_loss_mean": 13.448953213899031, "train/dyn_loss_std": 9.277927668198295, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9062411344569662, "train/extr_critic_critic_opt_grad_steps": 29155.0, "train/extr_critic_critic_opt_loss": 16063.47119848279, "train/extr_critic_mag": 6.10768365168917, "train/extr_critic_max": 6.10768365168917, "train/extr_critic_mean": 1.4371829006982886, "train/extr_critic_min": -0.20142990437106809, "train/extr_critic_std": 1.3662103367024574, "train/extr_return_normed_mag": 1.7267472864924998, "train/extr_return_normed_max": 1.7267472864924998, "train/extr_return_normed_mean": 0.33742767507615296, "train/extr_return_normed_min": -0.12362392087453518, "train/extr_return_normed_std": 0.3295244859612506, "train/extr_return_rate": 0.6724652190139329, "train/extr_return_raw_mag": 7.384213644525279, "train/extr_return_raw_max": 7.384213644525279, "train/extr_return_raw_mean": 1.4575627757155376, "train/extr_return_raw_min": -0.5089746454487676, "train/extr_return_raw_std": 1.4057352318279985, "train/extr_reward_mag": 1.0151271828706714, "train/extr_reward_max": 1.0151271828706714, "train/extr_reward_mean": 0.028325927518038214, "train/extr_reward_min": -0.3836705105892126, "train/extr_reward_std": 0.15508567331277806, "train/image_loss_mean": 7.1948897907699365, "train/image_loss_std": 11.48958630838256, "train/model_loss_mean": 15.315104139023934, "train/model_loss_std": 15.380801684614541, "train/model_opt_grad_norm": 62.959900593412094, "train/model_opt_grad_steps": 29128.014492753624, "train/model_opt_loss": 6089.0819233327675, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 398.5507246376812, "train/policy_entropy_mag": 2.52712663360264, "train/policy_entropy_max": 2.52712663360264, "train/policy_entropy_mean": 0.5775765774474628, "train/policy_entropy_min": 0.07937515532408936, "train/policy_entropy_std": 0.684031943048256, "train/policy_logprob_mag": 7.438383599986201, "train/policy_logprob_max": -0.009455744986948759, "train/policy_logprob_mean": -0.5778163926324983, "train/policy_logprob_min": -7.438383599986201, "train/policy_logprob_std": 1.1120895622433096, "train/policy_randomness_mag": 0.8919648001159447, "train/policy_randomness_max": 0.8919648001159447, "train/policy_randomness_mean": 0.20385918399130087, "train/policy_randomness_min": 0.02801594652397477, "train/policy_randomness_std": 0.24143325515847275, "train/post_ent_mag": 60.00006117336992, "train/post_ent_max": 60.00006117336992, "train/post_ent_mean": 42.28717803955078, "train/post_ent_min": 21.338995587998543, "train/post_ent_std": 7.401660293772601, "train/prior_ent_mag": 70.06466459191364, "train/prior_ent_max": 70.06466459191364, "train/prior_ent_mean": 55.74978554767111, "train/prior_ent_min": 41.69658909673276, "train/prior_ent_std": 4.760088675263999, "train/rep_loss_mean": 13.448953213899031, "train/rep_loss_std": 9.277927668198295, "train/reward_avg": 0.022903221031731886, "train/reward_loss_mean": 0.05050597415454146, "train/reward_loss_std": 0.2414246351606604, "train/reward_max_data": 1.0123188435167507, "train/reward_max_pred": 1.0059670166692871, "train/reward_neg_acc": 0.9941216318503671, "train/reward_neg_loss": 0.027412531823189795, "train/reward_pos_acc": 0.9626311249491097, "train/reward_pos_loss": 0.87014992211176, "train/reward_pred": 0.022135592102869483, "train/reward_rate": 0.027527740036231884, "train_stats/sum_log_reward": 7.071428696314494, "train_stats/max_log_achievement_collect_coal": 0.2571428571428571, "train_stats/max_log_achievement_collect_drink": 7.0095238095238095, "train_stats/max_log_achievement_collect_sapling": 2.257142857142857, "train_stats/max_log_achievement_collect_stone": 2.6666666666666665, "train_stats/max_log_achievement_collect_wood": 11.085714285714285, "train_stats/max_log_achievement_defeat_skeleton": 0.047619047619047616, "train_stats/max_log_achievement_defeat_zombie": 0.5238095238095238, "train_stats/max_log_achievement_eat_cow": 0.20952380952380953, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4285714285714286, "train_stats/max_log_achievement_make_wood_sword": 1.5047619047619047, "train_stats/max_log_achievement_place_furnace": 0.009523809523809525, "train_stats/max_log_achievement_place_plant": 1.9428571428571428, "train_stats/max_log_achievement_place_stone": 0.02857142857142857, "train_stats/max_log_achievement_place_table": 2.5428571428571427, "train_stats/max_log_achievement_wake_up": 1.4857142857142858, "train_stats/mean_log_entropy": 0.5425582800592695, "eval_stats/sum_log_reward": 6.6624999195337296, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 5.0, "eval_stats/max_log_achievement_collect_sapling": 2.0625, "eval_stats/max_log_achievement_collect_stone": 1.4375, "eval_stats/max_log_achievement_collect_wood": 9.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.4375, "eval_stats/max_log_achievement_make_wood_sword": 2.125, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.9375, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 2.5625, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.1239515515626408e-05, "report/cont_loss_std": 5.5404281738447025e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003382984723430127, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.311860594607424e-06, "report/cont_pred": 0.9941333532333374, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.58321475982666, "report/dyn_loss_std": 9.265380859375, "report/image_loss_mean": 7.749324321746826, "report/image_loss_std": 11.89702320098877, "report/model_loss_mean": 15.946418762207031, "report/model_loss_std": 15.347694396972656, "report/post_ent_mag": 59.754634857177734, "report/post_ent_max": 59.754634857177734, "report/post_ent_mean": 41.74034118652344, "report/post_ent_min": 22.174198150634766, "report/post_ent_std": 7.901205539703369, "report/prior_ent_mag": 70.56683349609375, "report/prior_ent_max": 70.56683349609375, "report/prior_ent_mean": 55.86201095581055, "report/prior_ent_min": 41.28678512573242, "report/prior_ent_std": 4.754758834838867, "report/rep_loss_mean": 13.58321475982666, "report/rep_loss_std": 9.265380859375, "report/reward_avg": 0.01113281212747097, "report/reward_loss_mean": 0.0471540167927742, "report/reward_loss_std": 0.22746261954307556, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0059373378753662, "report/reward_neg_acc": 0.9970208406448364, "report/reward_neg_loss": 0.03390492871403694, "report/reward_pos_acc": 0.9411764740943909, "report/reward_pos_loss": 0.8319676518440247, "report/reward_pred": 0.011201218701899052, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 6.129414032329805e-06, "eval/cont_loss_std": 2.1636869860230945e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0003200494684278965, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.822551884193672e-06, "eval/cont_pred": 0.9990179538726807, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 17.204952239990234, "eval/dyn_loss_std": 10.025214195251465, "eval/image_loss_mean": 10.704319953918457, "eval/image_loss_std": 12.856977462768555, "eval/model_loss_mean": 21.146516799926758, "eval/model_loss_std": 16.972461700439453, "eval/post_ent_mag": 56.75663757324219, "eval/post_ent_max": 56.75663757324219, "eval/post_ent_mean": 40.472434997558594, "eval/post_ent_min": 21.468034744262695, "eval/post_ent_std": 6.5771989822387695, "eval/prior_ent_mag": 70.56683349609375, "eval/prior_ent_max": 70.56683349609375, "eval/prior_ent_mean": 55.736724853515625, "eval/prior_ent_min": 43.14592742919922, "eval/prior_ent_std": 4.235217571258545, "eval/rep_loss_mean": 17.204952239990234, "eval/rep_loss_std": 10.025214195251465, "eval/reward_avg": 0.03203124925494194, "eval/reward_loss_mean": 0.11922004818916321, "eval/reward_loss_std": 0.7592674493789673, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.003589153289795, "eval/reward_neg_acc": 0.9898989200592041, "eval/reward_neg_loss": 0.04600907862186432, "eval/reward_pos_acc": 0.7647058963775635, "eval/reward_pos_loss": 2.250951051712036, "eval/reward_pred": 0.02986345998942852, "eval/reward_rate": 0.033203125, "replay/size": 478481.0, "replay/inserts": 22064.0, "replay/samples": 22064.0, "replay/insert_wait_avg": 1.4437053236432315e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.066908146869972e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5088.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2775637068838443e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2501909732819, "timer/env.step_count": 2758.0, "timer/env.step_total": 245.39771366119385, "timer/env.step_frac": 0.2453363327253279, "timer/env.step_avg": 0.08897669095764824, "timer/env.step_min": 0.02327132225036621, "timer/env.step_max": 1.8451364040374756, "timer/replay._sample_count": 22064.0, "timer/replay._sample_total": 11.83443546295166, "timer/replay._sample_frac": 0.01183147533462233, "timer/replay._sample_avg": 0.0005363685398364603, "timer/replay._sample_min": 0.00040721893310546875, "timer/replay._sample_max": 0.011294841766357422, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3394.0, "timer/agent.policy_total": 59.03785514831543, "timer/agent.policy_frac": 0.05902308810445647, "timer/agent.policy_avg": 0.017394771699562588, "timer/agent.policy_min": 0.009507417678833008, "timer/agent.policy_max": 0.19404864311218262, "timer/dataset_train_count": 1379.0, "timer/dataset_train_total": 0.15800929069519043, "timer/dataset_train_frac": 0.0001579697680851641, "timer/dataset_train_avg": 0.00011458251682029763, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.0009033679962158203, "timer/agent.train_count": 1379.0, "timer/agent.train_total": 622.3592813014984, "timer/agent.train_frac": 0.6222036115743391, "timer/agent.train_avg": 0.4513120241490199, "timer/agent.train_min": 0.43680858612060547, "timer/agent.train_max": 1.7158362865447998, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4776875972747803, "timer/agent.report_frac": 0.00047756811404351936, "timer/agent.report_avg": 0.23884379863739014, "timer/agent.report_min": 0.23210597038269043, "timer/agent.report_max": 0.24558162689208984, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.0742416381835938e-05, "timer/dataset_eval_frac": 2.073722811455079e-08, "timer/dataset_eval_avg": 2.0742416381835938e-05, "timer/dataset_eval_min": 2.0742416381835938e-05, "timer/dataset_eval_max": 2.0742416381835938e-05, "fps": 22.058149749655446}
{"step": 479160, "time": 22364.01293373108, "episode/length": 219.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 479880, "time": 22390.178376436234, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 479880, "time": 22390.18752861023, "episode/length": 241.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 480032, "time": 22399.04819893837, "episode/length": 194.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 480048, "time": 22401.177946329117, "episode/length": 136.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 22419.463977575302, "eval_episode/length": 54.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 480064, "time": 22423.832920074463, "eval_episode/length": 117.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9915254237288136}
{"step": 480064, "time": 22428.22090792656, "eval_episode/length": 176.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 480064, "time": 22430.346055984497, "eval_episode/length": 187.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 480064, "time": 22432.602214813232, "eval_episode/length": 204.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9804878048780488}
{"step": 480064, "time": 22434.621077775955, "eval_episode/length": 212.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 480064, "time": 22439.30860877037, "eval_episode/length": 48.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 480064, "time": 22445.085982084274, "eval_episode/length": 334.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9970149253731343}
{"step": 480112, "time": 22446.7355697155, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 480592, "time": 22464.73145198822, "episode/length": 292.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9692832764505119, "episode/intrinsic_return": 0.0}
{"step": 480864, "time": 22475.41651535034, "episode/length": 212.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 481456, "time": 22496.99483036995, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 481528, "time": 22500.711797952652, "episode/length": 205.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 481680, "time": 22507.66676068306, "episode/length": 395.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 482064, "time": 22522.272832393646, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 482576, "time": 22541.134903907776, "episode/length": 213.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 482720, "time": 22547.808740377426, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 482904, "time": 22555.400580644608, "episode/length": 171.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 483224, "time": 22567.707530021667, "episode/length": 396.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9949622166246851, "episode/intrinsic_return": 0.0}
{"step": 483312, "time": 22572.594695568085, "episode/length": 428.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 483320, "time": 22574.380037546158, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 483768, "time": 22592.796142578125, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 483928, "time": 22599.790471553802, "episode/length": 168.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 484320, "time": 22614.937531471252, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 484624, "time": 22626.874011039734, "episode/length": 237.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 484760, "time": 22632.861632823944, "episode/length": 179.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 484792, "time": 22635.504657030106, "episode/length": 195.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 486088, "time": 22680.991716623306, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 486160, "time": 22685.344685792923, "episode/length": 191.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 486160, "time": 22685.35539507866, "episode/length": 298.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.0}
{"step": 487144, "time": 22721.989012002945, "episode/length": 352.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9801699716713881, "episode/intrinsic_return": 0.0}
{"step": 487376, "time": 22731.67574429512, "episode/length": 907.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.998898678414097, "episode/intrinsic_return": 0.0}
{"step": 487488, "time": 22737.22757577896, "episode/length": 444.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9797752808988764, "episode/intrinsic_return": 0.0}
{"step": 487760, "time": 22747.89893603325, "episode/length": 199.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 488168, "time": 22763.193907499313, "episode/length": 421.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 488576, "time": 22778.760297060013, "episode/length": 301.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9867549668874173, "episode/intrinsic_return": 0.0}
{"step": 488864, "time": 22790.21165394783, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 488904, "time": 22792.908486127853, "episode/length": 176.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 488920, "time": 22794.943744659424, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 489256, "time": 22807.719641447067, "episode/length": 742.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9973082099596231, "episode/intrinsic_return": 0.0}
{"step": 489272, "time": 22809.90824818611, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 489392, "time": 22815.78640961647, "episode/length": 412.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9878934624697336, "episode/intrinsic_return": 0.0}
{"step": 489840, "time": 22832.635334014893, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 490040, "time": 22840.852068424225, "episode/length": 146.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 22858.866150856018, "eval_episode/length": 47.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 490048, "time": 22868.681874275208, "eval_episode/length": 177.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 490048, "time": 22871.092334508896, "eval_episode/length": 192.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 490048, "time": 22873.18861436844, "eval_episode/length": 202.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 490048, "time": 22876.98163461685, "eval_episode/length": 246.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9959514170040485}
{"step": 490048, "time": 22878.647980451584, "eval_episode/length": 247.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9959677419354839}
{"step": 490048, "time": 22880.538339853287, "eval_episode/length": 204.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 490048, "time": 22883.74661588669, "eval_episode/length": 288.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9826989619377162}
{"step": 490288, "time": 22891.858971118927, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 490600, "time": 22903.736435890198, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 490696, "time": 22908.66548848152, "episode/length": 221.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 490800, "time": 22913.96724176407, "episode/length": 190.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 490952, "time": 22920.366473197937, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 491248, "time": 22932.155269145966, "episode/length": 150.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 491368, "time": 22937.77473258972, "episode/length": 190.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9842931937172775, "episode/intrinsic_return": 0.0}
{"step": 491432, "time": 22941.591739177704, "episode/length": 254.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 491776, "time": 22956.64453649521, "episode/length": 185.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 492016, "time": 22966.384654045105, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 492336, "time": 22978.78293943405, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 492424, "time": 22983.20243358612, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 492576, "time": 22991.575259923935, "episode/length": 221.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 492896, "time": 23004.22726750374, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 492912, "time": 23006.384070396423, "episode/length": 207.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9855769230769231, "episode/intrinsic_return": 0.0}
{"step": 493608, "time": 23031.100364923477, "episode/length": 158.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 493856, "time": 23041.164189577103, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 494144, "time": 23052.545108556747, "episode/length": 346.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9827089337175793, "episode/intrinsic_return": 0.0}
{"step": 494264, "time": 23058.110624074936, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 494304, "time": 23061.246690750122, "episode/length": 285.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 494320, "time": 23063.410565137863, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 494320, "time": 23063.419934749603, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 494512, "time": 23073.287925720215, "episode/length": 45.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 495096, "time": 23094.355145215988, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 495336, "time": 23104.09398341179, "episode/length": 215.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 495448, "time": 23109.4175863266, "episode/length": 142.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 495640, "time": 23117.59095954895, "episode/length": 482.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.0}
{"step": 495696, "time": 23121.266335725784, "episode/length": 171.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 496104, "time": 23136.463926792145, "episode/length": 229.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 496592, "time": 23154.883362293243, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 496736, "time": 23161.361746311188, "episode/length": 277.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9856115107913669, "episode/intrinsic_return": 0.0}
{"step": 497072, "time": 23174.36599802971, "episode/length": 178.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 497120, "time": 23177.66069626808, "episode/length": 349.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9828571428571429, "episode/intrinsic_return": 0.0}
{"step": 497216, "time": 23182.41442632675, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 497232, "time": 23184.506715536118, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 497760, "time": 23203.768604040146, "episode/length": 206.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 498000, "time": 23213.42690896988, "episode/length": 362.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 498016, "time": 23215.66468191147, "episode/length": 159.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 498096, "time": 23220.018857717514, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 499032, "time": 23253.29682612419, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 499104, "time": 23257.556525707245, "episode/length": 253.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9724409448818898, "episode/intrinsic_return": 0.0}
{"step": 499224, "time": 23263.003413677216, "episode/length": 152.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 499592, "time": 23277.28445339203, "episode/length": 196.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 499600, "time": 23279.353892326355, "episode/length": 187.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 499616, "time": 23281.421837091446, "episode/length": 297.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 499744, "time": 23288.9132938385, "episode/length": 247.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 23321.001271009445, "eval_episode/length": 174.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 500032, "time": 23323.66588163376, "eval_episode/length": 199.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 500032, "time": 23326.60113978386, "eval_episode/length": 223.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9732142857142857}
{"step": 500032, "time": 23328.230919361115, "eval_episode/length": 224.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9911111111111112}
{"step": 500032, "time": 23333.00641822815, "eval_episode/length": 294.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.976271186440678}
{"step": 500032, "time": 23337.13578724861, "eval_episode/length": 352.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.9943342776203966}
{"step": 500032, "time": 23339.541839838028, "eval_episode/length": 194.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 500032, "time": 23342.261477470398, "eval_episode/length": 195.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 500176, "time": 23347.097764730453, "episode/length": 381.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9973821989528796, "episode/intrinsic_return": 0.0}
{"step": 500336, "time": 23354.096439361572, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 500392, "time": 23357.465493440628, "episode/length": 160.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 500393, "time": 23360.10648584366, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.422651936237077, "train/action_min": 0.0, "train/action_std": 3.272613471611998, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.043165173955765884, "train/actor_opt_grad_steps": 30510.0, "train/actor_opt_loss": -2.5703821924227968, "train/adv_mag": 0.5768288382910248, "train/adv_max": 0.533821874095085, "train/adv_mean": 0.004339707402733555, "train/adv_min": -0.47870312866411713, "train/adv_std": 0.06511450219983445, "train/cont_avg": 0.994852854793233, "train/cont_loss_mean": 0.0002845638011690956, "train/cont_loss_std": 0.008268619864068575, "train/cont_neg_acc": 0.9914682548154484, "train/cont_neg_loss": 0.019546886558545695, "train/cont_pos_acc": 0.9999482739240604, "train/cont_pos_loss": 0.0001943970291301781, "train/cont_pred": 0.9948233643868812, "train/cont_rate": 0.994852854793233, "train/dyn_loss_mean": 13.353117534092494, "train/dyn_loss_std": 9.219675193155618, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9256188022462946, "train/extr_critic_critic_opt_grad_steps": 30510.0, "train/extr_critic_critic_opt_loss": 15980.128619889567, "train/extr_critic_mag": 6.448513683519866, "train/extr_critic_max": 6.448513683519866, "train/extr_critic_mean": 1.5499043769406198, "train/extr_critic_min": -0.19367527782468869, "train/extr_critic_std": 1.442372765756191, "train/extr_return_normed_mag": 1.7360249937028813, "train/extr_return_normed_max": 1.7360249937028813, "train/extr_return_normed_mean": 0.34220139088487267, "train/extr_return_normed_min": -0.11954952961296067, "train/extr_return_normed_std": 0.33125835578692586, "train/extr_return_rate": 0.6962151874725083, "train/extr_return_raw_mag": 7.805407244460027, "train/extr_return_raw_max": 7.805407244460027, "train/extr_return_raw_mean": 1.569344240919988, "train/extr_return_raw_min": -0.4969690216887266, "train/extr_return_raw_std": 1.4822030363226295, "train/extr_reward_mag": 1.0201723109510608, "train/extr_reward_max": 1.0201723109510608, "train/extr_reward_mean": 0.029414857380596317, "train/extr_reward_min": -0.38549769641761494, "train/extr_reward_std": 0.15864832884162888, "train/image_loss_mean": 7.199254118410268, "train/image_loss_std": 11.35456509339182, "train/model_loss_mean": 15.26448229022492, "train/model_loss_std": 15.203081589892395, "train/model_opt_grad_norm": 64.54111935321549, "train/model_opt_grad_steps": 30483.0, "train/model_opt_loss": 14368.218375528666, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 949.2481203007519, "train/policy_entropy_mag": 2.5114809767644206, "train/policy_entropy_max": 2.5114809767644206, "train/policy_entropy_mean": 0.5788290115227377, "train/policy_entropy_min": 0.0793751356633086, "train/policy_entropy_std": 0.6798836947383737, "train/policy_logprob_mag": 7.438383668885195, "train/policy_logprob_max": -0.009455704697428789, "train/policy_logprob_mean": -0.5799660492212253, "train/policy_logprob_min": -7.438383668885195, "train/policy_logprob_std": 1.1138848263518255, "train/policy_randomness_mag": 0.8864425734469765, "train/policy_randomness_max": 0.8864425734469765, "train/policy_randomness_mean": 0.2043012405248513, "train/policy_randomness_min": 0.028015939658857826, "train/policy_randomness_std": 0.23996911013036742, "train/post_ent_mag": 60.07977796855726, "train/post_ent_max": 60.07977796855726, "train/post_ent_mean": 42.45181635806435, "train/post_ent_min": 21.316931487922382, "train/post_ent_std": 7.396994286013725, "train/prior_ent_mag": 70.18508096565877, "train/prior_ent_max": 70.18508096565877, "train/prior_ent_mean": 55.85329744152557, "train/prior_ent_min": 41.863652910505024, "train/prior_ent_std": 4.756899441095223, "train/rep_loss_mean": 13.353117534092494, "train/rep_loss_std": 9.219675193155618, "train/reward_avg": 0.024246651567238615, "train/reward_loss_mean": 0.053073137326348094, "train/reward_loss_std": 0.24927783124428943, "train/reward_max_data": 1.0157894774487144, "train/reward_max_pred": 1.0116915729709137, "train/reward_neg_acc": 0.9936161377376184, "train/reward_neg_loss": 0.029232792927414403, "train/reward_pos_acc": 0.9666296136110348, "train/reward_pos_loss": 0.8565871957549476, "train/reward_pred": 0.023436539666377064, "train/reward_rate": 0.028878348214285716, "train_stats/sum_log_reward": 7.611111217074924, "train_stats/max_log_achievement_collect_coal": 0.14444444444444443, "train_stats/max_log_achievement_collect_drink": 9.5, "train_stats/max_log_achievement_collect_sapling": 2.433333333333333, "train_stats/max_log_achievement_collect_stone": 2.1777777777777776, "train_stats/max_log_achievement_collect_wood": 12.222222222222221, "train_stats/max_log_achievement_defeat_skeleton": 0.044444444444444446, "train_stats/max_log_achievement_defeat_zombie": 0.6444444444444445, "train_stats/max_log_achievement_eat_cow": 0.14444444444444443, "train_stats/max_log_achievement_eat_plant": 0.011111111111111112, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3111111111111111, "train_stats/max_log_achievement_make_wood_sword": 2.188888888888889, "train_stats/max_log_achievement_place_furnace": 0.03333333333333333, "train_stats/max_log_achievement_place_plant": 2.1666666666666665, "train_stats/max_log_achievement_place_stone": 0.022222222222222223, "train_stats/max_log_achievement_place_table": 2.988888888888889, "train_stats/max_log_achievement_wake_up": 1.6444444444444444, "train_stats/mean_log_entropy": 0.5405900826056799, "eval_stats/sum_log_reward": 6.933333496252696, "eval_stats/max_log_achievement_collect_coal": 0.16666666666666666, "eval_stats/max_log_achievement_collect_drink": 6.75, "eval_stats/max_log_achievement_collect_sapling": 2.2916666666666665, "eval_stats/max_log_achievement_collect_stone": 1.375, "eval_stats/max_log_achievement_collect_wood": 11.458333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 0.8333333333333334, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.2083333333333333, "eval_stats/max_log_achievement_make_wood_sword": 2.8333333333333335, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.9583333333333333, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.75, "eval_stats/max_log_achievement_wake_up": 1.0833333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.0004161412944085896, "report/cont_loss_std": 0.013279036618769169, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.07088777422904968, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.878950896156312e-07, "report/cont_pred": 0.9944782853126526, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 11.306961059570312, "report/dyn_loss_std": 9.312488555908203, "report/image_loss_mean": 5.532567501068115, "report/image_loss_std": 8.545154571533203, "report/model_loss_mean": 12.3771333694458, "report/model_loss_std": 12.67044448852539, "report/post_ent_mag": 61.41950225830078, "report/post_ent_max": 61.41950225830078, "report/post_ent_mean": 44.45158767700195, "report/post_ent_min": 21.600614547729492, "report/post_ent_std": 7.774680137634277, "report/prior_ent_mag": 70.54805755615234, "report/prior_ent_max": 70.54805755615234, "report/prior_ent_mean": 56.002952575683594, "report/prior_ent_min": 43.1788215637207, "report/prior_ent_std": 4.7599711418151855, "report/rep_loss_mean": 11.306961059570312, "report/rep_loss_std": 9.312488555908203, "report/reward_avg": 0.021484375, "report/reward_loss_mean": 0.05997274070978165, "report/reward_loss_std": 0.29838553071022034, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0740699768066406, "report/reward_neg_acc": 0.9929719567298889, "report/reward_neg_loss": 0.0401606522500515, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7647172212600708, "report/reward_pred": 0.02316397801041603, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 5.125110874359962e-06, "eval/cont_loss_std": 7.808482041582465e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0004661987768486142, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 3.3169790185638703e-06, "eval/cont_pred": 0.9960923194885254, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.42103385925293, "eval/dyn_loss_std": 10.72481632232666, "eval/image_loss_mean": 17.19430923461914, "eval/image_loss_std": 20.9478816986084, "eval/model_loss_mean": 28.37086296081543, "eval/model_loss_std": 25.347061157226562, "eval/post_ent_mag": 61.18592071533203, "eval/post_ent_max": 61.18592071533203, "eval/post_ent_mean": 40.49296188354492, "eval/post_ent_min": 23.102720260620117, "eval/post_ent_std": 6.990571022033691, "eval/prior_ent_mag": 70.54805755615234, "eval/prior_ent_max": 70.54805755615234, "eval/prior_ent_mean": 56.310997009277344, "eval/prior_ent_min": 45.07036590576172, "eval/prior_ent_std": 4.418128967285156, "eval/rep_loss_mean": 18.42103385925293, "eval/rep_loss_std": 10.72481632232666, "eval/reward_avg": 0.04052734375, "eval/reward_loss_mean": 0.12393002212047577, "eval/reward_loss_std": 0.6855440139770508, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000596046447754, "eval/reward_neg_acc": 0.9877426624298096, "eval/reward_neg_loss": 0.07164980471134186, "eval/reward_pos_acc": 0.9111111164093018, "eval/reward_pos_loss": 1.2613152265548706, "eval/reward_pred": 0.038204967975616455, "eval/reward_rate": 0.0439453125, "replay/size": 499889.0, "replay/inserts": 21408.0, "replay/samples": 21408.0, "replay/insert_wait_avg": 1.423105441579548e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.084473989113208e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 8160.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2872850193696864e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.823469877243, "timer/env.step_count": 2676.0, "timer/env.step_total": 219.81687808036804, "timer/env.step_frac": 0.21941677819476815, "timer/env.step_avg": 0.08214382588952468, "timer/env.step_min": 0.02382659912109375, "timer/env.step_max": 3.504066228866577, "timer/replay._sample_count": 21408.0, "timer/replay._sample_total": 11.515295505523682, "timer/replay._sample_frac": 0.011494335930196057, "timer/replay._sample_avg": 0.0005378968378888118, "timer/replay._sample_min": 0.0004227161407470703, "timer/replay._sample_max": 0.029456138610839844, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3696.0, "timer/agent.policy_total": 64.67706871032715, "timer/agent.policy_frac": 0.0645593466863501, "timer/agent.policy_avg": 0.017499206902144793, "timer/agent.policy_min": 0.009670019149780273, "timer/agent.policy_max": 0.14434385299682617, "timer/dataset_train_count": 1338.0, "timer/dataset_train_total": 0.15241527557373047, "timer/dataset_train_frac": 0.00015213785677471346, "timer/dataset_train_avg": 0.00011391276201325147, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.0009124279022216797, "timer/agent.train_count": 1338.0, "timer/agent.train_total": 606.7190024852753, "timer/agent.train_frac": 0.6056146823547852, "timer/agent.train_avg": 0.45345216927150617, "timer/agent.train_min": 0.4371645450592041, "timer/agent.train_max": 1.8635649681091309, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47989749908447266, "timer/agent.report_frac": 0.0004790240132258792, "timer/agent.report_avg": 0.23994874954223633, "timer/agent.report_min": 0.23168349266052246, "timer/agent.report_max": 0.2482140064239502, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 2.9986062285482166e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 21.368724115686753}
{"step": 500936, "time": 23378.17951774597, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 500936, "time": 23378.186864376068, "episode/length": 166.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 501040, "time": 23385.18008852005, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 501144, "time": 23390.15543293953, "episode/length": 190.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 501216, "time": 23394.436639547348, "episode/length": 248.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 501768, "time": 23414.40337753296, "episode/length": 103.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 501776, "time": 23416.59571456909, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 502120, "time": 23429.579397678375, "episode/length": 215.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 502352, "time": 23439.181610107422, "episode/length": 176.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 502560, "time": 23447.778474330902, "episode/length": 189.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9842105263157894, "episode/intrinsic_return": 0.0}
{"step": 502656, "time": 23452.522471666336, "episode/length": 179.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 502832, "time": 23460.123750925064, "episode/length": 331.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 503056, "time": 23469.246086597443, "episode/length": 238.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 503160, "time": 23474.194339752197, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 503312, "time": 23481.279099702835, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 503592, "time": 23492.07122039795, "episode/length": 183.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 504488, "time": 23524.17218065262, "episode/length": 240.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 504528, "time": 23527.494815587997, "episode/length": 183.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 504560, "time": 23530.223548173904, "episode/length": 237.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 505184, "time": 23553.057233572006, "episode/length": 233.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 505344, "time": 23559.98766350746, "episode/length": 272.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 505688, "time": 23573.147681474686, "episode/length": 261.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9694656488549618, "episode/intrinsic_return": 0.0}
{"step": 505952, "time": 23583.75265455246, "episode/length": 449.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 506040, "time": 23588.10233092308, "episode/length": 400.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 506520, "time": 23605.894215106964, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 506856, "time": 23618.8953769207, "episode/length": 290.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 506896, "time": 23621.995090961456, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 506976, "time": 23626.474665641785, "episode/length": 301.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9834437086092715, "episode/intrinsic_return": 0.0}
{"step": 507136, "time": 23633.429483652115, "episode/length": 330.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9879154078549849, "episode/intrinsic_return": 0.0}
{"step": 507224, "time": 23637.807904720306, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 507416, "time": 23645.825030326843, "episode/length": 54.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 507472, "time": 23649.616844177246, "episode/length": 41.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 507568, "time": 23654.435889482498, "episode/length": 42.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9069767441860465, "episode/intrinsic_return": 0.0}
{"step": 507624, "time": 23657.968594312668, "episode/length": 208.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 507808, "time": 23665.908541679382, "episode/length": 41.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 507888, "time": 23670.275784254074, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 508160, "time": 23682.69635629654, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 508416, "time": 23693.066523313522, "episode/length": 31.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 508504, "time": 23697.407944202423, "episode/length": 247.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 508888, "time": 23711.939944028854, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 509040, "time": 23719.138688325882, "episode/length": 267.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 509128, "time": 23723.570636987686, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 509552, "time": 23739.702261924744, "episode/length": 240.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 509688, "time": 23745.745415449142, "episode/length": 224.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 509880, "time": 23754.061466693878, "episode/length": 288.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757785467128027, "episode/intrinsic_return": 0.0}
{"step": 509960, "time": 23758.261563301086, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 23782.295302391052, "eval_episode/length": 157.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 510016, "time": 23785.050793409348, "eval_episode/length": 183.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 510016, "time": 23786.913334846497, "eval_episode/length": 185.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.978494623655914}
{"step": 510016, "time": 23788.99451160431, "eval_episode/length": 196.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9695431472081218}
{"step": 510016, "time": 23790.76394176483, "eval_episode/length": 200.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 510016, "time": 23794.270087718964, "eval_episode/length": 241.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9834710743801653}
{"step": 510016, "time": 23798.06937265396, "eval_episode/length": 48.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 510016, "time": 23800.18664908409, "eval_episode/length": 302.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9966996699669967}
{"step": 510096, "time": 23802.891849517822, "episode/length": 209.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 510216, "time": 23808.393434286118, "episode/length": 146.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 510360, "time": 23814.89245200157, "episode/length": 59.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 510480, "time": 23820.669850826263, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 510568, "time": 23825.039130449295, "episode/length": 58.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9322033898305084, "episode/intrinsic_return": 0.0}
{"step": 510720, "time": 23832.020893096924, "episode/length": 198.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 510944, "time": 23841.267650604248, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 511456, "time": 23860.160256147385, "episode/length": 186.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 511608, "time": 23866.76738834381, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 511944, "time": 23880.204169750214, "episode/length": 281.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 512080, "time": 23886.62208223343, "episode/length": 214.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 512688, "time": 23908.853006124496, "episode/length": 245.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 512736, "time": 23912.09720492363, "episode/length": 281.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9822695035460993, "episode/intrinsic_return": 0.0}
{"step": 512864, "time": 23918.04047226906, "episode/length": 286.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9825783972125436, "episode/intrinsic_return": 0.0}
{"step": 512928, "time": 23921.771734714508, "episode/length": 247.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 512984, "time": 23924.974586248398, "episode/length": 190.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 513352, "time": 23939.112305164337, "episode/length": 52.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 513496, "time": 23945.567897558212, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 513944, "time": 23962.42254590988, "episode/length": 55.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 514000, "time": 23966.074261665344, "episode/length": 239.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 514008, "time": 23967.887271404266, "episode/length": 164.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 514080, "time": 23972.159716129303, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 514704, "time": 23994.841158866882, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 515024, "time": 24007.144939899445, "episode/length": 426.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9953161592505855, "episode/intrinsic_return": 0.0}
{"step": 515128, "time": 24012.101653814316, "episode/length": 282.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 515144, "time": 24014.298846960068, "episode/length": 269.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 515440, "time": 24026.256591558456, "episode/length": 186.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 515456, "time": 24028.376308202744, "episode/length": 180.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 515928, "time": 24045.625866651535, "episode/length": 152.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 516192, "time": 24058.188569784164, "episode/length": 32.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 516432, "time": 24067.77795290947, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 516568, "time": 24073.726152420044, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9611111111111111, "episode/intrinsic_return": 0.0}
{"step": 516584, "time": 24075.82267689705, "episode/length": 322.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9907120743034056, "episode/intrinsic_return": 0.0}
{"step": 516712, "time": 24081.861840486526, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 517040, "time": 24094.774925231934, "episode/length": 369.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 517128, "time": 24099.12060379982, "episode/length": 210.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 517488, "time": 24113.188334465027, "episode/length": 307.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9805194805194806, "episode/intrinsic_return": 0.0}
{"step": 517880, "time": 24127.946497678757, "episode/length": 161.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 518120, "time": 24138.17207956314, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 518176, "time": 24141.810146331787, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 518712, "time": 24161.305473327637, "episode/length": 314.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9968253968253968, "episode/intrinsic_return": 0.0}
{"step": 518800, "time": 24166.1084523201, "episode/length": 219.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 518816, "time": 24168.42623925209, "episode/length": 165.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 518864, "time": 24171.707728385925, "episode/length": 303.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9835526315789473, "episode/intrinsic_return": 0.0}
{"step": 518976, "time": 24177.06983923912, "episode/length": 230.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 519288, "time": 24188.88966679573, "episode/length": 145.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 519656, "time": 24203.025910139084, "episode/length": 104.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9428571428571428, "episode/intrinsic_return": 0.0}
{"step": 519912, "time": 24213.22106575966, "episode/length": 149.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 519984, "time": 24217.369508743286, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 24236.492779493332, "eval_episode/length": 79.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9875}
{"step": 520000, "time": 24241.013818502426, "eval_episode/length": 141.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 520000, "time": 24244.244074821472, "eval_episode/length": 179.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 520000, "time": 24246.60398697853, "eval_episode/length": 193.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 520000, "time": 24248.467451810837, "eval_episode/length": 195.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 520000, "time": 24253.31094932556, "eval_episode/length": 224.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 520000, "time": 24255.77043247223, "eval_episode/length": 242.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9711934156378601}
{"step": 520000, "time": 24260.157962083817, "eval_episode/length": 298.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9832775919732442}
{"step": 520032, "time": 24261.229367017746, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 520216, "time": 24268.8339908123, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 520592, "time": 24283.255247592926, "episode/length": 162.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 520728, "time": 24289.22369813919, "episode/length": 240.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 521544, "time": 24318.4555683136, "episode/length": 188.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 521672, "time": 24324.328114509583, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 521864, "time": 24332.244708776474, "episode/length": 234.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 521936, "time": 24336.493810415268, "episode/length": 214.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 522096, "time": 24343.54317522049, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 522168, "time": 24347.433539152145, "episode/length": 313.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9808917197452229, "episode/intrinsic_return": 0.0}
{"step": 522280, "time": 24352.664645671844, "episode/length": 210.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 522425, "time": 24360.16314959526, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.38320657481318, "train/action_min": 0.0, "train/action_std": 3.086712578068609, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04217575478327015, "train/actor_opt_grad_steps": 31865.0, "train/actor_opt_loss": -2.5924849279116895, "train/adv_mag": 0.5624497869740361, "train/adv_max": 0.5237913360630256, "train/adv_mean": 0.004059022125707945, "train/adv_min": -0.4371247054010198, "train/adv_std": 0.06307817793086819, "train/cont_avg": 0.9949756567028986, "train/cont_loss_mean": 0.0002942303418690508, "train/cont_loss_std": 0.008663479007013584, "train/cont_neg_acc": 0.9844275226487833, "train/cont_neg_loss": 0.0245799388896611, "train/cont_pos_acc": 0.9999430097531581, "train/cont_pos_loss": 0.00016696285627173222, "train/cont_pred": 0.9949733990689983, "train/cont_rate": 0.9949756567028986, "train/dyn_loss_mean": 13.198785906252654, "train/dyn_loss_std": 9.271522936613664, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8927051381788392, "train/extr_critic_critic_opt_grad_steps": 31865.0, "train/extr_critic_critic_opt_loss": 16051.741026947464, "train/extr_critic_mag": 6.626734975455464, "train/extr_critic_max": 6.626734975455464, "train/extr_critic_mean": 1.6505791484445766, "train/extr_critic_min": -0.19362739117249197, "train/extr_critic_std": 1.490857679342878, "train/extr_return_normed_mag": 1.6724958195202593, "train/extr_return_normed_max": 1.6724958195202593, "train/extr_return_normed_mean": 0.3456370591901351, "train/extr_return_normed_min": -0.12100808622072572, "train/extr_return_normed_std": 0.32847592288601224, "train/extr_return_rate": 0.7141309445318968, "train/extr_return_raw_mag": 7.825471117876578, "train/extr_return_raw_max": 7.825471117876578, "train/extr_return_raw_mean": 1.6694495738416477, "train/extr_return_raw_min": -0.49628842557254044, "train/extr_return_raw_std": 1.5243834943875023, "train/extr_reward_mag": 1.0192840738572937, "train/extr_reward_max": 1.0192840738572937, "train/extr_reward_mean": 0.03047465603204741, "train/extr_reward_min": -0.39358146985371906, "train/extr_reward_std": 0.16187403642612955, "train/image_loss_mean": 6.846009700194649, "train/image_loss_std": 10.84836361028146, "train/model_loss_mean": 14.81841478485992, "train/model_loss_std": 14.76036184421484, "train/model_opt_grad_norm": 58.200222291808196, "train/model_opt_grad_steps": 31837.22463768116, "train/model_opt_loss": 19315.29545261549, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1304.3478260869565, "train/policy_entropy_mag": 2.5037861025851704, "train/policy_entropy_max": 2.5037861025851704, "train/policy_entropy_mean": 0.5658706268970517, "train/policy_entropy_min": 0.07937512217440466, "train/policy_entropy_std": 0.6558335440746252, "train/policy_logprob_mag": 7.438383655271668, "train/policy_logprob_max": -0.009455696133005878, "train/policy_logprob_mean": -0.5656064053376516, "train/policy_logprob_min": -7.438383655271668, "train/policy_logprob_std": 1.1041850201461627, "train/policy_randomness_mag": 0.8837266188600789, "train/policy_randomness_max": 0.8837266188600789, "train/policy_randomness_mean": 0.1997274992906529, "train/policy_randomness_min": 0.02801593492968359, "train/policy_randomness_std": 0.2314804610998734, "train/post_ent_mag": 60.02688095535057, "train/post_ent_max": 60.02688095535057, "train/post_ent_mean": 42.6751284668411, "train/post_ent_min": 21.094740287117336, "train/post_ent_std": 7.44527792930603, "train/prior_ent_mag": 70.32245658100516, "train/prior_ent_max": 70.32245658100516, "train/prior_ent_mean": 55.966895448988765, "train/prior_ent_min": 42.31776085452757, "train/prior_ent_std": 4.676620818566585, "train/rep_loss_mean": 13.198785906252654, "train/rep_loss_std": 9.271522936613664, "train/reward_avg": 0.024404862861864378, "train/reward_loss_mean": 0.05283943646034037, "train/reward_loss_std": 0.2531474677548892, "train/reward_max_data": 1.0181159463481626, "train/reward_max_pred": 1.01047941999159, "train/reward_neg_acc": 0.9942057892896127, "train/reward_neg_loss": 0.028562675344933203, "train/reward_pos_acc": 0.9651914938636448, "train/reward_pos_loss": 0.8659512573394222, "train/reward_pred": 0.023538764235496088, "train/reward_rate": 0.029105808423913044, "train_stats/sum_log_reward": 7.307547288683225, "train_stats/max_log_achievement_collect_coal": 0.16981132075471697, "train_stats/max_log_achievement_collect_drink": 6.056603773584905, "train_stats/max_log_achievement_collect_sapling": 2.0283018867924527, "train_stats/max_log_achievement_collect_stone": 1.990566037735849, "train_stats/max_log_achievement_collect_wood": 11.764150943396226, "train_stats/max_log_achievement_defeat_skeleton": 0.03773584905660377, "train_stats/max_log_achievement_defeat_zombie": 0.5754716981132075, "train_stats/max_log_achievement_eat_cow": 0.1792452830188679, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.292452830188679, "train_stats/max_log_achievement_make_wood_sword": 1.8113207547169812, "train_stats/max_log_achievement_place_furnace": 0.03773584905660377, "train_stats/max_log_achievement_place_plant": 1.8113207547169812, "train_stats/max_log_achievement_place_stone": 0.018867924528301886, "train_stats/max_log_achievement_place_table": 3.0660377358490565, "train_stats/max_log_achievement_wake_up": 1.2641509433962264, "train_stats/mean_log_entropy": 0.5125408864246225, "train_stats/max_log_achievement_make_stone_pickaxe": 0.009708737864077669, "eval_stats/sum_log_reward": 7.8500001430511475, "eval_stats/max_log_achievement_collect_coal": 0.3125, "eval_stats/max_log_achievement_collect_drink": 3.8125, "eval_stats/max_log_achievement_collect_sapling": 2.4375, "eval_stats/max_log_achievement_collect_stone": 3.0625, "eval_stats/max_log_achievement_collect_wood": 12.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.6875, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.4375, "eval_stats/max_log_achievement_make_wood_sword": 1.4375, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 2.3125, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 3.25, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.2362426787149161e-05, "report/cont_loss_std": 0.00038472015876322985, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0025073743890970945, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.199716734845424e-07, "report/cont_pred": 0.9951292872428894, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.134673118591309, "report/dyn_loss_std": 9.765344619750977, "report/image_loss_mean": 7.636117935180664, "report/image_loss_std": 12.68069076538086, "report/model_loss_mean": 15.560966491699219, "report/model_loss_std": 16.809749603271484, "report/post_ent_mag": 59.91530990600586, "report/post_ent_max": 59.91530990600586, "report/post_ent_mean": 42.85767364501953, "report/post_ent_min": 22.449214935302734, "report/post_ent_std": 7.741870880126953, "report/prior_ent_mag": 70.65838623046875, "report/prior_ent_max": 70.65838623046875, "report/prior_ent_mean": 56.10271453857422, "report/prior_ent_min": 42.55030059814453, "report/prior_ent_std": 4.899129867553711, "report/rep_loss_mean": 13.134673118591309, "report/rep_loss_std": 9.765344619750977, "report/reward_avg": 0.02187499962747097, "report/reward_loss_mean": 0.04403112083673477, "report/reward_loss_std": 0.2197805792093277, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018048286437988, "report/reward_neg_acc": 0.9939819574356079, "report/reward_neg_loss": 0.02595428377389908, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7115351557731628, "report/reward_pred": 0.024311795830726624, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 1.2538712326204404e-06, "eval/cont_loss_std": 2.2329008061205968e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00016813060210552067, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.0526050431280964e-07, "eval/cont_pred": 0.993165135383606, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 16.628990173339844, "eval/dyn_loss_std": 10.635515213012695, "eval/image_loss_mean": 11.099407196044922, "eval/image_loss_std": 16.53227424621582, "eval/model_loss_mean": 21.193592071533203, "eval/model_loss_std": 20.549530029296875, "eval/post_ent_mag": 59.45807647705078, "eval/post_ent_max": 59.45807647705078, "eval/post_ent_mean": 42.002586364746094, "eval/post_ent_min": 21.711219787597656, "eval/post_ent_std": 7.291363716125488, "eval/prior_ent_mag": 70.65838623046875, "eval/prior_ent_max": 70.65838623046875, "eval/prior_ent_mean": 56.24069595336914, "eval/prior_ent_min": 43.02544403076172, "eval/prior_ent_std": 4.274595260620117, "eval/rep_loss_mean": 16.628990173339844, "eval/rep_loss_std": 10.635515213012695, "eval/reward_avg": 0.02744140475988388, "eval/reward_loss_mean": 0.11678837239742279, "eval/reward_loss_std": 0.7164601683616638, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.00233793258667, "eval/reward_neg_acc": 0.9888888001441956, "eval/reward_neg_loss": 0.04793408513069153, "eval/reward_pos_acc": 0.7647058963775635, "eval/reward_pos_loss": 2.1216633319854736, "eval/reward_pred": 0.023359831422567368, "eval/reward_rate": 0.033203125, "replay/size": 521921.0, "replay/inserts": 22032.0, "replay/samples": 22032.0, "replay/insert_wait_avg": 1.443205056367097e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.038414570760623e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4816.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2698660657255358e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0498087406158, "timer/env.step_count": 2754.0, "timer/env.step_total": 249.581148147583, "timer/env.step_frac": 0.24956871744407, "timer/env.step_avg": 0.09062496301655157, "timer/env.step_min": 0.024281740188598633, "timer/env.step_max": 3.326688289642334, "timer/replay._sample_count": 22032.0, "timer/replay._sample_total": 11.898707151412964, "timer/replay._sample_frac": 0.011898114521312954, "timer/replay._sample_avg": 0.0005400647762987003, "timer/replay._sample_min": 0.00042700767517089844, "timer/replay._sample_max": 0.011225461959838867, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3356.0, "timer/agent.policy_total": 56.932466983795166, "timer/agent.policy_frac": 0.05692963139055188, "timer/agent.policy_avg": 0.016964382295528952, "timer/agent.policy_min": 0.009486913681030273, "timer/agent.policy_max": 0.07961153984069824, "timer/dataset_train_count": 1377.0, "timer/dataset_train_total": 0.1559293270111084, "timer/dataset_train_frac": 0.00015592156075453235, "timer/dataset_train_avg": 0.00011323843646413101, "timer/dataset_train_min": 9.918212890625e-05, "timer/dataset_train_max": 0.00020122528076171875, "timer/agent.train_count": 1377.0, "timer/agent.train_total": 619.5843999385834, "timer/agent.train_frac": 0.6195535407569742, "timer/agent.train_avg": 0.44995236015873885, "timer/agent.train_min": 0.4379456043243408, "timer/agent.train_max": 1.7480230331420898, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4737842082977295, "timer/agent.report_frac": 0.0004737606108783482, "timer/agent.report_avg": 0.23689210414886475, "timer/agent.report_min": 0.2300405502319336, "timer/agent.report_max": 0.2437436580657959, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9562431341119106e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 22.030599293700206}
{"step": 522568, "time": 24364.810247182846, "episode/length": 585.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9982935153583617, "episode/intrinsic_return": 0.0}
{"step": 523160, "time": 24386.719079971313, "episode/length": 161.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 523312, "time": 24393.684913635254, "episode/length": 92.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.956989247311828, "episode/intrinsic_return": 0.0}
{"step": 523320, "time": 24395.299949407578, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 523440, "time": 24401.127839803696, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 523608, "time": 24408.322240829468, "episode/length": 188.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 523624, "time": 24410.523360729218, "episode/length": 181.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 523672, "time": 24413.76997280121, "episode/length": 265.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 524488, "time": 24444.47529578209, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 524720, "time": 24454.14435005188, "episode/length": 347.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9798850574712644, "episode/intrinsic_return": 0.0}
{"step": 524840, "time": 24459.657254457474, "episode/length": 190.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 524848, "time": 24461.782540798187, "episode/length": 146.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 524848, "time": 24461.790544509888, "episode/length": 152.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 524992, "time": 24470.04902768135, "episode/length": 193.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 525968, "time": 24504.769233942032, "episode/length": 294.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9796610169491525, "episode/intrinsic_return": 0.0}
{"step": 526024, "time": 24508.12789082527, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 526112, "time": 24512.93196129799, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 526120, "time": 24514.67196202278, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 526176, "time": 24518.38717031479, "episode/length": 147.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 526200, "time": 24520.496318101883, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 526480, "time": 24531.85404276848, "episode/length": 394.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9949367088607595, "episode/intrinsic_return": 0.0}
{"step": 527400, "time": 24564.330523490906, "episode/length": 171.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 527472, "time": 24568.582328557968, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 527520, "time": 24571.87344479561, "episode/length": 378.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9894459102902374, "episode/intrinsic_return": 0.0}
{"step": 527856, "time": 24584.72331094742, "episode/length": 206.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 527880, "time": 24587.127987146378, "episode/length": 220.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 527920, "time": 24590.216049194336, "episode/length": 179.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 527944, "time": 24592.34907770157, "episode/length": 246.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.97165991902834, "episode/intrinsic_return": 0.0}
{"step": 528248, "time": 24604.284514904022, "episode/length": 48.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 528416, "time": 24611.65514230728, "episode/length": 286.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9825783972125436, "episode/intrinsic_return": 0.0}
{"step": 528976, "time": 24632.13295698166, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9593908629441624, "episode/intrinsic_return": 0.0}
{"step": 528992, "time": 24634.300148010254, "episode/length": 183.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 529424, "time": 24650.554135084152, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 529624, "time": 24658.678877592087, "episode/length": 268.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 529640, "time": 24660.672356128693, "episode/length": 211.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 529696, "time": 24664.419726133347, "episode/length": 226.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 529952, "time": 24674.48344516754, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 529976, "time": 24676.82922887802, "episode/length": 215.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 24703.616411685944, "eval_episode/length": 173.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 530088, "time": 24705.253432512283, "eval_episode/length": 175.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9602272727272727}
{"step": 530088, "time": 24707.05024623871, "eval_episode/length": 177.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9775280898876404}
{"step": 530088, "time": 24709.80627131462, "eval_episode/length": 203.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 530088, "time": 24711.589009046555, "eval_episode/length": 205.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9660194174757282}
{"step": 530088, "time": 24713.901315927505, "eval_episode/length": 45.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 530088, "time": 24715.564796447754, "eval_episode/length": 227.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9649122807017544}
{"step": 530088, "time": 24721.9806098938, "eval_episode/length": 336.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9821958456973294}
{"step": 530400, "time": 24732.660425662994, "episode/length": 177.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9606741573033708, "episode/intrinsic_return": 0.0}
{"step": 530880, "time": 24750.475498199463, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 531248, "time": 24764.427297353745, "episode/length": 200.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 531344, "time": 24769.44243836403, "episode/length": 173.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 531512, "time": 24776.57232928276, "episode/length": 235.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 531664, "time": 24783.532049179077, "episode/length": 245.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 531728, "time": 24787.39687681198, "episode/length": 341.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9970760233918129, "episode/intrinsic_return": 0.0}
{"step": 531904, "time": 24794.85308098793, "episode/length": 187.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 532264, "time": 24808.537519931793, "episode/length": 285.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 532976, "time": 24836.002109527588, "episode/length": 182.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 533048, "time": 24839.833639383316, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 533152, "time": 24845.33144402504, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 533304, "time": 24851.77128648758, "episode/length": 256.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 533464, "time": 24858.909002542496, "episode/length": 322.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9814241486068112, "episode/intrinsic_return": 0.0}
{"step": 533712, "time": 24869.161833286285, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 534176, "time": 24886.43900322914, "episode/length": 313.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9872611464968153, "episode/intrinsic_return": 0.0}
{"step": 534560, "time": 24900.979395627975, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 534792, "time": 24910.142946720123, "episode/length": 165.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9819277108433735, "episode/intrinsic_return": 0.0}
{"step": 534856, "time": 24913.906396389008, "episode/length": 225.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 535256, "time": 24929.15465950966, "episode/length": 192.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 535376, "time": 24935.02534031868, "episode/length": 433.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9792626728110599, "episode/intrinsic_return": 0.0}
{"step": 535448, "time": 24938.85813331604, "episode/length": 267.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 535672, "time": 24948.216059684753, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 535720, "time": 24951.320621967316, "episode/length": 320.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 536456, "time": 24977.789687871933, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 536792, "time": 24990.598911762238, "episode/length": 167.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 536928, "time": 24997.025635004044, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 537136, "time": 25005.648013830185, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 537680, "time": 25025.64935851097, "episode/length": 302.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 537976, "time": 25037.15042924881, "episode/length": 389.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9974358974358974, "episode/intrinsic_return": 0.0}
{"step": 538360, "time": 25051.802234888077, "episode/length": 237.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 538384, "time": 25054.510671138763, "episode/length": 375.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 538664, "time": 25065.26032614708, "episode/length": 233.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 538792, "time": 25071.301500558853, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 538840, "time": 25074.502260684967, "episode/length": 144.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 539192, "time": 25087.980756282806, "episode/length": 578.0, "episode/score": 11.100000038743019, "episode/reward_rate": 0.9879101899827288, "episode/intrinsic_return": 0.0}
{"step": 539216, "time": 25090.609002113342, "episode/length": 154.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 539304, "time": 25094.953543901443, "episode/length": 296.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9865319865319865, "episode/intrinsic_return": 0.0}
{"step": 539968, "time": 25119.21678519249, "episode/length": 197.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 25144.883673667908, "eval_episode/length": 168.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 540072, "time": 25144.890853405, "eval_episode/length": 168.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 540072, "time": 25148.34496974945, "eval_episode/length": 169.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 540072, "time": 25150.19974541664, "eval_episode/length": 176.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 540072, "time": 25156.158542394638, "eval_episode/length": 272.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 540072, "time": 25159.2307806015, "eval_episode/length": 304.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9770491803278688}
{"step": 540072, "time": 25161.330659389496, "eval_episode/length": 317.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9874213836477987}
{"step": 540072, "time": 25163.778244256973, "eval_episode/length": 168.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 540184, "time": 25167.56479859352, "episode/length": 227.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 540512, "time": 25180.36180663109, "episode/length": 208.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 540736, "time": 25191.471769809723, "episode/length": 189.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 540768, "time": 25194.150237321854, "episode/length": 262.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9809885931558935, "episode/intrinsic_return": 0.0}
{"step": 540832, "time": 25197.91052055359, "episode/length": 204.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 541496, "time": 25221.558951616287, "episode/length": 337.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.0}
{"step": 541640, "time": 25227.938834905624, "episode/length": 208.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 541896, "time": 25238.118476867676, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 541968, "time": 25242.412453889847, "episode/length": 40.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9024390243902439, "episode/intrinsic_return": 0.0}
{"step": 542352, "time": 25256.97181725502, "episode/length": 380.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.994750656167979, "episode/intrinsic_return": 0.0}
{"step": 542632, "time": 25267.784720897675, "episode/length": 232.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 542856, "time": 25277.07359623909, "episode/length": 252.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 543632, "time": 25305.04635477066, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.95625, "episode/intrinsic_return": 0.0}
{"step": 543888, "time": 25315.38537812233, "episode/length": 248.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 543912, "time": 25317.580805778503, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 543920, "time": 25319.682141780853, "episode/length": 425.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 544288, "time": 25333.612557649612, "episode/length": 443.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 544536, "time": 25343.397786140442, "episode/length": 209.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 544536, "time": 25343.407876253128, "episode/length": 320.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 544704, "time": 25352.695513248444, "episode/length": 400.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9950124688279302, "episode/intrinsic_return": 0.0}
{"step": 544857, "time": 25360.18522667885, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.351401192801339, "train/action_min": 0.0, "train/action_std": 3.0581355588776726, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04055427057402475, "train/actor_opt_grad_steps": 33255.0, "train/actor_opt_loss": -3.155335594873343, "train/adv_mag": 0.5376806188906942, "train/adv_max": 0.5090379138078008, "train/adv_mean": 0.003675757627726333, "train/adv_min": -0.4209018326231411, "train/adv_std": 0.0611596248245665, "train/cont_avg": 0.9951729910714285, "train/cont_loss_mean": 0.0001394048830419032, "train/cont_loss_std": 0.003933097608247798, "train/cont_neg_acc": 0.9965306133031845, "train/cont_neg_loss": 0.009395423801314402, "train/cont_pos_acc": 0.9999718938555037, "train/cont_pos_loss": 8.77671104207524e-05, "train/cont_pred": 0.9951575990234103, "train/cont_rate": 0.9951729910714285, "train/dyn_loss_mean": 13.307345458439418, "train/dyn_loss_std": 9.257598427363805, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9348527290991374, "train/extr_critic_critic_opt_grad_steps": 33255.0, "train/extr_critic_critic_opt_loss": 16008.320131138393, "train/extr_critic_mag": 6.783865240642003, "train/extr_critic_max": 6.783865240642003, "train/extr_critic_mean": 1.7808872120721, "train/extr_critic_min": -0.19389647926603046, "train/extr_critic_std": 1.534822472504207, "train/extr_return_normed_mag": 1.6571501570088523, "train/extr_return_normed_max": 1.6571501570088523, "train/extr_return_normed_mean": 0.3518994752849851, "train/extr_return_normed_min": -0.12161292561462947, "train/extr_return_normed_std": 0.3241642322923456, "train/extr_return_rate": 0.757866483926773, "train/extr_return_raw_mag": 8.113779619761877, "train/extr_return_raw_max": 8.113779619761877, "train/extr_return_raw_mean": 1.7986343009131296, "train/extr_return_raw_min": -0.49355210747037614, "train/extr_return_raw_std": 1.5689296415873937, "train/extr_reward_mag": 1.0205061197280885, "train/extr_reward_max": 1.0205061197280885, "train/extr_reward_mean": 0.03119897630863956, "train/extr_reward_min": -0.40981149928910393, "train/extr_reward_std": 0.1638952328690461, "train/image_loss_mean": 6.896045865331377, "train/image_loss_std": 10.936135697364808, "train/model_loss_mean": 14.934513228280204, "train/model_loss_std": 14.809571497780937, "train/model_opt_grad_norm": 60.749329389844625, "train/model_opt_grad_steps": 33225.70714285714, "train/model_opt_loss": 18668.141531808036, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.5008072376251222, "train/policy_entropy_max": 2.5008072376251222, "train/policy_entropy_mean": 0.5565703796488898, "train/policy_entropy_min": 0.07937511546271188, "train/policy_entropy_std": 0.6604129669921739, "train/policy_logprob_mag": 7.438383647373745, "train/policy_logprob_max": -0.00945569558202156, "train/policy_logprob_mean": -0.5563131176999637, "train/policy_logprob_min": -7.438383647373745, "train/policy_logprob_std": 1.1035214624234608, "train/policy_randomness_mag": 0.8826752104929515, "train/policy_randomness_max": 0.8826752104929515, "train/policy_randomness_mean": 0.1964449201311384, "train/policy_randomness_min": 0.028015932640326875, "train/policy_randomness_std": 0.2330967961677483, "train/post_ent_mag": 60.26828174591064, "train/post_ent_max": 60.26828174591064, "train/post_ent_mean": 42.76923642839704, "train/post_ent_min": 21.21503061567034, "train/post_ent_std": 7.503975180217198, "train/prior_ent_mag": 70.29400738307407, "train/prior_ent_max": 70.29400738307407, "train/prior_ent_mean": 56.113900784083775, "train/prior_ent_min": 42.19311695098877, "train/prior_ent_std": 4.662583010537284, "train/rep_loss_mean": 13.307345458439418, "train/rep_loss_std": 9.257598427363805, "train/reward_avg": 0.024923269843150464, "train/reward_loss_mean": 0.05392085915165288, "train/reward_loss_std": 0.2542718740446227, "train/reward_max_data": 1.0157142894608633, "train/reward_max_pred": 1.0079552207674298, "train/reward_neg_acc": 0.9929436739001956, "train/reward_neg_loss": 0.029394398243831738, "train/reward_pos_acc": 0.9597528423581805, "train/reward_pos_loss": 0.8718206422669547, "train/reward_pred": 0.024131125205063393, "train/reward_rate": 0.029464285714285714, "train_stats/sum_log_reward": 7.9762888888722845, "train_stats/max_log_achievement_collect_coal": 0.20618556701030927, "train_stats/max_log_achievement_collect_drink": 6.989690721649485, "train_stats/max_log_achievement_collect_sapling": 2.6597938144329896, "train_stats/max_log_achievement_collect_stone": 2.515463917525773, "train_stats/max_log_achievement_collect_wood": 13.958762886597938, "train_stats/max_log_achievement_defeat_skeleton": 0.030927835051546393, "train_stats/max_log_achievement_defeat_zombie": 0.9278350515463918, "train_stats/max_log_achievement_eat_cow": 0.1134020618556701, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.6288659793814433, "train_stats/max_log_achievement_make_wood_sword": 1.6701030927835052, "train_stats/max_log_achievement_place_furnace": 0.08247422680412371, "train_stats/max_log_achievement_place_plant": 2.4742268041237114, "train_stats/max_log_achievement_place_stone": 0.061855670103092786, "train_stats/max_log_achievement_place_table": 3.7422680412371134, "train_stats/max_log_achievement_wake_up": 1.5360824742268042, "train_stats/mean_log_entropy": 0.5040264616614765, "eval_stats/sum_log_reward": 7.350000113248825, "eval_stats/max_log_achievement_collect_coal": 0.1875, "eval_stats/max_log_achievement_collect_drink": 6.125, "eval_stats/max_log_achievement_collect_sapling": 2.3125, "eval_stats/max_log_achievement_collect_stone": 2.625, "eval_stats/max_log_achievement_collect_wood": 12.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.8125, "eval_stats/max_log_achievement_make_wood_sword": 0.8125, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.3125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.0625, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 5.989679630147293e-05, "report/cont_loss_std": 0.0013030701084062457, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004914388991892338, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.862879697815515e-05, "report/cont_pred": 0.9970141649246216, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.430336952209473, "report/dyn_loss_std": 8.865015983581543, "report/image_loss_mean": 6.029982566833496, "report/image_loss_std": 9.383193016052246, "report/model_loss_mean": 13.527776718139648, "report/model_loss_std": 13.0901460647583, "report/post_ent_mag": 57.95552062988281, "report/post_ent_max": 57.95552062988281, "report/post_ent_mean": 43.365142822265625, "report/post_ent_min": 21.00650978088379, "report/post_ent_std": 7.135549068450928, "report/prior_ent_mag": 70.39171600341797, "report/prior_ent_max": 70.39171600341797, "report/prior_ent_mean": 56.106292724609375, "report/prior_ent_min": 44.257965087890625, "report/prior_ent_std": 4.587208271026611, "report/rep_loss_mean": 12.430336952209473, "report/rep_loss_std": 8.865015983581543, "report/reward_avg": 0.02753906324505806, "report/reward_loss_mean": 0.03953137248754501, "report/reward_loss_std": 0.1808881014585495, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.000955581665039, "report/reward_neg_acc": 0.9949647784233093, "report/reward_neg_loss": 0.018009483814239502, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7289261221885681, "report/reward_pred": 0.027739403769373894, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0018114774720743299, "eval/cont_loss_std": 0.05614161118865013, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.02848534658551216, "eval/cont_pos_acc": 0.9990215301513672, "eval/cont_pos_loss": 0.0017592781223356724, "eval/cont_pred": 0.9972850680351257, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 15.783268928527832, "eval/dyn_loss_std": 10.41931438446045, "eval/image_loss_mean": 7.855503082275391, "eval/image_loss_std": 10.391946792602539, "eval/model_loss_mean": 17.40525245666504, "eval/model_loss_std": 15.028986930847168, "eval/post_ent_mag": 62.48224639892578, "eval/post_ent_max": 62.48224639892578, "eval/post_ent_mean": 41.86211395263672, "eval/post_ent_min": 20.92544937133789, "eval/post_ent_std": 6.9847493171691895, "eval/prior_ent_mag": 70.39171600341797, "eval/prior_ent_max": 70.39171600341797, "eval/prior_ent_mean": 55.96518325805664, "eval/prior_ent_min": 39.209320068359375, "eval/prior_ent_std": 4.294301986694336, "eval/rep_loss_mean": 15.783268928527832, "eval/rep_loss_std": 10.41931438446045, "eval/reward_avg": 0.03574218600988388, "eval/reward_loss_mean": 0.07797689735889435, "eval/reward_loss_std": 0.48349469900131226, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.00108003616333, "eval/reward_neg_acc": 0.9939086437225342, "eval/reward_neg_loss": 0.01681443117558956, "eval/reward_pos_acc": 0.8205128312110901, "eval/reward_pos_loss": 1.622721552848816, "eval/reward_pred": 0.026041187345981598, "eval/reward_rate": 0.0380859375, "replay/size": 544353.0, "replay/inserts": 22432.0, "replay/samples": 22432.0, "replay/insert_wait_avg": 1.426865898083348e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.946223537864086e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5400.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2405713399251302e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0019967556, "timer/env.step_count": 2804.0, "timer/env.step_total": 235.84578490257263, "timer/env.step_frac": 0.23584531397712122, "timer/env.step_avg": 0.08411047963715144, "timer/env.step_min": 0.0241546630859375, "timer/env.step_max": 3.450866460800171, "timer/replay._sample_count": 22432.0, "timer/replay._sample_total": 12.043221950531006, "timer/replay._sample_frac": 0.012043197903208151, "timer/replay._sample_avg": 0.0005368768701199628, "timer/replay._sample_min": 0.0004284381866455078, "timer/replay._sample_max": 0.010779619216918945, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3479.0, "timer/agent.policy_total": 59.437628746032715, "timer/agent.policy_frac": 0.059437510063851645, "timer/agent.policy_avg": 0.017084687768333634, "timer/agent.policy_min": 0.00954747200012207, "timer/agent.policy_max": 0.09418153762817383, "timer/dataset_train_count": 1402.0, "timer/dataset_train_total": 0.16115880012512207, "timer/dataset_train_frac": 0.00016115847833102798, "timer/dataset_train_avg": 0.00011494921549580746, "timer/dataset_train_min": 9.918212890625e-05, "timer/dataset_train_max": 0.0008461475372314453, "timer/agent.train_count": 1402.0, "timer/agent.train_total": 631.2947242259979, "timer/agent.train_frac": 0.631293463687239, "timer/agent.train_avg": 0.4502815436704693, "timer/agent.train_min": 0.43735527992248535, "timer/agent.train_max": 1.729090690612793, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47588634490966797, "timer/agent.report_frac": 0.0004758853946828412, "timer/agent.report_avg": 0.23794317245483398, "timer/agent.report_min": 0.23152828216552734, "timer/agent.report_max": 0.24435806274414062, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.7670135498046875e-05, "timer/dataset_eval_frac": 3.7670060280143056e-08, "timer/dataset_eval_avg": 3.7670135498046875e-05, "timer/dataset_eval_min": 3.7670135498046875e-05, "timer/dataset_eval_max": 3.7670135498046875e-05, "fps": 22.431644724331132}
{"step": 545432, "time": 25379.59224653244, "episode/length": 188.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 545520, "time": 25384.497554779053, "episode/length": 235.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 545528, "time": 25386.184730052948, "episode/length": 201.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 545784, "time": 25396.726017951965, "episode/length": 236.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 545968, "time": 25404.843045949936, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 546984, "time": 25441.06204843521, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 547024, "time": 25444.198996305466, "episode/length": 187.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 547064, "time": 25447.026059389114, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 547112, "time": 25450.164693832397, "episode/length": 300.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.973421926910299, "episode/intrinsic_return": 0.0}
{"step": 547576, "time": 25467.474069595337, "episode/length": 379.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 547680, "time": 25472.649320840836, "episode/length": 268.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 547968, "time": 25484.054020881653, "episode/length": 249.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 548256, "time": 25495.434924840927, "episode/length": 464.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9978494623655914, "episode/intrinsic_return": 0.0}
{"step": 548472, "time": 25504.09069252014, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 548560, "time": 25508.873891353607, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 548640, "time": 25513.221774578094, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 548672, "time": 25515.97717809677, "episode/length": 200.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 549184, "time": 25536.573610544205, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 549296, "time": 25541.92188858986, "episode/length": 214.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 549960, "time": 25565.97025346756, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 550056, "time": 25591.453453063965, "eval_episode/length": 166.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 550056, "time": 25594.130975723267, "eval_episode/length": 189.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 550056, "time": 25596.14960861206, "eval_episode/length": 197.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 550056, "time": 25599.362637519836, "eval_episode/length": 233.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9700854700854701}
{"step": 550056, "time": 25601.356731414795, "eval_episode/length": 241.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9958677685950413}
{"step": 550056, "time": 25608.007478952408, "eval_episode/length": 143.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9652777777777778}
{"step": 550056, "time": 25610.194087266922, "eval_episode/length": 324.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9969230769230769}
{"step": 550056, "time": 25612.296693086624, "eval_episode/length": 335.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 550088, "time": 25613.385339975357, "episode/length": 264.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 550160, "time": 25617.74563717842, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 550368, "time": 25626.426785230637, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 550384, "time": 25628.633107423782, "episode/length": 265.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 550616, "time": 25637.991565465927, "episode/length": 246.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 550792, "time": 25645.540125370026, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 551160, "time": 25659.53290462494, "episode/length": 98.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9393939393939394, "episode/intrinsic_return": 0.0}
{"step": 551352, "time": 25667.676475048065, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 551456, "time": 25672.950570821762, "episode/length": 170.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 551712, "time": 25683.051810503006, "episode/length": 315.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9841772151898734, "episode/intrinsic_return": 0.0}
{"step": 551776, "time": 25686.95175552368, "episode/length": 144.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9517241379310345, "episode/intrinsic_return": 0.0}
{"step": 552112, "time": 25699.9957549572, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 552184, "time": 25703.861782073975, "episode/length": 252.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723320158102767, "episode/intrinsic_return": 0.0}
{"step": 552536, "time": 25717.354284763336, "episode/length": 268.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 553024, "time": 25735.955933094025, "episode/length": 195.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 553328, "time": 25748.516885995865, "episode/length": 246.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 553680, "time": 25762.09167790413, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 553680, "time": 25762.100772857666, "episode/length": 314.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 553792, "time": 25769.150925397873, "episode/length": 259.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 553984, "time": 25777.26631784439, "episode/length": 180.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 554000, "time": 25779.3711001873, "episode/length": 235.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 554136, "time": 25785.352612018585, "episode/length": 294.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 554136, "time": 25785.35856962204, "episode/length": 56.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 554392, "time": 25797.36811208725, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 555064, "time": 25821.6796605587, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 555248, "time": 25829.85380911827, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 555472, "time": 25839.092716932297, "episode/length": 185.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 555848, "time": 25853.27690052986, "episode/length": 314.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 555888, "time": 25856.616958379745, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 556232, "time": 25869.523686885834, "episode/length": 261.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 556264, "time": 25872.257623910904, "episode/length": 149.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 556832, "time": 25893.449783802032, "episode/length": 393.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 556840, "time": 25895.164434194565, "episode/length": 305.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9836601307189542, "episode/intrinsic_return": 0.0}
{"step": 556848, "time": 25897.34708547592, "episode/length": 199.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 557616, "time": 25926.94367837906, "episode/length": 220.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 557832, "time": 25935.707545518875, "episode/length": 294.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9864406779661017, "episode/intrinsic_return": 0.0}
{"step": 558128, "time": 25947.716036319733, "episode/length": 236.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 558160, "time": 25950.36485695839, "episode/length": 236.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9704641350210971, "episode/intrinsic_return": 0.0}
{"step": 558232, "time": 25954.280193805695, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 558320, "time": 25959.078466176987, "episode/length": 303.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9901315789473685, "episode/intrinsic_return": 0.0}
{"step": 558816, "time": 25977.549286603928, "episode/length": 246.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 558880, "time": 25981.24203467369, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9556962025316456, "episode/intrinsic_return": 0.0}
{"step": 559552, "time": 26005.652715444565, "episode/length": 214.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 559760, "time": 26014.324148893356, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 26045.437522172928, "eval_episode/length": 156.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 560040, "time": 26047.6062977314, "eval_episode/length": 168.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 560040, "time": 26049.416640758514, "eval_episode/length": 171.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 560040, "time": 26050.93973851204, "eval_episode/length": 172.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 560040, "time": 26053.208508491516, "eval_episode/length": 187.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 560040, "time": 26055.62514424324, "eval_episode/length": 205.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9805825242718447}
{"step": 560040, "time": 26057.878926753998, "eval_episode/length": 217.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9724770642201835}
{"step": 560040, "time": 26063.480852127075, "eval_episode/length": 305.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9967320261437909}
{"step": 560112, "time": 26066.135791778564, "episode/length": 243.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 560208, "time": 26071.058410167694, "episode/length": 235.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 560392, "time": 26078.615705013275, "episode/length": 444.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9910112359550561, "episode/intrinsic_return": 0.0}
{"step": 560448, "time": 26082.392625808716, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 560512, "time": 26086.152183294296, "episode/length": 284.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9964912280701754, "episode/intrinsic_return": 0.0}
{"step": 561168, "time": 26109.75134730339, "episode/length": 293.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9829931972789115, "episode/intrinsic_return": 0.0}
{"step": 561808, "time": 26133.229556798935, "episode/length": 281.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 562104, "time": 26144.69463467598, "episode/length": 206.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 562120, "time": 26146.96957230568, "episode/length": 215.0, "episode/score": 11.100000038743019, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 562152, "time": 26149.603151082993, "episode/length": 254.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 562264, "time": 26154.934532165527, "episode/length": 312.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9840255591054313, "episode/intrinsic_return": 0.0}
{"step": 562904, "time": 26178.2333445549, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 563096, "time": 26186.21687722206, "episode/length": 322.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9969040247678018, "episode/intrinsic_return": 0.0}
{"step": 563136, "time": 26189.324088573456, "episode/length": 365.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9890710382513661, "episode/intrinsic_return": 0.0}
{"step": 563368, "time": 26198.48652791977, "episode/length": 194.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 563432, "time": 26202.24131345749, "episode/length": 163.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 563608, "time": 26209.857368707657, "episode/length": 187.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 563720, "time": 26215.22630429268, "episode/length": 181.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 564288, "time": 26236.227516174316, "episode/length": 266.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 564488, "time": 26244.469745874405, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 564728, "time": 26254.197366952896, "episode/length": 169.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 564936, "time": 26263.0474858284, "episode/length": 151.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 565136, "time": 26271.74590945244, "episode/length": 254.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 565248, "time": 26277.33983039856, "episode/length": 226.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 565312, "time": 26283.100590467453, "episode/length": 212.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 565520, "time": 26291.730127573013, "episode/length": 297.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 566240, "time": 26317.793816804886, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 566240, "time": 26317.803131103516, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 566592, "time": 26333.12896347046, "episode/length": 43.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 566656, "time": 26337.314364910126, "episode/length": 51.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 566704, "time": 26340.521331071854, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 566912, "time": 26349.1289126873, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 567080, "time": 26356.28715801239, "episode/length": 348.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.994269340974212, "episode/intrinsic_return": 0.0}
{"step": 567088, "time": 26358.434779167175, "episode/length": 229.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 567089, "time": 26360.543488502502, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.351133497498876, "train/action_min": 0.0, "train/action_std": 3.1085922563676354, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04048622321846674, "train/actor_opt_grad_steps": 34650.0, "train/actor_opt_loss": -2.4502149246257843, "train/adv_mag": 0.5257005459970707, "train/adv_max": 0.5011503803644249, "train/adv_mean": 0.0037801002146296784, "train/adv_min": -0.3972809903270049, "train/adv_std": 0.05973687743861898, "train/cont_avg": 0.994822111061151, "train/cont_loss_mean": 0.0004377222894450504, "train/cont_loss_std": 0.01326722726830896, "train/cont_neg_acc": 0.9937916963860609, "train/cont_neg_loss": 0.03210859842611303, "train/cont_pos_acc": 0.9999294100905494, "train/cont_pos_loss": 0.000234661476853409, "train/cont_pred": 0.9948082536244564, "train/cont_rate": 0.994822111061151, "train/dyn_loss_mean": 13.069259080955451, "train/dyn_loss_std": 9.316856199031253, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9151447368182725, "train/extr_critic_critic_opt_grad_steps": 34650.0, "train/extr_critic_critic_opt_loss": 15870.262716389389, "train/extr_critic_mag": 6.9438750383665235, "train/extr_critic_max": 6.9438750383665235, "train/extr_critic_mean": 1.9090646248069598, "train/extr_critic_min": -0.19816828803192799, "train/extr_critic_std": 1.6158394367574789, "train/extr_return_normed_mag": 1.636847243892203, "train/extr_return_normed_max": 1.636847243892203, "train/extr_return_normed_mean": 0.36452096668507555, "train/extr_return_normed_min": -0.12113869442142171, "train/extr_return_normed_std": 0.3307863486756524, "train/extr_return_rate": 0.7694432336649448, "train/extr_return_raw_mag": 8.278191813462072, "train/extr_return_raw_max": 8.278191813462072, "train/extr_return_raw_mean": 1.9279008349068731, "train/extr_return_raw_min": -0.4958111622350679, "train/extr_return_raw_std": 1.6510659121780944, "train/extr_reward_mag": 1.018912847093541, "train/extr_reward_max": 1.018912847093541, "train/extr_reward_mean": 0.03360241694416074, "train/extr_reward_min": -0.3869091117982384, "train/extr_reward_std": 0.17114796130348453, "train/image_loss_mean": 6.674661807876697, "train/image_loss_std": 10.943773255931388, "train/model_loss_mean": 14.569153675930105, "train/model_loss_std": 14.841869539494137, "train/model_opt_grad_norm": 58.54441792330296, "train/model_opt_grad_steps": 34619.36690647482, "train/model_opt_loss": 12442.939779816772, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 854.31654676259, "train/policy_entropy_mag": 2.5232600977094912, "train/policy_entropy_max": 2.5232600977094912, "train/policy_entropy_mean": 0.5452278050587331, "train/policy_entropy_min": 0.07937510960179267, "train/policy_entropy_std": 0.6512274131071654, "train/policy_logprob_mag": 7.438383695890578, "train/policy_logprob_max": -0.009455690750008006, "train/policy_logprob_mean": -0.5453224936835199, "train/policy_logprob_min": -7.438383695890578, "train/policy_logprob_std": 1.0990766887184527, "train/policy_randomness_mag": 0.8906000839720527, "train/policy_randomness_max": 0.8906000839720527, "train/policy_randomness_mean": 0.1924414899495008, "train/policy_randomness_min": 0.028015930486990394, "train/policy_randomness_std": 0.22985470037666156, "train/post_ent_mag": 60.73098409090111, "train/post_ent_max": 60.73098409090111, "train/post_ent_mean": 42.988510186723666, "train/post_ent_min": 21.04302319176763, "train/post_ent_std": 7.601612197409431, "train/prior_ent_mag": 70.418264814418, "train/prior_ent_max": 70.418264814418, "train/prior_ent_mean": 56.123757616221475, "train/prior_ent_min": 42.586768143468625, "train/prior_ent_std": 4.695781337271492, "train/rep_loss_mean": 13.069259080955451, "train/rep_loss_std": 9.316856199031253, "train/reward_avg": 0.025323178836901626, "train/reward_loss_mean": 0.052498643119022144, "train/reward_loss_std": 0.24018554260833658, "train/reward_max_data": 1.015107917271072, "train/reward_max_pred": 1.0080933330727995, "train/reward_neg_acc": 0.9936530161246979, "train/reward_neg_loss": 0.028619639196922238, "train/reward_pos_acc": 0.9724644949967912, "train/reward_pos_loss": 0.8293131872904387, "train/reward_pred": 0.024743635307917063, "train/reward_rate": 0.02988702787769784, "train_stats/sum_log_reward": 7.80408174042799, "train_stats/max_log_achievement_collect_coal": 0.1836734693877551, "train_stats/max_log_achievement_collect_drink": 6.224489795918367, "train_stats/max_log_achievement_collect_sapling": 2.7448979591836733, "train_stats/max_log_achievement_collect_stone": 2.7244897959183674, "train_stats/max_log_achievement_collect_wood": 13.173469387755102, "train_stats/max_log_achievement_defeat_skeleton": 0.02040816326530612, "train_stats/max_log_achievement_defeat_zombie": 0.8979591836734694, "train_stats/max_log_achievement_eat_cow": 0.14285714285714285, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.01020408163265306, "train_stats/max_log_achievement_make_wood_pickaxe": 2.663265306122449, "train_stats/max_log_achievement_make_wood_sword": 1.0204081632653061, "train_stats/max_log_achievement_place_furnace": 0.07142857142857142, "train_stats/max_log_achievement_place_plant": 2.673469387755102, "train_stats/max_log_achievement_place_stone": 0.10204081632653061, "train_stats/max_log_achievement_place_table": 3.7346938775510203, "train_stats/max_log_achievement_wake_up": 1.346938775510204, "train_stats/mean_log_entropy": 0.49742939794550134, "train_stats/max_log_achievement_collect_iron": 0.011111111111111112, "eval_stats/sum_log_reward": 7.412500202655792, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.4375, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 3.375, "eval_stats/max_log_achievement_collect_stone": 1.375, "eval_stats/max_log_achievement_collect_wood": 15.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.5625, "eval_stats/max_log_achievement_make_wood_sword": 1.5625, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 3.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 4.375, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.2315222193137743e-05, "report/cont_loss_std": 0.000337353179929778, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00017509772442281246, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.183691892947536e-05, "report/cont_pred": 0.9970591068267822, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 11.753763198852539, "report/dyn_loss_std": 9.877038955688477, "report/image_loss_mean": 7.447429180145264, "report/image_loss_std": 10.663549423217773, "report/model_loss_mean": 14.561217308044434, "report/model_loss_std": 15.088253021240234, "report/post_ent_mag": 60.82472229003906, "report/post_ent_max": 60.82472229003906, "report/post_ent_mean": 44.56342697143555, "report/post_ent_min": 17.179927825927734, "report/post_ent_std": 7.887026309967041, "report/prior_ent_mag": 70.53578186035156, "report/prior_ent_max": 70.53578186035156, "report/prior_ent_mean": 56.66993713378906, "report/prior_ent_min": 42.51388168334961, "report/prior_ent_std": 4.775634765625, "report/rep_loss_mean": 11.753763198852539, "report/rep_loss_std": 9.877038955688477, "report/reward_avg": 0.01845703087747097, "report/reward_loss_mean": 0.0615188404917717, "report/reward_loss_std": 0.3200359046459198, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0224478244781494, "report/reward_neg_acc": 0.9830169677734375, "report/reward_neg_loss": 0.037233706563711166, "report/reward_pos_acc": 0.8695652484893799, "report/reward_pos_loss": 1.1184500455856323, "report/reward_pred": 0.017477693036198616, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 4.150291715632193e-05, "eval/cont_loss_std": 0.000763129792176187, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00023746179067529738, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.03479571104981e-05, "eval/cont_pred": 0.9941022992134094, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 16.278400421142578, "eval/dyn_loss_std": 10.2096586227417, "eval/image_loss_mean": 10.913201332092285, "eval/image_loss_std": 16.121675491333008, "eval/model_loss_mean": 20.77122688293457, "eval/model_loss_std": 20.042213439941406, "eval/post_ent_mag": 63.02141571044922, "eval/post_ent_max": 63.02141571044922, "eval/post_ent_mean": 43.09344482421875, "eval/post_ent_min": 19.186485290527344, "eval/post_ent_std": 7.476712703704834, "eval/prior_ent_mag": 70.53578186035156, "eval/prior_ent_max": 70.53578186035156, "eval/prior_ent_mean": 57.35795593261719, "eval/prior_ent_min": 44.056640625, "eval/prior_ent_std": 4.481551647186279, "eval/rep_loss_mean": 16.278400421142578, "eval/rep_loss_std": 10.2096586227417, "eval/reward_avg": 0.02880859375, "eval/reward_loss_mean": 0.09094303846359253, "eval/reward_loss_std": 0.5089696049690247, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000412940979004, "eval/reward_neg_acc": 0.9959595203399658, "eval/reward_neg_loss": 0.03140745311975479, "eval/reward_pos_acc": 0.7647058963775635, "eval/reward_pos_loss": 1.8244792222976685, "eval/reward_pred": 0.020157240331172943, "eval/reward_rate": 0.033203125, "replay/size": 566585.0, "replay/inserts": 22232.0, "replay/samples": 22224.0, "replay/insert_wait_avg": 1.4566890452996823e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.025340461319003e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5136.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2681305965530539e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2516975402832031e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.344479560852, "timer/env.step_count": 2779.0, "timer/env.step_total": 240.4177827835083, "timer/env.step_frac": 0.24033499229090655, "timer/env.step_avg": 0.0865123363740584, "timer/env.step_min": 0.023899555206298828, "timer/env.step_max": 3.62597918510437, "timer/replay._sample_count": 22224.0, "timer/replay._sample_total": 11.919189214706421, "timer/replay._sample_frac": 0.011915084711557469, "timer/replay._sample_avg": 0.0005363206090130679, "timer/replay._sample_min": 0.0003993511199951172, "timer/replay._sample_max": 0.012861013412475586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3421.0, "timer/agent.policy_total": 60.32772946357727, "timer/agent.policy_frac": 0.0603069549502197, "timer/agent.policy_avg": 0.01763453068213308, "timer/agent.policy_min": 0.00939178466796875, "timer/agent.policy_max": 0.18381261825561523, "timer/dataset_train_count": 1389.0, "timer/dataset_train_total": 0.15926527976989746, "timer/dataset_train_frac": 0.00015921043502915556, "timer/dataset_train_avg": 0.00011466182848804713, "timer/dataset_train_min": 9.965896606445312e-05, "timer/dataset_train_max": 0.0004968643188476562, "timer/agent.train_count": 1389.0, "timer/agent.train_total": 627.0998921394348, "timer/agent.train_frac": 0.6268839434338955, "timer/agent.train_avg": 0.451475804276051, "timer/agent.train_min": 0.43787384033203125, "timer/agent.train_max": 1.705444574356079, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47642970085144043, "timer/agent.report_frac": 0.00047626563707393226, "timer/agent.report_avg": 0.23821485042572021, "timer/agent.report_min": 0.22940993309020996, "timer/agent.report_max": 0.24701976776123047, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.910064697265625e-05, "timer/dataset_eval_frac": 3.9087182237284206e-08, "timer/dataset_eval_avg": 3.910064697265625e-05, "timer/dataset_eval_min": 3.910064697265625e-05, "timer/dataset_eval_max": 3.910064697265625e-05, "fps": 22.224022604537844}
{"step": 567184, "time": 26364.05110144615, "episode/length": 207.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 567592, "time": 26379.128983974457, "episode/length": 50.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 568000, "time": 26394.861678123474, "episode/length": 175.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 568136, "time": 26400.932119607925, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 568200, "time": 26404.7649102211, "episode/length": 192.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 568536, "time": 26417.841208934784, "episode/length": 505.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9881422924901185, "episode/intrinsic_return": 0.0}
{"step": 568784, "time": 26428.10364151001, "episode/length": 211.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 568920, "time": 26434.16212797165, "episode/length": 165.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9819277108433735, "episode/intrinsic_return": 0.0}
{"step": 569168, "time": 26444.32398557663, "episode/length": 281.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9822695035460993, "episode/intrinsic_return": 0.0}
{"step": 569192, "time": 26446.732313871384, "episode/length": 50.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9215686274509803, "episode/intrinsic_return": 0.0}
{"step": 569464, "time": 26457.680303812027, "episode/length": 297.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9832214765100671, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 26497.38577890396, "eval_episode/length": 128.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9534883720930233}
{"step": 570024, "time": 26501.266147613525, "eval_episode/length": 177.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9662921348314607}
{"step": 570024, "time": 26503.493206977844, "eval_episode/length": 190.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 570024, "time": 26505.51022195816, "eval_episode/length": 200.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9701492537313433}
{"step": 570024, "time": 26511.244089126587, "eval_episode/length": 285.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9965034965034965}
{"step": 570024, "time": 26513.326679944992, "eval_episode/length": 297.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9798657718120806}
{"step": 570024, "time": 26515.99302124977, "eval_episode/length": 320.0, "eval_episode/score": 10.099999971687794, "eval_episode/reward_rate": 0.9968847352024922}
{"step": 570024, "time": 26519.60776901245, "eval_episode/length": 362.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9944903581267218}
{"step": 570072, "time": 26521.251893043518, "episode/length": 233.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 570080, "time": 26523.237126111984, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 570336, "time": 26533.48538994789, "episode/length": 142.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 570384, "time": 26536.760026693344, "episode/length": 280.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 570568, "time": 26544.336025953293, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 570584, "time": 26546.48918914795, "episode/length": 176.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 570656, "time": 26550.669011116028, "episode/length": 148.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 570664, "time": 26552.373149871826, "episode/length": 332.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.987987987987988, "episode/intrinsic_return": 0.0}
{"step": 571336, "time": 26576.747551202774, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 571704, "time": 26590.603056669235, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 571992, "time": 26602.087512493134, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 572096, "time": 26607.364055633545, "episode/length": 219.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 572152, "time": 26610.59712910652, "episode/length": 185.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 572176, "time": 26613.211102724075, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 572392, "time": 26621.9260969162, "episode/length": 225.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 572976, "time": 26643.421562433243, "episode/length": 362.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9889807162534435, "episode/intrinsic_return": 0.0}
{"step": 573072, "time": 26648.34267807007, "episode/length": 216.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 573608, "time": 26669.760350465775, "episode/length": 178.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 573688, "time": 26674.215934991837, "episode/length": 247.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 573720, "time": 26676.905057668686, "episode/length": 165.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 573856, "time": 26683.273072957993, "episode/length": 212.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 574216, "time": 26696.922138929367, "episode/length": 264.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 574440, "time": 26706.04807662964, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 574552, "time": 26711.430561065674, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 574832, "time": 26722.742433309555, "episode/length": 48.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 575064, "time": 26731.941860198975, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 575104, "time": 26735.07654428482, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 575192, "time": 26739.481362342834, "episode/length": 166.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 575760, "time": 26760.573325395584, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 576128, "time": 26774.53155684471, "episode/length": 196.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 576136, "time": 26776.370843410492, "episode/length": 517.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9980694980694981, "episode/intrinsic_return": 0.0}
{"step": 576488, "time": 26789.83518385887, "episode/length": 161.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 576496, "time": 26792.034906625748, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 576512, "time": 26794.19798707962, "episode/length": 46.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 576728, "time": 26802.972579479218, "episode/length": 202.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9852216748768473, "episode/intrinsic_return": 0.0}
{"step": 576960, "time": 26812.90452837944, "episode/length": 57.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 577072, "time": 26818.358140707016, "episode/length": 422.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 577224, "time": 26824.910125732422, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 577968, "time": 26851.907586574554, "episode/length": 362.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9944903581267218, "episode/intrinsic_return": 0.0}
{"step": 578016, "time": 26855.195379018784, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 578072, "time": 26858.464227199554, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 578272, "time": 26867.16387820244, "episode/length": 222.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 578424, "time": 26874.17686367035, "episode/length": 182.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 578488, "time": 26877.774104595184, "episode/length": 294.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9898305084745763, "episode/intrinsic_return": 0.0}
{"step": 578856, "time": 26891.90379357338, "episode/length": 222.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 578880, "time": 26894.556574106216, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 579184, "time": 26906.58909726143, "episode/length": 151.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 579400, "time": 26915.206625699997, "episode/length": 140.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.950354609929078, "episode/intrinsic_return": 0.0}
{"step": 579552, "time": 26922.23655962944, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 579832, "time": 26933.18035387993, "episode/length": 226.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 579848, "time": 26935.404769420624, "episode/length": 120.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 26962.539246320724, "eval_episode/length": 143.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 580008, "time": 26965.89904689789, "eval_episode/length": 181.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.967032967032967}
{"step": 580008, "time": 26967.615747451782, "eval_episode/length": 182.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 580008, "time": 26969.600551366806, "eval_episode/length": 191.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 580008, "time": 26971.525273799896, "eval_episode/length": 199.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.97}
{"step": 580008, "time": 26973.677145957947, "eval_episode/length": 208.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9712918660287081}
{"step": 580008, "time": 26975.668855905533, "eval_episode/length": 217.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 580008, "time": 26980.022217988968, "eval_episode/length": 268.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9962825278810409}
{"step": 580576, "time": 27000.48586988449, "episode/length": 260.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9808429118773946, "episode/intrinsic_return": 0.0}
{"step": 581216, "time": 27023.671188116074, "episode/length": 253.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 581240, "time": 27025.825135231018, "episode/length": 229.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 581312, "time": 27030.033712387085, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 581512, "time": 27038.03834605217, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 581632, "time": 27044.163591861725, "episode/length": 224.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 582216, "time": 27067.07981801033, "episode/length": 419.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 582472, "time": 27077.504944562912, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704641350210971, "episode/intrinsic_return": 0.0}
{"step": 582600, "time": 27083.44412469864, "episode/length": 47.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 582784, "time": 27091.590093135834, "episode/length": 544.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9944954128440368, "episode/intrinsic_return": 0.0}
{"step": 583272, "time": 27109.586445331573, "episode/length": 253.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 583360, "time": 27114.434099912643, "episode/length": 255.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.98828125, "episode/intrinsic_return": 0.0}
{"step": 583496, "time": 27120.502025604248, "episode/length": 247.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9637096774193549, "episode/intrinsic_return": 0.0}
{"step": 583768, "time": 27131.18498635292, "episode/length": 318.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.987460815047022, "episode/intrinsic_return": 0.0}
{"step": 584056, "time": 27142.819980621338, "episode/length": 181.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 584288, "time": 27152.434649944305, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 584344, "time": 27155.802862405777, "episode/length": 338.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9941002949852508, "episode/intrinsic_return": 0.0}
{"step": 584792, "time": 27172.678372859955, "episode/length": 55.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 584856, "time": 27176.51299905777, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 585560, "time": 27201.828804016113, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 585624, "time": 27205.548097610474, "episode/length": 282.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9787985865724381, "episode/intrinsic_return": 0.0}
{"step": 585696, "time": 27209.8254237175, "episode/length": 402.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9975186104218362, "episode/intrinsic_return": 0.0}
{"step": 586048, "time": 27223.30100083351, "episode/length": 52.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 586288, "time": 27233.027258634567, "episode/length": 249.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 586488, "time": 27241.159009218216, "episode/length": 339.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 586728, "time": 27250.90281510353, "episode/length": 431.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 586808, "time": 27255.261714696884, "episode/length": 243.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9713114754098361, "episode/intrinsic_return": 0.0}
{"step": 586864, "time": 27259.185550928116, "episode/length": 258.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9845559845559846, "episode/intrinsic_return": 0.0}
{"step": 587112, "time": 27268.977531433105, "episode/length": 193.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 587344, "time": 27278.60847568512, "episode/length": 205.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 587536, "time": 27286.98451447487, "episode/length": 155.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 587600, "time": 27290.78350186348, "episode/length": 193.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 588240, "time": 27314.140873670578, "episode/length": 140.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 588240, "time": 27314.15362739563, "episode/length": 171.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 588296, "time": 27319.5290954113, "episode/length": 225.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 588296, "time": 27319.53814125061, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 588432, "time": 27327.828765153885, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 588496, "time": 27331.6773519516, "episode/length": 143.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 588768, "time": 27342.47359895706, "episode/length": 145.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 588776, "time": 27344.042951583862, "episode/length": 154.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 588968, "time": 27352.203157663345, "episode/length": 83.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9404761904761905, "episode/intrinsic_return": 0.0}
{"step": 589145, "time": 27360.781839609146, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.485436923262002, "train/action_min": 0.0, "train/action_std": 3.2567534757697065, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03871829450076473, "train/actor_opt_grad_steps": 36035.0, "train/actor_opt_loss": -5.156688633820285, "train/adv_mag": 0.5309341726959615, "train/adv_max": 0.4924932649170143, "train/adv_mean": 0.002816244443297562, "train/adv_min": -0.39711875047372736, "train/adv_std": 0.05810961254157018, "train/cont_avg": 0.9947421308876812, "train/cont_loss_mean": 0.00031895808254592544, "train/cont_loss_std": 0.00969191704993848, "train/cont_neg_acc": 0.9931677031344261, "train/cont_neg_loss": 0.037396126737460865, "train/cont_pos_acc": 0.9999572038650513, "train/cont_pos_loss": 0.00013311076551423884, "train/cont_pred": 0.9947411171768022, "train/cont_rate": 0.9947421308876812, "train/dyn_loss_mean": 13.164360661437547, "train/dyn_loss_std": 9.33902767430181, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8913610996543497, "train/extr_critic_critic_opt_grad_steps": 36035.0, "train/extr_critic_critic_opt_loss": 15711.466910099638, "train/extr_critic_mag": 7.232776064803635, "train/extr_critic_max": 7.232776064803635, "train/extr_critic_mean": 1.9822600138360176, "train/extr_critic_min": -0.20206806970679242, "train/extr_critic_std": 1.6675320570019707, "train/extr_return_normed_mag": 1.622153670027636, "train/extr_return_normed_max": 1.622153670027636, "train/extr_return_normed_mean": 0.36163166597269586, "train/extr_return_normed_min": -0.12543956616866417, "train/extr_return_normed_std": 0.32752208973186603, "train/extr_return_rate": 0.8009506571983945, "train/extr_return_raw_mag": 8.530321494392727, "train/extr_return_raw_max": 8.530321494392727, "train/extr_return_raw_mean": 1.9968493580818176, "train/extr_return_raw_min": -0.5280883442880451, "train/extr_return_raw_std": 1.6980002660682236, "train/extr_reward_mag": 1.0204900658648948, "train/extr_reward_max": 1.0204900658648948, "train/extr_reward_mean": 0.0340769374743104, "train/extr_reward_min": -0.4199117923128432, "train/extr_reward_std": 0.17149743459362915, "train/image_loss_mean": 6.69468891793403, "train/image_loss_std": 10.932780445485875, "train/model_loss_mean": 14.648102725761524, "train/model_loss_std": 14.87168242274851, "train/model_opt_grad_norm": 59.793202248172484, "train/model_opt_grad_steps": 36003.840579710144, "train/model_opt_loss": 18082.52721283401, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1231.8840579710145, "train/policy_entropy_mag": 2.4694191753000454, "train/policy_entropy_max": 2.4694191753000454, "train/policy_entropy_mean": 0.5633851581293604, "train/policy_entropy_min": 0.07937510257613832, "train/policy_entropy_std": 0.6575206358363663, "train/policy_logprob_mag": 7.4383836967357695, "train/policy_logprob_max": -0.009455679848358252, "train/policy_logprob_mean": -0.5632559806108475, "train/policy_logprob_min": -7.4383836967357695, "train/policy_logprob_std": 1.1065921416317208, "train/policy_randomness_mag": 0.8715966002664705, "train/policy_randomness_max": 0.8715966002664705, "train/policy_randomness_mean": 0.19885023758895154, "train/policy_randomness_min": 0.028015928045994995, "train/policy_randomness_std": 0.23207592888586764, "train/post_ent_mag": 60.4454536990843, "train/post_ent_max": 60.4454536990843, "train/post_ent_mean": 42.94255629829738, "train/post_ent_min": 21.039880393207937, "train/post_ent_std": 7.534898167071135, "train/prior_ent_mag": 70.47757494276848, "train/prior_ent_max": 70.47757494276848, "train/prior_ent_mean": 56.15394257808077, "train/prior_ent_min": 42.59816565029863, "train/prior_ent_std": 4.695247639780459, "train/rep_loss_mean": 13.164360661437547, "train/rep_loss_std": 9.33902767430181, "train/reward_avg": 0.02608200270291148, "train/reward_loss_mean": 0.054478511983609715, "train/reward_loss_std": 0.2486831375222275, "train/reward_max_data": 1.0166666706403096, "train/reward_max_pred": 1.0083701316861138, "train/reward_neg_acc": 0.9934101355248603, "train/reward_neg_loss": 0.029058706939922296, "train/reward_pos_acc": 0.9644995081251946, "train/reward_pos_loss": 0.8615794937679733, "train/reward_pred": 0.025269960637028882, "train/reward_rate": 0.030690953351449276, "train_stats/sum_log_reward": 7.876699230045948, "train_stats/max_log_achievement_collect_coal": 0.23300970873786409, "train_stats/max_log_achievement_collect_drink": 6.165048543689321, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 2.7475728155339807, "train_stats/max_log_achievement_collect_stone": 2.6407766990291264, "train_stats/max_log_achievement_collect_wood": 12.990291262135923, "train_stats/max_log_achievement_defeat_skeleton": 0.02912621359223301, "train_stats/max_log_achievement_defeat_zombie": 0.8349514563106796, "train_stats/max_log_achievement_eat_cow": 0.1553398058252427, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.019417475728155338, "train_stats/max_log_achievement_make_wood_pickaxe": 1.9029126213592233, "train_stats/max_log_achievement_make_wood_sword": 1.7281553398058251, "train_stats/max_log_achievement_place_furnace": 0.11650485436893204, "train_stats/max_log_achievement_place_plant": 2.6601941747572817, "train_stats/max_log_achievement_place_stone": 0.10679611650485436, "train_stats/max_log_achievement_place_table": 3.650485436893204, "train_stats/max_log_achievement_wake_up": 1.2718446601941749, "train_stats/mean_log_entropy": 0.487903969669805, "eval_stats/sum_log_reward": 7.912500262260437, "eval_stats/max_log_achievement_collect_coal": 0.1875, "eval_stats/max_log_achievement_collect_drink": 5.6875, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 3.0625, "eval_stats/max_log_achievement_collect_stone": 1.75, "eval_stats/max_log_achievement_collect_wood": 10.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.8125, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.6875, "eval_stats/max_log_achievement_make_wood_sword": 1.1875, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 3.0625, "eval_stats/max_log_achievement_place_stone": 0.25, "eval_stats/max_log_achievement_place_table": 3.3125, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.011235955056179775, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 4.582512701745145e-06, "report/cont_loss_std": 7.897371688159183e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0006847959011793137, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.915009079311858e-06, "report/cont_pred": 0.9960945844650269, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 14.531501770019531, "report/dyn_loss_std": 9.329402923583984, "report/image_loss_mean": 6.701600074768066, "report/image_loss_std": 11.631233215332031, "report/model_loss_mean": 15.468816757202148, "report/model_loss_std": 15.512778282165527, "report/post_ent_mag": 57.946136474609375, "report/post_ent_max": 57.946136474609375, "report/post_ent_mean": 41.7576789855957, "report/post_ent_min": 22.765111923217773, "report/post_ent_std": 6.702473163604736, "report/prior_ent_mag": 70.21951293945312, "report/prior_ent_max": 70.21951293945312, "report/prior_ent_mean": 56.6123161315918, "report/prior_ent_min": 42.53721618652344, "report/prior_ent_std": 4.540256500244141, "report/rep_loss_mean": 14.531501770019531, "report/rep_loss_std": 9.329402923583984, "report/reward_avg": 0.02119140699505806, "report/reward_loss_mean": 0.048309922218322754, "report/reward_loss_std": 0.21675123274326324, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0005981922149658, "report/reward_neg_acc": 0.99698805809021, "report/reward_neg_loss": 0.02492164820432663, "report/reward_pos_acc": 0.9642857313156128, "report/reward_pos_loss": 0.8802643418312073, "report/reward_pred": 0.01987399533390999, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.776517137841438e-06, "eval/cont_loss_std": 3.561903940862976e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0005015745991840959, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.0796252303844085e-07, "eval/cont_pred": 0.9970716238021851, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.696884155273438, "eval/dyn_loss_std": 10.996101379394531, "eval/image_loss_mean": 13.729757308959961, "eval/image_loss_std": 19.992904663085938, "eval/model_loss_mean": 23.856477737426758, "eval/model_loss_std": 24.509735107421875, "eval/post_ent_mag": 59.75688552856445, "eval/post_ent_max": 59.75688552856445, "eval/post_ent_mean": 42.388267517089844, "eval/post_ent_min": 19.682146072387695, "eval/post_ent_std": 7.5844855308532715, "eval/prior_ent_mag": 70.21951293945312, "eval/prior_ent_max": 70.21951293945312, "eval/prior_ent_mean": 57.39637756347656, "eval/prior_ent_min": 44.17851257324219, "eval/prior_ent_std": 4.78441047668457, "eval/rep_loss_mean": 16.696884155273438, "eval/rep_loss_std": 10.996101379394531, "eval/reward_avg": 0.03164062649011612, "eval/reward_loss_mean": 0.10858860611915588, "eval/reward_loss_std": 0.6767302751541138, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000624418258667, "eval/reward_neg_acc": 0.9838219285011292, "eval/reward_neg_loss": 0.03196581453084946, "eval/reward_pos_acc": 0.7428571581840515, "eval/reward_pos_loss": 2.2737295627593994, "eval/reward_pred": 0.025491300970315933, "eval/reward_rate": 0.0341796875, "replay/size": 588641.0, "replay/inserts": 22056.0, "replay/samples": 22064.0, "replay/insert_wait_avg": 1.4402510076058615e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.166969606373256e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5056.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2852251529693604e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2249028682709, "timer/env.step_count": 2757.0, "timer/env.step_total": 247.78625535964966, "timer/env.step_frac": 0.24773054005063397, "timer/env.step_avg": 0.08987531931797231, "timer/env.step_min": 0.024464130401611328, "timer/env.step_max": 3.696737051010132, "timer/replay._sample_count": 22064.0, "timer/replay._sample_total": 11.939681768417358, "timer/replay._sample_frac": 0.011936997103530233, "timer/replay._sample_avg": 0.000541138586313332, "timer/replay._sample_min": 0.0004119873046875, "timer/replay._sample_max": 0.009566068649291992, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3389.0, "timer/agent.policy_total": 58.04695415496826, "timer/agent.policy_frac": 0.058033902163914644, "timer/agent.policy_avg": 0.01712804784743826, "timer/agent.policy_min": 0.009495019912719727, "timer/agent.policy_max": 0.12572526931762695, "timer/dataset_train_count": 1379.0, "timer/dataset_train_total": 0.15712499618530273, "timer/dataset_train_frac": 0.00015708966626878316, "timer/dataset_train_avg": 0.00011394125901762344, "timer/dataset_train_min": 9.918212890625e-05, "timer/dataset_train_max": 0.0003566741943359375, "timer/agent.train_count": 1379.0, "timer/agent.train_total": 621.4260528087616, "timer/agent.train_frac": 0.6212863237325367, "timer/agent.train_avg": 0.4506352812246277, "timer/agent.train_min": 0.43726158142089844, "timer/agent.train_max": 1.5981628894805908, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47426867485046387, "timer/agent.report_frac": 0.00047416203444889115, "timer/agent.report_avg": 0.23713433742523193, "timer/agent.report_min": 0.2308340072631836, "timer/agent.report_max": 0.24343466758728027, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 6.341934204101562e-05, "timer/dataset_eval_frac": 6.340508205619824e-08, "timer/dataset_eval_avg": 6.341934204101562e-05, "timer/dataset_eval_min": 6.341934204101562e-05, "timer/dataset_eval_max": 6.341934204101562e-05, "fps": 22.05073874070734}
{"step": 589712, "time": 27380.084842205048, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 590008, "time": 27393.084117412567, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 590064, "time": 27396.914310216904, "episode/length": 160.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 27419.412809610367, "eval_episode/length": 146.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9591836734693877}
{"step": 590096, "time": 27421.92146754265, "eval_episode/length": 165.0, "eval_episode/score": 7.099999964237213, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 590096, "time": 27423.521855831146, "eval_episode/length": 167.0, "eval_episode/score": 8.099999964237213, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 590096, "time": 27426.19061756134, "eval_episode/length": 189.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9789473684210527}
{"step": 590096, "time": 27427.882441997528, "eval_episode/length": 190.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9790575916230366}
{"step": 590096, "time": 27429.817291736603, "eval_episode/length": 198.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 590096, "time": 27432.397655963898, "eval_episode/length": 219.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9681818181818181}
{"step": 590096, "time": 27437.8324508667, "eval_episode/length": 306.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9804560260586319}
{"step": 590104, "time": 27437.88632774353, "episode/length": 166.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 590456, "time": 27451.370370149612, "episode/length": 269.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 591200, "time": 27478.58884358406, "episode/length": 185.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 591296, "time": 27483.43932247162, "episode/length": 349.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9885714285714285, "episode/intrinsic_return": 0.0}
{"step": 591600, "time": 27495.338131666183, "episode/length": 198.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 591600, "time": 27495.345480680466, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 591904, "time": 27509.19818329811, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 592184, "time": 27519.99799656868, "episode/length": 401.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 592536, "time": 27533.52721476555, "episode/length": 166.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 592880, "time": 27546.943908691406, "episode/length": 555.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 592928, "time": 27550.275698661804, "episode/length": 352.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9858356940509915, "episode/intrinsic_return": 0.0}
{"step": 593120, "time": 27558.496517658234, "episode/length": 189.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 593200, "time": 27562.836634635925, "episode/length": 237.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 593264, "time": 27566.72311091423, "episode/length": 169.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 593384, "time": 27572.115367412567, "episode/length": 222.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 593688, "time": 27583.994515180588, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 594224, "time": 27604.000527381897, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 594576, "time": 27617.524935007095, "episode/length": 254.0, "episode/score": 9.100000038743019, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 594648, "time": 27621.322474956512, "episode/length": 190.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 594704, "time": 27625.10453057289, "episode/length": 221.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 594920, "time": 27633.71856188774, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 595752, "time": 27665.120262622833, "episode/length": 257.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 595984, "time": 27674.959574460983, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 596040, "time": 27678.427097082138, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 596120, "time": 27682.67582964897, "episode/length": 176.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 596288, "time": 27690.095009803772, "episode/length": 362.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 596600, "time": 27701.974283218384, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 597208, "time": 27724.119887828827, "episode/length": 114.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 597296, "time": 27728.97487783432, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 597368, "time": 27732.750400304794, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 597624, "time": 27743.198147535324, "episode/length": 424.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9788235294117648, "episode/intrinsic_return": 0.0}
{"step": 597896, "time": 27754.042384147644, "episode/length": 231.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 598280, "time": 27770.408719539642, "episode/length": 634.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9968503937007874, "episode/intrinsic_return": 0.0}
{"step": 598616, "time": 27783.36412191391, "episode/length": 251.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 598632, "time": 27785.489051103592, "episode/length": 157.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 598760, "time": 27791.3918299675, "episode/length": 193.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9845360824742269, "episode/intrinsic_return": 0.0}
{"step": 598888, "time": 27797.480982780457, "episode/length": 345.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9884393063583815, "episode/intrinsic_return": 0.0}
{"step": 599632, "time": 27824.360785722733, "episode/length": 291.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9828767123287672, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 27859.883549928665, "eval_episode/length": 115.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9913793103448276}
{"step": 600080, "time": 27863.38025856018, "eval_episode/length": 157.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 600080, "time": 27865.861692905426, "eval_episode/length": 178.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 600080, "time": 27869.462725400925, "eval_episode/length": 222.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9820627802690582}
{"step": 600080, "time": 27871.71872806549, "eval_episode/length": 57.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 600080, "time": 27873.698006153107, "eval_episode/length": 245.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9959349593495935}
{"step": 600080, "time": 27876.32033753395, "eval_episode/length": 269.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 600080, "time": 27879.4272005558, "eval_episode/length": 56.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 600416, "time": 27890.940857887268, "episode/length": 224.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9644444444444444, "episode/intrinsic_return": 0.0}
{"step": 601024, "time": 27912.973274469376, "episode/length": 282.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9787985865724381, "episode/intrinsic_return": 0.0}
{"step": 601040, "time": 27915.075825214386, "episode/length": 392.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9974554707379135, "episode/intrinsic_return": 0.0}
{"step": 601048, "time": 27916.76873755455, "episode/length": 176.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 601160, "time": 27922.103845119476, "episode/length": 283.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9823943661971831, "episode/intrinsic_return": 0.0}
{"step": 601192, "time": 27924.677531719208, "episode/length": 363.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9972527472527473, "episode/intrinsic_return": 0.0}
{"step": 601416, "time": 27933.80608201027, "episode/length": 473.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 601592, "time": 27941.20174598694, "episode/length": 53.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 601784, "time": 27949.249328374863, "episode/length": 45.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 601792, "time": 27951.33003425598, "episode/length": 394.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9949367088607595, "episode/intrinsic_return": 0.0}
{"step": 602952, "time": 27992.087030410767, "episode/length": 237.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9663865546218487, "episode/intrinsic_return": 0.0}
{"step": 602976, "time": 27994.631270885468, "episode/length": 319.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 603120, "time": 28001.15350675583, "episode/length": 166.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 603128, "time": 28002.85398864746, "episode/length": 241.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 603536, "time": 28018.513310194016, "episode/length": 311.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 603808, "time": 28029.416821479797, "episode/length": 276.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 604336, "time": 28048.96722126007, "episode/length": 413.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 604408, "time": 28052.717965364456, "episode/length": 181.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 604488, "time": 28056.967109918594, "episode/length": 336.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9970326409495549, "episode/intrinsic_return": 0.0}
{"step": 604736, "time": 28067.218321323395, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 604760, "time": 28069.38315629959, "episode/length": 203.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 604792, "time": 28071.951121091843, "episode/length": 47.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 604984, "time": 28080.04163956642, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 605512, "time": 28099.67828154564, "episode/length": 96.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 605600, "time": 28104.52367925644, "episode/length": 309.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9870967741935484, "episode/intrinsic_return": 0.0}
{"step": 605920, "time": 28117.07508277893, "episode/length": 263.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.0}
{"step": 606048, "time": 28123.064617872238, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 606120, "time": 28126.944126844406, "episode/length": 203.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 606296, "time": 28136.33745455742, "episode/length": 163.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 606464, "time": 28143.819328784943, "episode/length": 42.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 606488, "time": 28146.028307437897, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 606696, "time": 28154.52701497078, "episode/length": 237.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 606848, "time": 28161.602111577988, "episode/length": 44.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 606952, "time": 28166.482328653336, "episode/length": 168.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 607192, "time": 28176.1780128479, "episode/length": 158.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 607208, "time": 28178.226888418198, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 608288, "time": 28216.522206544876, "episode/length": 227.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 608312, "time": 28218.769790172577, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 608808, "time": 28237.11519932747, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 608888, "time": 28241.36930012703, "episode/length": 323.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 609264, "time": 28255.94694495201, "episode/length": 256.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 609304, "time": 28258.567971229553, "episode/length": 51.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 609392, "time": 28263.428488492966, "episode/length": 417.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 609576, "time": 28270.949716567993, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 609672, "time": 28275.623205184937, "episode/length": 45.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 28306.917338848114, "eval_episode/length": 60.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 610064, "time": 28310.998854875565, "eval_episode/length": 115.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9913793103448276}
{"step": 610064, "time": 28314.014505147934, "eval_episode/length": 148.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 610064, "time": 28316.979989528656, "eval_episode/length": 179.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 610064, "time": 28319.39382123947, "eval_episode/length": 195.0, "eval_episode/score": 7.1000000312924385, "eval_episode/reward_rate": 0.9897959183673469}
{"step": 610064, "time": 28321.34144091606, "eval_episode/length": 203.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 610064, "time": 28324.18226480484, "eval_episode/length": 230.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9783549783549783}
{"step": 610064, "time": 28327.003108024597, "eval_episode/length": 62.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 610120, "time": 28328.661511659622, "episode/length": 427.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 610952, "time": 28358.527395248413, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 610953, "time": 28361.21376681328, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.3968510347254135, "train/action_min": 0.0, "train/action_std": 3.1740769235526813, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03957316638244426, "train/actor_opt_grad_steps": 37405.0, "train/actor_opt_loss": 4.083293546867721, "train/adv_mag": 0.5376339276485583, "train/adv_max": 0.49990348254933076, "train/adv_mean": 0.004354887926972558, "train/adv_min": -0.4033992744105704, "train/adv_std": 0.058663111864863074, "train/cont_avg": 0.9951602711397058, "train/cont_loss_mean": 0.0002140277551393912, "train/cont_loss_std": 0.0065035609058203565, "train/cont_neg_acc": 0.9954320991480792, "train/cont_neg_loss": 0.018580505206382776, "train/cont_pos_acc": 0.9999566621640149, "train/cont_pos_loss": 0.0001348600267062954, "train/cont_pred": 0.9951359314077041, "train/cont_rate": 0.9951602711397058, "train/dyn_loss_mean": 13.0242759550319, "train/dyn_loss_std": 9.338166075594286, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9805075320250848, "train/extr_critic_critic_opt_grad_steps": 37405.0, "train/extr_critic_critic_opt_loss": 15688.997508329503, "train/extr_critic_mag": 7.42566878304762, "train/extr_critic_max": 7.42566878304762, "train/extr_critic_mean": 2.0966144230435875, "train/extr_critic_min": -0.18900207999874563, "train/extr_critic_std": 1.6593292285414303, "train/extr_return_normed_mag": 1.634507195037954, "train/extr_return_normed_max": 1.634507195037954, "train/extr_return_normed_mean": 0.3714913661208223, "train/extr_return_normed_min": -0.1275980485164944, "train/extr_return_normed_std": 0.32285778958569555, "train/extr_return_rate": 0.8374818515251664, "train/extr_return_raw_mag": 8.73888023109997, "train/extr_return_raw_max": 8.73888023109997, "train/extr_return_raw_mean": 2.1193801515242634, "train/extr_return_raw_min": -0.4971030139747788, "train/extr_return_raw_std": 1.6922892971950418, "train/extr_reward_mag": 1.025057654170429, "train/extr_reward_max": 1.025057654170429, "train/extr_reward_mean": 0.035027806667665785, "train/extr_reward_min": -0.42908109899829416, "train/extr_reward_std": 0.1736832519116647, "train/image_loss_mean": 6.644536880885854, "train/image_loss_std": 11.380948659251718, "train/model_loss_mean": 14.51311476090375, "train/model_loss_std": 15.285973520839915, "train/model_opt_grad_norm": 53.85513663115325, "train/model_opt_grad_steps": 37372.57352941176, "train/model_opt_loss": 18272.383372587316, "train/model_opt_model_opt_grad_overflow": 0.007352941176470588, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.47746203752125, "train/policy_entropy_max": 2.47746203752125, "train/policy_entropy_mean": 0.5876783255268546, "train/policy_entropy_min": 0.07937511095010183, "train/policy_entropy_std": 0.6586773020817953, "train/policy_logprob_mag": 7.43838363535264, "train/policy_logprob_max": -0.009455691482050015, "train/policy_logprob_mean": -0.5871397289721405, "train/policy_logprob_min": -7.43838363535264, "train/policy_logprob_std": 1.1218703674042927, "train/policy_randomness_mag": 0.8744353801012039, "train/policy_randomness_max": 0.8744353801012039, "train/policy_randomness_mean": 0.20742466026807532, "train/policy_randomness_min": 0.028015930958859184, "train/policy_randomness_std": 0.23248418289072373, "train/post_ent_mag": 60.36121340358959, "train/post_ent_max": 60.36121340358959, "train/post_ent_mean": 43.13845037011539, "train/post_ent_min": 21.200562042348526, "train/post_ent_std": 7.519630726645975, "train/prior_ent_mag": 70.60673640756046, "train/prior_ent_max": 70.60673640756046, "train/prior_ent_mean": 56.23461339052986, "train/prior_ent_min": 42.52472793354708, "train/prior_ent_std": 4.679865293643054, "train/rep_loss_mean": 13.0242759550319, "train/rep_loss_std": 9.338166075594286, "train/reward_avg": 0.02635928861084668, "train/reward_loss_mean": 0.05379840909667751, "train/reward_loss_std": 0.24579400832162185, "train/reward_max_data": 1.017647063030916, "train/reward_max_pred": 1.009787934667924, "train/reward_neg_acc": 0.993242876494632, "train/reward_neg_loss": 0.028550774180878175, "train/reward_pos_acc": 0.9654200335635859, "train/reward_pos_loss": 0.8526333382024485, "train/reward_pred": 0.025622834759654805, "train/reward_rate": 0.03068991268382353, "train_stats/sum_log_reward": 8.179545636881482, "train_stats/max_log_achievement_collect_coal": 0.3522727272727273, "train_stats/max_log_achievement_collect_drink": 5.840909090909091, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 2.227272727272727, "train_stats/max_log_achievement_collect_stone": 3.602272727272727, "train_stats/max_log_achievement_collect_wood": 12.034090909090908, "train_stats/max_log_achievement_defeat_skeleton": 0.045454545454545456, "train_stats/max_log_achievement_defeat_zombie": 0.7840909090909091, "train_stats/max_log_achievement_eat_cow": 0.10227272727272728, "train_stats/max_log_achievement_eat_plant": 0.011363636363636364, "train_stats/max_log_achievement_make_stone_pickaxe": 0.03409090909090909, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.034090909090909, "train_stats/max_log_achievement_make_wood_sword": 1.4090909090909092, "train_stats/max_log_achievement_place_furnace": 0.09090909090909091, "train_stats/max_log_achievement_place_plant": 2.1818181818181817, "train_stats/max_log_achievement_place_stone": 1.5568181818181819, "train_stats/max_log_achievement_place_table": 3.3636363636363638, "train_stats/max_log_achievement_wake_up": 1.1931818181818181, "train_stats/mean_log_entropy": 0.5566256855699149, "eval_stats/sum_log_reward": 7.4750001927216845, "eval_stats/max_log_achievement_collect_coal": 0.20833333333333334, "eval_stats/max_log_achievement_collect_drink": 1.9583333333333333, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.6666666666666667, "eval_stats/max_log_achievement_collect_stone": 3.5, "eval_stats/max_log_achievement_collect_wood": 10.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.08333333333333333, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.7083333333333333, "eval_stats/max_log_achievement_make_wood_sword": 1.2083333333333333, "eval_stats/max_log_achievement_place_furnace": 0.20833333333333334, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_stone": 1.0833333333333333, "eval_stats/max_log_achievement_place_table": 2.9583333333333335, "eval_stats/max_log_achievement_wake_up": 0.9583333333333334, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 1.3088565538055263e-06, "report/cont_loss_std": 1.536672789370641e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.2659020285354927e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.2866448741988279e-06, "report/cont_pred": 0.9980456829071045, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 11.579109191894531, "report/dyn_loss_std": 9.208891868591309, "report/image_loss_mean": 5.190737724304199, "report/image_loss_std": 8.864479064941406, "report/model_loss_mean": 12.191862106323242, "report/model_loss_std": 13.05379867553711, "report/post_ent_mag": 61.682762145996094, "report/post_ent_max": 61.682762145996094, "report/post_ent_mean": 43.7403564453125, "report/post_ent_min": 21.866416931152344, "report/post_ent_std": 7.317079544067383, "report/prior_ent_mag": 70.16529083251953, "report/prior_ent_max": 70.16529083251953, "report/prior_ent_mean": 55.72819519042969, "report/prior_ent_min": 43.19330596923828, "report/prior_ent_std": 4.682220458984375, "report/rep_loss_mean": 11.579109191894531, "report/rep_loss_std": 9.208891868591309, "report/reward_avg": 0.03105468675494194, "report/reward_loss_mean": 0.05365705490112305, "report/reward_loss_std": 0.20556555688381195, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0014569759368896, "report/reward_neg_acc": 0.9929150342941284, "report/reward_neg_loss": 0.029342466965317726, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7209574580192566, "report/reward_pred": 0.03155803680419922, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 7.876641575421672e-06, "eval/cont_loss_std": 0.00021023333829361945, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 8.326904207933694e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.874432412791066e-06, "eval/cont_pred": 0.9951094388961792, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 15.796928405761719, "eval/dyn_loss_std": 10.05250358581543, "eval/image_loss_mean": 10.836843490600586, "eval/image_loss_std": 14.162898063659668, "eval/model_loss_mean": 20.380237579345703, "eval/model_loss_std": 18.181331634521484, "eval/post_ent_mag": 59.35786819458008, "eval/post_ent_max": 59.35786819458008, "eval/post_ent_mean": 42.634613037109375, "eval/post_ent_min": 22.018810272216797, "eval/post_ent_std": 7.109486103057861, "eval/prior_ent_mag": 70.16529083251953, "eval/prior_ent_max": 70.16529083251953, "eval/prior_ent_mean": 56.72705078125, "eval/prior_ent_min": 43.5074462890625, "eval/prior_ent_std": 4.381524562835693, "eval/rep_loss_mean": 15.796928405761719, "eval/rep_loss_std": 10.05250358581543, "eval/reward_avg": 0.01728515513241291, "eval/reward_loss_mean": 0.06522959470748901, "eval/reward_loss_std": 0.3886314928531647, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0038385391235352, "eval/reward_neg_acc": 0.9930209517478943, "eval/reward_neg_loss": 0.03326060622930527, "eval/reward_pos_acc": 0.8571428656578064, "eval/reward_pos_loss": 1.5921293497085571, "eval/reward_pred": 0.014376713894307613, "eval/reward_rate": 0.0205078125, "replay/size": 610449.0, "replay/inserts": 21808.0, "replay/samples": 21808.0, "replay/insert_wait_avg": 1.433233697013827e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.087084499423502e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6952.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2741950356644784e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.420027256012, "timer/env.step_count": 2726.0, "timer/env.step_total": 216.98220252990723, "timer/env.step_frac": 0.21689110235533152, "timer/env.step_avg": 0.07959728632791901, "timer/env.step_min": 0.024190902709960938, "timer/env.step_max": 3.5777997970581055, "timer/replay._sample_count": 21808.0, "timer/replay._sample_total": 11.774095058441162, "timer/replay._sample_frac": 0.011769151693949565, "timer/replay._sample_avg": 0.0005398979759006403, "timer/replay._sample_min": 0.00040912628173828125, "timer/replay._sample_max": 0.026009321212768555, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3595.0, "timer/agent.policy_total": 61.28241944313049, "timer/agent.policy_frac": 0.06125668996373265, "timer/agent.policy_avg": 0.017046570081538384, "timer/agent.policy_min": 0.009514570236206055, "timer/agent.policy_max": 0.12463259696960449, "timer/dataset_train_count": 1363.0, "timer/dataset_train_total": 0.15463638305664062, "timer/dataset_train_frac": 0.0001545714588309301, "timer/dataset_train_avg": 0.00011345295895571579, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.0005056858062744141, "timer/agent.train_count": 1363.0, "timer/agent.train_total": 619.0048520565033, "timer/agent.train_frac": 0.618744962307814, "timer/agent.train_avg": 0.454148827627662, "timer/agent.train_min": 0.43961238861083984, "timer/agent.train_max": 2.0782949924468994, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4774489402770996, "timer/agent.report_frac": 0.0004772484829063886, "timer/agent.report_avg": 0.2387244701385498, "timer/agent.report_min": 0.23238086700439453, "timer/agent.report_max": 0.24506807327270508, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.002812833444938e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 21.798523334501205}
{"step": 611104, "time": 28366.478739500046, "episode/length": 286.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9965156794425087, "episode/intrinsic_return": 0.0}
{"step": 611176, "time": 28370.30158495903, "episode/length": 238.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 611240, "time": 28374.042423963547, "episode/length": 207.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 611264, "time": 28376.691128492355, "episode/length": 371.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9865591397849462, "episode/intrinsic_return": 0.0}
{"step": 611336, "time": 28380.57637834549, "episode/length": 207.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 611640, "time": 28392.4876101017, "episode/length": 49.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 611968, "time": 28405.46810221672, "episode/length": 639.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9984375, "episode/intrinsic_return": 0.0}
{"step": 612440, "time": 28422.79161143303, "episode/length": 289.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 612504, "time": 28426.73380589485, "episode/length": 165.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 612832, "time": 28439.693265914917, "episode/length": 195.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 612976, "time": 28446.223694086075, "episode/length": 58.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 613192, "time": 28454.94035935402, "episode/length": 231.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 613416, "time": 28464.319733142853, "episode/length": 307.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9967532467532467, "episode/intrinsic_return": 0.0}
{"step": 613456, "time": 28467.44376039505, "episode/length": 185.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 613800, "time": 28480.451835393906, "episode/length": 336.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9940652818991098, "episode/intrinsic_return": 0.0}
{"step": 614128, "time": 28493.45402288437, "episode/length": 143.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 614224, "time": 28498.313937664032, "episode/length": 222.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 614264, "time": 28501.06737947464, "episode/length": 57.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 614416, "time": 28509.658029317856, "episode/length": 346.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9855907780979827, "episode/intrinsic_return": 0.0}
{"step": 614536, "time": 28515.107244729996, "episode/length": 139.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 614816, "time": 28526.4627263546, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 615056, "time": 28536.179051160812, "episode/length": 232.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 615216, "time": 28543.0758228302, "episode/length": 297.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 615696, "time": 28561.07291650772, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 615824, "time": 28567.02294945717, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 615920, "time": 28571.828808546066, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 615968, "time": 28575.094226121902, "episode/length": 229.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 616536, "time": 28595.933910369873, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 616600, "time": 28599.676269054413, "episode/length": 222.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 617576, "time": 28634.373613595963, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 617672, "time": 28639.354770183563, "episode/length": 306.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9771986970684039, "episode/intrinsic_return": 0.0}
{"step": 617880, "time": 28648.098129987717, "episode/length": 37.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 617976, "time": 28652.919448137283, "episode/length": 429.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 618256, "time": 28664.153685569763, "episode/length": 285.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 618312, "time": 28667.490696668625, "episode/length": 298.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9933110367892977, "episode/intrinsic_return": 0.0}
{"step": 618328, "time": 28669.676443099976, "episode/length": 223.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 619232, "time": 28702.227471351624, "episode/length": 441.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9796380090497737, "episode/intrinsic_return": 0.0}
{"step": 619240, "time": 28704.280968427658, "episode/length": 195.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 619248, "time": 28706.88357067108, "episode/length": 170.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 619752, "time": 28725.364847898483, "episode/length": 64.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 620008, "time": 28736.238619327545, "episode/length": 425.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9976525821596244, "episode/intrinsic_return": 0.0}
{"step": 620008, "time": 28736.247141122818, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 28755.83727836609, "eval_episode/length": 35.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 620048, "time": 28758.459278345108, "eval_episode/length": 52.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 620048, "time": 28767.19414997101, "eval_episode/length": 179.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 620048, "time": 28769.2360329628, "eval_episode/length": 187.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.973404255319149}
{"step": 620048, "time": 28770.84782075882, "eval_episode/length": 190.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 620048, "time": 28774.063641786575, "eval_episode/length": 189.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 620048, "time": 28776.43212246895, "eval_episode/length": 245.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.967479674796748}
{"step": 620048, "time": 28779.635727882385, "eval_episode/length": 276.0, "eval_episode/score": 10.099999971687794, "eval_episode/reward_rate": 0.9963898916967509}
{"step": 620072, "time": 28780.250477552414, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 620120, "time": 28783.895688295364, "episode/length": 267.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9888059701492538, "episode/intrinsic_return": 0.0}
{"step": 620464, "time": 28797.441042900085, "episode/length": 42.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 620824, "time": 28810.997859477997, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 620888, "time": 28814.767684936523, "episode/length": 204.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 621304, "time": 28830.53480386734, "episode/length": 380.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 621568, "time": 28841.361882209778, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 621624, "time": 28844.592497110367, "episode/length": 193.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 621624, "time": 28844.601041793823, "episode/length": 144.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 622192, "time": 28867.67757153511, "episode/length": 272.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 622248, "time": 28870.941210746765, "episode/length": 311.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9839743589743589, "episode/intrinsic_return": 0.0}
{"step": 622800, "time": 28893.34503722191, "episode/length": 238.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 622952, "time": 28900.376470804214, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 623088, "time": 28906.978800058365, "episode/length": 282.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 623608, "time": 28925.953287363052, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 623920, "time": 28938.63064932823, "episode/length": 293.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9829931972789115, "episode/intrinsic_return": 0.0}
{"step": 623936, "time": 28940.794967889786, "episode/length": 288.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9896193771626297, "episode/intrinsic_return": 0.0}
{"step": 624184, "time": 28950.61861538887, "episode/length": 319.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996875, "episode/intrinsic_return": 0.0}
{"step": 624344, "time": 28957.663018226624, "episode/length": 173.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 624584, "time": 28967.40398669243, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 624752, "time": 28974.95966720581, "episode/length": 50.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 625600, "time": 29005.441402435303, "episode/length": 418.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9976133651551312, "episode/intrinsic_return": 0.0}
{"step": 625672, "time": 29009.36365389824, "episode/length": 185.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 625752, "time": 29013.744534492493, "episode/length": 368.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.997289972899729, "episode/intrinsic_return": 0.0}
{"step": 625944, "time": 29021.778660058975, "episode/length": 250.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 626232, "time": 29033.340806484222, "episode/length": 288.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 626336, "time": 29038.72137904167, "episode/length": 48.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 626440, "time": 29043.558207511902, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 626744, "time": 29055.435594320297, "episode/length": 248.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 626856, "time": 29060.90530729294, "episode/length": 156.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 627112, "time": 29071.126351356506, "episode/length": 437.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 627288, "time": 29078.724529504776, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 627832, "time": 29098.789241075516, "episode/length": 186.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 627968, "time": 29105.258435726166, "episode/length": 138.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 628288, "time": 29118.377581357956, "episode/length": 326.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 628592, "time": 29130.33417248726, "episode/length": 268.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9739776951672863, "episode/intrinsic_return": 0.0}
{"step": 628864, "time": 29141.20550608635, "episode/length": 328.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.993920972644377, "episode/intrinsic_return": 0.0}
{"step": 628896, "time": 29143.936628818512, "episode/length": 268.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 628984, "time": 29148.433186769485, "episode/length": 233.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 629040, "time": 29152.19522500038, "episode/length": 218.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 629240, "time": 29160.172543287277, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 629368, "time": 29166.069732427597, "episode/length": 62.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 629640, "time": 29176.97051882744, "episode/length": 49.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 629976, "time": 29189.8076338768, "episode/length": 210.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 29209.08159685135, "eval_episode/length": 48.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.8979591836734694}
{"step": 630032, "time": 29214.896475553513, "eval_episode/length": 144.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 630032, "time": 29217.59389281273, "eval_episode/length": 169.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9764705882352941}
{"step": 630032, "time": 29220.185111284256, "eval_episode/length": 189.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 630032, "time": 29223.23912501335, "eval_episode/length": 221.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 630032, "time": 29226.23473262787, "eval_episode/length": 253.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9724409448818898}
{"step": 630032, "time": 29229.66876578331, "eval_episode/length": 39.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 630032, "time": 29232.675875663757, "eval_episode/length": 324.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9907692307692307}
{"step": 630360, "time": 29243.57241988182, "episode/length": 47.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 630424, "time": 29247.27140402794, "episode/length": 190.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 630496, "time": 29251.478726625443, "episode/length": 181.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 630704, "time": 29260.120119333267, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 630728, "time": 29262.275626897812, "episode/length": 344.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9942028985507246, "episode/intrinsic_return": 0.0}
{"step": 631232, "time": 29282.99298095703, "episode/length": 329.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 631464, "time": 29292.140974998474, "episode/length": 91.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9891304347826086, "episode/intrinsic_return": 0.0}
{"step": 631536, "time": 29296.510061264038, "episode/length": 146.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 631888, "time": 29310.048244714737, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 632000, "time": 29315.406722784042, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 632128, "time": 29321.348559617996, "episode/length": 310.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9871382636655949, "episode/intrinsic_return": 0.0}
{"step": 632320, "time": 29329.50566959381, "episode/length": 201.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 632600, "time": 29340.342996120453, "episode/length": 451.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9889380530973452, "episode/intrinsic_return": 0.0}
{"step": 633008, "time": 29355.997492790222, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 633097, "time": 29361.53790163994, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.475261002135792, "train/action_min": 0.0, "train/action_std": 3.269091455198878, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.039782996966148454, "train/actor_opt_grad_steps": 38780.0, "train/actor_opt_loss": 5.729938394731755, "train/adv_mag": 0.541945812084692, "train/adv_max": 0.4926783601157099, "train/adv_mean": 0.005573331133373292, "train/adv_min": -0.41029319971156636, "train/adv_std": 0.05977361659995086, "train/cont_avg": 0.995082059352518, "train/cont_loss_mean": 0.00016706938697245977, "train/cont_loss_std": 0.005101185490244304, "train/cont_neg_acc": 0.9929085313845024, "train/cont_neg_loss": 0.02477408663079907, "train/cont_pos_acc": 0.9999787738854936, "train/cont_pos_loss": 4.728429845858554e-05, "train/cont_pred": 0.995094104207677, "train/cont_rate": 0.995082059352518, "train/dyn_loss_mean": 13.076203373696307, "train/dyn_loss_std": 9.298854210393891, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.002436959915024, "train/extr_critic_critic_opt_grad_steps": 38780.0, "train/extr_critic_critic_opt_loss": 15850.639255002248, "train/extr_critic_mag": 7.659758698168418, "train/extr_critic_max": 7.659758698168418, "train/extr_critic_mean": 2.4073000485948524, "train/extr_critic_min": -0.1821921026106361, "train/extr_critic_std": 1.7224221461110836, "train/extr_return_normed_mag": 1.5886421563814013, "train/extr_return_normed_max": 1.5886421563814013, "train/extr_return_normed_mean": 0.40365337039069304, "train/extr_return_normed_min": -0.13214689310934905, "train/extr_return_normed_std": 0.32340821902528943, "train/extr_return_rate": 0.8773892324605435, "train/extr_return_raw_mag": 8.886596329778218, "train/extr_return_raw_max": 8.886596329778218, "train/extr_return_raw_mean": 2.437567095104739, "train/extr_return_raw_min": -0.4797977308789603, "train/extr_return_raw_std": 1.760495463721186, "train/extr_reward_mag": 1.0320018675687501, "train/extr_reward_max": 1.0320018675687501, "train/extr_reward_mean": 0.03926003286146003, "train/extr_reward_min": -0.412787469170934, "train/extr_reward_std": 0.1842532667110292, "train/image_loss_mean": 6.447870539246703, "train/image_loss_std": 11.002486273539152, "train/model_loss_mean": 14.347754101101444, "train/model_loss_std": 14.869845060993441, "train/model_opt_grad_norm": 59.012516639215484, "train/model_opt_grad_steps": 38746.29496402878, "train/model_opt_loss": 17807.70911083633, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1241.0071942446043, "train/policy_entropy_mag": 2.467072238167413, "train/policy_entropy_max": 2.467072238167413, "train/policy_entropy_mean": 0.5440373371402136, "train/policy_entropy_min": 0.07937510311603546, "train/policy_entropy_std": 0.6190651029133968, "train/policy_logprob_mag": 7.4383837267649255, "train/policy_logprob_max": -0.009455686495404878, "train/policy_logprob_mean": -0.5436699105252465, "train/policy_logprob_min": -7.4383837267649255, "train/policy_logprob_std": 1.0971236936480022, "train/policy_randomness_mag": 0.8707682365993802, "train/policy_randomness_max": 0.8707682365993802, "train/policy_randomness_mean": 0.19202130486210472, "train/policy_randomness_min": 0.028015928182134525, "train/policy_randomness_std": 0.21850281460679694, "train/post_ent_mag": 60.28041850577156, "train/post_ent_max": 60.28041850577156, "train/post_ent_mean": 42.97668059095204, "train/post_ent_min": 21.197916264156643, "train/post_ent_std": 7.471742568256186, "train/prior_ent_mag": 70.54629950214633, "train/prior_ent_max": 70.54629950214633, "train/prior_ent_mean": 56.128109993694494, "train/prior_ent_min": 42.77543966718715, "train/prior_ent_std": 4.641764527602161, "train/rep_loss_mean": 13.076203373696307, "train/rep_loss_std": 9.298854210393891, "train/reward_avg": 0.02723625796786744, "train/reward_loss_mean": 0.0539945046410715, "train/reward_loss_std": 0.24747653434173666, "train/reward_max_data": 1.019424465062807, "train/reward_max_pred": 1.012391719886725, "train/reward_neg_acc": 0.9928296234110277, "train/reward_neg_loss": 0.02844805573950783, "train/reward_pos_acc": 0.968127897317461, "train/reward_pos_loss": 0.8412719892083312, "train/reward_pred": 0.026561220350722187, "train/reward_rate": 0.03161533273381295, "train_stats/sum_log_reward": 8.510000238418579, "train_stats/max_log_achievement_collect_coal": 0.34, "train_stats/max_log_achievement_collect_drink": 4.38, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 2.02, "train_stats/max_log_achievement_collect_stone": 5.94, "train_stats/max_log_achievement_collect_wood": 10.9, "train_stats/max_log_achievement_defeat_skeleton": 0.05, "train_stats/max_log_achievement_defeat_zombie": 0.59, "train_stats/max_log_achievement_eat_cow": 0.17, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.65, "train_stats/max_log_achievement_make_wood_sword": 1.18, "train_stats/max_log_achievement_place_furnace": 0.13, "train_stats/max_log_achievement_place_plant": 1.93, "train_stats/max_log_achievement_place_stone": 3.77, "train_stats/max_log_achievement_place_table": 3.22, "train_stats/max_log_achievement_wake_up": 1.23, "train_stats/mean_log_entropy": 0.5601673321425915, "eval_stats/sum_log_reward": 7.100000150501728, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 2.9375, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 4.4375, "eval_stats/max_log_achievement_collect_wood": 10.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.6875, "eval_stats/max_log_achievement_make_wood_sword": 0.75, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5625, "eval_stats/max_log_achievement_place_stone": 2.6875, "eval_stats/max_log_achievement_place_table": 2.9375, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 5.371163751988206e-06, "report/cont_loss_std": 7.502416701754555e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0005191524396650493, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.3429836346622324e-06, "report/cont_pred": 0.9941413402557373, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 12.219389915466309, "report/dyn_loss_std": 8.289653778076172, "report/image_loss_mean": 4.913765907287598, "report/image_loss_std": 7.7610273361206055, "report/model_loss_mean": 12.324007034301758, "report/model_loss_std": 10.979508399963379, "report/post_ent_mag": 60.748355865478516, "report/post_ent_max": 60.748355865478516, "report/post_ent_mean": 43.106781005859375, "report/post_ent_min": 21.50788116455078, "report/post_ent_std": 7.363279819488525, "report/prior_ent_mag": 70.32359313964844, "report/prior_ent_max": 70.32359313964844, "report/prior_ent_mean": 55.65678405761719, "report/prior_ent_min": 39.935020446777344, "report/prior_ent_std": 4.5514655113220215, "report/rep_loss_mean": 12.219389915466309, "report/rep_loss_std": 8.289653778076172, "report/reward_avg": 0.05693359300494194, "report/reward_loss_mean": 0.07860347628593445, "report/reward_loss_std": 0.27053046226501465, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0013916492462158, "report/reward_neg_acc": 0.9979189038276672, "report/reward_neg_loss": 0.03081458993256092, "report/reward_pos_acc": 0.9841270446777344, "report/reward_pos_loss": 0.8075736165046692, "report/reward_pred": 0.053935274481773376, "report/reward_rate": 0.0615234375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 8.561813046981115e-06, "eval/cont_loss_std": 0.00018241362704429775, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0029051518067717552, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.8933384328411194e-06, "eval/cont_pred": 0.9980496168136597, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 15.753189086914062, "eval/dyn_loss_std": 11.097813606262207, "eval/image_loss_mean": 10.871166229248047, "eval/image_loss_std": 13.071168899536133, "eval/model_loss_mean": 20.40927505493164, "eval/model_loss_std": 17.81204605102539, "eval/post_ent_mag": 62.83620071411133, "eval/post_ent_max": 62.83620071411133, "eval/post_ent_mean": 44.070701599121094, "eval/post_ent_min": 18.10845375061035, "eval/post_ent_std": 8.28692626953125, "eval/prior_ent_mag": 70.32359313964844, "eval/prior_ent_max": 70.32359313964844, "eval/prior_ent_mean": 57.32439041137695, "eval/prior_ent_min": 45.40628433227539, "eval/prior_ent_std": 4.417420387268066, "eval/rep_loss_mean": 15.753189086914062, "eval/rep_loss_std": 11.097813606262207, "eval/reward_avg": 0.03037109412252903, "eval/reward_loss_mean": 0.08618848770856857, "eval/reward_loss_std": 0.4894857406616211, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017588138580322, "eval/reward_neg_acc": 0.9919109344482422, "eval/reward_neg_loss": 0.034833576530218124, "eval/reward_pos_acc": 0.8857142925262451, "eval/reward_pos_loss": 1.5373315811157227, "eval/reward_pred": 0.024012619629502296, "eval/reward_rate": 0.0341796875, "replay/size": 632593.0, "replay/inserts": 22144.0, "replay/samples": 22144.0, "replay/insert_wait_avg": 1.4412351426361614e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.097245042723728e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4816.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2915989885298517e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3100423812866, "timer/env.step_count": 2768.0, "timer/env.step_total": 242.47207403182983, "timer/env.step_frac": 0.24239692071331534, "timer/env.step_avg": 0.08759829264155702, "timer/env.step_min": 0.024097919464111328, "timer/env.step_max": 3.7410218715667725, "timer/replay._sample_count": 22144.0, "timer/replay._sample_total": 11.992156028747559, "timer/replay._sample_frac": 0.011988439104539677, "timer/replay._sample_avg": 0.0005415532888704642, "timer/replay._sample_min": 0.00039458274841308594, "timer/replay._sample_max": 0.02879619598388672, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3370.0, "timer/agent.policy_total": 58.99055361747742, "timer/agent.policy_frac": 0.05897226971454524, "timer/agent.policy_avg": 0.017504615316758877, "timer/agent.policy_min": 0.009513378143310547, "timer/agent.policy_max": 0.13238525390625, "timer/dataset_train_count": 1384.0, "timer/dataset_train_total": 0.15969347953796387, "timer/dataset_train_frac": 0.0001596439831372739, "timer/dataset_train_avg": 0.00011538546209390453, "timer/dataset_train_min": 9.894371032714844e-05, "timer/dataset_train_max": 0.0009310245513916016, "timer/agent.train_count": 1384.0, "timer/agent.train_total": 627.3598306179047, "timer/agent.train_frac": 0.6271653827691703, "timer/agent.train_avg": 0.4532946753019542, "timer/agent.train_min": 0.4357593059539795, "timer/agent.train_max": 1.7152023315429688, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47832727432250977, "timer/agent.report_frac": 0.00047817901856091384, "timer/agent.report_avg": 0.23916363716125488, "timer/agent.report_min": 0.23055028915405273, "timer/agent.report_max": 0.24777698516845703, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 3.360660018297264e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 22.136833157620334}
{"step": 633408, "time": 29372.138275146484, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 633488, "time": 29376.554908514023, "episode/length": 169.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 633816, "time": 29389.097237348557, "episode/length": 293.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 633976, "time": 29396.112514972687, "episode/length": 171.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 634064, "time": 29400.96770954132, "episode/length": 353.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9858757062146892, "episode/intrinsic_return": 0.0}
{"step": 634104, "time": 29403.73767876625, "episode/length": 136.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 634168, "time": 29407.544485569, "episode/length": 43.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 634336, "time": 29414.989204645157, "episode/length": 251.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 634912, "time": 29436.286675453186, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 635376, "time": 29453.740828990936, "episode/length": 421.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9786729857819905, "episode/intrinsic_return": 0.0}
{"step": 635488, "time": 29459.165806770325, "episode/length": 259.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9884615384615385, "episode/intrinsic_return": 0.0}
{"step": 635592, "time": 29464.056998491287, "episode/length": 201.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 635768, "time": 29471.63846063614, "episode/length": 199.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 636144, "time": 29486.342658281326, "episode/length": 259.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 636216, "time": 29490.200257778168, "episode/length": 263.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 636232, "time": 29492.431555747986, "episode/length": 57.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 636712, "time": 29510.340680122375, "episode/length": 224.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 636856, "time": 29516.77984714508, "episode/length": 314.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 637320, "time": 29534.1225605011, "episode/length": 242.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9670781893004116, "episode/intrinsic_return": 0.0}
{"step": 637576, "time": 29544.514154434204, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 638096, "time": 29563.980211019516, "episode/length": 312.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9840255591054313, "episode/intrinsic_return": 0.0}
{"step": 638112, "time": 29566.241879224777, "episode/length": 327.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9908536585365854, "episode/intrinsic_return": 0.0}
{"step": 638328, "time": 29574.95348906517, "episode/length": 272.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 638408, "time": 29579.412937641144, "episode/length": 193.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 638728, "time": 29591.790096521378, "episode/length": 251.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 638800, "time": 29596.00578570366, "episode/length": 184.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 639240, "time": 29614.18044781685, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 639400, "time": 29621.17649769783, "episode/length": 395.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 639424, "time": 29623.830149173737, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 639784, "time": 29637.545459747314, "episode/length": 208.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 29663.227398872375, "eval_episode/length": 59.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 640016, "time": 29668.523500680923, "eval_episode/length": 140.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9645390070921985}
{"step": 640016, "time": 29671.05182170868, "eval_episode/length": 159.0, "eval_episode/score": 10.099999964237213, "eval_episode/reward_rate": 0.95625}
{"step": 640016, "time": 29673.480515241623, "eval_episode/length": 178.0, "eval_episode/score": 9.100000016391277, "eval_episode/reward_rate": 0.9888268156424581}
{"step": 640016, "time": 29676.52010011673, "eval_episode/length": 48.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 640016, "time": 29680.295897483826, "eval_episode/length": 256.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9766536964980544}
{"step": 640016, "time": 29682.27219581604, "eval_episode/length": 265.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.981203007518797}
{"step": 640016, "time": 29682.280576705933, "eval_episode/length": 265.0, "eval_episode/score": 10.099999971687794, "eval_episode/reward_rate": 0.9962406015037594}
{"step": 640048, "time": 29683.36407327652, "episode/length": 204.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9658536585365853, "episode/intrinsic_return": 0.0}
{"step": 640104, "time": 29686.659137248993, "episode/length": 162.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 640424, "time": 29699.1686835289, "episode/length": 211.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 640768, "time": 29712.623670578003, "episode/length": 304.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 640936, "time": 29719.86192536354, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 641256, "time": 29732.284245491028, "episode/length": 228.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 641288, "time": 29734.991695404053, "episode/length": 187.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 641768, "time": 29753.012963056564, "episode/length": 315.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.990506329113924, "episode/intrinsic_return": 0.0}
{"step": 641800, "time": 29755.780715227127, "episode/length": 171.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 642760, "time": 29790.01891183853, "episode/length": 338.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9941002949852508, "episode/intrinsic_return": 0.0}
{"step": 642896, "time": 29796.72329878807, "episode/length": 244.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9673469387755103, "episode/intrinsic_return": 0.0}
{"step": 643032, "time": 29802.745478868484, "episode/length": 365.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 643080, "time": 29806.005442857742, "episode/length": 163.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 643168, "time": 29811.012620687485, "episode/length": 170.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 643576, "time": 29826.321398496628, "episode/length": 350.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 644056, "time": 29844.445412635803, "episode/length": 110.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.963963963963964, "episode/intrinsic_return": 0.0}
{"step": 644120, "time": 29848.267176389694, "episode/length": 353.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 644152, "time": 29850.914579868317, "episode/length": 139.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 644168, "time": 29853.06537079811, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 644776, "time": 29875.373534679413, "episode/length": 234.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 644880, "time": 29880.811789512634, "episode/length": 162.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 645528, "time": 29904.4525244236, "episode/length": 533.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 645848, "time": 29916.92915701866, "episode/length": 223.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 645880, "time": 29919.75602197647, "episode/length": 349.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9971428571428571, "episode/intrinsic_return": 0.0}
{"step": 645912, "time": 29922.463820695877, "episode/length": 217.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 645992, "time": 29926.77563381195, "episode/length": 233.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 646432, "time": 29943.432851552963, "episode/length": 284.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 646504, "time": 29947.19194149971, "episode/length": 73.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9324324324324325, "episode/intrinsic_return": 0.0}
{"step": 646608, "time": 29952.48151731491, "episode/length": 228.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 647016, "time": 29967.7820584774, "episode/length": 145.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 647152, "time": 29974.14798283577, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 647288, "time": 29981.751821517944, "episode/length": 300.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9833887043189369, "episode/intrinsic_return": 0.0}
{"step": 647376, "time": 29987.23878955841, "episode/length": 186.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 647392, "time": 29989.347523212433, "episode/length": 174.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 647752, "time": 30002.868191719055, "episode/length": 57.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 647992, "time": 30012.686618328094, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 648096, "time": 30018.209139347076, "episode/length": 207.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 648456, "time": 30031.850004911423, "episode/length": 230.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 648552, "time": 30036.695695638657, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 648648, "time": 30041.59115433693, "episode/length": 186.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 648896, "time": 30051.95591187477, "episode/length": 99.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 649656, "time": 30079.154594898224, "episode/length": 284.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9964912280701754, "episode/intrinsic_return": 0.0}
{"step": 649672, "time": 30081.40372633934, "episode/length": 127.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 650000, "time": 30115.11784529686, "eval_episode/length": 161.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 650000, "time": 30117.68900370598, "eval_episode/length": 182.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.994535519125683}
{"step": 650000, "time": 30119.726871967316, "eval_episode/length": 193.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9690721649484536}
{"step": 650000, "time": 30122.010666370392, "eval_episode/length": 208.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 650000, "time": 30126.023247241974, "eval_episode/length": 261.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9961832061068703}
{"step": 650000, "time": 30127.708020210266, "eval_episode/length": 264.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 650000, "time": 30129.76601266861, "eval_episode/length": 110.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.954954954954955}
{"step": 650000, "time": 30137.283975362778, "eval_episode/length": 353.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9858757062146892}
{"step": 650032, "time": 30138.389365673065, "episode/length": 254.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 650096, "time": 30142.260309696198, "episode/length": 204.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 650704, "time": 30164.457599163055, "episode/length": 268.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9739776951672863, "episode/intrinsic_return": 0.0}
{"step": 651016, "time": 30176.514951705933, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 651024, "time": 30178.606174468994, "episode/length": 170.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 651632, "time": 30201.049925088882, "episode/length": 529.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9886792452830189, "episode/intrinsic_return": 0.0}
{"step": 651672, "time": 30203.709805488586, "episode/length": 489.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9918367346938776, "episode/intrinsic_return": 0.0}
{"step": 652016, "time": 30217.467131853104, "episode/length": 247.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 652072, "time": 30220.760780334473, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 652112, "time": 30223.995123147964, "episode/length": 401.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 652136, "time": 30226.242438077927, "episode/length": 254.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 652368, "time": 30235.962703227997, "episode/length": 168.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 652776, "time": 30251.142220258713, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 653224, "time": 30268.094956874847, "episode/length": 198.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 653440, "time": 30277.26617860794, "episode/length": 220.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 653528, "time": 30281.49625492096, "episode/length": 188.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 653848, "time": 30293.8835105896, "episode/length": 39.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 654032, "time": 30301.959488868713, "episode/length": 236.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 654128, "time": 30306.96306872368, "episode/length": 219.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 654584, "time": 30323.83997321129, "episode/length": 91.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 654656, "time": 30328.170379161835, "episode/length": 322.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9876160990712074, "episode/intrinsic_return": 0.0}
{"step": 655000, "time": 30341.309758663177, "episode/length": 360.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9916897506925207, "episode/intrinsic_return": 0.0}
{"step": 655465, "time": 30361.557386875153, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.486063494001116, "train/action_min": 0.0, "train/action_std": 3.302113892350878, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.038368626976651804, "train/actor_opt_grad_steps": 40175.0, "train/actor_opt_loss": 0.13171182194990771, "train/adv_mag": 0.49960516542196276, "train/adv_max": 0.44325887113809587, "train/adv_mean": 0.004259278339915389, "train/adv_min": -0.4131339377590588, "train/adv_std": 0.05656480102666787, "train/cont_avg": 0.9948800223214286, "train/cont_loss_mean": 0.00019206631195385984, "train/cont_loss_std": 0.005606725429288417, "train/cont_neg_acc": 0.9905952389751161, "train/cont_neg_loss": 0.022076814246254017, "train/cont_pos_acc": 0.9999508585248674, "train/cont_pos_loss": 8.623439010772164e-05, "train/cont_pred": 0.9948776985917772, "train/cont_rate": 0.9948800223214286, "train/dyn_loss_mean": 13.017494807924542, "train/dyn_loss_std": 9.346053940909249, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0492303788661956, "train/extr_critic_critic_opt_grad_steps": 40175.0, "train/extr_critic_critic_opt_loss": 15651.388839285713, "train/extr_critic_mag": 8.071303054264613, "train/extr_critic_max": 8.071303054264613, "train/extr_critic_mean": 2.5839914126055583, "train/extr_critic_min": -0.17343591451644896, "train/extr_critic_std": 1.8762662938662937, "train/extr_return_normed_mag": 1.550631900344576, "train/extr_return_normed_max": 1.550631900344576, "train/extr_return_normed_mean": 0.3934773168393544, "train/extr_return_normed_min": -0.1382185683186565, "train/extr_return_normed_std": 0.32683659366198947, "train/extr_return_rate": 0.8919592188937323, "train/extr_return_raw_mag": 9.382485682623727, "train/extr_return_raw_max": 9.382485682623727, "train/extr_return_raw_mean": 2.608926111459732, "train/extr_return_raw_min": -0.5043013155460357, "train/extr_return_raw_std": 1.9135752286229815, "train/extr_reward_mag": 1.0299824016434806, "train/extr_reward_max": 1.0299824016434806, "train/extr_reward_mean": 0.038466745016298126, "train/extr_reward_min": -0.45309542162077765, "train/extr_reward_std": 0.18215880819729396, "train/image_loss_mean": 6.663803734098162, "train/image_loss_std": 11.243417419706072, "train/model_loss_mean": 14.528863573074341, "train/model_loss_std": 15.15414639881679, "train/model_opt_grad_norm": 59.23954876491002, "train/model_opt_grad_steps": 40140.0, "train/model_opt_loss": 11808.201154436383, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 812.5, "train/policy_entropy_mag": 2.478604781627655, "train/policy_entropy_max": 2.478604781627655, "train/policy_entropy_mean": 0.5749867805412837, "train/policy_entropy_min": 0.07937510423362255, "train/policy_entropy_std": 0.6683074932013239, "train/policy_logprob_mag": 7.43838369846344, "train/policy_logprob_max": -0.00945568882328059, "train/policy_logprob_mean": -0.5744283186537879, "train/policy_logprob_min": -7.43838369846344, "train/policy_logprob_std": 1.1165303515536444, "train/policy_randomness_mag": 0.8748387157917022, "train/policy_randomness_max": 0.8748387157917022, "train/policy_randomness_mean": 0.20294510232550758, "train/policy_randomness_min": 0.028015928542507545, "train/policy_randomness_std": 0.23588321773069246, "train/post_ent_mag": 60.47799799782889, "train/post_ent_max": 60.47799799782889, "train/post_ent_mean": 43.28386249542236, "train/post_ent_min": 21.051676300593783, "train/post_ent_std": 7.501645050730024, "train/prior_ent_mag": 70.7201609475272, "train/prior_ent_max": 70.7201609475272, "train/prior_ent_mean": 56.34692489079067, "train/prior_ent_min": 42.434992272513256, "train/prior_ent_std": 4.729540351458958, "train/rep_loss_mean": 13.017494807924542, "train/rep_loss_std": 9.346053940909249, "train/reward_avg": 0.026503906226051706, "train/reward_loss_mean": 0.054370954712586746, "train/reward_loss_std": 0.2461599253118038, "train/reward_max_data": 1.0171428612300328, "train/reward_max_pred": 1.010262257712228, "train/reward_neg_acc": 0.993015330178397, "train/reward_neg_loss": 0.028888996969908477, "train/reward_pos_acc": 0.9665521843092783, "train/reward_pos_loss": 0.8511686261211123, "train/reward_pred": 0.025767095746206385, "train/reward_rate": 0.0310546875, "train_stats/sum_log_reward": 8.647368646922864, "train_stats/max_log_achievement_collect_coal": 0.37894736842105264, "train_stats/max_log_achievement_collect_drink": 4.894736842105263, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.8105263157894738, "train_stats/max_log_achievement_collect_stone": 6.389473684210526, "train_stats/max_log_achievement_collect_wood": 11.736842105263158, "train_stats/max_log_achievement_defeat_skeleton": 0.010526315789473684, "train_stats/max_log_achievement_defeat_zombie": 0.8526315789473684, "train_stats/max_log_achievement_eat_cow": 0.14736842105263157, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.010526315789473684, "train_stats/max_log_achievement_make_stone_sword": 0.021052631578947368, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7157894736842105, "train_stats/max_log_achievement_make_wood_sword": 1.368421052631579, "train_stats/max_log_achievement_place_furnace": 0.06315789473684211, "train_stats/max_log_achievement_place_plant": 1.7263157894736842, "train_stats/max_log_achievement_place_stone": 4.3052631578947365, "train_stats/max_log_achievement_place_table": 3.3263157894736843, "train_stats/max_log_achievement_wake_up": 1.3368421052631578, "train_stats/mean_log_entropy": 0.5691003283387737, "eval_stats/sum_log_reward": 8.47500017285347, "eval_stats/max_log_achievement_collect_coal": 0.1875, "eval_stats/max_log_achievement_collect_drink": 5.625, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.3125, "eval_stats/max_log_achievement_collect_stone": 5.5625, "eval_stats/max_log_achievement_collect_wood": 9.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.6875, "eval_stats/max_log_achievement_eat_cow": 0.3125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.3125, "eval_stats/max_log_achievement_make_wood_sword": 1.1875, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 1.3125, "eval_stats/max_log_achievement_place_stone": 3.5625, "eval_stats/max_log_achievement_place_table": 2.9375, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.001775016076862812, "report/cont_loss_std": 0.05311058461666107, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004980323137715459, "report/cont_pos_acc": 0.9990166425704956, "report/cont_pos_loss": 0.0017838054336607456, "report/cont_pred": 0.9922613501548767, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.61352252960205, "report/dyn_loss_std": 8.975513458251953, "report/image_loss_mean": 7.0604119300842285, "report/image_loss_std": 9.66418743133545, "report/model_loss_mean": 15.290517807006836, "report/model_loss_std": 13.431421279907227, "report/post_ent_mag": 59.723976135253906, "report/post_ent_max": 59.723976135253906, "report/post_ent_mean": 43.50630569458008, "report/post_ent_min": 19.632946014404297, "report/post_ent_std": 7.487626075744629, "report/prior_ent_mag": 70.4122314453125, "report/prior_ent_max": 70.4122314453125, "report/prior_ent_mean": 57.03965377807617, "report/prior_ent_min": 44.020843505859375, "report/prior_ent_std": 4.575796127319336, "report/rep_loss_mean": 13.61352252960205, "report/rep_loss_std": 8.975513458251953, "report/reward_avg": 0.02324218675494194, "report/reward_loss_mean": 0.0602170005440712, "report/reward_loss_std": 0.3242602050304413, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.070636510848999, "report/reward_neg_acc": 0.9979899525642395, "report/reward_neg_loss": 0.040031176060438156, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7527997493743896, "report/reward_pred": 0.02194463461637497, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 2.528850473026978e-06, "eval/cont_loss_std": 6.960520840948448e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0012727900175377727, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.3016139983365065e-08, "eval/cont_pred": 0.9980493783950806, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.984676361083984, "eval/dyn_loss_std": 11.084977149963379, "eval/image_loss_mean": 11.505155563354492, "eval/image_loss_std": 14.404214859008789, "eval/model_loss_mean": 22.392160415649414, "eval/model_loss_std": 18.902734756469727, "eval/post_ent_mag": 62.06812286376953, "eval/post_ent_max": 62.06812286376953, "eval/post_ent_mean": 41.44879150390625, "eval/post_ent_min": 21.197240829467773, "eval/post_ent_std": 7.851885795593262, "eval/prior_ent_mag": 70.4122314453125, "eval/prior_ent_max": 70.4122314453125, "eval/prior_ent_mean": 56.24140930175781, "eval/prior_ent_min": 44.672176361083984, "eval/prior_ent_std": 4.239817142486572, "eval/rep_loss_mean": 17.984676361083984, "eval/rep_loss_std": 11.084977149963379, "eval/reward_avg": 0.0224609375, "eval/reward_loss_mean": 0.09619645774364471, "eval/reward_loss_std": 0.5812943577766418, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0015239715576172, "eval/reward_neg_acc": 0.9899699091911316, "eval/reward_neg_loss": 0.04651108384132385, "eval/reward_pos_acc": 0.7037037014961243, "eval/reward_pos_loss": 1.9308748245239258, "eval/reward_pred": 0.018040429800748825, "eval/reward_rate": 0.0263671875, "replay/size": 654961.0, "replay/inserts": 22368.0, "replay/samples": 22368.0, "replay/insert_wait_avg": 1.439603527898611e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.128826541109317e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4960.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3540348699015957e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1473894119262695e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0019886493683, "timer/env.step_count": 2796.0, "timer/env.step_total": 233.9860498905182, "timer/env.step_frac": 0.23398558457523325, "timer/env.step_avg": 0.08368599781492067, "timer/env.step_min": 0.02443552017211914, "timer/env.step_max": 2.130016326904297, "timer/replay._sample_count": 22368.0, "timer/replay._sample_total": 12.155734062194824, "timer/replay._sample_frac": 0.012155709888750033, "timer/replay._sample_avg": 0.0005434430464142893, "timer/replay._sample_min": 0.0004222393035888672, "timer/replay._sample_max": 0.010308265686035156, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3416.0, "timer/agent.policy_total": 60.914695501327515, "timer/agent.policy_frac": 0.060914574363597686, "timer/agent.policy_avg": 0.017832170814205947, "timer/agent.policy_min": 0.009718656539916992, "timer/agent.policy_max": 0.15123653411865234, "timer/dataset_train_count": 1398.0, "timer/dataset_train_total": 0.16255402565002441, "timer/dataset_train_frac": 0.00016255370238770685, "timer/dataset_train_avg": 0.00011627612707440945, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.0010688304901123047, "timer/agent.train_count": 1398.0, "timer/agent.train_total": 634.3211538791656, "timer/agent.train_frac": 0.6343198924393123, "timer/agent.train_avg": 0.45373473095791533, "timer/agent.train_min": 0.4407353401184082, "timer/agent.train_max": 1.862905740737915, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47582364082336426, "timer/agent.report_frac": 0.00047582269457886327, "timer/agent.report_avg": 0.23791182041168213, "timer/agent.report_min": 0.23126459121704102, "timer/agent.report_max": 0.24455904960632324, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.552436828613281e-05, "timer/dataset_eval_frac": 3.552429764076075e-08, "timer/dataset_eval_avg": 3.552436828613281e-05, "timer/dataset_eval_min": 3.552436828613281e-05, "timer/dataset_eval_max": 3.552436828613281e-05, "fps": 22.36761733028489}
{"step": 655592, "time": 30365.727022647858, "episode/length": 194.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 655600, "time": 30367.823773384094, "episode/length": 183.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 655688, "time": 30372.17720723152, "episode/length": 137.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 655904, "time": 30381.51452422142, "episode/length": 334.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9880597014925373, "episode/intrinsic_return": 0.0}
{"step": 656008, "time": 30386.460344076157, "episode/length": 403.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9851485148514851, "episode/intrinsic_return": 0.0}
{"step": 656032, "time": 30389.112530708313, "episode/length": 323.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9845679012345679, "episode/intrinsic_return": 0.0}
{"step": 656584, "time": 30409.298895835876, "episode/length": 197.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 656936, "time": 30422.874727725983, "episode/length": 43.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 657136, "time": 30431.48644065857, "episode/length": 309.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 657160, "time": 30433.61891222, "episode/length": 195.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 657240, "time": 30437.998973608017, "episode/length": 193.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 657472, "time": 30447.73133611679, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700854700854701, "episode/intrinsic_return": 0.0}
{"step": 657520, "time": 30450.94740986824, "episode/length": 201.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 657536, "time": 30453.097078084946, "episode/length": 46.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8936170212765957, "episode/intrinsic_return": 0.0}
{"step": 658736, "time": 30495.591913700104, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 658912, "time": 30503.283197164536, "episode/length": 221.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 659304, "time": 30517.98543214798, "episode/length": 228.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 659496, "time": 30526.282804965973, "episode/length": 435.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 659624, "time": 30532.065057516098, "episode/length": 335.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 659752, "time": 30537.89708828926, "episode/length": 276.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9783393501805054, "episode/intrinsic_return": 0.0}
{"step": 659840, "time": 30542.73001241684, "episode/length": 289.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 30567.60750746727, "eval_episode/length": 47.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 660088, "time": 30574.1336209774, "eval_episode/length": 157.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 660088, "time": 30575.993530511856, "eval_episode/length": 163.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 660088, "time": 30577.98376226425, "eval_episode/length": 171.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 660088, "time": 30580.019769906998, "eval_episode/length": 179.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 660088, "time": 30582.353635549545, "eval_episode/length": 195.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 660088, "time": 30585.34156346321, "eval_episode/length": 226.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9779735682819384}
{"step": 660088, "time": 30587.445245981216, "eval_episode/length": 187.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9680851063829787}
{"step": 660296, "time": 30594.47765636444, "episode/length": 172.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 660336, "time": 30597.749936819077, "episode/length": 537.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9869888475836431, "episode/intrinsic_return": 0.0}
{"step": 661408, "time": 30635.836390018463, "episode/length": 333.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9790419161676647, "episode/intrinsic_return": 0.0}
{"step": 661672, "time": 30646.157431602478, "episode/length": 228.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 661768, "time": 30651.021000623703, "episode/length": 178.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 661816, "time": 30654.321848154068, "episode/length": 289.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 661848, "time": 30657.02902531624, "episode/length": 193.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 662024, "time": 30664.498619794846, "episode/length": 283.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9823943661971831, "episode/intrinsic_return": 0.0}
{"step": 662344, "time": 30676.838631868362, "episode/length": 379.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9763157894736842, "episode/intrinsic_return": 0.0}
{"step": 662904, "time": 30697.501223564148, "episode/length": 409.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9780487804878049, "episode/intrinsic_return": 0.0}
{"step": 663200, "time": 30709.55823945999, "episode/length": 190.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 663280, "time": 30713.98280620575, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 663408, "time": 30719.865016698837, "episode/length": 249.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 663440, "time": 30722.481374502182, "episode/length": 208.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9856459330143541, "episode/intrinsic_return": 0.0}
{"step": 663800, "time": 30737.920083999634, "episode/length": 243.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 663824, "time": 30740.55251765251, "episode/length": 224.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 664096, "time": 30751.275976896286, "episode/length": 218.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 664240, "time": 30757.756742715836, "episode/length": 166.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 664480, "time": 30767.525561094284, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 665456, "time": 30802.155520439148, "episode/length": 251.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 665464, "time": 30803.967573404312, "episode/length": 204.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 665600, "time": 30810.69728589058, "episode/length": 187.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 665688, "time": 30815.09000968933, "episode/length": 235.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 665992, "time": 30827.01877093315, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 666512, "time": 30846.390853881836, "episode/length": 403.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9777227722772277, "episode/intrinsic_return": 0.0}
{"step": 666832, "time": 30858.94053864479, "episode/length": 427.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.985981308411215, "episode/intrinsic_return": 0.0}
{"step": 666944, "time": 30864.35861849785, "episode/length": 184.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 666984, "time": 30867.184415578842, "episode/length": 58.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 667104, "time": 30873.153704881668, "episode/length": 327.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 667136, "time": 30875.96063184738, "episode/length": 142.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 667256, "time": 30881.31955218315, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.961352657004831, "episode/intrinsic_return": 0.0}
{"step": 667296, "time": 30884.486477851868, "episode/length": 200.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 667960, "time": 30908.39133620262, "episode/length": 106.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9439252336448598, "episode/intrinsic_return": 0.0}
{"step": 668008, "time": 30911.50121641159, "episode/length": 132.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9699248120300752, "episode/intrinsic_return": 0.0}
{"step": 668392, "time": 30926.254011154175, "episode/length": 366.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9918256130790191, "episode/intrinsic_return": 0.0}
{"step": 668400, "time": 30928.33799481392, "episode/length": 195.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 668616, "time": 30936.95456814766, "episode/length": 169.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 668728, "time": 30942.414914608, "episode/length": 178.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 669256, "time": 30961.88985824585, "episode/length": 155.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 669440, "time": 30970.025106430054, "episode/length": 287.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 669648, "time": 30978.846709489822, "episode/length": 210.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 669696, "time": 30982.12098145485, "episode/length": 338.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9852507374631269, "episode/intrinsic_return": 0.0}
{"step": 669720, "time": 30984.343196868896, "episode/length": 57.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 31018.072411060333, "eval_episode/length": 159.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 670072, "time": 31019.894367456436, "eval_episode/length": 161.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 670072, "time": 31022.488871574402, "eval_episode/length": 182.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 670072, "time": 31024.5795378685, "eval_episode/length": 194.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 670072, "time": 31028.286271572113, "eval_episode/length": 239.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9875}
{"step": 670072, "time": 31030.708460092545, "eval_episode/length": 256.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9961089494163424}
{"step": 670072, "time": 31032.91464447975, "eval_episode/length": 266.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9850187265917603}
{"step": 670072, "time": 31037.773837327957, "eval_episode/length": 173.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 670256, "time": 31044.35984659195, "episode/length": 204.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 670448, "time": 31053.0291929245, "episode/length": 214.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 670600, "time": 31059.51757979393, "episode/length": 274.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 671160, "time": 31080.00411939621, "episode/length": 88.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 671184, "time": 31082.761664390564, "episode/length": 185.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 671376, "time": 31090.861412763596, "episode/length": 241.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 671952, "time": 31113.608921289444, "episode/length": 168.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 672040, "time": 31117.915883779526, "episode/length": 455.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9978070175438597, "episode/intrinsic_return": 0.0}
{"step": 672064, "time": 31120.649350643158, "episode/length": 225.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 672112, "time": 31123.771359682083, "episode/length": 298.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9866220735785953, "episode/intrinsic_return": 0.0}
{"step": 672320, "time": 31132.555557012558, "episode/length": 45.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 672488, "time": 31139.507587194443, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 672568, "time": 31143.859867095947, "episode/length": 172.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 673480, "time": 31176.44710445404, "episode/length": 179.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 673864, "time": 31191.17823123932, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 674288, "time": 31207.414556741714, "episode/length": 271.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 674576, "time": 31218.886770248413, "episode/length": 399.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9925, "episode/intrinsic_return": 0.0}
{"step": 675168, "time": 31240.42870926857, "episode/length": 210.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 675560, "time": 31255.128938674927, "episode/length": 373.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9893048128342246, "episode/intrinsic_return": 0.0}
{"step": 675688, "time": 31261.106287240982, "episode/length": 754.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9880794701986755, "episode/intrinsic_return": 0.0}
{"step": 675936, "time": 31271.289848327637, "episode/length": 451.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9977876106194691, "episode/intrinsic_return": 0.0}
{"step": 676216, "time": 31282.432380199432, "episode/length": 204.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 676464, "time": 31292.716768741608, "episode/length": 161.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 676640, "time": 31300.248321294785, "episode/length": 571.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9982517482517482, "episode/intrinsic_return": 0.0}
{"step": 676704, "time": 31304.02102994919, "episode/length": 142.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 676800, "time": 31309.102567195892, "episode/length": 313.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9840764331210191, "episode/intrinsic_return": 0.0}
{"step": 677240, "time": 31325.294132232666, "episode/length": 66.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9253731343283582, "episode/intrinsic_return": 0.0}
{"step": 677272, "time": 31328.011031627655, "episode/length": 425.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 677832, "time": 31348.551875591278, "episode/length": 73.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 677912, "time": 31352.845460414886, "episode/length": 246.0, "episode/score": 11.100000068545341, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 677992, "time": 31357.169929027557, "episode/length": 287.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 678040, "time": 31360.456884384155, "episode/length": 196.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 678041, "time": 31363.222768068314, "train_stats/sum_log_reward": 9.141666904091835, "train_stats/max_log_achievement_collect_coal": 0.59375, "train_stats/max_log_achievement_collect_drink": 3.9791666666666665, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.6979166666666667, "train_stats/max_log_achievement_collect_stone": 9.197916666666666, "train_stats/max_log_achievement_collect_wood": 10.760416666666666, "train_stats/max_log_achievement_defeat_skeleton": 0.03125, "train_stats/max_log_achievement_defeat_zombie": 0.875, "train_stats/max_log_achievement_eat_cow": 0.22916666666666666, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4583333333333333, "train_stats/max_log_achievement_make_wood_sword": 1.2395833333333333, "train_stats/max_log_achievement_place_furnace": 0.11458333333333333, "train_stats/max_log_achievement_place_plant": 1.6041666666666667, "train_stats/max_log_achievement_place_stone": 6.489583333333333, "train_stats/max_log_achievement_place_table": 2.7604166666666665, "train_stats/max_log_achievement_wake_up": 1.5520833333333333, "train_stats/mean_log_entropy": 0.5628046242830654, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.352671521775266, "train/action_min": 0.0, "train/action_std": 3.0946916130417628, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03765683263170381, "train/actor_opt_grad_steps": 41580.0, "train/actor_opt_loss": -2.160799904610856, "train/adv_mag": 0.49400463150748125, "train/adv_max": 0.4490409341264278, "train/adv_mean": 0.0038070665424058446, "train/adv_min": -0.39152494210300715, "train/adv_std": 0.05492894805914967, "train/cont_avg": 0.9951587433510638, "train/cont_loss_mean": 0.0003591227902149838, "train/cont_loss_std": 0.010752669534071148, "train/cont_neg_acc": 0.9914218178877594, "train/cont_neg_loss": 0.037075650945901525, "train/cont_pos_acc": 0.9999373098637195, "train/cont_pos_loss": 0.00020069288948357304, "train/cont_pred": 0.9951279586088573, "train/cont_rate": 0.9951587433510638, "train/dyn_loss_mean": 13.143787181123773, "train/dyn_loss_std": 9.346729366491873, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0023217459096976, "train/extr_critic_critic_opt_grad_steps": 41580.0, "train/extr_critic_critic_opt_loss": 15827.426162178635, "train/extr_critic_mag": 8.489349574907452, "train/extr_critic_max": 8.489349574907452, "train/extr_critic_mean": 2.827748127862917, "train/extr_critic_min": -0.16263839708152392, "train/extr_critic_std": 1.9779242074235956, "train/extr_return_normed_mag": 1.5049445941938575, "train/extr_return_normed_max": 1.5049445941938575, "train/extr_return_normed_mean": 0.4015522468174603, "train/extr_return_normed_min": -0.131474920832519, "train/extr_return_normed_std": 0.3215074626900626, "train/extr_return_rate": 0.9126519590404862, "train/extr_return_raw_mag": 9.758979378017129, "train/extr_return_raw_max": 9.758979378017129, "train/extr_return_raw_mean": 2.851577735961752, "train/extr_return_raw_min": -0.4860041211260126, "train/extr_return_raw_std": 2.0131607444573802, "train/extr_reward_mag": 1.0319704722005425, "train/extr_reward_max": 1.0319704722005425, "train/extr_reward_mean": 0.040369195823973796, "train/extr_reward_min": -0.4232491998807758, "train/extr_reward_std": 0.18650847715688934, "train/image_loss_mean": 6.627947232401963, "train/image_loss_std": 11.648907729074464, "train/model_loss_mean": 14.568223730046698, "train/model_loss_std": 15.586963572400682, "train/model_opt_grad_norm": 56.319652192136076, "train/model_opt_grad_steps": 41544.24113475177, "train/model_opt_loss": 11734.734839040337, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 806.7375886524823, "train/policy_entropy_mag": 2.4946970516908253, "train/policy_entropy_max": 2.4946970516908253, "train/policy_entropy_mean": 0.5258675813674927, "train/policy_entropy_min": 0.07937508446316346, "train/policy_entropy_std": 0.6113426228787037, "train/policy_logprob_mag": 7.4383837111452795, "train/policy_logprob_max": -0.009455673502269366, "train/policy_logprob_mean": -0.5261206675505807, "train/policy_logprob_min": -7.4383837111452795, "train/policy_logprob_std": 1.0852022614884884, "train/policy_randomness_mag": 0.8805185831184928, "train/policy_randomness_max": 0.8805185831184928, "train/policy_randomness_mean": 0.1856081801737454, "train/policy_randomness_min": 0.028015921526449793, "train/policy_randomness_std": 0.21577711942348074, "train/post_ent_mag": 60.478522307483864, "train/post_ent_max": 60.478522307483864, "train/post_ent_mean": 43.224918852461144, "train/post_ent_min": 21.061052755261144, "train/post_ent_std": 7.541538448198467, "train/prior_ent_mag": 70.75475311279297, "train/prior_ent_max": 70.75475311279297, "train/prior_ent_mean": 56.401731639889114, "train/prior_ent_min": 43.06890760922263, "train/prior_ent_std": 4.623307097888162, "train/rep_loss_mean": 13.143787181123773, "train/rep_loss_std": 9.346729366491873, "train/reward_avg": 0.02731466071402773, "train/reward_loss_mean": 0.05364511905779652, "train/reward_loss_std": 0.24656258121872623, "train/reward_max_data": 1.0170212806539332, "train/reward_max_pred": 1.0110115734397942, "train/reward_neg_acc": 0.9932701177630864, "train/reward_neg_loss": 0.02798707194705593, "train/reward_pos_acc": 0.9690268492022305, "train/reward_pos_loss": 0.8385255387488831, "train/reward_pred": 0.026615663299482343, "train/reward_rate": 0.031603224734042555, "eval_stats/sum_log_reward": 9.037500321865082, "eval_stats/max_log_achievement_collect_coal": 0.5625, "eval_stats/max_log_achievement_collect_drink": 6.875, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 7.8125, "eval_stats/max_log_achievement_collect_wood": 9.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.8125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.4375, "eval_stats/max_log_achievement_make_wood_sword": 1.1875, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 5.1875, "eval_stats/max_log_achievement_place_table": 2.5625, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.486975169333164e-06, "report/cont_loss_std": 4.11245709983632e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002153530076611787, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.457211161934538e-06, "report/cont_pred": 0.9951138496398926, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 11.635931015014648, "report/dyn_loss_std": 8.716695785522461, "report/image_loss_mean": 6.4964823722839355, "report/image_loss_std": 16.217641830444336, "report/model_loss_mean": 13.548951148986816, "report/model_loss_std": 19.01174545288086, "report/post_ent_mag": 61.380035400390625, "report/post_ent_max": 61.380035400390625, "report/post_ent_mean": 44.56834030151367, "report/post_ent_min": 22.575159072875977, "report/post_ent_std": 7.685737609863281, "report/prior_ent_mag": 71.03096008300781, "report/prior_ent_max": 71.03096008300781, "report/prior_ent_mean": 56.45259475708008, "report/prior_ent_min": 44.15285873413086, "report/prior_ent_std": 4.771114349365234, "report/rep_loss_mean": 11.635931015014648, "report/rep_loss_std": 8.716695785522461, "report/reward_avg": 0.03544922173023224, "report/reward_loss_mean": 0.07090374827384949, "report/reward_loss_std": 0.3015226125717163, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0004997253417969, "report/reward_neg_acc": 0.9908537268638611, "report/reward_neg_loss": 0.036351852118968964, "report/reward_pos_acc": 0.949999988079071, "report/reward_pos_loss": 0.9208804965019226, "report/reward_pred": 0.034746017307043076, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 4.72880992674618e-06, "eval/cont_loss_std": 4.24221798311919e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00023543898714706302, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.3690250802465016e-06, "eval/cont_pred": 0.9941386580467224, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 17.58745574951172, "eval/dyn_loss_std": 10.597920417785645, "eval/image_loss_mean": 11.853652954101562, "eval/image_loss_std": 15.153337478637695, "eval/model_loss_mean": 22.512718200683594, "eval/model_loss_std": 19.478208541870117, "eval/post_ent_mag": 57.84355926513672, "eval/post_ent_max": 57.84355926513672, "eval/post_ent_mean": 41.06876754760742, "eval/post_ent_min": 21.451820373535156, "eval/post_ent_std": 6.879023551940918, "eval/prior_ent_mag": 71.03096008300781, "eval/prior_ent_max": 71.03096008300781, "eval/prior_ent_mean": 56.67256546020508, "eval/prior_ent_min": 43.084388732910156, "eval/prior_ent_std": 4.3429951667785645, "eval/rep_loss_mean": 17.58745574951172, "eval/rep_loss_std": 10.597920417785645, "eval/reward_avg": 0.0244140625, "eval/reward_loss_mean": 0.1065845936536789, "eval/reward_loss_std": 0.5594058632850647, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0029199123382568, "eval/reward_neg_acc": 0.9889112710952759, "eval/reward_neg_loss": 0.06496128439903259, "eval/reward_pos_acc": 0.84375, "eval/reward_pos_loss": 1.3969073295593262, "eval/reward_pred": 0.02260555513203144, "eval/reward_rate": 0.03125, "replay/size": 677537.0, "replay/inserts": 22576.0, "replay/samples": 22576.0, "replay/insert_wait_avg": 1.4247347664782378e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.145363267645778e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4576.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2422670851220618e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.650640964508, "timer/env.step_count": 2822.0, "timer/env.step_total": 234.78776264190674, "timer/env.step_frac": 0.2344008509951386, "timer/env.step_avg": 0.08319906542944959, "timer/env.step_min": 0.024005651473999023, "timer/env.step_max": 2.1766140460968018, "timer/replay._sample_count": 22576.0, "timer/replay._sample_total": 12.249809741973877, "timer/replay._sample_frac": 0.012229623025227945, "timer/replay._sample_avg": 0.0005426031955162064, "timer/replay._sample_min": 0.0003914833068847656, "timer/replay._sample_max": 0.012084484100341797, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3394.0, "timer/agent.policy_total": 57.938947439193726, "timer/agent.policy_frac": 0.057843468640326766, "timer/agent.policy_avg": 0.017070992174187897, "timer/agent.policy_min": 0.009604692459106445, "timer/agent.policy_max": 0.0884251594543457, "timer/dataset_train_count": 1411.0, "timer/dataset_train_total": 0.16170787811279297, "timer/dataset_train_frac": 0.00016144139633064223, "timer/dataset_train_avg": 0.00011460515812387878, "timer/dataset_train_min": 9.870529174804688e-05, "timer/dataset_train_max": 0.00044274330139160156, "timer/agent.train_count": 1411.0, "timer/agent.train_total": 638.324777841568, "timer/agent.train_frac": 0.6372728691381989, "timer/agent.train_avg": 0.4523917631761644, "timer/agent.train_min": 0.4376242160797119, "timer/agent.train_max": 1.7289013862609863, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4769432544708252, "timer/agent.report_frac": 0.0004761572897428266, "timer/agent.report_avg": 0.2384716272354126, "timer/agent.report_min": 0.23057031631469727, "timer/agent.report_max": 0.24637293815612793, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7610979362175855e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 22.538467959898068}
{"step": 678136, "time": 31366.377548217773, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 678208, "time": 31370.619647026062, "episode/length": 248.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 678616, "time": 31385.691636562347, "episode/length": 50.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 678824, "time": 31394.284673690796, "episode/length": 252.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9723320158102767, "episode/intrinsic_return": 0.0}
{"step": 679480, "time": 31418.27942633629, "episode/length": 185.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 680016, "time": 31440.157012462616, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 680048, "time": 31442.831692695618, "episode/length": 152.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 31465.603526353836, "eval_episode/length": 174.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 680056, "time": 31467.896291017532, "eval_episode/length": 192.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 680056, "time": 31470.177465438843, "eval_episode/length": 209.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 680056, "time": 31471.878233909607, "eval_episode/length": 213.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 680056, "time": 31473.8832116127, "eval_episode/length": 221.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 680056, "time": 31477.037487506866, "eval_episode/length": 258.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9961389961389961}
{"step": 680056, "time": 31479.981649637222, "eval_episode/length": 290.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9862542955326461}
{"step": 680056, "time": 31486.049907922745, "eval_episode/length": 170.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9649122807017544}
{"step": 680240, "time": 31492.618499994278, "episode/length": 370.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9946091644204852, "episode/intrinsic_return": 0.0}
{"step": 680328, "time": 31496.921797275543, "episode/length": 301.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9900662251655629, "episode/intrinsic_return": 0.0}
{"step": 681000, "time": 31521.284927845, "episode/length": 189.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 681312, "time": 31533.658974170685, "episode/length": 434.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9977011494252873, "episode/intrinsic_return": 0.0}
{"step": 681312, "time": 31533.669546842575, "episode/length": 336.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9910979228486647, "episode/intrinsic_return": 0.0}
{"step": 681584, "time": 31546.468866825104, "episode/length": 191.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 681688, "time": 31551.38472056389, "episode/length": 208.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 681896, "time": 31560.028542757034, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 681952, "time": 31563.667016506195, "episode/length": 202.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 682160, "time": 31572.215240478516, "episode/length": 514.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9980582524271845, "episode/intrinsic_return": 0.0}
{"step": 682600, "time": 31588.588505744934, "episode/length": 160.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 683296, "time": 31614.022916555405, "episode/length": 174.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 683352, "time": 31617.240530014038, "episode/length": 293.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9863945578231292, "episode/intrinsic_return": 0.0}
{"step": 683416, "time": 31621.005623340607, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 683688, "time": 31631.63125896454, "episode/length": 190.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 684520, "time": 31661.165308713913, "episode/length": 400.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9975062344139651, "episode/intrinsic_return": 0.0}
{"step": 684528, "time": 31663.307931900024, "episode/length": 367.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9918478260869565, "episode/intrinsic_return": 0.0}
{"step": 684584, "time": 31666.73622250557, "episode/length": 247.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 684712, "time": 31672.57023501396, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 684736, "time": 31675.177588701248, "episode/length": 380.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.994750656167979, "episode/intrinsic_return": 0.0}
{"step": 684928, "time": 31683.29318881035, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 685272, "time": 31696.437733650208, "episode/length": 246.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 685736, "time": 31713.853842020035, "episode/length": 255.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 685840, "time": 31719.84617137909, "episode/length": 156.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 685984, "time": 31726.872919797897, "episode/length": 181.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 686448, "time": 31744.155878305435, "episode/length": 213.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 686448, "time": 31744.167920827866, "episode/length": 216.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 686656, "time": 31754.402596235275, "episode/length": 266.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 686960, "time": 31766.510504961014, "episode/length": 139.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 687144, "time": 31774.033024072647, "episode/length": 276.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 687240, "time": 31778.959707021713, "episode/length": 187.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 687312, "time": 31783.27926015854, "episode/length": 107.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 687784, "time": 31800.59128499031, "episode/length": 313.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9808917197452229, "episode/intrinsic_return": 0.0}
{"step": 687928, "time": 31807.019419431686, "episode/length": 242.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 688168, "time": 31818.48093676567, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 688304, "time": 31824.916394472122, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 688424, "time": 31830.32954645157, "episode/length": 159.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 688600, "time": 31837.98226928711, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 688672, "time": 31842.18578696251, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 689064, "time": 31856.774451971054, "episode/length": 159.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 689744, "time": 31882.17145061493, "episode/length": 196.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 690008, "time": 31892.39767599106, "episode/length": 444.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9977528089887641, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 31918.13199853897, "eval_episode/length": 168.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 690040, "time": 31919.776280403137, "eval_episode/length": 169.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 690040, "time": 31922.198827266693, "eval_episode/length": 186.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 690040, "time": 31923.918108940125, "eval_episode/length": 187.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9840425531914894}
{"step": 690040, "time": 31927.563461780548, "eval_episode/length": 232.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 690040, "time": 31932.10127878189, "eval_episode/length": 294.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9966101694915255}
{"step": 690040, "time": 31935.400316476822, "eval_episode/length": 163.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9634146341463414}
{"step": 690040, "time": 31937.71730518341, "eval_episode/length": 344.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9884057971014493}
{"step": 690720, "time": 31960.868444919586, "episode/length": 255.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.97265625, "episode/intrinsic_return": 0.0}
{"step": 690792, "time": 31964.628211975098, "episode/length": 295.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 690808, "time": 31967.121571302414, "episode/length": 359.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 690984, "time": 31974.70929121971, "episode/length": 239.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9708333333333333, "episode/intrinsic_return": 0.0}
{"step": 691088, "time": 31979.935268878937, "episode/length": 45.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 691152, "time": 31983.697936296463, "episode/length": 175.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 691232, "time": 31988.041885137558, "episode/length": 328.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9817629179331308, "episode/intrinsic_return": 0.0}
{"step": 691400, "time": 31995.16444516182, "episode/length": 173.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 691720, "time": 32007.584304094315, "episode/length": 113.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9912280701754386, "episode/intrinsic_return": 0.0}
{"step": 692304, "time": 32029.27569460869, "episode/length": 151.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 692384, "time": 32033.605797052383, "episode/length": 509.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 692480, "time": 32038.425458192825, "episode/length": 186.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 693120, "time": 32061.87955904007, "episode/length": 245.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9715447154471545, "episode/intrinsic_return": 0.0}
{"step": 693352, "time": 32071.012861013412, "episode/length": 243.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 693408, "time": 32074.838195323944, "episode/length": 137.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 693832, "time": 32090.661549329758, "episode/length": 379.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 693928, "time": 32095.433970451355, "episode/length": 336.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9910979228486647, "episode/intrinsic_return": 0.0}
{"step": 693968, "time": 32098.64494895935, "episode/length": 280.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 694608, "time": 32121.868208646774, "episode/length": 185.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 694664, "time": 32125.16876268387, "episode/length": 284.0, "episode/score": 12.100000075995922, "episode/reward_rate": 0.9964912280701754, "episode/intrinsic_return": 0.0}
{"step": 694736, "time": 32129.470436811447, "episode/length": 112.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9911504424778761, "episode/intrinsic_return": 0.0}
{"step": 694776, "time": 32132.196389198303, "episode/length": 286.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790940766550522, "episode/intrinsic_return": 0.0}
{"step": 695112, "time": 32145.044761657715, "episode/length": 219.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9681818181818181, "episode/intrinsic_return": 0.0}
{"step": 695312, "time": 32153.8325445652, "episode/length": 237.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 695512, "time": 32161.967049121857, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 695856, "time": 32175.523703098297, "episode/length": 139.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 696376, "time": 32196.42734026909, "episode/length": 220.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 696408, "time": 32199.17139530182, "episode/length": 304.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.980327868852459, "episode/intrinsic_return": 0.0}
{"step": 696568, "time": 32206.22387433052, "episode/length": 237.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 697408, "time": 32236.59105157852, "episode/length": 286.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9965156794425087, "episode/intrinsic_return": 0.0}
{"step": 697528, "time": 32241.981927871704, "episode/length": 251.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 697680, "time": 32248.934131145477, "episode/length": 295.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 698248, "time": 32269.465254068375, "episode/length": 433.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 698336, "time": 32274.303590536118, "episode/length": 309.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 698640, "time": 32286.22861981392, "episode/length": 282.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 698672, "time": 32289.33851003647, "episode/length": 282.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9752650176678446, "episode/intrinsic_return": 0.0}
{"step": 699264, "time": 32311.07971048355, "episode/length": 216.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 699848, "time": 32332.69180727005, "episode/length": 270.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.977859778597786, "episode/intrinsic_return": 0.0}
{"step": 699872, "time": 32335.38036775589, "episode/length": 307.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9967532467532467, "episode/intrinsic_return": 0.0}
{"step": 699992, "time": 32340.735314130783, "episode/length": 168.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.0}
{"step": 700024, "time": 32364.49254655838, "eval_episode/length": 169.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 700024, "time": 32366.706757307053, "eval_episode/length": 183.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 700024, "time": 32368.73612523079, "eval_episode/length": 192.0, "eval_episode/score": 9.100000031292439, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 700024, "time": 32370.47792005539, "eval_episode/length": 196.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9644670050761421}
{"step": 700024, "time": 32372.21979689598, "eval_episode/length": 199.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.995}
{"step": 700024, "time": 32372.22807121277, "eval_episode/length": 199.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.995}
{"step": 700024, "time": 32377.686982631683, "eval_episode/length": 244.0, "eval_episode/score": 11.100000016391277, "eval_episode/reward_rate": 0.9959183673469387}
{"step": 700024, "time": 32379.61527776718, "eval_episode/length": 51.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 700025, "time": 32380.655747413635, "train_stats/sum_log_reward": 9.583146304226993, "train_stats/max_log_achievement_collect_coal": 0.48314606741573035, "train_stats/max_log_achievement_collect_drink": 3.764044943820225, "train_stats/max_log_achievement_collect_iron": 0.011235955056179775, "train_stats/max_log_achievement_collect_sapling": 1.7303370786516854, "train_stats/max_log_achievement_collect_stone": 9.853932584269662, "train_stats/max_log_achievement_collect_wood": 11.685393258426966, "train_stats/max_log_achievement_defeat_skeleton": 0.033707865168539325, "train_stats/max_log_achievement_defeat_zombie": 0.9213483146067416, "train_stats/max_log_achievement_eat_cow": 0.14606741573033707, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.056179775280898875, "train_stats/max_log_achievement_make_stone_sword": 0.011235955056179775, "train_stats/max_log_achievement_make_wood_pickaxe": 1.8314606741573034, "train_stats/max_log_achievement_make_wood_sword": 1.4269662921348314, "train_stats/max_log_achievement_place_furnace": 0.2808988764044944, "train_stats/max_log_achievement_place_plant": 1.696629213483146, "train_stats/max_log_achievement_place_stone": 7.01123595505618, "train_stats/max_log_achievement_place_table": 3.247191011235955, "train_stats/max_log_achievement_wake_up": 1.797752808988764, "train_stats/mean_log_entropy": 0.6443132486905945, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.445956710481296, "train/action_min": 0.0, "train/action_std": 3.201690856557693, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.036932609907358235, "train/actor_opt_grad_steps": 42970.0, "train/actor_opt_loss": -4.838256976682774, "train/adv_mag": 0.47180613636100377, "train/adv_max": 0.41814881758968325, "train/adv_mean": 0.0029501594734984878, "train/adv_min": -0.3868997070911157, "train/adv_std": 0.05449741472401758, "train/cont_avg": 0.9949532390510949, "train/cont_loss_mean": 0.00015479920641419217, "train/cont_loss_std": 0.004706722530565531, "train/cont_neg_acc": 0.9962200213522807, "train/cont_neg_loss": 0.01051372136518601, "train/cont_pos_acc": 0.9999713249450183, "train/cont_pos_loss": 9.132777221127377e-05, "train/cont_pred": 0.9949484406596553, "train/cont_rate": 0.9949532390510949, "train/dyn_loss_mean": 12.902523207838518, "train/dyn_loss_std": 9.370967677039822, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9492441481047303, "train/extr_critic_critic_opt_grad_steps": 42970.0, "train/extr_critic_critic_opt_loss": 15445.374558052008, "train/extr_critic_mag": 8.663314499124123, "train/extr_critic_max": 8.663314499124123, "train/extr_critic_mean": 2.950862416385734, "train/extr_critic_min": -0.17067516633193858, "train/extr_critic_std": 2.0055779575431436, "train/extr_return_normed_mag": 1.5044422819666619, "train/extr_return_normed_max": 1.5044422819666619, "train/extr_return_normed_mean": 0.4077223732958745, "train/extr_return_normed_min": -0.13855185571813236, "train/extr_return_normed_std": 0.32160552085316096, "train/extr_return_rate": 0.9301988804427377, "train/extr_return_raw_mag": 9.907440916465147, "train/extr_return_raw_max": 9.907440916465147, "train/extr_return_raw_mean": 2.9695228364345803, "train/extr_return_raw_min": -0.48655637674523095, "train/extr_return_raw_std": 2.03479694885059, "train/extr_reward_mag": 1.0323908120176217, "train/extr_reward_max": 1.0323908120176217, "train/extr_reward_mean": 0.04211998316221428, "train/extr_reward_min": -0.43127614825311367, "train/extr_reward_std": 0.19079126874460792, "train/image_loss_mean": 6.421826999552929, "train/image_loss_std": 11.306621092079329, "train/model_loss_mean": 14.218526519998147, "train/model_loss_std": 15.26069338304283, "train/model_opt_grad_norm": 52.563942665601296, "train/model_opt_grad_steps": 42933.71532846715, "train/model_opt_loss": 18412.554430885037, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1295.6204379562043, "train/policy_entropy_mag": 2.486076669971438, "train/policy_entropy_max": 2.486076669971438, "train/policy_entropy_mean": 0.5548695188804265, "train/policy_entropy_min": 0.07937506216503408, "train/policy_entropy_std": 0.6561935879018185, "train/policy_logprob_mag": 7.4383837219572415, "train/policy_logprob_max": -0.009455662744160551, "train/policy_logprob_mean": -0.5543851352086032, "train/policy_logprob_min": -7.4383837219572415, "train/policy_logprob_std": 1.1026694557092485, "train/policy_randomness_mag": 0.8774759656321394, "train/policy_randomness_max": 0.8774759656321394, "train/policy_randomness_mean": 0.19584459273049432, "train/policy_randomness_min": 0.028015913659312427, "train/policy_randomness_std": 0.23160753817888943, "train/post_ent_mag": 60.526008160444945, "train/post_ent_max": 60.526008160444945, "train/post_ent_mean": 43.41255240892842, "train/post_ent_min": 20.9784543392432, "train/post_ent_std": 7.517224002058488, "train/prior_ent_mag": 70.82292308946596, "train/prior_ent_max": 70.82292308946596, "train/prior_ent_mean": 56.37032760842873, "train/prior_ent_min": 42.895860184718224, "train/prior_ent_std": 4.700752808229766, "train/rep_loss_mean": 12.902523207838518, "train/rep_loss_std": 9.370967677039822, "train/reward_avg": 0.028790060376381352, "train/reward_loss_mean": 0.05503092248019946, "train/reward_loss_std": 0.24410522343033422, "train/reward_max_data": 1.0197080338958406, "train/reward_max_pred": 1.0132303177005184, "train/reward_neg_acc": 0.9929570660103847, "train/reward_neg_loss": 0.028439966145984447, "train/reward_pos_acc": 0.9704467166949363, "train/reward_pos_loss": 0.8335990148739223, "train/reward_pred": 0.028178911227868857, "train/reward_rate": 0.03303917655109489, "eval_stats/sum_log_reward": 9.225000143051147, "eval_stats/max_log_achievement_collect_coal": 0.6666666666666666, "eval_stats/max_log_achievement_collect_drink": 4.041666666666667, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.7083333333333333, "eval_stats/max_log_achievement_collect_stone": 8.375, "eval_stats/max_log_achievement_collect_wood": 10.708333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5833333333333334, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.7916666666666667, "eval_stats/max_log_achievement_make_wood_sword": 1.4166666666666667, "eval_stats/max_log_achievement_place_furnace": 0.041666666666666664, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_stone": 5.666666666666667, "eval_stats/max_log_achievement_place_table": 3.0833333333333335, "eval_stats/max_log_achievement_wake_up": 1.4583333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.381085348839406e-05, "report/cont_loss_std": 0.00040355234523303807, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.004546586889773607, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.922180778521579e-07, "report/cont_pred": 0.9970831871032715, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.953971862792969, "report/dyn_loss_std": 9.061212539672852, "report/image_loss_mean": 5.584753036499023, "report/image_loss_std": 9.753034591674805, "report/model_loss_mean": 13.40661907196045, "report/model_loss_std": 13.71261215209961, "report/post_ent_mag": 59.93210983276367, "report/post_ent_max": 59.93210983276367, "report/post_ent_mean": 42.25138854980469, "report/post_ent_min": 21.35605239868164, "report/post_ent_std": 7.345903396606445, "report/prior_ent_mag": 71.00553894042969, "report/prior_ent_max": 71.00553894042969, "report/prior_ent_mean": 55.704681396484375, "report/prior_ent_min": 39.534996032714844, "report/prior_ent_std": 4.465785980224609, "report/rep_loss_mean": 12.953971862792969, "report/rep_loss_std": 9.061212539672852, "report/reward_avg": 0.02998046949505806, "report/reward_loss_mean": 0.049470216035842896, "report/reward_loss_std": 0.167047917842865, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0967109203338623, "report/reward_neg_acc": 0.9808080196380615, "report/reward_neg_loss": 0.02771809697151184, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6828406453132629, "report/reward_pred": 0.030962416902184486, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 4.2042796849273145e-05, "eval/cont_loss_std": 0.0007525153923779726, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.005107587669044733, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.7187330740853213e-05, "eval/cont_pred": 0.9951250553131104, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.693260192871094, "eval/dyn_loss_std": 10.614404678344727, "eval/image_loss_mean": 11.638374328613281, "eval/image_loss_std": 13.01844310760498, "eval/model_loss_mean": 21.756542205810547, "eval/model_loss_std": 17.381643295288086, "eval/post_ent_mag": 61.803184509277344, "eval/post_ent_max": 61.803184509277344, "eval/post_ent_mean": 43.21232223510742, "eval/post_ent_min": 20.94386863708496, "eval/post_ent_std": 8.072896003723145, "eval/prior_ent_mag": 71.00553894042969, "eval/prior_ent_max": 71.00553894042969, "eval/prior_ent_mean": 57.8065185546875, "eval/prior_ent_min": 46.795494079589844, "eval/prior_ent_std": 4.428060054779053, "eval/rep_loss_mean": 16.693260192871094, "eval/rep_loss_std": 10.614404678344727, "eval/reward_avg": 0.02285156399011612, "eval/reward_loss_mean": 0.10216964781284332, "eval/reward_loss_std": 0.6169456839561462, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0005826950073242, "eval/reward_neg_acc": 0.9939698576927185, "eval/reward_neg_loss": 0.04322803393006325, "eval/reward_pos_acc": 0.7586206793785095, "eval/reward_pos_loss": 2.124476432800293, "eval/reward_pred": 0.014917200431227684, "eval/reward_rate": 0.0283203125, "replay/size": 699521.0, "replay/inserts": 21984.0, "replay/samples": 21984.0, "replay/insert_wait_avg": 1.415002988068471e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.410072448819312e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7920.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2802656250770645e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1324882507324219e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1017.420396566391, "timer/env.step_count": 2748.0, "timer/env.step_total": 222.28102159500122, "timer/env.step_frac": 0.21847509873515342, "timer/env.step_avg": 0.08088829024563363, "timer/env.step_min": 0.024010896682739258, "timer/env.step_max": 3.505908966064453, "timer/replay._sample_count": 21984.0, "timer/replay._sample_total": 11.948701620101929, "timer/replay._sample_frac": 0.011744114488393024, "timer/replay._sample_avg": 0.0005435180867950295, "timer/replay._sample_min": 0.00042128562927246094, "timer/replay._sample_max": 0.011921167373657227, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3738.0, "timer/agent.policy_total": 65.14850497245789, "timer/agent.policy_frac": 0.06403302429587833, "timer/agent.policy_avg": 0.0174287065201867, "timer/agent.policy_min": 0.009647607803344727, "timer/agent.policy_max": 0.16605806350708008, "timer/dataset_train_count": 1374.0, "timer/dataset_train_total": 0.15552186965942383, "timer/dataset_train_frac": 0.00015285900517060782, "timer/dataset_train_avg": 0.00011318913366770293, "timer/dataset_train_min": 9.965896606445312e-05, "timer/dataset_train_max": 0.0003676414489746094, "timer/agent.train_count": 1374.0, "timer/agent.train_total": 622.5042161941528, "timer/agent.train_frac": 0.6118456228074368, "timer/agent.train_avg": 0.45305983711364833, "timer/agent.train_min": 0.43870973587036133, "timer/agent.train_max": 1.796213150024414, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47689366340637207, "timer/agent.report_frac": 0.0004687282317278104, "timer/agent.report_avg": 0.23844683170318604, "timer/agent.report_min": 0.2303779125213623, "timer/agent.report_max": 0.24651575088500977, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.1635406845915964e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 21.607257013169704}
{"step": 700144, "time": 32384.765869140625, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 700176, "time": 32387.641716957092, "episode/length": 40.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 700240, "time": 32391.40468811989, "episode/length": 237.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 700240, "time": 32391.41770553589, "episode/length": 458.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9912854030501089, "episode/intrinsic_return": 0.0}
{"step": 700568, "time": 32406.3326587677, "episode/length": 48.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 700936, "time": 32420.507697820663, "episode/length": 335.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 701096, "time": 32427.55828666687, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 701472, "time": 32442.01497030258, "episode/length": 153.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 701672, "time": 32450.28079175949, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 701720, "time": 32453.540190458298, "episode/length": 184.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 702032, "time": 32465.866135835648, "episode/length": 269.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 702560, "time": 32485.683008909225, "episode/length": 202.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 702704, "time": 32492.199583768845, "episode/length": 319.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.990625, "episode/intrinsic_return": 0.0}
{"step": 703080, "time": 32506.387650489807, "episode/length": 247.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 703184, "time": 32511.77293777466, "episode/length": 326.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9938837920489296, "episode/intrinsic_return": 0.0}
{"step": 703184, "time": 32511.781105041504, "episode/length": 182.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9890710382513661, "episode/intrinsic_return": 0.0}
{"step": 703256, "time": 32517.312781333923, "episode/length": 197.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 704040, "time": 32545.680388450623, "episode/length": 184.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9837837837837838, "episode/intrinsic_return": 0.0}
{"step": 704488, "time": 32562.427451372147, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 704544, "time": 32568.29634451866, "episode/length": 229.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 704680, "time": 32574.40997195244, "episode/length": 186.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 704944, "time": 32585.19508266449, "episode/length": 433.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 705120, "time": 32592.59655547142, "episode/length": 254.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 705224, "time": 32597.683822870255, "episode/length": 245.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 705384, "time": 32604.629842042923, "episode/length": 418.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9952267303102625, "episode/intrinsic_return": 0.0}
{"step": 705408, "time": 32607.301830530167, "episode/length": 170.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 706112, "time": 32632.67577147484, "episode/length": 178.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 706120, "time": 32634.377240419388, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 706544, "time": 32650.61837029457, "episode/length": 249.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 706648, "time": 32655.533247232437, "episode/length": 65.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 706768, "time": 32661.6346077919, "episode/length": 227.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 706800, "time": 32664.298305749893, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 706800, "time": 32664.307685136795, "episode/length": 196.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 707096, "time": 32677.43494963646, "episode/length": 210.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 707768, "time": 32701.862380504608, "episode/length": 297.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765100671140939, "episode/intrinsic_return": 0.0}
{"step": 707840, "time": 32706.176260232925, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9675925925925926, "episode/intrinsic_return": 0.0}
{"step": 708464, "time": 32729.016230106354, "episode/length": 226.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 708640, "time": 32736.522451639175, "episode/length": 229.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 709096, "time": 32753.552298784256, "episode/length": 318.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9843260188087775, "episode/intrinsic_return": 0.0}
{"step": 709232, "time": 32759.998187303543, "episode/length": 303.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9835526315789473, "episode/intrinsic_return": 0.0}
{"step": 709400, "time": 32766.92204475403, "episode/length": 328.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 709584, "time": 32774.979111909866, "episode/length": 139.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 709712, "time": 32781.121347904205, "episode/length": 326.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9877675840978594, "episode/intrinsic_return": 0.0}
{"step": 709728, "time": 32783.21513271332, "episode/length": 244.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 709952, "time": 32792.338957071304, "episode/length": 68.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 32810.73519158363, "eval_episode/length": 45.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 710008, "time": 32817.31427383423, "eval_episode/length": 160.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9751552795031055}
{"step": 710008, "time": 32820.53348636627, "eval_episode/length": 192.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 710008, "time": 32822.71052789688, "eval_episode/length": 203.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 710008, "time": 32824.77364587784, "eval_episode/length": 214.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9953488372093023}
{"step": 710008, "time": 32826.82578372955, "eval_episode/length": 225.0, "eval_episode/score": 7.1000000312924385, "eval_episode/reward_rate": 0.995575221238938}
{"step": 710008, "time": 32828.80265855789, "eval_episode/length": 185.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9623655913978495}
{"step": 710008, "time": 32832.357815504074, "eval_episode/length": 43.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 710448, "time": 32849.38235616684, "episode/length": 151.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 710520, "time": 32853.20147061348, "episode/length": 334.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.991044776119403, "episode/intrinsic_return": 0.0}
{"step": 710560, "time": 32856.26699471474, "episode/length": 75.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 710832, "time": 32867.19758582115, "episode/length": 155.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 711432, "time": 32888.829639196396, "episode/length": 214.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 711512, "time": 32893.02954292297, "episode/length": 358.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9916434540389972, "episode/intrinsic_return": 0.0}
{"step": 711920, "time": 32908.78191947937, "episode/length": 60.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 712232, "time": 32920.452719926834, "episode/length": 89.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 712280, "time": 32923.70643115044, "episode/length": 397.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9974874371859297, "episode/intrinsic_return": 0.0}
{"step": 712520, "time": 32933.49841451645, "episode/length": 258.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 712552, "time": 32936.21519494057, "episode/length": 253.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 712880, "time": 32950.81358790398, "episode/length": 255.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 713168, "time": 32962.26567149162, "episode/length": 325.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9969325153374233, "episode/intrinsic_return": 0.0}
{"step": 713384, "time": 32970.88594818115, "episode/length": 182.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 713592, "time": 32979.45644545555, "episode/length": 52.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 713688, "time": 32984.386880636215, "episode/length": 175.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 713968, "time": 32995.80408644676, "episode/length": 216.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 713992, "time": 32998.03248143196, "episode/length": 179.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 714104, "time": 33003.39916968346, "episode/length": 197.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 714824, "time": 33029.40512704849, "episode/length": 242.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 714880, "time": 33033.22105169296, "episode/length": 186.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 715240, "time": 33046.861924409866, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 715320, "time": 33051.24130868912, "episode/length": 203.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 715512, "time": 33059.28805923462, "episode/length": 239.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 715584, "time": 33063.52387261391, "episode/length": 184.0, "episode/score": 12.100000038743019, "episode/reward_rate": 0.9837837837837838, "episode/intrinsic_return": 0.0}
{"step": 716192, "time": 33085.73186182976, "episode/length": 163.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 716344, "time": 33092.259086847305, "episode/length": 293.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 716880, "time": 33112.40365123749, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 717200, "time": 33124.7046186924, "episode/length": 244.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 717600, "time": 33140.0369784832, "episode/length": 346.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9884726224783862, "episode/intrinsic_return": 0.0}
{"step": 717720, "time": 33145.443143844604, "episode/length": 266.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 718144, "time": 33161.41911101341, "episode/length": 243.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 718160, "time": 33163.56732869148, "episode/length": 1053.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9857685009487666, "episode/intrinsic_return": 0.0}
{"step": 718264, "time": 33168.70972132683, "episode/length": 239.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 718432, "time": 33176.244426727295, "episode/length": 193.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 718632, "time": 33184.42043328285, "episode/length": 413.0, "episode/score": 14.100000008940697, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 718648, "time": 33186.687415122986, "episode/length": 47.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 719384, "time": 33213.2184715271, "episode/length": 207.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 719560, "time": 33220.74498438835, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 719832, "time": 33231.63912153244, "episode/length": 278.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 719856, "time": 33234.3006811142, "episode/length": 213.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 719968, "time": 33239.656740665436, "episode/length": 72.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 720096, "time": 33265.82523751259, "eval_episode/length": 155.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 720096, "time": 33271.06212735176, "eval_episode/length": 193.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 720096, "time": 33274.251922369, "eval_episode/length": 229.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 720096, "time": 33276.62769174576, "eval_episode/length": 245.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9959349593495935}
{"step": 720096, "time": 33281.24940466881, "eval_episode/length": 157.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 720096, "time": 33283.2288043499, "eval_episode/length": 322.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9969040247678018}
{"step": 720096, "time": 33284.93981933594, "eval_episode/length": 326.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9877675840978594}
{"step": 720096, "time": 33287.18725967407, "eval_episode/length": 336.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9940652818991098}
{"step": 720208, "time": 33290.971244096756, "episode/length": 221.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 720448, "time": 33300.60451412201, "episode/length": 405.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 720704, "time": 33310.94338274002, "episode/length": 258.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 720776, "time": 33314.84088039398, "episode/length": 265.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 721120, "time": 33330.05551147461, "episode/length": 194.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 721312, "time": 33338.11972618103, "episode/length": 181.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 721344, "time": 33340.67502140999, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 722160, "time": 33369.94571661949, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 722392, "time": 33379.46164870262, "episode/length": 302.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.0}
{"step": 722393, "time": 33382.057118177414, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.488646589006696, "train/action_min": 0.0, "train/action_std": 3.3006713134901866, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03695601729143943, "train/actor_opt_grad_steps": 44355.0, "train/actor_opt_loss": -5.1666384612875325, "train/adv_mag": 0.49037124386855535, "train/adv_max": 0.44720266993556707, "train/adv_mean": 0.00297756741426513, "train/adv_min": -0.39933674101318634, "train/adv_std": 0.053839777436639584, "train/cont_avg": 0.9955845424107143, "train/cont_loss_mean": 0.000242322558044553, "train/cont_loss_std": 0.00742475161918849, "train/cont_neg_acc": 0.9943877565009254, "train/cont_neg_loss": 0.03144483803425828, "train/cont_pos_acc": 0.9999719470739364, "train/cont_pos_loss": 8.628100315034105e-05, "train/cont_pred": 0.9955815059798104, "train/cont_rate": 0.9955845424107143, "train/dyn_loss_mean": 12.872952583857945, "train/dyn_loss_std": 9.350639683859688, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9760820554835455, "train/extr_critic_critic_opt_grad_steps": 44355.0, "train/extr_critic_critic_opt_loss": 15432.647426060268, "train/extr_critic_mag": 8.77693294116429, "train/extr_critic_max": 8.77693294116429, "train/extr_critic_mean": 2.9231488602502007, "train/extr_critic_min": -0.15541133454867773, "train/extr_critic_std": 1.974236512184143, "train/extr_return_normed_mag": 1.4908746753420148, "train/extr_return_normed_max": 1.4908746753420148, "train/extr_return_normed_mean": 0.39476639213306564, "train/extr_return_normed_min": -0.14189224088830607, "train/extr_return_normed_std": 0.31434341477496286, "train/extr_return_rate": 0.9360696175268718, "train/extr_return_raw_mag": 9.930405896050589, "train/extr_return_raw_max": 9.930405896050589, "train/extr_return_raw_mean": 2.94211505481175, "train/extr_return_raw_min": -0.4794414097709315, "train/extr_return_raw_std": 2.004282719748361, "train/extr_reward_mag": 1.0344807488577707, "train/extr_reward_max": 1.0344807488577707, "train/extr_reward_mean": 0.0409929035098425, "train/extr_reward_min": -0.4245070116860526, "train/extr_reward_std": 0.18781593484537942, "train/image_loss_mean": 6.458992576599121, "train/image_loss_std": 11.300660603387016, "train/model_loss_mean": 14.237185232979911, "train/model_loss_std": 15.215662547520228, "train/model_opt_grad_norm": 58.08684392970243, "train/model_opt_grad_steps": 44317.3, "train/model_opt_loss": 16922.211073521205, "train/model_opt_model_opt_grad_overflow": 0.007142857142857143, "train/model_opt_model_opt_grad_scale": 1187.5, "train/policy_entropy_mag": 2.5050240755081177, "train/policy_entropy_max": 2.5050240755081177, "train/policy_entropy_mean": 0.5775773968015399, "train/policy_entropy_min": 0.07937507677291121, "train/policy_entropy_std": 0.683857479265758, "train/policy_logprob_mag": 7.438383766583034, "train/policy_logprob_max": -0.009455665167687194, "train/policy_logprob_mean": -0.5779419356158801, "train/policy_logprob_min": -7.438383766583034, "train/policy_logprob_std": 1.1179972141981125, "train/policy_randomness_mag": 0.8841635708298002, "train/policy_randomness_max": 0.8841635708298002, "train/policy_randomness_mean": 0.2038594744035176, "train/policy_randomness_min": 0.028015918776925122, "train/policy_randomness_std": 0.2413716804768358, "train/post_ent_mag": 60.814253779820035, "train/post_ent_max": 60.814253779820035, "train/post_ent_mean": 43.555687931605746, "train/post_ent_min": 21.022704069955008, "train/post_ent_std": 7.560774874687195, "train/prior_ent_mag": 70.84372291564941, "train/prior_ent_max": 70.84372291564941, "train/prior_ent_mean": 56.46906179700579, "train/prior_ent_min": 42.90870516640799, "train/prior_ent_std": 4.730698602540152, "train/rep_loss_mean": 12.872952583857945, "train/rep_loss_std": 9.350639683859688, "train/reward_avg": 0.027769949566572905, "train/reward_loss_mean": 0.05417889319360256, "train/reward_loss_std": 0.24565622923629624, "train/reward_max_data": 1.0178571471146174, "train/reward_max_pred": 1.0102777353354864, "train/reward_neg_acc": 0.9928929844072887, "train/reward_neg_loss": 0.028238913643040826, "train/reward_pos_acc": 0.9710733413696289, "train/reward_pos_loss": 0.843939813545772, "train/reward_pred": 0.02708530131993549, "train/reward_rate": 0.03194056919642857, "train_stats/sum_log_reward": 9.162500177820524, "train_stats/max_log_achievement_collect_coal": 0.46875, "train_stats/max_log_achievement_collect_drink": 5.375, "train_stats/max_log_achievement_collect_iron": 0.010416666666666666, "train_stats/max_log_achievement_collect_sapling": 1.5520833333333333, "train_stats/max_log_achievement_collect_stone": 8.583333333333334, "train_stats/max_log_achievement_collect_wood": 11.0625, "train_stats/max_log_achievement_defeat_skeleton": 0.03125, "train_stats/max_log_achievement_defeat_zombie": 0.75, "train_stats/max_log_achievement_eat_cow": 0.21875, "train_stats/max_log_achievement_eat_plant": 0.010416666666666666, "train_stats/max_log_achievement_make_stone_pickaxe": 0.07291666666666667, "train_stats/max_log_achievement_make_stone_sword": 0.010416666666666666, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5, "train_stats/max_log_achievement_make_wood_sword": 1.03125, "train_stats/max_log_achievement_place_furnace": 0.28125, "train_stats/max_log_achievement_place_plant": 1.5, "train_stats/max_log_achievement_place_stone": 5.625, "train_stats/max_log_achievement_place_table": 3.1145833333333335, "train_stats/max_log_achievement_wake_up": 1.5208333333333333, "train_stats/mean_log_entropy": 0.5931835348407427, "eval_stats/sum_log_reward": 8.475000232458115, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 5.5, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 5.875, "eval_stats/max_log_achievement_collect_wood": 10.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.875, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1875, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 0.25, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 3.8125, "eval_stats/max_log_achievement_place_table": 2.875, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 2.917275423897081e-06, "report/cont_loss_std": 3.365182055858895e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00012635462917387486, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.5545798507664585e-06, "report/cont_pred": 0.9970681667327881, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 11.794906616210938, "report/dyn_loss_std": 9.000045776367188, "report/image_loss_mean": 6.144057750701904, "report/image_loss_std": 8.254199981689453, "report/model_loss_mean": 13.258062362670898, "report/model_loss_std": 12.122230529785156, "report/post_ent_mag": 60.10426330566406, "report/post_ent_max": 60.10426330566406, "report/post_ent_mean": 45.055850982666016, "report/post_ent_min": 18.347816467285156, "report/post_ent_std": 7.679515838623047, "report/prior_ent_mag": 71.15520477294922, "report/prior_ent_max": 71.15520477294922, "report/prior_ent_mean": 56.8714599609375, "report/prior_ent_min": 44.16681671142578, "report/prior_ent_std": 4.985764026641846, "report/rep_loss_mean": 11.794906616210938, "report/rep_loss_std": 9.000045776367188, "report/reward_avg": 0.02812499925494194, "report/reward_loss_mean": 0.03705797716975212, "report/reward_loss_std": 0.16117028892040253, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011320114135742, "report/reward_neg_acc": 0.9969818592071533, "report/reward_neg_loss": 0.016918644309043884, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7043413519859314, "report/reward_pred": 0.027284637093544006, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00425930880010128, "eval/cont_loss_std": 0.09894087165594101, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 1.0900501012802124, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.3059928960501566e-06, "eval/cont_pred": 0.9977952241897583, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.215984344482422, "eval/dyn_loss_std": 10.925806045532227, "eval/image_loss_mean": 9.920221328735352, "eval/image_loss_std": 16.461496353149414, "eval/model_loss_mean": 19.780179977416992, "eval/model_loss_std": 21.116302490234375, "eval/post_ent_mag": 58.61191177368164, "eval/post_ent_max": 58.61191177368164, "eval/post_ent_mean": 43.47810363769531, "eval/post_ent_min": 21.03579330444336, "eval/post_ent_std": 7.940121650695801, "eval/prior_ent_mag": 71.15520477294922, "eval/prior_ent_max": 71.15520477294922, "eval/prior_ent_mean": 56.882049560546875, "eval/prior_ent_min": 44.671104431152344, "eval/prior_ent_std": 4.457230567932129, "eval/rep_loss_mean": 16.215984344482422, "eval/rep_loss_std": 10.925806045532227, "eval/reward_avg": 0.0322265625, "eval/reward_loss_mean": 0.1261085867881775, "eval/reward_loss_std": 0.7667596936225891, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0004892349243164, "eval/reward_neg_acc": 0.9848178625106812, "eval/reward_neg_loss": 0.0695321336388588, "eval/reward_pos_acc": 0.8611111044883728, "eval/reward_pos_loss": 1.678817868232727, "eval/reward_pred": 0.03231596201658249, "eval/reward_rate": 0.03515625, "replay/size": 721889.0, "replay/inserts": 22368.0, "replay/samples": 22368.0, "replay/insert_wait_avg": 1.4233167079385258e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.208448625600048e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4904.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2635601286398062e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.3523535728455, "timer/env.step_count": 2796.0, "timer/env.step_total": 235.20418429374695, "timer/env.step_frac": 0.23488653464940054, "timer/env.step_avg": 0.08412166820234154, "timer/env.step_min": 0.024685382843017578, "timer/env.step_max": 3.9734132289886475, "timer/replay._sample_count": 22368.0, "timer/replay._sample_total": 12.134423732757568, "timer/replay._sample_frac": 0.012118035863661477, "timer/replay._sample_avg": 0.0005424903314001059, "timer/replay._sample_min": 0.0004124641418457031, "timer/replay._sample_max": 0.026040077209472656, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3409.0, "timer/agent.policy_total": 59.68486475944519, "timer/agent.policy_frac": 0.059604258727198656, "timer/agent.policy_avg": 0.01750802721016286, "timer/agent.policy_min": 0.00965428352355957, "timer/agent.policy_max": 0.13231134414672852, "timer/dataset_train_count": 1398.0, "timer/dataset_train_total": 0.1603102684020996, "timer/dataset_train_frac": 0.0001600937650269751, "timer/dataset_train_avg": 0.00011467115050221718, "timer/dataset_train_min": 9.989738464355469e-05, "timer/dataset_train_max": 0.0004496574401855469, "timer/agent.train_count": 1398.0, "timer/agent.train_total": 634.3565061092377, "timer/agent.train_frac": 0.6334997904042876, "timer/agent.train_avg": 0.4537600186761357, "timer/agent.train_min": 0.4330894947052002, "timer/agent.train_max": 2.4810495376586914, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47950196266174316, "timer/agent.report_frac": 0.00047885438222706567, "timer/agent.report_avg": 0.23975098133087158, "timer/agent.report_min": 0.23193979263305664, "timer/agent.report_max": 0.24756217002868652, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.6716461181640625e-05, "timer/dataset_eval_frac": 3.66668746027665e-08, "timer/dataset_eval_avg": 3.6716461181640625e-05, "timer/dataset_eval_min": 3.6716461181640625e-05, "timer/dataset_eval_max": 3.6716461181640625e-05, "fps": 22.33724377011455}
{"step": 722432, "time": 33383.44986104965, "episode/length": 277.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 722520, "time": 33387.68458223343, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 722744, "time": 33396.80545473099, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 722824, "time": 33401.16237235069, "episode/length": 37.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 723072, "time": 33411.59494137764, "episode/length": 219.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 723952, "time": 33442.889400959015, "episode/length": 437.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.997716894977169, "episode/intrinsic_return": 0.0}
{"step": 723976, "time": 33445.08669948578, "episode/length": 226.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 724112, "time": 33451.59693837166, "episode/length": 209.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 724128, "time": 33453.744371414185, "episode/length": 172.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 724968, "time": 33483.48497533798, "episode/length": 452.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9801324503311258, "episode/intrinsic_return": 0.0}
{"step": 725200, "time": 33493.05771398544, "episode/length": 265.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 725384, "time": 33500.78975510597, "episode/length": 319.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 725632, "time": 33511.05522727966, "episode/length": 206.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 725744, "time": 33516.51864480972, "episode/length": 418.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9809069212410502, "episode/intrinsic_return": 0.0}
{"step": 726168, "time": 33532.20781493187, "episode/length": 276.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 726240, "time": 33536.47679615021, "episode/length": 263.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 726448, "time": 33545.031383514404, "episode/length": 291.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 726800, "time": 33558.557448387146, "episode/length": 199.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 727264, "time": 33575.68476271629, "episode/length": 189.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 727296, "time": 33578.30504155159, "episode/length": 207.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 727560, "time": 33588.64548611641, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 727712, "time": 33595.613946676254, "episode/length": 192.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 727832, "time": 33601.134638786316, "episode/length": 357.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9916201117318436, "episode/intrinsic_return": 0.0}
{"step": 727928, "time": 33605.98001122475, "episode/length": 317.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9779874213836478, "episode/intrinsic_return": 0.0}
{"step": 728512, "time": 33627.60993361473, "episode/length": 257.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9844961240310077, "episode/intrinsic_return": 0.0}
{"step": 728856, "time": 33640.66062498093, "episode/length": 198.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 729160, "time": 33654.428347587585, "episode/length": 165.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 729216, "time": 33658.028249025345, "episode/length": 187.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 729272, "time": 33661.41344666481, "episode/length": 213.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 729416, "time": 33667.88279557228, "episode/length": 264.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9886792452830189, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 33710.32096219063, "eval_episode/length": 110.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.954954954954955}
{"step": 730080, "time": 33715.218408584595, "eval_episode/length": 184.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 730080, "time": 33717.07049679756, "eval_episode/length": 191.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 730080, "time": 33720.835903167725, "eval_episode/length": 237.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 730080, "time": 33720.845010757446, "eval_episode/length": 237.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 730080, "time": 33724.321962594986, "eval_episode/length": 242.0, "eval_episode/score": 13.099999994039536, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 730080, "time": 33726.155853033066, "eval_episode/length": 62.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 730080, "time": 33729.406081438065, "eval_episode/length": 286.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 730184, "time": 33732.664756536484, "episode/length": 422.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9976359338061466, "episode/intrinsic_return": 0.0}
{"step": 730320, "time": 33739.141320466995, "episode/length": 182.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 730736, "time": 33754.68817329407, "episode/length": 196.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 730864, "time": 33760.57730555534, "episode/length": 293.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9965986394557823, "episode/intrinsic_return": 0.0}
{"step": 730872, "time": 33762.29338979721, "episode/length": 181.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 730888, "time": 33764.440427064896, "episode/length": 208.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 731400, "time": 33783.28453421593, "episode/length": 433.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9930875576036866, "episode/intrinsic_return": 0.0}
{"step": 731520, "time": 33789.05404162407, "episode/length": 166.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9820359281437125, "episode/intrinsic_return": 0.0}
{"step": 731864, "time": 33802.024789094925, "episode/length": 323.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9969135802469136, "episode/intrinsic_return": 0.0}
{"step": 732072, "time": 33810.59260010719, "episode/length": 218.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 732960, "time": 33842.5089673996, "episode/length": 261.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.0}
{"step": 733184, "time": 33851.667750597, "episode/length": 222.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 733272, "time": 33856.12825727463, "episode/length": 218.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 733304, "time": 33858.833325862885, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 733520, "time": 33867.83238649368, "episode/length": 347.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 733640, "time": 33873.30621433258, "episode/length": 343.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9854651162790697, "episode/intrinsic_return": 0.0}
{"step": 733744, "time": 33878.63947868347, "episode/length": 54.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9272727272727272, "episode/intrinsic_return": 0.0}
{"step": 734320, "time": 33899.64670777321, "episode/length": 430.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9953596287703016, "episode/intrinsic_return": 0.0}
{"step": 734520, "time": 33907.854934215546, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 734520, "time": 33907.86327123642, "episode/length": 305.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9967320261437909, "episode/intrinsic_return": 0.0}
{"step": 734672, "time": 33916.6203558445, "episode/length": 143.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 734800, "time": 33922.5630505085, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 735352, "time": 33942.74856829643, "episode/length": 200.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 735608, "time": 33953.11556315422, "episode/length": 291.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 735720, "time": 33958.54119634628, "episode/length": 259.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 735736, "time": 33960.73167562485, "episode/length": 151.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 736128, "time": 33975.59037065506, "episode/length": 225.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 736528, "time": 33990.79358744621, "episode/length": 231.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 736600, "time": 33994.55903506279, "episode/length": 58.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 736688, "time": 33999.281019449234, "episode/length": 235.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 736976, "time": 34010.70062661171, "episode/length": 306.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 737016, "time": 34013.431661605835, "episode/length": 159.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 737040, "time": 34016.07174038887, "episode/length": 210.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 737368, "time": 34030.22148013115, "episode/length": 219.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 737424, "time": 34033.99893569946, "episode/length": 212.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 737864, "time": 34050.30335569382, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 737992, "time": 34056.122540950775, "episode/length": 173.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 738376, "time": 34070.7029504776, "episode/length": 210.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 738648, "time": 34081.463546037674, "episode/length": 200.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 738792, "time": 34087.890223264694, "episode/length": 226.0, "episode/score": 6.100000038743019, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 739336, "time": 34108.02456712723, "episode/length": 289.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 739520, "time": 34116.07030773163, "episode/length": 261.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9847328244274809, "episode/intrinsic_return": 0.0}
{"step": 739568, "time": 34119.297760248184, "episode/length": 212.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 739600, "time": 34121.87297916412, "episode/length": 278.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.992831541218638, "episode/intrinsic_return": 0.0}
{"step": 739664, "time": 34125.69565010071, "episode/length": 208.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 739808, "time": 34132.388748168945, "episode/length": 144.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 740064, "time": 34157.87834095955, "eval_episode/length": 46.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 740064, "time": 34163.04368686676, "eval_episode/length": 128.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9534883720930233}
{"step": 740064, "time": 34165.513132333755, "eval_episode/length": 144.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9724137931034482}
{"step": 740064, "time": 34168.258335113525, "eval_episode/length": 169.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9764705882352941}
{"step": 740064, "time": 34170.21698951721, "eval_episode/length": 177.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9775280898876404}
{"step": 740064, "time": 34174.400491952896, "eval_episode/length": 234.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 740064, "time": 34177.643389463425, "eval_episode/length": 268.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9739776951672863}
{"step": 740064, "time": 34182.65443921089, "eval_episode/length": 343.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9796511627906976}
{"step": 740808, "time": 34207.36867046356, "episode/length": 251.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 740848, "time": 34210.53931570053, "episode/length": 308.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 741384, "time": 34230.09939336777, "episode/length": 222.0, "episode/score": 11.100000038743019, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 741448, "time": 34233.87768626213, "episode/length": 204.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 741584, "time": 34240.75550818443, "episode/length": 239.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 742192, "time": 34262.7618098259, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 742296, "time": 34267.577669382095, "episode/length": 369.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9891891891891892, "episode/intrinsic_return": 0.0}
{"step": 742360, "time": 34271.26796603203, "episode/length": 354.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9887323943661972, "episode/intrinsic_return": 0.0}
{"step": 742560, "time": 34280.009885787964, "episode/length": 45.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 742928, "time": 34293.908599853516, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 743024, "time": 34298.71921443939, "episode/length": 196.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 743288, "time": 34309.089252233505, "episode/length": 237.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 743336, "time": 34312.37643408775, "episode/length": 310.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9710610932475884, "episode/intrinsic_return": 0.0}
{"step": 743776, "time": 34328.978006362915, "episode/length": 525.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9980988593155894, "episode/intrinsic_return": 0.0}
{"step": 744168, "time": 34343.63379096985, "episode/length": 233.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 744256, "time": 34348.367685079575, "episode/length": 211.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 744296, "time": 34351.12725734711, "episode/length": 158.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 744552, "time": 34361.37644004822, "episode/length": 157.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 744832, "time": 34372.67047071457, "episode/length": 71.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 744984, "time": 34379.187578201294, "episode/length": 256.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766536964980544, "episode/intrinsic_return": 0.0}
{"step": 745001, "time": 34382.32419896126, "train_stats/sum_log_reward": 9.579166889190674, "train_stats/max_log_achievement_collect_coal": 0.4583333333333333, "train_stats/max_log_achievement_collect_drink": 5.09375, "train_stats/max_log_achievement_collect_iron": 0.020833333333333332, "train_stats/max_log_achievement_collect_sapling": 1.625, "train_stats/max_log_achievement_collect_stone": 8.947916666666666, "train_stats/max_log_achievement_collect_wood": 12.197916666666666, "train_stats/max_log_achievement_defeat_skeleton": 0.020833333333333332, "train_stats/max_log_achievement_defeat_zombie": 0.9791666666666666, "train_stats/max_log_achievement_eat_cow": 0.13541666666666666, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0625, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.6458333333333333, "train_stats/max_log_achievement_make_wood_sword": 1.34375, "train_stats/max_log_achievement_place_furnace": 0.5625, "train_stats/max_log_achievement_place_plant": 1.59375, "train_stats/max_log_achievement_place_stone": 5.447916666666667, "train_stats/max_log_achievement_place_table": 3.2916666666666665, "train_stats/max_log_achievement_wake_up": 1.4791666666666667, "train_stats/mean_log_entropy": 0.6051739828350643, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.601082443345523, "train/action_min": 0.0, "train/action_std": 3.3614590337090458, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03643207220321006, "train/actor_opt_grad_steps": 45760.0, "train/actor_opt_loss": -4.34092837318461, "train/adv_mag": 0.48557241208164403, "train/adv_max": 0.4368914082540688, "train/adv_mean": 0.0030870613833895145, "train/adv_min": -0.3872918590163508, "train/adv_std": 0.05335019267302878, "train/cont_avg": 0.9952626329787234, "train/cont_loss_mean": 0.00022981823552631618, "train/cont_loss_std": 0.007022899844749171, "train/cont_neg_acc": 0.9931442090805541, "train/cont_neg_loss": 0.017011583018898845, "train/cont_pos_acc": 0.9999582370122274, "train/cont_pos_loss": 0.00014007399762886979, "train/cont_pred": 0.995255523539604, "train/cont_rate": 0.9952626329787234, "train/dyn_loss_mean": 13.004580010759069, "train/dyn_loss_std": 9.38771906643049, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.936950591861779, "train/extr_critic_critic_opt_grad_steps": 45760.0, "train/extr_critic_critic_opt_loss": 15189.106119791666, "train/extr_critic_mag": 8.993230589738129, "train/extr_critic_max": 8.993230589738129, "train/extr_critic_mean": 3.0265675690157194, "train/extr_critic_min": -0.17464221031107802, "train/extr_critic_std": 2.023899306642248, "train/extr_return_normed_mag": 1.4916616137146104, "train/extr_return_normed_max": 1.4916616137146104, "train/extr_return_normed_mean": 0.4001859370486956, "train/extr_return_normed_min": -0.14966037388600356, "train/extr_return_normed_std": 0.3182546207879452, "train/extr_return_rate": 0.9400132556333609, "train/extr_return_raw_mag": 10.091214565520591, "train/extr_return_raw_max": 10.091214565520591, "train/extr_return_raw_mean": 3.0465080822613224, "train/extr_return_raw_min": -0.502240166385123, "train/extr_return_raw_std": 2.054138207266517, "train/extr_reward_mag": 1.0335352725171028, "train/extr_reward_max": 1.0335352725171028, "train/extr_reward_mean": 0.04331277963434551, "train/extr_reward_min": -0.4364592631657918, "train/extr_reward_std": 0.19297312929275187, "train/image_loss_mean": 6.451479314912295, "train/image_loss_std": 11.302223925894879, "train/model_loss_mean": 14.310043970743815, "train/model_loss_std": 15.242771561264146, "train/model_opt_grad_norm": 54.9062325497891, "train/model_opt_grad_steps": 45721.0, "train/model_opt_loss": 13067.260787206338, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 908.6879432624113, "train/policy_entropy_mag": 2.501586236006825, "train/policy_entropy_max": 2.501586236006825, "train/policy_entropy_mean": 0.5808177873597923, "train/policy_entropy_min": 0.07937507690690088, "train/policy_entropy_std": 0.683082751559873, "train/policy_logprob_mag": 7.4383837009998075, "train/policy_logprob_max": -0.009455668469164388, "train/policy_logprob_mean": -0.5811059149444526, "train/policy_logprob_min": -7.4383837009998075, "train/policy_logprob_std": 1.1178520063981943, "train/policy_randomness_mag": 0.8829501613657526, "train/policy_randomness_max": 0.8829501613657526, "train/policy_randomness_mean": 0.20500319234445585, "train/policy_randomness_min": 0.02801591877871794, "train/policy_randomness_std": 0.24109823441674524, "train/post_ent_mag": 60.37703101516615, "train/post_ent_max": 60.37703101516615, "train/post_ent_mean": 43.4448150742984, "train/post_ent_min": 21.21319636892765, "train/post_ent_std": 7.533788488266316, "train/prior_ent_mag": 70.82800796184134, "train/prior_ent_max": 70.82800796184134, "train/prior_ent_mean": 56.529449895764074, "train/prior_ent_min": 42.8557148926647, "train/prior_ent_std": 4.698897896083534, "train/rep_loss_mean": 13.004580010759069, "train/rep_loss_std": 9.38771906643049, "train/reward_avg": 0.02882867898290039, "train/reward_loss_mean": 0.05558686626824082, "train/reward_loss_std": 0.24908722049378335, "train/reward_max_data": 1.0148936205721917, "train/reward_max_pred": 1.0087191678108054, "train/reward_neg_acc": 0.992441270791047, "train/reward_neg_loss": 0.028738358943122076, "train/reward_pos_acc": 0.968439222650325, "train/reward_pos_loss": 0.8442406028720504, "train/reward_pred": 0.02801588393668545, "train/reward_rate": 0.03303690159574468, "eval_stats/sum_log_reward": 9.162500232458115, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 3.0, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.6875, "eval_stats/max_log_achievement_collect_stone": 6.5, "eval_stats/max_log_achievement_collect_wood": 10.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.9375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.4375, "eval_stats/max_log_achievement_make_wood_sword": 1.1875, "eval_stats/max_log_achievement_place_furnace": 0.4375, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_stone": 3.5, "eval_stats/max_log_achievement_place_table": 2.4375, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 8.725996281100379e-07, "report/cont_loss_std": 1.046623492584331e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.837431207415648e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.462582172796829e-07, "report/cont_pred": 0.9970695376396179, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.858394622802734, "report/dyn_loss_std": 9.53267765045166, "report/image_loss_mean": 5.385004043579102, "report/image_loss_std": 9.744087219238281, "report/model_loss_mean": 13.152084350585938, "report/model_loss_std": 14.022050857543945, "report/post_ent_mag": 59.90971755981445, "report/post_ent_max": 59.90971755981445, "report/post_ent_mean": 42.866912841796875, "report/post_ent_min": 20.381675720214844, "report/post_ent_std": 7.772281169891357, "report/prior_ent_mag": 70.45793151855469, "report/prior_ent_max": 70.45793151855469, "report/prior_ent_mean": 55.96095275878906, "report/prior_ent_min": 44.414794921875, "report/prior_ent_std": 4.379329681396484, "report/rep_loss_mean": 12.858394622802734, "report/rep_loss_std": 9.53267765045166, "report/reward_avg": 0.0263671875, "report/reward_loss_mean": 0.05204249918460846, "report/reward_loss_std": 0.2500941753387451, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0041520595550537, "report/reward_neg_acc": 0.9859296083450317, "report/reward_neg_loss": 0.029459165409207344, "report/reward_pos_acc": 0.9655172228813171, "report/reward_pos_loss": 0.8268844485282898, "report/reward_pred": 0.030458997935056686, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.0001479615893913433, "eval/cont_loss_std": 0.004714557435363531, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.0699453923734836e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00014809577260166407, "eval/cont_pred": 0.9988861680030823, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 18.942333221435547, "eval/dyn_loss_std": 11.516703605651855, "eval/image_loss_mean": 16.032384872436523, "eval/image_loss_std": 24.866552352905273, "eval/model_loss_mean": 27.520889282226562, "eval/model_loss_std": 28.99334144592285, "eval/post_ent_mag": 60.652767181396484, "eval/post_ent_max": 60.652767181396484, "eval/post_ent_mean": 41.43689727783203, "eval/post_ent_min": 19.030086517333984, "eval/post_ent_std": 7.683992862701416, "eval/prior_ent_mag": 70.45793151855469, "eval/prior_ent_max": 70.45793151855469, "eval/prior_ent_mean": 57.7509765625, "eval/prior_ent_min": 45.1889533996582, "eval/prior_ent_std": 4.604320526123047, "eval/rep_loss_mean": 18.942333221435547, "eval/rep_loss_std": 11.516703605651855, "eval/reward_avg": 0.02666015550494194, "eval/reward_loss_mean": 0.1229555606842041, "eval/reward_loss_std": 0.7439910769462585, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023088455200195, "eval/reward_neg_acc": 0.9838871955871582, "eval/reward_neg_loss": 0.05346139147877693, "eval/reward_pos_acc": 0.7096773982048035, "eval/reward_pos_loss": 2.349010467529297, "eval/reward_pred": 0.021777234971523285, "eval/reward_rate": 0.0302734375, "replay/size": 744497.0, "replay/inserts": 22608.0, "replay/samples": 22608.0, "replay/insert_wait_avg": 1.409303947956277e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.068616804971986e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5048.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2675196924224708e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2793033123016, "timer/env.step_count": 2826.0, "timer/env.step_total": 234.31295156478882, "timer/env.step_frac": 0.23424752545503078, "timer/env.step_avg": 0.08291328788562945, "timer/env.step_min": 0.024402379989624023, "timer/env.step_max": 3.3011744022369385, "timer/replay._sample_count": 22608.0, "timer/replay._sample_total": 12.1711266040802, "timer/replay._sample_frac": 0.012167728117313849, "timer/replay._sample_avg": 0.000538354856868374, "timer/replay._sample_min": 0.00042366981506347656, "timer/replay._sample_max": 0.010828018188476562, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3457.0, "timer/agent.policy_total": 58.980729818344116, "timer/agent.policy_frac": 0.05896426090496594, "timer/agent.policy_avg": 0.01706124669318603, "timer/agent.policy_min": 0.009263277053833008, "timer/agent.policy_max": 0.0979464054107666, "timer/dataset_train_count": 1413.0, "timer/dataset_train_total": 0.16024112701416016, "timer/dataset_train_frac": 0.00016019638363359254, "timer/dataset_train_avg": 0.00011340490234547781, "timer/dataset_train_min": 9.870529174804688e-05, "timer/dataset_train_max": 0.00035643577575683594, "timer/agent.train_count": 1413.0, "timer/agent.train_total": 634.8989231586456, "timer/agent.train_frac": 0.634721643301282, "timer/agent.train_avg": 0.44932690952487303, "timer/agent.train_min": 0.43602442741394043, "timer/agent.train_max": 1.6798558235168457, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4799375534057617, "timer/agent.report_frac": 0.0004798035426870352, "timer/agent.report_avg": 0.23996877670288086, "timer/agent.report_min": 0.2331099510192871, "timer/agent.report_max": 0.2468276023864746, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.146246487075468e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 22.60137890103065}
{"step": 745080, "time": 34384.84285545349, "episode/length": 217.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 745216, "time": 34391.28950047493, "episode/length": 356.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 745440, "time": 34400.59813785553, "episode/length": 207.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 746208, "time": 34430.049482584, "episode/length": 254.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 746712, "time": 34448.3861477375, "episode/length": 186.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 746760, "time": 34451.67546916008, "episode/length": 307.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9902597402597403, "episode/intrinsic_return": 0.0}
{"step": 746912, "time": 34458.892517089844, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 746984, "time": 34462.66755604744, "episode/length": 303.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9835526315789473, "episode/intrinsic_return": 0.0}
{"step": 747056, "time": 34466.931210041046, "episode/length": 246.0, "episode/score": 13.100000038743019, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 747336, "time": 34477.8211209774, "episode/length": 52.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 747480, "time": 34484.33165192604, "episode/length": 52.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 747552, "time": 34488.6923224926, "episode/length": 339.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 747688, "time": 34494.63825941086, "episode/length": 337.0, "episode/score": 13.099999994039536, "episode/reward_rate": 0.9970414201183432, "episode/intrinsic_return": 0.0}
{"step": 747728, "time": 34497.79927396774, "episode/length": 189.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 748080, "time": 34511.19473528862, "episode/length": 43.0, "episode/score": 0.09999999403953552, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 748816, "time": 34537.64082455635, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 748856, "time": 34540.31587100029, "episode/length": 171.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 748936, "time": 34544.66224694252, "episode/length": 243.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 748984, "time": 34547.9009578228, "episode/length": 277.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9784172661870504, "episode/intrinsic_return": 0.0}
{"step": 749856, "time": 34579.153972387314, "episode/length": 221.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 34587.127836465836, "episode/length": 311.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9967948717948718, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 34608.26672792435, "eval_episode/length": 173.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 750048, "time": 34609.85875701904, "eval_episode/length": 176.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 750048, "time": 34611.94628548622, "eval_episode/length": 186.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9786096256684492}
{"step": 750048, "time": 34611.953520059586, "eval_episode/length": 186.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 750048, "time": 34616.05483698845, "eval_episode/length": 199.0, "eval_episode/score": 11.099999979138374, "eval_episode/reward_rate": 0.995}
{"step": 750048, "time": 34618.757692575455, "eval_episode/length": 218.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9817351598173516}
{"step": 750048, "time": 34623.76291871071, "eval_episode/length": 245.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9796747967479674}
{"step": 750048, "time": 34626.27122592926, "eval_episode/length": 266.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9850187265917603}
{"step": 750376, "time": 34638.795859098434, "episode/length": 189.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 750408, "time": 34641.46839761734, "episode/length": 198.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 750464, "time": 34645.17796278, "episode/length": 184.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 751040, "time": 34666.051495075226, "episode/length": 262.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 751216, "time": 34673.668061733246, "episode/length": 440.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 751480, "time": 34684.008991241455, "episode/length": 137.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 751656, "time": 34691.58103942871, "episode/length": 224.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 752144, "time": 34709.982551813126, "episode/length": 261.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 752152, "time": 34711.6556224823, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 752456, "time": 34723.386337041855, "episode/length": 154.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 752640, "time": 34731.61679148674, "episode/length": 271.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 752648, "time": 34733.24972367287, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 752784, "time": 34739.58100652695, "episode/length": 758.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9789196310935442, "episode/intrinsic_return": 0.0}
{"step": 753272, "time": 34757.4658536911, "episode/length": 201.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 753336, "time": 34761.113879442215, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 753552, "time": 34770.233649253845, "episode/length": 136.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 753600, "time": 34773.500562906265, "episode/length": 181.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 754072, "time": 34792.672072172165, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 754304, "time": 34802.290279865265, "episode/length": 207.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 754816, "time": 34821.16561985016, "episode/length": 253.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 754896, "time": 34825.43828558922, "episode/length": 342.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9854227405247813, "episode/intrinsic_return": 0.0}
{"step": 755256, "time": 34838.97925114632, "episode/length": 212.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 755688, "time": 34855.118057727814, "episode/length": 260.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 756056, "time": 34869.065140247345, "episode/length": 247.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 756496, "time": 34885.70630764961, "episode/length": 273.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 756512, "time": 34887.77677941322, "episode/length": 201.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 756720, "time": 34896.37642669678, "episode/length": 422.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9976359338061466, "episode/intrinsic_return": 0.0}
{"step": 756768, "time": 34899.62025427818, "episode/length": 243.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9713114754098361, "episode/intrinsic_return": 0.0}
{"step": 757152, "time": 34914.255940675735, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 757232, "time": 34918.48830866814, "episode/length": 494.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9838383838383838, "episode/intrinsic_return": 0.0}
{"step": 757584, "time": 34931.8995847702, "episode/length": 290.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9862542955326461, "episode/intrinsic_return": 0.0}
{"step": 758320, "time": 34958.39932179451, "episode/length": 282.0, "episode/score": 14.100000008940697, "episode/reward_rate": 0.9823321554770318, "episode/intrinsic_return": 0.0}
{"step": 758480, "time": 34965.3546500206, "episode/length": 247.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 758568, "time": 34969.84259605408, "episode/length": 224.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 758848, "time": 34981.128509283066, "episode/length": 265.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 758968, "time": 34986.511837005615, "episode/length": 49.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 759104, "time": 34992.989023923874, "episode/length": 323.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 759160, "time": 34996.36366200447, "episode/length": 84.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 759560, "time": 35011.396938323975, "episode/length": 246.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 760032, "time": 35045.15675497055, "eval_episode/length": 59.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 760032, "time": 35050.25699353218, "eval_episode/length": 138.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 760032, "time": 35053.57820701599, "eval_episode/length": 176.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9548022598870056}
{"step": 760032, "time": 35057.72542619705, "eval_episode/length": 226.0, "eval_episode/score": 12.099999994039536, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 760032, "time": 35059.518273830414, "eval_episode/length": 230.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9653679653679653}
{"step": 760032, "time": 35063.18836450577, "eval_episode/length": 217.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 760032, "time": 35065.6529583931, "eval_episode/length": 156.0, "eval_episode/score": 11.099999979138374, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 760032, "time": 35069.66786527634, "eval_episode/length": 348.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9914040114613181}
{"step": 760176, "time": 35074.53675341606, "episode/length": 165.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 760216, "time": 35077.27388930321, "episode/length": 372.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9946380697050938, "episode/intrinsic_return": 0.0}
{"step": 760512, "time": 35089.09790182114, "episode/length": 419.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9976190476190476, "episode/intrinsic_return": 0.0}
{"step": 760552, "time": 35091.78260207176, "episode/length": 41.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 760896, "time": 35105.152540683746, "episode/length": 47.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 761072, "time": 35112.83631968498, "episode/length": 245.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 761456, "time": 35127.43445158005, "episode/length": 391.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9923469387755102, "episode/intrinsic_return": 0.0}
{"step": 761456, "time": 35127.449416399, "episode/length": 310.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9807073954983923, "episode/intrinsic_return": 0.0}
{"step": 761640, "time": 35136.75628352165, "episode/length": 182.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 761760, "time": 35142.680483579636, "episode/length": 274.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9781818181818182, "episode/intrinsic_return": 0.0}
{"step": 762216, "time": 35161.26536798477, "episode/length": 164.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 762680, "time": 35178.407982349396, "episode/length": 439.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9795454545454545, "episode/intrinsic_return": 0.0}
{"step": 762720, "time": 35181.56293821335, "episode/length": 270.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 762968, "time": 35191.26707458496, "episode/length": 236.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9915611814345991, "episode/intrinsic_return": 0.0}
{"step": 763248, "time": 35202.49044251442, "episode/length": 223.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 763544, "time": 35213.944247722626, "episode/length": 222.0, "episode/score": 11.1000000461936, "episode/reward_rate": 0.968609865470852, "episode/intrinsic_return": 0.0}
{"step": 763616, "time": 35218.148983478546, "episode/length": 111.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 764128, "time": 35236.940480709076, "episode/length": 109.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 764416, "time": 35248.37323665619, "episode/length": 216.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 764600, "time": 35256.09248709679, "episode/length": 392.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9974554707379135, "episode/intrinsic_return": 0.0}
{"step": 764856, "time": 35266.509570121765, "episode/length": 235.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 764912, "time": 35270.11931729317, "episode/length": 161.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 765096, "time": 35277.688777685165, "episode/length": 120.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 765128, "time": 35280.39386677742, "episode/length": 363.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 765616, "time": 35298.71551132202, "episode/length": 149.0, "episode/score": 8.1000000461936, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 766184, "time": 35319.19221043587, "episode/length": 165.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 766232, "time": 35322.378231048584, "episode/length": 137.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 766392, "time": 35329.503457546234, "episode/length": 223.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 766656, "time": 35340.372425317764, "episode/length": 388.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9922879177377892, "episode/intrinsic_return": 0.0}
{"step": 766712, "time": 35343.72969675064, "episode/length": 224.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9688888888888889, "episode/intrinsic_return": 0.0}
{"step": 767216, "time": 35362.53364276886, "episode/length": 264.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 767737, "time": 35382.48914885521, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.543391268018266, "train/action_min": 0.0, "train/action_std": 3.2837161698811492, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0362514543124068, "train/actor_opt_grad_steps": 47175.0, "train/actor_opt_loss": -3.782295831669332, "train/adv_mag": 0.48671394187799644, "train/adv_max": 0.42483036702787375, "train/adv_mean": 0.0029276651859080132, "train/adv_min": -0.4159145160040385, "train/adv_std": 0.05305770341254456, "train/cont_avg": 0.9951653279049296, "train/cont_loss_mean": 0.00012402279145127447, "train/cont_loss_std": 0.0036621861452642364, "train/cont_neg_acc": 0.9962273651445416, "train/cont_neg_loss": 0.008747984583665193, "train/cont_pos_acc": 0.9999792441515856, "train/cont_pos_loss": 7.62469355559493e-05, "train/cont_pred": 0.9951551707697587, "train/cont_rate": 0.9951653279049296, "train/dyn_loss_mean": 12.762451762884435, "train/dyn_loss_std": 9.391812472276285, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0084255081667026, "train/extr_critic_critic_opt_grad_steps": 47175.0, "train/extr_critic_critic_opt_loss": 15283.314776353433, "train/extr_critic_mag": 9.168612238386986, "train/extr_critic_max": 9.168612238386986, "train/extr_critic_mean": 3.1302455126399726, "train/extr_critic_min": -0.1648362287333314, "train/extr_critic_std": 2.096545242927444, "train/extr_return_normed_mag": 1.4849177775248674, "train/extr_return_normed_max": 1.4849177775248674, "train/extr_return_normed_mean": 0.4161093016745339, "train/extr_return_normed_min": -0.13508406229002376, "train/extr_return_normed_std": 0.3208873852247923, "train/extr_return_rate": 0.9212712309729885, "train/extr_return_raw_mag": 10.24009309016483, "train/extr_return_raw_max": 10.24009309016483, "train/extr_return_raw_mean": 3.1496925034993133, "train/extr_return_raw_min": -0.5063026120335283, "train/extr_return_raw_std": 2.1285193587692692, "train/extr_reward_mag": 1.0335679071050294, "train/extr_reward_max": 1.0335679071050294, "train/extr_reward_mean": 0.043743406186326286, "train/extr_reward_min": -0.4555902422313959, "train/extr_reward_std": 0.19440160618281702, "train/image_loss_mean": 6.399430553678056, "train/image_loss_std": 11.265860802690748, "train/model_loss_mean": 14.112104536781848, "train/model_loss_std": 15.186630994501249, "train/model_opt_grad_norm": 55.903548724214794, "train/model_opt_grad_steps": 47135.288732394365, "train/model_opt_loss": 18360.080291318223, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1302.8169014084508, "train/policy_entropy_mag": 2.4737855363899555, "train/policy_entropy_max": 2.4737855363899555, "train/policy_entropy_mean": 0.5733090616028074, "train/policy_entropy_min": 0.07937508375501968, "train/policy_entropy_std": 0.6643849327950411, "train/policy_logprob_mag": 7.438383659846346, "train/policy_logprob_max": -0.00945567838768934, "train/policy_logprob_mean": -0.5730065581664233, "train/policy_logprob_min": -7.438383659846346, "train/policy_logprob_std": 1.112404766636835, "train/policy_randomness_mag": 0.8731377343056907, "train/policy_randomness_max": 0.8731377343056907, "train/policy_randomness_mean": 0.20235294009178456, "train/policy_randomness_min": 0.02801592122028831, "train/policy_randomness_std": 0.23449872560064558, "train/post_ent_mag": 60.82772072268204, "train/post_ent_max": 60.82772072268204, "train/post_ent_mean": 43.80024901913925, "train/post_ent_min": 20.9996723658602, "train/post_ent_std": 7.606201712514313, "train/prior_ent_mag": 70.90483797100228, "train/prior_ent_max": 70.90483797100228, "train/prior_ent_mean": 56.60410937457017, "train/prior_ent_min": 42.68132964658066, "train/prior_ent_std": 4.7694458625686, "train/rep_loss_mean": 12.762451762884435, "train/rep_loss_std": 9.391812472276285, "train/reward_avg": 0.02920334486448219, "train/reward_loss_mean": 0.055078969166522294, "train/reward_loss_std": 0.24257976016108418, "train/reward_max_data": 1.0190140890403532, "train/reward_max_pred": 1.0101465742352982, "train/reward_neg_acc": 0.9928808237465334, "train/reward_neg_loss": 0.028390800482003202, "train/reward_pos_acc": 0.9732492331048133, "train/reward_pos_loss": 0.8234104891897926, "train/reward_pred": 0.02845271253092608, "train/reward_rate": 0.03355386223591549, "train_stats/sum_log_reward": 9.715384778085646, "train_stats/max_log_achievement_collect_coal": 0.7692307692307693, "train_stats/max_log_achievement_collect_drink": 4.626373626373627, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.4175824175824177, "train_stats/max_log_achievement_collect_stone": 10.406593406593407, "train_stats/max_log_achievement_collect_wood": 10.461538461538462, "train_stats/max_log_achievement_defeat_skeleton": 0.06593406593406594, "train_stats/max_log_achievement_defeat_zombie": 0.6923076923076923, "train_stats/max_log_achievement_eat_cow": 0.23076923076923078, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.03296703296703297, "train_stats/max_log_achievement_make_stone_sword": 0.01098901098901099, "train_stats/max_log_achievement_make_wood_pickaxe": 1.6813186813186813, "train_stats/max_log_achievement_make_wood_sword": 1.120879120879121, "train_stats/max_log_achievement_place_furnace": 0.989010989010989, "train_stats/max_log_achievement_place_plant": 1.3626373626373627, "train_stats/max_log_achievement_place_stone": 4.791208791208791, "train_stats/max_log_achievement_place_table": 3.1758241758241756, "train_stats/max_log_achievement_wake_up": 1.4945054945054945, "train_stats/mean_log_entropy": 0.6032447022396129, "eval_stats/sum_log_reward": 9.725000202655792, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 5.0625, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 9.25, "eval_stats/max_log_achievement_collect_wood": 10.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.6875, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5625, "eval_stats/max_log_achievement_make_wood_sword": 1.0625, "eval_stats/max_log_achievement_place_furnace": 1.0, "eval_stats/max_log_achievement_place_plant": 1.9375, "eval_stats/max_log_achievement_place_stone": 3.875, "eval_stats/max_log_achievement_place_table": 2.9375, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 5.874928774574073e-06, "report/cont_loss_std": 0.00017545717128086835, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.379030673997477e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 5.647809757647337e-06, "report/cont_pred": 0.9960883855819702, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.610944747924805, "report/dyn_loss_std": 9.976758003234863, "report/image_loss_mean": 7.031486988067627, "report/image_loss_std": 11.222393035888672, "report/model_loss_mean": 15.259712219238281, "report/model_loss_std": 15.68024730682373, "report/post_ent_mag": 62.975494384765625, "report/post_ent_max": 62.975494384765625, "report/post_ent_mean": 42.93551254272461, "report/post_ent_min": 20.15118980407715, "report/post_ent_std": 8.191224098205566, "report/prior_ent_mag": 70.71221923828125, "report/prior_ent_max": 70.71221923828125, "report/prior_ent_mean": 56.733116149902344, "report/prior_ent_min": 39.469303131103516, "report/prior_ent_std": 4.794729232788086, "report/rep_loss_mean": 13.610944747924805, "report/rep_loss_std": 9.976758003234863, "report/reward_avg": 0.02968749962747097, "report/reward_loss_mean": 0.06165322661399841, "report/reward_loss_std": 0.2749684154987335, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0012214183807373, "report/reward_neg_acc": 0.9868553280830383, "report/reward_neg_loss": 0.03409148380160332, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8404691219329834, "report/reward_pred": 0.028309617191553116, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.1489048574730987e-06, "eval/cont_loss_std": 1.971117490029428e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 9.610115375835449e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.829959033893829e-07, "eval/cont_pred": 0.9951170086860657, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.04372787475586, "eval/dyn_loss_std": 10.619036674499512, "eval/image_loss_mean": 9.1182222366333, "eval/image_loss_std": 11.795588493347168, "eval/model_loss_mean": 20.022445678710938, "eval/model_loss_std": 16.137042999267578, "eval/post_ent_mag": 59.54515838623047, "eval/post_ent_max": 59.54515838623047, "eval/post_ent_mean": 42.09027099609375, "eval/post_ent_min": 20.31201171875, "eval/post_ent_std": 7.475704193115234, "eval/prior_ent_mag": 70.71221923828125, "eval/prior_ent_max": 70.71221923828125, "eval/prior_ent_mean": 57.15333557128906, "eval/prior_ent_min": 45.55632781982422, "eval/prior_ent_std": 3.9535162448883057, "eval/rep_loss_mean": 18.04372787475586, "eval/rep_loss_std": 10.619036674499512, "eval/reward_avg": 0.02158202975988388, "eval/reward_loss_mean": 0.0779850035905838, "eval/reward_loss_std": 0.45202434062957764, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017399787902832, "eval/reward_neg_acc": 0.9849246144294739, "eval/reward_neg_loss": 0.048140231519937515, "eval/reward_pos_acc": 0.931034505367279, "eval/reward_pos_loss": 1.1019692420959473, "eval/reward_pred": 0.0227186381816864, "eval/reward_rate": 0.0283203125, "replay/size": 767233.0, "replay/inserts": 22736.0, "replay/samples": 22736.0, "replay/insert_wait_avg": 1.4126846104084314e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.954853343762284e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4928.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2907405178268235e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1475105285645, "timer/env.step_count": 2842.0, "timer/env.step_total": 227.49262261390686, "timer/env.step_frac": 0.22745907000626345, "timer/env.step_avg": 0.08004666524064281, "timer/env.step_min": 0.024035930633544922, "timer/env.step_max": 3.384877920150757, "timer/replay._sample_count": 22736.0, "timer/replay._sample_total": 12.150986909866333, "timer/replay._sample_frac": 0.012149194775723333, "timer/replay._sample_avg": 0.0005344381997654088, "timer/replay._sample_min": 0.0004215240478515625, "timer/replay._sample_max": 0.020742416381835938, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3458.0, "timer/agent.policy_total": 59.30007863044739, "timer/agent.policy_frac": 0.05929133253464591, "timer/agent.policy_avg": 0.01714866357155795, "timer/agent.policy_min": 0.009649515151977539, "timer/agent.policy_max": 0.11201000213623047, "timer/dataset_train_count": 1421.0, "timer/dataset_train_total": 0.16417813301086426, "timer/dataset_train_frac": 0.00016415391857956866, "timer/dataset_train_avg": 0.0001155370394165125, "timer/dataset_train_min": 9.918212890625e-05, "timer/dataset_train_max": 0.0009717941284179688, "timer/agent.train_count": 1421.0, "timer/agent.train_total": 638.8641607761383, "timer/agent.train_frac": 0.6387699354853238, "timer/agent.train_avg": 0.44958772749904174, "timer/agent.train_min": 0.4361000061035156, "timer/agent.train_max": 1.755188226699829, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47678709030151367, "timer/agent.report_frac": 0.0004767167695588605, "timer/agent.report_avg": 0.23839354515075684, "timer/agent.report_min": 0.23255395889282227, "timer/agent.report_max": 0.2442331314086914, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7890859559447083e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 22.732335091261216}
{"step": 767776, "time": 35383.8810300827, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9585492227979274, "episode/intrinsic_return": 0.0}
{"step": 768344, "time": 35404.675662994385, "episode/length": 243.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 768376, "time": 35407.44056200981, "episode/length": 144.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 768392, "time": 35409.529671669006, "episode/length": 843.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9928909952606635, "episode/intrinsic_return": 0.0}
{"step": 768656, "time": 35420.36015129089, "episode/length": 308.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9935275080906149, "episode/intrinsic_return": 0.0}
{"step": 768832, "time": 35427.98181390762, "episode/length": 60.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 769488, "time": 35451.790283203125, "episode/length": 483.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9979338842975206, "episode/intrinsic_return": 0.0}
{"step": 769528, "time": 35454.776883125305, "episode/length": 351.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 769536, "time": 35456.87723278999, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 769648, "time": 35462.247883081436, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 769936, "time": 35473.44039559364, "episode/length": 409.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9780487804878049, "episode/intrinsic_return": 0.0}
{"step": 770016, "time": 35493.61990237236, "eval_episode/length": 57.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 770016, "time": 35500.347707271576, "eval_episode/length": 174.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 770016, "time": 35503.04276371002, "eval_episode/length": 199.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.995}
{"step": 770016, "time": 35503.050231695175, "eval_episode/length": 199.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.995}
{"step": 770016, "time": 35507.41012477875, "eval_episode/length": 216.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 770016, "time": 35510.02807807922, "eval_episode/length": 182.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9617486338797814}
{"step": 770016, "time": 35512.47318601608, "eval_episode/length": 259.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9961538461538462}
{"step": 770016, "time": 35515.1100730896, "eval_episode/length": 279.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9964285714285714}
{"step": 770336, "time": 35527.59412717819, "episode/length": 99.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 770536, "time": 35535.718767642975, "episode/length": 267.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 771048, "time": 35554.67470908165, "episode/length": 194.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 771256, "time": 35563.244111299515, "episode/length": 164.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 771568, "time": 35575.66111469269, "episode/length": 239.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 771608, "time": 35578.36759519577, "episode/length": 368.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.991869918699187, "episode/intrinsic_return": 0.0}
{"step": 771624, "time": 35580.66564035416, "episode/length": 45.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 772104, "time": 35598.595247507095, "episode/length": 195.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 772352, "time": 35608.84987282753, "episode/length": 439.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9977272727272727, "episode/intrinsic_return": 0.0}
{"step": 772544, "time": 35617.11817288399, "episode/length": 116.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9658119658119658, "episode/intrinsic_return": 0.0}
{"step": 772816, "time": 35627.98352789879, "episode/length": 309.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9806451612903225, "episode/intrinsic_return": 0.0}
{"step": 772824, "time": 35629.639679670334, "episode/length": 156.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 772992, "time": 35637.19738841057, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 773288, "time": 35648.46498131752, "episode/length": 469.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 773936, "time": 35672.18888378143, "episode/length": 360.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9889196675900277, "episode/intrinsic_return": 0.0}
{"step": 774144, "time": 35680.854078769684, "episode/length": 199.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 774160, "time": 35683.06762075424, "episode/length": 166.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 774536, "time": 35697.27020931244, "episode/length": 46.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9148936170212766, "episode/intrinsic_return": 0.0}
{"step": 775032, "time": 35715.61873960495, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 775032, "time": 35715.628437042236, "episode/length": 365.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9972677595628415, "episode/intrinsic_return": 0.0}
{"step": 775240, "time": 35726.11552762985, "episode/length": 360.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9833795013850416, "episode/intrinsic_return": 0.0}
{"step": 775280, "time": 35729.39382147789, "episode/length": 307.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 775328, "time": 35732.57651090622, "episode/length": 147.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 775432, "time": 35737.52883172035, "episode/length": 186.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 775824, "time": 35752.677562236786, "episode/length": 353.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9887005649717514, "episode/intrinsic_return": 0.0}
{"step": 776088, "time": 35762.88225531578, "episode/length": 32.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8787878787878788, "episode/intrinsic_return": 0.0}
{"step": 776328, "time": 35772.62766313553, "episode/length": 223.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 776432, "time": 35778.081703424454, "episode/length": 137.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 776440, "time": 35779.656349897385, "episode/length": 149.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 776752, "time": 35792.08343887329, "episode/length": 214.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9674418604651163, "episode/intrinsic_return": 0.0}
{"step": 776840, "time": 35796.52913069725, "episode/length": 225.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 777112, "time": 35807.33904147148, "episode/length": 228.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 777184, "time": 35811.56868815422, "episode/length": 218.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 777632, "time": 35828.30389094353, "episode/length": 148.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 777936, "time": 35840.42853188515, "episode/length": 187.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 778000, "time": 35844.23177647591, "episode/length": 238.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9874476987447699, "episode/intrinsic_return": 0.0}
{"step": 778120, "time": 35849.69604110718, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 778344, "time": 35860.41620230675, "episode/length": 251.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 778464, "time": 35866.31896042824, "episode/length": 168.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 778496, "time": 35868.95621204376, "episode/length": 217.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 778944, "time": 35885.61838412285, "episode/length": 163.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 779256, "time": 35897.65096783638, "episode/length": 258.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 779416, "time": 35904.79628109932, "episode/length": 184.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 779464, "time": 35908.139070272446, "episode/length": 167.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 779848, "time": 35922.70335102081, "episode/length": 187.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 780000, "time": 35952.85452628136, "eval_episode/length": 214.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.986046511627907}
{"step": 780000, "time": 35956.42631483078, "eval_episode/length": 254.0, "eval_episode/score": 12.099999971687794, "eval_episode/reward_rate": 0.996078431372549}
{"step": 780000, "time": 35959.33712100983, "eval_episode/length": 284.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9859649122807017}
{"step": 780000, "time": 35962.84983205795, "eval_episode/length": 328.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9908814589665653}
{"step": 780000, "time": 35966.43760871887, "eval_episode/length": 353.0, "eval_episode/score": 13.100000023841858, "eval_episode/reward_rate": 0.9915254237288136}
{"step": 780000, "time": 35969.532918930054, "eval_episode/length": 358.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9832869080779945}
{"step": 780000, "time": 35973.0540869236, "eval_episode/length": 403.0, "eval_episode/score": 11.100000031292439, "eval_episode/reward_rate": 0.9876237623762376}
{"step": 780000, "time": 35976.99021720886, "eval_episode/length": 240.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.995850622406639}
{"step": 780000, "time": 35976.995658159256, "eval_episode/length": 96.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9896907216494846}
{"step": 780344, "time": 35988.39205145836, "episode/length": 292.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9829351535836177, "episode/intrinsic_return": 0.0}
{"step": 780568, "time": 35997.48832535744, "episode/length": 258.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 780688, "time": 36003.38143658638, "episode/length": 277.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9856115107913669, "episode/intrinsic_return": 0.0}
{"step": 780952, "time": 36013.81445360184, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 780952, "time": 36013.82240486145, "episode/length": 185.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 781232, "time": 36026.88313293457, "episode/length": 172.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 781248, "time": 36029.040410757065, "episode/length": 287.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 781656, "time": 36044.26146364212, "episode/length": 279.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 781704, "time": 36047.56193971634, "episode/length": 56.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 781896, "time": 36055.70647525787, "episode/length": 165.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 782192, "time": 36067.60132455826, "episode/length": 154.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9548387096774194, "episode/intrinsic_return": 0.0}
{"step": 782384, "time": 36075.615248441696, "episode/length": 178.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 782792, "time": 36090.951751470566, "episode/length": 305.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9836601307189542, "episode/intrinsic_return": 0.0}
{"step": 782936, "time": 36097.472078084946, "episode/length": 212.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 783192, "time": 36107.8918671608, "episode/length": 191.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 783544, "time": 36121.53314089775, "episode/length": 229.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 783848, "time": 36133.757930994034, "episode/length": 182.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 783944, "time": 36138.632553100586, "episode/length": 49.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 783984, "time": 36141.90346240997, "episode/length": 411.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9975728155339806, "episode/intrinsic_return": 0.0}
{"step": 784168, "time": 36149.44657993317, "episode/length": 153.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 784456, "time": 36160.63045501709, "episode/length": 207.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 784472, "time": 36163.302411556244, "episode/length": 159.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 784472, "time": 36163.31230998039, "episode/length": 321.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.0}
{"step": 785568, "time": 36204.974801540375, "episode/length": 197.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 785584, "time": 36207.29356980324, "episode/length": 423.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 786008, "time": 36223.05261325836, "episode/length": 229.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 786032, "time": 36225.72734832764, "episode/length": 194.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 786552, "time": 36246.49634194374, "episode/length": 259.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 786864, "time": 36259.22315001488, "episode/length": 159.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 786912, "time": 36262.91774606705, "episode/length": 306.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 787136, "time": 36272.02110695839, "episode/length": 195.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 787152, "time": 36274.14133429527, "episode/length": 400.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9900249376558603, "episode/intrinsic_return": 0.0}
{"step": 787448, "time": 36285.42191386223, "episode/length": 449.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 788048, "time": 36308.35566663742, "episode/length": 254.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 788296, "time": 36318.14787173271, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 788304, "time": 36320.32693171501, "episode/length": 218.0, "episode/score": 11.099999956786633, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 788616, "time": 36332.28064060211, "episode/length": 322.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9845201238390093, "episode/intrinsic_return": 0.0}
{"step": 788768, "time": 36339.29794549942, "episode/length": 201.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 788896, "time": 36345.3629553318, "episode/length": 180.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9834254143646409, "episode/intrinsic_return": 0.0}
{"step": 789040, "time": 36352.00735092163, "episode/length": 237.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 789376, "time": 36364.87426733971, "episode/length": 307.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9837662337662337, "episode/intrinsic_return": 0.0}
{"step": 789800, "time": 36380.6498196125, "episode/length": 218.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 789801, "time": 36383.25013065338, "train_stats/sum_log_reward": 9.497959391042894, "train_stats/max_log_achievement_collect_coal": 0.8163265306122449, "train_stats/max_log_achievement_collect_drink": 4.1938775510204085, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.5612244897959184, "train_stats/max_log_achievement_collect_stone": 11.224489795918368, "train_stats/max_log_achievement_collect_wood": 10.979591836734693, "train_stats/max_log_achievement_defeat_skeleton": 0.05102040816326531, "train_stats/max_log_achievement_defeat_zombie": 0.7142857142857143, "train_stats/max_log_achievement_eat_cow": 0.15306122448979592, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.01020408163265306, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7959183673469388, "train_stats/max_log_achievement_make_wood_sword": 1.0612244897959184, "train_stats/max_log_achievement_place_furnace": 1.0, "train_stats/max_log_achievement_place_plant": 1.5, "train_stats/max_log_achievement_place_stone": 4.836734693877551, "train_stats/max_log_achievement_place_table": 3.204081632653061, "train_stats/max_log_achievement_wake_up": 1.4591836734693877, "train_stats/mean_log_entropy": 0.5444867557712963, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.538538836050725, "train/action_min": 0.0, "train/action_std": 3.3106078652368076, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0362897715733751, "train/actor_opt_grad_steps": 48575.0, "train/actor_opt_loss": -3.5807935366596, "train/adv_mag": 0.45641303472760797, "train/adv_max": 0.4059732863004657, "train/adv_mean": 0.002955083003964477, "train/adv_min": -0.381865284257177, "train/adv_std": 0.05200629937799944, "train/cont_avg": 0.9953577898550725, "train/cont_loss_mean": 0.00014105055583840917, "train/cont_loss_std": 0.003940664467127868, "train/cont_neg_acc": 0.9977240904289133, "train/cont_neg_loss": 0.010844304503435483, "train/cont_pos_acc": 0.9999644186185754, "train/cont_pos_loss": 9.213326887603806e-05, "train/cont_pred": 0.9953477067359979, "train/cont_rate": 0.9953577898550725, "train/dyn_loss_mean": 12.884600210880887, "train/dyn_loss_std": 9.371438268302143, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0246691103430763, "train/extr_critic_critic_opt_grad_steps": 48575.0, "train/extr_critic_critic_opt_loss": 15374.7372693048, "train/extr_critic_mag": 9.438049675761789, "train/extr_critic_max": 9.438049675761789, "train/extr_critic_mean": 3.198509036630824, "train/extr_critic_min": -0.16622520529705545, "train/extr_critic_std": 2.131977034651715, "train/extr_return_normed_mag": 1.471132547095202, "train/extr_return_normed_max": 1.471132547095202, "train/extr_return_normed_mean": 0.4066746468129365, "train/extr_return_normed_min": -0.12631764894594316, "train/extr_return_normed_std": 0.3129295679754105, "train/extr_return_rate": 0.9353308535140493, "train/extr_return_raw_mag": 10.578287781148717, "train/extr_return_raw_max": 10.578287781148717, "train/extr_return_raw_mean": 3.218879513118578, "train/extr_return_raw_min": -0.4659443625073502, "train/extr_return_raw_std": 2.1637245658515156, "train/extr_reward_mag": 1.04144587378571, "train/extr_reward_max": 1.04144587378571, "train/extr_reward_mean": 0.0448290859821482, "train/extr_reward_min": -0.4153488718945047, "train/extr_reward_std": 0.1962357177466586, "train/image_loss_mean": 6.497893582219663, "train/image_loss_std": 11.2501293576282, "train/model_loss_mean": 14.284916580587193, "train/model_loss_std": 15.180753535118656, "train/model_opt_grad_norm": 55.18209421461907, "train/model_opt_grad_steps": 48533.862318840576, "train/model_opt_loss": 19145.475005661232, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1340.5797101449275, "train/policy_entropy_mag": 2.491898992787237, "train/policy_entropy_max": 2.491898992787237, "train/policy_entropy_mean": 0.5556210655233135, "train/policy_entropy_min": 0.07937506937246391, "train/policy_entropy_std": 0.657744941936023, "train/policy_logprob_mag": 7.43838375893192, "train/policy_logprob_max": -0.009455669563317644, "train/policy_logprob_mean": -0.5557153004667034, "train/policy_logprob_min": -7.43838375893192, "train/policy_logprob_std": 1.1009560953015867, "train/policy_randomness_mag": 0.8795309909012007, "train/policy_randomness_max": 0.8795309909012007, "train/policy_randomness_mean": 0.1961098551966142, "train/policy_randomness_min": 0.028015916195252667, "train/policy_randomness_std": 0.2321551015627557, "train/post_ent_mag": 60.913648439490274, "train/post_ent_max": 60.913648439490274, "train/post_ent_mean": 43.70350633151289, "train/post_ent_min": 20.840743258379508, "train/post_ent_std": 7.559007755224256, "train/prior_ent_mag": 70.96926028486611, "train/prior_ent_max": 70.96926028486611, "train/prior_ent_mean": 56.648708150006726, "train/prior_ent_min": 42.91101604959239, "train/prior_ent_std": 4.728947466698246, "train/rep_loss_mean": 12.884600210880887, "train/rep_loss_std": 9.371438268302143, "train/reward_avg": 0.029144021500225947, "train/reward_loss_mean": 0.05612195792027574, "train/reward_loss_std": 0.2539831601839135, "train/reward_max_data": 1.0202898599099421, "train/reward_max_pred": 1.0115726443304531, "train/reward_neg_acc": 0.9929224684618522, "train/reward_neg_loss": 0.029206290139236313, "train/reward_pos_acc": 0.9697344134683195, "train/reward_pos_loss": 0.8426461232745129, "train/reward_pred": 0.02852236331049083, "train/reward_rate": 0.03335880887681159, "eval_stats/sum_log_reward": 9.805882481967702, "eval_stats/max_log_achievement_collect_coal": 0.7647058823529411, "eval_stats/max_log_achievement_collect_drink": 3.6470588235294117, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.4705882352941178, "eval_stats/max_log_achievement_collect_stone": 9.941176470588236, "eval_stats/max_log_achievement_collect_wood": 11.470588235294118, "eval_stats/max_log_achievement_defeat_skeleton": 0.17647058823529413, "eval_stats/max_log_achievement_defeat_zombie": 0.7058823529411765, "eval_stats/max_log_achievement_eat_cow": 0.29411764705882354, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.6470588235294117, "eval_stats/max_log_achievement_make_wood_sword": 1.1764705882352942, "eval_stats/max_log_achievement_place_furnace": 0.9411764705882353, "eval_stats/max_log_achievement_place_plant": 1.411764705882353, "eval_stats/max_log_achievement_place_stone": 5.176470588235294, "eval_stats/max_log_achievement_place_table": 3.5294117647058822, "eval_stats/max_log_achievement_wake_up": 1.6470588235294117, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 1.4084321264817845e-06, "report/cont_loss_std": 2.7577369110076688e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00014867971185594797, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.4881569515855517e-07, "report/cont_pred": 0.9921885132789612, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 12.057044982910156, "report/dyn_loss_std": 8.576848983764648, "report/image_loss_mean": 6.403098106384277, "report/image_loss_std": 8.053836822509766, "report/model_loss_mean": 13.705057144165039, "report/model_loss_std": 11.286044120788574, "report/post_ent_mag": 64.88648223876953, "report/post_ent_max": 64.88648223876953, "report/post_ent_mean": 44.95814514160156, "report/post_ent_min": 22.736454010009766, "report/post_ent_std": 8.351449966430664, "report/prior_ent_mag": 71.05593872070312, "report/prior_ent_max": 71.05593872070312, "report/prior_ent_mean": 57.22536849975586, "report/prior_ent_min": 44.0882682800293, "report/prior_ent_std": 5.141552925109863, "report/rep_loss_mean": 12.057044982910156, "report/rep_loss_std": 8.576848983764648, "report/reward_avg": 0.03798828274011612, "report/reward_loss_mean": 0.06773032248020172, "report/reward_loss_std": 0.27336323261260986, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0035269260406494, "report/reward_neg_acc": 0.9959142208099365, "report/reward_neg_loss": 0.0375092551112175, "report/reward_pos_acc": 0.9777777791023254, "report/reward_pos_loss": 0.7252063751220703, "report/reward_pred": 0.03783425688743591, "report/reward_rate": 0.0439453125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 4.856722739532415e-07, "eval/cont_loss_std": 3.8598191167693585e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.157179475645535e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.8533452223200584e-07, "eval/cont_pred": 0.99609375, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.477792739868164, "eval/dyn_loss_std": 10.772967338562012, "eval/image_loss_mean": 11.350196838378906, "eval/image_loss_std": 17.24390411376953, "eval/model_loss_mean": 21.945850372314453, "eval/model_loss_std": 21.441946029663086, "eval/post_ent_mag": 59.131797790527344, "eval/post_ent_max": 59.131797790527344, "eval/post_ent_mean": 41.945770263671875, "eval/post_ent_min": 21.28102684020996, "eval/post_ent_std": 7.378850936889648, "eval/prior_ent_mag": 71.05593872070312, "eval/prior_ent_max": 71.05593872070312, "eval/prior_ent_mean": 57.09567642211914, "eval/prior_ent_min": 41.399234771728516, "eval/prior_ent_std": 4.403287410736084, "eval/rep_loss_mean": 17.477792739868164, "eval/rep_loss_std": 10.772967338562012, "eval/reward_avg": 0.04033202677965164, "eval/reward_loss_mean": 0.10897646844387054, "eval/reward_loss_std": 0.5683222413063049, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011627674102783, "eval/reward_neg_acc": 0.9805924892425537, "eval/reward_neg_loss": 0.04991517215967178, "eval/reward_pos_acc": 0.8888888955116272, "eval/reward_pos_loss": 1.3938877582550049, "eval/reward_pred": 0.039383336901664734, "eval/reward_rate": 0.0439453125, "replay/size": 789297.0, "replay/inserts": 22064.0, "replay/samples": 22064.0, "replay/insert_wait_avg": 1.4449804048766427e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.628085698659564e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5888.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.22448672419009e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.7477698326111, "timer/env.step_count": 2758.0, "timer/env.step_total": 239.78361797332764, "timer/env.step_frac": 0.23960444899461006, "timer/env.step_avg": 0.08694112326806658, "timer/env.step_min": 0.02438068389892578, "timer/env.step_max": 4.303929805755615, "timer/replay._sample_count": 22064.0, "timer/replay._sample_total": 11.453685760498047, "timer/replay._sample_frac": 0.011445127439468423, "timer/replay._sample_avg": 0.0005191119362082146, "timer/replay._sample_min": 0.00039505958557128906, "timer/replay._sample_max": 0.010176897048950195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3494.0, "timer/agent.policy_total": 60.399030923843384, "timer/agent.policy_frac": 0.060353900098069624, "timer/agent.policy_avg": 0.017286499978203602, "timer/agent.policy_min": 0.00959324836730957, "timer/agent.policy_max": 0.14089441299438477, "timer/dataset_train_count": 1379.0, "timer/dataset_train_total": 0.1597895622253418, "timer/dataset_train_frac": 0.00015967016569226912, "timer/dataset_train_avg": 0.00011587350415180696, "timer/dataset_train_min": 9.989738464355469e-05, "timer/dataset_train_max": 0.0010828971862792969, "timer/agent.train_count": 1379.0, "timer/agent.train_total": 623.9559800624847, "timer/agent.train_frac": 0.6234897532340742, "timer/agent.train_avg": 0.45246989127083737, "timer/agent.train_min": 0.43670082092285156, "timer/agent.train_max": 1.6760103702545166, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47737598419189453, "timer/agent.report_frac": 0.00047701928356207304, "timer/agent.report_avg": 0.23868799209594727, "timer/agent.report_min": 0.2316761016845703, "timer/agent.report_max": 0.24569988250732422, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.097125591235379e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 22.047216303857805}
{"step": 790000, "time": 36390.14351916313, "episode/length": 172.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 790056, "time": 36394.02749156952, "episode/length": 219.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 790072, "time": 36396.70591497421, "episode/length": 162.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9815950920245399, "episode/intrinsic_return": 0.0}
{"step": 790088, "time": 36415.34502220154, "eval_episode/length": 81.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9878048780487805}
{"step": 790088, "time": 36417.84486413002, "eval_episode/length": 101.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9901960784313726}
{"step": 790088, "time": 36420.6713013649, "eval_episode/length": 43.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9090909090909091}
{"step": 790088, "time": 36423.68089437485, "eval_episode/length": 156.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 790088, "time": 36426.69513916969, "eval_episode/length": 188.0, "eval_episode/score": 12.100000016391277, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 790088, "time": 36426.70292854309, "eval_episode/length": 188.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9682539682539683}
{"step": 790088, "time": 36430.82404589653, "eval_episode/length": 206.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9710144927536232}
{"step": 790088, "time": 36436.214104652405, "eval_episode/length": 161.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 790232, "time": 36441.10933923721, "episode/length": 53.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9259259259259259, "episode/intrinsic_return": 0.0}
{"step": 790480, "time": 36451.45711803436, "episode/length": 271.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 790608, "time": 36457.49009823799, "episode/length": 213.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 790696, "time": 36461.80661678314, "episode/length": 57.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 790736, "time": 36465.05756306648, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 790824, "time": 36469.56881093979, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 791344, "time": 36488.899590969086, "episode/length": 91.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9891304347826086, "episode/intrinsic_return": 0.0}
{"step": 791768, "time": 36504.60169696808, "episode/length": 213.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 792104, "time": 36517.605899333954, "episode/length": 262.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 792304, "time": 36526.159677028656, "episode/length": 227.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 792336, "time": 36528.95098423958, "episode/length": 204.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 792496, "time": 36535.96148943901, "episode/length": 302.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 792680, "time": 36543.64463996887, "episode/length": 242.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 793520, "time": 36573.91892242432, "episode/length": 336.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9940652818991098, "episode/intrinsic_return": 0.0}
{"step": 793592, "time": 36577.69027328491, "episode/length": 185.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 793896, "time": 36589.75019788742, "episode/length": 265.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9887218045112782, "episode/intrinsic_return": 0.0}
{"step": 794232, "time": 36602.68182969093, "episode/length": 240.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 794464, "time": 36612.169256448746, "episode/length": 222.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 794504, "time": 36614.877673864365, "episode/length": 394.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9949367088607595, "episode/intrinsic_return": 0.0}
{"step": 794872, "time": 36630.84079670906, "episode/length": 45.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 794872, "time": 36630.8503677845, "episode/length": 316.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9968454258675079, "episode/intrinsic_return": 0.0}
{"step": 794984, "time": 36638.13343811035, "episode/length": 182.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 795104, "time": 36643.99985218048, "episode/length": 325.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9877300613496932, "episode/intrinsic_return": 0.0}
{"step": 795648, "time": 36663.97102999687, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 796224, "time": 36685.0746152401, "episode/length": 248.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 796440, "time": 36693.8062787056, "episode/length": 355.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 796656, "time": 36702.85475087166, "episode/length": 222.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 797016, "time": 36716.52081441879, "episode/length": 267.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9738805970149254, "episode/intrinsic_return": 0.0}
{"step": 797264, "time": 36726.684336423874, "episode/length": 102.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 797344, "time": 36731.02447962761, "episode/length": 211.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 797440, "time": 36735.79196500778, "episode/length": 371.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9865591397849462, "episode/intrinsic_return": 0.0}
{"step": 797920, "time": 36753.63875293732, "episode/length": 211.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 798032, "time": 36759.08627128601, "episode/length": 171.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 798040, "time": 36760.772456884384, "episode/length": 366.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9918256130790191, "episode/intrinsic_return": 0.0}
{"step": 798408, "time": 36774.87760424614, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 798584, "time": 36782.21179151535, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 798640, "time": 36786.02283000946, "episode/length": 456.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9934354485776805, "episode/intrinsic_return": 0.0}
{"step": 799424, "time": 36814.32901930809, "episode/length": 172.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 799600, "time": 36822.391753196716, "episode/length": 209.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 799616, "time": 36824.62309384346, "episode/length": 197.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 799784, "time": 36831.84931564331, "episode/length": 292.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 799816, "time": 36834.579661130905, "episode/length": 153.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 800072, "time": 36861.309076309204, "eval_episode/length": 81.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.926829268292683}
{"step": 800072, "time": 36868.52281332016, "eval_episode/length": 205.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 800072, "time": 36870.27817130089, "eval_episode/length": 125.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9920634920634921}
{"step": 800072, "time": 36872.217188835144, "eval_episode/length": 215.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 800072, "time": 36872.2252163887, "eval_episode/length": 215.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 800072, "time": 36877.76791596413, "eval_episode/length": 263.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9734848484848485}
{"step": 800072, "time": 36879.76696014404, "eval_episode/length": 272.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 800072, "time": 36881.97470998764, "eval_episode/length": 287.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9965277777777778}
{"step": 800264, "time": 36888.55036902428, "episode/length": 231.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 800272, "time": 36890.59730195999, "episode/length": 81.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9390243902439024, "episode/intrinsic_return": 0.0}
{"step": 800320, "time": 36893.709844350815, "episode/length": 371.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 800536, "time": 36902.317645549774, "episode/length": 236.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 800856, "time": 36914.69906377792, "episode/length": 156.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 800896, "time": 36918.5586810112, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 801112, "time": 36927.10606765747, "episode/length": 161.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 801656, "time": 36947.25079417229, "episode/length": 166.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 801936, "time": 36958.60334396362, "episode/length": 268.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 802128, "time": 36966.64668369293, "episode/length": 198.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 802200, "time": 36970.439388751984, "episode/length": 162.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 802712, "time": 36989.56013035774, "episode/length": 304.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 803544, "time": 37021.00836634636, "episode/length": 409.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 803720, "time": 37028.63773703575, "episode/length": 325.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9846625766871165, "episode/intrinsic_return": 0.0}
{"step": 804184, "time": 37045.89806365967, "episode/length": 247.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 804264, "time": 37050.34285354614, "episode/length": 425.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 804880, "time": 37073.06836104393, "episode/length": 402.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9776674937965261, "episode/intrinsic_return": 0.0}
{"step": 804912, "time": 37075.731125593185, "episode/length": 371.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9865591397849462, "episode/intrinsic_return": 0.0}
{"step": 805112, "time": 37083.71762633324, "episode/length": 195.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 805144, "time": 37086.37944102287, "episode/length": 303.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 805656, "time": 37105.539850473404, "episode/length": 173.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 805704, "time": 37108.95015382767, "episode/length": 446.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 806280, "time": 37130.09674119949, "episode/length": 319.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 806440, "time": 37137.157326459885, "episode/length": 194.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 806536, "time": 37142.11938357353, "episode/length": 293.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 806752, "time": 37151.23402953148, "episode/length": 200.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 806800, "time": 37154.425179481506, "episode/length": 142.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 806864, "time": 37158.45605015755, "episode/length": 218.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 807400, "time": 37177.99034571648, "episode/length": 310.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9967845659163987, "episode/intrinsic_return": 0.0}
{"step": 807808, "time": 37193.74367117882, "episode/length": 190.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 808368, "time": 37214.36961507797, "episode/length": 240.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 808448, "time": 37218.86747074127, "episode/length": 342.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9912536443148688, "episode/intrinsic_return": 0.0}
{"step": 808536, "time": 37223.12397480011, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 808544, "time": 37225.25260949135, "episode/length": 223.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 808976, "time": 37241.49629163742, "episode/length": 304.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9934426229508196, "episode/intrinsic_return": 0.0}
{"step": 809096, "time": 37247.66036391258, "episode/length": 286.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9860627177700348, "episode/intrinsic_return": 0.0}
{"step": 809128, "time": 37250.45650219917, "episode/length": 215.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 809328, "time": 37259.0385723114, "episode/length": 189.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 810008, "time": 37283.31088709831, "episode/length": 182.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 810056, "time": 37306.52554893494, "eval_episode/length": 148.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 810056, "time": 37308.39191055298, "eval_episode/length": 153.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 810056, "time": 37310.98971867561, "eval_episode/length": 176.0, "eval_episode/score": 9.100000016391277, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 810056, "time": 37312.87819600105, "eval_episode/length": 183.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 810056, "time": 37316.14256858826, "eval_episode/length": 220.0, "eval_episode/score": 12.100000023841858, "eval_episode/reward_rate": 0.9728506787330317}
{"step": 810056, "time": 37317.91011428833, "eval_episode/length": 225.0, "eval_episode/score": 11.100000016391277, "eval_episode/reward_rate": 0.995575221238938}
{"step": 810056, "time": 37320.53298139572, "eval_episode/length": 249.0, "eval_episode/score": 10.099999971687794, "eval_episode/reward_rate": 0.996}
{"step": 810056, "time": 37322.978065252304, "eval_episode/length": 268.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9851301115241635}
{"step": 810064, "time": 37323.48082828522, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 810160, "time": 37328.24710869789, "episode/length": 213.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 810216, "time": 37331.55072617531, "episode/length": 209.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 810584, "time": 37345.73201942444, "episode/length": 45.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9347826086956522, "episode/intrinsic_return": 0.0}
{"step": 810720, "time": 37352.17328238487, "episode/length": 202.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 811513, "time": 37383.36311483383, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.616682613597197, "train/action_min": 0.0, "train/action_std": 3.3897923757048214, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03686227256377392, "train/actor_opt_grad_steps": 49945.0, "train/actor_opt_loss": -2.9655852335888673, "train/adv_mag": 0.5069164548288373, "train/adv_max": 0.4220392535276273, "train/adv_mean": 0.003968036057278155, "train/adv_min": -0.4303378782728139, "train/adv_std": 0.053101837881566846, "train/cont_avg": 0.9952392578125, "train/cont_loss_mean": 0.0002549863889359973, "train/cont_loss_std": 0.007915268744109567, "train/cont_neg_acc": 0.9907271248452804, "train/cont_neg_loss": 0.057743680895087246, "train/cont_pos_acc": 0.9999855695401921, "train/cont_pos_loss": 3.2016442839122305e-05, "train/cont_pred": 0.9952721863108522, "train/cont_rate": 0.9952392578125, "train/dyn_loss_mean": 12.907100509194766, "train/dyn_loss_std": 9.431799040121192, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0045385790221832, "train/extr_critic_critic_opt_grad_steps": 49945.0, "train/extr_critic_critic_opt_loss": 15417.775728113511, "train/extr_critic_mag": 9.564262656604543, "train/extr_critic_max": 9.564262656604543, "train/extr_critic_mean": 3.3449820543036743, "train/extr_critic_min": -0.1669362643185784, "train/extr_critic_std": 2.2189955728895523, "train/extr_return_normed_mag": 1.4600743397193796, "train/extr_return_normed_max": 1.4600743397193796, "train/extr_return_normed_mean": 0.4200727985624005, "train/extr_return_normed_min": -0.12785218858762698, "train/extr_return_normed_std": 0.31964811770355, "train/extr_return_rate": 0.9252020642161369, "train/extr_return_raw_mag": 10.696995580897612, "train/extr_return_raw_max": 10.696995580897612, "train/extr_return_raw_mean": 3.3729596926885494, "train/extr_return_raw_min": -0.48534096525434184, "train/extr_return_raw_std": 2.2513976158464657, "train/extr_reward_mag": 1.0377662883085363, "train/extr_reward_max": 1.0377662883085363, "train/extr_reward_mean": 0.04729669428813983, "train/extr_reward_min": -0.4251062545706244, "train/extr_reward_std": 0.20170509705648704, "train/image_loss_mean": 6.528216691578136, "train/image_loss_std": 11.674382903996635, "train/model_loss_mean": 14.328377281918245, "train/model_loss_std": 15.600664875086617, "train/model_opt_grad_norm": 51.8480924578274, "train/model_opt_grad_steps": 49902.56617647059, "train/model_opt_loss": 18608.655625287225, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1295.9558823529412, "train/policy_entropy_mag": 2.4785527411629173, "train/policy_entropy_max": 2.4785527411629173, "train/policy_entropy_mean": 0.5654676528099705, "train/policy_entropy_min": 0.07937508059994262, "train/policy_entropy_std": 0.6779846224714728, "train/policy_logprob_mag": 7.438383768586552, "train/policy_logprob_max": -0.009455671479158542, "train/policy_logprob_mean": -0.5659930037663263, "train/policy_logprob_min": -7.438383768586552, "train/policy_logprob_std": 1.1060341824503506, "train/policy_randomness_mag": 0.8748203502858386, "train/policy_randomness_max": 0.8748203502858386, "train/policy_randomness_mean": 0.1995852680548149, "train/policy_randomness_min": 0.028015920070602614, "train/policy_randomness_std": 0.23929881929036448, "train/post_ent_mag": 60.727193131166345, "train/post_ent_max": 60.727193131166345, "train/post_ent_mean": 43.66056001887602, "train/post_ent_min": 20.826600733925314, "train/post_ent_std": 7.5595783310778, "train/prior_ent_mag": 71.02379894256592, "train/prior_ent_max": 71.02379894256592, "train/prior_ent_mean": 56.58886631797342, "train/prior_ent_min": 42.453039926641125, "train/prior_ent_std": 4.717975707615123, "train/rep_loss_mean": 12.907100509194766, "train/rep_loss_std": 9.431799040121192, "train/reward_avg": 0.02950295848388444, "train/reward_loss_mean": 0.055645294665523315, "train/reward_loss_std": 0.24711850449881134, "train/reward_max_data": 1.0169117687379612, "train/reward_max_pred": 1.0098233582342373, "train/reward_neg_acc": 0.9926054241026149, "train/reward_neg_loss": 0.028853691121398965, "train/reward_pos_acc": 0.9707304028903737, "train/reward_pos_loss": 0.825796555946855, "train/reward_pred": 0.028829105177839452, "train/reward_rate": 0.03378475413602941, "train_stats/sum_log_reward": 9.920224945196944, "train_stats/max_log_achievement_collect_coal": 0.8426966292134831, "train_stats/max_log_achievement_collect_drink": 5.033707865168539, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.5168539325842696, "train_stats/max_log_achievement_collect_stone": 12.49438202247191, "train_stats/max_log_achievement_collect_wood": 10.52808988764045, "train_stats/max_log_achievement_defeat_skeleton": 0.011235955056179775, "train_stats/max_log_achievement_defeat_zombie": 0.8202247191011236, "train_stats/max_log_achievement_eat_cow": 0.11235955056179775, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.011235955056179775, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.898876404494382, "train_stats/max_log_achievement_make_wood_sword": 1.0898876404494382, "train_stats/max_log_achievement_place_furnace": 1.3258426966292134, "train_stats/max_log_achievement_place_plant": 1.4606741573033708, "train_stats/max_log_achievement_place_stone": 5.314606741573034, "train_stats/max_log_achievement_place_table": 2.853932584269663, "train_stats/max_log_achievement_wake_up": 1.4269662921348314, "train_stats/mean_log_entropy": 0.5868423095579898, "eval_stats/sum_log_reward": 8.933333575725555, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 3.2083333333333335, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.0416666666666667, "eval_stats/max_log_achievement_collect_stone": 9.375, "eval_stats/max_log_achievement_collect_wood": 8.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.4166666666666667, "eval_stats/max_log_achievement_make_wood_sword": 0.9166666666666666, "eval_stats/max_log_achievement_place_furnace": 0.9166666666666666, "eval_stats/max_log_achievement_place_plant": 0.9583333333333334, "eval_stats/max_log_achievement_place_stone": 3.7083333333333335, "eval_stats/max_log_achievement_place_table": 2.5, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 4.770483428728767e-06, "report/cont_loss_std": 2.7590043828240596e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00016026107186917216, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.31360604125075e-06, "report/cont_pred": 0.9970664978027344, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 11.722091674804688, "report/dyn_loss_std": 8.822547912597656, "report/image_loss_mean": 5.42015266418457, "report/image_loss_std": 7.1321611404418945, "report/model_loss_mean": 12.509284973144531, "report/model_loss_std": 11.059747695922852, "report/post_ent_mag": 57.23204803466797, "report/post_ent_max": 57.23204803466797, "report/post_ent_mean": 43.03164291381836, "report/post_ent_min": 21.64324188232422, "report/post_ent_std": 7.060061454772949, "report/prior_ent_mag": 70.88046264648438, "report/prior_ent_max": 70.88046264648438, "report/prior_ent_mean": 55.20035171508789, "report/prior_ent_min": 41.67729949951172, "report/prior_ent_std": 4.430485248565674, "report/rep_loss_mean": 11.722091674804688, "report/rep_loss_std": 8.822547912597656, "report/reward_avg": 0.03330077975988388, "report/reward_loss_mean": 0.0558728352189064, "report/reward_loss_std": 0.26351773738861084, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0005755424499512, "report/reward_neg_acc": 0.998985767364502, "report/reward_neg_loss": 0.03005419299006462, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7257986664772034, "report/reward_pred": 0.03240649402141571, "report/reward_rate": 0.037109375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 4.444991645868868e-06, "eval/cont_loss_std": 8.463683479931206e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.9640248612849973e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.370960141386604e-06, "eval/cont_pred": 0.9970660209655762, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.31095314025879, "eval/dyn_loss_std": 11.51777172088623, "eval/image_loss_mean": 12.434122085571289, "eval/image_loss_std": 18.865283966064453, "eval/model_loss_mean": 23.505859375, "eval/model_loss_std": 23.283903121948242, "eval/post_ent_mag": 62.758384704589844, "eval/post_ent_max": 62.758384704589844, "eval/post_ent_mean": 42.363922119140625, "eval/post_ent_min": 22.507896423339844, "eval/post_ent_std": 8.277026176452637, "eval/prior_ent_mag": 70.88046264648438, "eval/prior_ent_max": 70.88046264648438, "eval/prior_ent_mean": 58.073150634765625, "eval/prior_ent_min": 44.63018798828125, "eval/prior_ent_std": 4.549664497375488, "eval/rep_loss_mean": 18.31095314025879, "eval/rep_loss_std": 11.51777172088623, "eval/reward_avg": 0.03066406026482582, "eval/reward_loss_mean": 0.08516018837690353, "eval/reward_loss_std": 0.5105672478675842, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0032122135162354, "eval/reward_neg_acc": 0.9939271211624146, "eval/reward_neg_loss": 0.041075967252254486, "eval/reward_pos_acc": 0.944444477558136, "eval/reward_pos_loss": 1.2950273752212524, "eval/reward_pred": 0.02888190560042858, "eval/reward_rate": 0.03515625, "replay/size": 811009.0, "replay/inserts": 21712.0, "replay/samples": 21712.0, "replay/insert_wait_avg": 1.4421403100583689e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.588207936409913e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6760.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2633715860942412e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1018180847168, "timer/env.step_count": 2714.0, "timer/env.step_total": 224.04320168495178, "timer/env.step_frac": 0.2240203923576644, "timer/env.step_avg": 0.08255092177043176, "timer/env.step_min": 0.02460956573486328, "timer/env.step_max": 3.567237377166748, "timer/replay._sample_count": 21712.0, "timer/replay._sample_total": 11.215835094451904, "timer/replay._sample_frac": 0.011214693235865943, "timer/replay._sample_avg": 0.0005165730975705557, "timer/replay._sample_min": 0.0004298686981201172, "timer/replay._sample_max": 0.012909412384033203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3559.0, "timer/agent.policy_total": 60.9703688621521, "timer/agent.policy_frac": 0.06096416160798081, "timer/agent.policy_avg": 0.01713132027596294, "timer/agent.policy_min": 0.00954294204711914, "timer/agent.policy_max": 0.11354398727416992, "timer/dataset_train_count": 1357.0, "timer/dataset_train_total": 0.1539621353149414, "timer/dataset_train_frac": 0.00015394646078115574, "timer/dataset_train_avg": 0.00011345772683488681, "timer/dataset_train_min": 9.894371032714844e-05, "timer/dataset_train_max": 0.0007419586181640625, "timer/agent.train_count": 1357.0, "timer/agent.train_total": 612.9022738933563, "timer/agent.train_frac": 0.6128398757109733, "timer/agent.train_avg": 0.45165974494720434, "timer/agent.train_min": 0.43761396408081055, "timer/agent.train_max": 1.7476413249969482, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4779205322265625, "timer/agent.report_frac": 0.000477871876227385, "timer/agent.report_avg": 0.23896026611328125, "timer/agent.report_min": 0.23130464553833008, "timer/agent.report_max": 0.24661588668823242, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051447119998627e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 21.709484108024043}
{"step": 811832, "time": 37394.0563287735, "episode/length": 227.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 811952, "time": 37400.02777647972, "episode/length": 352.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9858356940509915, "episode/intrinsic_return": 0.0}
{"step": 812144, "time": 37408.09414768219, "episode/length": 259.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 812208, "time": 37411.94874405861, "episode/length": 403.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9777227722772277, "episode/intrinsic_return": 0.0}
{"step": 812304, "time": 37417.11595964432, "episode/length": 267.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 812472, "time": 37424.201288461685, "episode/length": 218.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 812520, "time": 37427.39284014702, "episode/length": 241.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 812848, "time": 37440.30512857437, "episode/length": 439.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9795454545454545, "episode/intrinsic_return": 0.0}
{"step": 813192, "time": 37453.384179115295, "episode/length": 130.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 813864, "time": 37477.96277356148, "episode/length": 253.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.984251968503937, "episode/intrinsic_return": 0.0}
{"step": 813888, "time": 37480.67017412186, "episode/length": 209.0, "episode/score": 12.1000000461936, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 813976, "time": 37485.09848976135, "episode/length": 187.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 814160, "time": 37493.29790329933, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 814192, "time": 37495.96198177338, "episode/length": 279.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 814296, "time": 37500.83763551712, "episode/length": 248.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 814648, "time": 37514.1435008049, "episode/length": 224.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 815160, "time": 37533.10784959793, "episode/length": 147.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 815304, "time": 37539.52647805214, "episode/length": 176.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 815304, "time": 37539.533890247345, "episode/length": 125.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 815368, "time": 37545.19445228577, "episode/length": 271.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 815600, "time": 37555.015087127686, "episode/length": 179.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 815632, "time": 37557.67184448242, "episode/length": 220.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9909502262443439, "episode/intrinsic_return": 0.0}
{"step": 815776, "time": 37564.118216991425, "episode/length": 197.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 816728, "time": 37597.63018655777, "episode/length": 177.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 816832, "time": 37602.98855757713, "episode/length": 272.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 817288, "time": 37619.92788147926, "episode/length": 239.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 817512, "time": 37629.01780247688, "episode/length": 275.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 817584, "time": 37633.32974529266, "episode/length": 225.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 817616, "time": 37636.048419475555, "episode/length": 40.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 817720, "time": 37641.08983254433, "episode/length": 264.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 817920, "time": 37649.6194190979, "episode/length": 285.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9965034965034965, "episode/intrinsic_return": 0.0}
{"step": 818536, "time": 37671.93027305603, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 818808, "time": 37682.72781729698, "episode/length": 148.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 819112, "time": 37694.705557346344, "episode/length": 148.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 819248, "time": 37703.18390893936, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 819256, "time": 37704.76469755173, "episode/length": 217.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 819256, "time": 37704.77549910545, "episode/length": 315.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9968354430379747, "episode/intrinsic_return": 0.0}
{"step": 819264, "time": 37708.572075366974, "episode/length": 512.0, "episode/score": 13.100000031292439, "episode/reward_rate": 0.9980506822612085, "episode/intrinsic_return": 0.0}
{"step": 819560, "time": 37719.952831983566, "episode/length": 55.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 819744, "time": 37728.16080546379, "episode/length": 59.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 819800, "time": 37731.41587352753, "episode/length": 276.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 820040, "time": 37763.34276866913, "eval_episode/length": 148.0, "eval_episode/score": 10.100000016391277, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 820040, "time": 37764.981219530106, "eval_episode/length": 151.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 820040, "time": 37766.90992665291, "eval_episode/length": 156.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 820040, "time": 37768.69524049759, "eval_episode/length": 160.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 820040, "time": 37772.67573046684, "eval_episode/length": 213.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 820040, "time": 37776.25954222679, "eval_episode/length": 258.0, "eval_episode/score": 8.100000016391277, "eval_episode/reward_rate": 0.9961389961389961}
{"step": 820040, "time": 37781.179263591766, "eval_episode/length": 117.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9915254237288136}
{"step": 820040, "time": 37783.35207271576, "eval_episode/length": 343.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9912790697674418}
{"step": 820456, "time": 37797.532148361206, "episode/length": 239.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 820856, "time": 37812.62224960327, "episode/length": 49.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 821024, "time": 37820.10571932793, "episode/length": 276.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9891696750902527, "episode/intrinsic_return": 0.0}
{"step": 821240, "time": 37828.84905934334, "episode/length": 209.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 821848, "time": 37851.05956172943, "episode/length": 255.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.97265625, "episode/intrinsic_return": 0.0}
{"step": 822184, "time": 37863.825682878494, "episode/length": 365.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 822288, "time": 37869.14086771011, "episode/length": 317.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9968553459119497, "episode/intrinsic_return": 0.0}
{"step": 822336, "time": 37872.42853856087, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 822368, "time": 37875.08623480797, "episode/length": 389.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 823192, "time": 37904.425837516785, "episode/length": 491.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.991869918699187, "episode/intrinsic_return": 0.0}
{"step": 823216, "time": 37907.32245016098, "episode/length": 273.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 823512, "time": 37918.787298202515, "episode/length": 146.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 823552, "time": 37921.90375113487, "episode/length": 288.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 823640, "time": 37926.23438715935, "episode/length": 223.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 823712, "time": 37930.48663330078, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 823832, "time": 37935.93972468376, "episode/length": 205.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 824696, "time": 37966.95124745369, "episode/length": 184.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 824752, "time": 37970.68442249298, "episode/length": 154.0, "episode/score": 10.100000038743019, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 824808, "time": 37974.08378863335, "episode/length": 201.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 824904, "time": 37979.00811648369, "episode/length": 316.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9779179810725552, "episode/intrinsic_return": 0.0}
{"step": 825120, "time": 37988.04840350151, "episode/length": 175.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 825248, "time": 37993.961893081665, "episode/length": 176.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 825792, "time": 38014.058644771576, "episode/length": 268.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 826080, "time": 38025.4018740654, "episode/length": 172.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 826280, "time": 38033.68306541443, "episode/length": 190.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 826544, "time": 38044.40144634247, "episode/length": 177.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 826760, "time": 38053.031799316406, "episode/length": 243.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 826992, "time": 38062.80221700668, "episode/length": 217.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 827016, "time": 38064.957432985306, "episode/length": 432.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 827352, "time": 38078.02664899826, "episode/length": 305.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9836601307189542, "episode/intrinsic_return": 0.0}
{"step": 827976, "time": 38102.49799656868, "episode/length": 236.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 828112, "time": 38108.829734802246, "episode/length": 289.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 828136, "time": 38110.94173693657, "episode/length": 171.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 828368, "time": 38120.9234521389, "episode/length": 171.0, "episode/score": 12.100000038743019, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 828408, "time": 38123.61091852188, "episode/length": 265.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 828848, "time": 38140.25265145302, "episode/length": 287.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 829040, "time": 38148.48500204086, "episode/length": 83.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9404761904761905, "episode/intrinsic_return": 0.0}
{"step": 829448, "time": 38163.52004861832, "episode/length": 166.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9820359281437125, "episode/intrinsic_return": 0.0}
{"step": 829528, "time": 38167.76170921326, "episode/length": 271.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 829808, "time": 38179.12332677841, "episode/length": 174.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 829816, "time": 38180.73544430733, "episode/length": 45.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 830024, "time": 38209.428661584854, "eval_episode/length": 149.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 830024, "time": 38211.8109266758, "eval_episode/length": 168.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9644970414201184}
{"step": 830024, "time": 38215.973584890366, "eval_episode/length": 223.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9732142857142857}
{"step": 830024, "time": 38217.88320732117, "eval_episode/length": 228.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 830024, "time": 38221.294909238815, "eval_episode/length": 268.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9851301115241635}
{"step": 830024, "time": 38224.61889266968, "eval_episode/length": 307.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9967532467532467}
{"step": 830024, "time": 38226.89304161072, "eval_episode/length": 322.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9845201238390093}
{"step": 830024, "time": 38229.029420375824, "eval_episode/length": 183.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 830344, "time": 38239.954182863235, "episode/length": 295.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 830368, "time": 38242.481417417526, "episode/length": 165.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 830488, "time": 38247.76947402954, "episode/length": 293.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9863945578231292, "episode/intrinsic_return": 0.0}
{"step": 830512, "time": 38250.43804311752, "episode/length": 436.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9794050343249427, "episode/intrinsic_return": 0.0}
{"step": 830912, "time": 38265.38990163803, "episode/length": 49.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 830936, "time": 38267.931448459625, "episode/length": 260.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 831120, "time": 38275.9041121006, "episode/length": 198.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 831272, "time": 38282.45425653458, "episode/length": 182.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 831816, "time": 38302.501272678375, "episode/length": 183.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 831936, "time": 38308.350261449814, "episode/length": 124.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.952, "episode/intrinsic_return": 0.0}
{"step": 832000, "time": 38312.020283699036, "episode/length": 188.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 832264, "time": 38322.283527612686, "episode/length": 236.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9662447257383966, "episode/intrinsic_return": 0.0}
{"step": 832584, "time": 38334.89217019081, "episode/length": 345.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9739884393063584, "episode/intrinsic_return": 0.0}
{"step": 832832, "time": 38345.20594906807, "episode/length": 213.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 833184, "time": 38358.8636507988, "episode/length": 283.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 833232, "time": 38362.21136569977, "episode/length": 244.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 833480, "time": 38372.02939558029, "episode/length": 184.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 833672, "time": 38380.138061761856, "episode/length": 60.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 833672, "time": 38380.14693760872, "episode/length": 216.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 833673, "time": 38384.658264160156, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.6358815068783965, "train/action_min": 0.0, "train/action_std": 3.4161531925201416, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03612010233590136, "train/actor_opt_grad_steps": 51315.0, "train/actor_opt_loss": -1.4365904273978178, "train/adv_mag": 0.48973687230676843, "train/adv_max": 0.4214258085990298, "train/adv_mean": 0.003583035107737118, "train/adv_min": -0.4242263800208119, "train/adv_std": 0.05172585911940837, "train/cont_avg": 0.9950818048007246, "train/cont_loss_mean": 0.0001724817171229734, "train/cont_loss_std": 0.005104222181545871, "train/cont_neg_acc": 0.9934006225371707, "train/cont_neg_loss": 0.018997975968221104, "train/cont_pos_acc": 0.9999644592188407, "train/cont_pos_loss": 5.2607033041966915e-05, "train/cont_pred": 0.9950863671475563, "train/cont_rate": 0.9950818048007246, "train/dyn_loss_mean": 12.699214962945469, "train/dyn_loss_std": 9.36049153148264, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0565708063650823, "train/extr_critic_critic_opt_grad_steps": 51315.0, "train/extr_critic_critic_opt_loss": 15392.07759425951, "train/extr_critic_mag": 9.806305387745732, "train/extr_critic_max": 9.806305387745732, "train/extr_critic_mean": 3.5899736034697383, "train/extr_critic_min": -0.15496915319691534, "train/extr_critic_std": 2.3722513689511064, "train/extr_return_normed_mag": 1.4340287472890771, "train/extr_return_normed_max": 1.4340287472890771, "train/extr_return_normed_mean": 0.43019493507302325, "train/extr_return_normed_min": -0.11652647768673689, "train/extr_return_normed_std": 0.3225038988866668, "train/extr_return_rate": 0.9263063759907432, "train/extr_return_raw_mag": 11.108481738878334, "train/extr_return_raw_max": 11.108481738878334, "train/extr_return_raw_mean": 3.6166788892469546, "train/extr_return_raw_min": -0.4630231395147849, "train/extr_return_raw_std": 2.40764203797216, "train/extr_reward_mag": 1.0422753579374673, "train/extr_reward_max": 1.0422753579374673, "train/extr_reward_mean": 0.04874802742531334, "train/extr_reward_min": -0.41411525615747424, "train/extr_reward_std": 0.2047330055763756, "train/image_loss_mean": 6.405175419821256, "train/image_loss_std": 11.390236160029536, "train/model_loss_mean": 14.081982322361158, "train/model_loss_std": 15.299913779548977, "train/model_opt_grad_norm": 55.91023161791373, "train/model_opt_grad_steps": 51271.29710144927, "train/model_opt_loss": 17602.477899966034, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.4906973424165146, "train/policy_entropy_max": 2.4906973424165146, "train/policy_entropy_mean": 0.5645290081915648, "train/policy_entropy_min": 0.07937506823867992, "train/policy_entropy_std": 0.6834899614686551, "train/policy_logprob_mag": 7.438383807306704, "train/policy_logprob_max": -0.00945566784914421, "train/policy_logprob_mean": -0.5643199336701545, "train/policy_logprob_min": -7.438383807306704, "train/policy_logprob_std": 1.1052581944327424, "train/policy_randomness_mag": 0.8791068606618522, "train/policy_randomness_max": 0.8791068606618522, "train/policy_randomness_mean": 0.1992539679226668, "train/policy_randomness_min": 0.028015915790329807, "train/policy_randomness_std": 0.24124196387719418, "train/post_ent_mag": 60.992492952208586, "train/post_ent_max": 60.992492952208586, "train/post_ent_mean": 43.86774400351704, "train/post_ent_min": 20.697963728420977, "train/post_ent_std": 7.583394575810087, "train/prior_ent_mag": 70.9970452128977, "train/prior_ent_max": 70.9970452128977, "train/prior_ent_mean": 56.617650267006695, "train/prior_ent_min": 42.535381400066875, "train/prior_ent_std": 4.740223058755847, "train/rep_loss_mean": 12.699214962945469, "train/rep_loss_std": 9.36049153148264, "train/reward_avg": 0.029736328012971342, "train/reward_loss_mean": 0.057105582571871906, "train/reward_loss_std": 0.24914182495811713, "train/reward_max_data": 1.0166666706403096, "train/reward_max_pred": 1.0118706805118616, "train/reward_neg_acc": 0.9925479115783304, "train/reward_neg_loss": 0.030107321062435705, "train/reward_pos_acc": 0.972187279359154, "train/reward_pos_loss": 0.8221674008645873, "train/reward_pred": 0.029196460069953533, "train/reward_rate": 0.0342575294384058, "train_stats/sum_log_reward": 9.72376261371197, "train_stats/max_log_achievement_collect_coal": 1.1782178217821782, "train_stats/max_log_achievement_collect_drink": 4.514851485148514, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.3267326732673268, "train_stats/max_log_achievement_collect_stone": 13.643564356435643, "train_stats/max_log_achievement_collect_wood": 9.316831683168317, "train_stats/max_log_achievement_defeat_skeleton": 0.06930693069306931, "train_stats/max_log_achievement_defeat_zombie": 0.594059405940594, "train_stats/max_log_achievement_eat_cow": 0.09900990099009901, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.009900990099009901, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5445544554455446, "train_stats/max_log_achievement_make_wood_sword": 1.1782178217821782, "train_stats/max_log_achievement_place_furnace": 1.891089108910891, "train_stats/max_log_achievement_place_plant": 1.2772277227722773, "train_stats/max_log_achievement_place_stone": 4.158415841584159, "train_stats/max_log_achievement_place_table": 2.5841584158415842, "train_stats/max_log_achievement_wake_up": 1.4455445544554455, "train_stats/mean_log_entropy": 0.5837545495222111, "eval_stats/sum_log_reward": 9.53750017285347, "eval_stats/max_log_achievement_collect_coal": 1.375, "eval_stats/max_log_achievement_collect_drink": 3.0, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 11.25, "eval_stats/max_log_achievement_collect_wood": 7.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 1.25, "eval_stats/max_log_achievement_place_furnace": 1.875, "eval_stats/max_log_achievement_place_plant": 1.6875, "eval_stats/max_log_achievement_place_stone": 2.375, "eval_stats/max_log_achievement_place_table": 2.1875, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 1.65519340953324e-05, "report/cont_loss_std": 0.0003293456684332341, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0007261209539137781, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.1667978469631635e-05, "report/cont_pred": 0.9931575059890747, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.377440452575684, "report/dyn_loss_std": 9.406648635864258, "report/image_loss_mean": 6.809431076049805, "report/image_loss_std": 11.29573917388916, "report/model_loss_mean": 14.884601593017578, "report/model_loss_std": 15.214983940124512, "report/post_ent_mag": 58.02686309814453, "report/post_ent_max": 58.02686309814453, "report/post_ent_mean": 44.021968841552734, "report/post_ent_min": 19.93563461303711, "report/post_ent_std": 7.248652458190918, "report/prior_ent_mag": 71.46883392333984, "report/prior_ent_max": 71.46883392333984, "report/prior_ent_mean": 57.584228515625, "report/prior_ent_min": 39.94254684448242, "report/prior_ent_std": 4.819322109222412, "report/rep_loss_mean": 13.377440452575684, "report/rep_loss_std": 9.406648635864258, "report/reward_avg": 0.01943359337747097, "report/reward_loss_mean": 0.04868970811367035, "report/reward_loss_std": 0.21462289988994598, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0002555847167969, "report/reward_neg_acc": 0.9899899959564209, "report/reward_neg_loss": 0.027417683973908424, "report/reward_pos_acc": 0.9599999785423279, "report/reward_pos_loss": 0.8987197875976562, "report/reward_pred": 0.020152930170297623, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.3542153283196967e-06, "eval/cont_loss_std": 1.0468862456036732e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 7.485539390472695e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.935617981682299e-07, "eval/cont_pred": 0.995116651058197, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.741390228271484, "eval/dyn_loss_std": 11.15499496459961, "eval/image_loss_mean": 11.420073509216309, "eval/image_loss_std": 17.61492156982422, "eval/model_loss_mean": 22.75119400024414, "eval/model_loss_std": 21.655677795410156, "eval/post_ent_mag": 62.88921356201172, "eval/post_ent_max": 62.88921356201172, "eval/post_ent_mean": 41.58739471435547, "eval/post_ent_min": 21.996917724609375, "eval/post_ent_std": 7.814894199371338, "eval/prior_ent_mag": 71.46883392333984, "eval/prior_ent_max": 71.46883392333984, "eval/prior_ent_mean": 57.593292236328125, "eval/prior_ent_min": 46.47250747680664, "eval/prior_ent_std": 4.217329502105713, "eval/rep_loss_mean": 18.741390228271484, "eval/rep_loss_std": 11.15499496459961, "eval/reward_avg": 0.03115234337747097, "eval/reward_loss_mean": 0.08628495782613754, "eval/reward_loss_std": 0.5208328366279602, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0005900859832764, "eval/reward_neg_acc": 0.99493408203125, "eval/reward_neg_loss": 0.03146947920322418, "eval/reward_pos_acc": 0.8108108043670654, "eval/reward_pos_loss": 1.5485247373580933, "eval/reward_pred": 0.026141677051782608, "eval/reward_rate": 0.0361328125, "replay/size": 833169.0, "replay/inserts": 22160.0, "replay/samples": 22160.0, "replay/insert_wait_avg": 1.4331689380136208e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.524002150938399e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5424.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3010603840020553e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.2793416976929, "timer/env.step_count": 2770.0, "timer/env.step_total": 243.4232189655304, "timer/env.step_frac": 0.2431121953967417, "timer/env.step_avg": 0.08787841839910844, "timer/env.step_min": 0.024235010147094727, "timer/env.step_max": 3.518953800201416, "timer/replay._sample_count": 22160.0, "timer/replay._sample_total": 11.506367921829224, "timer/replay._sample_frac": 0.011491666154142264, "timer/replay._sample_avg": 0.0005192404296854343, "timer/replay._sample_min": 0.00042176246643066406, "timer/replay._sample_max": 0.026024818420410156, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3448.0, "timer/agent.policy_total": 60.03466320037842, "timer/agent.policy_frac": 0.059957956486536734, "timer/agent.policy_avg": 0.01741144524372924, "timer/agent.policy_min": 0.009581804275512695, "timer/agent.policy_max": 0.13213109970092773, "timer/dataset_train_count": 1385.0, "timer/dataset_train_total": 0.16199374198913574, "timer/dataset_train_frac": 0.00016178676143909203, "timer/dataset_train_avg": 0.00011696299060587418, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.004918813705444336, "timer/agent.train_count": 1385.0, "timer/agent.train_total": 623.672703742981, "timer/agent.train_frac": 0.6228758327177001, "timer/agent.train_avg": 0.45030520125847, "timer/agent.train_min": 0.43586063385009766, "timer/agent.train_max": 1.7363812923431396, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47444677352905273, "timer/agent.report_frac": 0.000473840569530394, "timer/agent.report_avg": 0.23722338676452637, "timer/agent.report_min": 0.22981858253479004, "timer/agent.report_max": 0.2446281909942627, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.838539123535156e-05, "timer/dataset_eval_frac": 3.833634594944126e-08, "timer/dataset_eval_avg": 3.838539123535156e-05, "timer/dataset_eval_min": 3.838539123535156e-05, "timer/dataset_eval_max": 3.838539123535156e-05, "fps": 22.13138534855652}
{"step": 833696, "time": 38385.37592768669, "episode/length": 138.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 833952, "time": 38396.11163473129, "episode/length": 34.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 834032, "time": 38400.30823612213, "episode/length": 44.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 834064, "time": 38403.01580953598, "episode/length": 280.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9857651245551602, "episode/intrinsic_return": 0.0}
{"step": 834568, "time": 38421.49182367325, "episode/length": 216.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 835080, "time": 38440.298330545425, "episode/length": 230.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 835328, "time": 38450.62804675102, "episode/length": 382.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9947780678851175, "episode/intrinsic_return": 0.0}
{"step": 835616, "time": 38463.69775414467, "episode/length": 193.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 835720, "time": 38468.65677547455, "episode/length": 252.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 835776, "time": 38472.36285877228, "episode/length": 217.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 835832, "time": 38475.61809206009, "episode/length": 157.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 836160, "time": 38488.52202606201, "episode/length": 275.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 836192, "time": 38491.25354003906, "episode/length": 138.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 836704, "time": 38512.37570333481, "episode/length": 171.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 836912, "time": 38520.87553310394, "episode/length": 428.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9976689976689976, "episode/intrinsic_return": 0.0}
{"step": 837384, "time": 38538.369777202606, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 837568, "time": 38546.39621210098, "episode/length": 223.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 837976, "time": 38561.5964076519, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 838008, "time": 38564.22956109047, "episode/length": 230.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 838760, "time": 38591.29066705704, "episode/length": 379.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9842105263157894, "episode/intrinsic_return": 0.0}
{"step": 839096, "time": 38604.404017448425, "episode/length": 362.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9944903581267218, "episode/intrinsic_return": 0.0}
{"step": 839568, "time": 38622.212987184525, "episode/length": 249.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 839584, "time": 38624.332116127014, "episode/length": 60.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 839632, "time": 38627.62378835678, "episode/length": 280.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 839688, "time": 38630.82994771004, "episode/length": 213.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 839776, "time": 38635.589247465134, "episode/length": 357.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9888268156424581, "episode/intrinsic_return": 0.0}
{"step": 839848, "time": 38639.58263516426, "episode/length": 135.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 840008, "time": 38666.29931282997, "eval_episode/length": 151.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9539473684210527}
{"step": 840008, "time": 38668.98256230354, "eval_episode/length": 174.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 840008, "time": 38672.98488211632, "eval_episode/length": 226.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 840008, "time": 38674.70963573456, "eval_episode/length": 228.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 840008, "time": 38677.86381626129, "eval_episode/length": 89.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9888888888888889}
{"step": 840008, "time": 38680.0459792614, "eval_episode/length": 277.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9964028776978417}
{"step": 840008, "time": 38685.01812386513, "eval_episode/length": 350.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9943019943019943}
{"step": 840008, "time": 38688.22450733185, "eval_episode/length": 157.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 840248, "time": 38696.3132853508, "episode/length": 551.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9891304347826086, "episode/intrinsic_return": 0.0}
{"step": 840600, "time": 38709.831411123276, "episode/length": 102.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9514563106796117, "episode/intrinsic_return": 0.0}
{"step": 840944, "time": 38723.45527720451, "episode/length": 169.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 841016, "time": 38727.23003053665, "episode/length": 180.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 841304, "time": 38738.91554260254, "episode/length": 201.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 841560, "time": 38749.20230102539, "episode/length": 443.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 841584, "time": 38751.78437614441, "episode/length": 79.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 841632, "time": 38754.99917054176, "episode/length": 222.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 841688, "time": 38758.19821047783, "episode/length": 256.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 841976, "time": 38769.47609257698, "episode/length": 51.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 842000, "time": 38772.13050365448, "episode/length": 51.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 842032, "time": 38774.970863342285, "episode/length": 178.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 842608, "time": 38796.1230635643, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 842720, "time": 38801.5795238018, "episode/length": 128.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 842872, "time": 38808.238092422485, "episode/length": 327.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 842976, "time": 38813.730377197266, "episode/length": 124.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.0}
{"step": 843368, "time": 38828.33674502373, "episode/length": 216.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 843688, "time": 38841.01763033867, "episode/length": 210.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.985781990521327, "episode/intrinsic_return": 0.0}
{"step": 843752, "time": 38844.84178996086, "episode/length": 214.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 844240, "time": 38864.798828840256, "episode/length": 366.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9918256130790191, "episode/intrinsic_return": 0.0}
{"step": 844280, "time": 38867.73786115646, "episode/length": 208.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 844776, "time": 38886.12134695053, "episode/length": 237.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 844904, "time": 38891.94360661507, "episode/length": 272.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 845296, "time": 38907.24996471405, "episode/length": 131.0, "episode/score": 8.1000000461936, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 845392, "time": 38912.03054499626, "episode/length": 60.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 845576, "time": 38919.63984966278, "episode/length": 227.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 845880, "time": 38931.675367832184, "episode/length": 273.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 846264, "time": 38946.18590474129, "episode/length": 108.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 846304, "time": 38949.36855816841, "episode/length": 190.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 846384, "time": 38953.7121527195, "episode/length": 262.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 846480, "time": 38958.65443778038, "episode/length": 437.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 846624, "time": 38965.077778339386, "episode/length": 130.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 847184, "time": 38985.5997133255, "episode/length": 235.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 848128, "time": 39019.24244570732, "episode/length": 217.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 848144, "time": 39021.34535884857, "episode/length": 282.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9681978798586572, "episode/intrinsic_return": 0.0}
{"step": 848544, "time": 39036.431124687195, "episode/length": 239.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 848696, "time": 39042.957535266876, "episode/length": 276.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9747292418772563, "episode/intrinsic_return": 0.0}
{"step": 849248, "time": 39063.53175115585, "episode/length": 367.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9836956521739131, "episode/intrinsic_return": 0.0}
{"step": 849328, "time": 39067.75504183769, "episode/length": 149.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 849384, "time": 39070.944778203964, "episode/length": 274.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 849472, "time": 39075.70443058014, "episode/length": 400.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9900249376558603, "episode/intrinsic_return": 0.0}
{"step": 849536, "time": 39079.64984202385, "episode/length": 770.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.993514915693904, "episode/intrinsic_return": 0.0}
{"step": 849864, "time": 39091.94482088089, "episode/length": 145.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 850096, "time": 39124.67855811119, "eval_episode/length": 177.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 850096, "time": 39127.12720680237, "eval_episode/length": 196.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9695431472081218}
{"step": 850096, "time": 39130.10094213486, "eval_episode/length": 226.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 850096, "time": 39131.93356633186, "eval_episode/length": 231.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.978448275862069}
{"step": 850096, "time": 39134.63237452507, "eval_episode/length": 254.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.996078431372549}
{"step": 850096, "time": 39138.40632081032, "eval_episode/length": 299.0, "eval_episode/score": 12.099999964237213, "eval_episode/reward_rate": 0.9866666666666667}
{"step": 850096, "time": 39144.18591284752, "eval_episode/length": 136.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 850096, "time": 39146.73209166527, "eval_episode/length": 184.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 850768, "time": 39169.46385860443, "episode/length": 161.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 850920, "time": 39175.9615252018, "episode/length": 172.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 850952, "time": 39178.69198870659, "episode/length": 195.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 850968, "time": 39180.819590091705, "episode/length": 302.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.0}
{"step": 851256, "time": 39192.13749551773, "episode/length": 388.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9922879177377892, "episode/intrinsic_return": 0.0}
{"step": 851448, "time": 39200.36372804642, "episode/length": 197.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 851632, "time": 39208.46751213074, "episode/length": 287.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 851672, "time": 39211.182626247406, "episode/length": 302.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 851888, "time": 39220.239204883575, "episode/length": 139.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 852144, "time": 39233.05495214462, "episode/length": 148.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 852296, "time": 39239.42495894432, "episode/length": 171.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 853072, "time": 39267.490254879, "episode/length": 202.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 853320, "time": 39277.28175449371, "episode/length": 210.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 853400, "time": 39281.60305714607, "episode/length": 40.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 853416, "time": 39283.74417209625, "episode/length": 158.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 853544, "time": 39289.68211436272, "episode/length": 285.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9965034965034965, "episode/intrinsic_return": 0.0}
{"step": 853552, "time": 39291.81381583214, "episode/length": 322.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9845201238390093, "episode/intrinsic_return": 0.0}
{"step": 853640, "time": 39296.16544556618, "episode/length": 167.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 853736, "time": 39300.96872115135, "episode/length": 230.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 853936, "time": 39309.477828502655, "episode/length": 64.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 853984, "time": 39312.63919901848, "episode/length": 54.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 855488, "time": 39365.09708356857, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 855512, "time": 39367.24399590492, "episode/length": 263.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9734848484848485, "episode/intrinsic_return": 0.0}
{"step": 855544, "time": 39369.942836761475, "episode/length": 248.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 855744, "time": 39378.63052225113, "episode/length": 262.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9809885931558935, "episode/intrinsic_return": 0.0}
{"step": 855752, "time": 39380.29435920715, "episode/length": 303.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9835526315789473, "episode/intrinsic_return": 0.0}
{"step": 855817, "time": 39385.01278972626, "train_stats/sum_log_reward": 9.568750212589899, "train_stats/max_log_achievement_collect_coal": 0.84375, "train_stats/max_log_achievement_collect_drink": 4.75, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.3958333333333333, "train_stats/max_log_achievement_collect_stone": 12.375, "train_stats/max_log_achievement_collect_wood": 9.385416666666666, "train_stats/max_log_achievement_defeat_skeleton": 0.0625, "train_stats/max_log_achievement_defeat_zombie": 0.84375, "train_stats/max_log_achievement_eat_cow": 0.13541666666666666, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.010416666666666666, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3854166666666667, "train_stats/max_log_achievement_make_wood_sword": 1.1041666666666667, "train_stats/max_log_achievement_place_furnace": 1.4270833333333333, "train_stats/max_log_achievement_place_plant": 1.3333333333333333, "train_stats/max_log_achievement_place_stone": 4.479166666666667, "train_stats/max_log_achievement_place_table": 2.5833333333333335, "train_stats/max_log_achievement_wake_up": 1.5833333333333333, "train_stats/mean_log_entropy": 0.5495108279089133, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.455526008880396, "train/action_min": 0.0, "train/action_std": 3.2956225271705244, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03426854928834833, "train/actor_opt_grad_steps": 52700.0, "train/actor_opt_loss": -11.112449390425098, "train/adv_mag": 0.45209688741526155, "train/adv_max": 0.3879054514624232, "train/adv_mean": 0.0014942095660719276, "train/adv_min": -0.37584591565801084, "train/adv_std": 0.049291062832093065, "train/cont_avg": 0.9952506744604317, "train/cont_loss_mean": 0.00018379214174782968, "train/cont_loss_std": 0.005597863949615023, "train/cont_neg_acc": 0.9917865712865651, "train/cont_neg_loss": 0.026920106349587632, "train/cont_pos_acc": 0.9999788021869797, "train/cont_pos_loss": 5.8897171747520484e-05, "train/cont_pred": 0.9952745291826536, "train/cont_rate": 0.9952506744604317, "train/dyn_loss_mean": 12.649345596917241, "train/dyn_loss_std": 9.423769024636249, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0598953452041682, "train/extr_critic_critic_opt_grad_steps": 52700.0, "train/extr_critic_critic_opt_loss": 15316.575961106115, "train/extr_critic_mag": 10.056687670645953, "train/extr_critic_max": 10.056687670645953, "train/extr_critic_mean": 3.5812802709263862, "train/extr_critic_min": -0.16333196146025075, "train/extr_critic_std": 2.3949793697261126, "train/extr_return_normed_mag": 1.4234053248124157, "train/extr_return_normed_max": 1.4234053248124157, "train/extr_return_normed_mean": 0.42282912906982917, "train/extr_return_normed_min": -0.10927153716413238, "train/extr_return_normed_std": 0.3161777513061496, "train/extr_return_rate": 0.9213312645610288, "train/extr_return_raw_mag": 11.259466404537504, "train/extr_return_raw_max": 11.259466404537504, "train/extr_return_raw_mean": 3.59272660282876, "train/extr_return_raw_min": -0.4837628136650264, "train/extr_return_raw_std": 2.4226988296714618, "train/extr_reward_mag": 1.0355198331874051, "train/extr_reward_max": 1.0355198331874051, "train/extr_reward_mean": 0.046691481613641166, "train/extr_reward_min": -0.41939526753459905, "train/extr_reward_std": 0.20064324976728976, "train/image_loss_mean": 6.294082247096, "train/image_loss_std": 11.090838199039156, "train/model_loss_mean": 13.939184950410032, "train/model_loss_std": 15.067223507723362, "train/model_opt_grad_norm": 53.140855208687164, "train/model_opt_grad_steps": 52654.79136690647, "train/model_opt_loss": 17990.720042715828, "train/model_opt_model_opt_grad_overflow": 0.007194244604316547, "train/model_opt_model_opt_grad_scale": 1285.9712230215828, "train/policy_entropy_mag": 2.4918418633852073, "train/policy_entropy_max": 2.4918418633852073, "train/policy_entropy_mean": 0.5517044363261985, "train/policy_entropy_min": 0.07937505471406223, "train/policy_entropy_std": 0.6763877201852181, "train/policy_logprob_mag": 7.438383764500241, "train/policy_logprob_max": -0.009455660967786106, "train/policy_logprob_mean": -0.5516110581459759, "train/policy_logprob_min": -7.438383764500241, "train/policy_logprob_std": 1.0972880472382196, "train/policy_randomness_mag": 0.8795108267729231, "train/policy_randomness_max": 0.8795108267729231, "train/policy_randomness_mean": 0.19472745629094487, "train/policy_randomness_min": 0.028015911029718763, "train/policy_randomness_std": 0.23873518396624557, "train/post_ent_mag": 61.1071726023722, "train/post_ent_max": 61.1071726023722, "train/post_ent_mean": 43.98089330659496, "train/post_ent_min": 20.72568645065637, "train/post_ent_std": 7.684680973025535, "train/prior_ent_mag": 71.05138232553605, "train/prior_ent_max": 71.05138232553605, "train/prior_ent_mean": 56.67349116922283, "train/prior_ent_min": 42.312400598320174, "train/prior_ent_std": 4.784677207041129, "train/rep_loss_mean": 12.649345596917241, "train/rep_loss_std": 9.423769024636249, "train/reward_avg": 0.02896667034666744, "train/reward_loss_mean": 0.055311580610682635, "train/reward_loss_std": 0.2475300046394197, "train/reward_max_data": 1.0215827389586745, "train/reward_max_pred": 1.012272632379326, "train/reward_neg_acc": 0.9922699357965867, "train/reward_neg_loss": 0.028553951893457406, "train/reward_pos_acc": 0.9722696332622776, "train/reward_pos_loss": 0.832864565386189, "train/reward_pred": 0.028106915463003323, "train/reward_rate": 0.033245278776978415, "eval_stats/sum_log_reward": 9.662500232458115, "eval_stats/max_log_achievement_collect_coal": 0.6875, "eval_stats/max_log_achievement_collect_drink": 4.375, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 12.125, "eval_stats/max_log_achievement_collect_wood": 10.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.375, "eval_stats/max_log_achievement_make_wood_sword": 1.5, "eval_stats/max_log_achievement_place_furnace": 1.3125, "eval_stats/max_log_achievement_place_plant": 1.1875, "eval_stats/max_log_achievement_place_stone": 4.5625, "eval_stats/max_log_achievement_place_table": 3.0, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.793531848510611e-06, "report/cont_loss_std": 7.58455425966531e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.4444372936850414e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.713339199544862e-06, "report/cont_pred": 0.9931615591049194, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 12.994285583496094, "report/dyn_loss_std": 9.042623519897461, "report/image_loss_mean": 6.1117353439331055, "report/image_loss_std": 10.53386116027832, "report/model_loss_mean": 13.984295845031738, "report/model_loss_std": 14.23143196105957, "report/post_ent_mag": 61.13623046875, "report/post_ent_max": 61.13623046875, "report/post_ent_mean": 43.773780822753906, "report/post_ent_min": 19.174304962158203, "report/post_ent_std": 7.2819623947143555, "report/prior_ent_mag": 71.3328857421875, "report/prior_ent_max": 71.3328857421875, "report/prior_ent_mean": 57.05236053466797, "report/prior_ent_min": 43.86260986328125, "report/prior_ent_std": 4.851995944976807, "report/rep_loss_mean": 12.994285583496094, "report/rep_loss_std": 9.042623519897461, "report/reward_avg": 0.04140625149011612, "report/reward_loss_mean": 0.07598629593849182, "report/reward_loss_std": 0.32436490058898926, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0121936798095703, "report/reward_neg_acc": 0.9856557846069336, "report/reward_neg_loss": 0.031424377113580704, "report/reward_pos_acc": 0.9583333730697632, "report/reward_pos_loss": 0.9820787310600281, "report/reward_pred": 0.039162710309028625, "report/reward_rate": 0.046875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 7.428268986586772e-07, "eval/cont_loss_std": 7.3768533184193075e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.861336361092981e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.060724899725756e-07, "eval/cont_pred": 0.9951167702674866, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.82045555114746, "eval/dyn_loss_std": 10.877134323120117, "eval/image_loss_mean": 10.676107406616211, "eval/image_loss_std": 16.573511123657227, "eval/model_loss_mean": 22.07679557800293, "eval/model_loss_std": 20.794424057006836, "eval/post_ent_mag": 59.715538024902344, "eval/post_ent_max": 59.715538024902344, "eval/post_ent_mean": 41.20419692993164, "eval/post_ent_min": 21.68741798400879, "eval/post_ent_std": 7.232564926147461, "eval/prior_ent_mag": 71.3328857421875, "eval/prior_ent_max": 71.3328857421875, "eval/prior_ent_mean": 57.17776107788086, "eval/prior_ent_min": 44.01941680908203, "eval/prior_ent_std": 4.38590145111084, "eval/rep_loss_mean": 18.82045555114746, "eval/rep_loss_std": 10.877134323120117, "eval/reward_avg": 0.01728515699505806, "eval/reward_loss_mean": 0.10841357707977295, "eval/reward_loss_std": 0.615356981754303, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0029149055480957, "eval/reward_neg_acc": 0.9839839935302734, "eval/reward_neg_loss": 0.07814664393663406, "eval/reward_pos_acc": 0.8799999952316284, "eval/reward_pos_loss": 1.317880392074585, "eval/reward_pred": 0.019889138638973236, "eval/reward_rate": 0.0244140625, "replay/size": 855313.0, "replay/inserts": 22144.0, "replay/samples": 22144.0, "replay/insert_wait_avg": 1.4222318554200188e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.590993164591706e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6376.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3428245912980256e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3388388156891, "timer/env.step_count": 2768.0, "timer/env.step_total": 233.8131034374237, "timer/env.step_frac": 0.23373390531775945, "timer/env.step_avg": 0.0844700518198785, "timer/env.step_min": 0.0242459774017334, "timer/env.step_max": 2.094376564025879, "timer/replay._sample_count": 22144.0, "timer/replay._sample_total": 11.485930919647217, "timer/replay._sample_frac": 0.011482040358690384, "timer/replay._sample_avg": 0.0005186926896516988, "timer/replay._sample_min": 0.0003726482391357422, "timer/replay._sample_max": 0.008930444717407227, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3565.0, "timer/agent.policy_total": 62.27651405334473, "timer/agent.policy_frac": 0.06225541950073087, "timer/agent.policy_avg": 0.017468867897151397, "timer/agent.policy_min": 0.009543895721435547, "timer/agent.policy_max": 0.12410306930541992, "timer/dataset_train_count": 1384.0, "timer/dataset_train_total": 0.15836644172668457, "timer/dataset_train_frac": 0.00015831279920529341, "timer/dataset_train_avg": 0.00011442661974471428, "timer/dataset_train_min": 9.846687316894531e-05, "timer/dataset_train_max": 0.0010998249053955078, "timer/agent.train_count": 1384.0, "timer/agent.train_total": 627.024197101593, "timer/agent.train_frac": 0.6268118089305951, "timer/agent.train_avg": 0.4530521655358331, "timer/agent.train_min": 0.43727946281433105, "timer/agent.train_max": 2.533396005630493, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47690820693969727, "timer/agent.report_frac": 0.0004767466666637812, "timer/agent.report_avg": 0.23845410346984863, "timer/agent.report_min": 0.2321925163269043, "timer/agent.report_max": 0.24471569061279297, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 6.461143493652344e-05, "timer/dataset_eval_frac": 6.458954949006833e-08, "timer/dataset_eval_avg": 6.461143493652344e-05, "timer/dataset_eval_min": 6.461143493652344e-05, "timer/dataset_eval_max": 6.461143493652344e-05, "fps": 22.13619155203494}
{"step": 856240, "time": 39399.32173585892, "episode/length": 570.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9947460595446584, "episode/intrinsic_return": 0.0}
{"step": 856352, "time": 39404.7878575325, "episode/length": 301.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9900662251655629, "episode/intrinsic_return": 0.0}
{"step": 856360, "time": 39406.52727794647, "episode/length": 327.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 857064, "time": 39431.79936361313, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 857072, "time": 39433.997962236404, "episode/length": 194.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 857096, "time": 39436.33290243149, "episode/length": 200.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 857128, "time": 39438.99549412727, "episode/length": 171.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 857488, "time": 39453.02630662918, "episode/length": 51.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 857856, "time": 39467.15249609947, "episode/length": 263.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9734848484848485, "episode/intrinsic_return": 0.0}
{"step": 857872, "time": 39469.270474910736, "episode/length": 189.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 858008, "time": 39475.102615356445, "episode/length": 220.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 858560, "time": 39495.685683488846, "episode/length": 186.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 858576, "time": 39498.158658504486, "episode/length": 184.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 858752, "time": 39505.717433691025, "episode/length": 202.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9852216748768473, "episode/intrinsic_return": 0.0}
{"step": 859120, "time": 39519.79782581329, "episode/length": 203.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 859264, "time": 39526.46974277496, "episode/length": 173.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 859368, "time": 39531.30937862396, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 39573.1496489048, "eval_episode/length": 56.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9122807017543859}
{"step": 860080, "time": 39580.75735139847, "eval_episode/length": 190.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 860080, "time": 39583.15757393837, "eval_episode/length": 205.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 860080, "time": 39587.04836678505, "eval_episode/length": 196.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 860080, "time": 39588.91186285019, "eval_episode/length": 259.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9961538461538462}
{"step": 860080, "time": 39592.987676143646, "eval_episode/length": 314.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9873015873015873}
{"step": 860080, "time": 39595.09572482109, "eval_episode/length": 324.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9907692307692307}
{"step": 860080, "time": 39596.7768304348, "eval_episode/length": 327.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9908536585365854}
{"step": 860240, "time": 39603.96989107132, "episode/length": 209.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 860752, "time": 39623.221764326096, "episode/length": 271.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 860808, "time": 39626.34562778473, "episode/length": 210.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 860928, "time": 39632.255502939224, "episode/length": 271.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 861008, "time": 39636.487302064896, "episode/length": 217.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 861128, "time": 39642.00083208084, "episode/length": 219.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 861184, "time": 39645.70326542854, "episode/length": 46.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 861480, "time": 39657.130994319916, "episode/length": 154.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 861952, "time": 39675.02030968666, "episode/length": 492.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9939148073022313, "episode/intrinsic_return": 0.0}
{"step": 862144, "time": 39683.18663048744, "episode/length": 722.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9986168741355463, "episode/intrinsic_return": 0.0}
{"step": 862192, "time": 39686.48380255699, "episode/length": 125.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 862464, "time": 39697.27867913246, "episode/length": 191.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 862568, "time": 39702.15088868141, "episode/length": 226.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 862848, "time": 39713.51299762726, "episode/length": 214.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 862896, "time": 39717.13721656799, "episode/length": 235.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 863216, "time": 39729.590960264206, "episode/length": 216.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 863392, "time": 39737.26931142807, "episode/length": 179.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 863792, "time": 39752.41666197777, "episode/length": 199.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 863872, "time": 39756.82725358009, "episode/length": 127.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 864112, "time": 39766.707221508026, "episode/length": 205.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 864848, "time": 39793.140092372894, "episode/length": 337.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9970414201183432, "episode/intrinsic_return": 0.0}
{"step": 865288, "time": 39809.57743597031, "episode/length": 339.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9970588235294118, "episode/intrinsic_return": 0.0}
{"step": 865424, "time": 39816.0893535614, "episode/length": 253.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9881889763779528, "episode/intrinsic_return": 0.0}
{"step": 865616, "time": 39824.14633321762, "episode/length": 217.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 865808, "time": 39832.4168946743, "episode/length": 251.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 866608, "time": 39861.08859086037, "episode/length": 463.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 866736, "time": 39867.061876535416, "episode/length": 327.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 866896, "time": 39874.14877986908, "episode/length": 183.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 866912, "time": 39876.29348278046, "episode/length": 461.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9978354978354979, "episode/intrinsic_return": 0.0}
{"step": 867688, "time": 39904.222437381744, "episode/length": 258.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 867824, "time": 39910.67060995102, "episode/length": 371.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 868152, "time": 39923.28269672394, "episode/length": 176.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 868312, "time": 39930.27989435196, "episode/length": 312.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9904153354632588, "episode/intrinsic_return": 0.0}
{"step": 868800, "time": 39950.50171613693, "episode/length": 235.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 869288, "time": 39968.459258794785, "episode/length": 298.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.0}
{"step": 869520, "time": 39978.09958648682, "episode/length": 211.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 869544, "time": 39980.176795482635, "episode/length": 531.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 869680, "time": 39986.555406332016, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 869936, "time": 39996.882608413696, "episode/length": 202.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 870064, "time": 40023.61995983124, "eval_episode/length": 170.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 870064, "time": 40026.65419626236, "eval_episode/length": 201.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9801980198019802}
{"step": 870064, "time": 40029.90889143944, "eval_episode/length": 237.0, "eval_episode/score": 12.099999994039536, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 870064, "time": 40032.17988348007, "eval_episode/length": 51.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9423076923076923}
{"step": 870064, "time": 40034.59181165695, "eval_episode/length": 271.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9816176470588235}
{"step": 870064, "time": 40036.61934900284, "eval_episode/length": 277.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9856115107913669}
{"step": 870064, "time": 40044.401720047, "eval_episode/length": 364.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9972602739726028}
{"step": 870064, "time": 40046.670939683914, "eval_episode/length": 140.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 870296, "time": 40054.25704097748, "episode/length": 325.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9969325153374233, "episode/intrinsic_return": 0.0}
{"step": 870360, "time": 40057.97552537918, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 870488, "time": 40063.89509367943, "episode/length": 120.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 871344, "time": 40094.58036494255, "episode/length": 207.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 871416, "time": 40098.48860192299, "episode/length": 233.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 871432, "time": 40100.589847803116, "episode/length": 267.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 871736, "time": 40112.40171575546, "episode/length": 37.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 871800, "time": 40116.167285203934, "episode/length": 232.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 871808, "time": 40118.280172109604, "episode/length": 649.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9984615384615385, "episode/intrinsic_return": 0.0}
{"step": 871960, "time": 40124.77267956734, "episode/length": 207.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 872272, "time": 40137.50579333305, "episode/length": 66.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 872480, "time": 40146.04330158234, "episode/length": 132.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 872544, "time": 40149.92210435867, "episode/length": 33.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 872920, "time": 40164.08158278465, "episode/length": 319.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.996875, "episode/intrinsic_return": 0.0}
{"step": 873512, "time": 40185.829365968704, "episode/length": 270.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 873528, "time": 40188.206097602844, "episode/length": 215.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 873568, "time": 40191.467113256454, "episode/length": 127.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 873984, "time": 40207.20229816437, "episode/length": 436.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9977116704805492, "episode/intrinsic_return": 0.0}
{"step": 874248, "time": 40217.630576610565, "episode/length": 220.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 874352, "time": 40223.01225042343, "episode/length": 178.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 874392, "time": 40225.764815568924, "episode/length": 322.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9876160990712074, "episode/intrinsic_return": 0.0}
{"step": 875008, "time": 40248.394752025604, "episode/length": 81.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9390243902439024, "episode/intrinsic_return": 0.0}
{"step": 875048, "time": 40251.203896045685, "episode/length": 189.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 875064, "time": 40253.725648641586, "episode/length": 186.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 875112, "time": 40256.96199154854, "episode/length": 393.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9974619289340102, "episode/intrinsic_return": 0.0}
{"step": 875320, "time": 40265.66882324219, "episode/length": 225.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 875328, "time": 40267.79052901268, "episode/length": 34.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 875784, "time": 40284.570209264755, "episode/length": 191.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 875864, "time": 40288.87005352974, "episode/length": 234.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 876400, "time": 40308.892718076706, "episode/length": 173.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 876552, "time": 40315.71918988228, "episode/length": 152.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 876920, "time": 40331.560522317886, "episode/length": 315.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9841772151898734, "episode/intrinsic_return": 0.0}
{"step": 876944, "time": 40334.16073060036, "episode/length": 228.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 877000, "time": 40337.60724687576, "episode/length": 74.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 877784, "time": 40365.79461979866, "episode/length": 153.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 877848, "time": 40369.74179172516, "episode/length": 247.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 878184, "time": 40382.69369506836, "episode/length": 299.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 878185, "time": 40385.33284139633, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.566310773577009, "train/action_min": 0.0, "train/action_std": 3.3166540793010166, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03471851755997964, "train/actor_opt_grad_steps": 54095.0, "train/actor_opt_loss": -6.597888632118702, "train/adv_mag": 0.44435145663363596, "train/adv_max": 0.3915971970983914, "train/adv_mean": 0.0024837126585875273, "train/adv_min": -0.3782526470720768, "train/adv_std": 0.05004610592233283, "train/cont_avg": 0.9953125, "train/cont_loss_mean": 0.00010337839383173072, "train/cont_loss_std": 0.0030568029702335154, "train/cont_neg_acc": 0.9963343619442672, "train/cont_neg_loss": 0.0075079578825660185, "train/cont_pos_acc": 0.9999649299042566, "train/cont_pos_loss": 6.499744146099471e-05, "train/cont_pred": 0.9952978364058903, "train/cont_rate": 0.9953125, "train/dyn_loss_mean": 12.811000061035156, "train/dyn_loss_std": 9.44254640851702, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0756424801690239, "train/extr_critic_critic_opt_grad_steps": 54095.0, "train/extr_critic_critic_opt_loss": 15606.381745256696, "train/extr_critic_mag": 10.079184246063232, "train/extr_critic_max": 10.079184246063232, "train/extr_critic_mean": 3.4815862008503506, "train/extr_critic_min": -0.17223713908876692, "train/extr_critic_std": 2.422600257396698, "train/extr_return_normed_mag": 1.4297330617904662, "train/extr_return_normed_max": 1.4297330617904662, "train/extr_return_normed_mean": 0.4128611290029117, "train/extr_return_normed_min": -0.1105262370247926, "train/extr_return_normed_std": 0.32099961255277903, "train/extr_return_rate": 0.9074205275092806, "train/extr_return_raw_mag": 11.260529790605817, "train/extr_return_raw_max": 11.260529790605817, "train/extr_return_raw_mean": 3.5005524362836566, "train/extr_return_raw_min": -0.4943187654018402, "train/extr_return_raw_std": 2.4500258105141777, "train/extr_reward_mag": 1.0356659701892308, "train/extr_reward_max": 1.0356659701892308, "train/extr_reward_mean": 0.047703713670905146, "train/extr_reward_min": -0.43436107890946524, "train/extr_reward_std": 0.2026957401207515, "train/image_loss_mean": 6.481815828595843, "train/image_loss_std": 11.618005211012704, "train/model_loss_mean": 14.225861161095755, "train/model_loss_std": 15.586344201224192, "train/model_opt_grad_norm": 52.099923038482665, "train/model_opt_grad_steps": 54048.514285714286, "train/model_opt_loss": 18187.541657366073, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1276.7857142857142, "train/policy_entropy_mag": 2.5125447937420438, "train/policy_entropy_max": 2.5125447937420438, "train/policy_entropy_mean": 0.5548908740282059, "train/policy_entropy_min": 0.07937506650175367, "train/policy_entropy_std": 0.6879854791930744, "train/policy_logprob_mag": 7.438383776800973, "train/policy_logprob_max": -0.009455665167687194, "train/policy_logprob_mean": -0.554924827175481, "train/policy_logprob_min": -7.438383776800973, "train/policy_logprob_std": 1.102838244182723, "train/policy_randomness_mag": 0.8868180526154382, "train/policy_randomness_max": 0.8868180526154382, "train/policy_randomness_mean": 0.19585212713905742, "train/policy_randomness_min": 0.028015915091548646, "train/policy_randomness_std": 0.24282868398087365, "train/post_ent_mag": 60.951882416861395, "train/post_ent_max": 60.951882416861395, "train/post_ent_mean": 43.799270330156595, "train/post_ent_min": 20.7612747328622, "train/post_ent_std": 7.619583405767169, "train/prior_ent_mag": 71.00920219421387, "train/prior_ent_max": 71.00920219421387, "train/prior_ent_mean": 56.66908411298479, "train/prior_ent_min": 42.162652124677386, "train/prior_ent_std": 4.76155584539686, "train/rep_loss_mean": 12.811000061035156, "train/rep_loss_std": 9.44254640851702, "train/reward_avg": 0.029912109087620462, "train/reward_loss_mean": 0.05734202378828611, "train/reward_loss_std": 0.2491055764257908, "train/reward_max_data": 1.0235714341912951, "train/reward_max_pred": 1.0153540108885084, "train/reward_neg_acc": 0.9923119966472899, "train/reward_neg_loss": 0.02988763427627938, "train/reward_pos_acc": 0.9722661827291761, "train/reward_pos_loss": 0.8292058054889951, "train/reward_pred": 0.02920927932219846, "train/reward_rate": 0.034458705357142856, "train_stats/sum_log_reward": 10.11075286711416, "train_stats/max_log_achievement_collect_coal": 1.064516129032258, "train_stats/max_log_achievement_collect_drink": 4.89247311827957, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.5698924731182795, "train_stats/max_log_achievement_collect_stone": 14.75268817204301, "train_stats/max_log_achievement_collect_wood": 9.946236559139784, "train_stats/max_log_achievement_defeat_skeleton": 0.043010752688172046, "train_stats/max_log_achievement_defeat_zombie": 0.7956989247311828, "train_stats/max_log_achievement_eat_cow": 0.20430107526881722, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.010752688172043012, "train_stats/max_log_achievement_make_wood_pickaxe": 1.6236559139784945, "train_stats/max_log_achievement_make_wood_sword": 1.1720430107526882, "train_stats/max_log_achievement_place_furnace": 2.075268817204301, "train_stats/max_log_achievement_place_plant": 1.4193548387096775, "train_stats/max_log_achievement_place_stone": 4.827956989247312, "train_stats/max_log_achievement_place_table": 2.6129032258064515, "train_stats/max_log_achievement_wake_up": 1.3440860215053763, "train_stats/mean_log_entropy": 0.5366881941595385, "eval_stats/sum_log_reward": 9.725000262260437, "eval_stats/max_log_achievement_collect_coal": 1.125, "eval_stats/max_log_achievement_collect_drink": 4.0625, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 13.0, "eval_stats/max_log_achievement_collect_wood": 9.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.0625, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.6875, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 1.9375, "eval_stats/max_log_achievement_place_plant": 1.0625, "eval_stats/max_log_achievement_place_stone": 3.9375, "eval_stats/max_log_achievement_place_table": 2.8125, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 4.490117646582803e-07, "report/cont_loss_std": 6.346772352117114e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.138811244862154e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.3160354228602955e-07, "report/cont_pred": 0.9960939884185791, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 11.492328643798828, "report/dyn_loss_std": 8.898850440979004, "report/image_loss_mean": 3.734511137008667, "report/image_loss_std": 6.635260581970215, "report/model_loss_mean": 10.678871154785156, "report/model_loss_std": 10.517827987670898, "report/post_ent_mag": 60.301109313964844, "report/post_ent_max": 60.301109313964844, "report/post_ent_mean": 44.043731689453125, "report/post_ent_min": 21.549022674560547, "report/post_ent_std": 7.411252975463867, "report/prior_ent_mag": 71.02275085449219, "report/prior_ent_max": 71.02275085449219, "report/prior_ent_mean": 55.56565856933594, "report/prior_ent_min": 45.13269805908203, "report/prior_ent_std": 4.482235431671143, "report/rep_loss_mean": 11.492328643798828, "report/rep_loss_std": 8.898850440979004, "report/reward_avg": 0.02763671800494194, "report/reward_loss_mean": 0.04896268993616104, "report/reward_loss_std": 0.2735244035720825, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0024046897888184, "report/reward_neg_acc": 0.9959676861763, "report/reward_neg_loss": 0.016936490312218666, "report/reward_pos_acc": 0.90625, "report/reward_pos_loss": 1.0417749881744385, "report/reward_pred": 0.024551698938012123, "report/reward_rate": 0.03125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 3.436517363297753e-05, "eval/cont_loss_std": 0.0008426097920164466, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0020496337674558163, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.0421400879276916e-05, "eval/cont_pred": 0.9980208873748779, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 18.864459991455078, "eval/dyn_loss_std": 10.793070793151855, "eval/image_loss_mean": 16.318687438964844, "eval/image_loss_std": 24.90875816345215, "eval/model_loss_mean": 27.746755599975586, "eval/model_loss_std": 28.775636672973633, "eval/post_ent_mag": 60.5987548828125, "eval/post_ent_max": 60.5987548828125, "eval/post_ent_mean": 41.92765808105469, "eval/post_ent_min": 21.030372619628906, "eval/post_ent_std": 7.238733768463135, "eval/prior_ent_mag": 71.02275085449219, "eval/prior_ent_max": 71.02275085449219, "eval/prior_ent_mean": 58.42955780029297, "eval/prior_ent_min": 41.942909240722656, "eval/prior_ent_std": 4.811509609222412, "eval/rep_loss_mean": 18.864459991455078, "eval/rep_loss_std": 10.793070793151855, "eval/reward_avg": 0.02695312350988388, "eval/reward_loss_mean": 0.10935976356267929, "eval/reward_loss_std": 0.5823787450790405, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0053825378417969, "eval/reward_neg_acc": 0.9778225421905518, "eval/reward_neg_loss": 0.0657503753900528, "eval/reward_pos_acc": 0.875, "eval/reward_pos_loss": 1.4612510204315186, "eval/reward_pred": 0.031557876616716385, "eval/reward_rate": 0.03125, "replay/size": 877681.0, "replay/inserts": 22368.0, "replay/samples": 22368.0, "replay/insert_wait_avg": 1.4317798853261617e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.650667677621474e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5656.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3146322889746163e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3087928295135, "timer/env.step_count": 2796.0, "timer/env.step_total": 232.6551673412323, "timer/env.step_frac": 0.23258334727133065, "timer/env.step_avg": 0.08321000262561956, "timer/env.step_min": 0.0242769718170166, "timer/env.step_max": 3.4468464851379395, "timer/replay._sample_count": 22368.0, "timer/replay._sample_total": 11.631080865859985, "timer/replay._sample_frac": 0.01162749038020534, "timer/replay._sample_avg": 0.0005199875208270737, "timer/replay._sample_min": 0.00041866302490234375, "timer/replay._sample_max": 0.011126279830932617, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3503.0, "timer/agent.policy_total": 61.709301471710205, "timer/agent.policy_frac": 0.06169025196425276, "timer/agent.policy_avg": 0.017616129452386584, "timer/agent.policy_min": 0.009587526321411133, "timer/agent.policy_max": 0.1296374797821045, "timer/dataset_train_count": 1398.0, "timer/dataset_train_total": 0.15865206718444824, "timer/dataset_train_frac": 0.00015860309168699662, "timer/dataset_train_avg": 0.00011348502659831777, "timer/dataset_train_min": 9.846687316894531e-05, "timer/dataset_train_max": 0.0008702278137207031, "timer/agent.train_count": 1398.0, "timer/agent.train_total": 631.0303540229797, "timer/agent.train_frac": 0.6308355565265221, "timer/agent.train_avg": 0.4513807968690842, "timer/agent.train_min": 0.43851637840270996, "timer/agent.train_max": 1.73990797996521, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47736358642578125, "timer/agent.report_frac": 0.0004772162254772264, "timer/agent.report_avg": 0.23868179321289062, "timer/agent.report_min": 0.2312157154083252, "timer/agent.report_max": 0.24614787101745605, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.050815742474557e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 22.360779207319048}
{"step": 878304, "time": 40389.39834332466, "episode/length": 404.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9950617283950617, "episode/intrinsic_return": 0.0}
{"step": 879096, "time": 40417.6824555397, "episode/length": 113.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9912280701754386, "episode/intrinsic_return": 0.0}
{"step": 879464, "time": 40431.82147550583, "episode/length": 201.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 879520, "time": 40435.49710416794, "episode/length": 151.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 879848, "time": 40447.85146903992, "episode/length": 365.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9863387978142076, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 40471.71421909332, "eval_episode/length": 45.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8913043478260869}
{"step": 880048, "time": 40476.413733005524, "eval_episode/length": 115.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9913793103448276}
{"step": 880048, "time": 40479.212102651596, "eval_episode/length": 141.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 880048, "time": 40480.97946333885, "eval_episode/length": 146.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9659863945578231}
{"step": 880048, "time": 40483.96326828003, "eval_episode/length": 175.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9659090909090909}
{"step": 880048, "time": 40483.97057032585, "eval_episode/length": 175.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 880048, "time": 40487.69617533684, "eval_episode/length": 181.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.967032967032967}
{"step": 880048, "time": 40490.932569503784, "eval_episode/length": 171.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 880080, "time": 40492.02137231827, "episode/length": 384.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9974025974025974, "episode/intrinsic_return": 0.0}
{"step": 880152, "time": 40495.90393424034, "episode/length": 131.0, "episode/score": 9.1000000461936, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 880224, "time": 40500.24885725975, "episode/length": 612.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9934747145187602, "episode/intrinsic_return": 0.0}
{"step": 880472, "time": 40509.99481844902, "episode/length": 440.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9977324263038548, "episode/intrinsic_return": 0.0}
{"step": 881000, "time": 40529.55861926079, "episode/length": 191.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 881080, "time": 40533.79874038696, "episode/length": 411.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9975728155339806, "episode/intrinsic_return": 0.0}
{"step": 881208, "time": 40539.72005939484, "episode/length": 210.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 881640, "time": 40555.970289707184, "episode/length": 185.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 881920, "time": 40567.16496968269, "episode/length": 180.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 882112, "time": 40575.23640346527, "episode/length": 235.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 882416, "time": 40587.20802640915, "episode/length": 150.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 882488, "time": 40591.042367219925, "episode/length": 329.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 882856, "time": 40605.1745967865, "episode/length": 54.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 882912, "time": 40609.05088043213, "episode/length": 353.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 883824, "time": 40641.4126060009, "episode/length": 352.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9886685552407932, "episode/intrinsic_return": 0.0}
{"step": 884080, "time": 40651.81207346916, "episode/length": 245.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 884120, "time": 40654.55536675453, "episode/length": 379.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 884176, "time": 40658.43605923653, "episode/length": 164.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 884176, "time": 40658.44598221779, "episode/length": 316.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9810725552050473, "episode/intrinsic_return": 0.0}
{"step": 884568, "time": 40674.835330963135, "episode/length": 206.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 884592, "time": 40677.55915117264, "episode/length": 58.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 885208, "time": 40701.44356060028, "episode/length": 339.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 885472, "time": 40712.187084198, "episode/length": 443.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9977477477477478, "episode/intrinsic_return": 0.0}
{"step": 886024, "time": 40732.44911813736, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 886032, "time": 40734.708485126495, "episode/length": 102.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 886264, "time": 40744.01927781105, "episode/length": 260.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 886520, "time": 40754.2906999588, "episode/length": 243.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9713114754098361, "episode/intrinsic_return": 0.0}
{"step": 886592, "time": 40758.68024301529, "episode/length": 301.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 886704, "time": 40763.981721162796, "episode/length": 327.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9817073170731707, "episode/intrinsic_return": 0.0}
{"step": 887056, "time": 40777.486607313156, "episode/length": 403.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9925742574257426, "episode/intrinsic_return": 0.0}
{"step": 887424, "time": 40791.53209519386, "episode/length": 173.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 887456, "time": 40794.19741368294, "episode/length": 247.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 887592, "time": 40800.24947476387, "episode/length": 195.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 887632, "time": 40803.46524357796, "episode/length": 115.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 888136, "time": 40821.91443371773, "episode/length": 233.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 888992, "time": 40852.93162369728, "episode/length": 174.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 889056, "time": 40856.79054689407, "episode/length": 316.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9842271293375394, "episode/intrinsic_return": 0.0}
{"step": 889080, "time": 40859.02269244194, "episode/length": 252.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 889232, "time": 40865.91239261627, "episode/length": 221.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 889248, "time": 40868.00096464157, "episode/length": 201.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 889248, "time": 40868.00857949257, "episode/length": 138.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 889296, "time": 40872.959255456924, "episode/length": 233.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 889400, "time": 40878.01000380516, "episode/length": 350.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9886039886039886, "episode/intrinsic_return": 0.0}
{"step": 890032, "time": 40922.18301010132, "eval_episode/length": 178.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 890032, "time": 40925.120249032974, "eval_episode/length": 207.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9711538461538461}
{"step": 890032, "time": 40928.13965392113, "eval_episode/length": 239.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 890032, "time": 40930.78611588478, "eval_episode/length": 263.0, "eval_episode/score": 7.10000005364418, "eval_episode/reward_rate": 0.9924242424242424}
{"step": 890032, "time": 40933.095108509064, "eval_episode/length": 279.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 890032, "time": 40934.997269153595, "eval_episode/length": 285.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9965034965034965}
{"step": 890032, "time": 40938.86059999466, "eval_episode/length": 331.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9909638554216867}
{"step": 890032, "time": 40941.967700242996, "eval_episode/length": 186.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 890544, "time": 40959.142510175705, "episode/length": 182.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 890776, "time": 40968.65390133858, "episode/length": 190.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 890960, "time": 40976.69822406769, "episode/length": 213.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 890968, "time": 40978.29171156883, "episode/length": 246.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 891624, "time": 41002.1363222599, "episode/length": 134.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 892064, "time": 41018.819024086, "episode/length": 353.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9971751412429378, "episode/intrinsic_return": 0.0}
{"step": 892568, "time": 41037.27015352249, "episode/length": 438.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.979498861047836, "episode/intrinsic_return": 0.0}
{"step": 892704, "time": 41043.69409894943, "episode/length": 217.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 892792, "time": 41048.00576329231, "episode/length": 251.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 892848, "time": 41051.737850904465, "episode/length": 443.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 892864, "time": 41053.830535173416, "episode/length": 432.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 893152, "time": 41066.886773347855, "episode/length": 72.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9452054794520548, "episode/intrinsic_return": 0.0}
{"step": 893328, "time": 41074.388986349106, "episode/length": 294.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9898305084745763, "episode/intrinsic_return": 0.0}
{"step": 893568, "time": 41084.038709402084, "episode/length": 242.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9835390946502057, "episode/intrinsic_return": 0.0}
{"step": 894560, "time": 41119.241646289825, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 894624, "time": 41122.99400520325, "episode/length": 219.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 895072, "time": 41139.62855863571, "episode/length": 375.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9867021276595744, "episode/intrinsic_return": 0.0}
{"step": 896232, "time": 41180.44578099251, "episode/length": 440.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 896280, "time": 41183.74664735794, "episode/length": 214.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 896328, "time": 41186.96691417694, "episode/length": 441.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.997737556561086, "episode/intrinsic_return": 0.0}
{"step": 896464, "time": 41193.404995918274, "episode/length": 173.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 896664, "time": 41201.541512966156, "episode/length": 53.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 896704, "time": 41204.717182159424, "episode/length": 443.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 896712, "time": 41206.60574507713, "episode/length": 422.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9976359338061466, "episode/intrinsic_return": 0.0}
{"step": 897384, "time": 41230.63396906853, "episode/length": 476.0, "episode/score": 14.100000023841858, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 898160, "time": 41258.63561177254, "episode/length": 441.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.997737556561086, "episode/intrinsic_return": 0.0}
{"step": 898168, "time": 41260.32167840004, "episode/length": 187.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 899472, "time": 41306.33773446083, "episode/length": 345.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9884393063583815, "episode/intrinsic_return": 0.0}
{"step": 899480, "time": 41308.098641872406, "episode/length": 345.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9884393063583815, "episode/intrinsic_return": 0.0}
{"step": 899560, "time": 41312.475818157196, "episode/length": 409.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 899832, "time": 41323.250027656555, "episode/length": 437.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.997716894977169, "episode/intrinsic_return": 0.0}
{"step": 900016, "time": 41351.678231954575, "eval_episode/length": 158.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 900016, "time": 41354.66868519783, "eval_episode/length": 188.0, "eval_episode/score": 11.100000016391277, "eval_episode/reward_rate": 0.9788359788359788}
{"step": 900016, "time": 41357.81995201111, "eval_episode/length": 217.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 900016, "time": 41360.691927194595, "eval_episode/length": 245.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9796747967479674}
{"step": 900016, "time": 41362.54498672485, "eval_episode/length": 250.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9641434262948207}
{"step": 900016, "time": 41364.86369371414, "eval_episode/length": 265.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9962406015037594}
{"step": 900016, "time": 41367.296990156174, "eval_episode/length": 283.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9859154929577465}
{"step": 900016, "time": 41371.37632513046, "eval_episode/length": 151.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.993421052631579}
{"step": 900264, "time": 41379.49897122383, "episode/length": 474.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9978947368421053, "episode/intrinsic_return": 0.0}
{"step": 900361, "time": 41385.352895498276, "train_stats/sum_log_reward": 10.337500149011612, "train_stats/max_log_achievement_collect_coal": 1.05, "train_stats/max_log_achievement_collect_drink": 7.625, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.225, "train_stats/max_log_achievement_collect_stone": 18.0625, "train_stats/max_log_achievement_collect_wood": 10.8, "train_stats/max_log_achievement_defeat_skeleton": 0.0875, "train_stats/max_log_achievement_defeat_zombie": 0.5375, "train_stats/max_log_achievement_eat_cow": 0.1625, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.025, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.6375, "train_stats/max_log_achievement_make_wood_sword": 1.25, "train_stats/max_log_achievement_place_furnace": 2.3125, "train_stats/max_log_achievement_place_plant": 1.2, "train_stats/max_log_achievement_place_stone": 6.725, "train_stats/max_log_achievement_place_table": 2.7375, "train_stats/max_log_achievement_wake_up": 1.8375, "train_stats/mean_log_entropy": 0.5644665844738483, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.479979141898777, "train/action_min": 0.0, "train/action_std": 3.216175808422807, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.034554622217040996, "train/actor_opt_grad_steps": 55485.0, "train/actor_opt_loss": -7.90908162260725, "train/adv_mag": 0.4600336767625118, "train/adv_max": 0.39542880891889765, "train/adv_mean": 0.0026523677935581845, "train/adv_min": -0.40158534913823224, "train/adv_std": 0.04987566256760687, "train/cont_avg": 0.995209182518116, "train/cont_loss_mean": 0.00029997152741918114, "train/cont_loss_std": 0.009130896296176656, "train/cont_neg_acc": 0.9926846118076987, "train/cont_neg_loss": 0.03958227111145433, "train/cont_pos_acc": 0.9999786593775818, "train/cont_pos_loss": 7.901352320614082e-05, "train/cont_pred": 0.9952102165291274, "train/cont_rate": 0.995209182518116, "train/dyn_loss_mean": 12.821842504584271, "train/dyn_loss_std": 9.460093007571455, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0164925430131995, "train/extr_critic_critic_opt_grad_steps": 55485.0, "train/extr_critic_critic_opt_loss": 15416.752023890398, "train/extr_critic_mag": 10.185119573620783, "train/extr_critic_max": 10.185119573620783, "train/extr_critic_mean": 3.586212322331857, "train/extr_critic_min": -0.14452794410180356, "train/extr_critic_std": 2.4618355545444763, "train/extr_return_normed_mag": 1.4240441892458044, "train/extr_return_normed_max": 1.4240441892458044, "train/extr_return_normed_mean": 0.4185776963182118, "train/extr_return_normed_min": -0.11041069208927777, "train/extr_return_normed_std": 0.3226567394491555, "train/extr_return_rate": 0.9179357726504838, "train/extr_return_raw_mag": 11.376841448355412, "train/extr_return_raw_max": 11.376841448355412, "train/extr_return_raw_mean": 3.606667852056199, "train/extr_return_raw_min": -0.48046061536972073, "train/extr_return_raw_std": 2.493097291476485, "train/extr_reward_mag": 1.0401756245156992, "train/extr_reward_max": 1.0401756245156992, "train/extr_reward_mean": 0.049971886087155, "train/extr_reward_min": -0.43116254391877545, "train/extr_reward_std": 0.20760243083687796, "train/image_loss_mean": 6.345710543618686, "train/image_loss_std": 11.172949034234751, "train/model_loss_mean": 14.096942030865213, "train/model_loss_std": 15.184207480886709, "train/model_opt_grad_norm": 52.58597860474517, "train/model_opt_grad_steps": 55437.3768115942, "train/model_opt_loss": 20175.174323482788, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1431.159420289855, "train/policy_entropy_mag": 2.5094874889954277, "train/policy_entropy_max": 2.5094874889954277, "train/policy_entropy_mean": 0.5233984822812288, "train/policy_entropy_min": 0.0793750390842341, "train/policy_entropy_std": 0.6573254409907521, "train/policy_logprob_mag": 7.438383828038755, "train/policy_logprob_max": -0.009455660135363754, "train/policy_logprob_mean": -0.5234479828589205, "train/policy_logprob_min": -7.438383828038755, "train/policy_logprob_std": 1.0836156166118125, "train/policy_randomness_mag": 0.8857389602108278, "train/policy_randomness_max": 0.8857389602108278, "train/policy_randomness_mean": 0.18473669746215793, "train/policy_randomness_min": 0.028015905356817486, "train/policy_randomness_std": 0.23200703433890274, "train/post_ent_mag": 61.080552419026695, "train/post_ent_max": 61.080552419026695, "train/post_ent_mean": 43.89898507491402, "train/post_ent_min": 20.689470208209492, "train/post_ent_std": 7.676994278811026, "train/prior_ent_mag": 71.02676645914714, "train/prior_ent_max": 71.02676645914714, "train/prior_ent_mean": 56.73486253489619, "train/prior_ent_min": 42.13303190037824, "train/prior_ent_std": 4.798692105472952, "train/rep_loss_mean": 12.821842504584271, "train/rep_loss_std": 9.460093007571455, "train/reward_avg": 0.031053979921600094, "train/reward_loss_mean": 0.05782609071204628, "train/reward_loss_std": 0.25335382432609366, "train/reward_max_data": 1.0246376870335012, "train/reward_max_pred": 1.0178420725076094, "train/reward_neg_acc": 0.9919658234153969, "train/reward_neg_loss": 0.029445655023058254, "train/reward_pos_acc": 0.974247491878012, "train/reward_pos_loss": 0.830583071363145, "train/reward_pred": 0.030378207078446514, "train/reward_rate": 0.035439311594202896, "eval_stats/sum_log_reward": 9.433333575725555, "eval_stats/max_log_achievement_collect_coal": 0.875, "eval_stats/max_log_achievement_collect_drink": 6.458333333333333, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 11.125, "eval_stats/max_log_achievement_collect_wood": 7.666666666666667, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.7916666666666666, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.9583333333333334, "eval_stats/max_log_achievement_place_furnace": 1.1666666666666667, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_stone": 3.8333333333333335, "eval_stats/max_log_achievement_place_table": 2.0416666666666665, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.1623187674558721e-06, "report/cont_loss_std": 3.095632200711407e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00018269963038619608, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.235436237986505e-08, "report/cont_pred": 0.9941415786743164, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 11.25462818145752, "report/dyn_loss_std": 9.090068817138672, "report/image_loss_mean": 6.479490280151367, "report/image_loss_std": 15.361754417419434, "report/model_loss_mean": 13.277755737304688, "report/model_loss_std": 18.42436408996582, "report/post_ent_mag": 59.99446105957031, "report/post_ent_max": 59.99446105957031, "report/post_ent_mean": 44.99006271362305, "report/post_ent_min": 21.820056915283203, "report/post_ent_std": 7.626687526702881, "report/prior_ent_mag": 70.99517822265625, "report/prior_ent_max": 70.99517822265625, "report/prior_ent_mean": 56.49177169799805, "report/prior_ent_min": 38.56787872314453, "report/prior_ent_std": 4.960230350494385, "report/rep_loss_mean": 11.25462818145752, "report/rep_loss_std": 9.090068817138672, "report/reward_avg": 0.02500000037252903, "report/reward_loss_mean": 0.045487456023693085, "report/reward_loss_std": 0.1629485785961151, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0041632652282715, "report/reward_neg_acc": 0.9939576983451843, "report/reward_neg_loss": 0.025447765365242958, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6874039769172668, "report/reward_pred": 0.02570171281695366, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.1412017784095951e-06, "eval/cont_loss_std": 1.298798179050209e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.433816841104999e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.801764010968327e-07, "eval/cont_pred": 0.9951165914535522, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.530357360839844, "eval/dyn_loss_std": 10.36363410949707, "eval/image_loss_mean": 9.139069557189941, "eval/image_loss_std": 10.826250076293945, "eval/model_loss_mean": 19.76304817199707, "eval/model_loss_std": 15.324798583984375, "eval/post_ent_mag": 60.125709533691406, "eval/post_ent_max": 60.125709533691406, "eval/post_ent_mean": 42.21310043334961, "eval/post_ent_min": 20.247600555419922, "eval/post_ent_std": 7.965951919555664, "eval/prior_ent_mag": 70.99517822265625, "eval/prior_ent_max": 70.99517822265625, "eval/prior_ent_mean": 57.899845123291016, "eval/prior_ent_min": 45.05924606323242, "eval/prior_ent_std": 4.513139724731445, "eval/rep_loss_mean": 17.530357360839844, "eval/rep_loss_std": 10.36363410949707, "eval/reward_avg": 0.04736328125, "eval/reward_loss_mean": 0.10576211661100388, "eval/reward_loss_std": 0.5129315257072449, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0029726028442383, "eval/reward_neg_acc": 0.9866117835044861, "eval/reward_neg_loss": 0.0348355695605278, "eval/reward_pos_acc": 0.8301886916160583, "eval/reward_pos_loss": 1.4051902294158936, "eval/reward_pred": 0.04086194187402725, "eval/reward_rate": 0.0517578125, "replay/size": 899857.0, "replay/inserts": 22176.0, "replay/samples": 22176.0, "replay/insert_wait_avg": 1.4395102277978674e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.704385372123333e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7400.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2621041890737173e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0024456977844, "timer/env.step_count": 2772.0, "timer/env.step_total": 207.0798840522766, "timer/env.step_frac": 0.20707937759870162, "timer/env.step_avg": 0.07470414287600166, "timer/env.step_min": 0.024061203002929688, "timer/env.step_max": 3.375075578689575, "timer/replay._sample_count": 22176.0, "timer/replay._sample_total": 11.597068071365356, "timer/replay._sample_frac": 0.011597039708511036, "timer/replay._sample_avg": 0.0005229558112989428, "timer/replay._sample_min": 0.0003814697265625, "timer/replay._sample_max": 0.010629892349243164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3697.0, "timer/agent.policy_total": 63.06293773651123, "timer/agent.policy_frac": 0.06306278350400134, "timer/agent.policy_avg": 0.01705786792981099, "timer/agent.policy_min": 0.009660959243774414, "timer/agent.policy_max": 0.09406495094299316, "timer/dataset_train_count": 1386.0, "timer/dataset_train_total": 0.1560382843017578, "timer/dataset_train_frac": 0.00015603790268020495, "timer/dataset_train_avg": 0.00011258173470545297, "timer/dataset_train_min": 9.655952453613281e-05, "timer/dataset_train_max": 0.0004115104675292969, "timer/agent.train_count": 1386.0, "timer/agent.train_total": 624.6779861450195, "timer/agent.train_frac": 0.6246764583751893, "timer/agent.train_avg": 0.45070561770924933, "timer/agent.train_min": 0.43604588508605957, "timer/agent.train_max": 1.7609171867370605, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47443485260009766, "timer/agent.report_frac": 0.0004744336922786676, "timer/agent.report_avg": 0.23721742630004883, "timer/agent.report_min": 0.22914505004882812, "timer/agent.report_max": 0.24528980255126953, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.741806954036776e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 22.175614725298725}
{"step": 900464, "time": 41389.01437115669, "episode/length": 287.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 900992, "time": 41408.33664941788, "episode/length": 450.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9955654101995566, "episode/intrinsic_return": 0.0}
{"step": 901056, "time": 41411.97250819206, "episode/length": 197.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 901616, "time": 41434.4200925827, "episode/length": 430.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9930394431554525, "episode/intrinsic_return": 0.0}
{"step": 901848, "time": 41443.72558546066, "episode/length": 197.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 902040, "time": 41451.9230222702, "episode/length": 275.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 902224, "time": 41459.89741206169, "episode/length": 153.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 902456, "time": 41469.08346605301, "episode/length": 371.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9919354838709677, "episode/intrinsic_return": 0.0}
{"step": 902808, "time": 41482.63719654083, "episode/length": 292.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 903048, "time": 41492.22758793831, "episode/length": 435.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9793577981651376, "episode/intrinsic_return": 0.0}
{"step": 903128, "time": 41496.45643568039, "episode/length": 159.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 903648, "time": 41515.9233520031, "episode/length": 177.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 904344, "time": 41540.80252623558, "episode/length": 191.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 904376, "time": 41543.402545928955, "episode/length": 291.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.976027397260274, "episode/intrinsic_return": 0.0}
{"step": 904440, "time": 41547.1775662899, "episode/length": 352.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9915014164305949, "episode/intrinsic_return": 0.0}
{"step": 904480, "time": 41550.36243343353, "episode/length": 427.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 905024, "time": 41570.516048669815, "episode/length": 236.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 905224, "time": 41578.63099741936, "episode/length": 345.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9971098265895953, "episode/intrinsic_return": 0.0}
{"step": 905784, "time": 41599.32133102417, "episode/length": 341.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9853801169590644, "episode/intrinsic_return": 0.0}
{"step": 905936, "time": 41606.716146469116, "episode/length": 186.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 906640, "time": 41632.22395324707, "episode/length": 282.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9787985865724381, "episode/intrinsic_return": 0.0}
{"step": 906688, "time": 41635.47582387924, "episode/length": 93.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9468085106382979, "episode/intrinsic_return": 0.0}
{"step": 906792, "time": 41640.29781913757, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 907024, "time": 41649.881432294846, "episode/length": 334.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9970149253731343, "episode/intrinsic_return": 0.0}
{"step": 907464, "time": 41666.28025174141, "episode/length": 304.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.980327868852459, "episode/intrinsic_return": 0.0}
{"step": 908144, "time": 41691.086067676544, "episode/length": 294.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9864406779661017, "episode/intrinsic_return": 0.0}
{"step": 908208, "time": 41694.845962285995, "episode/length": 176.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 908312, "time": 41699.77237558365, "episode/length": 208.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 908336, "time": 41702.35206270218, "episode/length": 205.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 908488, "time": 41708.889090538025, "episode/length": 604.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9900826446280991, "episode/intrinsic_return": 0.0}
{"step": 908680, "time": 41717.086243867874, "episode/length": 151.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 909000, "time": 41729.513132333755, "episode/length": 246.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 909352, "time": 41744.70079374313, "episode/length": 150.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 909568, "time": 41753.93397092819, "episode/length": 169.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 909584, "time": 41755.99590063095, "episode/length": 637.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9905956112852664, "episode/intrinsic_return": 0.0}
{"step": 909768, "time": 41763.67642188072, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 909872, "time": 41768.98440027237, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 910000, "time": 41774.97028899193, "episode/length": 188.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 910000, "time": 41794.845927000046, "eval_episode/length": 108.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9908256880733946}
{"step": 910000, "time": 41800.929194927216, "eval_episode/length": 207.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 910000, "time": 41802.639706373215, "eval_episode/length": 210.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.976303317535545}
{"step": 910000, "time": 41805.831765174866, "eval_episode/length": 134.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9925925925925926}
{"step": 910000, "time": 41807.74119544029, "eval_episode/length": 245.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9959349593495935}
{"step": 910000, "time": 41809.90358233452, "eval_episode/length": 258.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9961389961389961}
{"step": 910000, "time": 41813.0890185833, "eval_episode/length": 292.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9795221843003413}
{"step": 910000, "time": 41818.48852443695, "eval_episode/length": 371.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9865591397849462}
{"step": 910088, "time": 41822.7868680954, "episode/length": 175.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 910904, "time": 41851.92791175842, "episode/length": 237.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 911272, "time": 41866.148035764694, "episode/length": 174.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 911792, "time": 41885.50312304497, "episode/length": 304.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.980327868852459, "episode/intrinsic_return": 0.0}
{"step": 911872, "time": 41889.7079167366, "episode/length": 262.0, "episode/score": 13.099999994039536, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 912152, "time": 41900.664885520935, "episode/length": 257.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 912288, "time": 41907.08223819733, "episode/length": 339.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 912808, "time": 41926.153765916824, "episode/length": 237.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 913056, "time": 41936.385261297226, "episode/length": 433.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9792626728110599, "episode/intrinsic_return": 0.0}
{"step": 913328, "time": 41947.17905306816, "episode/length": 256.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9766536964980544, "episode/intrinsic_return": 0.0}
{"step": 914152, "time": 41976.44683766365, "episode/length": 102.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 914688, "time": 41996.4070250988, "episode/length": 234.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 914992, "time": 42008.11377334595, "episode/length": 623.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9983974358974359, "episode/intrinsic_return": 0.0}
{"step": 915040, "time": 42011.39171099663, "episode/length": 395.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 915856, "time": 42040.46705913544, "episode/length": 349.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9914285714285714, "episode/intrinsic_return": 0.0}
{"step": 915856, "time": 42040.47881746292, "episode/length": 462.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9978401727861771, "episode/intrinsic_return": 0.0}
{"step": 916072, "time": 42051.06050825119, "episode/length": 172.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 916576, "time": 42069.9704580307, "episode/length": 535.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9981343283582089, "episode/intrinsic_return": 0.0}
{"step": 916664, "time": 42074.28357410431, "episode/length": 208.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 917296, "time": 42097.638619184494, "episode/length": 152.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 917368, "time": 42101.41506910324, "episode/length": 188.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 917424, "time": 42105.22875022888, "episode/length": 105.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 917704, "time": 42118.15631556511, "episode/length": 443.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 917848, "time": 42124.504600048065, "episode/length": 147.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 917992, "time": 42130.9384200573, "episode/length": 774.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9974193548387097, "episode/intrinsic_return": 0.0}
{"step": 918624, "time": 42154.03491067886, "episode/length": 447.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9799107142857143, "episode/intrinsic_return": 0.0}
{"step": 918680, "time": 42157.2952144146, "episode/length": 121.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 919544, "time": 42188.19179868698, "episode/length": 264.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 920008, "time": 42205.7485742569, "episode/length": 172.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 920088, "time": 42228.38161230087, "eval_episode/length": 112.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9911504424778761}
{"step": 920088, "time": 42231.36440491676, "eval_episode/length": 142.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.993006993006993}
{"step": 920088, "time": 42234.848490953445, "eval_episode/length": 178.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 920088, "time": 42238.3229739666, "eval_episode/length": 206.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 920088, "time": 42238.33082318306, "eval_episode/length": 206.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 920088, "time": 42244.0149333477, "eval_episode/length": 261.0, "eval_episode/score": 13.100000008940697, "eval_episode/reward_rate": 0.9770992366412213}
{"step": 920088, "time": 42246.36231660843, "eval_episode/length": 274.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9963636363636363}
{"step": 920088, "time": 42250.09679841995, "eval_episode/length": 320.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9813084112149533}
{"step": 920312, "time": 42257.76512312889, "episode/length": 37.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 920424, "time": 42263.18476510048, "episode/length": 390.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.989769820971867, "episode/intrinsic_return": 0.0}
{"step": 920448, "time": 42265.906868219376, "episode/length": 324.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9969230769230769, "episode/intrinsic_return": 0.0}
{"step": 920624, "time": 42273.49626612663, "episode/length": 242.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 920808, "time": 42280.95828652382, "episode/length": 429.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 920960, "time": 42287.9019651413, "episode/length": 637.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9905956112852664, "episode/intrinsic_return": 0.0}
{"step": 921176, "time": 42296.40854406357, "episode/length": 397.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.992462311557789, "episode/intrinsic_return": 0.0}
{"step": 921528, "time": 42309.741933345795, "episode/length": 151.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 922256, "time": 42336.09694266319, "episode/length": 134.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 922312, "time": 42339.34170484543, "episode/length": 345.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9855491329479769, "episode/intrinsic_return": 0.0}
{"step": 922504, "time": 42347.42333006859, "episode/length": 259.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 922608, "time": 42352.71909928322, "episode/length": 247.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 922800, "time": 42360.86517930031, "episode/length": 158.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 923465, "time": 42385.61186552048, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.5041495487607754, "train/action_min": 0.0, "train/action_std": 3.291473761920271, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03409420296806714, "train/actor_opt_grad_steps": 56900.0, "train/actor_opt_loss": -5.793585849630421, "train/adv_mag": 0.4483891793366136, "train/adv_max": 0.3946743338272489, "train/adv_mean": 0.0026643477089739213, "train/adv_min": -0.37717975799379677, "train/adv_std": 0.04902235955513757, "train/cont_avg": 0.995245150862069, "train/cont_loss_mean": 8.856753730753518e-05, "train/cont_loss_std": 0.002618437575907545, "train/cont_neg_acc": 0.9970990703023713, "train/cont_neg_loss": 0.008281733199786184, "train/cont_pos_acc": 0.9999864602911062, "train/cont_pos_loss": 3.968998039565033e-05, "train/cont_pred": 0.9952509390896764, "train/cont_rate": 0.995245150862069, "train/dyn_loss_mean": 12.69388757245294, "train/dyn_loss_std": 9.455214717470366, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.060289337306187, "train/extr_critic_critic_opt_grad_steps": 56900.0, "train/extr_critic_critic_opt_loss": 15384.08538523707, "train/extr_critic_mag": 10.364913979892073, "train/extr_critic_max": 10.364913979892073, "train/extr_critic_mean": 3.572174096929616, "train/extr_critic_min": -0.14667751789093017, "train/extr_critic_std": 2.4584151679071886, "train/extr_return_normed_mag": 1.4289126165981951, "train/extr_return_normed_max": 1.4289126165981951, "train/extr_return_normed_mean": 0.4117819973107042, "train/extr_return_normed_min": -0.106306937388305, "train/extr_return_normed_std": 0.31896734905653984, "train/extr_return_rate": 0.9233984852659292, "train/extr_return_raw_mag": 11.517800923051505, "train/extr_return_raw_max": 11.517800923051505, "train/extr_return_raw_mean": 3.592937977560635, "train/extr_return_raw_min": -0.4439369324980111, "train/extr_return_raw_std": 2.485276722085887, "train/extr_reward_mag": 1.037436524752913, "train/extr_reward_max": 1.037436524752913, "train/extr_reward_mean": 0.04973714453136099, "train/extr_reward_min": -0.41973707840360447, "train/extr_reward_std": 0.2062137502020803, "train/image_loss_mean": 6.3848007169263115, "train/image_loss_std": 11.476572118956467, "train/model_loss_mean": 14.057129846770188, "train/model_loss_std": 15.468486075565734, "train/model_opt_grad_norm": 52.47017067218649, "train/model_opt_grad_steps": 56851.020689655175, "train/model_opt_loss": 19479.413294719827, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1387.9310344827586, "train/policy_entropy_mag": 2.4656643522196804, "train/policy_entropy_max": 2.4656643522196804, "train/policy_entropy_mean": 0.538773565456785, "train/policy_entropy_min": 0.0793750375509262, "train/policy_entropy_std": 0.6654203071676451, "train/policy_logprob_mag": 7.43838377985461, "train/policy_logprob_max": -0.009455660011233954, "train/policy_logprob_mean": -0.5393938907261553, "train/policy_logprob_min": -7.43838377985461, "train/policy_logprob_std": 1.09284845878338, "train/policy_randomness_mag": 0.8702713140125933, "train/policy_randomness_max": 0.8702713140125933, "train/policy_randomness_mean": 0.1901634266664242, "train/policy_randomness_min": 0.0280159048993012, "train/policy_randomness_std": 0.23486416905090726, "train/post_ent_mag": 61.14944773706897, "train/post_ent_max": 61.14944773706897, "train/post_ent_mean": 44.02932057873956, "train/post_ent_min": 20.806305207877323, "train/post_ent_std": 7.659176204944479, "train/prior_ent_mag": 71.05731359021416, "train/prior_ent_max": 71.05731359021416, "train/prior_ent_mean": 56.78413075414197, "train/prior_ent_min": 42.46532650651603, "train/prior_ent_std": 4.818838616075187, "train/rep_loss_mean": 12.69388757245294, "train/rep_loss_std": 9.455214717470366, "train/reward_avg": 0.030780576233719957, "train/reward_loss_mean": 0.05590802848595997, "train/reward_loss_std": 0.246984710826956, "train/reward_max_data": 1.0193103494315312, "train/reward_max_pred": 1.0142856129284563, "train/reward_neg_acc": 0.9928003574239797, "train/reward_neg_loss": 0.027737061236182164, "train/reward_pos_acc": 0.9689499263105721, "train/reward_pos_loss": 0.8379750358647313, "train/reward_pred": 0.029695885968876297, "train/reward_rate": 0.034900323275862066, "train_stats/sum_log_reward": 10.65000015795231, "train_stats/max_log_achievement_collect_coal": 1.0625, "train_stats/max_log_achievement_collect_drink": 8.9875, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.525, "train_stats/max_log_achievement_collect_stone": 16.7625, "train_stats/max_log_achievement_collect_wood": 9.9875, "train_stats/max_log_achievement_defeat_skeleton": 0.0875, "train_stats/max_log_achievement_defeat_zombie": 0.7625, "train_stats/max_log_achievement_eat_cow": 0.2625, "train_stats/max_log_achievement_eat_plant": 0.0125, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.6625, "train_stats/max_log_achievement_make_wood_sword": 1.075, "train_stats/max_log_achievement_place_furnace": 2.5125, "train_stats/max_log_achievement_place_plant": 1.475, "train_stats/max_log_achievement_place_stone": 4.875, "train_stats/max_log_achievement_place_table": 2.75, "train_stats/max_log_achievement_wake_up": 2.0375, "train_stats/mean_log_entropy": 0.5932191006839276, "eval_stats/sum_log_reward": 10.412500321865082, "eval_stats/max_log_achievement_collect_coal": 1.0, "eval_stats/max_log_achievement_collect_drink": 5.8125, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.5625, "eval_stats/max_log_achievement_collect_stone": 11.125, "eval_stats/max_log_achievement_collect_wood": 8.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 1.4375, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.4375, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_furnace": 1.5, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 3.1875, "eval_stats/max_log_achievement_place_table": 2.5625, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.4564881212209002e-06, "report/cont_loss_std": 3.250446752645075e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002364001702517271, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.17513799486369e-08, "report/cont_pred": 0.9941419363021851, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.106849670410156, "report/dyn_loss_std": 9.319645881652832, "report/image_loss_mean": 7.086317539215088, "report/image_loss_std": 12.590434074401855, "report/model_loss_mean": 15.002681732177734, "report/model_loss_std": 16.524690628051758, "report/post_ent_mag": 62.92073059082031, "report/post_ent_max": 62.92073059082031, "report/post_ent_mean": 43.61906814575195, "report/post_ent_min": 20.93006134033203, "report/post_ent_std": 7.901375770568848, "report/prior_ent_mag": 71.29410552978516, "report/prior_ent_max": 71.29410552978516, "report/prior_ent_mean": 57.068729400634766, "report/prior_ent_min": 38.84433364868164, "report/prior_ent_std": 5.165280342102051, "report/rep_loss_mean": 13.106849670410156, "report/rep_loss_std": 9.319645881652832, "report/reward_avg": 0.03144530951976776, "report/reward_loss_mean": 0.05225247144699097, "report/reward_loss_std": 0.21119165420532227, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0130794048309326, "report/reward_neg_acc": 0.9989878535270691, "report/reward_neg_loss": 0.026041094213724136, "report/reward_pos_acc": 0.9722222089767456, "report/reward_pos_loss": 0.7716091275215149, "report/reward_pred": 0.03019813261926174, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0003712693287525326, "eval/cont_loss_std": 0.011660595424473286, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.12669329345226288, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.790313981739018e-08, "eval/cont_pred": 0.9973810911178589, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.955303192138672, "eval/dyn_loss_std": 10.664945602416992, "eval/image_loss_mean": 11.82284927368164, "eval/image_loss_std": 16.539268493652344, "eval/model_loss_mean": 22.0989990234375, "eval/model_loss_std": 20.506919860839844, "eval/post_ent_mag": 60.21765899658203, "eval/post_ent_max": 60.21765899658203, "eval/post_ent_mean": 43.99940872192383, "eval/post_ent_min": 19.469058990478516, "eval/post_ent_std": 8.4661865234375, "eval/prior_ent_mag": 71.29410552978516, "eval/prior_ent_max": 71.29410552978516, "eval/prior_ent_mean": 58.96359634399414, "eval/prior_ent_min": 46.44468307495117, "eval/prior_ent_std": 4.624802589416504, "eval/rep_loss_mean": 16.955303192138672, "eval/rep_loss_std": 10.664945602416992, "eval/reward_avg": 0.03632812201976776, "eval/reward_loss_mean": 0.10259649157524109, "eval/reward_loss_std": 0.6756762862205505, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.003532886505127, "eval/reward_neg_acc": 0.9928789734840393, "eval/reward_neg_loss": 0.023910365998744965, "eval/reward_pos_acc": 0.7804877758026123, "eval/reward_pos_loss": 1.989144206047058, "eval/reward_pred": 0.02655588462948799, "eval/reward_rate": 0.0400390625, "replay/size": 922961.0, "replay/inserts": 23104.0, "replay/samples": 23104.0, "replay/insert_wait_avg": 1.4317910757091236e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.749891681354131e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5544.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2781024839282896e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.246600151062, "timer/env.step_count": 2888.0, "timer/env.step_total": 210.02712845802307, "timer/env.step_frac": 0.20997534850536234, "timer/env.step_avg": 0.07272407495083902, "timer/env.step_min": 0.02454829216003418, "timer/env.step_max": 3.4096384048461914, "timer/replay._sample_count": 23104.0, "timer/replay._sample_total": 12.081040859222412, "timer/replay._sample_frac": 0.012078062407208259, "timer/replay._sample_avg": 0.0005228982366353191, "timer/replay._sample_min": 0.00040841102600097656, "timer/replay._sample_max": 0.010787725448608398, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3581.0, "timer/agent.policy_total": 63.06860852241516, "timer/agent.policy_frac": 0.06305305962838588, "timer/agent.policy_avg": 0.017612010198943078, "timer/agent.policy_min": 0.009550809860229492, "timer/agent.policy_max": 0.14651107788085938, "timer/dataset_train_count": 1444.0, "timer/dataset_train_total": 0.16822433471679688, "timer/dataset_train_frac": 0.00016818286079791806, "timer/dataset_train_avg": 0.00011649884675678454, "timer/dataset_train_min": 9.894371032714844e-05, "timer/dataset_train_max": 0.004174947738647461, "timer/agent.train_count": 1444.0, "timer/agent.train_total": 651.4873230457306, "timer/agent.train_frac": 0.651326705781694, "timer/agent.train_avg": 0.45116850626435634, "timer/agent.train_min": 0.43587565422058105, "timer/agent.train_max": 1.8050212860107422, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4740016460418701, "timer/agent.report_frac": 0.00047388478598206095, "timer/agent.report_avg": 0.23700082302093506, "timer/agent.report_min": 0.23118901252746582, "timer/agent.report_max": 0.2428126335144043, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.05100543409906e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 23.097969774180818}
{"step": 923592, "time": 42389.75821065903, "episode/length": 392.0, "episode/score": 13.099999979138374, "episode/reward_rate": 0.9974554707379135, "episode/intrinsic_return": 0.0}
{"step": 923928, "time": 42402.77118706703, "episode/length": 140.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 924064, "time": 42409.47010540962, "episode/length": 58.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 924416, "time": 42423.47314095497, "episode/length": 60.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 924424, "time": 42425.277572870255, "episode/length": 432.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 924512, "time": 42430.21369218826, "episode/length": 462.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9892008639308856, "episode/intrinsic_return": 0.0}
{"step": 924576, "time": 42433.985807180405, "episode/length": 245.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 924752, "time": 42441.60760974884, "episode/length": 304.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 924984, "time": 42450.68644452095, "episode/length": 309.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9806451612903225, "episode/intrinsic_return": 0.0}
{"step": 925280, "time": 42462.46575379372, "episode/length": 151.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 925384, "time": 42467.39080643654, "episode/length": 390.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9948849104859335, "episode/intrinsic_return": 0.0}
{"step": 926200, "time": 42498.13263607025, "episode/length": 221.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 926232, "time": 42500.982286930084, "episode/length": 206.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 926416, "time": 42509.055981874466, "episode/length": 141.0, "episode/score": 12.10000005364418, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 927104, "time": 42534.21093606949, "episode/length": 214.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 927184, "time": 42538.52080202103, "episode/length": 303.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 927792, "time": 42560.803439855576, "episode/length": 421.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9786729857819905, "episode/intrinsic_return": 0.0}
{"step": 927976, "time": 42568.343908786774, "episode/length": 221.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 928008, "time": 42571.03877258301, "episode/length": 112.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9911504424778761, "episode/intrinsic_return": 0.0}
{"step": 928152, "time": 42577.424567222595, "episode/length": 395.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 928536, "time": 42592.19832134247, "episode/length": 287.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 929136, "time": 42614.23368144035, "episode/length": 339.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 929192, "time": 42617.57855629921, "episode/length": 584.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 929344, "time": 42624.515136003494, "episode/length": 269.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 930072, "time": 42671.62245988846, "eval_episode/length": 165.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 930072, "time": 42673.522446870804, "eval_episode/length": 171.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 930072, "time": 42675.26508164406, "eval_episode/length": 176.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 930072, "time": 42679.792907714844, "eval_episode/length": 234.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9829787234042553}
{"step": 930072, "time": 42681.57664346695, "eval_episode/length": 236.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9789029535864979}
{"step": 930072, "time": 42685.49055480957, "eval_episode/length": 288.0, "eval_episode/score": 13.100000001490116, "eval_episode/reward_rate": 0.9792387543252595}
{"step": 930072, "time": 42688.81970977783, "eval_episode/length": 328.0, "eval_episode/score": 12.100000016391277, "eval_episode/reward_rate": 0.993920972644377}
{"step": 930072, "time": 42691.505088329315, "eval_episode/length": 351.0, "eval_episode/score": 12.099999979138374, "eval_episode/reward_rate": 0.9971590909090909}
{"step": 930424, "time": 42703.46546411514, "episode/length": 301.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9900662251655629, "episode/intrinsic_return": 0.0}
{"step": 930592, "time": 42711.097275972366, "episode/length": 304.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9901639344262295, "episode/intrinsic_return": 0.0}
{"step": 931184, "time": 42732.65358686447, "episode/length": 400.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 931216, "time": 42735.39689087868, "episode/length": 259.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 931288, "time": 42739.363131284714, "episode/length": 242.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 931320, "time": 42741.99291229248, "episode/length": 440.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9977324263038548, "episode/intrinsic_return": 0.0}
{"step": 931504, "time": 42750.113030433655, "episode/length": 370.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9892183288409704, "episode/intrinsic_return": 0.0}
{"step": 932504, "time": 42785.449887514114, "episode/length": 160.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 932528, "time": 42788.05223321915, "episode/length": 262.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9885931558935361, "episode/intrinsic_return": 0.0}
{"step": 932800, "time": 42798.920667886734, "episode/length": 450.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9800443458980045, "episode/intrinsic_return": 0.0}
{"step": 932960, "time": 42806.05398225784, "episode/length": 208.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 933032, "time": 42809.916541576385, "episode/length": 65.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9242424242424242, "episode/intrinsic_return": 0.0}
{"step": 933152, "time": 42815.86301469803, "episode/length": 319.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.978125, "episode/intrinsic_return": 0.0}
{"step": 933320, "time": 42822.89373779297, "episode/length": 226.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 933336, "time": 42824.99782848358, "episode/length": 268.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 934560, "time": 42870.28582382202, "episode/length": 154.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9548387096774194, "episode/intrinsic_return": 0.0}
{"step": 934696, "time": 42876.32121229172, "episode/length": 207.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 934752, "time": 42879.988176584244, "episode/length": 428.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953379953379954, "episode/intrinsic_return": 0.0}
{"step": 934928, "time": 42887.78293180466, "episode/length": 221.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 935000, "time": 42891.52984404564, "episode/length": 308.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 935112, "time": 42896.772176742554, "episode/length": 268.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 935168, "time": 42900.549327373505, "episode/length": 295.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9831081081081081, "episode/intrinsic_return": 0.0}
{"step": 935472, "time": 42912.498546123505, "episode/length": 44.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9111111111111111, "episode/intrinsic_return": 0.0}
{"step": 935864, "time": 42927.2132730484, "episode/length": 315.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9968354430379747, "episode/intrinsic_return": 0.0}
{"step": 936416, "time": 42947.85338163376, "episode/length": 214.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 936696, "time": 42958.73274421692, "episode/length": 266.0, "episode/score": 12.100000038743019, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 936792, "time": 42963.63564634323, "episode/length": 254.0, "episode/score": 13.099999979138374, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 937272, "time": 42981.71610546112, "episode/length": 262.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 937320, "time": 42984.96350693703, "episode/length": 230.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 937432, "time": 42990.28758263588, "episode/length": 312.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9840255591054313, "episode/intrinsic_return": 0.0}
{"step": 937496, "time": 42994.02266049385, "episode/length": 203.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 937528, "time": 42996.651272535324, "episode/length": 315.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9968354430379747, "episode/intrinsic_return": 0.0}
{"step": 937712, "time": 43004.62765455246, "episode/length": 161.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 937808, "time": 43009.63008618355, "episode/length": 60.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 937960, "time": 43016.107746601105, "episode/length": 57.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 938960, "time": 43051.724192380905, "episode/length": 155.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 939720, "time": 43078.85541367531, "episode/length": 285.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 939800, "time": 43083.171711206436, "episode/length": 248.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 939816, "time": 43085.19190406799, "episode/length": 377.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9973544973544973, "episode/intrinsic_return": 0.0}
{"step": 940056, "time": 43113.025577545166, "eval_episode/length": 64.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9846153846153847}
{"step": 940056, "time": 43120.15994858742, "eval_episode/length": 178.0, "eval_episode/score": 11.099999979138374, "eval_episode/reward_rate": 0.994413407821229}
{"step": 940056, "time": 43124.626235961914, "eval_episode/length": 241.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9793388429752066}
{"step": 940056, "time": 43127.550740242004, "eval_episode/length": 265.0, "eval_episode/score": 11.1000000461936, "eval_episode/reward_rate": 0.9962406015037594}
{"step": 940056, "time": 43129.360607385635, "eval_episode/length": 266.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9962546816479401}
{"step": 940056, "time": 43131.47657299042, "eval_episode/length": 276.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9747292418772563}
{"step": 940056, "time": 43136.067419052124, "eval_episode/length": 344.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9855072463768116}
{"step": 940056, "time": 43138.78229570389, "eval_episode/length": 304.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 940128, "time": 43141.45169711113, "episode/length": 356.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9859943977591037, "episode/intrinsic_return": 0.0}
{"step": 940560, "time": 43157.78434038162, "episode/length": 482.0, "episode/score": 9.100000038743019, "episode/reward_rate": 0.9979296066252588, "episode/intrinsic_return": 0.0}
{"step": 940672, "time": 43163.10371923447, "episode/length": 338.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9970501474926253, "episode/intrinsic_return": 0.0}
{"step": 940712, "time": 43165.90054607391, "episode/length": 397.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9874371859296482, "episode/intrinsic_return": 0.0}
{"step": 940800, "time": 43170.67412877083, "episode/length": 229.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 940880, "time": 43174.96133375168, "episode/length": 144.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 941120, "time": 43184.62165379524, "episode/length": 123.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 941296, "time": 43192.35665535927, "episode/length": 61.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 942472, "time": 43235.265297174454, "episode/length": 238.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 943048, "time": 43256.25221633911, "episode/length": 296.0, "episode/score": 14.099999979138374, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 943096, "time": 43259.43382406235, "episode/length": 411.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9927184466019418, "episode/intrinsic_return": 0.0}
{"step": 943128, "time": 43262.11526608467, "episode/length": 413.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 943384, "time": 43272.28791356087, "episode/length": 312.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9936102236421726, "episode/intrinsic_return": 0.0}
{"step": 943528, "time": 43278.773564100266, "episode/length": 300.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9900332225913622, "episode/intrinsic_return": 0.0}
{"step": 943736, "time": 43287.43999671936, "episode/length": 304.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 944448, "time": 43313.531687259674, "episode/length": 466.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9978586723768736, "episode/intrinsic_return": 0.0}
{"step": 944736, "time": 43324.927137851715, "episode/length": 200.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9651741293532339, "episode/intrinsic_return": 0.0}
{"step": 944888, "time": 43331.41752576828, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 944952, "time": 43335.265072107315, "episode/length": 195.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.0}
{"step": 944976, "time": 43338.14607024193, "episode/length": 312.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9936102236421726, "episode/intrinsic_return": 0.0}
{"step": 945080, "time": 43343.07088422775, "episode/length": 167.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 945792, "time": 43369.047887802124, "episode/length": 342.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9883381924198251, "episode/intrinsic_return": 0.0}
{"step": 946217, "time": 43385.84946870804, "train_stats/sum_log_reward": 10.194117826573988, "train_stats/max_log_achievement_collect_coal": 1.0588235294117647, "train_stats/max_log_achievement_collect_drink": 6.870588235294117, "train_stats/max_log_achievement_collect_iron": 0.011764705882352941, "train_stats/max_log_achievement_collect_sapling": 1.2, "train_stats/max_log_achievement_collect_stone": 17.270588235294117, "train_stats/max_log_achievement_collect_wood": 10.694117647058823, "train_stats/max_log_achievement_defeat_skeleton": 0.1411764705882353, "train_stats/max_log_achievement_defeat_zombie": 0.9294117647058824, "train_stats/max_log_achievement_eat_cow": 0.2235294117647059, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.011764705882352941, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.8588235294117648, "train_stats/max_log_achievement_make_wood_sword": 1.3411764705882352, "train_stats/max_log_achievement_place_furnace": 2.541176470588235, "train_stats/max_log_achievement_place_plant": 1.1764705882352942, "train_stats/max_log_achievement_place_stone": 5.2823529411764705, "train_stats/max_log_achievement_place_table": 2.9176470588235293, "train_stats/max_log_achievement_wake_up": 1.3764705882352941, "train_stats/mean_log_entropy": 0.5481356245629928, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.487572898327465, "train/action_min": 0.0, "train/action_std": 3.3083880854324557, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.033675415585683266, "train/actor_opt_grad_steps": 58335.0, "train/actor_opt_loss": -8.340138296321244, "train/adv_mag": 0.4454723896694855, "train/adv_max": 0.3938176411558205, "train/adv_mean": 0.002413324207839356, "train/adv_min": -0.3732714929001432, "train/adv_std": 0.04895907165613812, "train/cont_avg": 0.9952822403169014, "train/cont_loss_mean": 0.00021798046052515894, "train/cont_loss_std": 0.0066830647690122235, "train/cont_neg_acc": 0.9908392437806366, "train/cont_neg_loss": 0.024551857516495624, "train/cont_pos_acc": 0.9999377916396504, "train/cont_pos_loss": 0.00010648196099803332, "train/cont_pred": 0.9952676925860661, "train/cont_rate": 0.9952822403169014, "train/dyn_loss_mean": 12.90177785846549, "train/dyn_loss_std": 9.455265199634391, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0323110235408999, "train/extr_critic_critic_opt_grad_steps": 58335.0, "train/extr_critic_critic_opt_loss": 15399.741919289172, "train/extr_critic_mag": 10.555499016399114, "train/extr_critic_max": 10.555499016399114, "train/extr_critic_mean": 3.6531043338104032, "train/extr_critic_min": -0.15436767440446666, "train/extr_critic_std": 2.531344089709537, "train/extr_return_normed_mag": 1.4130160036221358, "train/extr_return_normed_max": 1.4130160036221358, "train/extr_return_normed_mean": 0.4126308736666827, "train/extr_return_normed_min": -0.10954214325568205, "train/extr_return_normed_std": 0.322643100165985, "train/extr_return_rate": 0.9199155048585274, "train/extr_return_raw_mag": 11.610131250300878, "train/extr_return_raw_max": 11.610131250300878, "train/extr_return_raw_mean": 3.6721863461212374, "train/extr_return_raw_min": -0.47072998324120546, "train/extr_return_raw_std": 2.5601091821428756, "train/extr_reward_mag": 1.0464368353427296, "train/extr_reward_max": 1.0464368353427296, "train/extr_reward_mean": 0.05048145243609455, "train/extr_reward_min": -0.43458802095601257, "train/extr_reward_std": 0.20875983485873317, "train/image_loss_mean": 6.473831284214073, "train/image_loss_std": 11.798458468746132, "train/model_loss_mean": 14.272424113582558, "train/model_loss_std": 15.734781715231883, "train/model_opt_grad_norm": 52.3387842922346, "train/model_opt_grad_steps": 58284.612676056335, "train/model_opt_loss": 18209.27459286972, "train/model_opt_model_opt_grad_overflow": 0.007042253521126761, "train/model_opt_model_opt_grad_scale": 1267.605633802817, "train/policy_entropy_mag": 2.4711058559552046, "train/policy_entropy_max": 2.4711058559552046, "train/policy_entropy_mean": 0.5105203123579563, "train/policy_entropy_min": 0.0793750374250009, "train/policy_entropy_std": 0.6570290196949328, "train/policy_logprob_mag": 7.438383847894803, "train/policy_logprob_max": -0.009455658397047033, "train/policy_logprob_mean": -0.5105653027413597, "train/policy_logprob_min": -7.438383847894803, "train/policy_logprob_std": 1.073747927034405, "train/policy_randomness_mag": 0.8721919236048846, "train/policy_randomness_max": 0.8721919236048846, "train/policy_randomness_mean": 0.18019126785892836, "train/policy_randomness_min": 0.028015904784412453, "train/policy_randomness_std": 0.23190241307020187, "train/post_ent_mag": 60.90550086867641, "train/post_ent_max": 60.90550086867641, "train/post_ent_mean": 43.87638580967003, "train/post_ent_min": 20.60692805975256, "train/post_ent_std": 7.648922268773468, "train/prior_ent_mag": 71.06473997948875, "train/prior_ent_max": 71.06473997948875, "train/prior_ent_mean": 56.831326686160665, "train/prior_ent_min": 42.23551433187136, "train/prior_ent_std": 4.802379104453073, "train/rep_loss_mean": 12.90177785846549, "train/rep_loss_std": 9.455265199634391, "train/reward_avg": 0.03171833708856098, "train/reward_loss_mean": 0.05730815643680767, "train/reward_loss_std": 0.24592459967858354, "train/reward_max_data": 1.0197183145603663, "train/reward_max_pred": 1.0131444821895008, "train/reward_neg_acc": 0.9921002627258569, "train/reward_neg_loss": 0.028911842820300182, "train/reward_pos_acc": 0.9734750024869409, "train/reward_pos_loss": 0.8214425608305864, "train/reward_pred": 0.03103850163440679, "train/reward_rate": 0.03598151408450704, "eval_stats/sum_log_reward": 10.537500351667404, "eval_stats/max_log_achievement_collect_coal": 1.4375, "eval_stats/max_log_achievement_collect_drink": 9.75, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 15.375, "eval_stats/max_log_achievement_collect_wood": 10.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 1.0, "eval_stats/max_log_achievement_eat_cow": 0.3125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.4375, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 2.1875, "eval_stats/max_log_achievement_place_plant": 1.1875, "eval_stats/max_log_achievement_place_stone": 4.375, "eval_stats/max_log_achievement_place_table": 2.4375, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.0010989517904818058, "report/cont_loss_std": 0.0350351557135582, "report/cont_neg_acc": 0.75, "report/cont_neg_loss": 0.2804540693759918, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.441803301029722e-06, "report/cont_pred": 0.9967489242553711, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.746273040771484, "report/dyn_loss_std": 9.76156997680664, "report/image_loss_mean": 6.771911144256592, "report/image_loss_std": 14.692788124084473, "report/model_loss_mean": 15.068038940429688, "report/model_loss_std": 18.69147300720215, "report/post_ent_mag": 61.2728157043457, "report/post_ent_max": 61.2728157043457, "report/post_ent_mean": 43.60938262939453, "report/post_ent_min": 21.534744262695312, "report/post_ent_std": 7.613041877746582, "report/prior_ent_mag": 70.46688842773438, "report/prior_ent_max": 70.46688842773438, "report/prior_ent_mean": 56.90468978881836, "report/prior_ent_min": 37.68030548095703, "report/prior_ent_std": 4.536213397979736, "report/rep_loss_mean": 13.746273040771484, "report/rep_loss_std": 9.76156997680664, "report/reward_avg": 0.02919921837747097, "report/reward_loss_mean": 0.04726552218198776, "report/reward_loss_std": 0.21515467762947083, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011322498321533, "report/reward_neg_acc": 0.9959595203399658, "report/reward_neg_loss": 0.024143818765878677, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7205150127410889, "report/reward_pred": 0.02919415570795536, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 7.5499633567233104e-06, "eval/cont_loss_std": 0.00023758412862662226, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.3109229257679544e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.544529125880217e-06, "eval/cont_pred": 0.9990159273147583, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 17.165407180786133, "eval/dyn_loss_std": 10.842973709106445, "eval/image_loss_mean": 11.177226066589355, "eval/image_loss_std": 15.720048904418945, "eval/model_loss_mean": 21.56837272644043, "eval/model_loss_std": 19.924419403076172, "eval/post_ent_mag": 59.91576385498047, "eval/post_ent_max": 59.91576385498047, "eval/post_ent_mean": 43.14548110961914, "eval/post_ent_min": 22.572660446166992, "eval/post_ent_std": 7.752418518066406, "eval/prior_ent_mag": 70.46688842773438, "eval/prior_ent_max": 70.46688842773438, "eval/prior_ent_mean": 58.37060546875, "eval/prior_ent_min": 45.98816680908203, "eval/prior_ent_std": 4.855038642883301, "eval/rep_loss_mean": 17.165407180786133, "eval/rep_loss_std": 10.842973709106445, "eval/reward_avg": 0.0263671875, "eval/reward_loss_mean": 0.09189343452453613, "eval/reward_loss_std": 0.46655797958374023, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0018024444580078, "eval/reward_neg_acc": 0.98591548204422, "eval/reward_neg_loss": 0.05945749953389168, "eval/reward_pos_acc": 0.9000000357627869, "eval/reward_pos_loss": 1.1666040420532227, "eval/reward_pred": 0.02826453186571598, "eval/reward_rate": 0.029296875, "replay/size": 945713.0, "replay/inserts": 22752.0, "replay/samples": 22752.0, "replay/insert_wait_avg": 1.4527165101717963e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.657972856245296e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5776.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3038309657342546e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2367963790893555e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2231321334839, "timer/env.step_count": 2844.0, "timer/env.step_total": 217.21884298324585, "timer/env.step_frac": 0.21717038529184615, "timer/env.step_avg": 0.07637793353841274, "timer/env.step_min": 0.023952484130859375, "timer/env.step_max": 2.0891847610473633, "timer/replay._sample_count": 22752.0, "timer/replay._sample_total": 11.902993202209473, "timer/replay._sample_frac": 0.011900337854434834, "timer/replay._sample_avg": 0.0005231625000971112, "timer/replay._sample_min": 0.0004105567932128906, "timer/replay._sample_max": 0.009330987930297852, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3566.0, "timer/agent.policy_total": 62.96991586685181, "timer/agent.policy_frac": 0.0629558683896227, "timer/agent.policy_avg": 0.017658417236918623, "timer/agent.policy_min": 0.009481430053710938, "timer/agent.policy_max": 0.1724088191986084, "timer/dataset_train_count": 1422.0, "timer/dataset_train_total": 0.16033005714416504, "timer/dataset_train_frac": 0.0001602942903371768, "timer/dataset_train_avg": 0.00011274968856832985, "timer/dataset_train_min": 9.775161743164062e-05, "timer/dataset_train_max": 0.0002772808074951172, "timer/agent.train_count": 1422.0, "timer/agent.train_total": 643.8701553344727, "timer/agent.train_frac": 0.6437265192628494, "timer/agent.train_avg": 0.4527919517120061, "timer/agent.train_min": 0.4378166198730469, "timer/agent.train_max": 1.7312085628509521, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47528791427612305, "timer/agent.report_frac": 0.000475181885928123, "timer/agent.report_avg": 0.23764395713806152, "timer/agent.report_min": 0.22968220710754395, "timer/agent.report_max": 0.2456057071685791, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.170259715236823e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 22.746566009299972}
{"step": 946224, "time": 43385.86325716972, "episode/length": 221.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 946384, "time": 43393.34306669235, "episode/length": 186.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 946568, "time": 43401.16607117653, "episode/length": 433.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 946888, "time": 43413.9048409462, "episode/length": 268.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 946936, "time": 43417.072964429855, "episode/length": 231.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 947400, "time": 43434.7073264122, "episode/length": 302.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9834983498349835, "episode/intrinsic_return": 0.0}
{"step": 947944, "time": 43454.72455120087, "episode/length": 171.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 948368, "time": 43470.97743964195, "episode/length": 267.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 948392, "time": 43473.14403319359, "episode/length": 429.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 948768, "time": 43487.80371785164, "episode/length": 297.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9765100671140939, "episode/intrinsic_return": 0.0}
{"step": 948824, "time": 43491.162845134735, "episode/length": 235.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 948920, "time": 43496.09455037117, "episode/length": 65.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9393939393939394, "episode/intrinsic_return": 0.0}
{"step": 949272, "time": 43509.433057546616, "episode/length": 233.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 949440, "time": 43517.06000351906, "episode/length": 318.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9937304075235109, "episode/intrinsic_return": 0.0}
{"step": 949448, "time": 43518.6804227829, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 949944, "time": 43536.94634795189, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 950040, "time": 43561.992369413376, "eval_episode/length": 157.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9620253164556962}
{"step": 950040, "time": 43563.572789907455, "eval_episode/length": 159.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.99375}
{"step": 950040, "time": 43567.44893741608, "eval_episode/length": 204.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9707317073170731}
{"step": 950040, "time": 43569.280450344086, "eval_episode/length": 209.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 950040, "time": 43570.893171072006, "eval_episode/length": 210.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.995260663507109}
{"step": 950040, "time": 43572.8216650486, "eval_episode/length": 219.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9727272727272728}
{"step": 950040, "time": 43579.10308790207, "eval_episode/length": 318.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9968652037617555}
{"step": 950040, "time": 43581.80719733238, "eval_episode/length": 184.0, "eval_episode/score": 10.099999964237213, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 950216, "time": 43587.75545501709, "episode/length": 173.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 950336, "time": 43595.542749881744, "episode/length": 195.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 951024, "time": 43620.41279244423, "episode/length": 653.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 951592, "time": 43641.29010462761, "episode/length": 289.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 951768, "time": 43648.80768895149, "episode/length": 290.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 951872, "time": 43654.15879368782, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 951912, "time": 43656.92177772522, "episode/length": 373.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9919786096256684, "episode/intrinsic_return": 0.0}
{"step": 952088, "time": 43664.449132442474, "episode/length": 61.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 952432, "time": 43677.911838531494, "episode/length": 261.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 952808, "time": 43691.97056698799, "episode/length": 419.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9976190476190476, "episode/intrinsic_return": 0.0}
{"step": 953128, "time": 43704.51437664032, "episode/length": 169.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9823529411764705, "episode/intrinsic_return": 0.0}
{"step": 953320, "time": 43712.61991286278, "episode/length": 421.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 953464, "time": 43718.97292423248, "episode/length": 198.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 953512, "time": 43722.155171871185, "episode/length": 177.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 953536, "time": 43724.71313714981, "episode/length": 313.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9968152866242038, "episode/intrinsic_return": 0.0}
{"step": 953776, "time": 43734.6619951725, "episode/length": 167.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 955080, "time": 43780.051491975784, "episode/length": 395.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 955136, "time": 43783.78491139412, "episode/length": 250.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9641434262948207, "episode/intrinsic_return": 0.0}
{"step": 955232, "time": 43788.869946718216, "episode/length": 220.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 955312, "time": 43793.096991062164, "episode/length": 224.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 955696, "time": 43807.502840042114, "episode/length": 296.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9831649831649831, "episode/intrinsic_return": 0.0}
{"step": 956152, "time": 43824.27801370621, "episode/length": 296.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9730639730639731, "episode/intrinsic_return": 0.0}
{"step": 956208, "time": 43828.00622367859, "episode/length": 333.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9850299401197605, "episode/intrinsic_return": 0.0}
{"step": 956384, "time": 43835.52093601227, "episode/length": 155.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 956480, "time": 43840.45405316353, "episode/length": 145.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 956760, "time": 43851.31052613258, "episode/length": 209.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 957328, "time": 43872.19775938988, "episode/length": 564.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9893805309734514, "episode/intrinsic_return": 0.0}
{"step": 957600, "time": 43882.94301199913, "episode/length": 151.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 957880, "time": 43893.73385119438, "episode/length": 215.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 958360, "time": 43911.628678798676, "episode/length": 390.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9820971867007673, "episode/intrinsic_return": 0.0}
{"step": 958408, "time": 43914.851648807526, "episode/length": 338.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9852507374631269, "episode/intrinsic_return": 0.0}
{"step": 958424, "time": 43916.91062569618, "episode/length": 242.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 958480, "time": 43922.38119697571, "episode/length": 109.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 958776, "time": 43933.93773460388, "episode/length": 251.0, "episode/score": 13.100000016391277, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 960016, "time": 43977.50650382042, "episode/length": 191.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 960024, "time": 44000.06280350685, "eval_episode/length": 166.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 960024, "time": 44003.30024576187, "eval_episode/length": 201.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9702970297029703}
{"step": 960024, "time": 44005.217975616455, "eval_episode/length": 207.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 960024, "time": 44007.08913254738, "eval_episode/length": 213.0, "eval_episode/score": 12.099999994039536, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 960024, "time": 44009.98153543472, "eval_episode/length": 242.0, "eval_episode/score": 7.1000000461936, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 960024, "time": 44020.41690325737, "eval_episode/length": 185.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 960024, "time": 44020.42757606506, "eval_episode/length": 393.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9898477157360406}
{"step": 960024, "time": 44025.28879022598, "eval_episode/length": 426.0, "eval_episode/score": 12.100000031292439, "eval_episode/reward_rate": 0.990632318501171}
{"step": 960040, "time": 44025.82550048828, "episode/length": 201.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 960208, "time": 44033.39964556694, "episode/length": 359.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 960728, "time": 44052.09582257271, "episode/length": 564.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9982300884955753, "episode/intrinsic_return": 0.0}
{"step": 961064, "time": 44065.25359463692, "episode/length": 397.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 961072, "time": 44067.459055662155, "episode/length": 332.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.984984984984985, "episode/intrinsic_return": 0.0}
{"step": 961160, "time": 44071.81869316101, "episode/length": 139.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 961272, "time": 44077.13221907616, "episode/length": 311.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 962040, "time": 44104.81874251366, "episode/length": 252.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 962064, "time": 44107.4111533165, "episode/length": 98.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9494949494949495, "episode/intrinsic_return": 0.0}
{"step": 962112, "time": 44110.595819711685, "episode/length": 237.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 962176, "time": 44114.38328099251, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 962688, "time": 44133.63783288002, "episode/length": 202.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 962872, "time": 44141.284739494324, "episode/length": 224.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 963512, "time": 44164.975383758545, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 963624, "time": 44170.40065360069, "episode/length": 657.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9954407294832827, "episode/intrinsic_return": 0.0}
{"step": 963672, "time": 44173.601321697235, "episode/length": 194.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 964216, "time": 44193.54869008064, "episode/length": 381.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 964720, "time": 44212.39828658104, "episode/length": 334.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.991044776119403, "episode/intrinsic_return": 0.0}
{"step": 965448, "time": 44238.416093826294, "episode/length": 408.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9877750611246944, "episode/intrinsic_return": 0.0}
{"step": 965456, "time": 44240.453494787216, "episode/length": 345.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9884393063583815, "episode/intrinsic_return": 0.0}
{"step": 965544, "time": 44244.77774477005, "episode/length": 239.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 965688, "time": 44251.62214541435, "episode/length": 183.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 966104, "time": 44267.264293432236, "episode/length": 172.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 966152, "time": 44270.58630490303, "episode/length": 309.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9903225806451613, "episode/intrinsic_return": 0.0}
{"step": 966240, "time": 44275.31397676468, "episode/length": 420.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.995249406175772, "episode/intrinsic_return": 0.0}
{"step": 966768, "time": 44296.48996472359, "episode/length": 164.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 966808, "time": 44299.141483306885, "episode/length": 411.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 967216, "time": 44314.73098897934, "episode/length": 208.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 967392, "time": 44322.288949012756, "episode/length": 212.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 967888, "time": 44340.777527570724, "episode/length": 216.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 968400, "time": 44359.77306032181, "episode/length": 269.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 968456, "time": 44363.034499406815, "episode/length": 374.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946666666666667, "episode/intrinsic_return": 0.0}
{"step": 968888, "time": 44379.24458050728, "episode/length": 186.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 969017, "time": 44386.22777271271, "train_stats/sum_log_reward": 10.52857156026931, "train_stats/max_log_achievement_collect_coal": 1.0, "train_stats/max_log_achievement_collect_drink": 7.833333333333333, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.5714285714285714, "train_stats/max_log_achievement_collect_stone": 16.392857142857142, "train_stats/max_log_achievement_collect_wood": 10.94047619047619, "train_stats/max_log_achievement_defeat_skeleton": 0.08333333333333333, "train_stats/max_log_achievement_defeat_zombie": 1.1071428571428572, "train_stats/max_log_achievement_eat_cow": 0.2261904761904762, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.011904761904761904, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.6785714285714286, "train_stats/max_log_achievement_make_wood_sword": 1.5357142857142858, "train_stats/max_log_achievement_place_furnace": 2.011904761904762, "train_stats/max_log_achievement_place_plant": 1.5476190476190477, "train_stats/max_log_achievement_place_stone": 6.25, "train_stats/max_log_achievement_place_table": 2.9523809523809526, "train_stats/max_log_achievement_wake_up": 1.7142857142857142, "train_stats/mean_log_entropy": 0.5562986765234244, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.515859684474032, "train/action_min": 0.0, "train/action_std": 3.322368218865193, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.032959834318345704, "train/actor_opt_grad_steps": 59755.0, "train/actor_opt_loss": -7.8576421312672995, "train/adv_mag": 0.45042340803734016, "train/adv_max": 0.39374776845666726, "train/adv_mean": 0.0018689943178085895, "train/adv_min": -0.3805347992710664, "train/adv_std": 0.047598488681333165, "train/cont_avg": 0.9952959947183099, "train/cont_loss_mean": 9.839305775459476e-05, "train/cont_loss_std": 0.002959892889608009, "train/cont_neg_acc": 0.9988262913596462, "train/cont_neg_loss": 0.0038405112310825437, "train/cont_pos_acc": 0.9999861242905469, "train/cont_pos_loss": 7.787368492783337e-05, "train/cont_pred": 0.9952861020262812, "train/cont_rate": 0.9952959947183099, "train/dyn_loss_mean": 12.97623990958845, "train/dyn_loss_std": 9.513753716374787, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0136141991111594, "train/extr_critic_critic_opt_grad_steps": 59755.0, "train/extr_critic_critic_opt_loss": 15226.778368452904, "train/extr_critic_mag": 10.65949532011865, "train/extr_critic_max": 10.65949532011865, "train/extr_critic_mean": 3.60327621077148, "train/extr_critic_min": -0.14840334485953963, "train/extr_critic_std": 2.5573105132076104, "train/extr_return_normed_mag": 1.4111503102410008, "train/extr_return_normed_max": 1.4111503102410008, "train/extr_return_normed_mean": 0.40590216555226016, "train/extr_return_normed_min": -0.10490481922744026, "train/extr_return_normed_std": 0.321493521227803, "train/extr_return_rate": 0.9072321128677314, "train/extr_return_raw_mag": 11.699754721681837, "train/extr_return_raw_max": 11.699754721681837, "train/extr_return_raw_mean": 3.6182946856592744, "train/extr_return_raw_min": -0.48822483798147925, "train/extr_return_raw_std": 2.5846207964588217, "train/extr_reward_mag": 1.0437305829894374, "train/extr_reward_max": 1.0437305829894374, "train/extr_reward_mean": 0.04920214964208049, "train/extr_reward_min": -0.4286110073747769, "train/extr_reward_std": 0.20624754619850239, "train/image_loss_mean": 6.669810456289372, "train/image_loss_std": 12.122615760480853, "train/model_loss_mean": 14.513341507441561, "train/model_loss_std": 16.069796965155803, "train/model_opt_grad_norm": 52.490738734393055, "train/model_opt_grad_steps": 59703.40140845071, "train/model_opt_loss": 19492.448194047094, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1346.8309859154929, "train/policy_entropy_mag": 2.4956189612267723, "train/policy_entropy_max": 2.4956189612267723, "train/policy_entropy_mean": 0.5337215231757768, "train/policy_entropy_min": 0.07937503375217948, "train/policy_entropy_std": 0.6777320848384374, "train/policy_logprob_mag": 7.438383824388746, "train/policy_logprob_max": -0.009455659229990462, "train/policy_logprob_mean": -0.5338993609791071, "train/policy_logprob_min": -7.438383824388746, "train/policy_logprob_std": 1.0925736141876436, "train/policy_randomness_mag": 0.8808439760140969, "train/policy_randomness_max": 0.8808439760140969, "train/policy_randomness_mean": 0.18838027623337758, "train/policy_randomness_min": 0.028015903538276613, "train/policy_randomness_std": 0.23920968521228977, "train/post_ent_mag": 61.313362551407074, "train/post_ent_max": 61.313362551407074, "train/post_ent_mean": 43.89366912841797, "train/post_ent_min": 20.533299647586446, "train/post_ent_std": 7.736294964669456, "train/prior_ent_mag": 71.11889315323091, "train/prior_ent_max": 71.11889315323091, "train/prior_ent_mean": 56.93128967285156, "train/prior_ent_min": 41.86861220883652, "train/prior_ent_std": 4.8562382342110215, "train/rep_loss_mean": 12.97623990958845, "train/rep_loss_std": 9.513753716374787, "train/reward_avg": 0.03186963551717115, "train/reward_loss_mean": 0.057688765411435715, "train/reward_loss_std": 0.25298240224660284, "train/reward_max_data": 1.0211267656003926, "train/reward_max_pred": 1.0144656493630209, "train/reward_neg_acc": 0.9931131517383415, "train/reward_neg_loss": 0.02908734261045154, "train/reward_pos_acc": 0.9752170884273421, "train/reward_pos_loss": 0.8227345574070031, "train/reward_pred": 0.03110280644778215, "train/reward_rate": 0.036167198503521125, "eval_stats/sum_log_reward": 9.850000232458115, "eval_stats/max_log_achievement_collect_coal": 1.125, "eval_stats/max_log_achievement_collect_drink": 7.9375, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 13.5625, "eval_stats/max_log_achievement_collect_wood": 10.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.9375, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 1.375, "eval_stats/max_log_achievement_place_furnace": 1.875, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_stone": 3.8125, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.015335530042648315, "report/cont_loss_std": 0.4875602126121521, "report/cont_neg_acc": 0.875, "report/cont_neg_loss": 1.9626835584640503, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.080319063679781e-06, "report/cont_pred": 0.9932479858398438, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 11.377412796020508, "report/dyn_loss_std": 9.1434965133667, "report/image_loss_mean": 5.398420333862305, "report/image_loss_std": 8.79599380493164, "report/model_loss_mean": 12.306400299072266, "report/model_loss_std": 13.049492835998535, "report/post_ent_mag": 62.360374450683594, "report/post_ent_max": 62.360374450683594, "report/post_ent_mean": 45.19720458984375, "report/post_ent_min": 19.627185821533203, "report/post_ent_std": 7.68007755279541, "report/prior_ent_mag": 71.75773620605469, "report/prior_ent_max": 71.75773620605469, "report/prior_ent_mean": 56.69361877441406, "report/prior_ent_min": 38.89653778076172, "report/prior_ent_std": 5.382731914520264, "report/rep_loss_mean": 11.377412796020508, "report/rep_loss_std": 9.1434965133667, "report/reward_avg": 0.01982421800494194, "report/reward_loss_mean": 0.06619659066200256, "report/reward_loss_std": 0.32505160570144653, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0041394233703613, "report/reward_neg_acc": 0.9959879517555237, "report/reward_neg_loss": 0.048831768333911896, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.707408607006073, "report/reward_pred": 0.022734589874744415, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 1.03957773944785e-07, "eval/cont_loss_std": 1.345146301900968e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.975271829403937e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.520043172031365e-08, "eval/cont_pred": 0.9990234375, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 17.753211975097656, "eval/dyn_loss_std": 10.542840957641602, "eval/image_loss_mean": 10.922510147094727, "eval/image_loss_std": 15.046297073364258, "eval/model_loss_mean": 21.655956268310547, "eval/model_loss_std": 19.072277069091797, "eval/post_ent_mag": 63.112117767333984, "eval/post_ent_max": 63.112117767333984, "eval/post_ent_mean": 43.63969421386719, "eval/post_ent_min": 19.7243709564209, "eval/post_ent_std": 8.518026351928711, "eval/prior_ent_mag": 71.75773620605469, "eval/prior_ent_max": 71.75773620605469, "eval/prior_ent_mean": 59.041961669921875, "eval/prior_ent_min": 45.551902770996094, "eval/prior_ent_std": 4.620114326477051, "eval/rep_loss_mean": 17.753211975097656, "eval/rep_loss_std": 10.542840957641602, "eval/reward_avg": 0.02177734300494194, "eval/reward_loss_mean": 0.08151763677597046, "eval/reward_loss_std": 0.5114955306053162, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0005977153778076, "eval/reward_neg_acc": 0.9820000529289246, "eval/reward_neg_loss": 0.05305832251906395, "eval/reward_pos_acc": 0.9583333730697632, "eval/reward_pos_loss": 1.2673225402832031, "eval/reward_pred": 0.02729160524904728, "eval/reward_rate": 0.0234375, "replay/size": 968513.0, "replay/inserts": 22800.0, "replay/samples": 22800.0, "replay/insert_wait_avg": 1.4344119189078347e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.722355491236636e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6176.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2785659552855814e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3240787982941, "timer/env.step_count": 2850.0, "timer/env.step_total": 216.43355560302734, "timer/env.step_frac": 0.2163634368004343, "timer/env.step_avg": 0.07594159845720258, "timer/env.step_min": 0.02399301528930664, "timer/env.step_max": 2.0425119400024414, "timer/replay._sample_count": 22800.0, "timer/replay._sample_total": 12.02113151550293, "timer/replay._sample_frac": 0.01201723698378241, "timer/replay._sample_avg": 0.0005272426103290758, "timer/replay._sample_min": 0.00041747093200683594, "timer/replay._sample_max": 0.011603355407714844, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3622.0, "timer/agent.policy_total": 63.729254484176636, "timer/agent.policy_frac": 0.06370860787509548, "timer/agent.policy_avg": 0.01759504541252806, "timer/agent.policy_min": 0.009523391723632812, "timer/agent.policy_max": 0.1482253074645996, "timer/dataset_train_count": 1425.0, "timer/dataset_train_total": 0.162217378616333, "timer/dataset_train_frac": 0.00016216482443490458, "timer/dataset_train_avg": 0.00011383675692374246, "timer/dataset_train_min": 9.775161743164062e-05, "timer/dataset_train_max": 0.0010657310485839844, "timer/agent.train_count": 1425.0, "timer/agent.train_total": 642.6522440910339, "timer/agent.train_frac": 0.6424440415980617, "timer/agent.train_avg": 0.4509840309410764, "timer/agent.train_min": 0.4346587657928467, "timer/agent.train_max": 1.7898638248443604, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5007467269897461, "timer/agent.report_frac": 0.0005005844981671355, "timer/agent.report_avg": 0.25037336349487305, "timer/agent.report_min": 0.23012232780456543, "timer/agent.report_max": 0.27062439918518066, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8839301864997015e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 22.79167823873634}
{"step": 969432, "time": 44400.14393091202, "episode/length": 327.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9908536585365854, "episode/intrinsic_return": 0.0}
{"step": 970008, "time": 44441.75275731087, "eval_episode/length": 160.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 970008, "time": 44445.01724600792, "eval_episode/length": 197.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 970008, "time": 44447.077046871185, "eval_episode/length": 204.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 970008, "time": 44449.5124270916, "eval_episode/length": 224.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 970008, "time": 44454.83901977539, "eval_episode/length": 305.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9836601307189542}
{"step": 970008, "time": 44459.69289445877, "eval_episode/length": 181.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 970008, "time": 44461.61185050011, "eval_episode/length": 181.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.978021978021978}
{"step": 970008, "time": 44463.203518390656, "eval_episode/length": 388.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9897172236503856}
{"step": 970040, "time": 44464.32060575485, "episode/length": 491.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9979674796747967, "episode/intrinsic_return": 0.0}
{"step": 970056, "time": 44466.527980566025, "episode/length": 199.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 970216, "time": 44473.575785160065, "episode/length": 226.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 970248, "time": 44476.28085184097, "episode/length": 169.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 970320, "time": 44480.46542644501, "episode/length": 443.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 970384, "time": 44484.34094762802, "episode/length": 395.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9974747474747475, "episode/intrinsic_return": 0.0}
{"step": 970632, "time": 44494.0258102417, "episode/length": 73.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9324324324324325, "episode/intrinsic_return": 0.0}
{"step": 971440, "time": 44523.0605905056, "episode/length": 443.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 971760, "time": 44535.3520898819, "episode/length": 192.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 971776, "time": 44537.64600086212, "episode/length": 190.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 972408, "time": 44560.49153447151, "episode/length": 221.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 972616, "time": 44569.289630651474, "episode/length": 319.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 972792, "time": 44576.96050071716, "episode/length": 300.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 972864, "time": 44581.13390827179, "episode/length": 428.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953379953379954, "episode/intrinsic_return": 0.0}
{"step": 973072, "time": 44589.654383182526, "episode/length": 343.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9796511627906976, "episode/intrinsic_return": 0.0}
{"step": 973184, "time": 44595.11885380745, "episode/length": 177.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9550561797752809, "episode/intrinsic_return": 0.0}
{"step": 973584, "time": 44610.26094698906, "episode/length": 146.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 973624, "time": 44612.97924494743, "episode/length": 94.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 973712, "time": 44617.80879545212, "episode/length": 241.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 974152, "time": 44634.232412815094, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 974280, "time": 44640.05994439125, "episode/length": 86.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9425287356321839, "episode/intrinsic_return": 0.0}
{"step": 974848, "time": 44664.01766824722, "episode/length": 425.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9906103286384976, "episode/intrinsic_return": 0.0}
{"step": 974928, "time": 44670.143562316895, "episode/length": 288.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9757785467128027, "episode/intrinsic_return": 0.0}
{"step": 975136, "time": 44678.9361345768, "episode/length": 243.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 975192, "time": 44682.26005315781, "episode/length": 264.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9886792452830189, "episode/intrinsic_return": 0.0}
{"step": 975416, "time": 44691.76014137268, "episode/length": 223.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 975640, "time": 44701.05785536766, "episode/length": 185.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 975840, "time": 44709.722041130066, "episode/length": 265.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 976280, "time": 44726.18368434906, "episode/length": 54.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9272727272727272, "episode/intrinsic_return": 0.0}
{"step": 976856, "time": 44747.42675328255, "episode/length": 240.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 977064, "time": 44756.130106925964, "episode/length": 233.0, "episode/score": 13.099999971687794, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 977088, "time": 44758.89896321297, "episode/length": 350.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9886039886039886, "episode/intrinsic_return": 0.0}
{"step": 977144, "time": 44762.16277742386, "episode/length": 215.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 977208, "time": 44765.92750620842, "episode/length": 115.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 977552, "time": 44779.45415568352, "episode/length": 301.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 977592, "time": 44782.10588598251, "episode/length": 243.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 977664, "time": 44786.37434577942, "episode/length": 351.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9971590909090909, "episode/intrinsic_return": 0.0}
{"step": 978600, "time": 44819.61232185364, "episode/length": 217.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 978656, "time": 44823.30750083923, "episode/length": 137.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 979240, "time": 44844.47851371765, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 979248, "time": 44846.5538752079, "episode/length": 272.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 979256, "time": 44848.20225763321, "episode/length": 198.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 979376, "time": 44854.0783162117, "episode/length": 89.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 979912, "time": 44873.48459291458, "episode/length": 345.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9884393063583815, "episode/intrinsic_return": 0.0}
{"step": 980096, "time": 44900.89179062843, "eval_episode/length": 135.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9632352941176471}
{"step": 980096, "time": 44902.778248786926, "eval_episode/length": 141.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 980096, "time": 44904.906073093414, "eval_episode/length": 152.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 980096, "time": 44906.966960430145, "eval_episode/length": 162.0, "eval_episode/score": 9.100000016391277, "eval_episode/reward_rate": 0.9815950920245399}
{"step": 980096, "time": 44911.859006881714, "eval_episode/length": 236.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9957805907172996}
{"step": 980096, "time": 44913.62100195885, "eval_episode/length": 238.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.99581589958159}
{"step": 980096, "time": 44918.86758160591, "eval_episode/length": 184.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 980096, "time": 44921.125688791275, "eval_episode/length": 336.0, "eval_episode/score": 13.099999956786633, "eval_episode/reward_rate": 0.9970326409495549}
{"step": 980320, "time": 44928.89064669609, "episode/length": 403.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9925742574257426, "episode/intrinsic_return": 0.0}
{"step": 980328, "time": 44930.604152202606, "episode/length": 389.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9897435897435898, "episode/intrinsic_return": 0.0}
{"step": 980744, "time": 44946.37742996216, "episode/length": 187.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 981088, "time": 44959.930377960205, "episode/length": 213.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 981312, "time": 44969.02641749382, "episode/length": 122.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.991869918699187, "episode/intrinsic_return": 0.0}
{"step": 981352, "time": 44971.65420675278, "episode/length": 261.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 981488, "time": 44978.06967878342, "episode/length": 279.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 982056, "time": 44998.73533773422, "episode/length": 431.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 982408, "time": 45012.22359800339, "episode/length": 207.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 982512, "time": 45017.63600921631, "episode/length": 273.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9708029197080292, "episode/intrinsic_return": 0.0}
{"step": 982856, "time": 45030.78519940376, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 982976, "time": 45036.598829746246, "episode/length": 185.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 983056, "time": 45042.48957705498, "episode/length": 245.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9715447154471545, "episode/intrinsic_return": 0.0}
{"step": 983488, "time": 45058.924317121506, "episode/length": 53.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 983560, "time": 45062.736429691315, "episode/length": 187.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 984072, "time": 45081.95284295082, "episode/length": 519.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9865384615384616, "episode/intrinsic_return": 0.0}
{"step": 984192, "time": 45087.83999300003, "episode/length": 354.0, "episode/score": 13.100000016391277, "episode/reward_rate": 0.9943661971830986, "episode/intrinsic_return": 0.0}
{"step": 984400, "time": 45096.68345570564, "episode/length": 248.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 984504, "time": 45101.980130434036, "episode/length": 248.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 984768, "time": 45112.94718837738, "episode/length": 223.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 984896, "time": 45119.027220487595, "episode/length": 166.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 985200, "time": 45131.00027632713, "episode/length": 213.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 985744, "time": 45151.098690748215, "episode/length": 167.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 985744, "time": 45151.108572006226, "episode/length": 360.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9695290858725761, "episode/intrinsic_return": 0.0}
{"step": 985952, "time": 45161.64758872986, "episode/length": 219.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 986240, "time": 45173.05651950836, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 986576, "time": 45186.04113674164, "episode/length": 258.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 986632, "time": 45189.30540275574, "episode/length": 319.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.996875, "episode/intrinsic_return": 0.0}
{"step": 987472, "time": 45219.619074344635, "episode/length": 337.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.985207100591716, "episode/intrinsic_return": 0.0}
{"step": 987480, "time": 45221.231238126755, "episode/length": 216.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 987640, "time": 45228.421093940735, "episode/length": 304.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9934426229508196, "episode/intrinsic_return": 0.0}
{"step": 987760, "time": 45234.33187913895, "episode/length": 189.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 987920, "time": 45241.35010099411, "episode/length": 160.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 988176, "time": 45251.58547973633, "episode/length": 277.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 988944, "time": 45279.31953263283, "episode/length": 183.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 988992, "time": 45282.50143289566, "episode/length": 405.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9926108374384236, "episode/intrinsic_return": 0.0}
{"step": 989368, "time": 45296.78351211548, "episode/length": 348.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9914040114613181, "episode/intrinsic_return": 0.0}
{"step": 989392, "time": 45299.39248108864, "episode/length": 183.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 989440, "time": 45302.53441929817, "episode/length": 61.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 989656, "time": 45311.22946715355, "episode/length": 251.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 989704, "time": 45314.374452352524, "episode/length": 242.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 989784, "time": 45318.836935043335, "episode/length": 200.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 990080, "time": 45347.076770067215, "eval_episode/length": 65.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9848484848484849}
{"step": 990080, "time": 45349.24981832504, "eval_episode/length": 78.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9493670886075949}
{"step": 990080, "time": 45355.941930770874, "eval_episode/length": 191.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 990080, "time": 45358.525245428085, "eval_episode/length": 197.0, "eval_episode/score": 11.099999964237213, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 990080, "time": 45361.73218393326, "eval_episode/length": 198.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9698492462311558}
{"step": 990080, "time": 45366.009487867355, "eval_episode/length": 256.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9961089494163424}
{"step": 990080, "time": 45368.898924827576, "eval_episode/length": 284.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9964912280701754}
{"step": 990080, "time": 45371.3703391552, "eval_episode/length": 223.0, "eval_episode/score": 11.10000005364418, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 990168, "time": 45374.109251737595, "episode/length": 335.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 990449, "time": 45386.17928123474, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.441594821303638, "train/action_min": 0.0, "train/action_std": 3.2899139603572105, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03261279927761252, "train/actor_opt_grad_steps": 61135.0, "train/actor_opt_loss": -8.306481155705875, "train/adv_mag": 0.4253594739668405, "train/adv_max": 0.36977761094249895, "train/adv_mean": 0.001871881342839203, "train/adv_min": -0.3599969887021762, "train/adv_std": 0.04698695467590396, "train/cont_avg": 0.99560546875, "train/cont_loss_mean": 0.00013382005149975893, "train/cont_loss_std": 0.00367318245133844, "train/cont_neg_acc": 0.9976608188528764, "train/cont_neg_loss": 0.016982380078460618, "train/cont_pos_acc": 0.999985327471548, "train/cont_pos_loss": 5.256017179724393e-05, "train/cont_pred": 0.9956098261164196, "train/cont_rate": 0.99560546875, "train/dyn_loss_mean": 12.824787182594413, "train/dyn_loss_std": 9.439684127693745, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0178171311741444, "train/extr_critic_critic_opt_grad_steps": 61135.0, "train/extr_critic_critic_opt_loss": 15217.243608617071, "train/extr_critic_mag": 10.667135900525905, "train/extr_critic_max": 10.667135900525905, "train/extr_critic_mean": 3.5329296766822016, "train/extr_critic_min": -0.1496179530869669, "train/extr_critic_std": 2.517659003165231, "train/extr_return_normed_mag": 1.4247769428722894, "train/extr_return_normed_max": 1.4247769428722894, "train/extr_return_normed_mean": 0.4058498446621112, "train/extr_return_normed_min": -0.09412761628905784, "train/extr_return_normed_std": 0.3188321614888177, "train/extr_return_rate": 0.8988612120720878, "train/extr_return_raw_mag": 11.670924478502416, "train/extr_return_raw_max": 11.670924478502416, "train/extr_return_raw_mean": 3.5478705007638505, "train/extr_return_raw_min": -0.43809013874895536, "train/extr_return_raw_std": 2.541985018039817, "train/extr_reward_mag": 1.0405222213090355, "train/extr_reward_max": 1.0405222213090355, "train/extr_reward_mean": 0.04920852217656463, "train/extr_reward_min": -0.4169099749024235, "train/extr_reward_std": 0.2057529729026467, "train/image_loss_mean": 6.622316244822829, "train/image_loss_std": 11.927165469126916, "train/model_loss_mean": 14.374195326620073, "train/model_loss_std": 15.853410692357306, "train/model_opt_grad_norm": 52.829546472919525, "train/model_opt_grad_steps": 61082.07462686567, "train/model_opt_loss": 19079.764983675374, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1324.6268656716418, "train/policy_entropy_mag": 2.5106133204787526, "train/policy_entropy_max": 2.5106133204787526, "train/policy_entropy_mean": 0.5515753315455878, "train/policy_entropy_min": 0.07937503111229013, "train/policy_entropy_std": 0.6918386687983328, "train/policy_logprob_mag": 7.438383828348188, "train/policy_logprob_max": -0.009455659329446394, "train/policy_logprob_mean": -0.5519499018121121, "train/policy_logprob_min": -7.438383828348188, "train/policy_logprob_std": 1.1064000521133195, "train/policy_randomness_mag": 0.8861363289961174, "train/policy_randomness_max": 0.8861363289961174, "train/policy_randomness_mean": 0.19468188641676262, "train/policy_randomness_min": 0.028015902669016105, "train/policy_randomness_std": 0.24418868836182267, "train/post_ent_mag": 61.095198332373776, "train/post_ent_max": 61.095198332373776, "train/post_ent_mean": 44.04014800911519, "train/post_ent_min": 20.695498053707293, "train/post_ent_std": 7.65408972839811, "train/prior_ent_mag": 71.13302902677167, "train/prior_ent_max": 71.13302902677167, "train/prior_ent_mean": 56.890454363467086, "train/prior_ent_min": 41.7449010592788, "train/prior_ent_std": 4.792362517385341, "train/rep_loss_mean": 12.824787182594413, "train/rep_loss_std": 9.439684127693745, "train/reward_avg": 0.030910389421424316, "train/reward_loss_mean": 0.056872953785889184, "train/reward_loss_std": 0.2513205460203228, "train/reward_max_data": 1.0246268715431441, "train/reward_max_pred": 1.0138032543125437, "train/reward_neg_acc": 0.992315193165594, "train/reward_neg_loss": 0.02930197825154929, "train/reward_pos_acc": 0.9755270770236627, "train/reward_pos_loss": 0.8196822204696599, "train/reward_pred": 0.030467630690658717, "train/reward_rate": 0.03500320662313433, "train_stats/sum_log_reward": 10.28181832486933, "train_stats/max_log_achievement_collect_coal": 1.0795454545454546, "train_stats/max_log_achievement_collect_drink": 7.431818181818182, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.6477272727272727, "train_stats/max_log_achievement_collect_stone": 14.454545454545455, "train_stats/max_log_achievement_collect_wood": 10.556818181818182, "train_stats/max_log_achievement_defeat_skeleton": 0.03409090909090909, "train_stats/max_log_achievement_defeat_zombie": 0.875, "train_stats/max_log_achievement_eat_cow": 0.22727272727272727, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.011363636363636364, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3863636363636365, "train_stats/max_log_achievement_make_wood_sword": 1.25, "train_stats/max_log_achievement_place_furnace": 1.9318181818181819, "train_stats/max_log_achievement_place_plant": 1.6136363636363635, "train_stats/max_log_achievement_place_stone": 5.034090909090909, "train_stats/max_log_achievement_place_table": 2.625, "train_stats/max_log_achievement_wake_up": 1.5909090909090908, "train_stats/mean_log_entropy": 0.5454807234081355, "eval_stats/sum_log_reward": 10.183333575725555, "eval_stats/max_log_achievement_collect_coal": 0.5833333333333334, "eval_stats/max_log_achievement_collect_drink": 6.125, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.4583333333333333, "eval_stats/max_log_achievement_collect_stone": 12.708333333333334, "eval_stats/max_log_achievement_collect_wood": 9.541666666666666, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.9166666666666666, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.3333333333333333, "eval_stats/max_log_achievement_make_wood_sword": 1.2083333333333333, "eval_stats/max_log_achievement_place_furnace": 1.5, "eval_stats/max_log_achievement_place_plant": 1.4583333333333333, "eval_stats/max_log_achievement_place_stone": 4.875, "eval_stats/max_log_achievement_place_table": 2.4583333333333335, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 7.691219252592418e-06, "report/cont_loss_std": 0.0001538078358862549, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.013790410477668e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.625264515809249e-06, "report/cont_pred": 0.9970628619194031, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.266120910644531, "report/dyn_loss_std": 9.757987022399902, "report/image_loss_mean": 5.55292272567749, "report/image_loss_std": 11.985814094543457, "report/model_loss_mean": 12.960954666137695, "report/model_loss_std": 16.151538848876953, "report/post_ent_mag": 62.03525161743164, "report/post_ent_max": 62.03525161743164, "report/post_ent_mean": 43.813743591308594, "report/post_ent_min": 21.901111602783203, "report/post_ent_std": 7.7132649421691895, "report/prior_ent_mag": 71.33859252929688, "report/prior_ent_max": 71.33859252929688, "report/prior_ent_mean": 56.31458282470703, "report/prior_ent_min": 40.49058151245117, "report/prior_ent_std": 4.912978649139404, "report/rep_loss_mean": 12.266120910644531, "report/rep_loss_std": 9.757987022399902, "report/reward_avg": 0.03457031399011612, "report/reward_loss_mean": 0.0483524352312088, "report/reward_loss_std": 0.17593823373317719, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002932071685791, "report/reward_neg_acc": 0.9959391355514526, "report/reward_neg_loss": 0.021349087357521057, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7303600311279297, "report/reward_pred": 0.033099621534347534, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0011635486735031009, "eval/cont_loss_std": 0.03707120567560196, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 0.3970249593257904, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.9094766179914586e-07, "eval/cont_pred": 0.9977526664733887, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.71229362487793, "eval/dyn_loss_std": 11.152137756347656, "eval/image_loss_mean": 11.777815818786621, "eval/image_loss_std": 17.04146385192871, "eval/model_loss_mean": 23.127634048461914, "eval/model_loss_std": 21.583728790283203, "eval/post_ent_mag": 57.41685104370117, "eval/post_ent_max": 57.41685104370117, "eval/post_ent_mean": 40.94082260131836, "eval/post_ent_min": 20.944561004638672, "eval/post_ent_std": 7.592952728271484, "eval/prior_ent_mag": 71.33859252929688, "eval/prior_ent_max": 71.33859252929688, "eval/prior_ent_mean": 57.01081848144531, "eval/prior_ent_min": 45.376522064208984, "eval/prior_ent_std": 4.261159896850586, "eval/rep_loss_mean": 18.71229362487793, "eval/rep_loss_std": 11.152137756347656, "eval/reward_avg": 0.05000000074505806, "eval/reward_loss_mean": 0.1212792918086052, "eval/reward_loss_std": 0.6704111099243164, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0120429992675781, "eval/reward_neg_acc": 0.9917441010475159, "eval/reward_neg_loss": 0.06030448526144028, "eval/reward_pos_acc": 0.9272726774215698, "eval/reward_pos_loss": 1.195544719696045, "eval/reward_pred": 0.04699704051017761, "eval/reward_rate": 0.0537109375, "replay/size": 989945.0, "replay/inserts": 21432.0, "replay/samples": 21424.0, "replay/insert_wait_avg": 1.4122229273882586e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.779777529704384e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 8232.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2599518278249845e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9441051483154, "timer/env.step_count": 2679.0, "timer/env.step_total": 220.89933109283447, "timer/env.step_frac": 0.220911678918363, "timer/env.step_avg": 0.08245589066548506, "timer/env.step_min": 0.0240476131439209, "timer/env.step_max": 3.5420522689819336, "timer/replay._sample_count": 21424.0, "timer/replay._sample_total": 11.41364073753357, "timer/replay._sample_frac": 0.011414278736950657, "timer/replay._sample_avg": 0.0005327502211320747, "timer/replay._sample_min": 0.00043082237243652344, "timer/replay._sample_max": 0.02596569061279297, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3708.0, "timer/agent.policy_total": 63.75518870353699, "timer/agent.policy_frac": 0.06375875248955098, "timer/agent.policy_avg": 0.01719395596104018, "timer/agent.policy_min": 0.009734153747558594, "timer/agent.policy_max": 0.13016963005065918, "timer/dataset_train_count": 1339.0, "timer/dataset_train_total": 0.15204215049743652, "timer/dataset_train_frac": 0.00015205064934593025, "timer/dataset_train_avg": 0.00011354902949771211, "timer/dataset_train_min": 9.751319885253906e-05, "timer/dataset_train_max": 0.000507354736328125, "timer/agent.train_count": 1339.0, "timer/agent.train_total": 605.7330048084259, "timer/agent.train_frac": 0.6057668640574478, "timer/agent.train_avg": 0.4523771507157774, "timer/agent.train_min": 0.4395616054534912, "timer/agent.train_max": 2.8050637245178223, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4741988182067871, "timer/agent.report_frac": 0.0004742253249609909, "timer/agent.report_avg": 0.23709940910339355, "timer/agent.report_min": 0.22794866561889648, "timer/agent.report_max": 0.24625015258789062, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7181237308806103e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 21.432909708440505}
{"step": 990768, "time": 45397.39951491356, "episode/length": 221.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 991216, "time": 45414.317407131195, "episode/length": 178.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 991224, "time": 45415.96515059471, "episode/length": 231.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 991488, "time": 45428.378276348114, "episode/length": 164.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 991800, "time": 45440.34133219719, "episode/length": 267.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9664179104477612, "episode/intrinsic_return": 0.0}
{"step": 991808, "time": 45442.56645035744, "episode/length": 301.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 991992, "time": 45450.09230184555, "episode/length": 152.0, "episode/score": 10.100000061094761, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 992960, "time": 45484.65088605881, "episode/length": 217.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 993344, "time": 45499.35664725304, "episode/length": 454.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9978021978021978, "episode/intrinsic_return": 0.0}
{"step": 993440, "time": 45504.23359823227, "episode/length": 276.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9747292418772563, "episode/intrinsic_return": 0.0}
{"step": 993672, "time": 45513.488916158676, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 994032, "time": 45527.588337183, "episode/length": 278.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 994040, "time": 45529.21763253212, "episode/length": 278.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9713261648745519, "episode/intrinsic_return": 0.0}
{"step": 994104, "time": 45533.14173531532, "episode/length": 582.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9914236706689536, "episode/intrinsic_return": 0.0}
{"step": 994160, "time": 45536.774889945984, "episode/length": 333.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9910179640718563, "episode/intrinsic_return": 0.0}
{"step": 994304, "time": 45543.20915055275, "episode/length": 167.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 994400, "time": 45548.026638031006, "episode/length": 90.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 995576, "time": 45589.50812911987, "episode/length": 176.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 995632, "time": 45593.27284550667, "episode/length": 198.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 995672, "time": 45595.993012189865, "episode/length": 158.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 996032, "time": 45609.989223241806, "episode/length": 240.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 996272, "time": 45619.93325138092, "episode/length": 353.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9858757062146892, "episode/intrinsic_return": 0.0}
{"step": 996408, "time": 45625.85511302948, "episode/length": 382.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9895561357702349, "episode/intrinsic_return": 0.0}
{"step": 996512, "time": 45631.24572682381, "episode/length": 309.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9870967741935484, "episode/intrinsic_return": 0.0}
{"step": 996840, "time": 45643.64601588249, "episode/length": 157.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 996936, "time": 45648.6224758625, "episode/length": 162.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 997384, "time": 45665.3545024395, "episode/length": 213.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 997752, "time": 45679.56046009064, "episode/length": 214.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 997768, "time": 45681.65132403374, "episode/length": 115.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 998392, "time": 45704.42733550072, "episode/length": 264.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9735849056603774, "episode/intrinsic_return": 0.0}
{"step": 998440, "time": 45707.866510629654, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 998472, "time": 45710.40399646759, "episode/length": 257.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 998480, "time": 45712.51636147499, "episode/length": 521.0, "episode/score": 14.099999994039536, "episode/reward_rate": 0.9980842911877394, "episode/intrinsic_return": 0.0}
{"step": 999104, "time": 45735.187405347824, "episode/length": 214.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 999464, "time": 45750.559233665466, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 1000032, "time": 45771.67418408394, "episode/length": 439.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9795454545454545, "episode/intrinsic_return": 0.0}
{"step": 1000064, "time": 45774.37869000435, "episode/length": 198.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 1000064, "time": 45794.35440135002, "eval_episode/length": 152.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 1000064, "time": 45796.71313166618, "eval_episode/length": 164.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 1000064, "time": 45798.68247246742, "eval_episode/length": 172.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 1000064, "time": 45800.632150411606, "eval_episode/length": 180.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 1000064, "time": 45803.40212082863, "eval_episode/length": 206.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9710144927536232}
{"step": 1000064, "time": 45805.048226594925, "eval_episode/length": 208.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 1000064, "time": 45807.125816345215, "eval_episode/length": 218.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9771689497716894}
{"step": 1000064, "time": 45809.142167806625, "eval_episode/length": 227.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 1000064, "time": 45809.149735212326, "eval_episode/length": 62.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 1000144, "time": 45813.611577272415, "episode/length": 298.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.979933110367893, "episode/intrinsic_return": 0.0}
{"step": 1000208, "time": 45817.36815714836, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 1000800, "time": 45838.9849820137, "episode/length": 294.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 1000968, "time": 45845.98832154274, "episode/length": 187.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 1000976, "time": 45848.08824777603, "episode/length": 233.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 1002016, "time": 45884.780594587326, "episode/length": 441.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9796380090497737, "episode/intrinsic_return": 0.0}
{"step": 1002176, "time": 45892.09374213219, "episode/length": 171.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 1002568, "time": 45906.649497032166, "episode/length": 312.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9904153354632588, "episode/intrinsic_return": 0.0}
{"step": 1002904, "time": 45919.75330662727, "episode/length": 344.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 1003768, "time": 45950.54405403137, "episode/length": 149.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 1003976, "time": 45959.27819943428, "episode/length": 244.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 1004032, "time": 45963.05238246918, "episode/length": 231.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 1004072, "time": 45965.74464893341, "episode/length": 504.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 1004216, "time": 45972.15688252449, "episode/length": 55.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 1004544, "time": 45985.129313230515, "episode/length": 446.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9977628635346756, "episode/intrinsic_return": 0.0}
{"step": 1004704, "time": 45992.239377975464, "episode/length": 224.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1005216, "time": 46011.308789253235, "episode/length": 529.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 1005352, "time": 46017.47390341759, "episode/length": 171.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 1005448, "time": 46022.229915857315, "episode/length": 654.0, "episode/score": 12.099999964237213, "episode/reward_rate": 0.983206106870229, "episode/intrinsic_return": 0.0}
{"step": 1005784, "time": 46035.28949856758, "episode/length": 218.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 1005896, "time": 46040.82480764389, "episode/length": 227.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1006280, "time": 46055.23119854927, "episode/length": 257.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9728682170542635, "episode/intrinsic_return": 0.0}
{"step": 1006440, "time": 46062.20324969292, "episode/length": 135.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 1006952, "time": 46081.344158649445, "episode/length": 300.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9966777408637874, "episode/intrinsic_return": 0.0}
{"step": 1007064, "time": 46086.77848005295, "episode/length": 159.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 1007328, "time": 46097.67061853409, "episode/length": 234.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9702127659574468, "episode/intrinsic_return": 0.0}
{"step": 1007504, "time": 46105.38934659958, "episode/length": 200.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 1007616, "time": 46111.02025604248, "episode/length": 363.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 1007832, "time": 46121.715230703354, "episode/length": 62.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 1008224, "time": 46137.03612828255, "episode/length": 222.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 1008536, "time": 46148.94316959381, "episode/length": 414.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 1008576, "time": 46152.13505578041, "episode/length": 202.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 1008680, "time": 46157.24464058876, "episode/length": 56.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 1008816, "time": 46163.70812726021, "episode/length": 316.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9716088328075709, "episode/intrinsic_return": 0.0}
{"step": 1009000, "time": 46171.41602921486, "episode/length": 172.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 1009008, "time": 46173.62877178192, "episode/length": 242.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 1009056, "time": 46176.846111536026, "episode/length": 152.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 1009344, "time": 46188.253632068634, "episode/length": 229.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 1010048, "time": 46230.70494198799, "eval_episode/length": 87.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9886363636363636}
{"step": 1010048, "time": 46237.8875746727, "eval_episode/length": 213.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 1010048, "time": 46239.978915929794, "eval_episode/length": 224.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 1010048, "time": 46245.514369010925, "eval_episode/length": 223.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9910714285714286}
{"step": 1010048, "time": 46247.64786076546, "eval_episode/length": 319.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9875}
{"step": 1010048, "time": 46249.5277056694, "eval_episode/length": 326.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9785932721712538}
{"step": 1010048, "time": 46254.002692222595, "eval_episode/length": 175.0, "eval_episode/score": 12.099999971687794, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 1010048, "time": 46255.7854411602, "eval_episode/length": 392.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9949109414758269}
{"step": 1010160, "time": 46259.566267967224, "episode/length": 197.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 1010344, "time": 46267.28713417053, "episode/length": 166.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 1010384, "time": 46270.481091976166, "episode/length": 195.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 1010424, "time": 46273.20738172531, "episode/length": 235.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1010600, "time": 46280.86109185219, "episode/length": 192.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 1010752, "time": 46287.860117435455, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 1010760, "time": 46289.55920100212, "episode/length": 176.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 1010832, "time": 46293.77424621582, "episode/length": 60.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 1011512, "time": 46318.140008211136, "episode/length": 168.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 1011640, "time": 46323.98027586937, "episode/length": 156.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 1011960, "time": 46336.52135014534, "episode/length": 191.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 1012416, "time": 46353.73559141159, "episode/length": 56.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 1012656, "time": 46363.596635103226, "episode/length": 256.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 1012848, "time": 46371.95777249336, "episode/length": 520.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9980806142034548, "episode/intrinsic_return": 0.0}
{"step": 1013209, "time": 46386.468770980835, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.496454373211928, "train/action_min": 0.0, "train/action_std": 3.335241453748354, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03269093328903259, "train/actor_opt_grad_steps": 62515.0, "train/actor_opt_loss": -6.92901652694588, "train/adv_mag": 0.4280988550941709, "train/adv_max": 0.3716828457906213, "train/adv_mean": 0.0023772845536858397, "train/adv_min": -0.37068968979825434, "train/adv_std": 0.04742715384443881, "train/cont_avg": 0.9953441351232394, "train/cont_loss_mean": 0.00022339631662529808, "train/cont_loss_std": 0.0065532135227799795, "train/cont_neg_acc": 0.9900234744582378, "train/cont_neg_loss": 0.03576434260289524, "train/cont_pos_acc": 0.99995848788342, "train/cont_pos_loss": 0.00012286378655738852, "train/cont_pred": 0.9953300507975297, "train/cont_rate": 0.9953441351232394, "train/dyn_loss_mean": 12.754799238393005, "train/dyn_loss_std": 9.4644048314699, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0987043649377957, "train/extr_critic_critic_opt_grad_steps": 62515.0, "train/extr_critic_critic_opt_loss": 15319.555093254841, "train/extr_critic_mag": 10.585654124407702, "train/extr_critic_max": 10.585654124407702, "train/extr_critic_mean": 3.4887079302693755, "train/extr_critic_min": -0.16565347557336513, "train/extr_critic_std": 2.5347261798213907, "train/extr_return_normed_mag": 1.4226358356610151, "train/extr_return_normed_max": 1.4226358356610151, "train/extr_return_normed_mean": 0.403291373395584, "train/extr_return_normed_min": -0.09947271862814963, "train/extr_return_normed_std": 0.3219282170626479, "train/extr_return_rate": 0.8979607253846987, "train/extr_return_raw_mag": 11.624023900905126, "train/extr_return_raw_max": 11.624023900905126, "train/extr_return_raw_mean": 3.507651535558029, "train/extr_return_raw_min": -0.4962385734412032, "train/extr_return_raw_std": 2.5638639851355216, "train/extr_reward_mag": 1.0435878592477719, "train/extr_reward_max": 1.0435878592477719, "train/extr_reward_mean": 0.05050603752877091, "train/extr_reward_min": -0.4352431725448286, "train/extr_reward_std": 0.20866508540553105, "train/image_loss_mean": 6.444272039641796, "train/image_loss_std": 11.493814834406678, "train/model_loss_mean": 14.154524924049914, "train/model_loss_std": 15.438964870614065, "train/model_opt_grad_norm": 48.69529146543691, "train/model_opt_grad_steps": 62460.66197183099, "train/model_opt_loss": 18310.77521181778, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1294.0140845070423, "train/policy_entropy_mag": 2.4915356803947772, "train/policy_entropy_max": 2.4915356803947772, "train/policy_entropy_mean": 0.5585562460859057, "train/policy_entropy_min": 0.07937502651147439, "train/policy_entropy_std": 0.6964173782879198, "train/policy_logprob_mag": 7.438383844536795, "train/policy_logprob_max": -0.009455659229990462, "train/policy_logprob_mean": -0.5578622765524287, "train/policy_logprob_min": -7.438383844536795, "train/policy_logprob_std": 1.1070709291478278, "train/policy_randomness_mag": 0.879402755431726, "train/policy_randomness_max": 0.879402755431726, "train/policy_randomness_mean": 0.19714584547868916, "train/policy_randomness_min": 0.028015900967301617, "train/policy_randomness_std": 0.24580477293528302, "train/post_ent_mag": 61.349440668670226, "train/post_ent_max": 61.349440668670226, "train/post_ent_mean": 44.12920425307583, "train/post_ent_min": 20.881057390024964, "train/post_ent_std": 7.77165881009169, "train/prior_ent_mag": 71.12894649236975, "train/prior_ent_max": 71.12894649236975, "train/prior_ent_mean": 56.91192258915431, "train/prior_ent_min": 41.7480222137881, "train/prior_ent_std": 4.84329024167128, "train/rep_loss_mean": 12.754799238393005, "train/rep_loss_std": 9.4644048314699, "train/reward_avg": 0.03146594373220709, "train/reward_loss_mean": 0.05714995597659702, "train/reward_loss_std": 0.2483211035879565, "train/reward_max_data": 1.0274647952805103, "train/reward_max_pred": 1.0178220901690738, "train/reward_neg_acc": 0.9919035921634083, "train/reward_neg_loss": 0.028829193503504068, "train/reward_pos_acc": 0.9728555637346187, "train/reward_pos_loss": 0.8275537713312767, "train/reward_pred": 0.03077307324463003, "train/reward_rate": 0.03568579445422535, "train_stats/sum_log_reward": 10.279775501636976, "train_stats/max_log_achievement_collect_coal": 1.0, "train_stats/max_log_achievement_collect_drink": 8.337078651685394, "train_stats/max_log_achievement_collect_iron": 0.011235955056179775, "train_stats/max_log_achievement_collect_sapling": 1.7191011235955056, "train_stats/max_log_achievement_collect_stone": 15.0, "train_stats/max_log_achievement_collect_wood": 9.348314606741573, "train_stats/max_log_achievement_defeat_skeleton": 0.0898876404494382, "train_stats/max_log_achievement_defeat_zombie": 0.8876404494382022, "train_stats/max_log_achievement_eat_cow": 0.2247191011235955, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.033707865168539325, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.404494382022472, "train_stats/max_log_achievement_make_wood_sword": 1.2247191011235956, "train_stats/max_log_achievement_place_furnace": 2.247191011235955, "train_stats/max_log_achievement_place_plant": 1.651685393258427, "train_stats/max_log_achievement_place_stone": 4.573033707865169, "train_stats/max_log_achievement_place_table": 2.50561797752809, "train_stats/max_log_achievement_wake_up": 1.449438202247191, "train_stats/mean_log_entropy": 0.510791701882073, "eval_stats/sum_log_reward": 9.629411949830896, "eval_stats/max_log_achievement_collect_coal": 0.8823529411764706, "eval_stats/max_log_achievement_collect_drink": 7.882352941176471, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.4705882352941178, "eval_stats/max_log_achievement_collect_stone": 12.823529411764707, "eval_stats/max_log_achievement_collect_wood": 9.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.058823529411764705, "eval_stats/max_log_achievement_defeat_zombie": 1.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.588235294117647, "eval_stats/max_log_achievement_make_wood_sword": 1.2941176470588236, "eval_stats/max_log_achievement_place_furnace": 1.7647058823529411, "eval_stats/max_log_achievement_place_plant": 1.411764705882353, "eval_stats/max_log_achievement_place_stone": 4.176470588235294, "eval_stats/max_log_achievement_place_table": 2.411764705882353, "eval_stats/max_log_achievement_wake_up": 1.1176470588235294, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.095199867355404e-06, "report/cont_loss_std": 3.2517848012503237e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00011633936082944274, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.54935025118175e-06, "report/cont_pred": 0.9951132535934448, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.186234474182129, "report/dyn_loss_std": 9.705538749694824, "report/image_loss_mean": 8.335517883300781, "report/image_loss_std": 15.239798545837402, "report/model_loss_mean": 16.303586959838867, "report/model_loss_std": 19.18589210510254, "report/post_ent_mag": 62.49175262451172, "report/post_ent_max": 62.49175262451172, "report/post_ent_mean": 44.050724029541016, "report/post_ent_min": 20.803558349609375, "report/post_ent_std": 8.173272132873535, "report/prior_ent_mag": 71.46058654785156, "report/prior_ent_max": 71.46058654785156, "report/prior_ent_mean": 57.01513671875, "report/prior_ent_min": 42.22612762451172, "report/prior_ent_std": 5.253386974334717, "report/rep_loss_mean": 13.186234474182129, "report/rep_loss_std": 9.705538749694824, "report/reward_avg": 0.03339843824505806, "report/reward_loss_mean": 0.056322645395994186, "report/reward_loss_std": 0.24881702661514282, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001756191253662, "report/reward_neg_acc": 0.9918863773345947, "report/reward_neg_loss": 0.025250203907489777, "report/reward_pos_acc": 0.9473684430122375, "report/reward_pos_loss": 0.8625707030296326, "report/reward_pred": 0.03153514117002487, "report/reward_rate": 0.037109375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 9.640971256885678e-06, "eval/cont_loss_std": 0.00013656812370754778, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0008591145742684603, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 6.309702712314902e-06, "eval/cont_pred": 0.9960908889770508, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.1849308013916, "eval/dyn_loss_std": 11.03265380859375, "eval/image_loss_mean": 12.170997619628906, "eval/image_loss_std": 16.934431076049805, "eval/model_loss_mean": 22.58429718017578, "eval/model_loss_std": 20.634122848510742, "eval/post_ent_mag": 61.382606506347656, "eval/post_ent_max": 61.382606506347656, "eval/post_ent_mean": 43.89386749267578, "eval/post_ent_min": 21.57457733154297, "eval/post_ent_std": 8.235088348388672, "eval/prior_ent_mag": 71.46058654785156, "eval/prior_ent_max": 71.46058654785156, "eval/prior_ent_mean": 58.73861312866211, "eval/prior_ent_min": 38.618751525878906, "eval/prior_ent_std": 4.899678707122803, "eval/rep_loss_mean": 17.1849308013916, "eval/rep_loss_std": 11.03265380859375, "eval/reward_avg": 0.04931640625, "eval/reward_loss_mean": 0.10233339667320251, "eval/reward_loss_std": 0.5060403943061829, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017647743225098, "eval/reward_neg_acc": 0.9896907806396484, "eval/reward_neg_loss": 0.02909434400498867, "eval/reward_pos_acc": 0.8888888955116272, "eval/reward_pos_loss": 1.417923927307129, "eval/reward_pred": 0.038981836289167404, "eval/reward_rate": 0.052734375, "replay/size": 1000000.0, "replay/inserts": 22760.0, "replay/samples": 22768.0, "replay/insert_wait_avg": 1.370948731165988e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.409574512688107e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4968.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2581763060196587e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2411494255066, "timer/env.step_count": 2845.0, "timer/env.step_total": 227.60679697990417, "timer/env.step_frac": 0.22755192296440838, "timer/env.step_avg": 0.08000238909662713, "timer/env.step_min": 0.024379491806030273, "timer/env.step_max": 3.6006367206573486, "timer/replay._sample_count": 22768.0, "timer/replay._sample_total": 11.95290756225586, "timer/replay._sample_frac": 0.011950025820394483, "timer/replay._sample_avg": 0.0005249871557561428, "timer/replay._sample_min": 0.0004169940948486328, "timer/replay._sample_max": 0.02603459358215332, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3466.0, "timer/agent.policy_total": 59.229416608810425, "timer/agent.policy_frac": 0.059215136912562666, "timer/agent.policy_avg": 0.01708869492464236, "timer/agent.policy_min": 0.009664535522460938, "timer/agent.policy_max": 0.10129308700561523, "timer/dataset_train_count": 1423.0, "timer/dataset_train_total": 0.16401910781860352, "timer/dataset_train_frac": 0.00016397956424089202, "timer/dataset_train_avg": 0.0001152629007860882, "timer/dataset_train_min": 9.918212890625e-05, "timer/dataset_train_max": 0.0005099773406982422, "timer/agent.train_count": 1423.0, "timer/agent.train_total": 641.2310738563538, "timer/agent.train_frac": 0.6410764786318259, "timer/agent.train_avg": 0.4506191664485972, "timer/agent.train_min": 0.4389064311981201, "timer/agent.train_max": 1.7286479473114014, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4769587516784668, "timer/agent.report_frac": 0.0004768437610794261, "timer/agent.report_avg": 0.2384793758392334, "timer/agent.report_min": 0.2332744598388672, "timer/agent.report_max": 0.2436842918395996, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8126609618233488e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 22.754192291314666}
{"step": 1013240, "time": 46387.273844480515, "episode/length": 309.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 1013480, "time": 46397.25482058525, "episode/length": 330.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9818731117824774, "episode/intrinsic_return": 0.0}
{"step": 1013752, "time": 46408.07842087746, "episode/length": 166.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 1013856, "time": 46413.26025247574, "episode/length": 149.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1013904, "time": 46416.48322367668, "episode/length": 282.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9823321554770318, "episode/intrinsic_return": 0.0}
{"step": 1014288, "time": 46431.11039638519, "episode/length": 441.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9796380090497737, "episode/intrinsic_return": 0.0}
{"step": 1014376, "time": 46435.486783504486, "episode/length": 190.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 1014480, "time": 46440.77521324158, "episode/length": 370.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9973045822102425, "episode/intrinsic_return": 0.0}
{"step": 1014728, "time": 46450.50750231743, "episode/length": 185.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 1014792, "time": 46454.22263669968, "episode/length": 116.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 1015336, "time": 46474.39126873016, "episode/length": 67.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 1015528, "time": 46482.43033218384, "episode/length": 255.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 1015864, "time": 46497.057923316956, "episode/length": 196.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 1016200, "time": 46510.07523941994, "episode/length": 183.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 1016296, "time": 46514.949632406235, "episode/length": 239.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 1016328, "time": 46517.812586307526, "episode/length": 302.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 1016400, "time": 46522.17686533928, "episode/length": 239.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 1016968, "time": 46542.74424743652, "episode/length": 179.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 1017896, "time": 46575.88189101219, "episode/length": 199.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 1017984, "time": 46580.94004821777, "episode/length": 206.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 1018016, "time": 46583.661017656326, "episode/length": 130.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 1018152, "time": 46589.544264793396, "episode/length": 351.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9857954545454546, "episode/intrinsic_return": 0.0}
{"step": 1018280, "time": 46595.42406630516, "episode/length": 301.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9900662251655629, "episode/intrinsic_return": 0.0}
{"step": 1018512, "time": 46605.24694752693, "episode/length": 594.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 1019360, "time": 46635.4949028492, "episode/length": 182.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 1019584, "time": 46644.87928032875, "episode/length": 195.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 1019784, "time": 46652.92423534393, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 1019848, "time": 46656.60826444626, "episode/length": 166.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 1019960, "time": 46662.0426800251, "episode/length": 246.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 1020000, "time": 46665.33669090271, "episode/length": 230.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 1020032, "time": 46684.02190232277, "eval_episode/length": 64.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9846153846153847}
{"step": 1020032, "time": 46688.77046728134, "eval_episode/length": 134.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 1020032, "time": 46692.33637523651, "eval_episode/length": 177.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9775280898876404}
{"step": 1020032, "time": 46694.41425824165, "eval_episode/length": 188.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9682539682539683}
{"step": 1020032, "time": 46697.49405646324, "eval_episode/length": 218.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9634703196347032}
{"step": 1020032, "time": 46699.14071011543, "eval_episode/length": 219.0, "eval_episode/score": 13.099999994039536, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 1020032, "time": 46702.03013586998, "eval_episode/length": 182.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.994535519125683}
{"step": 1020032, "time": 46708.59887099266, "eval_episode/length": 91.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9565217391304348}
{"step": 1020344, "time": 46718.99881887436, "episode/length": 492.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9918864097363083, "episode/intrinsic_return": 0.0}
{"step": 1020536, "time": 46727.26639032364, "episode/length": 541.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9981549815498155, "episode/intrinsic_return": 0.0}
{"step": 1021288, "time": 46754.102352142334, "episode/length": 240.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 1021440, "time": 46761.301735162735, "episode/length": 184.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 1021544, "time": 46766.19012308121, "episode/length": 211.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 1021608, "time": 46769.975882291794, "episode/length": 39.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 1021616, "time": 46772.0759973526, "episode/length": 158.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 1021760, "time": 46778.595537662506, "episode/length": 271.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 1022800, "time": 46815.36196947098, "episode/length": 376.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946949602122016, "episode/intrinsic_return": 0.0}
{"step": 1023096, "time": 46826.870633125305, "episode/length": 206.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 1023528, "time": 46843.175181388855, "episode/length": 247.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 1023592, "time": 46847.07967042923, "episode/length": 228.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 1024016, "time": 46864.94809746742, "episode/length": 501.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.99800796812749, "episode/intrinsic_return": 0.0}
{"step": 1024128, "time": 46870.45784020424, "episode/length": 313.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 1024304, "time": 46878.03817009926, "episode/length": 336.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9881305637982196, "episode/intrinsic_return": 0.0}
{"step": 1024376, "time": 46881.76248002052, "episode/length": 479.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9979166666666667, "episode/intrinsic_return": 0.0}
{"step": 1024784, "time": 46897.5045645237, "episode/length": 156.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 1025192, "time": 46912.82078242302, "episode/length": 298.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.0}
{"step": 1025504, "time": 46925.13948392868, "episode/length": 300.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9966777408637874, "episode/intrinsic_return": 0.0}
{"step": 1025848, "time": 46938.366065740585, "episode/length": 132.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 1025936, "time": 46943.029527425766, "episode/length": 292.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 1026216, "time": 46953.87985062599, "episode/length": 274.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9854545454545455, "episode/intrinsic_return": 0.0}
{"step": 1026288, "time": 46958.14612817764, "episode/length": 54.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1026736, "time": 46974.90258646011, "episode/length": 303.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9835526315789473, "episode/intrinsic_return": 0.0}
{"step": 1026928, "time": 46982.98656439781, "episode/length": 177.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9831460674157303, "episode/intrinsic_return": 0.0}
{"step": 1027288, "time": 46996.703924655914, "episode/length": 363.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9862637362637363, "episode/intrinsic_return": 0.0}
{"step": 1027536, "time": 47006.87937164307, "episode/length": 425.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9976525821596244, "episode/intrinsic_return": 0.0}
{"step": 1027560, "time": 47009.01509141922, "episode/length": 167.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 1027712, "time": 47016.129202365875, "episode/length": 314.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 1028328, "time": 47038.62077522278, "episode/length": 198.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 1028912, "time": 47060.29969263077, "episode/length": 247.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 1029008, "time": 47065.25788617134, "episode/length": 180.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 1029048, "time": 47068.07122588158, "episode/length": 188.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 1029048, "time": 47068.082324266434, "episode/length": 344.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9942028985507246, "episode/intrinsic_return": 0.0}
{"step": 1029192, "time": 47076.47267484665, "episode/length": 237.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 1029376, "time": 47084.50351548195, "episode/length": 429.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9976744186046511, "episode/intrinsic_return": 0.0}
{"step": 1029960, "time": 47105.91107225418, "episode/length": 280.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 1030016, "time": 47130.69301748276, "eval_episode/length": 164.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9575757575757575}
{"step": 1030016, "time": 47134.29966545105, "eval_episode/length": 207.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 1030016, "time": 47136.14675307274, "eval_episode/length": 210.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.981042654028436}
{"step": 1030016, "time": 47138.30094432831, "eval_episode/length": 220.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.995475113122172}
{"step": 1030016, "time": 47141.28261232376, "eval_episode/length": 249.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.996}
{"step": 1030016, "time": 47149.36539411545, "eval_episode/length": 179.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 1030016, "time": 47151.69841217995, "eval_episode/length": 403.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.995049504950495}
{"step": 1030016, "time": 47153.62033748627, "eval_episode/length": 411.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9781553398058253}
{"step": 1030560, "time": 47172.12314248085, "episode/length": 193.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 1030808, "time": 47181.95694231987, "episode/length": 236.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 1030872, "time": 47185.92785692215, "episode/length": 209.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 1030928, "time": 47189.63593697548, "episode/length": 324.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9969230769230769, "episode/intrinsic_return": 0.0}
{"step": 1030976, "time": 47192.86402249336, "episode/length": 199.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 1031184, "time": 47201.45153713226, "episode/length": 266.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 1031528, "time": 47214.61256861687, "episode/length": 309.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 1032080, "time": 47235.20518040657, "episode/length": 150.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 1032328, "time": 47247.034672021866, "episode/length": 220.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 1032440, "time": 47252.49906826019, "episode/length": 113.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9912280701754386, "episode/intrinsic_return": 0.0}
{"step": 1032464, "time": 47255.1074693203, "episode/length": 312.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9808306709265175, "episode/intrinsic_return": 0.0}
{"step": 1032616, "time": 47261.78995037079, "episode/length": 210.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 1032816, "time": 47270.56311774254, "episode/length": 250.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 1033136, "time": 47282.99263858795, "episode/length": 243.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 1033416, "time": 47293.92202377319, "episode/length": 304.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9737704918032787, "episode/intrinsic_return": 0.0}
{"step": 1033744, "time": 47306.96648526192, "episode/length": 162.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 1034304, "time": 47327.835332393646, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 1034352, "time": 47331.605607271194, "episode/length": 216.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 1034440, "time": 47335.966940164566, "episode/length": 246.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 1035032, "time": 47357.5971968174, "episode/length": 368.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 1035112, "time": 47361.907532930374, "episode/length": 246.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 1035224, "time": 47367.25561332703, "episode/length": 225.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 1035488, "time": 47378.014524936676, "episode/length": 217.0, "episode/score": 9.1000000461936, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1035560, "time": 47381.876133441925, "episode/length": 403.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 1035625, "time": 47386.75231170654, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.52547287095523, "train/action_min": 0.0, "train/action_std": 3.3353250939795314, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03254976972990425, "train/actor_opt_grad_steps": 63930.0, "train/actor_opt_loss": -8.728856049530895, "train/adv_mag": 0.4220245592560328, "train/adv_max": 0.39022978421644117, "train/adv_mean": 0.0021078832790066473, "train/adv_min": -0.3413558342355363, "train/adv_std": 0.047326735280295636, "train/cont_avg": 0.9956020057624113, "train/cont_loss_mean": 0.00012584373018480603, "train/cont_loss_std": 0.0038229157750372823, "train/cont_neg_acc": 0.9960034021309444, "train/cont_neg_loss": 0.01687321640008252, "train/cont_pos_acc": 0.9999930338656648, "train/cont_pos_loss": 3.238478229375692e-05, "train/cont_pred": 0.9956102223261029, "train/cont_rate": 0.9956020057624113, "train/dyn_loss_mean": 12.914066632588705, "train/dyn_loss_std": 9.460297787443121, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.021654227523939, "train/extr_critic_critic_opt_grad_steps": 63930.0, "train/extr_critic_critic_opt_loss": 15291.485531637854, "train/extr_critic_mag": 10.589670519456796, "train/extr_critic_max": 10.589670519456796, "train/extr_critic_mean": 3.475330114364624, "train/extr_critic_min": -0.16781979841543426, "train/extr_critic_std": 2.5146555849846375, "train/extr_return_normed_mag": 1.4291536207740188, "train/extr_return_normed_max": 1.4291536207740188, "train/extr_return_normed_mean": 0.40300299491442687, "train/extr_return_normed_min": -0.09781708642311976, "train/extr_return_normed_std": 0.3205114117962249, "train/extr_return_rate": 0.9011340618979001, "train/extr_return_raw_mag": 11.637722360326888, "train/extr_return_raw_max": 11.637722360326888, "train/extr_return_raw_mean": 3.492041562465911, "train/extr_return_raw_min": -0.4832621763678307, "train/extr_return_raw_std": 2.544109468764447, "train/extr_reward_mag": 1.0495888882494988, "train/extr_reward_max": 1.0495888882494988, "train/extr_reward_mean": 0.051927977208550094, "train/extr_reward_min": -0.42800306935682364, "train/extr_reward_std": 0.2108286920380085, "train/image_loss_mean": 6.366832995245643, "train/image_loss_std": 11.531543907544291, "train/model_loss_mean": 14.173837350615372, "train/model_loss_std": 15.492442320424614, "train/model_opt_grad_norm": 50.9425037247794, "train/model_opt_grad_steps": 63874.40425531915, "train/model_opt_loss": 18424.29117492243, "train/model_opt_model_opt_grad_overflow": 0.0070921985815602835, "train/model_opt_model_opt_grad_scale": 1294.3262411347519, "train/policy_entropy_mag": 2.4982885891664113, "train/policy_entropy_max": 2.4982885891664113, "train/policy_entropy_mean": 0.5571305808868814, "train/policy_entropy_min": 0.07937503093523336, "train/policy_entropy_std": 0.7050847007450483, "train/policy_logprob_mag": 7.43838385318188, "train/policy_logprob_max": -0.009455658402954432, "train/policy_logprob_mean": -0.5567111332788535, "train/policy_logprob_min": -7.43838385318188, "train/policy_logprob_std": 1.1055620798827908, "train/policy_randomness_mag": 0.8817862386399127, "train/policy_randomness_max": 0.8817862386399127, "train/policy_randomness_mean": 0.19664264570736717, "train/policy_randomness_min": 0.02801590255653182, "train/policy_randomness_std": 0.24886395650129792, "train/post_ent_mag": 61.10973726096728, "train/post_ent_max": 61.10973726096728, "train/post_ent_mean": 43.94234772269608, "train/post_ent_min": 20.79042594314467, "train/post_ent_std": 7.655460090501934, "train/prior_ent_mag": 71.33227100778133, "train/prior_ent_max": 71.33227100778133, "train/prior_ent_mean": 56.89671883008159, "train/prior_ent_min": 41.701670829285966, "train/prior_ent_std": 4.830344605953135, "train/rep_loss_mean": 12.914066632588705, "train/rep_loss_std": 9.460297787443121, "train/reward_avg": 0.03280972939724407, "train/reward_loss_mean": 0.058438580549249414, "train/reward_loss_std": 0.25258429274491384, "train/reward_max_data": 1.0205673807901694, "train/reward_max_pred": 1.0137778943312084, "train/reward_neg_acc": 0.9920782734316291, "train/reward_neg_loss": 0.029253612212995266, "train/reward_pos_acc": 0.9721824991787579, "train/reward_pos_loss": 0.8257626016089257, "train/reward_pred": 0.03199522795670844, "train/reward_rate": 0.0368323359929078, "train_stats/sum_log_reward": 10.187912270263, "train_stats/max_log_achievement_collect_coal": 1.032967032967033, "train_stats/max_log_achievement_collect_drink": 8.725274725274724, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.5494505494505495, "train_stats/max_log_achievement_collect_stone": 14.813186813186814, "train_stats/max_log_achievement_collect_wood": 10.31868131868132, "train_stats/max_log_achievement_defeat_skeleton": 0.07692307692307693, "train_stats/max_log_achievement_defeat_zombie": 1.1758241758241759, "train_stats/max_log_achievement_eat_cow": 0.23076923076923078, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3956043956043955, "train_stats/max_log_achievement_make_wood_sword": 1.4615384615384615, "train_stats/max_log_achievement_place_furnace": 2.098901098901099, "train_stats/max_log_achievement_place_plant": 1.4945054945054945, "train_stats/max_log_achievement_place_stone": 4.736263736263736, "train_stats/max_log_achievement_place_table": 2.5604395604395602, "train_stats/max_log_achievement_wake_up": 1.5384615384615385, "train_stats/mean_log_entropy": 0.5562523803213141, "eval_stats/sum_log_reward": 10.225000232458115, "eval_stats/max_log_achievement_collect_coal": 0.875, "eval_stats/max_log_achievement_collect_drink": 5.625, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 14.375, "eval_stats/max_log_achievement_collect_wood": 8.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1875, "eval_stats/max_log_achievement_make_wood_sword": 1.0625, "eval_stats/max_log_achievement_place_furnace": 2.0, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_stone": 4.4375, "eval_stats/max_log_achievement_place_table": 2.0625, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 7.0992723522067536e-06, "report/cont_loss_std": 0.00012838449038099498, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00019900643383152783, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.157627922220854e-06, "report/cont_pred": 0.9951120615005493, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.426527976989746, "report/dyn_loss_std": 9.165460586547852, "report/image_loss_mean": 7.111891269683838, "report/image_loss_std": 11.818607330322266, "report/model_loss_mean": 14.6283540725708, "report/model_loss_std": 15.412432670593262, "report/post_ent_mag": 62.578636169433594, "report/post_ent_max": 62.578636169433594, "report/post_ent_mean": 44.92320251464844, "report/post_ent_min": 20.035024642944336, "report/post_ent_std": 7.838193416595459, "report/prior_ent_mag": 71.5571060180664, "report/prior_ent_max": 71.5571060180664, "report/prior_ent_mean": 57.55883026123047, "report/prior_ent_min": 44.460330963134766, "report/prior_ent_std": 5.071125030517578, "report/rep_loss_mean": 12.426527976989746, "report/rep_loss_std": 9.165460586547852, "report/reward_avg": 0.03876952826976776, "report/reward_loss_mean": 0.060539714992046356, "report/reward_loss_std": 0.23380722105503082, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0896201133728027, "report/reward_neg_acc": 0.9877675175666809, "report/reward_neg_loss": 0.026018353179097176, "report/reward_pos_acc": 0.9534883499145508, "report/reward_pos_loss": 0.8481084108352661, "report/reward_pred": 0.03689700365066528, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 2.8480721425694355e-07, "eval/cont_loss_std": 2.261955160065554e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.0026014428585768e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.2660523768536223e-07, "eval/cont_pred": 0.9980467557907104, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 18.1328182220459, "eval/dyn_loss_std": 10.374600410461426, "eval/image_loss_mean": 11.655110359191895, "eval/image_loss_std": 14.93272876739502, "eval/model_loss_mean": 22.628963470458984, "eval/model_loss_std": 18.961627960205078, "eval/post_ent_mag": 59.47206115722656, "eval/post_ent_max": 59.47206115722656, "eval/post_ent_mean": 42.17808532714844, "eval/post_ent_min": 20.666370391845703, "eval/post_ent_std": 8.0188570022583, "eval/prior_ent_mag": 71.5571060180664, "eval/prior_ent_max": 71.5571060180664, "eval/prior_ent_mean": 58.46421813964844, "eval/prior_ent_min": 42.71696472167969, "eval/prior_ent_std": 4.508764266967773, "eval/rep_loss_mean": 18.1328182220459, "eval/rep_loss_std": 10.374600410461426, "eval/reward_avg": 0.04375000298023224, "eval/reward_loss_mean": 0.09416403621435165, "eval/reward_loss_std": 0.5198419690132141, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0761265754699707, "eval/reward_neg_acc": 0.9836233258247375, "eval/reward_neg_loss": 0.03712870553135872, "eval/reward_pos_acc": 0.8723403811454773, "eval/reward_pos_loss": 1.279770851135254, "eval/reward_pred": 0.03975396603345871, "eval/reward_rate": 0.0458984375, "replay/size": 1000000.0, "replay/inserts": 22416.0, "replay/samples": 22416.0, "replay/insert_wait_avg": 1.3645889927539376e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.2503081559284e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5792.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2842166489659093e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2536008358002, "timer/env.step_count": 2802.0, "timer/env.step_total": 226.56787943840027, "timer/env.step_frac": 0.22651043620246186, "timer/env.step_avg": 0.08085934312576741, "timer/env.step_min": 0.024526119232177734, "timer/env.step_max": 3.5351438522338867, "timer/replay._sample_count": 22416.0, "timer/replay._sample_total": 11.651963472366333, "timer/replay._sample_frac": 0.011649009273878233, "timer/replay._sample_avg": 0.0005198056509799399, "timer/replay._sample_min": 0.00042819976806640625, "timer/replay._sample_max": 0.008718490600585938, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3526.0, "timer/agent.policy_total": 62.38105773925781, "timer/agent.policy_frac": 0.06236524186179678, "timer/agent.policy_avg": 0.017691735036658482, "timer/agent.policy_min": 0.009633064270019531, "timer/agent.policy_max": 0.28209638595581055, "timer/dataset_train_count": 1401.0, "timer/dataset_train_total": 0.16373419761657715, "timer/dataset_train_frac": 0.000163692685014843, "timer/dataset_train_avg": 0.00011686952006893443, "timer/dataset_train_min": 0.00010204315185546875, "timer/dataset_train_max": 0.0005543231964111328, "timer/agent.train_count": 1401.0, "timer/agent.train_total": 635.0417132377625, "timer/agent.train_frac": 0.634880706959844, "timer/agent.train_avg": 0.4532774541311652, "timer/agent.train_min": 0.4383699893951416, "timer/agent.train_max": 1.8025038242340088, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47830843925476074, "timer/agent.report_frac": 0.00047818717058863055, "timer/agent.report_avg": 0.23915421962738037, "timer/agent.report_min": 0.2345292568206787, "timer/agent.report_max": 0.24377918243408203, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8841333884910256e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 22.41000312991548}
{"step": 1036232, "time": 47407.14496421814, "episode/length": 223.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1036728, "time": 47425.65567803383, "episode/length": 211.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 1036864, "time": 47432.01640820503, "episode/length": 313.0, "episode/score": 13.099999964237213, "episode/reward_rate": 0.9872611464968153, "episode/intrinsic_return": 0.0}
{"step": 1037176, "time": 47443.88841509819, "episode/length": 358.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9916434540389972, "episode/intrinsic_return": 0.0}
{"step": 1037392, "time": 47453.19686126709, "episode/length": 228.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 1038400, "time": 47488.9392914772, "episode/length": 410.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9902676399026764, "episode/intrinsic_return": 0.0}
{"step": 1038664, "time": 47499.14622092247, "episode/length": 429.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9976744186046511, "episode/intrinsic_return": 0.0}
{"step": 1038968, "time": 47511.0614233017, "episode/length": 223.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1039144, "time": 47518.614080667496, "episode/length": 218.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 1039200, "time": 47522.26819849014, "episode/length": 463.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9806034482758621, "episode/intrinsic_return": 0.0}
{"step": 1039400, "time": 47530.26827263832, "episode/length": 316.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9842271293375394, "episode/intrinsic_return": 0.0}
{"step": 1039696, "time": 47542.12156009674, "episode/length": 161.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 1040000, "time": 47573.60663628578, "eval_episode/length": 137.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9492753623188406}
{"step": 1040000, "time": 47579.269749403, "eval_episode/length": 219.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 1040000, "time": 47581.9921336174, "eval_episode/length": 242.0, "eval_episode/score": 12.100000016391277, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 1040000, "time": 47583.85027933121, "eval_episode/length": 250.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9960159362549801}
{"step": 1040000, "time": 47587.16748833656, "eval_episode/length": 287.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 1040000, "time": 47592.01622056961, "eval_episode/length": 359.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 1040000, "time": 47594.71026420593, "eval_episode/length": 246.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9676113360323887}
{"step": 1040000, "time": 47598.57319545746, "eval_episode/length": 430.0, "eval_episode/score": 13.100000001490116, "eval_episode/reward_rate": 0.9976798143851509}
{"step": 1040176, "time": 47604.53542780876, "episode/length": 430.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953596287703016, "episode/intrinsic_return": 0.0}
{"step": 1040712, "time": 47626.08480119705, "episode/length": 195.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 1040992, "time": 47637.6125831604, "episode/length": 101.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 1041240, "time": 47647.87911391258, "episode/length": 192.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 1041640, "time": 47662.98029541969, "episode/length": 333.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9880239520958084, "episode/intrinsic_return": 0.0}
{"step": 1041920, "time": 47674.38325023651, "episode/length": 314.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 1042208, "time": 47685.72193837166, "episode/length": 442.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796839729119639, "episode/intrinsic_return": 0.0}
{"step": 1042240, "time": 47688.53323340416, "episode/length": 379.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9973684210526316, "episode/intrinsic_return": 0.0}
{"step": 1042392, "time": 47695.43888926506, "episode/length": 209.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1042560, "time": 47702.94945144653, "episode/length": 164.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 1042896, "time": 47715.92231106758, "episode/length": 62.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 1043296, "time": 47731.12614774704, "episode/length": 287.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 1043328, "time": 47734.48496890068, "episode/length": 175.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 1043520, "time": 47743.08128428459, "episode/length": 119.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 1043536, "time": 47745.34790158272, "episode/length": 165.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 1043880, "time": 47758.38757967949, "episode/length": 279.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 1044016, "time": 47764.82821083069, "episode/length": 61.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9354838709677419, "episode/intrinsic_return": 0.0}
{"step": 1044160, "time": 47771.22498011589, "episode/length": 990.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9979818365287588, "episode/intrinsic_return": 0.0}
{"step": 1044672, "time": 47790.35556435585, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 1044680, "time": 47791.859500169754, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 1044784, "time": 47797.20963716507, "episode/length": 95.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 1044904, "time": 47802.71871328354, "episode/length": 332.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.996996996996997, "episode/intrinsic_return": 0.0}
{"step": 1045176, "time": 47813.75532197952, "episode/length": 234.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1045688, "time": 47832.60200858116, "episode/length": 225.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 1045776, "time": 47837.596632003784, "episode/length": 279.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 1046288, "time": 47856.76808524132, "episode/length": 201.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 1046424, "time": 47862.735297203064, "episode/length": 282.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9823321554770318, "episode/intrinsic_return": 0.0}
{"step": 1046792, "time": 47876.87713289261, "episode/length": 250.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 1047024, "time": 47886.43768787384, "episode/length": 264.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 1047064, "time": 47889.18499660492, "episode/length": 235.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1047096, "time": 47891.85460329056, "episode/length": 301.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9768211920529801, "episode/intrinsic_return": 0.0}
{"step": 1047696, "time": 47914.20518350601, "episode/length": 239.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 1047712, "time": 47916.275844335556, "episode/length": 252.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 1048152, "time": 47932.75151562691, "episode/length": 232.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 1048216, "time": 47936.579329013824, "episode/length": 177.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 1048608, "time": 47953.58444023132, "episode/length": 272.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 1048960, "time": 47967.35718345642, "episode/length": 241.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 1049008, "time": 47970.4741230011, "episode/length": 163.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 1049400, "time": 47984.97545862198, "episode/length": 287.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9826388888888888, "episode/intrinsic_return": 0.0}
{"step": 1049680, "time": 47996.329414606094, "episode/length": 190.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 1049784, "time": 48001.31035709381, "episode/length": 258.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 1050088, "time": 48034.84107923508, "eval_episode/length": 93.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9893617021276596}
{"step": 1050088, "time": 48038.93249964714, "eval_episode/length": 138.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9568345323741008}
{"step": 1050088, "time": 48044.617128133774, "eval_episode/length": 181.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.978021978021978}
{"step": 1050088, "time": 48046.89163970947, "eval_episode/length": 192.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 1050088, "time": 48049.111078977585, "eval_episode/length": 205.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 1050088, "time": 48054.502437114716, "eval_episode/length": 192.0, "eval_episode/score": 11.099999964237213, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 1050088, "time": 48056.47325396538, "eval_episode/length": 297.0, "eval_episode/score": 11.100000016391277, "eval_episode/reward_rate": 0.9765100671140939}
{"step": 1050088, "time": 48058.845297813416, "eval_episode/length": 314.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9809523809523809}
{"step": 1050272, "time": 48065.28371214867, "episode/length": 163.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 1050520, "time": 48075.05196976662, "episode/length": 431.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 1050864, "time": 48088.70915603638, "episode/length": 182.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 1051000, "time": 48094.65406703949, "episode/length": 347.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 1051128, "time": 48100.52644062042, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 1052096, "time": 48135.0375995636, "episode/length": 196.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 1052272, "time": 48142.793469429016, "episode/length": 158.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 1052344, "time": 48146.69862151146, "episode/length": 332.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 1052616, "time": 48157.59005737305, "episode/length": 500.0, "episode/score": 13.099999964237213, "episode/reward_rate": 0.9920159680638723, "episode/intrinsic_return": 0.0}
{"step": 1053000, "time": 48172.27541184425, "episode/length": 266.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 1053392, "time": 48187.26825070381, "episode/length": 547.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9945255474452555, "episode/intrinsic_return": 0.0}
{"step": 1053424, "time": 48189.864695072174, "episode/length": 286.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 1053688, "time": 48200.36779379845, "episode/length": 133.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1053760, "time": 48204.73183512688, "episode/length": 435.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 1053872, "time": 48210.232822179794, "episode/length": 221.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 1053960, "time": 48214.54605174065, "episode/length": 210.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1054512, "time": 48235.21410870552, "episode/length": 188.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 1054816, "time": 48247.09420585632, "episode/length": 308.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9870550161812298, "episode/intrinsic_return": 0.0}
{"step": 1055104, "time": 48258.61422872543, "episode/length": 213.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 1055560, "time": 48275.4890396595, "episode/length": 233.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 1055928, "time": 48289.7906601429, "episode/length": 312.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9840255591054313, "episode/intrinsic_return": 0.0}
{"step": 1056112, "time": 48297.89576911926, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 1056256, "time": 48304.27047777176, "episode/length": 297.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765100671140939, "episode/intrinsic_return": 0.0}
{"step": 1056696, "time": 48320.57309746742, "episode/length": 272.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 1056904, "time": 48331.01091003418, "episode/length": 367.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9891304347826086, "episode/intrinsic_return": 0.0}
{"step": 1057432, "time": 48350.53700089455, "episode/length": 187.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 1057560, "time": 48356.50373291969, "episode/length": 249.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 1057800, "time": 48366.17322039604, "episode/length": 504.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9782178217821782, "episode/intrinsic_return": 0.0}
{"step": 1057864, "time": 48369.934272527695, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 1057984, "time": 48375.873807907104, "episode/length": 359.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 1058112, "time": 48381.99920654297, "episode/length": 150.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 1058185, "time": 48386.8552134037, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.611509498974955, "train/action_min": 0.0, "train/action_std": 3.4087978305546103, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03261245055295897, "train/actor_opt_grad_steps": 65340.0, "train/actor_opt_loss": -5.720513613881372, "train/adv_mag": 0.4258135736834073, "train/adv_max": 0.3806924324297736, "train/adv_mean": 0.00216819427510824, "train/adv_min": -0.3516756155600784, "train/adv_std": 0.04716975537809075, "train/cont_avg": 0.9955188940602837, "train/cont_loss_mean": 0.0003769228335857967, "train/cont_loss_std": 0.011381481231491797, "train/cont_neg_acc": 0.981374536845701, "train/cont_neg_loss": 0.10809787377432303, "train/cont_pos_acc": 0.9999721553308744, "train/cont_pos_loss": 9.751167538572064e-05, "train/cont_pred": 0.9955560121130436, "train/cont_rate": 0.9955188940602837, "train/dyn_loss_mean": 13.073697096912573, "train/dyn_loss_std": 9.379969799772223, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0115078341030905, "train/extr_critic_critic_opt_grad_steps": 65340.0, "train/extr_critic_critic_opt_loss": 15401.312029033688, "train/extr_critic_mag": 10.586789841347553, "train/extr_critic_max": 10.586789841347553, "train/extr_critic_mean": 3.3449381023434035, "train/extr_critic_min": -0.15255432348724798, "train/extr_critic_std": 2.5440528874701642, "train/extr_return_normed_mag": 1.4156421828777233, "train/extr_return_normed_max": 1.4156421828777233, "train/extr_return_normed_mean": 0.3870700405421832, "train/extr_return_normed_min": -0.09429247114569583, "train/extr_return_normed_std": 0.321960449535796, "train/extr_return_rate": 0.8858350401229047, "train/extr_return_raw_mag": 11.571664228506968, "train/extr_return_raw_max": 11.571664228506968, "train/extr_return_raw_mean": 3.3622470848949244, "train/extr_return_raw_min": -0.47941113258084506, "train/extr_return_raw_std": 2.5696711362676417, "train/extr_reward_mag": 1.0499385569957977, "train/extr_reward_max": 1.0499385569957977, "train/extr_reward_mean": 0.051058779331914925, "train/extr_reward_min": -0.44462897760648257, "train/extr_reward_std": 0.21008665405266674, "train/image_loss_mean": 6.624840935916765, "train/image_loss_std": 11.857650851527005, "train/model_loss_mean": 14.528573638158488, "train/model_loss_std": 15.731677995505908, "train/model_opt_grad_norm": 49.77182520873158, "train/model_opt_grad_steps": 65282.985815602835, "train/model_opt_loss": 18569.14617963209, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1276.595744680851, "train/policy_entropy_mag": 2.532822495656656, "train/policy_entropy_max": 2.532822495656656, "train/policy_entropy_mean": 0.5576465835808017, "train/policy_entropy_min": 0.0793750265494306, "train/policy_entropy_std": 0.7163826189142593, "train/policy_logprob_mag": 7.438383863327351, "train/policy_logprob_max": -0.009455658402954432, "train/policy_logprob_mean": -0.5577009060281388, "train/policy_logprob_min": -7.438383863327351, "train/policy_logprob_std": 1.1069303099990737, "train/policy_randomness_mag": 0.8939751910825148, "train/policy_randomness_max": 0.8939751910825148, "train/policy_randomness_mean": 0.19682477224380412, "train/policy_randomness_min": 0.0280159010505634, "train/policy_randomness_std": 0.25285162612901513, "train/post_ent_mag": 61.35080066978509, "train/post_ent_max": 61.35080066978509, "train/post_ent_mean": 43.96209432723674, "train/post_ent_min": 20.63302038747368, "train/post_ent_std": 7.7029364734676715, "train/prior_ent_mag": 71.26677103245513, "train/prior_ent_max": 71.26677103245513, "train/prior_ent_mean": 57.06542660327668, "train/prior_ent_min": 41.58402966438456, "train/prior_ent_std": 4.828715111346955, "train/rep_loss_mean": 13.073697096912573, "train/rep_loss_std": 9.379969799772223, "train/reward_avg": 0.03290738555080924, "train/reward_loss_mean": 0.05913756618685756, "train/reward_loss_std": 0.2571678308519066, "train/reward_max_data": 1.0262411410081471, "train/reward_max_pred": 1.019806757886359, "train/reward_neg_acc": 0.9923992161209702, "train/reward_neg_loss": 0.029539252961622485, "train/reward_pos_acc": 0.9702216775704783, "train/reward_pos_loss": 0.8334856836508352, "train/reward_pred": 0.03187971981572555, "train/reward_rate": 0.0369639295212766, "train_stats/sum_log_reward": 10.45714301154727, "train_stats/max_log_achievement_collect_coal": 0.9404761904761905, "train_stats/max_log_achievement_collect_drink": 7.440476190476191, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.5476190476190477, "train_stats/max_log_achievement_collect_stone": 17.821428571428573, "train_stats/max_log_achievement_collect_wood": 10.785714285714286, "train_stats/max_log_achievement_defeat_skeleton": 0.05952380952380952, "train_stats/max_log_achievement_defeat_zombie": 1.1071428571428572, "train_stats/max_log_achievement_eat_cow": 0.19047619047619047, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.023809523809523808, "train_stats/max_log_achievement_make_stone_sword": 0.011904761904761904, "train_stats/max_log_achievement_make_wood_pickaxe": 1.8928571428571428, "train_stats/max_log_achievement_make_wood_sword": 1.4166666666666667, "train_stats/max_log_achievement_place_furnace": 2.5357142857142856, "train_stats/max_log_achievement_place_plant": 1.4880952380952381, "train_stats/max_log_achievement_place_stone": 5.845238095238095, "train_stats/max_log_achievement_place_table": 2.9404761904761907, "train_stats/max_log_achievement_wake_up": 1.5, "train_stats/mean_log_entropy": 0.5400339354361806, "eval_stats/sum_log_reward": 10.78750017285347, "eval_stats/max_log_achievement_collect_coal": 1.0, "eval_stats/max_log_achievement_collect_drink": 6.5625, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.6875, "eval_stats/max_log_achievement_collect_stone": 13.875, "eval_stats/max_log_achievement_collect_wood": 10.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.3125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.75, "eval_stats/max_log_achievement_make_wood_sword": 1.4375, "eval_stats/max_log_achievement_place_furnace": 2.0, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_stone": 4.625, "eval_stats/max_log_achievement_place_table": 2.6875, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 8.751439963816665e-07, "report/cont_loss_std": 1.1218578038096894e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00017069322348106652, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.0919074472658394e-07, "report/cont_pred": 0.996094286441803, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.4107027053833, "report/dyn_loss_std": 9.6611967086792, "report/image_loss_mean": 6.0216383934021, "report/image_loss_std": 8.007913589477539, "report/model_loss_mean": 14.118457794189453, "report/model_loss_std": 12.23344612121582, "report/post_ent_mag": 61.21503448486328, "report/post_ent_max": 61.21503448486328, "report/post_ent_mean": 43.26215744018555, "report/post_ent_min": 21.99323272705078, "report/post_ent_std": 7.921225547790527, "report/prior_ent_mag": 71.43240356445312, "report/prior_ent_max": 71.43240356445312, "report/prior_ent_mean": 56.79141616821289, "report/prior_ent_min": 43.20343017578125, "report/prior_ent_std": 4.616322994232178, "report/rep_loss_mean": 13.4107027053833, "report/rep_loss_std": 9.6611967086792, "report/reward_avg": 0.03212890401482582, "report/reward_loss_mean": 0.050396695733070374, "report/reward_loss_std": 0.2527717649936676, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018129348754883, "report/reward_neg_acc": 0.9878543019294739, "report/reward_neg_loss": 0.02687409147620201, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6959614753723145, "report/reward_pred": 0.03422462195158005, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.009385460056364536, "eval/cont_loss_std": 0.3001483976840973, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 1.9221152067184448, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.3356735450997803e-07, "eval/cont_pred": 0.9960947036743164, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.655542373657227, "eval/dyn_loss_std": 10.310270309448242, "eval/image_loss_mean": 9.469160079956055, "eval/image_loss_std": 14.117526054382324, "eval/model_loss_mean": 20.173458099365234, "eval/model_loss_std": 18.200666427612305, "eval/post_ent_mag": 58.102073669433594, "eval/post_ent_max": 58.102073669433594, "eval/post_ent_mean": 41.816322326660156, "eval/post_ent_min": 22.985668182373047, "eval/post_ent_std": 7.311098575592041, "eval/prior_ent_mag": 71.43240356445312, "eval/prior_ent_max": 71.43240356445312, "eval/prior_ent_mean": 57.493431091308594, "eval/prior_ent_min": 44.9326286315918, "eval/prior_ent_std": 4.585392475128174, "eval/rep_loss_mean": 17.655542373657227, "eval/rep_loss_std": 10.310270309448242, "eval/reward_avg": 0.04902343451976776, "eval/reward_loss_mean": 0.10158461332321167, "eval/reward_loss_std": 0.49199143052101135, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0030097961425781, "eval/reward_neg_acc": 0.9835051894187927, "eval/reward_neg_loss": 0.03780373930931091, "eval/reward_pos_acc": 0.8703703880310059, "eval/reward_pos_loss": 1.2472783327102661, "eval/reward_pred": 0.047139815986156464, "eval/reward_rate": 0.052734375, "replay/size": 1000000.0, "replay/inserts": 22560.0, "replay/samples": 22560.0, "replay/insert_wait_avg": 1.3912083409356733e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.288110401613492e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5968.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3038316297147613e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.093932390213, "timer/env.step_count": 2820.0, "timer/env.step_total": 217.44297432899475, "timer/env.step_frac": 0.21742255130906407, "timer/env.step_avg": 0.07710743770531729, "timer/env.step_min": 0.02390265464782715, "timer/env.step_max": 2.2608747482299805, "timer/replay._sample_count": 22560.0, "timer/replay._sample_total": 11.718489170074463, "timer/replay._sample_frac": 0.011717388527762995, "timer/replay._sample_avg": 0.0005194365766876978, "timer/replay._sample_min": 0.0004239082336425781, "timer/replay._sample_max": 0.009291887283325195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3566.0, "timer/agent.policy_total": 63.59619903564453, "timer/agent.policy_frac": 0.0635902258537359, "timer/agent.policy_avg": 0.017834043476064085, "timer/agent.policy_min": 0.00966644287109375, "timer/agent.policy_max": 0.16996526718139648, "timer/dataset_train_count": 1410.0, "timer/dataset_train_total": 0.1562364101409912, "timer/dataset_train_frac": 0.00015622173585993866, "timer/dataset_train_avg": 0.00011080596463900086, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.00028252601623535156, "timer/agent.train_count": 1410.0, "timer/agent.train_total": 637.596156835556, "timer/agent.train_frac": 0.6375362715297237, "timer/agent.train_avg": 0.4521958559117419, "timer/agent.train_min": 0.4372894763946533, "timer/agent.train_max": 1.8722615242004395, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4725511074066162, "timer/agent.report_frac": 0.0004725067237206654, "timer/agent.report_avg": 0.2362755537033081, "timer/agent.report_min": 0.22792506217956543, "timer/agent.report_max": 0.24462604522705078, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7177165201491535e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 22.557528795846956}
{"step": 1058632, "time": 48401.781148672104, "episode/length": 296.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9831649831649831, "episode/intrinsic_return": 0.0}
{"step": 1059112, "time": 48419.71000576019, "episode/length": 193.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 1059528, "time": 48435.844053030014, "episode/length": 261.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 1059768, "time": 48445.64454245567, "episode/length": 222.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.968609865470852, "episode/intrinsic_return": 0.0}
{"step": 1059792, "time": 48448.33194899559, "episode/length": 386.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9948320413436692, "episode/intrinsic_return": 0.0}
{"step": 1059824, "time": 48451.10640954971, "episode/length": 252.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 1060072, "time": 48482.40249705315, "eval_episode/length": 182.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 1060072, "time": 48484.296530008316, "eval_episode/length": 189.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 1060072, "time": 48487.60713195801, "eval_episode/length": 224.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 1060072, "time": 48490.835352659225, "eval_episode/length": 260.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9961685823754789}
{"step": 1060072, "time": 48493.52642226219, "eval_episode/length": 281.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.975177304964539}
{"step": 1060072, "time": 48495.302023649216, "eval_episode/length": 284.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9894736842105263}
{"step": 1060072, "time": 48499.99995160103, "eval_episode/length": 163.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 1060072, "time": 48501.680920124054, "eval_episode/length": 349.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9914285714285714}
{"step": 1060104, "time": 48502.77223777771, "episode/length": 248.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 1060232, "time": 48508.8250682354, "episode/length": 295.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9695945945945946, "episode/intrinsic_return": 0.0}
{"step": 1060616, "time": 48523.399856328964, "episode/length": 187.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 1061552, "time": 48557.265916347504, "episode/length": 215.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 1061872, "time": 48569.81112909317, "episode/length": 204.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 1062080, "time": 48578.40993666649, "episode/length": 430.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9976798143851509, "episode/intrinsic_return": 0.0}
{"step": 1062104, "time": 48580.69234967232, "episode/length": 321.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9875776397515528, "episode/intrinsic_return": 0.0}
{"step": 1062256, "time": 48587.797495126724, "episode/length": 307.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9902597402597403, "episode/intrinsic_return": 0.0}
{"step": 1062744, "time": 48605.717743873596, "episode/length": 329.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9878787878787879, "episode/intrinsic_return": 0.0}
{"step": 1063008, "time": 48616.642282009125, "episode/length": 298.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.979933110367893, "episode/intrinsic_return": 0.0}
{"step": 1063184, "time": 48624.196521520615, "episode/length": 426.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 1063744, "time": 48644.851038217545, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 1064072, "time": 48657.501311302185, "episode/length": 274.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 1064088, "time": 48659.51160001755, "episode/length": 247.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 1064112, "time": 48662.247651815414, "episode/length": 137.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 1064152, "time": 48664.949749708176, "episode/length": 324.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9753846153846154, "episode/intrinsic_return": 0.0}
{"step": 1064520, "time": 48678.954642534256, "episode/length": 221.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 1064560, "time": 48682.010639190674, "episode/length": 101.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 1065000, "time": 48700.16740846634, "episode/length": 342.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9941690962099126, "episode/intrinsic_return": 0.0}
{"step": 1065104, "time": 48705.47483110428, "episode/length": 239.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 1065784, "time": 48730.02624678612, "episode/length": 211.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 1065976, "time": 48738.1675901413, "episode/length": 237.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 1066072, "time": 48743.48620057106, "episode/length": 244.0, "episode/score": 12.100000061094761, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 1066672, "time": 48765.74290513992, "episode/length": 314.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9746031746031746, "episode/intrinsic_return": 0.0}
{"step": 1067016, "time": 48778.905091285706, "episode/length": 238.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 1067032, "time": 48781.07236146927, "episode/length": 155.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1067368, "time": 48794.03530049324, "episode/length": 355.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 1067528, "time": 48801.13062095642, "episode/length": 61.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 1067608, "time": 48805.76770210266, "episode/length": 191.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 1067808, "time": 48814.43230128288, "episode/length": 54.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 1067896, "time": 48818.84107017517, "episode/length": 361.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.988950276243094, "episode/intrinsic_return": 0.0}
{"step": 1067952, "time": 48822.72397851944, "episode/length": 246.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 1067984, "time": 48825.34232544899, "episode/length": 163.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 1068256, "time": 48836.27910709381, "episode/length": 55.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 1068280, "time": 48838.47630691528, "episode/length": 464.0, "episode/score": 14.100000008940697, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 1068304, "time": 48841.059052467346, "episode/length": 43.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 1068688, "time": 48855.56467485428, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 1068712, "time": 48857.978761434555, "episode/length": 211.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 1069272, "time": 48878.4981739521, "episode/length": 171.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 1069528, "time": 48888.899000644684, "episode/length": 192.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 1069672, "time": 48895.489350795746, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 1069936, "time": 48906.22932100296, "episode/length": 206.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 1070016, "time": 48910.64264130592, "episode/length": 213.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 1070056, "time": 48934.742042303085, "eval_episode/length": 175.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 1070056, "time": 48936.90553736687, "eval_episode/length": 189.0, "eval_episode/score": 12.099999994039536, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 1070056, "time": 48938.589414834976, "eval_episode/length": 193.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.979381443298969}
{"step": 1070056, "time": 48940.78028798103, "eval_episode/length": 203.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9656862745098039}
{"step": 1070056, "time": 48945.33592271805, "eval_episode/length": 268.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9851301115241635}
{"step": 1070056, "time": 48947.57781624794, "eval_episode/length": 277.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9712230215827338}
{"step": 1070056, "time": 48950.22192358971, "eval_episode/length": 299.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 1070056, "time": 48952.364493608475, "eval_episode/length": 311.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 1070328, "time": 48961.5707449913, "episode/length": 339.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1070624, "time": 48973.464052438736, "episode/length": 168.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 1070880, "time": 48983.85359954834, "episode/length": 273.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 1071136, "time": 48994.14709210396, "episode/length": 182.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 1071456, "time": 49006.68693161011, "episode/length": 342.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9941690962099126, "episode/intrinsic_return": 0.0}
{"step": 1071888, "time": 49022.90434765816, "episode/length": 243.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 1072368, "time": 49040.77508735657, "episode/length": 293.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1072400, "time": 49043.47645545006, "episode/length": 358.0, "episode/score": 12.099999964237213, "episode/reward_rate": 0.9860724233983287, "episode/intrinsic_return": 0.0}
{"step": 1072640, "time": 49053.30647087097, "episode/length": 288.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9757785467128027, "episode/intrinsic_return": 0.0}
{"step": 1072968, "time": 49065.75204014778, "episode/length": 292.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 1073168, "time": 49076.1712346077, "episode/length": 213.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 1073496, "time": 49088.78966450691, "episode/length": 200.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 1073768, "time": 49099.67180418968, "episode/length": 360.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9916897506925207, "episode/intrinsic_return": 0.0}
{"step": 1073840, "time": 49103.95284795761, "episode/length": 183.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 1073976, "time": 49110.00349402428, "episode/length": 196.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 1074072, "time": 49114.83406710625, "episode/length": 137.0, "episode/score": 10.100000038743019, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 1074104, "time": 49117.60769677162, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 1074552, "time": 49134.51638817787, "episode/length": 426.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9976580796252927, "episode/intrinsic_return": 0.0}
{"step": 1075280, "time": 49161.54420661926, "episode/length": 188.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 1075280, "time": 49161.55311179161, "episode/length": 222.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 1075344, "time": 49167.26664876938, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 1075512, "time": 49174.40397453308, "episode/length": 292.0, "episode/score": 14.100000038743019, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 1075696, "time": 49182.3903028965, "episode/length": 202.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 1075784, "time": 49186.793605566025, "episode/length": 242.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 1076104, "time": 49199.168987989426, "episode/length": 193.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 1076440, "time": 49212.22099494934, "episode/length": 115.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 1076688, "time": 49222.38300728798, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 1076776, "time": 49226.69124507904, "episode/length": 186.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 1077176, "time": 49241.85046219826, "episode/length": 383.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9973958333333334, "episode/intrinsic_return": 0.0}
{"step": 1077424, "time": 49252.19013094902, "episode/length": 204.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 1077776, "time": 49265.74432873726, "episode/length": 166.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 1078184, "time": 49281.10551571846, "episode/length": 186.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 1078240, "time": 49284.882061481476, "episode/length": 317.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 1078688, "time": 49301.72376585007, "episode/length": 322.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9814241486068112, "episode/intrinsic_return": 0.0}
{"step": 1078760, "time": 49305.499494075775, "episode/length": 434.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9977011494252873, "episode/intrinsic_return": 0.0}
{"step": 1078856, "time": 49310.52765059471, "episode/length": 209.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1079472, "time": 49333.16049385071, "episode/length": 336.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9910979228486647, "episode/intrinsic_return": 0.0}
{"step": 1079888, "time": 49348.95717048645, "episode/length": 307.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9967532467532467, "episode/intrinsic_return": 0.0}
{"step": 1080040, "time": 49370.992889642715, "eval_episode/length": 47.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9166666666666666}
{"step": 1080040, "time": 49373.10556077957, "eval_episode/length": 58.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 1080040, "time": 49379.93223285675, "eval_episode/length": 176.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 1080040, "time": 49386.318777799606, "eval_episode/length": 232.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 1080040, "time": 49387.988302230835, "eval_episode/length": 233.0, "eval_episode/score": 12.100000023841858, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 1080040, "time": 49390.827186107635, "eval_episode/length": 213.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 1080040, "time": 49393.32683777809, "eval_episode/length": 280.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.99644128113879}
{"step": 1080040, "time": 49397.06262540817, "eval_episode/length": 266.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9700374531835206}
{"step": 1080041, "time": 49398.09582686424, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.606412550982307, "train/action_min": 0.0, "train/action_std": 3.4692274384638844, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.032011580365874315, "train/actor_opt_grad_steps": 66725.0, "train/actor_opt_loss": -7.446071244995384, "train/adv_mag": 0.4357309976921362, "train/adv_max": 0.3975402831154711, "train/adv_mean": 0.002250143030912167, "train/adv_min": -0.3613526734578259, "train/adv_std": 0.046997671481221914, "train/cont_avg": 0.9953900505514706, "train/cont_loss_mean": 0.00011755303323343135, "train/cont_loss_std": 0.0035997910880320875, "train/cont_neg_acc": 0.991172840418639, "train/cont_neg_loss": 0.01938347045626735, "train/cont_pos_acc": 0.9999999811544138, "train/cont_pos_loss": 2.1314504447749312e-05, "train/cont_pred": 0.9954256722155739, "train/cont_rate": 0.9953900505514706, "train/dyn_loss_mean": 13.004000250030966, "train/dyn_loss_std": 9.436716808992273, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0499748938223894, "train/extr_critic_critic_opt_grad_steps": 66725.0, "train/extr_critic_critic_opt_loss": 15312.301169002758, "train/extr_critic_mag": 10.642907303922316, "train/extr_critic_max": 10.642907303922316, "train/extr_critic_mean": 3.3840589400599983, "train/extr_critic_min": -0.1604741285828983, "train/extr_critic_std": 2.566366912687526, "train/extr_return_normed_mag": 1.412945617647732, "train/extr_return_normed_max": 1.412945617647732, "train/extr_return_normed_mean": 0.3908100981703576, "train/extr_return_normed_min": -0.08958517691558775, "train/extr_return_normed_std": 0.32199461856747374, "train/extr_return_rate": 0.8836268247926936, "train/extr_return_raw_mag": 11.634926543516272, "train/extr_return_raw_max": 11.634926543516272, "train/extr_return_raw_mean": 3.4021681915311253, "train/extr_return_raw_min": -0.46739835204447017, "train/extr_return_raw_std": 2.5936280506498672, "train/extr_reward_mag": 1.0489421381669886, "train/extr_reward_max": 1.0489421381669886, "train/extr_reward_mean": 0.05006871346439071, "train/extr_reward_min": -0.4230024963617325, "train/extr_reward_std": 0.20829763088156195, "train/image_loss_mean": 6.503381420584286, "train/image_loss_std": 11.77735438416986, "train/model_loss_mean": 14.364211951985078, "train/model_loss_std": 15.692385876879973, "train/model_opt_grad_norm": 51.6942556886112, "train/model_opt_grad_steps": 66666.60294117648, "train/model_opt_loss": 18338.537504308362, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1277.5735294117646, "train/policy_entropy_mag": 2.5591228551724376, "train/policy_entropy_max": 2.5591228551724376, "train/policy_entropy_mean": 0.588663423762602, "train/policy_entropy_min": 0.07937502269359197, "train/policy_entropy_std": 0.7523575859034762, "train/policy_logprob_mag": 7.438383866758907, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5892486263285664, "train/policy_logprob_min": -7.438383866758907, "train/policy_logprob_std": 1.13132741959656, "train/policy_randomness_mag": 0.9032580620225739, "train/policy_randomness_max": 0.9032580620225739, "train/policy_randomness_mean": 0.20777235662235932, "train/policy_randomness_min": 0.028015899704769254, "train/policy_randomness_std": 0.2655492124750334, "train/post_ent_mag": 61.286682689891144, "train/post_ent_max": 61.286682689891144, "train/post_ent_mean": 43.89673112420475, "train/post_ent_min": 20.562049879747278, "train/post_ent_std": 7.70852987205281, "train/prior_ent_mag": 71.27133038464714, "train/prior_ent_max": 71.27133038464714, "train/prior_ent_mean": 56.93747812158921, "train/prior_ent_min": 41.50866474824793, "train/prior_ent_std": 4.857387721538544, "train/rep_loss_mean": 13.004000250030966, "train/rep_loss_std": 9.436716808992273, "train/reward_avg": 0.03252814755336765, "train/reward_loss_mean": 0.058312853825662064, "train/reward_loss_std": 0.24891398233525894, "train/reward_max_data": 1.0264705945463741, "train/reward_max_pred": 1.0188675312434925, "train/reward_neg_acc": 0.9923293450299431, "train/reward_neg_loss": 0.02984083440456101, "train/reward_pos_acc": 0.9773589692571584, "train/reward_pos_loss": 0.8086259470266455, "train/reward_pred": 0.03208371644894428, "train/reward_rate": 0.036578010110294115, "train_stats/sum_log_reward": 10.421839333128656, "train_stats/max_log_achievement_collect_coal": 0.8160919540229885, "train_stats/max_log_achievement_collect_drink": 7.2298850574712645, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.6206896551724137, "train_stats/max_log_achievement_collect_stone": 14.735632183908047, "train_stats/max_log_achievement_collect_wood": 10.402298850574713, "train_stats/max_log_achievement_defeat_skeleton": 0.1724137931034483, "train_stats/max_log_achievement_defeat_zombie": 0.9885057471264368, "train_stats/max_log_achievement_eat_cow": 0.1724137931034483, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.022988505747126436, "train_stats/max_log_achievement_make_stone_sword": 0.011494252873563218, "train_stats/max_log_achievement_make_wood_pickaxe": 2.218390804597701, "train_stats/max_log_achievement_make_wood_sword": 1.0459770114942528, "train_stats/max_log_achievement_place_furnace": 1.8850574712643677, "train_stats/max_log_achievement_place_plant": 1.5862068965517242, "train_stats/max_log_achievement_place_stone": 5.551724137931035, "train_stats/max_log_achievement_place_table": 2.7471264367816093, "train_stats/max_log_achievement_wake_up": 1.6206896551724137, "train_stats/mean_log_entropy": 0.5494177197587902, "eval_stats/sum_log_reward": 10.100000301996866, "eval_stats/max_log_achievement_collect_coal": 0.9583333333333334, "eval_stats/max_log_achievement_collect_drink": 5.958333333333333, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.8333333333333333, "eval_stats/max_log_achievement_collect_stone": 11.291666666666666, "eval_stats/max_log_achievement_collect_wood": 10.416666666666666, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 1.125, "eval_stats/max_log_achievement_eat_cow": 0.08333333333333333, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.0416666666666665, "eval_stats/max_log_achievement_make_wood_sword": 1.0833333333333333, "eval_stats/max_log_achievement_place_furnace": 1.8333333333333333, "eval_stats/max_log_achievement_place_plant": 1.7916666666666667, "eval_stats/max_log_achievement_place_stone": 3.25, "eval_stats/max_log_achievement_place_table": 2.875, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 7.10727420027979e-07, "report/cont_loss_std": 1.830546352721285e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00020275572023820132, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.1705954250373907e-07, "report/cont_pred": 0.9970707893371582, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 13.856485366821289, "report/dyn_loss_std": 8.37039852142334, "report/image_loss_mean": 6.354186058044434, "report/image_loss_std": 13.13833236694336, "report/model_loss_mean": 14.714929580688477, "report/model_loss_std": 16.56959342956543, "report/post_ent_mag": 59.7487678527832, "report/post_ent_max": 59.7487678527832, "report/post_ent_mean": 42.53644561767578, "report/post_ent_min": 20.37844467163086, "report/post_ent_std": 6.820122718811035, "report/prior_ent_mag": 71.25796508789062, "report/prior_ent_max": 71.25796508789062, "report/prior_ent_mean": 56.98042297363281, "report/prior_ent_min": 37.75347137451172, "report/prior_ent_std": 4.525670528411865, "report/rep_loss_mean": 13.856485366821289, "report/rep_loss_std": 8.37039852142334, "report/reward_avg": 0.03242187201976776, "report/reward_loss_mean": 0.04685200750827789, "report/reward_loss_std": 0.17525409162044525, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.023230791091919, "report/reward_neg_acc": 0.99493408203125, "report/reward_neg_loss": 0.02093842439353466, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.7381142973899841, "report/reward_pred": 0.03123783878982067, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.4608313904318493e-05, "eval/cont_loss_std": 0.00041693574166856706, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0029844518285244703, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.597014242018304e-08, "eval/cont_pred": 0.9951316714286804, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.680728912353516, "eval/dyn_loss_std": 11.418868064880371, "eval/image_loss_mean": 11.301512718200684, "eval/image_loss_std": 16.089210510253906, "eval/model_loss_mean": 22.054790496826172, "eval/model_loss_std": 20.799333572387695, "eval/post_ent_mag": 56.66762161254883, "eval/post_ent_max": 56.66762161254883, "eval/post_ent_mean": 42.02116012573242, "eval/post_ent_min": 19.196834564208984, "eval/post_ent_std": 7.799220085144043, "eval/prior_ent_mag": 71.25796508789062, "eval/prior_ent_max": 71.25796508789062, "eval/prior_ent_mean": 57.440277099609375, "eval/prior_ent_min": 44.88246154785156, "eval/prior_ent_std": 4.486748218536377, "eval/rep_loss_mean": 17.680728912353516, "eval/rep_loss_std": 11.418868064880371, "eval/reward_avg": 0.05009765550494194, "eval/reward_loss_mean": 0.14482712745666504, "eval/reward_loss_std": 0.642870306968689, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0032918453216553, "eval/reward_neg_acc": 0.9782833456993103, "eval/reward_neg_loss": 0.06903590261936188, "eval/reward_pos_acc": 0.8421052694320679, "eval/reward_pos_loss": 1.4306188821792603, "eval/reward_pred": 0.04585333168506622, "eval/reward_rate": 0.0556640625, "replay/size": 1000000.0, "replay/inserts": 21856.0, "replay/samples": 21856.0, "replay/insert_wait_avg": 1.3706450231951467e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.235127824640902e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7904.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2701279238650674e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1011.2734613418579, "timer/env.step_count": 2732.0, "timer/env.step_total": 220.9540708065033, "timer/env.step_frac": 0.21849092184553082, "timer/env.step_avg": 0.08087630703019887, "timer/env.step_min": 0.024377822875976562, "timer/env.step_max": 3.5780458450317383, "timer/replay._sample_count": 21856.0, "timer/replay._sample_total": 11.324807405471802, "timer/replay._sample_frac": 0.01119856086250392, "timer/replay._sample_avg": 0.0005181555364875459, "timer/replay._sample_min": 0.0004131793975830078, "timer/replay._sample_max": 0.010151147842407227, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3720.0, "timer/agent.policy_total": 65.54295825958252, "timer/agent.policy_frac": 0.0648122993088473, "timer/agent.policy_avg": 0.017619074800963044, "timer/agent.policy_min": 0.00973200798034668, "timer/agent.policy_max": 0.271467924118042, "timer/dataset_train_count": 1366.0, "timer/dataset_train_total": 0.15082597732543945, "timer/dataset_train_frac": 0.0001491446014269064, "timer/dataset_train_avg": 0.00011041433186342566, "timer/dataset_train_min": 9.655952453613281e-05, "timer/dataset_train_max": 0.0003380775451660156, "timer/agent.train_count": 1366.0, "timer/agent.train_total": 616.3989005088806, "timer/agent.train_frac": 0.6095274167394658, "timer/agent.train_avg": 0.45124370461850705, "timer/agent.train_min": 0.4381406307220459, "timer/agent.train_max": 1.8565902709960938, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4731895923614502, "timer/agent.report_frac": 0.0004679145754834457, "timer/agent.report_avg": 0.2365947961807251, "timer/agent.report_min": 0.23051977157592773, "timer/agent.report_max": 0.24266982078552246, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.6876724305128486e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 21.61206042937295}
{"step": 1080144, "time": 49401.66527915001, "episode/length": 295.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 1080272, "time": 49407.599427223206, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 1080504, "time": 49416.882828235626, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9691629955947136, "episode/intrinsic_return": 0.0}
{"step": 1081040, "time": 49437.4234085083, "episode/length": 284.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 1081336, "time": 49448.86871623993, "episode/length": 393.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9923857868020305, "episode/intrinsic_return": 0.0}
{"step": 1081592, "time": 49460.89328122139, "episode/length": 418.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9952267303102625, "episode/intrinsic_return": 0.0}
{"step": 1081728, "time": 49467.30470466614, "episode/length": 197.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 1081848, "time": 49472.71472144127, "episode/length": 196.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 1082064, "time": 49481.83729720116, "episode/length": 323.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9845679012345679, "episode/intrinsic_return": 0.0}
{"step": 1082120, "time": 49485.02975153923, "episode/length": 201.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 1082848, "time": 49511.93476486206, "episode/length": 188.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 1083552, "time": 49537.622242212296, "episode/length": 212.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 1083624, "time": 49541.53794789314, "episode/length": 253.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 1084016, "time": 49556.876593112946, "episode/length": 243.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 1084064, "time": 49560.17549610138, "episode/length": 377.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 1084376, "time": 49572.153759002686, "episode/length": 190.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 1084536, "time": 49579.57280802727, "episode/length": 580.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 1084552, "time": 49581.657913684845, "episode/length": 303.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 1084568, "time": 49583.76915478706, "episode/length": 354.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 1085496, "time": 49616.856442928314, "episode/length": 184.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 1085512, "time": 49618.96631169319, "episode/length": 244.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 1085832, "time": 49631.51262283325, "episode/length": 39.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 1085992, "time": 49638.71411681175, "episode/length": 61.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 1086128, "time": 49645.25196695328, "episode/length": 312.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9712460063897763, "episode/intrinsic_return": 0.0}
{"step": 1086248, "time": 49650.71592974663, "episode/length": 213.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 1086256, "time": 49652.81451463699, "episode/length": 234.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1086264, "time": 49654.411828279495, "episode/length": 213.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 1086424, "time": 49661.41104912758, "episode/length": 294.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9796610169491525, "episode/intrinsic_return": 0.0}
{"step": 1087024, "time": 49683.76021170616, "episode/length": 306.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 1087136, "time": 49689.1230404377, "episode/length": 162.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 1087368, "time": 49698.48110127449, "episode/length": 117.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9915254237288136, "episode/intrinsic_return": 0.0}
{"step": 1087560, "time": 49706.76060652733, "episode/length": 178.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9832402234636871, "episode/intrinsic_return": 0.0}
{"step": 1087840, "time": 49718.19619989395, "episode/length": 197.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 1087872, "time": 49720.862614154816, "episode/length": 200.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 1088136, "time": 49731.42106461525, "episode/length": 36.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8918918918918919, "episode/intrinsic_return": 0.0}
{"step": 1088216, "time": 49735.77586364746, "episode/length": 245.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 1088656, "time": 49752.57232046127, "episode/length": 189.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 1088800, "time": 49759.204107522964, "episode/length": 154.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 1088912, "time": 49764.64323759079, "episode/length": 364.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9945205479452055, "episode/intrinsic_return": 0.0}
{"step": 1089104, "time": 49772.74671411514, "episode/length": 216.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1089424, "time": 49785.343232154846, "episode/length": 193.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 1089480, "time": 49788.78535532951, "episode/length": 306.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 1089632, "time": 49797.53088116646, "episode/length": 176.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 1089760, "time": 49803.57704615593, "episode/length": 202.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 1090024, "time": 49835.36859536171, "eval_episode/length": 168.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 1090024, "time": 49837.39701509476, "eval_episode/length": 175.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 1090024, "time": 49840.156869888306, "eval_episode/length": 201.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 1090024, "time": 49842.68791937828, "eval_episode/length": 221.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.972972972972973}
{"step": 1090024, "time": 49850.457505464554, "eval_episode/length": 353.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9858757062146892}
{"step": 1090024, "time": 49853.464299201965, "eval_episode/length": 216.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 1090024, "time": 49856.008352041245, "eval_episode/length": 203.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 1090024, "time": 49857.89329242706, "eval_episode/length": 409.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 1090120, "time": 49861.15091204643, "episode/length": 182.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 1090152, "time": 49863.823038339615, "episode/length": 154.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 1090504, "time": 49877.399235248566, "episode/length": 47.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 1090640, "time": 49884.0037484169, "episode/length": 229.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 1091576, "time": 49917.52241897583, "episode/length": 177.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 1091640, "time": 49921.3135535717, "episode/length": 316.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9873817034700315, "episode/intrinsic_return": 0.0}
{"step": 1092232, "time": 49943.09753251076, "episode/length": 324.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9907692307692307, "episode/intrinsic_return": 0.0}
{"step": 1092376, "time": 49949.69243431091, "episode/length": 233.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 1092600, "time": 49958.973570108414, "episode/length": 45.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9130434782608695, "episode/intrinsic_return": 0.0}
{"step": 1092688, "time": 49963.786266326904, "episode/length": 400.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9975062344139651, "episode/intrinsic_return": 0.0}
{"step": 1092920, "time": 49973.031616687775, "episode/length": 436.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9794050343249427, "episode/intrinsic_return": 0.0}
{"step": 1092992, "time": 49977.32211995125, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 1093000, "time": 49978.96878695488, "episode/length": 294.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.976271186440678, "episode/intrinsic_return": 0.0}
{"step": 1093552, "time": 49999.52297496796, "episode/length": 246.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 1093992, "time": 50015.72318482399, "episode/length": 201.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 1094504, "time": 50034.891438007355, "episode/length": 63.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 1094776, "time": 50045.78297281265, "episode/length": 271.0, "episode/score": 11.1000000461936, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 1094776, "time": 50045.81070661545, "episode/length": 626.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9984051036682615, "episode/intrinsic_return": 0.0}
{"step": 1094976, "time": 50056.278404951096, "episode/length": 247.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 1095008, "time": 50059.10009789467, "episode/length": 260.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 1095088, "time": 50063.443717718124, "episode/length": 299.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.0}
{"step": 1095232, "time": 50069.82785511017, "episode/length": 278.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 1095728, "time": 50088.39545536041, "episode/length": 79.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 1096192, "time": 50105.65836644173, "episode/length": 147.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 1096328, "time": 50111.6725256443, "episode/length": 193.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 1096968, "time": 50135.04742240906, "episode/length": 426.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 1097032, "time": 50138.74311685562, "episode/length": 256.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 1097552, "time": 50158.33865427971, "episode/length": 227.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1097584, "time": 50161.046372652054, "episode/length": 293.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1097696, "time": 50166.352043390274, "episode/length": 364.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9972602739726028, "episode/intrinsic_return": 0.0}
{"step": 1097744, "time": 50171.359914302826, "episode/length": 404.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 1097896, "time": 50177.95774292946, "episode/length": 212.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 1098128, "time": 50187.54584264755, "episode/length": 224.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1098960, "time": 50217.390223026276, "episode/length": 240.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 1098960, "time": 50217.399045944214, "episode/length": 248.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 1099136, "time": 50226.723187446594, "episode/length": 179.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 1099160, "time": 50228.92686223984, "episode/length": 176.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 1099320, "time": 50235.94088125229, "episode/length": 177.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 1099392, "time": 50240.369131565094, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 1099688, "time": 50251.83028912544, "episode/length": 194.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 1100008, "time": 50288.11824822426, "eval_episode/length": 226.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 1100008, "time": 50290.246755599976, "eval_episode/length": 236.0, "eval_episode/score": 13.100000008940697, "eval_episode/reward_rate": 0.9957805907172996}
{"step": 1100008, "time": 50293.23318529129, "eval_episode/length": 266.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9962546816479401}
{"step": 1100008, "time": 50297.87502002716, "eval_episode/length": 102.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9902912621359223}
{"step": 1100008, "time": 50300.41858148575, "eval_episode/length": 347.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 1100008, "time": 50302.53224658966, "eval_episode/length": 357.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9916201117318436}
{"step": 1100008, "time": 50305.17853283882, "eval_episode/length": 381.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9764397905759162}
{"step": 1100008, "time": 50307.217915296555, "eval_episode/length": 392.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9949109414758269}
{"step": 1100584, "time": 50326.810853004456, "episode/length": 202.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 1100776, "time": 50335.03541302681, "episode/length": 402.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9776674937965261, "episode/intrinsic_return": 0.0}
{"step": 1101200, "time": 50351.412128686905, "episode/length": 254.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 1101224, "time": 50353.61466741562, "episode/length": 228.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 1102128, "time": 50386.41809344292, "episode/length": 304.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9868852459016394, "episode/intrinsic_return": 0.0}
{"step": 1102136, "time": 50388.109973192215, "episode/length": 396.0, "episode/score": 12.099999964237213, "episode/reward_rate": 0.9949622166246851, "episode/intrinsic_return": 0.0}
{"step": 1102184, "time": 50391.31559252739, "episode/length": 357.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9888268156424581, "episode/intrinsic_return": 0.0}
{"step": 1102313, "time": 50398.26971197128, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.469557069188399, "train/action_min": 0.0, "train/action_std": 3.312675143317353, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03218794701178726, "train/actor_opt_grad_steps": 68100.0, "train/actor_opt_loss": -9.137831852376031, "train/adv_mag": 0.40605581964520243, "train/adv_max": 0.3717086700012358, "train/adv_mean": 0.0019513911421533436, "train/adv_min": -0.3282542328397147, "train/adv_std": 0.04628537086059721, "train/cont_avg": 0.995693289118705, "train/cont_loss_mean": 0.00019191224129369678, "train/cont_loss_std": 0.005693310763631122, "train/cont_neg_acc": 0.9947841729191568, "train/cont_neg_loss": 0.015740296483855026, "train/cont_pos_acc": 0.9999435604047432, "train/cont_pos_loss": 0.00011344926529294476, "train/cont_pred": 0.9956733966045243, "train/cont_rate": 0.995693289118705, "train/dyn_loss_mean": 13.297925626631264, "train/dyn_loss_std": 9.380782559621249, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0557582344082619, "train/extr_critic_critic_opt_grad_steps": 68100.0, "train/extr_critic_critic_opt_loss": 15350.840778158723, "train/extr_critic_mag": 10.737931148611384, "train/extr_critic_max": 10.737931148611384, "train/extr_critic_mean": 3.3299912668818195, "train/extr_critic_min": -0.1454023028449189, "train/extr_critic_std": 2.5220446466541975, "train/extr_return_normed_mag": 1.4264997604081957, "train/extr_return_normed_max": 1.4264997604081957, "train/extr_return_normed_mean": 0.3878404994448312, "train/extr_return_normed_min": -0.08524185408362382, "train/extr_return_normed_std": 0.3160215450062169, "train/extr_return_rate": 0.8812734656196703, "train/extr_return_raw_mag": 11.72338273027818, "train/extr_return_raw_max": 11.72338273027818, "train/extr_return_raw_mean": 3.34571488812673, "train/extr_return_raw_min": -0.4697854930548359, "train/extr_return_raw_std": 2.5490451948248225, "train/extr_reward_mag": 1.047245267483828, "train/extr_reward_max": 1.047245267483828, "train/extr_reward_mean": 0.050080323122816975, "train/extr_reward_min": -0.41482600719808677, "train/extr_reward_std": 0.20752295079848748, "train/image_loss_mean": 6.497331464890953, "train/image_loss_std": 11.674338934232862, "train/model_loss_mean": 14.53552703034106, "train/model_loss_std": 15.549052389405615, "train/model_opt_grad_norm": 50.92101379778745, "train/model_opt_grad_steps": 68040.3381294964, "train/model_opt_loss": 18300.406095436152, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1258.9928057553957, "train/policy_entropy_mag": 2.584171085906543, "train/policy_entropy_max": 2.584171085906543, "train/policy_entropy_mean": 0.5718819944978618, "train/policy_entropy_min": 0.07937503343434643, "train/policy_entropy_std": 0.7326576295945284, "train/policy_logprob_mag": 7.438383815957488, "train/policy_logprob_max": -0.00945566011686548, "train/policy_logprob_mean": -0.5717730985270987, "train/policy_logprob_min": -7.438383815957488, "train/policy_logprob_std": 1.1215223507057848, "train/policy_randomness_mag": 0.9120989892122556, "train/policy_randomness_max": 0.9120989892122556, "train/policy_randomness_mean": 0.2018492475366421, "train/policy_randomness_min": 0.028015903431734594, "train/policy_randomness_std": 0.25859599179929965, "train/post_ent_mag": 60.99963551802601, "train/post_ent_max": 60.99963551802601, "train/post_ent_mean": 43.65089797973633, "train/post_ent_min": 20.53184501044184, "train/post_ent_std": 7.673156570187576, "train/prior_ent_mag": 71.1948855283449, "train/prior_ent_max": 71.1948855283449, "train/prior_ent_mean": 57.020202938601265, "train/prior_ent_min": 41.45149574005347, "train/prior_ent_std": 4.868064544183745, "train/rep_loss_mean": 13.297925626631264, "train/rep_loss_std": 9.380782559621249, "train/reward_avg": 0.03358953438109631, "train/reward_loss_mean": 0.05924836795428674, "train/reward_loss_std": 0.25406456636867936, "train/reward_max_data": 1.0294964099101882, "train/reward_max_pred": 1.0198575018121183, "train/reward_neg_acc": 0.991651410250355, "train/reward_neg_loss": 0.029409266063581695, "train/reward_pos_acc": 0.9727836761543219, "train/reward_pos_loss": 0.8278393865489274, "train/reward_pred": 0.03278168129379586, "train/reward_rate": 0.037523887140287766, "train_stats/sum_log_reward": 10.176923290713804, "train_stats/max_log_achievement_collect_coal": 0.9340659340659341, "train_stats/max_log_achievement_collect_drink": 7.197802197802198, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.3406593406593406, "train_stats/max_log_achievement_collect_stone": 14.659340659340659, "train_stats/max_log_achievement_collect_wood": 10.307692307692308, "train_stats/max_log_achievement_defeat_skeleton": 0.06593406593406594, "train_stats/max_log_achievement_defeat_zombie": 0.945054945054945, "train_stats/max_log_achievement_eat_cow": 0.26373626373626374, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.01098901098901099, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.0549450549450547, "train_stats/max_log_achievement_make_wood_sword": 1.0879120879120878, "train_stats/max_log_achievement_place_furnace": 2.197802197802198, "train_stats/max_log_achievement_place_plant": 1.3296703296703296, "train_stats/max_log_achievement_place_stone": 4.274725274725275, "train_stats/max_log_achievement_place_table": 2.6263736263736264, "train_stats/max_log_achievement_wake_up": 1.5934065934065933, "train_stats/mean_log_entropy": 0.5610651447550281, "eval_stats/sum_log_reward": 10.475000321865082, "eval_stats/max_log_achievement_collect_coal": 1.5, "eval_stats/max_log_achievement_collect_drink": 7.3125, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 23.0, "eval_stats/max_log_achievement_collect_wood": 8.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.625, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_furnace": 3.75, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 5.625, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.218528713157866e-06, "report/cont_loss_std": 6.557018059538677e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002133631642209366, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.197210728307255e-06, "report/cont_pred": 0.9951141476631165, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 10.986835479736328, "report/dyn_loss_std": 9.17186450958252, "report/image_loss_mean": 4.886684417724609, "report/image_loss_std": 11.781387329101562, "report/model_loss_mean": 11.542562484741211, "report/model_loss_std": 15.519305229187012, "report/post_ent_mag": 61.98434829711914, "report/post_ent_max": 61.98434829711914, "report/post_ent_mean": 45.323646545410156, "report/post_ent_min": 22.809066772460938, "report/post_ent_std": 7.745377063751221, "report/prior_ent_mag": 71.33207702636719, "report/prior_ent_max": 71.33207702636719, "report/prior_ent_mean": 56.730770111083984, "report/prior_ent_min": 36.78288269042969, "report/prior_ent_std": 4.949370384216309, "report/rep_loss_mean": 10.986835479736328, "report/rep_loss_std": 9.17186450958252, "report/reward_avg": 0.03828125074505806, "report/reward_loss_mean": 0.06377218663692474, "report/reward_loss_std": 0.265146404504776, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018079280853271, "report/reward_neg_acc": 0.9908256530761719, "report/reward_neg_loss": 0.031644947826862335, "report/reward_pos_acc": 0.9767441749572754, "report/reward_pos_loss": 0.7967216372489929, "report/reward_pred": 0.037285298109054565, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 6.290907776929089e-07, "eval/cont_loss_std": 6.000147550366819e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.738149775424972e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.180293101147981e-07, "eval/cont_pred": 0.9980465769767761, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 19.309934616088867, "eval/dyn_loss_std": 10.523178100585938, "eval/image_loss_mean": 10.54564380645752, "eval/image_loss_std": 13.269938468933105, "eval/model_loss_mean": 22.2510986328125, "eval/model_loss_std": 17.406068801879883, "eval/post_ent_mag": 59.74189376831055, "eval/post_ent_max": 59.74189376831055, "eval/post_ent_mean": 41.01749038696289, "eval/post_ent_min": 19.494291305541992, "eval/post_ent_std": 7.813385963439941, "eval/prior_ent_mag": 71.33207702636719, "eval/prior_ent_max": 71.33207702636719, "eval/prior_ent_mean": 58.41363525390625, "eval/prior_ent_min": 43.930503845214844, "eval/prior_ent_std": 4.187992095947266, "eval/rep_loss_mean": 19.309934616088867, "eval/rep_loss_std": 10.523178100585938, "eval/reward_avg": 0.04599609225988388, "eval/reward_loss_mean": 0.11949440836906433, "eval/reward_loss_std": 0.6052101850509644, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012269020080566, "eval/reward_neg_acc": 0.9845996499061584, "eval/reward_neg_loss": 0.04602887108922005, "eval/reward_pos_acc": 0.7999999523162842, "eval/reward_pos_loss": 1.5506030321121216, "eval/reward_pred": 0.04389303922653198, "eval/reward_rate": 0.048828125, "replay/size": 1000000.0, "replay/inserts": 22272.0, "replay/samples": 22272.0, "replay/insert_wait_avg": 1.3545926274924444e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.988178524477729e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6424.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2602708111070606e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1544027328491, "timer/env.step_count": 2784.0, "timer/env.step_total": 226.37512254714966, "timer/env.step_frac": 0.22634017500557524, "timer/env.step_avg": 0.08131290321377502, "timer/env.step_min": 0.023842334747314453, "timer/env.step_max": 3.41375732421875, "timer/replay._sample_count": 22272.0, "timer/replay._sample_total": 11.498911380767822, "timer/replay._sample_frac": 0.011497136191519913, "timer/replay._sample_avg": 0.0005162945124267161, "timer/replay._sample_min": 0.0003986358642578125, "timer/replay._sample_max": 0.010865926742553711, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3587.0, "timer/agent.policy_total": 61.77000021934509, "timer/agent.policy_frac": 0.061760464234885196, "timer/agent.policy_avg": 0.017220518600319232, "timer/agent.policy_min": 0.009635686874389648, "timer/agent.policy_max": 0.11473202705383301, "timer/dataset_train_count": 1392.0, "timer/dataset_train_total": 0.1538698673248291, "timer/dataset_train_frac": 0.00015384611306453372, "timer/dataset_train_avg": 0.0001105386977908255, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.0010194778442382812, "timer/agent.train_count": 1392.0, "timer/agent.train_total": 633.656418800354, "timer/agent.train_frac": 0.63355859562177, "timer/agent.train_avg": 0.4552129445404842, "timer/agent.train_min": 0.4418787956237793, "timer/agent.train_max": 1.8780689239501953, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4750046730041504, "timer/agent.report_frac": 0.0004749313423069825, "timer/agent.report_avg": 0.2375023365020752, "timer/agent.report_min": 0.23004984855651855, "timer/agent.report_max": 0.24495482444763184, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.1943157488797274e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 22.268217517798075}
{"step": 1102424, "time": 50401.90856218338, "episode/length": 205.0, "episode/score": 12.100000038743019, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 1102600, "time": 50409.52452993393, "episode/length": 432.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9930715935334873, "episode/intrinsic_return": 0.0}
{"step": 1102960, "time": 50423.885281562805, "episode/length": 44.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9111111111111111, "episode/intrinsic_return": 0.0}
{"step": 1102976, "time": 50426.14861154556, "episode/length": 218.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 1103072, "time": 50431.02278447151, "episode/length": 233.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 1103080, "time": 50432.71790409088, "episode/length": 111.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 1103128, "time": 50435.88535165787, "episode/length": 317.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9874213836477987, "episode/intrinsic_return": 0.0}
{"step": 1104000, "time": 50467.54867386818, "episode/length": 196.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 1104248, "time": 50477.398869752884, "episode/length": 264.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 1104528, "time": 50488.694665670395, "episode/length": 298.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765886287625418, "episode/intrinsic_return": 0.0}
{"step": 1104584, "time": 50491.962906360626, "episode/length": 202.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 1104640, "time": 50495.697729587555, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 1105048, "time": 50511.13953661919, "episode/length": 246.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 1106072, "time": 50549.60368227959, "episode/length": 367.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 1106200, "time": 50555.56267166138, "episode/length": 201.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 1106384, "time": 50563.74732875824, "episode/length": 231.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9698275862068966, "episode/intrinsic_return": 0.0}
{"step": 1106856, "time": 50581.69485449791, "episode/length": 225.0, "episode/score": 12.1000000461936, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 1107432, "time": 50602.802982091904, "episode/length": 428.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 1107624, "time": 50611.27228689194, "episode/length": 421.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9786729857819905, "episode/intrinsic_return": 0.0}
{"step": 1107760, "time": 50617.85273981094, "episode/length": 210.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1107832, "time": 50621.753628730774, "episode/length": 180.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 1108056, "time": 50630.96003770828, "episode/length": 621.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9967845659163987, "episode/intrinsic_return": 0.0}
{"step": 1108072, "time": 50633.219244241714, "episode/length": 428.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 1108696, "time": 50656.0170853138, "episode/length": 229.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 1108952, "time": 50666.50747013092, "episode/length": 343.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 1109272, "time": 50678.99857401848, "episode/length": 229.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 1109704, "time": 50695.52197051048, "episode/length": 233.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 1109784, "time": 50699.79692721367, "episode/length": 252.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 1109872, "time": 50704.79665851593, "episode/length": 224.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1109912, "time": 50707.63267445564, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 1109968, "time": 50711.408155441284, "episode/length": 158.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 1110096, "time": 50739.04555821419, "eval_episode/length": 135.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 1110096, "time": 50744.14850783348, "eval_episode/length": 210.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.995260663507109}
{"step": 1110096, "time": 50744.17510199547, "eval_episode/length": 210.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.995260663507109}
{"step": 1110096, "time": 50747.8620223999, "eval_episode/length": 211.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9716981132075472}
{"step": 1110096, "time": 50750.10062813759, "eval_episode/length": 225.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9778761061946902}
{"step": 1110096, "time": 50753.80394721031, "eval_episode/length": 59.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 1110096, "time": 50756.14586567879, "eval_episode/length": 277.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9820143884892086}
{"step": 1110096, "time": 50759.644686460495, "eval_episode/length": 317.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9842767295597484}
{"step": 1110304, "time": 50766.69408106804, "episode/length": 334.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9791044776119403, "episode/intrinsic_return": 0.0}
{"step": 1110816, "time": 50785.757940769196, "episode/length": 232.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 1111224, "time": 50800.95859980583, "episode/length": 168.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.0}
{"step": 1111232, "time": 50803.138409376144, "episode/length": 190.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 1111328, "time": 50808.09086108208, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1111528, "time": 50816.168107271194, "episode/length": 217.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1111552, "time": 50818.81906962395, "episode/length": 284.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 1112040, "time": 50836.87893486023, "episode/length": 216.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9861751152073732, "episode/intrinsic_return": 0.0}
{"step": 1112856, "time": 50866.44493341446, "episode/length": 162.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 1112960, "time": 50871.79548239708, "episode/length": 215.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 1113144, "time": 50879.33440589905, "episode/length": 403.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 1113392, "time": 50889.54074382782, "episode/length": 321.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.984472049689441, "episode/intrinsic_return": 0.0}
{"step": 1113864, "time": 50907.114725112915, "episode/length": 227.0, "episode/score": 13.100000038743019, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1113952, "time": 50912.05850672722, "episode/length": 340.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9912023460410557, "episode/intrinsic_return": 0.0}
{"step": 1114248, "time": 50925.353694438934, "episode/length": 339.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9970588235294118, "episode/intrinsic_return": 0.0}
{"step": 1114424, "time": 50933.1613111496, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 1114688, "time": 50943.863661527634, "episode/length": 215.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 1114760, "time": 50947.702000141144, "episode/length": 428.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9953379953379954, "episode/intrinsic_return": 0.0}
{"step": 1114776, "time": 50949.76281142235, "episode/length": 65.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9242424242424242, "episode/intrinsic_return": 0.0}
{"step": 1114808, "time": 50952.53412628174, "episode/length": 207.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 1115160, "time": 50966.28573155403, "episode/length": 220.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 1115656, "time": 50984.8365752697, "episode/length": 109.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9454545454545454, "episode/intrinsic_return": 0.0}
{"step": 1115760, "time": 50990.43418812752, "episode/length": 133.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1115856, "time": 50995.28996396065, "episode/length": 248.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 1116128, "time": 51006.111347436905, "episode/length": 212.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 1116216, "time": 51010.55102443695, "episode/length": 282.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9893992932862191, "episode/intrinsic_return": 0.0}
{"step": 1116440, "time": 51019.83438229561, "episode/length": 203.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 1116984, "time": 51039.89695954323, "episode/length": 227.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1117328, "time": 51053.4297041893, "episode/length": 208.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 1117328, "time": 51053.43965768814, "episode/length": 320.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 1117448, "time": 51060.74199986458, "episode/length": 198.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 1117736, "time": 51072.08101415634, "episode/length": 246.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 1117896, "time": 51079.16775679588, "episode/length": 209.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 1117984, "time": 51083.97896695137, "episode/length": 192.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 1118352, "time": 51098.582377672195, "episode/length": 170.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 1118496, "time": 51105.005927324295, "episode/length": 295.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 1119048, "time": 51125.12081360817, "episode/length": 132.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 1119144, "time": 51129.995958805084, "episode/length": 80.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9506172839506173, "episode/intrinsic_return": 0.0}
{"step": 1119552, "time": 51145.72573852539, "episode/length": 226.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 1119736, "time": 51153.3090941906, "episode/length": 285.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 1119856, "time": 51159.2003698349, "episode/length": 88.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 1119856, "time": 51159.20985007286, "episode/length": 315.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9841772151898734, "episode/intrinsic_return": 0.0}
{"step": 1120024, "time": 51168.12276959419, "episode/length": 336.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9881305637982196, "episode/intrinsic_return": 0.0}
{"step": 1120080, "time": 51190.29602217674, "eval_episode/length": 124.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.992}
{"step": 1120080, "time": 51192.94252347946, "eval_episode/length": 148.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 1120080, "time": 51196.62011098862, "eval_episode/length": 188.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 1120080, "time": 51198.40439748764, "eval_episode/length": 191.0, "eval_episode/score": 12.099999979138374, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 1120080, "time": 51201.75946521759, "eval_episode/length": 230.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 1120080, "time": 51205.186232328415, "eval_episode/length": 143.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9583333333333334}
{"step": 1120080, "time": 51207.00808882713, "eval_episode/length": 271.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9963235294117647}
{"step": 1120080, "time": 51210.32576465607, "eval_episode/length": 116.0, "eval_episode/score": 11.100000016391277, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 1120248, "time": 51215.79130792618, "episode/length": 236.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 1120672, "time": 51232.02827167511, "episode/length": 346.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9855907780979827, "episode/intrinsic_return": 0.0}
{"step": 1120736, "time": 51235.785084724426, "episode/length": 210.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1121160, "time": 51251.802894830704, "episode/length": 177.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 1121264, "time": 51257.26101708412, "episode/length": 213.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 1121664, "time": 51272.42334318161, "episode/length": 225.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 1121792, "time": 51278.38578128815, "episode/length": 220.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 1122176, "time": 51293.289903879166, "episode/length": 179.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 1122232, "time": 51296.6096739769, "episode/length": 247.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 1122376, "time": 51304.83865594864, "episode/length": 212.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 1122536, "time": 51311.91235256195, "episode/length": 171.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 1123296, "time": 51339.969779253006, "episode/length": 187.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 1123304, "time": 51341.78477334976, "episode/length": 430.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9953596287703016, "episode/intrinsic_return": 0.0}
{"step": 1123336, "time": 51344.54015350342, "episode/length": 258.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 1123560, "time": 51353.79827094078, "episode/length": 172.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.953757225433526, "episode/intrinsic_return": 0.0}
{"step": 1123736, "time": 51361.379410505295, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 1123864, "time": 51367.35521745682, "episode/length": 274.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 1124512, "time": 51391.18834686279, "episode/length": 246.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 1124576, "time": 51394.9898982048, "episode/length": 154.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9806451612903225, "episode/intrinsic_return": 0.0}
{"step": 1124617, "time": 51398.68397140503, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.531766183035714, "train/action_min": 0.0, "train/action_std": 3.357671689987183, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03209420702021037, "train/actor_opt_grad_steps": 69495.0, "train/actor_opt_loss": -7.2496245028185, "train/adv_mag": 0.40939833798578806, "train/adv_max": 0.3762618703501565, "train/adv_mean": 0.0020945541521119335, "train/adv_min": -0.32568603605031965, "train/adv_std": 0.0458770774570959, "train/cont_avg": 0.995458984375, "train/cont_loss_mean": 0.0001991533765182193, "train/cont_loss_std": 0.006127530062095892, "train/cont_neg_acc": 0.9919557831117085, "train/cont_neg_loss": 0.020150521092006914, "train/cont_pos_acc": 0.9999719768762588, "train/cont_pos_loss": 0.00011086513912224355, "train/cont_pred": 0.9954648264816829, "train/cont_rate": 0.995458984375, "train/dyn_loss_mean": 13.060536425454275, "train/dyn_loss_std": 9.41681570325579, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.046982291340828, "train/extr_critic_critic_opt_grad_steps": 69495.0, "train/extr_critic_critic_opt_loss": 15309.288337053571, "train/extr_critic_mag": 10.673223529543195, "train/extr_critic_max": 10.673223529543195, "train/extr_critic_mean": 3.223058860642569, "train/extr_critic_min": -0.15448388542447772, "train/extr_critic_std": 2.561452432189669, "train/extr_return_normed_mag": 1.4186090213911875, "train/extr_return_normed_max": 1.4186090213911875, "train/extr_return_normed_mean": 0.38032891750335696, "train/extr_return_normed_min": -0.07873881831765175, "train/extr_return_normed_std": 0.32099241114088467, "train/extr_return_rate": 0.8649051776954106, "train/extr_return_raw_mag": 11.620971236910139, "train/extr_return_raw_max": 11.620971236910139, "train/extr_return_raw_mean": 3.239982667991093, "train/extr_return_raw_min": -0.46575355529785156, "train/extr_return_raw_std": 2.5908492156437464, "train/extr_reward_mag": 1.0491712706429617, "train/extr_reward_max": 1.0491712706429617, "train/extr_reward_mean": 0.05139963077381253, "train/extr_reward_min": -0.44548399788992743, "train/extr_reward_std": 0.21139611335737366, "train/image_loss_mean": 6.639319828578404, "train/image_loss_std": 11.646317315101623, "train/model_loss_mean": 14.535996750422887, "train/model_loss_std": 15.57945931979588, "train/model_opt_grad_norm": 47.99847318104335, "train/model_opt_grad_steps": 69433.95714285714, "train/model_opt_loss": 19417.938741629463, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1330.357142857143, "train/policy_entropy_mag": 2.5956934366907394, "train/policy_entropy_max": 2.5956934366907394, "train/policy_entropy_mean": 0.597446593429361, "train/policy_entropy_min": 0.07937502834413733, "train/policy_entropy_std": 0.7563861412661416, "train/policy_logprob_mag": 7.4383838244846885, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5982902109622955, "train/policy_logprob_min": -7.4383838244846885, "train/policy_logprob_std": 1.1408968827554158, "train/policy_randomness_mag": 0.9161658755370549, "train/policy_randomness_max": 0.9161658755370549, "train/policy_randomness_mean": 0.21087243003504616, "train/policy_randomness_min": 0.028015901680503573, "train/policy_randomness_std": 0.2669711136392185, "train/post_ent_mag": 61.36688022613525, "train/post_ent_max": 61.36688022613525, "train/post_ent_mean": 43.98429489135742, "train/post_ent_min": 20.638285759517125, "train/post_ent_std": 7.726362316949027, "train/prior_ent_mag": 71.23642327444894, "train/prior_ent_max": 71.23642327444894, "train/prior_ent_mean": 57.110173034667966, "train/prior_ent_min": 41.45239794594901, "train/prior_ent_std": 4.92137645312718, "train/rep_loss_mean": 13.060536425454275, "train/rep_loss_std": 9.41681570325579, "train/reward_avg": 0.03416573650070599, "train/reward_loss_mean": 0.060156104101666386, "train/reward_loss_std": 0.25574420328651154, "train/reward_max_data": 1.0250000059604645, "train/reward_max_pred": 1.014888093301228, "train/reward_neg_acc": 0.9918393697057452, "train/reward_neg_loss": 0.030108159062053476, "train/reward_pos_acc": 0.9736785450151988, "train/reward_pos_loss": 0.8143326124974659, "train/reward_pred": 0.033351971741233555, "train/reward_rate": 0.03823939732142857, "train_stats/sum_log_reward": 10.583871246666037, "train_stats/max_log_achievement_collect_coal": 1.1397849462365592, "train_stats/max_log_achievement_collect_drink": 6.150537634408602, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.4516129032258065, "train_stats/max_log_achievement_collect_stone": 14.129032258064516, "train_stats/max_log_achievement_collect_wood": 10.397849462365592, "train_stats/max_log_achievement_defeat_skeleton": 0.03225806451612903, "train_stats/max_log_achievement_defeat_zombie": 1.032258064516129, "train_stats/max_log_achievement_eat_cow": 0.17204301075268819, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.3225806451612905, "train_stats/max_log_achievement_make_wood_sword": 1.1612903225806452, "train_stats/max_log_achievement_place_furnace": 1.924731182795699, "train_stats/max_log_achievement_place_plant": 1.4301075268817205, "train_stats/max_log_achievement_place_stone": 4.924731182795699, "train_stats/max_log_achievement_place_table": 2.870967741935484, "train_stats/max_log_achievement_wake_up": 1.5376344086021505, "train_stats/mean_log_entropy": 0.5484812163537548, "eval_stats/sum_log_reward": 10.037500232458115, "eval_stats/max_log_achievement_collect_coal": 0.8125, "eval_stats/max_log_achievement_collect_drink": 5.9375, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.3125, "eval_stats/max_log_achievement_collect_stone": 9.125, "eval_stats/max_log_achievement_collect_wood": 9.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.0625, "eval_stats/max_log_achievement_make_wood_sword": 1.25, "eval_stats/max_log_achievement_place_furnace": 1.125, "eval_stats/max_log_achievement_place_plant": 1.3125, "eval_stats/max_log_achievement_place_stone": 3.4375, "eval_stats/max_log_achievement_place_table": 2.4375, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 9.812509233597666e-06, "report/cont_loss_std": 0.0002512909413781017, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002583071473054588, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.347904440597631e-06, "report/cont_pred": 0.9941339492797852, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 12.708502769470215, "report/dyn_loss_std": 8.894951820373535, "report/image_loss_mean": 5.338586807250977, "report/image_loss_std": 9.914322853088379, "report/model_loss_mean": 13.012662887573242, "report/model_loss_std": 13.612421989440918, "report/post_ent_mag": 63.83490753173828, "report/post_ent_max": 63.83490753173828, "report/post_ent_mean": 44.36932373046875, "report/post_ent_min": 21.508174896240234, "report/post_ent_std": 7.7945380210876465, "report/prior_ent_mag": 71.17300415039062, "report/prior_ent_max": 71.17300415039062, "report/prior_ent_mean": 57.15850830078125, "report/prior_ent_min": 38.772342681884766, "report/prior_ent_std": 5.030688285827637, "report/rep_loss_mean": 12.708502769470215, "report/rep_loss_std": 8.894951820373535, "report/reward_avg": 0.02890624850988388, "report/reward_loss_mean": 0.04896450415253639, "report/reward_loss_std": 0.1772112250328064, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0058577060699463, "report/reward_neg_acc": 0.9899193048477173, "report/reward_neg_loss": 0.028270399197936058, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6904817819595337, "report/reward_pred": 0.030334312468767166, "report/reward_rate": 0.03125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.003991004079580307, "eval/cont_loss_std": 0.12670542299747467, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.007535521872341633, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.003977104090154171, "eval/cont_pred": 0.9951632022857666, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.113828659057617, "eval/dyn_loss_std": 11.080422401428223, "eval/image_loss_mean": 9.968145370483398, "eval/image_loss_std": 13.603102684020996, "eval/model_loss_mean": 20.36272430419922, "eval/model_loss_std": 18.32120704650879, "eval/post_ent_mag": 59.477874755859375, "eval/post_ent_max": 59.477874755859375, "eval/post_ent_mean": 42.01714324951172, "eval/post_ent_min": 20.756067276000977, "eval/post_ent_std": 7.702104091644287, "eval/prior_ent_mag": 71.17300415039062, "eval/prior_ent_max": 71.17300415039062, "eval/prior_ent_mean": 57.261260986328125, "eval/prior_ent_min": 44.13629150390625, "eval/prior_ent_std": 4.586745738983154, "eval/rep_loss_mean": 17.113828659057617, "eval/rep_loss_std": 11.080422401428223, "eval/reward_avg": 0.05078125, "eval/reward_loss_mean": 0.12229063361883163, "eval/reward_loss_std": 0.5785252451896667, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017950534820557, "eval/reward_neg_acc": 0.9845201969146729, "eval/reward_neg_loss": 0.05694546550512314, "eval/reward_pos_acc": 0.8909090757369995, "eval/reward_pos_loss": 1.2735538482666016, "eval/reward_pred": 0.044693589210510254, "eval/reward_rate": 0.0537109375, "replay/size": 1000000.0, "replay/inserts": 22304.0, "replay/samples": 22304.0, "replay/insert_wait_avg": 1.3510350517426195e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.134922303975569e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5016.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3543658279345936e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4036021232605, "timer/env.step_count": 2788.0, "timer/env.step_total": 231.58157324790955, "timer/env.step_frac": 0.23148814414142443, "timer/env.step_avg": 0.08306369198275092, "timer/env.step_min": 0.024218082427978516, "timer/env.step_max": 3.506507396697998, "timer/replay._sample_count": 22304.0, "timer/replay._sample_total": 11.583161115646362, "timer/replay._sample_frac": 0.011578488013300048, "timer/replay._sample_avg": 0.0005193311117129826, "timer/replay._sample_min": 0.00038242340087890625, "timer/replay._sample_max": 0.02595973014831543, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3415.0, "timer/agent.policy_total": 60.51091814041138, "timer/agent.policy_frac": 0.06048650565829908, "timer/agent.policy_avg": 0.017719156117250768, "timer/agent.policy_min": 0.009524345397949219, "timer/agent.policy_max": 0.17355585098266602, "timer/dataset_train_count": 1394.0, "timer/dataset_train_total": 0.15527653694152832, "timer/dataset_train_frac": 0.00015521389228504256, "timer/dataset_train_avg": 0.00011138919436264585, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0010330677032470703, "timer/agent.train_count": 1394.0, "timer/agent.train_total": 634.5859220027924, "timer/agent.train_frac": 0.6343299051062439, "timer/agent.train_avg": 0.4552266298441839, "timer/agent.train_min": 0.4383068084716797, "timer/agent.train_max": 1.8911468982696533, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47916746139526367, "timer/agent.report_frac": 0.0004789741464127846, "timer/agent.report_avg": 0.23958373069763184, "timer/agent.report_min": 0.23255252838134766, "timer/agent.report_max": 0.24661493301391602, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 9.274482727050781e-05, "timer/dataset_eval_frac": 9.270741036284339e-08, "timer/dataset_eval_avg": 9.274482727050781e-05, "timer/dataset_eval_min": 9.274482727050781e-05, "timer/dataset_eval_max": 9.274482727050781e-05, "fps": 22.29468970754786}
{"step": 1125288, "time": 51421.34585809708, "episode/length": 177.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9606741573033708, "episode/intrinsic_return": 0.0}
{"step": 1125704, "time": 51437.032995939255, "episode/length": 300.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9966777408637874, "episode/intrinsic_return": 0.0}
{"step": 1125784, "time": 51441.4036090374, "episode/length": 443.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 1125840, "time": 51445.04110980034, "episode/length": 316.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9968454258675079, "episode/intrinsic_return": 0.0}
{"step": 1125984, "time": 51451.56107521057, "episode/length": 302.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 1126024, "time": 51454.79700779915, "episode/length": 285.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9825174825174825, "episode/intrinsic_return": 0.0}
{"step": 1126888, "time": 51486.44562602043, "episode/length": 296.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9831649831649831, "episode/intrinsic_return": 0.0}
{"step": 1126888, "time": 51486.45390033722, "episode/length": 199.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 1127504, "time": 51510.993571043015, "episode/length": 184.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 1127544, "time": 51513.7307612896, "episode/length": 194.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 1127568, "time": 51516.33647155762, "episode/length": 232.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 1127648, "time": 51520.69090127945, "episode/length": 232.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9699570815450643, "episode/intrinsic_return": 0.0}
{"step": 1128344, "time": 51545.656883478165, "episode/length": 312.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.987220447284345, "episode/intrinsic_return": 0.0}
{"step": 1128448, "time": 51550.9515068531, "episode/length": 112.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9557522123893806, "episode/intrinsic_return": 0.0}
{"step": 1129048, "time": 51572.63389801979, "episode/length": 269.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 1129096, "time": 51575.86595106125, "episode/length": 564.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9911504424778761, "episode/intrinsic_return": 0.0}
{"step": 1129328, "time": 51585.414187431335, "episode/length": 219.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 1129488, "time": 51592.60041618347, "episode/length": 229.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 1129600, "time": 51597.90165519714, "episode/length": 143.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 1129920, "time": 51610.28335046768, "episode/length": 301.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9801324503311258, "episode/intrinsic_return": 0.0}
{"step": 1130008, "time": 51614.54623937607, "episode/length": 389.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9974358974358974, "episode/intrinsic_return": 0.0}
{"step": 1130064, "time": 51635.16909337044, "eval_episode/length": 67.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9852941176470589}
{"step": 1130064, "time": 51640.436221838, "eval_episode/length": 149.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.96}
{"step": 1130064, "time": 51644.151386499405, "eval_episode/length": 196.0, "eval_episode/score": 12.099999971687794, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 1130064, "time": 51646.44924449921, "eval_episode/length": 207.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 1130064, "time": 51648.93648171425, "eval_episode/length": 227.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 1130064, "time": 51651.83831977844, "eval_episode/length": 255.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.99609375}
{"step": 1130064, "time": 51656.23757767677, "eval_episode/length": 168.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 1130064, "time": 51660.36297607422, "eval_episode/length": 373.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9893048128342246}
{"step": 1130136, "time": 51662.56351137161, "episode/length": 223.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1130520, "time": 51679.19675254822, "episode/length": 177.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9606741573033708, "episode/intrinsic_return": 0.0}
{"step": 1130976, "time": 51696.4329354763, "episode/length": 205.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 1131032, "time": 51699.7227833271, "episode/length": 192.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 1131296, "time": 51710.548785448074, "episode/length": 160.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 1131376, "time": 51714.86515545845, "episode/length": 290.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 1131376, "time": 51714.96248745918, "episode/length": 181.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 1131952, "time": 51737.94991469383, "episode/length": 178.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 1132240, "time": 51749.32422852516, "episode/length": 262.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9657794676806084, "episode/intrinsic_return": 0.0}
{"step": 1132568, "time": 51761.80100989342, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 1132608, "time": 51765.06542134285, "episode/length": 375.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 1132664, "time": 51768.53615093231, "episode/length": 160.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 1132704, "time": 51771.73766589165, "episode/length": 175.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 1132952, "time": 51781.49333047867, "episode/length": 196.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 1133272, "time": 51793.79501795769, "episode/length": 279.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 1133672, "time": 51808.93608736992, "episode/length": 214.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 1133856, "time": 51816.910058259964, "episode/length": 112.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9911504424778761, "episode/intrinsic_return": 0.0}
{"step": 1134640, "time": 51845.15187931061, "episode/length": 258.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 1135632, "time": 51880.223494291306, "episode/length": 377.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 1136072, "time": 51896.54349708557, "episode/length": 425.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 1136176, "time": 51901.98600149155, "episode/length": 433.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1136264, "time": 51907.032676935196, "episode/length": 373.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9866310160427807, "episode/intrinsic_return": 0.0}
{"step": 1136312, "time": 51910.6205971241, "episode/length": 84.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 1136448, "time": 51917.18258166313, "episode/length": 225.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 1136928, "time": 51934.883845329285, "episode/length": 383.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 1137408, "time": 51952.65879559517, "episode/length": 645.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9876160990712074, "episode/intrinsic_return": 0.0}
{"step": 1137584, "time": 51960.288313150406, "episode/length": 488.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9897750511247444, "episode/intrinsic_return": 0.0}
{"step": 1137688, "time": 51965.308809280396, "episode/length": 201.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 1138024, "time": 51978.404722452164, "episode/length": 230.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 1138280, "time": 51988.75897741318, "episode/length": 251.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 1138752, "time": 52008.40222978592, "episode/length": 287.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 1138792, "time": 52011.25907993317, "episode/length": 150.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 1138936, "time": 52017.711196660995, "episode/length": 250.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 1139304, "time": 52031.68092226982, "episode/length": 373.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.983957219251337, "episode/intrinsic_return": 0.0}
{"step": 1139432, "time": 52037.81917357445, "episode/length": 61.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 1139512, "time": 52042.11396121979, "episode/length": 153.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 1139696, "time": 52050.11315226555, "episode/length": 117.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9915254237288136, "episode/intrinsic_return": 0.0}
{"step": 1139784, "time": 52054.431369781494, "episode/length": 219.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 1139840, "time": 52058.12364435196, "episode/length": 303.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 1140048, "time": 52088.664974689484, "eval_episode/length": 148.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 1140048, "time": 52090.485072374344, "eval_episode/length": 152.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 1140048, "time": 52092.76757764816, "eval_episode/length": 167.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 1140048, "time": 52094.46425652504, "eval_episode/length": 168.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9644970414201184}
{"step": 1140048, "time": 52099.64731502533, "eval_episode/length": 243.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9959016393442623}
{"step": 1140048, "time": 52102.0924680233, "eval_episode/length": 262.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9771863117870723}
{"step": 1140048, "time": 52106.27224826813, "eval_episode/length": 318.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9843260188087775}
{"step": 1140048, "time": 52108.84389615059, "eval_episode/length": 170.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 1140352, "time": 52119.00906896591, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 1140808, "time": 52135.75438642502, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 1140904, "time": 52140.545295000076, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 1140952, "time": 52143.88477611542, "episode/length": 407.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 1141416, "time": 52161.33527994156, "episode/length": 132.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 1141552, "time": 52167.78967189789, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 1142168, "time": 52190.60283303261, "episode/length": 308.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 1142520, "time": 52204.20619750023, "episode/length": 213.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 1142584, "time": 52207.96882009506, "episode/length": 209.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 1142584, "time": 52207.97507429123, "episode/length": 51.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 1143000, "time": 52225.512911081314, "episode/length": 180.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 1143176, "time": 52233.142050504684, "episode/length": 423.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 1143624, "time": 52249.9510538578, "episode/length": 129.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.0}
{"step": 1143728, "time": 52255.42790055275, "episode/length": 526.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9981024667931688, "episode/intrinsic_return": 0.0}
{"step": 1143944, "time": 52263.97815608978, "episode/length": 373.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9893048128342246, "episode/intrinsic_return": 0.0}
{"step": 1144048, "time": 52269.27009725571, "episode/length": 108.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 1144384, "time": 52282.31413626671, "episode/length": 224.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9688888888888889, "episode/intrinsic_return": 0.0}
{"step": 1144728, "time": 52295.44883322716, "episode/length": 215.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 1144816, "time": 52300.28956437111, "episode/length": 424.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9976470588235294, "episode/intrinsic_return": 0.0}
{"step": 1144888, "time": 52304.04648542404, "episode/length": 157.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 1144944, "time": 52307.92354440689, "episode/length": 302.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1145152, "time": 52316.690041303635, "episode/length": 177.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9831460674157303, "episode/intrinsic_return": 0.0}
{"step": 1145752, "time": 52338.48456764221, "episode/length": 212.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 1146152, "time": 52353.75095295906, "episode/length": 220.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 1146384, "time": 52363.57305312157, "episode/length": 186.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 1146448, "time": 52367.500960588455, "episode/length": 203.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 1146608, "time": 52374.4762172699, "episode/length": 207.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 1147209, "time": 52398.86939716339, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.559962062970967, "train/action_min": 0.0, "train/action_std": 3.343099179842793, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03091664622861443, "train/actor_opt_grad_steps": 70900.0, "train/actor_opt_loss": -10.03540310443293, "train/adv_mag": 0.4244082126211613, "train/adv_max": 0.3791794072017602, "train/adv_mean": 0.0016223837163202102, "train/adv_min": -0.3487163855040327, "train/adv_std": 0.04531778617108122, "train/cont_avg": 0.99529726285461, "train/cont_loss_mean": 9.302972762583093e-05, "train/cont_loss_std": 0.0027586278835644135, "train/cont_neg_acc": 0.9968025581442195, "train/cont_neg_loss": 0.009880311754445528, "train/cont_pos_acc": 0.9999721388444833, "train/cont_pos_loss": 5.263497381981811e-05, "train/cont_pred": 0.9952857156171866, "train/cont_rate": 0.99529726285461, "train/dyn_loss_mean": 13.19799258861136, "train/dyn_loss_std": 9.458182395772731, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0116484579465068, "train/extr_critic_critic_opt_grad_steps": 70900.0, "train/extr_critic_critic_opt_loss": 15142.506441156915, "train/extr_critic_mag": 10.655707839532948, "train/extr_critic_max": 10.655707839532948, "train/extr_critic_mean": 3.227610806201367, "train/extr_critic_min": -0.16036661127780347, "train/extr_critic_std": 2.617685131147398, "train/extr_return_normed_mag": 1.4253746364133577, "train/extr_return_normed_max": 1.4253746364133577, "train/extr_return_normed_mean": 0.385685125881053, "train/extr_return_normed_min": -0.07441974291247679, "train/extr_return_normed_std": 0.3271555025526818, "train/extr_return_rate": 0.8428750613057021, "train/extr_return_raw_mag": 11.635941667759672, "train/extr_return_raw_max": 11.635941667759672, "train/extr_return_raw_mean": 3.24070638967744, "train/extr_return_raw_min": -0.474569984784363, "train/extr_return_raw_std": 2.6419337100171028, "train/extr_reward_mag": 1.0467336279280641, "train/extr_reward_max": 1.0467336279280641, "train/extr_reward_mean": 0.050305516201447936, "train/extr_reward_min": -0.438915619613431, "train/extr_reward_std": 0.20866547577770045, "train/image_loss_mean": 6.546892277737881, "train/image_loss_std": 12.193469487183483, "train/model_loss_mean": 14.525828929657632, "train/model_loss_std": 16.102008406997573, "train/model_opt_grad_norm": 50.813026779932336, "train/model_opt_grad_steps": 70837.60283687944, "train/model_opt_loss": 19148.91189466977, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1320.9219858156027, "train/policy_entropy_mag": 2.6090334882127477, "train/policy_entropy_max": 2.6090334882127477, "train/policy_entropy_mean": 0.6044899168166709, "train/policy_entropy_min": 0.07937502137101288, "train/policy_entropy_std": 0.7787158184863151, "train/policy_logprob_mag": 7.438383917436532, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6044373459427069, "train/policy_logprob_min": -7.438383917436532, "train/policy_logprob_std": 1.1450085360953148, "train/policy_randomness_mag": 0.9208743280552804, "train/policy_randomness_max": 0.9208743280552804, "train/policy_randomness_mean": 0.2133584146169906, "train/policy_randomness_min": 0.028015899174708002, "train/policy_randomness_std": 0.274852509934006, "train/post_ent_mag": 61.279225450880986, "train/post_ent_max": 61.279225450880986, "train/post_ent_mean": 43.74586319077945, "train/post_ent_min": 20.460338714274954, "train/post_ent_std": 7.715744512300965, "train/prior_ent_mag": 71.27979873765445, "train/prior_ent_max": 71.27979873765445, "train/prior_ent_mean": 56.98227353468009, "train/prior_ent_min": 41.13380648565631, "train/prior_ent_std": 4.8787980688379164, "train/rep_loss_mean": 13.19799258861136, "train/rep_loss_std": 9.458182395772731, "train/reward_avg": 0.03525806180736486, "train/reward_loss_mean": 0.060048061799495775, "train/reward_loss_std": 0.24775813963819057, "train/reward_max_data": 1.0234042608991583, "train/reward_max_pred": 1.0178843271647784, "train/reward_neg_acc": 0.992265745257655, "train/reward_neg_loss": 0.02955219501642682, "train/reward_pos_acc": 0.9762798070062136, "train/reward_pos_loss": 0.8061575437268467, "train/reward_pred": 0.0343940905064133, "train/reward_rate": 0.039401872783687945, "train_stats/sum_log_reward": 10.398850753389556, "train_stats/max_log_achievement_collect_coal": 1.0114942528735633, "train_stats/max_log_achievement_collect_drink": 7.563218390804598, "train_stats/max_log_achievement_collect_iron": 0.04597701149425287, "train_stats/max_log_achievement_collect_sapling": 1.5632183908045978, "train_stats/max_log_achievement_collect_stone": 15.229885057471265, "train_stats/max_log_achievement_collect_wood": 10.206896551724139, "train_stats/max_log_achievement_defeat_skeleton": 0.09195402298850575, "train_stats/max_log_achievement_defeat_zombie": 0.9770114942528736, "train_stats/max_log_achievement_eat_cow": 0.1724137931034483, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.022988505747126436, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.0919540229885056, "train_stats/max_log_achievement_make_wood_sword": 1.0229885057471264, "train_stats/max_log_achievement_place_furnace": 2.4367816091954024, "train_stats/max_log_achievement_place_plant": 1.4827586206896552, "train_stats/max_log_achievement_place_stone": 4.057471264367816, "train_stats/max_log_achievement_place_table": 2.5632183908045976, "train_stats/max_log_achievement_wake_up": 1.7701149425287357, "train_stats/mean_log_entropy": 0.5668482787307652, "eval_stats/sum_log_reward": 10.225000321865082, "eval_stats/max_log_achievement_collect_coal": 1.6875, "eval_stats/max_log_achievement_collect_drink": 5.3125, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 14.9375, "eval_stats/max_log_achievement_collect_wood": 7.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.8125, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_furnace": 2.5, "eval_stats/max_log_achievement_place_plant": 1.4375, "eval_stats/max_log_achievement_place_stone": 3.625, "eval_stats/max_log_achievement_place_table": 1.75, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 2.850838711765391e-07, "report/cont_loss_std": 1.959230985448812e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.283407179173082e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.0181775539640512e-07, "report/cont_pred": 0.998046875, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 11.466193199157715, "report/dyn_loss_std": 8.981453895568848, "report/image_loss_mean": 5.785224437713623, "report/image_loss_std": 16.941299438476562, "report/model_loss_mean": 12.714890480041504, "report/model_loss_std": 19.96697235107422, "report/post_ent_mag": 62.88941955566406, "report/post_ent_max": 62.88941955566406, "report/post_ent_mean": 44.669334411621094, "report/post_ent_min": 21.31298828125, "report/post_ent_std": 7.6708598136901855, "report/prior_ent_mag": 71.12759399414062, "report/prior_ent_max": 71.12759399414062, "report/prior_ent_mean": 56.3104248046875, "report/prior_ent_min": 38.717987060546875, "report/prior_ent_std": 5.031551361083984, "report/rep_loss_mean": 11.466193199157715, "report/rep_loss_std": 8.981453895568848, "report/reward_avg": 0.03896484524011612, "report/reward_loss_mean": 0.049950011074543, "report/reward_loss_std": 0.19922402501106262, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.1212174892425537, "report/reward_neg_acc": 0.9938837289810181, "report/reward_neg_loss": 0.018738506361842155, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7620078921318054, "report/reward_pred": 0.03643478453159332, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.3275174498849083e-06, "eval/cont_loss_std": 2.3630986106581986e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.000123735168017447, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.8514087969379034e-06, "eval/cont_pred": 0.9960924386978149, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.891799926757812, "eval/dyn_loss_std": 11.120671272277832, "eval/image_loss_mean": 11.47437858581543, "eval/image_loss_std": 15.492096900939941, "eval/model_loss_mean": 21.734214782714844, "eval/model_loss_std": 20.1453914642334, "eval/post_ent_mag": 60.72392654418945, "eval/post_ent_max": 60.72392654418945, "eval/post_ent_mean": 42.183868408203125, "eval/post_ent_min": 20.510971069335938, "eval/post_ent_std": 7.683650493621826, "eval/prior_ent_mag": 71.12759399414062, "eval/prior_ent_max": 71.12759399414062, "eval/prior_ent_mean": 57.40943145751953, "eval/prior_ent_min": 42.372222900390625, "eval/prior_ent_std": 5.291994571685791, "eval/rep_loss_mean": 16.891799926757812, "eval/rep_loss_std": 11.120671272277832, "eval/reward_avg": 0.0439453125, "eval/reward_loss_mean": 0.12475428730249405, "eval/reward_loss_std": 0.5509074330329895, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.067955732345581, "eval/reward_neg_acc": 0.9743589162826538, "eval/reward_neg_loss": 0.06037649139761925, "eval/reward_pos_acc": 0.8775510191917419, "eval/reward_pos_loss": 1.4057409763336182, "eval/reward_pred": 0.04252282530069351, "eval/reward_rate": 0.0478515625, "replay/size": 1000000.0, "replay/inserts": 22592.0, "replay/samples": 22592.0, "replay/insert_wait_avg": 1.3689122693059128e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.113112395613456e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5712.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2756145300985384e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1607961654663, "timer/env.step_count": 2824.0, "timer/env.step_total": 224.2333493232727, "timer/env.step_frac": 0.22419729925724424, "timer/env.step_avg": 0.0794027440946433, "timer/env.step_min": 0.02471327781677246, "timer/env.step_max": 3.4775497913360596, "timer/replay._sample_count": 22592.0, "timer/replay._sample_total": 11.678977489471436, "timer/replay._sample_frac": 0.011677099856590729, "timer/replay._sample_avg": 0.0005169519072889269, "timer/replay._sample_min": 0.00043320655822753906, "timer/replay._sample_max": 0.014717817306518555, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3538.0, "timer/agent.policy_total": 62.45259141921997, "timer/agent.policy_frac": 0.06244255089647388, "timer/agent.policy_avg": 0.01765194782906161, "timer/agent.policy_min": 0.009437322616577148, "timer/agent.policy_max": 0.15643596649169922, "timer/dataset_train_count": 1412.0, "timer/dataset_train_total": 0.1559739112854004, "timer/dataset_train_frac": 0.0001559488353106735, "timer/dataset_train_avg": 0.00011046310997549602, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0010547637939453125, "timer/agent.train_count": 1412.0, "timer/agent.train_total": 637.3732233047485, "timer/agent.train_frac": 0.6372707526113648, "timer/agent.train_avg": 0.4513974669297086, "timer/agent.train_min": 0.43454837799072266, "timer/agent.train_max": 1.9212055206298828, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47666072845458984, "timer/agent.report_frac": 0.00047658409555950167, "timer/agent.report_avg": 0.23833036422729492, "timer/agent.report_min": 0.2316601276397705, "timer/agent.report_max": 0.24500060081481934, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.1466192798262465e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 22.588056962569645}
{"step": 1147496, "time": 52408.63549995422, "episode/length": 443.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 1147944, "time": 52425.565017938614, "episode/length": 401.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 1148648, "time": 52451.110292196274, "episode/length": 143.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 1148832, "time": 52459.22995567322, "episode/length": 384.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9922077922077922, "episode/intrinsic_return": 0.0}
{"step": 1148880, "time": 52462.49220371246, "episode/length": 340.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9970674486803519, "episode/intrinsic_return": 0.0}
{"step": 1148968, "time": 52466.96237182617, "episode/length": 322.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9876160990712074, "episode/intrinsic_return": 0.0}
{"step": 1149536, "time": 52488.322566986084, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 1149640, "time": 52493.51526546478, "episode/length": 560.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9910873440285205, "episode/intrinsic_return": 0.0}
{"step": 1150000, "time": 52507.4697906971, "episode/length": 423.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787735849056604, "episode/intrinsic_return": 0.0}
{"step": 1150032, "time": 52532.601075172424, "eval_episode/length": 190.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 1150032, "time": 52534.8177087307, "eval_episode/length": 202.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 1150032, "time": 52536.719467163086, "eval_episode/length": 208.0, "eval_episode/score": 10.100000016391277, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 1150032, "time": 52539.30587005615, "eval_episode/length": 231.0, "eval_episode/score": 13.099999994039536, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 1150032, "time": 52542.08373761177, "eval_episode/length": 258.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 1150032, "time": 52545.291900634766, "eval_episode/length": 292.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9726962457337884}
{"step": 1150032, "time": 52547.46784377098, "eval_episode/length": 299.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.98}
{"step": 1150032, "time": 52549.37121629715, "eval_episode/length": 101.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9901960784313726}
{"step": 1150288, "time": 52558.092282533646, "episode/length": 164.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 1150448, "time": 52565.02676534653, "episode/length": 224.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1150592, "time": 52571.678143024445, "episode/length": 517.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9980694980694981, "episode/intrinsic_return": 0.0}
{"step": 1150600, "time": 52573.37276816368, "episode/length": 220.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 1150976, "time": 52587.97253203392, "episode/length": 261.0, "episode/score": 12.099999964237213, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 1151256, "time": 52599.000621795654, "episode/length": 201.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 1151632, "time": 52613.84477376938, "episode/length": 167.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 1152128, "time": 52632.36469459534, "episode/length": 265.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 1152160, "time": 52635.03884100914, "episode/length": 327.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1152480, "time": 52647.69839286804, "episode/length": 105.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 1152512, "time": 52650.45203948021, "episode/length": 257.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9728682170542635, "episode/intrinsic_return": 0.0}
{"step": 1152864, "time": 52664.10488462448, "episode/length": 235.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1153176, "time": 52676.333517074585, "episode/length": 239.0, "episode/score": 13.099999994039536, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 1153264, "time": 52681.22072291374, "episode/length": 97.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 1153384, "time": 52686.65628242493, "episode/length": 348.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.994269340974212, "episode/intrinsic_return": 0.0}
{"step": 1153808, "time": 52703.059061050415, "episode/length": 205.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 1154224, "time": 52718.80366063118, "episode/length": 51.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 1154568, "time": 52732.15903997421, "episode/length": 256.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 1154632, "time": 52735.96359062195, "episode/length": 220.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 1154664, "time": 52738.70479631424, "episode/length": 185.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 1154712, "time": 52742.01903963089, "episode/length": 322.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9845201238390093, "episode/intrinsic_return": 0.0}
{"step": 1155296, "time": 52765.639233112335, "episode/length": 238.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 1155720, "time": 52781.38561296463, "episode/length": 306.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.990228013029316, "episode/intrinsic_return": 0.0}
{"step": 1156304, "time": 52803.16035819054, "episode/length": 259.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 1156528, "time": 52812.32879638672, "episode/length": 232.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 1156648, "time": 52817.958354473114, "episode/length": 241.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9710743801652892, "episode/intrinsic_return": 0.0}
{"step": 1156944, "time": 52829.88790798187, "episode/length": 288.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 1157216, "time": 52840.75092816353, "episode/length": 186.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 1157288, "time": 52844.57137846947, "episode/length": 248.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 1157456, "time": 52852.215331315994, "episode/length": 856.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9906651108518086, "episode/intrinsic_return": 0.0}
{"step": 1158232, "time": 52879.82039260864, "episode/length": 457.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9890829694323144, "episode/intrinsic_return": 0.0}
{"step": 1158344, "time": 52885.21803641319, "episode/length": 211.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 1158408, "time": 52889.01277589798, "episode/length": 234.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1158576, "time": 52896.460169792175, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 1158728, "time": 52903.04115176201, "episode/length": 158.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 1158888, "time": 52910.00099658966, "episode/length": 322.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9907120743034056, "episode/intrinsic_return": 0.0}
{"step": 1159064, "time": 52917.56643772125, "episode/length": 221.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 1159424, "time": 52931.51568722725, "episode/length": 148.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 1159688, "time": 52941.91842460632, "episode/length": 159.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 1159728, "time": 52945.17430329323, "episode/length": 313.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9808917197452229, "episode/intrinsic_return": 0.0}
{"step": 1160016, "time": 52980.75046348572, "eval_episode/length": 216.0, "eval_episode/score": 13.100000008940697, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 1160016, "time": 52982.48755192757, "eval_episode/length": 219.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 1160016, "time": 52984.14383935928, "eval_episode/length": 221.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9819819819819819}
{"step": 1160016, "time": 52987.019747018814, "eval_episode/length": 247.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9959677419354839}
{"step": 1160016, "time": 52991.5679166317, "eval_episode/length": 315.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 1160016, "time": 52993.77927660942, "eval_episode/length": 326.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9877675840978594}
{"step": 1160016, "time": 52996.364809036255, "eval_episode/length": 344.0, "eval_episode/score": 12.099999994039536, "eval_episode/reward_rate": 0.9971014492753624}
{"step": 1160016, "time": 53000.32702422142, "eval_episode/length": 175.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 1160136, "time": 53004.22190976143, "episode/length": 223.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1160680, "time": 53024.230828762054, "episode/length": 201.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 1160720, "time": 53027.51103067398, "episode/length": 228.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 1160832, "time": 53032.78846049309, "episode/length": 262.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 1161080, "time": 53042.5584628582, "episode/length": 312.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.987220447284345, "episode/intrinsic_return": 0.0}
{"step": 1161112, "time": 53045.42046165466, "episode/length": 210.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1161416, "time": 53057.35746526718, "episode/length": 210.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1161664, "time": 53067.527405023575, "episode/length": 117.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9915254237288136, "episode/intrinsic_return": 0.0}
{"step": 1161784, "time": 53073.04800105095, "episode/length": 205.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 1162424, "time": 53096.39157938957, "episode/length": 198.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 1162456, "time": 53099.00788283348, "episode/length": 345.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9826589595375722, "episode/intrinsic_return": 0.0}
{"step": 1162488, "time": 53101.612679481506, "episode/length": 225.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 1162608, "time": 53107.52168369293, "episode/length": 190.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 1162624, "time": 53109.77469468117, "episode/length": 104.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 1162880, "time": 53120.111379384995, "episode/length": 220.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 1163624, "time": 53148.56932616234, "episode/length": 244.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 1163712, "time": 53153.639875650406, "episode/length": 152.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 1163928, "time": 53162.2774848938, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 1164240, "time": 53174.671005010605, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1164488, "time": 53184.58311057091, "episode/length": 383.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9973958333333334, "episode/intrinsic_return": 0.0}
{"step": 1164496, "time": 53186.59630703926, "episode/length": 254.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 1164640, "time": 53193.08285474777, "episode/length": 253.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9724409448818898, "episode/intrinsic_return": 0.0}
{"step": 1165640, "time": 53228.37126135826, "episode/length": 213.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 1165928, "time": 53239.79795408249, "episode/length": 287.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9826388888888888, "episode/intrinsic_return": 0.0}
{"step": 1165960, "time": 53242.44530081749, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 1166272, "time": 53254.766370773315, "episode/length": 319.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.990625, "episode/intrinsic_return": 0.0}
{"step": 1166544, "time": 53265.37879228592, "episode/length": 237.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 1166592, "time": 53268.95627570152, "episode/length": 495.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 1167032, "time": 53285.068769454956, "episode/length": 348.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9885386819484241, "episode/intrinsic_return": 0.0}
{"step": 1167168, "time": 53291.48382019997, "episode/length": 190.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 1167376, "time": 53300.19660902023, "episode/length": 176.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 1167584, "time": 53308.824023485184, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 1168264, "time": 53333.23774981499, "episode/length": 208.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 1168320, "time": 53337.05175471306, "episode/length": 221.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 1168384, "time": 53340.903569459915, "episode/length": 485.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 1168896, "time": 53359.90551733971, "episode/length": 215.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 1168984, "time": 53364.195603609085, "episode/length": 200.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 1169008, "time": 53366.82093977928, "episode/length": 177.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 1169897, "time": 53399.09752416611, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.548865519778829, "train/action_min": 0.0, "train/action_std": 3.3004280211220327, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.030864587316000964, "train/actor_opt_grad_steps": 72315.0, "train/actor_opt_loss": -6.780406975305416, "train/adv_mag": 0.41467992069435794, "train/adv_max": 0.36847555291065026, "train/adv_mean": 0.002045267613859426, "train/adv_min": -0.3493152910345037, "train/adv_std": 0.045120016920944334, "train/cont_avg": 0.9952478543133803, "train/cont_loss_mean": 0.00020903151784283706, "train/cont_loss_std": 0.006530582379749011, "train/cont_neg_acc": 0.992730496622992, "train/cont_neg_loss": 0.018993179323281748, "train/cont_pos_acc": 0.9999654427380629, "train/cont_pos_loss": 0.00012511316194321144, "train/cont_pred": 0.9952369714286965, "train/cont_rate": 0.9952478543133803, "train/dyn_loss_mean": 13.090227550184222, "train/dyn_loss_std": 9.438491646672638, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0287183334290142, "train/extr_critic_critic_opt_grad_steps": 72315.0, "train/extr_critic_critic_opt_loss": 15318.145473426497, "train/extr_critic_mag": 10.676686125741877, "train/extr_critic_max": 10.676686125741877, "train/extr_critic_mean": 3.109060960756221, "train/extr_critic_min": -0.17118133373663458, "train/extr_critic_std": 2.604005065602316, "train/extr_return_normed_mag": 1.4402838063911654, "train/extr_return_normed_max": 1.4402838063911654, "train/extr_return_normed_mean": 0.3768025170749342, "train/extr_return_normed_min": -0.07284185059473548, "train/extr_return_normed_std": 0.32741183829559406, "train/extr_return_rate": 0.8293491849597071, "train/extr_return_raw_mag": 11.672961913364034, "train/extr_return_raw_max": 11.672961913364034, "train/extr_return_raw_mean": 3.1254896210952543, "train/extr_return_raw_min": -0.4884021211887749, "train/extr_return_raw_std": 2.631720229773454, "train/extr_reward_mag": 1.0430096740454016, "train/extr_reward_max": 1.0430096740454016, "train/extr_reward_mean": 0.05037137241640561, "train/extr_reward_min": -0.446106687398024, "train/extr_reward_std": 0.20918697055796504, "train/image_loss_mean": 6.691990177396318, "train/image_loss_std": 12.227810329114886, "train/model_loss_mean": 14.607033057951591, "train/model_loss_std": 16.090500072694162, "train/model_opt_grad_norm": 48.384290319093516, "train/model_opt_grad_steps": 72251.31690140846, "train/model_opt_loss": 18399.637853488115, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1258.8028169014085, "train/policy_entropy_mag": 2.6068949850512224, "train/policy_entropy_max": 2.6068949850512224, "train/policy_entropy_mean": 0.579217285547458, "train/policy_entropy_min": 0.07937502645900552, "train/policy_entropy_std": 0.7440927486184618, "train/policy_logprob_mag": 7.438383800882689, "train/policy_logprob_max": -0.009455659229990462, "train/policy_logprob_mean": -0.5793532177176274, "train/policy_logprob_min": -7.438383800882689, "train/policy_logprob_std": 1.12836154875621, "train/policy_randomness_mag": 0.9201195261008303, "train/policy_randomness_max": 0.9201195261008303, "train/policy_randomness_mean": 0.20443828435431063, "train/policy_randomness_min": 0.028015901019770494, "train/policy_randomness_std": 0.26263208215085554, "train/post_ent_mag": 61.28850431845222, "train/post_ent_max": 61.28850431845222, "train/post_ent_mean": 43.90552356881155, "train/post_ent_min": 20.519454123268666, "train/post_ent_std": 7.742914683382276, "train/prior_ent_mag": 71.28408507226219, "train/prior_ent_max": 71.28408507226219, "train/prior_ent_mean": 57.04621833478901, "train/prior_ent_min": 41.238528023303395, "train/prior_ent_std": 4.939743263620726, "train/rep_loss_mean": 13.090227550184222, "train/rep_loss_std": 9.438491646672638, "train/reward_avg": 0.035628713221407274, "train/reward_loss_mean": 0.060697360908691315, "train/reward_loss_std": 0.24618564661539777, "train/reward_max_data": 1.0267605697604971, "train/reward_max_pred": 1.017770358374421, "train/reward_neg_acc": 0.9922977925186426, "train/reward_neg_loss": 0.03062534262754128, "train/reward_pos_acc": 0.9801711032927876, "train/reward_pos_loss": 0.786368662622613, "train/reward_pred": 0.034933680838997096, "train/reward_rate": 0.03974334286971831, "train_stats/sum_log_reward": 10.78965546618933, "train_stats/max_log_achievement_collect_coal": 1.0, "train_stats/max_log_achievement_collect_drink": 6.620689655172414, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.9310344827586208, "train_stats/max_log_achievement_collect_stone": 14.793103448275861, "train_stats/max_log_achievement_collect_wood": 11.183908045977011, "train_stats/max_log_achievement_defeat_skeleton": 0.06896551724137931, "train_stats/max_log_achievement_defeat_zombie": 1.2183908045977012, "train_stats/max_log_achievement_eat_cow": 0.28735632183908044, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.011494252873563218, "train_stats/max_log_achievement_make_stone_sword": 0.022988505747126436, "train_stats/max_log_achievement_make_wood_pickaxe": 2.4597701149425286, "train_stats/max_log_achievement_make_wood_sword": 0.9885057471264368, "train_stats/max_log_achievement_place_furnace": 2.1149425287356323, "train_stats/max_log_achievement_place_plant": 1.7816091954022988, "train_stats/max_log_achievement_place_stone": 4.655172413793103, "train_stats/max_log_achievement_place_table": 2.9655172413793105, "train_stats/max_log_achievement_wake_up": 1.4252873563218391, "train_stats/mean_log_entropy": 0.551638977623534, "eval_stats/sum_log_reward": 10.975000232458115, "eval_stats/max_log_achievement_collect_coal": 1.125, "eval_stats/max_log_achievement_collect_drink": 5.9375, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.6875, "eval_stats/max_log_achievement_collect_stone": 13.6875, "eval_stats/max_log_achievement_collect_wood": 10.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.5, "eval_stats/max_log_achievement_eat_cow": 0.4375, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.625, "eval_stats/max_log_achievement_make_wood_sword": 0.9375, "eval_stats/max_log_achievement_place_furnace": 2.0625, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 3.8125, "eval_stats/max_log_achievement_place_table": 2.125, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00037228321889415383, "report/cont_loss_std": 0.011754822917282581, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00011735004227375612, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00037353410152718425, "report/cont_pred": 0.9948073625564575, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.120207786560059, "report/dyn_loss_std": 9.658476829528809, "report/image_loss_mean": 6.6241607666015625, "report/image_loss_std": 13.273920059204102, "report/model_loss_mean": 13.952035903930664, "report/model_loss_std": 17.40671730041504, "report/post_ent_mag": 60.90232849121094, "report/post_ent_max": 60.90232849121094, "report/post_ent_mean": 44.784339904785156, "report/post_ent_min": 21.681201934814453, "report/post_ent_std": 7.894813537597656, "report/prior_ent_mag": 71.08464050292969, "report/prior_ent_max": 71.08464050292969, "report/prior_ent_mean": 57.19026184082031, "report/prior_ent_min": 34.406036376953125, "report/prior_ent_std": 5.169752597808838, "report/rep_loss_mean": 12.120207786560059, "report/rep_loss_std": 9.658476829528809, "report/reward_avg": 0.0302734375, "report/reward_loss_mean": 0.05537910759449005, "report/reward_loss_std": 0.2264140397310257, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0012071132659912, "report/reward_neg_acc": 0.9828281998634338, "report/reward_neg_loss": 0.02834485098719597, "report/reward_pos_acc": 0.9411764740943909, "report/reward_pos_loss": 0.8425528407096863, "report/reward_pred": 0.02843061462044716, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 5.466114089358598e-05, "eval/cont_loss_std": 0.0012249605497345328, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.010429294779896736, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.4177401428460144e-05, "eval/cont_pred": 0.9970766305923462, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.5997314453125, "eval/dyn_loss_std": 10.409808158874512, "eval/image_loss_mean": 14.022253036499023, "eval/image_loss_std": 19.102746963500977, "eval/model_loss_mean": 25.87935447692871, "eval/model_loss_std": 23.184085845947266, "eval/post_ent_mag": 60.99266815185547, "eval/post_ent_max": 60.99266815185547, "eval/post_ent_mean": 41.12761688232422, "eval/post_ent_min": 21.74356460571289, "eval/post_ent_std": 7.7376227378845215, "eval/prior_ent_mag": 71.08464050292969, "eval/prior_ent_max": 71.08464050292969, "eval/prior_ent_mean": 58.63878631591797, "eval/prior_ent_min": 43.51518249511719, "eval/prior_ent_std": 4.414994716644287, "eval/rep_loss_mean": 19.5997314453125, "eval/rep_loss_std": 10.409808158874512, "eval/reward_avg": 0.04433593526482582, "eval/reward_loss_mean": 0.09720689058303833, "eval/reward_loss_std": 0.4901607632637024, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0366318225860596, "eval/reward_neg_acc": 0.9856410026550293, "eval/reward_neg_loss": 0.042586978524923325, "eval/reward_pos_acc": 0.918367326259613, "eval/reward_pos_loss": 1.18403160572052, "eval/reward_pred": 0.0427548922598362, "eval/reward_rate": 0.0478515625, "replay/size": 1000000.0, "replay/inserts": 22688.0, "replay/samples": 22688.0, "replay/insert_wait_avg": 1.350856466252982e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.066698425411337e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5608.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3013113922467415e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2193582057953, "timer/env.step_count": 2836.0, "timer/env.step_total": 222.605571269989, "timer/env.step_frac": 0.22255675162026597, "timer/env.step_avg": 0.07849279663962941, "timer/env.step_min": 0.024286508560180664, "timer/env.step_max": 1.9944660663604736, "timer/replay._sample_count": 22688.0, "timer/replay._sample_total": 11.819511890411377, "timer/replay._sample_frac": 0.01181691975209653, "timer/replay._sample_avg": 0.0005209587398806143, "timer/replay._sample_min": 0.00043463706970214844, "timer/replay._sample_max": 0.02581310272216797, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3537.0, "timer/agent.policy_total": 61.180055141448975, "timer/agent.policy_frac": 0.06116663773754034, "timer/agent.policy_avg": 0.017297160062609267, "timer/agent.policy_min": 0.009709358215332031, "timer/agent.policy_max": 0.09526348114013672, "timer/dataset_train_count": 1418.0, "timer/dataset_train_total": 0.1584916114807129, "timer/dataset_train_frac": 0.00015845685266981528, "timer/dataset_train_avg": 0.0001117712351768074, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0010607242584228516, "timer/agent.train_count": 1418.0, "timer/agent.train_total": 639.7828543186188, "timer/agent.train_frac": 0.6396425434779311, "timer/agent.train_avg": 0.45118678019648717, "timer/agent.train_min": 0.4379734992980957, "timer/agent.train_max": 1.979480504989624, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4712510108947754, "timer/agent.report_frac": 0.00047114766078924, "timer/agent.report_avg": 0.2356255054473877, "timer/agent.report_min": 0.22943544387817383, "timer/agent.report_max": 0.24181556701660156, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.7412123522446766e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 22.682698965884725}
{"step": 1170000, "time": 53417.704287052155, "eval_episode/length": 43.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 1170000, "time": 53426.65982723236, "eval_episode/length": 161.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 1170000, "time": 53429.081110715866, "eval_episode/length": 180.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 1170000, "time": 53430.8193089962, "eval_episode/length": 185.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.989247311827957}
{"step": 1170000, "time": 53440.20828127861, "eval_episode/length": 314.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9873015873015873}
{"step": 1170000, "time": 53442.5961997509, "eval_episode/length": 213.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9719626168224299}
{"step": 1170000, "time": 53445.047744989395, "eval_episode/length": 393.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9771573604060914}
{"step": 1170000, "time": 53446.96962714195, "eval_episode/length": 212.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 1170024, "time": 53447.556356430054, "episode/length": 373.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9893048128342246, "episode/intrinsic_return": 0.0}
{"step": 1170072, "time": 53450.78419470787, "episode/length": 210.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 1170288, "time": 53460.41781210899, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 1170576, "time": 53471.71579790115, "episode/length": 288.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 1170688, "time": 53477.20470905304, "episode/length": 209.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1170704, "time": 53479.39175224304, "episode/length": 214.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 1171024, "time": 53491.72675228119, "episode/length": 593.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9915824915824916, "episode/intrinsic_return": 0.0}
{"step": 1171392, "time": 53505.58172082901, "episode/length": 383.0, "episode/score": 12.099999964237213, "episode/reward_rate": 0.9973958333333334, "episode/intrinsic_return": 0.0}
{"step": 1171752, "time": 53521.14796614647, "episode/length": 215.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 1172264, "time": 53540.02562236786, "episode/length": 273.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 1172608, "time": 53553.55124092102, "episode/length": 239.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 1172728, "time": 53558.96032834053, "episode/length": 166.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 1172888, "time": 53566.16862440109, "episode/length": 324.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9876923076923076, "episode/intrinsic_return": 0.0}
{"step": 1172912, "time": 53568.76423406601, "episode/length": 291.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 1173432, "time": 53587.62046456337, "episode/length": 67.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 1173904, "time": 53605.487394571304, "episode/length": 268.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 1174024, "time": 53610.91350579262, "episode/length": 219.0, "episode/score": 13.099999979138374, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 1174256, "time": 53620.53245615959, "episode/length": 443.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9977477477477478, "episode/intrinsic_return": 0.0}
{"step": 1174288, "time": 53623.2266061306, "episode/length": 32.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8484848484848485, "episode/intrinsic_return": 0.0}
{"step": 1174456, "time": 53630.28692340851, "episode/length": 192.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 1174560, "time": 53635.65449428558, "episode/length": 228.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 1175464, "time": 53667.68521308899, "episode/length": 194.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 1175592, "time": 53673.53794550896, "episode/length": 162.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 1175960, "time": 53687.58661675453, "episode/length": 174.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 1175968, "time": 53689.71833181381, "episode/length": 213.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 1175984, "time": 53691.828352212906, "episode/length": 190.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 1176104, "time": 53697.1840941906, "episode/length": 436.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9908466819221968, "episode/intrinsic_return": 0.0}
{"step": 1176128, "time": 53699.81397938728, "episode/length": 637.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9905956112852664, "episode/intrinsic_return": 0.0}
{"step": 1176192, "time": 53703.548419713974, "episode/length": 344.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 1176976, "time": 53731.76300287247, "episode/length": 125.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 1177248, "time": 53742.58544611931, "episode/length": 222.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 1177368, "time": 53748.10698413849, "episode/length": 157.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 1177432, "time": 53751.94896864891, "episode/length": 180.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 1177480, "time": 53755.12379312515, "episode/length": 235.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1177544, "time": 53758.94273471832, "episode/length": 197.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 1178072, "time": 53778.604748249054, "episode/length": 234.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 1178624, "time": 53799.12135577202, "episode/length": 134.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 1178832, "time": 53807.982513189316, "episode/length": 168.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 1178832, "time": 53807.99639940262, "episode/length": 197.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 1178992, "time": 53816.84884262085, "episode/length": 357.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9916201117318436, "episode/intrinsic_return": 0.0}
{"step": 1179096, "time": 53821.679079294205, "episode/length": 215.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 1179144, "time": 53824.90148663521, "episode/length": 213.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9626168224299065, "episode/intrinsic_return": 0.0}
{"step": 1179656, "time": 53844.152901887894, "episode/length": 197.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 1180088, "time": 53877.425837278366, "eval_episode/length": 41.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8809523809523809}
{"step": 1180088, "time": 53884.034168958664, "eval_episode/length": 156.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 1180088, "time": 53887.01779508591, "eval_episode/length": 187.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 1180088, "time": 53889.78690457344, "eval_episode/length": 210.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.995260663507109}
{"step": 1180088, "time": 53892.00291085243, "eval_episode/length": 226.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.973568281938326}
{"step": 1180088, "time": 53893.69535779953, "eval_episode/length": 186.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9786096256684492}
{"step": 1180088, "time": 53895.4425804615, "eval_episode/length": 232.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 1180088, "time": 53899.320730924606, "eval_episode/length": 278.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9713261648745519}
{"step": 1180592, "time": 53916.68206906319, "episode/length": 199.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 1180824, "time": 53925.78561878204, "episode/length": 248.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 1180920, "time": 53930.90315032005, "episode/length": 286.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9965156794425087, "episode/intrinsic_return": 0.0}
{"step": 1181248, "time": 53943.78075289726, "episode/length": 301.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9768211920529801, "episode/intrinsic_return": 0.0}
{"step": 1181448, "time": 53951.94171524048, "episode/length": 77.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 1181504, "time": 53955.618685245514, "episode/length": 72.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 1181544, "time": 53958.52494239807, "episode/length": 235.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1181720, "time": 53965.94968628883, "episode/length": 592.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9966273187183811, "episode/intrinsic_return": 0.0}
{"step": 1181752, "time": 53968.63910865784, "episode/length": 325.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9969325153374233, "episode/intrinsic_return": 0.0}
{"step": 1182840, "time": 54006.92250370979, "episode/length": 135.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9558823529411765, "episode/intrinsic_return": 0.0}
{"step": 1183184, "time": 54020.35650587082, "episode/length": 209.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 1183264, "time": 54024.650651693344, "episode/length": 192.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 1183280, "time": 54026.82027196884, "episode/length": 522.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9923518164435946, "episode/intrinsic_return": 0.0}
{"step": 1183808, "time": 54046.38758468628, "episode/length": 319.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.978125, "episode/intrinsic_return": 0.0}
{"step": 1183888, "time": 54050.6950571537, "episode/length": 292.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9692832764505119, "episode/intrinsic_return": 0.0}
{"step": 1184624, "time": 54077.2879588604, "episode/length": 179.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 1184672, "time": 54080.576241731644, "episode/length": 228.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 1185056, "time": 54095.21458411217, "episode/length": 155.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 1185336, "time": 54106.1350338459, "episode/length": 82.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 1185392, "time": 54109.985649585724, "episode/length": 265.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 1185976, "time": 54130.98394918442, "episode/length": 336.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9851632047477745, "episode/intrinsic_return": 0.0}
{"step": 1186088, "time": 54136.47136282921, "episode/length": 579.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 1186088, "time": 54136.48453497887, "episode/length": 686.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9985443959243085, "episode/intrinsic_return": 0.0}
{"step": 1186672, "time": 54159.613248348236, "episode/length": 255.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 1187136, "time": 54176.96452116966, "episode/length": 217.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1187208, "time": 54180.83999705315, "episode/length": 414.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9903614457831326, "episode/intrinsic_return": 0.0}
{"step": 1187232, "time": 54183.53978252411, "episode/length": 271.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 1188056, "time": 54215.05120229721, "episode/length": 245.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 1188232, "time": 54222.634940862656, "episode/length": 361.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 1188312, "time": 54227.110003232956, "episode/length": 291.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.976027397260274, "episode/intrinsic_return": 0.0}
{"step": 1188464, "time": 54234.03606438637, "episode/length": 296.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 1188912, "time": 54250.8111512661, "episode/length": 221.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 1188928, "time": 54252.8612446785, "episode/length": 281.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 1189064, "time": 54259.01318740845, "episode/length": 231.0, "episode/score": 12.100000038743019, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 1189120, "time": 54262.72165441513, "episode/length": 235.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 1189696, "time": 54283.63486123085, "episode/length": 182.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 1190072, "time": 54318.179329156876, "eval_episode/length": 155.0, "eval_episode/score": 8.100000016391277, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 1190072, "time": 54318.18627977371, "eval_episode/length": 155.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 1190072, "time": 54323.45538830757, "eval_episode/length": 196.0, "eval_episode/score": 13.099999964237213, "eval_episode/reward_rate": 0.9695431472081218}
{"step": 1190072, "time": 54325.29586601257, "eval_episode/length": 201.0, "eval_episode/score": 11.100000031292439, "eval_episode/reward_rate": 0.995049504950495}
{"step": 1190072, "time": 54330.43960905075, "eval_episode/length": 281.0, "eval_episode/score": 13.100000008940697, "eval_episode/reward_rate": 0.9964539007092199}
{"step": 1190072, "time": 54332.8789627552, "eval_episode/length": 301.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9801324503311258}
{"step": 1190072, "time": 54334.761322021484, "eval_episode/length": 306.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9739413680781759}
{"step": 1190072, "time": 54338.57572007179, "eval_episode/length": 198.0, "eval_episode/score": 13.099999994039536, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 1190240, "time": 54344.41527414322, "episode/length": 221.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 1190528, "time": 54355.84054803848, "episode/length": 276.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 1190848, "time": 54368.17834568024, "episode/length": 215.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 1190856, "time": 54369.907212495804, "episode/length": 349.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9971428571428571, "episode/intrinsic_return": 0.0}
{"step": 1191248, "time": 54385.07667565346, "episode/length": 291.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 1191464, "time": 54393.64060974121, "episode/length": 316.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9905362776025236, "episode/intrinsic_return": 0.0}
{"step": 1191561, "time": 54399.55156707764, "eval_stats/sum_log_reward": 10.266666933894157, "eval_stats/max_log_achievement_collect_coal": 1.0, "eval_stats/max_log_achievement_collect_drink": 5.875, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.4583333333333333, "eval_stats/max_log_achievement_collect_stone": 14.375, "eval_stats/max_log_achievement_collect_wood": 9.916666666666666, "eval_stats/max_log_achievement_defeat_skeleton": 0.20833333333333334, "eval_stats/max_log_achievement_defeat_zombie": 1.0833333333333333, "eval_stats/max_log_achievement_eat_cow": 0.20833333333333334, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5833333333333333, "eval_stats/max_log_achievement_make_wood_sword": 0.9583333333333334, "eval_stats/max_log_achievement_place_furnace": 2.125, "eval_stats/max_log_achievement_place_plant": 1.3333333333333333, "eval_stats/max_log_achievement_place_stone": 4.791666666666667, "eval_stats/max_log_achievement_place_table": 2.3333333333333335, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "train_stats/sum_log_reward": 10.523529613719267, "train_stats/max_log_achievement_collect_coal": 0.8, "train_stats/max_log_achievement_collect_drink": 7.705882352941177, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.8470588235294119, "train_stats/max_log_achievement_collect_stone": 13.870588235294118, "train_stats/max_log_achievement_collect_wood": 10.176470588235293, "train_stats/max_log_achievement_defeat_skeleton": 0.10588235294117647, "train_stats/max_log_achievement_defeat_zombie": 1.223529411764706, "train_stats/max_log_achievement_eat_cow": 0.3058823529411765, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7411764705882353, "train_stats/max_log_achievement_make_wood_sword": 0.9529411764705882, "train_stats/max_log_achievement_place_furnace": 2.0, "train_stats/max_log_achievement_place_plant": 1.6941176470588235, "train_stats/max_log_achievement_place_stone": 4.470588235294118, "train_stats/max_log_achievement_place_table": 2.6588235294117646, "train_stats/max_log_achievement_wake_up": 1.8705882352941177, "train_stats/mean_log_entropy": 0.5991965907461503, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.530119267216435, "train/action_min": 0.0, "train/action_std": 3.3004371837333397, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.030683848868917535, "train/actor_opt_grad_steps": 73700.0, "train/actor_opt_loss": -6.445071740227717, "train/adv_mag": 0.43304284766868306, "train/adv_max": 0.38304471219027486, "train/adv_mean": 0.0018833059662601618, "train/adv_min": -0.36353015038702224, "train/adv_std": 0.04474133156515934, "train/cont_avg": 0.995826099537037, "train/cont_loss_mean": 0.00015429202616048686, "train/cont_loss_std": 0.004310778838579507, "train/cont_neg_acc": 0.9925220467426159, "train/cont_neg_loss": 0.024255449486466844, "train/cont_pos_acc": 0.9999781529108683, "train/cont_pos_loss": 5.4514020255556645e-05, "train/cont_pred": 0.9958357312061169, "train/cont_rate": 0.995826099537037, "train/dyn_loss_mean": 13.12876858887849, "train/dyn_loss_std": 9.365046642444751, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0616005610536645, "train/extr_critic_critic_opt_grad_steps": 73700.0, "train/extr_critic_critic_opt_loss": 15279.084664351853, "train/extr_critic_mag": 10.672332198531539, "train/extr_critic_max": 10.672332198531539, "train/extr_critic_mean": 3.0599683187626026, "train/extr_critic_min": -0.15294672736415157, "train/extr_critic_std": 2.564306379247595, "train/extr_return_normed_mag": 1.432745478771351, "train/extr_return_normed_max": 1.432745478771351, "train/extr_return_normed_mean": 0.3655487964550654, "train/extr_return_normed_min": -0.0766235036706483, "train/extr_return_normed_std": 0.32137546406851875, "train/extr_return_rate": 0.8401008367538452, "train/extr_return_raw_mag": 11.665510714495623, "train/extr_return_raw_max": 11.665510714495623, "train/extr_return_raw_mean": 3.075141852873343, "train/extr_return_raw_min": -0.48367389694408136, "train/extr_return_raw_std": 2.587222127561216, "train/extr_reward_mag": 1.0545021569287336, "train/extr_reward_max": 1.0545021569287336, "train/extr_reward_mean": 0.04990109025880143, "train/extr_reward_min": -0.44708958820060446, "train/extr_reward_std": 0.20788682401180267, "train/image_loss_mean": 6.574188695130525, "train/image_loss_std": 11.79905525136877, "train/model_loss_mean": 14.512959105880173, "train/model_loss_std": 15.641383058053476, "train/model_opt_grad_norm": 50.53630518030237, "train/model_opt_grad_steps": 73635.12592592592, "train/model_opt_loss": 21334.158955439816, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1462.962962962963, "train/policy_entropy_mag": 2.614693018242165, "train/policy_entropy_max": 2.614693018242165, "train/policy_entropy_mean": 0.620281434500659, "train/policy_entropy_min": 0.07937503385323065, "train/policy_entropy_std": 0.7692327260971069, "train/policy_logprob_mag": 7.438383830035174, "train/policy_logprob_max": -0.009455661068635959, "train/policy_logprob_mean": -0.6201599858425282, "train/policy_logprob_min": -7.438383830035174, "train/policy_logprob_std": 1.150353319115109, "train/policy_randomness_mag": 0.9228718929820591, "train/policy_randomness_max": 0.9228718929820591, "train/policy_randomness_mean": 0.2189321262968911, "train/policy_randomness_min": 0.028015903590453996, "train/policy_randomness_std": 0.2715053931430534, "train/post_ent_mag": 61.139408620198566, "train/post_ent_max": 61.139408620198566, "train/post_ent_mean": 43.843844208893955, "train/post_ent_min": 20.394948055126047, "train/post_ent_std": 7.697424411773682, "train/prior_ent_mag": 71.25232549596716, "train/prior_ent_max": 71.25232549596716, "train/prior_ent_mean": 57.03803538569698, "train/prior_ent_min": 41.51972825792101, "train/prior_ent_std": 4.850781991746691, "train/rep_loss_mean": 13.12876858887849, "train/rep_loss_std": 9.365046642444751, "train/reward_avg": 0.035664785722339595, "train/reward_loss_mean": 0.06135496486116339, "train/reward_loss_std": 0.25768380220289583, "train/reward_max_data": 1.0296296366938837, "train/reward_max_pred": 1.0205487569173177, "train/reward_neg_acc": 0.9916558353989212, "train/reward_neg_loss": 0.030537171109958933, "train/reward_pos_acc": 0.9771408783064948, "train/reward_pos_loss": 0.8109162145190769, "train/reward_pred": 0.034863348836424175, "train/reward_rate": 0.03951099537037037, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.8532678041083273e-06, "report/cont_loss_std": 2.2288109903456643e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000288896553684026, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 7.276076985363034e-07, "report/cont_pred": 0.9960942268371582, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.079919815063477, "report/dyn_loss_std": 10.215018272399902, "report/image_loss_mean": 6.667366027832031, "report/image_loss_std": 9.994787216186523, "report/model_loss_mean": 13.968063354492188, "report/model_loss_std": 14.402527809143066, "report/post_ent_mag": 63.81977081298828, "report/post_ent_max": 63.81977081298828, "report/post_ent_mean": 45.74489974975586, "report/post_ent_min": 17.79184913635254, "report/post_ent_std": 8.22913932800293, "report/prior_ent_mag": 71.38804626464844, "report/prior_ent_max": 71.38804626464844, "report/prior_ent_mean": 57.64802932739258, "report/prior_ent_min": 40.31512451171875, "report/prior_ent_std": 5.195274829864502, "report/rep_loss_mean": 12.079919815063477, "report/rep_loss_std": 10.215018272399902, "report/reward_avg": 0.03457031026482582, "report/reward_loss_mean": 0.052743829786777496, "report/reward_loss_std": 0.19669035077095032, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018212795257568, "report/reward_neg_acc": 0.9949238896369934, "report/reward_neg_loss": 0.0275320615619421, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6895025968551636, "report/reward_pred": 0.03516741096973419, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 5.411669008026365e-06, "eval/cont_loss_std": 8.943058492150158e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00016220596444327384, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.2584000513888896e-06, "eval/cont_pred": 0.9990184307098389, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 16.064952850341797, "eval/dyn_loss_std": 11.060111045837402, "eval/image_loss_mean": 11.030719757080078, "eval/image_loss_std": 16.13130760192871, "eval/model_loss_mean": 20.737407684326172, "eval/model_loss_std": 20.34421157836914, "eval/post_ent_mag": 62.11589050292969, "eval/post_ent_max": 62.11589050292969, "eval/post_ent_mean": 43.69318771362305, "eval/post_ent_min": 22.497053146362305, "eval/post_ent_std": 8.101226806640625, "eval/prior_ent_mag": 71.38804626464844, "eval/prior_ent_max": 71.38804626464844, "eval/prior_ent_mean": 58.05841827392578, "eval/prior_ent_min": 46.30235290527344, "eval/prior_ent_std": 4.328148365020752, "eval/rep_loss_mean": 16.064952850341797, "eval/rep_loss_std": 11.060111045837402, "eval/reward_avg": 0.03242187574505806, "eval/reward_loss_mean": 0.06770951300859451, "eval/reward_loss_std": 0.38933318853378296, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0108211040496826, "eval/reward_neg_acc": 0.988877534866333, "eval/reward_neg_loss": 0.031680796295404434, "eval/reward_pos_acc": 0.9428571462631226, "eval/reward_pos_loss": 1.085777997970581, "eval/reward_pred": 0.03182997927069664, "eval/reward_rate": 0.0341796875, "replay/size": 1000000.0, "replay/inserts": 21664.0, "replay/samples": 21664.0, "replay/insert_wait_avg": 1.3526710660982343e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.106936027943823e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 8264.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2609296246627408e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.087784767150879e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4463186264038, "timer/env.step_count": 2708.0, "timer/env.step_total": 216.21377539634705, "timer/env.step_frac": 0.2161173182117407, "timer/env.step_avg": 0.07984260539008384, "timer/env.step_min": 0.0246121883392334, "timer/env.step_max": 3.483461856842041, "timer/replay._sample_count": 21664.0, "timer/replay._sample_total": 11.216274976730347, "timer/replay._sample_frac": 0.01121127117757813, "timer/replay._sample_avg": 0.0005177379512892516, "timer/replay._sample_min": 0.0004265308380126953, "timer/replay._sample_max": 0.0187835693359375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3741.0, "timer/agent.policy_total": 65.54407215118408, "timer/agent.policy_frac": 0.06551483166150784, "timer/agent.policy_avg": 0.017520468364390293, "timer/agent.policy_min": 0.009739875793457031, "timer/agent.policy_max": 0.1308448314666748, "timer/dataset_train_count": 1354.0, "timer/dataset_train_total": 0.14767003059387207, "timer/dataset_train_frac": 0.0001476041521114502, "timer/dataset_train_avg": 0.00010906206099990552, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.0005373954772949219, "timer/agent.train_count": 1354.0, "timer/agent.train_total": 610.0446331501007, "timer/agent.train_frac": 0.6097724803342591, "timer/agent.train_avg": 0.450549950627844, "timer/agent.train_min": 0.43626904487609863, "timer/agent.train_max": 1.9645452499389648, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4799361228942871, "timer/agent.report_frac": 0.00047972201402393227, "timer/agent.report_avg": 0.23996806144714355, "timer/agent.report_min": 0.23212695121765137, "timer/agent.report_max": 0.24780917167663574, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.88357781264044e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 21.654029310703915}
{"step": 1191624, "time": 54401.524344205856, "episode/length": 172.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 1191744, "time": 54407.53284621239, "episode/length": 334.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9970149253731343, "episode/intrinsic_return": 0.0}
{"step": 1192168, "time": 54423.27383303642, "episode/length": 163.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 1192496, "time": 54436.26783299446, "episode/length": 93.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 1192624, "time": 54442.1530251503, "episode/length": 365.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9863387978142076, "episode/intrinsic_return": 0.0}
{"step": 1192680, "time": 54445.405542612076, "episode/length": 228.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 1192896, "time": 54454.424548625946, "episode/length": 49.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 1193304, "time": 54469.77383351326, "episode/length": 256.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 1193520, "time": 54478.859666109085, "episode/length": 373.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9866310160427807, "episode/intrinsic_return": 0.0}
{"step": 1193536, "time": 54481.06385564804, "episode/length": 238.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 1194088, "time": 54501.24114203453, "episode/length": 327.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9817073170731707, "episode/intrinsic_return": 0.0}
{"step": 1194120, "time": 54503.90893769264, "episode/length": 243.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 1194448, "time": 54516.795263528824, "episode/length": 220.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 1194840, "time": 54531.54423856735, "episode/length": 191.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 1195056, "time": 54540.701212882996, "episode/length": 303.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 1195088, "time": 54543.5211956501, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 1195488, "time": 54558.87550544739, "episode/length": 80.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 1195488, "time": 54558.88486337662, "episode/length": 323.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 1195696, "time": 54569.43671965599, "episode/length": 25.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1196000, "time": 54581.39273619652, "episode/length": 234.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 1196008, "time": 54583.01936149597, "episode/length": 64.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1196536, "time": 54604.52516055107, "episode/length": 376.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9973474801061007, "episode/intrinsic_return": 0.0}
{"step": 1196568, "time": 54607.198389053345, "episode/length": 188.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 1196720, "time": 54614.171686172485, "episode/length": 203.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 1196848, "time": 54620.15189242363, "episode/length": 299.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 1196896, "time": 54623.38191437721, "episode/length": 350.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9886039886039886, "episode/intrinsic_return": 0.0}
{"step": 1197424, "time": 54642.822860240936, "episode/length": 177.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 1197624, "time": 54650.961133003235, "episode/length": 201.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 1198080, "time": 54668.23433470726, "episode/length": 192.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 1198272, "time": 54676.43521666527, "episode/length": 321.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.984472049689441, "episode/intrinsic_return": 0.0}
{"step": 1198368, "time": 54681.185723781586, "episode/length": 205.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 1198936, "time": 54701.644391059875, "episode/length": 254.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 1199048, "time": 54707.85475254059, "episode/length": 309.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 1199536, "time": 54726.00585889816, "episode/length": 181.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 1199720, "time": 54733.59241485596, "episode/length": 358.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9944289693593314, "episode/intrinsic_return": 0.0}
{"step": 1200056, "time": 54762.564755916595, "eval_episode/length": 56.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 1200056, "time": 54772.70147442818, "eval_episode/length": 192.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9689119170984456}
{"step": 1200056, "time": 54774.409873485565, "eval_episode/length": 195.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 1200056, "time": 54776.90084218979, "eval_episode/length": 213.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 1200056, "time": 54780.236540317535, "eval_episode/length": 192.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 1200056, "time": 54782.200781822205, "eval_episode/length": 254.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.996078431372549}
{"step": 1200056, "time": 54785.25181269646, "eval_episode/length": 286.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9825783972125436}
{"step": 1200056, "time": 54789.427948236465, "eval_episode/length": 347.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.985632183908046}
{"step": 1200280, "time": 54797.08330321312, "episode/length": 250.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 1200536, "time": 54807.40540909767, "episode/length": 199.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 1201040, "time": 54826.46945118904, "episode/length": 333.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9970059880239521, "episode/intrinsic_return": 0.0}
{"step": 1201280, "time": 54836.19999504089, "episode/length": 456.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9978118161925602, "episode/intrinsic_return": 0.0}
{"step": 1201352, "time": 54839.978439092636, "episode/length": 287.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 1201440, "time": 54844.835498809814, "episode/length": 144.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 1201872, "time": 54861.063895225525, "episode/length": 268.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 1202216, "time": 54873.999333143234, "episode/length": 598.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.996661101836394, "episode/intrinsic_return": 0.0}
{"step": 1202296, "time": 54878.262567043304, "episode/length": 219.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 1202688, "time": 54893.431223869324, "episode/length": 166.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 1202824, "time": 54899.39064979553, "episode/length": 222.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 1202976, "time": 54906.19553732872, "episode/length": 429.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9976744186046511, "episode/intrinsic_return": 0.0}
{"step": 1203224, "time": 54915.96914148331, "episode/length": 222.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 1203912, "time": 54940.9517993927, "episode/length": 254.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 1203952, "time": 54944.191286087036, "episode/length": 206.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 1204584, "time": 54968.798144340515, "episode/length": 236.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 1204776, "time": 54977.04380607605, "episode/length": 319.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 1204784, "time": 54979.12915968895, "episode/length": 244.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 1205768, "time": 55013.70757102966, "episode/length": 317.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9874213836477987, "episode/intrinsic_return": 0.0}
{"step": 1205864, "time": 55018.567724466324, "episode/length": 243.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 1205992, "time": 55024.43141245842, "episode/length": 254.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9725490196078431, "episode/intrinsic_return": 0.0}
{"step": 1206040, "time": 55027.56554889679, "episode/length": 181.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 1206128, "time": 55032.321904182434, "episode/length": 167.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 1206384, "time": 55042.61737251282, "episode/length": 200.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 1206400, "time": 55044.84262728691, "episode/length": 427.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 1207024, "time": 55067.47479224205, "episode/length": 144.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 1207152, "time": 55073.384026527405, "episode/length": 144.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 1207976, "time": 55102.76469397545, "episode/length": 230.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 1208096, "time": 55108.85098075867, "episode/length": 211.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 1208240, "time": 55115.33105754852, "episode/length": 231.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 1208456, "time": 55123.965774059296, "episode/length": 301.0, "episode/score": 13.1000000461936, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 1208768, "time": 55136.48370075226, "episode/length": 217.0, "episode/score": 12.1000000461936, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1208944, "time": 55144.159462213516, "episode/length": 223.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1209416, "time": 55161.71614766121, "episode/length": 455.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 1209752, "time": 55174.623663425446, "episode/length": 206.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 1210040, "time": 55206.537351846695, "eval_episode/length": 164.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9575757575757575}
{"step": 1210040, "time": 55209.37734413147, "eval_episode/length": 191.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 1210040, "time": 55211.06855106354, "eval_episode/length": 192.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9689119170984456}
{"step": 1210040, "time": 55213.144147872925, "eval_episode/length": 201.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.995049504950495}
{"step": 1210040, "time": 55216.369507312775, "eval_episode/length": 233.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9786324786324786}
{"step": 1210040, "time": 55220.28649973869, "eval_episode/length": 288.0, "eval_episode/score": 12.099999979138374, "eval_episode/reward_rate": 0.9965397923875432}
{"step": 1210040, "time": 55222.76274609566, "eval_episode/length": 308.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9870550161812298}
{"step": 1210040, "time": 55227.47251033783, "eval_episode/length": 183.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 1210056, "time": 55228.04563474655, "episode/length": 1096.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9990884229717412, "episode/intrinsic_return": 0.0}
{"step": 1210064, "time": 55230.073113679886, "episode/length": 260.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 1210520, "time": 55246.88074922562, "episode/length": 56.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 1210800, "time": 55258.18601465225, "episode/length": 172.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 1210832, "time": 55260.74408745766, "episode/length": 257.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 1211080, "time": 55270.431500434875, "episode/length": 266.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 1211128, "time": 55273.68111824989, "episode/length": 171.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 1211656, "time": 55293.11159992218, "episode/length": 426.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953161592505855, "episode/intrinsic_return": 0.0}
{"step": 1211760, "time": 55298.48671889305, "episode/length": 212.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9624413145539906, "episode/intrinsic_return": 0.0}
{"step": 1212016, "time": 55308.904994249344, "episode/length": 444.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 1212304, "time": 55320.3037917614, "episode/length": 222.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 1212448, "time": 55328.52261328697, "episode/length": 205.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 1212864, "time": 55344.39870548248, "episode/length": 253.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 1213048, "time": 55352.08873772621, "episode/length": 160.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 1213872, "time": 55381.891795158386, "episode/length": 195.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 1213928, "time": 55385.11999440193, "episode/length": 349.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 1214281, "time": 55399.797924518585, "train_stats/sum_log_reward": 10.960465323093326, "train_stats/max_log_achievement_collect_coal": 1.255813953488372, "train_stats/max_log_achievement_collect_drink": 7.244186046511628, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.6627906976744187, "train_stats/max_log_achievement_collect_stone": 16.569767441860463, "train_stats/max_log_achievement_collect_wood": 10.104651162790697, "train_stats/max_log_achievement_defeat_skeleton": 0.09302325581395349, "train_stats/max_log_achievement_defeat_zombie": 1.0813953488372092, "train_stats/max_log_achievement_eat_cow": 0.313953488372093, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.9651162790697674, "train_stats/max_log_achievement_make_wood_sword": 1.1395348837209303, "train_stats/max_log_achievement_place_furnace": 2.36046511627907, "train_stats/max_log_achievement_place_plant": 1.4767441860465116, "train_stats/max_log_achievement_place_stone": 4.558139534883721, "train_stats/max_log_achievement_place_table": 2.604651162790698, "train_stats/max_log_achievement_wake_up": 1.755813953488372, "train_stats/mean_log_entropy": 0.5588949111311935, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.586934264277069, "train/action_min": 0.0, "train/action_std": 3.3740194179642367, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.031030848687908178, "train/actor_opt_grad_steps": 75085.0, "train/actor_opt_loss": -8.777149480203507, "train/adv_mag": 0.4181018822209936, "train/adv_max": 0.3675894560948224, "train/adv_mean": 0.0019482400242542982, "train/adv_min": -0.35246476321153236, "train/adv_std": 0.045221766824243774, "train/cont_avg": 0.9956879951584507, "train/cont_loss_mean": 9.850251263833663e-05, "train/cont_loss_std": 0.0028148762717289406, "train/cont_neg_acc": 0.9974178407393711, "train/cont_neg_loss": 0.011049103287936766, "train/cont_pos_acc": 0.9999723476423344, "train/cont_pos_loss": 4.747903239632478e-05, "train/cont_pred": 0.9956812690681135, "train/cont_rate": 0.9956879951584507, "train/dyn_loss_mean": 13.179527047654274, "train/dyn_loss_std": 9.427732111702502, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0581068316815605, "train/extr_critic_critic_opt_grad_steps": 75085.0, "train/extr_critic_critic_opt_loss": 15111.232848261443, "train/extr_critic_mag": 10.672530086947159, "train/extr_critic_max": 10.672530086947159, "train/extr_critic_mean": 3.141271058942231, "train/extr_critic_min": -0.15828860141861606, "train/extr_critic_std": 2.548680385233651, "train/extr_return_normed_mag": 1.441919723027189, "train/extr_return_normed_max": 1.441919723027189, "train/extr_return_normed_mean": 0.37879615287545704, "train/extr_return_normed_min": -0.07825203654421888, "train/extr_return_normed_std": 0.3214093164449007, "train/extr_return_rate": 0.8553871869201392, "train/extr_return_raw_mag": 11.676907284159055, "train/extr_return_raw_max": 11.676907284159055, "train/extr_return_raw_mean": 3.1568589915691967, "train/extr_return_raw_min": -0.5064093639523211, "train/extr_return_raw_std": 2.5759577658814443, "train/extr_reward_mag": 1.0464455174728178, "train/extr_reward_max": 1.0464455174728178, "train/extr_reward_mean": 0.04948652573716893, "train/extr_reward_min": -0.472344008130087, "train/extr_reward_std": 0.207443747407114, "train/image_loss_mean": 6.612675562710829, "train/image_loss_std": 11.8360118127205, "train/model_loss_mean": 14.580463812384806, "train/model_loss_std": 15.660101279406481, "train/model_opt_grad_norm": 53.68373094478124, "train/model_opt_grad_steps": 75018.64788732394, "train/model_opt_loss": 18346.669474856953, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1258.8028169014085, "train/policy_entropy_mag": 2.590131892284877, "train/policy_entropy_max": 2.590131892284877, "train/policy_entropy_mean": 0.6053423356841987, "train/policy_entropy_min": 0.07937502855776062, "train/policy_entropy_std": 0.7530753881158964, "train/policy_logprob_mag": 7.438383851252811, "train/policy_logprob_max": -0.009455658397047033, "train/policy_logprob_mean": -0.6059807434048451, "train/policy_logprob_min": -7.438383851252811, "train/policy_logprob_std": 1.1421965289283806, "train/policy_randomness_mag": 0.9142028920247521, "train/policy_randomness_max": 0.9142028920247521, "train/policy_randomness_mean": 0.2136592845052061, "train/policy_randomness_min": 0.02801590172810034, "train/policy_randomness_std": 0.2658025605577818, "train/post_ent_mag": 61.31076861099458, "train/post_ent_max": 61.31076861099458, "train/post_ent_mean": 43.75976444298113, "train/post_ent_min": 20.717157780284612, "train/post_ent_std": 7.756806329942085, "train/prior_ent_mag": 71.21261913675657, "train/prior_ent_max": 71.21261913675657, "train/prior_ent_mean": 56.999679431109364, "train/prior_ent_min": 41.629580430581534, "train/prior_ent_std": 4.880538970651761, "train/rep_loss_mean": 13.179527047654274, "train/rep_loss_std": 9.427732111702502, "train/reward_avg": 0.03614519112809023, "train/reward_loss_mean": 0.05997352278463437, "train/reward_loss_std": 0.24828567418833852, "train/reward_max_data": 1.0239436676804448, "train/reward_max_pred": 1.0175429036919499, "train/reward_neg_acc": 0.9917990674435253, "train/reward_neg_loss": 0.02896819435532244, "train/reward_pos_acc": 0.9779435979648375, "train/reward_pos_loss": 0.8064118783238908, "train/reward_pred": 0.03555768215372949, "train/reward_rate": 0.04002530809859155, "eval_stats/sum_log_reward": 10.162500232458115, "eval_stats/max_log_achievement_collect_coal": 0.6875, "eval_stats/max_log_achievement_collect_drink": 5.9375, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 12.6875, "eval_stats/max_log_achievement_collect_wood": 9.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.1875, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.8125, "eval_stats/max_log_achievement_make_wood_sword": 0.8125, "eval_stats/max_log_achievement_place_furnace": 2.0, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 2.4375, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 2.6447676759744354e-07, "report/cont_loss_std": 1.0677825912353e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.12970426218817e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.2331715854306822e-07, "report/cont_pred": 0.9980467557907104, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 14.277804374694824, "report/dyn_loss_std": 9.399690628051758, "report/image_loss_mean": 5.615200042724609, "report/image_loss_std": 8.719996452331543, "report/model_loss_mean": 14.234212875366211, "report/model_loss_std": 12.806981086730957, "report/post_ent_mag": 60.39911651611328, "report/post_ent_max": 60.39911651611328, "report/post_ent_mean": 43.224830627441406, "report/post_ent_min": 23.04084014892578, "report/post_ent_std": 7.567649841308594, "report/prior_ent_mag": 71.1585922241211, "report/prior_ent_max": 71.1585922241211, "report/prior_ent_mean": 57.207359313964844, "report/prior_ent_min": 42.789405822753906, "report/prior_ent_std": 4.789628982543945, "report/rep_loss_mean": 14.277804374694824, "report/rep_loss_std": 9.399690628051758, "report/reward_avg": 0.02226562425494194, "report/reward_loss_mean": 0.052330028265714645, "report/reward_loss_std": 0.24556316435337067, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0000128746032715, "report/reward_neg_acc": 0.9929859638214111, "report/reward_neg_loss": 0.033847078680992126, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7617908716201782, "report/reward_pred": 0.02272236905992031, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 5.467881010190467e-07, "eval/cont_loss_std": 3.0948026505939197e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.745372876233887e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.147619279137871e-07, "eval/cont_pred": 0.9951170086860657, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.125789642333984, "eval/dyn_loss_std": 11.044340133666992, "eval/image_loss_mean": 12.34195327758789, "eval/image_loss_std": 15.997708320617676, "eval/model_loss_mean": 23.320758819580078, "eval/model_loss_std": 20.238494873046875, "eval/post_ent_mag": 59.435546875, "eval/post_ent_max": 59.435546875, "eval/post_ent_mean": 42.329917907714844, "eval/post_ent_min": 20.28404426574707, "eval/post_ent_std": 7.335705757141113, "eval/prior_ent_mag": 71.1585922241211, "eval/prior_ent_max": 71.1585922241211, "eval/prior_ent_mean": 58.144073486328125, "eval/prior_ent_min": 44.04386901855469, "eval/prior_ent_std": 4.808681964874268, "eval/rep_loss_mean": 18.125789642333984, "eval/rep_loss_std": 11.044340133666992, "eval/reward_avg": 0.04238281026482582, "eval/reward_loss_mean": 0.10333169996738434, "eval/reward_loss_std": 0.5671492218971252, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.123277187347412, "eval/reward_neg_acc": 0.9938524961471558, "eval/reward_neg_loss": 0.03639181703329086, "eval/reward_pos_acc": 0.875, "eval/reward_pos_loss": 1.4644426107406616, "eval/reward_pred": 0.03567078337073326, "eval/reward_rate": 0.046875, "replay/size": 1000000.0, "replay/inserts": 22720.0, "replay/samples": 22720.0, "replay/insert_wait_avg": 1.3323422049132872e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.045262853864213e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5792.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.274831387219508e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1877326965332, "timer/env.step_count": 2840.0, "timer/env.step_total": 218.47326254844666, "timer/env.step_frac": 0.2184322556720795, "timer/env.step_avg": 0.07692720512269248, "timer/env.step_min": 0.02405524253845215, "timer/env.step_max": 3.5380640029907227, "timer/replay._sample_count": 22720.0, "timer/replay._sample_total": 11.68844199180603, "timer/replay._sample_frac": 0.011686248100937685, "timer/replay._sample_avg": 0.0005144560735830119, "timer/replay._sample_min": 0.0003657341003417969, "timer/replay._sample_max": 0.00908517837524414, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3564.0, "timer/agent.policy_total": 63.526777505874634, "timer/agent.policy_frac": 0.06351485369112128, "timer/agent.policy_avg": 0.017824572813096136, "timer/agent.policy_min": 0.009571075439453125, "timer/agent.policy_max": 0.24437332153320312, "timer/dataset_train_count": 1420.0, "timer/dataset_train_total": 0.15932250022888184, "timer/dataset_train_frac": 0.00015929259580033448, "timer/dataset_train_avg": 0.00011219894382315623, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.004164457321166992, "timer/agent.train_count": 1420.0, "timer/agent.train_total": 642.6950945854187, "timer/agent.train_frac": 0.6425744623488786, "timer/agent.train_avg": 0.4526021792855061, "timer/agent.train_min": 0.43901777267456055, "timer/agent.train_max": 1.9514594078063965, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4805276393890381, "timer/agent.report_frac": 0.0004804374455718654, "timer/agent.report_avg": 0.24026381969451904, "timer/agent.report_min": 0.23483014106750488, "timer/agent.report_max": 0.2456974983215332, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.955835473895352e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 22.715356113267283}
{"step": 1214360, "time": 55402.37840437889, "episode/length": 337.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.985207100591716, "episode/intrinsic_return": 0.0}
{"step": 1214400, "time": 55405.59065365791, "episode/length": 414.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9783132530120482, "episode/intrinsic_return": 0.0}
{"step": 1214448, "time": 55408.87973713875, "episode/length": 303.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 1214456, "time": 55410.529108285904, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 1214456, "time": 55410.53731894493, "episode/length": 198.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 1214784, "time": 55425.198952674866, "episode/length": 106.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 1215216, "time": 55441.55276417732, "episode/length": 345.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9913294797687862, "episode/intrinsic_return": 0.0}
{"step": 1215288, "time": 55445.22406196594, "episode/length": 62.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 1215368, "time": 55449.5356400013, "episode/length": 113.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9912280701754386, "episode/intrinsic_return": 0.0}
{"step": 1215648, "time": 55460.815504550934, "episode/length": 160.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 1216008, "time": 55474.24172997475, "episode/length": 193.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 1216104, "time": 55479.01883101463, "episode/length": 278.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.0}
{"step": 1216336, "time": 55488.614490270615, "episode/length": 85.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 1216592, "time": 55498.91650605202, "episode/length": 273.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 1216640, "time": 55502.22351241112, "episode/length": 273.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 1217296, "time": 55526.108716487885, "episode/length": 250.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9760956175298805, "episode/intrinsic_return": 0.0}
{"step": 1217344, "time": 55529.53324389458, "episode/length": 125.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 1217616, "time": 55540.31538319588, "episode/length": 280.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9750889679715302, "episode/intrinsic_return": 0.0}
{"step": 1217648, "time": 55542.88751459122, "episode/length": 192.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 1218376, "time": 55569.63986873627, "episode/length": 295.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9763513513513513, "episode/intrinsic_return": 0.0}
{"step": 1218736, "time": 55583.78580117226, "episode/length": 267.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 1218792, "time": 55587.091334819794, "episode/length": 446.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9977628635346756, "episode/intrinsic_return": 0.0}
{"step": 1219072, "time": 55598.36664271355, "episode/length": 215.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 1219080, "time": 55600.05623078346, "episode/length": 222.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 1219568, "time": 55618.3442299366, "episode/length": 365.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9972677595628415, "episode/intrinsic_return": 0.0}
{"step": 1219960, "time": 55632.99131798744, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 1220024, "time": 55657.21532320976, "eval_episode/length": 155.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 1220024, "time": 55665.56046485901, "eval_episode/length": 304.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9770491803278688}
{"step": 1220024, "time": 55668.094850063324, "eval_episode/length": 319.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.990625}
{"step": 1220024, "time": 55670.4132707119, "eval_episode/length": 335.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9880952380952381}
{"step": 1220024, "time": 55672.73790407181, "eval_episode/length": 351.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9886363636363636}
{"step": 1220024, "time": 55675.46997094154, "eval_episode/length": 377.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 1220024, "time": 55677.34629368782, "eval_episode/length": 65.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9848484848484849}
{"step": 1220024, "time": 55679.01395368576, "eval_episode/length": 387.0, "eval_episode/score": 13.100000008940697, "eval_episode/reward_rate": 0.9974226804123711}
{"step": 1220072, "time": 55680.648763895035, "episode/length": 302.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 1220472, "time": 55695.79690670967, "episode/length": 174.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 1220736, "time": 55708.5850880146, "episode/length": 389.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9974358974358974, "episode/intrinsic_return": 0.0}
{"step": 1220840, "time": 55713.44134759903, "episode/length": 255.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 1221200, "time": 55727.315557956696, "episode/length": 307.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9805194805194806, "episode/intrinsic_return": 0.0}
{"step": 1221400, "time": 55735.60605454445, "episode/length": 179.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 1221728, "time": 55748.38270020485, "episode/length": 269.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9851851851851852, "episode/intrinsic_return": 0.0}
{"step": 1222016, "time": 55759.9363117218, "episode/length": 242.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 1222216, "time": 55768.01657629013, "episode/length": 391.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9974489795918368, "episode/intrinsic_return": 0.0}
{"step": 1222648, "time": 55784.156661987305, "episode/length": 225.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 1222912, "time": 55794.91593551636, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 1222920, "time": 55796.61124968529, "episode/length": 305.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9967320261437909, "episode/intrinsic_return": 0.0}
{"step": 1223008, "time": 55801.303968429565, "episode/length": 225.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 1223704, "time": 55826.25694131851, "episode/length": 185.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 1224680, "time": 55860.818606853485, "episode/length": 208.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 1224736, "time": 55864.538714170456, "episode/length": 227.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1224760, "time": 55866.76968359947, "episode/length": 502.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9821073558648111, "episode/intrinsic_return": 0.0}
{"step": 1225464, "time": 55892.23664474487, "episode/length": 430.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9930394431554525, "episode/intrinsic_return": 0.0}
{"step": 1225616, "time": 55899.188009262085, "episode/length": 485.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 1225920, "time": 55911.09494924545, "episode/length": 56.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 1226384, "time": 55928.39943933487, "episode/length": 205.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 1226560, "time": 55935.89712762833, "episode/length": 234.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1226584, "time": 55938.19222784042, "episode/length": 227.0, "episode/score": 11.1000000461936, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1226800, "time": 55947.25676202774, "episode/length": 386.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 1227144, "time": 55960.300151109695, "episode/length": 527.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.990530303030303, "episode/intrinsic_return": 0.0}
{"step": 1227408, "time": 55971.545354127884, "episode/length": 223.0, "episode/score": 13.100000031292439, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1227744, "time": 55984.40274095535, "episode/length": 227.0, "episode/score": 10.1000000461936, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1227904, "time": 55991.379079818726, "episode/length": 189.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 1228280, "time": 56005.54031419754, "episode/length": 211.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 1228328, "time": 56008.795516490936, "episode/length": 709.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 1228776, "time": 56025.52603793144, "episode/length": 203.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 1229400, "time": 56050.24752664566, "episode/length": 248.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9718875502008032, "episode/intrinsic_return": 0.0}
{"step": 1229480, "time": 56054.52774000168, "episode/length": 334.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9970149253731343, "episode/intrinsic_return": 0.0}
{"step": 1229600, "time": 56060.68650555611, "episode/length": 211.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 1229624, "time": 56062.82639122009, "episode/length": 234.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1229864, "time": 56072.44422125816, "episode/length": 197.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 1230008, "time": 56102.239569664, "eval_episode/length": 169.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 1230008, "time": 56105.612369298935, "eval_episode/length": 208.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 1230008, "time": 56108.50543928146, "eval_episode/length": 235.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9788135593220338}
{"step": 1230008, "time": 56110.46973490715, "eval_episode/length": 244.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9959183673469387}
{"step": 1230008, "time": 56116.02114534378, "eval_episode/length": 328.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9817629179331308}
{"step": 1230008, "time": 56120.31549167633, "eval_episode/length": 383.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9895833333333334}
{"step": 1230008, "time": 56124.11557388306, "eval_episode/length": 222.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 1230008, "time": 56127.22800850868, "eval_episode/length": 465.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9785407725321889}
{"step": 1230344, "time": 56138.51146697998, "episode/length": 251.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 1230384, "time": 56141.60082960129, "episode/length": 200.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 1230424, "time": 56144.29043030739, "episode/length": 482.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9730848861283644, "episode/intrinsic_return": 0.0}
{"step": 1230512, "time": 56149.24997639656, "episode/length": 80.0, "episode/score": 8.1000000461936, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 1230936, "time": 56164.8349943161, "episode/length": 191.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 1231568, "time": 56188.080875873566, "episode/length": 147.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9527027027027027, "episode/intrinsic_return": 0.0}
{"step": 1231864, "time": 56199.50024366379, "episode/length": 189.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 1232352, "time": 56217.8322968483, "episode/length": 60.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 1232560, "time": 56226.345584869385, "episode/length": 266.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 1232688, "time": 56232.323404312134, "episode/length": 382.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9921671018276762, "episode/intrinsic_return": 0.0}
{"step": 1232696, "time": 56233.90369820595, "episode/length": 386.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9948320413436692, "episode/intrinsic_return": 0.0}
{"step": 1232848, "time": 56241.01217150688, "episode/length": 238.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 1233320, "time": 56258.29922127724, "episode/length": 350.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 1233480, "time": 56265.246876716614, "episode/length": 499.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.986, "episode/intrinsic_return": 0.0}
{"step": 1233896, "time": 56281.01698946953, "episode/length": 149.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1233968, "time": 56285.36098599434, "episode/length": 201.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 1234096, "time": 56291.252603292465, "episode/length": 175.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 1234216, "time": 56296.81058907509, "episode/length": 330.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9818731117824774, "episode/intrinsic_return": 0.0}
{"step": 1234912, "time": 56322.14720106125, "episode/length": 257.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 1234952, "time": 56324.96171784401, "episode/length": 203.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 1235224, "time": 56335.8868367672, "episode/length": 217.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1235304, "time": 56340.27070593834, "episode/length": 342.0, "episode/score": 13.099999964237213, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 1235648, "time": 56353.757128715515, "episode/length": 86.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 1235720, "time": 56357.86182594299, "episode/length": 227.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 1236008, "time": 56369.184826374054, "episode/length": 87.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 1236424, "time": 56384.966527462006, "episode/length": 275.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 1236793, "time": 56400.257140636444, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.767994982130984, "train/action_min": 0.0, "train/action_std": 3.5494158995066973, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.030535663814937816, "train/actor_opt_grad_steps": 76500.0, "train/actor_opt_loss": -8.323205713684677, "train/adv_mag": 0.415536123598721, "train/adv_max": 0.36987524189002124, "train/adv_mean": 0.001853856753278699, "train/adv_min": -0.341920018301788, "train/adv_std": 0.04412224191300412, "train/cont_avg": 0.9955604499113475, "train/cont_loss_mean": 0.00012826677340161877, "train/cont_loss_std": 0.0039006282834365175, "train/cont_neg_acc": 0.9942586971512923, "train/cont_neg_loss": 0.023774112070992837, "train/cont_pos_acc": 0.9999930266792892, "train/cont_pos_loss": 2.9082568301967162e-05, "train/cont_pred": 0.9955802995262416, "train/cont_rate": 0.9955604499113475, "train/dyn_loss_mean": 13.14327215641103, "train/dyn_loss_std": 9.440188644625616, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0567528330687936, "train/extr_critic_critic_opt_grad_steps": 76500.0, "train/extr_critic_critic_opt_loss": 15122.54632784796, "train/extr_critic_mag": 10.76808258489514, "train/extr_critic_max": 10.76808258489514, "train/extr_critic_mean": 3.0814355112982135, "train/extr_critic_min": -0.16748813027185752, "train/extr_critic_std": 2.623007408270599, "train/extr_return_normed_mag": 1.4328630012823336, "train/extr_return_normed_max": 1.4328630012823336, "train/extr_return_normed_mean": 0.3690887509931064, "train/extr_return_normed_min": -0.07474250541273372, "train/extr_return_normed_std": 0.3264372806388436, "train/extr_return_rate": 0.8372128487478757, "train/extr_return_raw_mag": 11.731447260430519, "train/extr_return_raw_max": 11.731447260430519, "train/extr_return_raw_mean": 3.0964702756692333, "train/extr_return_raw_min": -0.5067015660147295, "train/extr_return_raw_std": 2.650223083529912, "train/extr_reward_mag": 1.0480826002486208, "train/extr_reward_max": 1.0480826002486208, "train/extr_reward_mean": 0.049524653359507835, "train/extr_reward_min": -0.433595782476114, "train/extr_reward_std": 0.2082591007153193, "train/image_loss_mean": 6.511429235444846, "train/image_loss_std": 12.149835627129738, "train/model_loss_mean": 14.45877719770932, "train/model_loss_std": 15.99626476206678, "train/model_opt_grad_norm": 47.92312654535821, "train/model_opt_grad_steps": 76432.36170212766, "train/model_opt_loss": 18229.587696697694, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1258.8652482269504, "train/policy_entropy_mag": 2.594487834484019, "train/policy_entropy_max": 2.594487834484019, "train/policy_entropy_mean": 0.6486491045207842, "train/policy_entropy_min": 0.07937502385453975, "train/policy_entropy_std": 0.7975940285845006, "train/policy_logprob_mag": 7.438383870090998, "train/policy_logprob_max": -0.009455659241805263, "train/policy_logprob_mean": -0.6492103522128247, "train/policy_logprob_min": -7.438383870090998, "train/policy_logprob_std": 1.1684804740526997, "train/policy_randomness_mag": 0.9157403475003885, "train/policy_randomness_max": 0.9157403475003885, "train/policy_randomness_mean": 0.22894467011833866, "train/policy_randomness_min": 0.028015900073004953, "train/policy_randomness_std": 0.2815156897120442, "train/post_ent_mag": 61.5537898557406, "train/post_ent_max": 61.5537898557406, "train/post_ent_mean": 43.84494767966845, "train/post_ent_min": 20.681129550257474, "train/post_ent_std": 7.7627808624971, "train/prior_ent_mag": 71.24320826970094, "train/prior_ent_max": 71.24320826970094, "train/prior_ent_mean": 57.051367955850374, "train/prior_ent_min": 40.74056668653556, "train/prior_ent_std": 4.926223775173756, "train/rep_loss_mean": 13.14327215641103, "train/rep_loss_std": 9.440188644625616, "train/reward_avg": 0.03695007753129124, "train/reward_loss_mean": 0.06125641529653089, "train/reward_loss_std": 0.2524955854982349, "train/reward_max_data": 1.0255319209809, "train/reward_max_pred": 1.0199671738536646, "train/reward_neg_acc": 0.9915485830171734, "train/reward_neg_loss": 0.029904361523634997, "train/reward_pos_acc": 0.9804619702887027, "train/reward_pos_loss": 0.7974898747518553, "train/reward_pred": 0.036256216122960365, "train/reward_rate": 0.04091173537234043, "train_stats/sum_log_reward": 10.600000213493, "train_stats/max_log_achievement_collect_coal": 1.0227272727272727, "train_stats/max_log_achievement_collect_drink": 6.5227272727272725, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.9090909090909092, "train_stats/max_log_achievement_collect_stone": 15.772727272727273, "train_stats/max_log_achievement_collect_wood": 11.647727272727273, "train_stats/max_log_achievement_defeat_skeleton": 0.09090909090909091, "train_stats/max_log_achievement_defeat_zombie": 1.1818181818181819, "train_stats/max_log_achievement_eat_cow": 0.2727272727272727, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.011363636363636364, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.25, "train_stats/max_log_achievement_make_wood_sword": 1.3295454545454546, "train_stats/max_log_achievement_place_furnace": 1.9772727272727273, "train_stats/max_log_achievement_place_plant": 1.7272727272727273, "train_stats/max_log_achievement_place_stone": 5.090909090909091, "train_stats/max_log_achievement_place_table": 3.1363636363636362, "train_stats/max_log_achievement_wake_up": 1.7727272727272727, "train_stats/mean_log_entropy": 0.6059171977368268, "eval_stats/sum_log_reward": 10.97500029206276, "eval_stats/max_log_achievement_collect_coal": 1.125, "eval_stats/max_log_achievement_collect_drink": 7.375, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.8125, "eval_stats/max_log_achievement_collect_stone": 19.1875, "eval_stats/max_log_achievement_collect_wood": 13.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.3125, "eval_stats/max_log_achievement_eat_cow": 0.375, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.625, "eval_stats/max_log_achievement_make_wood_sword": 2.0625, "eval_stats/max_log_achievement_place_furnace": 1.625, "eval_stats/max_log_achievement_place_plant": 1.6875, "eval_stats/max_log_achievement_place_stone": 6.25, "eval_stats/max_log_achievement_place_table": 3.5625, "eval_stats/max_log_achievement_wake_up": 2.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.00017983636644203216, "report/cont_loss_std": 0.005353039596229792, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.392541839275509e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00018069632642436773, "report/cont_pred": 0.9939748048782349, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 14.459699630737305, "report/dyn_loss_std": 9.710773468017578, "report/image_loss_mean": 6.458715438842773, "report/image_loss_std": 15.101760864257812, "report/model_loss_mean": 15.199028015136719, "report/model_loss_std": 18.888002395629883, "report/post_ent_mag": 61.18578338623047, "report/post_ent_max": 61.18578338623047, "report/post_ent_mean": 42.07331848144531, "report/post_ent_min": 20.927154541015625, "report/post_ent_std": 7.951292037963867, "report/prior_ent_mag": 71.0241928100586, "report/prior_ent_max": 71.0241928100586, "report/prior_ent_mean": 56.60000991821289, "report/prior_ent_min": 41.19800567626953, "report/prior_ent_std": 4.713156223297119, "report/rep_loss_mean": 14.459699630737305, "report/rep_loss_std": 9.710773468017578, "report/reward_avg": 0.03691406175494194, "report/reward_loss_mean": 0.06431350111961365, "report/reward_loss_std": 0.24778658151626587, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0021910667419434, "report/reward_neg_acc": 0.9959267377853394, "report/reward_neg_loss": 0.03098352439701557, "report/reward_pos_acc": 0.9761905074119568, "report/reward_pos_loss": 0.8436001539230347, "report/reward_pred": 0.0355905257165432, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 1.1271339644736145e-05, "eval/cont_loss_std": 0.00033843197161331773, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.5446426914422773e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1267257832514588e-05, "eval/cont_pred": 0.9990123510360718, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 18.596969604492188, "eval/dyn_loss_std": 10.504172325134277, "eval/image_loss_mean": 12.221755981445312, "eval/image_loss_std": 19.083837509155273, "eval/model_loss_mean": 23.50763702392578, "eval/model_loss_std": 23.264572143554688, "eval/post_ent_mag": 61.71343231201172, "eval/post_ent_max": 61.71343231201172, "eval/post_ent_mean": 42.65135192871094, "eval/post_ent_min": 18.51435089111328, "eval/post_ent_std": 7.682800769805908, "eval/prior_ent_mag": 71.05347442626953, "eval/prior_ent_max": 71.05347442626953, "eval/prior_ent_mean": 59.331451416015625, "eval/prior_ent_min": 43.967987060546875, "eval/prior_ent_std": 4.4407758712768555, "eval/rep_loss_mean": 18.596969604492188, "eval/rep_loss_std": 10.504172325134277, "eval/reward_avg": 0.04189452901482582, "eval/reward_loss_mean": 0.12768858671188354, "eval/reward_loss_std": 0.6772712469100952, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0776033401489258, "eval/reward_neg_acc": 0.9866939187049866, "eval/reward_neg_loss": 0.04264623671770096, "eval/reward_pos_acc": 0.8723403811454773, "eval/reward_pos_loss": 1.8954838514328003, "eval/reward_pred": 0.0325712189078331, "eval/reward_rate": 0.0458984375, "replay/size": 1000000.0, "replay/inserts": 22512.0, "replay/samples": 22512.0, "replay/insert_wait_avg": 1.3412739591727293e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.12086808232441e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6832.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2445784843498426e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4205498695374, "timer/env.step_count": 2814.0, "timer/env.step_total": 222.24449133872986, "timer/env.step_frac": 0.22215106573701657, "timer/env.step_avg": 0.07897814191141786, "timer/env.step_min": 0.02447223663330078, "timer/env.step_max": 3.432126998901367, "timer/replay._sample_count": 22512.0, "timer/replay._sample_total": 11.659730911254883, "timer/replay._sample_frac": 0.01165482947424001, "timer/replay._sample_avg": 0.0005179340312391117, "timer/replay._sample_min": 0.00042891502380371094, "timer/replay._sample_max": 0.03380107879638672, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3668.0, "timer/agent.policy_total": 64.51867914199829, "timer/agent.policy_frac": 0.06449155722602062, "timer/agent.policy_avg": 0.01758960718156987, "timer/agent.policy_min": 0.009836912155151367, "timer/agent.policy_max": 0.12437582015991211, "timer/dataset_train_count": 1407.0, "timer/dataset_train_total": 0.1552894115447998, "timer/dataset_train_frac": 0.00015522413205631448, "timer/dataset_train_avg": 0.000110369162434115, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0010561943054199219, "timer/agent.train_count": 1407.0, "timer/agent.train_total": 633.863941192627, "timer/agent.train_frac": 0.633597481854294, "timer/agent.train_avg": 0.4505074208902821, "timer/agent.train_min": 0.43679022789001465, "timer/agent.train_max": 1.8311512470245361, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4735844135284424, "timer/agent.report_frac": 0.0004733853313890858, "timer/agent.report_avg": 0.2367922067642212, "timer/agent.report_min": 0.23058247566223145, "timer/agent.report_max": 0.24300193786621094, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9551475939242867e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 22.502230367416477}
{"step": 1237112, "time": 56415.14153575897, "episode/length": 235.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1237264, "time": 56422.225610256195, "episode/length": 293.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 1237376, "time": 56427.616362810135, "episode/length": 425.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 1237376, "time": 56427.625123262405, "episode/length": 215.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 1237696, "time": 56441.765677690506, "episode/length": 210.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1237896, "time": 56449.97921514511, "episode/length": 183.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 1237912, "time": 56452.110406160355, "episode/length": 476.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9874213836477987, "episode/intrinsic_return": 0.0}
{"step": 1237936, "time": 56454.66980886459, "episode/length": 276.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9783393501805054, "episode/intrinsic_return": 0.0}
{"step": 1238784, "time": 56484.80471420288, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9602272727272727, "episode/intrinsic_return": 0.0}
{"step": 1239432, "time": 56508.247883081436, "episode/length": 270.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.977859778597786, "episode/intrinsic_return": 0.0}
{"step": 1239520, "time": 56512.94026970863, "episode/length": 227.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 1239600, "time": 56517.30455136299, "episode/length": 207.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 1239672, "time": 56521.100373506546, "episode/length": 221.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.963963963963964, "episode/intrinsic_return": 0.0}
{"step": 1239920, "time": 56531.173199892044, "episode/length": 350.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9971509971509972, "episode/intrinsic_return": 0.0}
{"step": 1240008, "time": 56535.54349923134, "episode/length": 328.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9969604863221885, "episode/intrinsic_return": 0.0}
{"step": 1240096, "time": 56555.882595300674, "eval_episode/length": 46.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 1240096, "time": 56562.55921959877, "eval_episode/length": 160.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.968944099378882}
{"step": 1240096, "time": 56565.9073638916, "eval_episode/length": 193.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 1240096, "time": 56567.89292216301, "eval_episode/length": 198.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 1240096, "time": 56570.90942287445, "eval_episode/length": 227.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 1240096, "time": 56574.672454595566, "eval_episode/length": 229.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 1240096, "time": 56577.40857219696, "eval_episode/length": 301.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9735099337748344}
{"step": 1240096, "time": 56579.8789396286, "eval_episode/length": 318.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9843260188087775}
{"step": 1240496, "time": 56593.30832576752, "episode/length": 213.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 1240920, "time": 56608.95324635506, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 1241024, "time": 56614.24842238426, "episode/length": 126.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 1241136, "time": 56619.75175380707, "episode/length": 212.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 1241608, "time": 56637.5765273571, "episode/length": 260.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9731800766283525, "episode/intrinsic_return": 0.0}
{"step": 1241840, "time": 56647.29795098305, "episode/length": 490.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9877800407331976, "episode/intrinsic_return": 0.0}
{"step": 1242344, "time": 56665.778817892075, "episode/length": 333.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9880239520958084, "episode/intrinsic_return": 0.0}
{"step": 1242752, "time": 56681.30735683441, "episode/length": 50.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 1242848, "time": 56686.34810090065, "episode/length": 125.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 1243616, "time": 56713.732922792435, "episode/length": 389.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.0}
{"step": 1243640, "time": 56716.01789736748, "episode/length": 312.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9840255591054313, "episode/intrinsic_return": 0.0}
{"step": 1243808, "time": 56723.6939136982, "episode/length": 347.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 1243888, "time": 56727.89204907417, "episode/length": 284.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 1244264, "time": 56741.79445743561, "episode/length": 542.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.990791896869245, "episode/intrinsic_return": 0.0}
{"step": 1244496, "time": 56751.61575508118, "episode/length": 85.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 1244704, "time": 56760.08809256554, "episode/length": 231.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 1245208, "time": 56780.17672300339, "episode/length": 306.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9869706840390879, "episode/intrinsic_return": 0.0}
{"step": 1245400, "time": 56788.3717854023, "episode/length": 222.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 1245512, "time": 56793.82668876648, "episode/length": 573.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9982578397212544, "episode/intrinsic_return": 0.0}
{"step": 1245536, "time": 56796.436052560806, "episode/length": 205.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9854368932038835, "episode/intrinsic_return": 0.0}
{"step": 1245904, "time": 56810.73488712311, "episode/length": 48.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 1246184, "time": 56821.49698925018, "episode/length": 184.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 1246720, "time": 56841.467349529266, "episode/length": 277.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9748201438848921, "episode/intrinsic_return": 0.0}
{"step": 1246832, "time": 56846.82967567444, "episode/length": 161.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 1246864, "time": 56849.539976119995, "episode/length": 182.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 1246920, "time": 56852.79484295845, "episode/length": 331.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9969879518072289, "episode/intrinsic_return": 0.0}
{"step": 1247352, "time": 56868.96760773659, "episode/length": 267.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9664179104477612, "episode/intrinsic_return": 0.0}
{"step": 1247712, "time": 56882.879284620285, "episode/length": 225.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 1248384, "time": 56907.49261593819, "episode/length": 592.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9898819561551433, "episode/intrinsic_return": 0.0}
{"step": 1248528, "time": 56914.033945798874, "episode/length": 292.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9795221843003413, "episode/intrinsic_return": 0.0}
{"step": 1249016, "time": 56932.00853061676, "episode/length": 162.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 1249256, "time": 56941.87767505646, "episode/length": 298.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.0}
{"step": 1249416, "time": 56948.82872891426, "episode/length": 49.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 1249448, "time": 56951.53088283539, "episode/length": 132.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9548872180451128, "episode/intrinsic_return": 0.0}
{"step": 1249920, "time": 56969.34257531166, "episode/length": 399.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9925, "episode/intrinsic_return": 0.0}
{"step": 1250080, "time": 56995.8486495018, "eval_episode/length": 156.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9617834394904459}
{"step": 1250080, "time": 56998.45287632942, "eval_episode/length": 181.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 1250080, "time": 57001.389966487885, "eval_episode/length": 211.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 1250080, "time": 57004.22015571594, "eval_episode/length": 237.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 1250080, "time": 57011.45365190506, "eval_episode/length": 312.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9840255591054313}
{"step": 1250080, "time": 57013.27324461937, "eval_episode/length": 317.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9968553459119497}
{"step": 1250080, "time": 57017.522753953934, "eval_episode/length": 215.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9907407407407407}
{"step": 1250080, "time": 57021.44598507881, "eval_episode/length": 424.0, "eval_episode/score": 11.099999964237213, "eval_episode/reward_rate": 0.9811764705882353}
{"step": 1250120, "time": 57022.55926990509, "episode/length": 399.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 1250248, "time": 57028.49787259102, "episode/length": 426.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 1250608, "time": 57042.436244010925, "episode/length": 168.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 1250720, "time": 57048.03175854683, "episode/length": 420.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9904988123515439, "episode/intrinsic_return": 0.0}
{"step": 1251136, "time": 57063.64942097664, "episode/length": 214.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 1251200, "time": 57067.47165846825, "episode/length": 134.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1251248, "time": 57070.74463009834, "episode/length": 224.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1251656, "time": 57085.99994850159, "episode/length": 175.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 1251672, "time": 57088.19247341156, "episode/length": 392.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9949109414758269, "episode/intrinsic_return": 0.0}
{"step": 1251800, "time": 57094.097343206406, "episode/length": 234.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1252264, "time": 57111.68102765083, "episode/length": 57.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 1252456, "time": 57120.45650792122, "episode/length": 230.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 1252576, "time": 57126.30609893799, "episode/length": 231.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 1252816, "time": 57135.85252523422, "episode/length": 195.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 1252976, "time": 57142.92237854004, "episode/length": 164.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 1253824, "time": 57175.06473946571, "episode/length": 327.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9847560975609756, "episode/intrinsic_return": 0.0}
{"step": 1254064, "time": 57184.72189950943, "episode/length": 200.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 1254176, "time": 57190.04572081566, "episode/length": 238.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 1254392, "time": 57198.8004462719, "episode/length": 196.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 1254576, "time": 57206.91865491867, "episode/length": 429.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 1254648, "time": 57210.67853283882, "episode/length": 208.0, "episode/score": 12.100000038743019, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 1255344, "time": 57235.999088048935, "episode/length": 159.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 1255952, "time": 57258.11003422737, "episode/length": 421.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9928909952606635, "episode/intrinsic_return": 0.0}
{"step": 1256136, "time": 57265.66609668732, "episode/length": 244.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9877551020408163, "episode/intrinsic_return": 0.0}
{"step": 1256208, "time": 57269.95535469055, "episode/length": 194.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 1256504, "time": 57281.255954265594, "episode/length": 240.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 1256528, "time": 57283.93574523926, "episode/length": 606.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.985172981878089, "episode/intrinsic_return": 0.0}
{"step": 1256824, "time": 57295.39150309563, "episode/length": 303.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9835526315789473, "episode/intrinsic_return": 0.0}
{"step": 1257256, "time": 57311.41735243797, "episode/length": 238.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 1257656, "time": 57326.786356687546, "episode/length": 180.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 1257672, "time": 57329.0411093235, "episode/length": 480.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.997920997920998, "episode/intrinsic_return": 0.0}
{"step": 1258232, "time": 57349.74942779541, "episode/length": 215.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 1258288, "time": 57353.50101184845, "episode/length": 291.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 1258320, "time": 57356.18923163414, "episode/length": 272.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 1258336, "time": 57358.28677368164, "episode/length": 188.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 1258536, "time": 57366.36382102966, "episode/length": 250.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 1258664, "time": 57372.13178420067, "episode/length": 175.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 1258896, "time": 57381.90246415138, "episode/length": 152.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 1259152, "time": 57392.107197761536, "episode/length": 31.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 1259337, "time": 57400.591130018234, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.694601721797429, "train/action_min": 0.0, "train/action_std": 3.495473662166731, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03025798979116247, "train/actor_opt_grad_steps": 77910.0, "train/actor_opt_loss": -7.816913299843774, "train/adv_mag": 0.3883166189523453, "train/adv_max": 0.34908335756325554, "train/adv_mean": 0.0017799895357331079, "train/adv_min": -0.3216952518791172, "train/adv_std": 0.04349917255289166, "train/cont_avg": 0.9956574135638298, "train/cont_loss_mean": 0.00011561572553788977, "train/cont_loss_std": 0.003438126824643895, "train/cont_neg_acc": 0.9877295924084527, "train/cont_neg_loss": 0.021306441492015438, "train/cont_pos_acc": 0.9999930072338024, "train/cont_pos_loss": 3.747815210074745e-05, "train/cont_pred": 0.9956727564757597, "train/cont_rate": 0.9956574135638298, "train/dyn_loss_mean": 13.108531038811867, "train/dyn_loss_std": 9.372113552499325, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0252356816690864, "train/extr_critic_critic_opt_grad_steps": 77910.0, "train/extr_critic_critic_opt_loss": 15237.831407912234, "train/extr_critic_mag": 10.797512521135046, "train/extr_critic_max": 10.797512521135046, "train/extr_critic_mean": 3.013024350430103, "train/extr_critic_min": -0.16824934245846795, "train/extr_critic_std": 2.68488317854861, "train/extr_return_normed_mag": 1.4227626053154045, "train/extr_return_normed_max": 1.4227626053154045, "train/extr_return_normed_mean": 0.3631285350796179, "train/extr_return_normed_min": -0.06553844308335308, "train/extr_return_normed_std": 0.3287803632147769, "train/extr_return_rate": 0.7998153495450392, "train/extr_return_raw_mag": 11.776174660270096, "train/extr_return_raw_max": 11.776174660270096, "train/extr_return_raw_mean": 3.0277142008991107, "train/extr_return_raw_min": -0.5113159723527042, "train/extr_return_raw_std": 2.7147093994397644, "train/extr_reward_mag": 1.0457643380401829, "train/extr_reward_max": 1.0457643380401829, "train/extr_reward_mean": 0.04980817878394262, "train/extr_reward_min": -0.4695841648899917, "train/extr_reward_std": 0.20779468171985438, "train/image_loss_mean": 6.612659089108731, "train/image_loss_std": 12.169604839162623, "train/model_loss_mean": 14.539508866925612, "train/model_loss_std": 16.00354710031063, "train/model_opt_grad_norm": 49.89630201353249, "train/model_opt_grad_steps": 77840.91489361702, "train/model_opt_loss": 18779.23156305408, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1294.3262411347519, "train/policy_entropy_mag": 2.636923377395522, "train/policy_entropy_max": 2.636923377395522, "train/policy_entropy_mean": 0.6518686508878748, "train/policy_entropy_min": 0.07937502253351482, "train/policy_entropy_std": 0.804710992684601, "train/policy_logprob_mag": 7.438383893763765, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.650546762960177, "train/policy_logprob_min": -7.438383893763765, "train/policy_logprob_std": 1.170043148047535, "train/policy_randomness_mag": 0.9307182333993573, "train/policy_randomness_max": 0.9307182333993573, "train/policy_randomness_mean": 0.23008102675278982, "train/policy_randomness_min": 0.028015899676697473, "train/policy_randomness_std": 0.2840276635284965, "train/post_ent_mag": 61.097275754238694, "train/post_ent_max": 61.097275754238694, "train/post_ent_mean": 43.83582546694059, "train/post_ent_min": 20.619103749593098, "train/post_ent_std": 7.696200205079207, "train/prior_ent_mag": 71.16582867777939, "train/prior_ent_max": 71.16582867777939, "train/prior_ent_mean": 57.0228769018295, "train/prior_ent_min": 40.85702460539257, "train/prior_ent_std": 4.872377943485342, "train/rep_loss_mean": 13.108531038811867, "train/rep_loss_std": 9.372113552499325, "train/reward_avg": 0.03799520664788941, "train/reward_loss_mean": 0.061615674155401, "train/reward_loss_std": 0.24977048914483252, "train/reward_max_data": 1.0255319209809, "train/reward_max_pred": 1.017814183911533, "train/reward_neg_acc": 0.9917439564745477, "train/reward_neg_loss": 0.029906197682234414, "train/reward_pos_acc": 0.9796834845914908, "train/reward_pos_loss": 0.791179672200629, "train/reward_pred": 0.03720024728764456, "train/reward_rate": 0.041798260195035464, "train_stats/sum_log_reward": 10.54943841360928, "train_stats/max_log_achievement_collect_coal": 1.1797752808988764, "train_stats/max_log_achievement_collect_drink": 7.696629213483146, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.853932584269663, "train_stats/max_log_achievement_collect_stone": 15.842696629213483, "train_stats/max_log_achievement_collect_wood": 10.213483146067416, "train_stats/max_log_achievement_defeat_skeleton": 0.10112359550561797, "train_stats/max_log_achievement_defeat_zombie": 0.9887640449438202, "train_stats/max_log_achievement_eat_cow": 0.25842696629213485, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.6067415730337078, "train_stats/max_log_achievement_make_wood_sword": 1.5842696629213484, "train_stats/max_log_achievement_place_furnace": 2.056179775280899, "train_stats/max_log_achievement_place_plant": 1.6179775280898876, "train_stats/max_log_achievement_place_stone": 5.786516853932584, "train_stats/max_log_achievement_place_table": 2.7191011235955056, "train_stats/max_log_achievement_wake_up": 1.7752808988764044, "train_stats/mean_log_entropy": 0.6247288142697195, "eval_stats/sum_log_reward": 10.100000351667404, "eval_stats/max_log_achievement_collect_coal": 0.5625, "eval_stats/max_log_achievement_collect_drink": 7.0, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.8125, "eval_stats/max_log_achievement_collect_stone": 11.5, "eval_stats/max_log_achievement_collect_wood": 10.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.3125, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5625, "eval_stats/max_log_achievement_make_wood_sword": 1.5, "eval_stats/max_log_achievement_place_furnace": 1.625, "eval_stats/max_log_achievement_place_plant": 1.5625, "eval_stats/max_log_achievement_place_stone": 3.8125, "eval_stats/max_log_achievement_place_table": 3.1875, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 1.4402279703062959e-05, "report/cont_loss_std": 0.00033907368197105825, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0005851130117662251, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.0474082955624908e-05, "report/cont_pred": 0.9931577444076538, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.017736434936523, "report/dyn_loss_std": 9.187122344970703, "report/image_loss_mean": 6.100950241088867, "report/image_loss_std": 10.328702926635742, "report/model_loss_mean": 13.975690841674805, "report/model_loss_std": 13.549917221069336, "report/post_ent_mag": 61.24360656738281, "report/post_ent_max": 61.24360656738281, "report/post_ent_mean": 44.12149429321289, "report/post_ent_min": 21.501264572143555, "report/post_ent_std": 8.163849830627441, "report/prior_ent_mag": 71.71128845214844, "report/prior_ent_max": 71.71128845214844, "report/prior_ent_mean": 57.17496871948242, "report/prior_ent_min": 39.42596435546875, "report/prior_ent_std": 4.857721328735352, "report/rep_loss_mean": 13.017736434936523, "report/rep_loss_std": 9.187122344970703, "report/reward_avg": 0.03779296949505806, "report/reward_loss_mean": 0.06408432126045227, "report/reward_loss_std": 0.2375074177980423, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0057518482208252, "report/reward_neg_acc": 0.9918200373649597, "report/reward_neg_loss": 0.03359181806445122, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7123816013336182, "report/reward_pred": 0.03841470554471016, "report/reward_rate": 0.044921875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.2338384749455145e-06, "eval/cont_loss_std": 2.825605042744428e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00038446811959147453, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.0778290260304857e-07, "eval/cont_pred": 0.997071385383606, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.112581253051758, "eval/dyn_loss_std": 10.737427711486816, "eval/image_loss_mean": 9.870304107666016, "eval/image_loss_std": 12.445873260498047, "eval/model_loss_mean": 21.431058883666992, "eval/model_loss_std": 16.722814559936523, "eval/post_ent_mag": 57.584373474121094, "eval/post_ent_max": 57.584373474121094, "eval/post_ent_mean": 40.931541442871094, "eval/post_ent_min": 21.374217987060547, "eval/post_ent_std": 7.376645088195801, "eval/prior_ent_mag": 71.71128845214844, "eval/prior_ent_max": 71.71128845214844, "eval/prior_ent_mean": 57.58782958984375, "eval/prior_ent_min": 44.72764587402344, "eval/prior_ent_std": 4.479796409606934, "eval/rep_loss_mean": 19.112581253051758, "eval/rep_loss_std": 10.737427711486816, "eval/reward_avg": 0.04287109524011612, "eval/reward_loss_mean": 0.0932043269276619, "eval/reward_loss_std": 0.4433351755142212, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0013105869293213, "eval/reward_neg_acc": 0.9826175570487976, "eval/reward_neg_loss": 0.0427749939262867, "eval/reward_pos_acc": 0.8913043737411499, "eval/reward_pos_loss": 1.165375828742981, "eval/reward_pred": 0.0420452319085598, "eval/reward_rate": 0.044921875, "replay/size": 1000000.0, "replay/inserts": 22544.0, "replay/samples": 22544.0, "replay/insert_wait_avg": 1.354747160349102e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.168459107809832e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5952.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2484529326038976e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.354819059372, "timer/env.step_count": 2818.0, "timer/env.step_total": 225.60873198509216, "timer/env.step_frac": 0.225528710100313, "timer/env.step_avg": 0.0800598765028716, "timer/env.step_min": 0.024376630783081055, "timer/env.step_max": 3.4443717002868652, "timer/replay._sample_count": 22544.0, "timer/replay._sample_total": 11.624585151672363, "timer/replay._sample_frac": 0.011620461990279505, "timer/replay._sample_avg": 0.0005156398665575037, "timer/replay._sample_min": 0.00040531158447265625, "timer/replay._sample_max": 0.02594161033630371, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3562.0, "timer/agent.policy_total": 63.20702242851257, "timer/agent.policy_frac": 0.0631846033269933, "timer/agent.policy_avg": 0.01774481258520847, "timer/agent.policy_min": 0.00960683822631836, "timer/agent.policy_max": 0.24470138549804688, "timer/dataset_train_count": 1409.0, "timer/dataset_train_total": 0.15759754180908203, "timer/dataset_train_frac": 0.00015754164303148968, "timer/dataset_train_avg": 0.00011185063293760258, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0010578632354736328, "timer/agent.train_count": 1409.0, "timer/agent.train_total": 635.7878787517548, "timer/agent.train_frac": 0.635562369109775, "timer/agent.train_avg": 0.4512334128827216, "timer/agent.train_min": 0.43613529205322266, "timer/agent.train_max": 4.318871974945068, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47547411918640137, "timer/agent.report_frac": 0.0004753054717460021, "timer/agent.report_avg": 0.23773705959320068, "timer/agent.report_min": 0.23076772689819336, "timer/agent.report_max": 0.244706392288208, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8123413610820657e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 22.53570278800516}
{"step": 1259984, "time": 57422.50834393501, "episode/length": 205.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 1260064, "time": 57442.730563402176, "eval_episode/length": 56.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 1260064, "time": 57448.00553536415, "eval_episode/length": 141.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.971830985915493}
{"step": 1260064, "time": 57451.1426589489, "eval_episode/length": 175.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 1260064, "time": 57453.503126621246, "eval_episode/length": 194.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 1260064, "time": 57455.749586343765, "eval_episode/length": 206.0, "eval_episode/score": 11.100000038743019, "eval_episode/reward_rate": 0.9806763285024155}
{"step": 1260064, "time": 57457.448780059814, "eval_episode/length": 208.0, "eval_episode/score": 12.099999994039536, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 1260064, "time": 57460.657932281494, "eval_episode/length": 186.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 1260064, "time": 57464.23541641235, "eval_episode/length": 72.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9178082191780822}
{"step": 1260168, "time": 57467.71442055702, "episode/length": 203.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 1260544, "time": 57482.23298764229, "episode/length": 277.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 1260728, "time": 57489.67704629898, "episode/length": 257.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 1261208, "time": 57507.59687376022, "episode/length": 371.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9973118279569892, "episode/intrinsic_return": 0.0}
{"step": 1261680, "time": 57527.240783929825, "episode/length": 423.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9976415094339622, "episode/intrinsic_return": 0.0}
{"step": 1262024, "time": 57540.202820539474, "episode/length": 545.0, "episode/score": 13.099999971687794, "episode/reward_rate": 0.9981684981684982, "episode/intrinsic_return": 0.0}
{"step": 1262096, "time": 57544.5872964859, "episode/length": 263.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 1262128, "time": 57547.26089310646, "episode/length": 197.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 1262256, "time": 57553.144189834595, "episode/length": 387.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9974226804123711, "episode/intrinsic_return": 0.0}
{"step": 1262280, "time": 57555.407782793045, "episode/length": 193.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 1262592, "time": 57567.826733350754, "episode/length": 172.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 1262904, "time": 57579.62901997566, "episode/length": 341.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9883040935672515, "episode/intrinsic_return": 0.0}
{"step": 1263560, "time": 57603.211247205734, "episode/length": 182.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 1263824, "time": 57613.78565621376, "episode/length": 195.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 1264072, "time": 57623.479120731354, "episode/length": 298.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.0}
{"step": 1264224, "time": 57630.31935667992, "episode/length": 274.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 1264688, "time": 57647.7565805912, "episode/length": 300.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9966777408637874, "episode/intrinsic_return": 0.0}
{"step": 1264896, "time": 57656.28213787079, "episode/length": 166.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 1265200, "time": 57668.01418709755, "episode/length": 325.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9969325153374233, "episode/intrinsic_return": 0.0}
{"step": 1265536, "time": 57681.000692129135, "episode/length": 425.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 1265600, "time": 57684.833894729614, "episode/length": 190.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 1265616, "time": 57686.93842506409, "episode/length": 338.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9941002949852508, "episode/intrinsic_return": 0.0}
{"step": 1265784, "time": 57694.00361657143, "episode/length": 244.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 1266544, "time": 57721.56299376488, "episode/length": 167.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 1266584, "time": 57724.41538476944, "episode/length": 294.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.976271186440678, "episode/intrinsic_return": 0.0}
{"step": 1267080, "time": 57743.060149908066, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 1267216, "time": 57749.50111722946, "episode/length": 201.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 1267344, "time": 57755.435705661774, "episode/length": 305.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9967320261437909, "episode/intrinsic_return": 0.0}
{"step": 1267840, "time": 57773.81974172592, "episode/length": 256.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 1267848, "time": 57775.460397958755, "episode/length": 394.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9924050632911392, "episode/intrinsic_return": 0.0}
{"step": 1268032, "time": 57783.34168839455, "episode/length": 185.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 1269568, "time": 57837.037294626236, "episode/length": 293.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9965986394557823, "episode/intrinsic_return": 0.0}
{"step": 1269608, "time": 57839.66036224365, "episode/length": 282.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9787985865724381, "episode/intrinsic_return": 0.0}
{"step": 1269624, "time": 57841.70424222946, "episode/length": 222.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 1270008, "time": 57858.173692941666, "episode/length": 427.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9929906542056075, "episode/intrinsic_return": 0.0}
{"step": 1270048, "time": 57883.69886779785, "eval_episode/length": 196.0, "eval_episode/score": 11.099999971687794, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 1270048, "time": 57886.09331822395, "eval_episode/length": 209.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 1270048, "time": 57887.97160243988, "eval_episode/length": 212.0, "eval_episode/score": 12.099999979138374, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 1270048, "time": 57890.35894060135, "eval_episode/length": 226.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.973568281938326}
{"step": 1270048, "time": 57893.72115945816, "eval_episode/length": 259.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9961538461538462}
{"step": 1270048, "time": 57897.064452171326, "eval_episode/length": 296.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9764309764309764}
{"step": 1270048, "time": 57898.75052165985, "eval_episode/length": 299.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 1270048, "time": 57905.34304738045, "eval_episode/length": 412.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9975786924939467}
{"step": 1270136, "time": 57908.06672334671, "episode/length": 574.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9895652173913043, "episode/intrinsic_return": 0.0}
{"step": 1270448, "time": 57920.42198085785, "episode/length": 301.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9801324503311258, "episode/intrinsic_return": 0.0}
{"step": 1270600, "time": 57926.98031044006, "episode/length": 439.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9840909090909091, "episode/intrinsic_return": 0.0}
{"step": 1270712, "time": 57932.28609037399, "episode/length": 357.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9916201117318436, "episode/intrinsic_return": 0.0}
{"step": 1271536, "time": 57961.82390880585, "episode/length": 245.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 1272160, "time": 57984.568190813065, "episode/length": 318.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9905956112852664, "episode/intrinsic_return": 0.0}
{"step": 1272280, "time": 57990.054764032364, "episode/length": 283.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 1272440, "time": 57997.08095860481, "episode/length": 229.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 1272520, "time": 58001.21172785759, "episode/length": 297.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 1272864, "time": 58014.82472658157, "episode/length": 268.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 1273032, "time": 58021.879570961, "episode/length": 425.0, "episode/score": 10.100000038743019, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 1273144, "time": 58027.267439842224, "episode/length": 200.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 1273856, "time": 58053.692808389664, "episode/length": 123.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9435483870967742, "episode/intrinsic_return": 0.0}
{"step": 1273864, "time": 58055.360424518585, "episode/length": 212.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 1274656, "time": 58083.86157131195, "episode/length": 266.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 1274696, "time": 58086.527455329895, "episode/length": 530.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.992467043314501, "episode/intrinsic_return": 0.0}
{"step": 1275392, "time": 58111.74010658264, "episode/length": 388.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9768637532133676, "episode/intrinsic_return": 0.0}
{"step": 1275528, "time": 58117.84684586525, "episode/length": 207.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 1275552, "time": 58120.45679283142, "episode/length": 314.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 1275584, "time": 58123.1446352005, "episode/length": 304.0, "episode/score": 15.100000001490116, "episode/reward_rate": 0.9868852459016394, "episode/intrinsic_return": 0.0}
{"step": 1276192, "time": 58145.38906311989, "episode/length": 468.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9808102345415778, "episode/intrinsic_return": 0.0}
{"step": 1276224, "time": 58148.04709625244, "episode/length": 195.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 1276608, "time": 58162.76464867592, "episode/length": 238.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 1276664, "time": 58165.99015069008, "episode/length": 58.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9322033898305084, "episode/intrinsic_return": 0.0}
{"step": 1276704, "time": 58169.073803424835, "episode/length": 59.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 1276968, "time": 58179.39471626282, "episode/length": 179.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 1277064, "time": 58184.3877696991, "episode/length": 188.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 1277184, "time": 58190.39521121979, "episode/length": 223.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1277232, "time": 58193.70741724968, "episode/length": 421.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9928909952606635, "episode/intrinsic_return": 0.0}
{"step": 1278088, "time": 58225.63947057724, "episode/length": 172.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 1278288, "time": 58234.22901940346, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 1278640, "time": 58247.854925870895, "episode/length": 253.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 1278672, "time": 58250.5761179924, "episode/length": 47.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 1278712, "time": 58253.10093379021, "episode/length": 390.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9769820971867008, "episode/intrinsic_return": 0.0}
{"step": 1278808, "time": 58257.930106163025, "episode/length": 217.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 1278872, "time": 58261.76445913315, "episode/length": 210.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1279008, "time": 58268.02427315712, "episode/length": 254.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9725490196078431, "episode/intrinsic_return": 0.0}
{"step": 1280032, "time": 58325.6772108078, "eval_episode/length": 164.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 1280032, "time": 58328.44953250885, "eval_episode/length": 168.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 1280032, "time": 58331.952999830246, "eval_episode/length": 210.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.995260663507109}
{"step": 1280032, "time": 58333.86394023895, "eval_episode/length": 215.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 1280032, "time": 58335.77809357643, "eval_episode/length": 223.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 1280032, "time": 58337.599326610565, "eval_episode/length": 224.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 1280032, "time": 58339.682480573654, "eval_episode/length": 234.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 1280032, "time": 58344.771208286285, "eval_episode/length": 88.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9887640449438202}
{"step": 1280296, "time": 58353.47745347023, "episode/length": 197.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 1280312, "time": 58355.574269771576, "episode/length": 277.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 1280448, "time": 58361.949884176254, "episode/length": 221.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 1280472, "time": 58364.09379005432, "episode/length": 228.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 1280528, "time": 58367.965687036514, "episode/length": 411.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9878640776699029, "episode/intrinsic_return": 0.0}
{"step": 1280584, "time": 58371.180971860886, "episode/length": 221.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 1280800, "time": 58380.217609643936, "episode/length": 240.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 1281168, "time": 58394.08870124817, "episode/length": 269.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9703703703703703, "episode/intrinsic_return": 0.0}
{"step": 1281305, "time": 58401.02579712868, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.521311516309306, "train/action_min": 0.0, "train/action_std": 3.288311377058934, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.030517858065610384, "train/actor_opt_grad_steps": 79300.0, "train/actor_opt_loss": -5.5905008893596, "train/adv_mag": 0.42527921856754886, "train/adv_max": 0.3802382115029941, "train/adv_mean": 0.0017765812782292321, "train/adv_min": -0.34275520946422633, "train/adv_std": 0.044304048764879686, "train/cont_avg": 0.9956945711678832, "train/cont_loss_mean": 0.0002276462415622923, "train/cont_loss_std": 0.006884174396001332, "train/cont_neg_acc": 0.994814814903118, "train/cont_neg_loss": 0.03732372519504039, "train/cont_pos_acc": 0.9999498368179711, "train/cont_pos_loss": 0.00010809500234635331, "train/cont_pred": 0.9956603715889645, "train/cont_rate": 0.9956945711678832, "train/dyn_loss_mean": 13.221841220438046, "train/dyn_loss_std": 9.416080836832089, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0623545146336522, "train/extr_critic_critic_opt_grad_steps": 79300.0, "train/extr_critic_critic_opt_loss": 15494.989179402372, "train/extr_critic_mag": 10.66290576962659, "train/extr_critic_max": 10.66290576962659, "train/extr_critic_mean": 2.8912719862304463, "train/extr_critic_min": -0.14693765744675685, "train/extr_critic_std": 2.565082979898383, "train/extr_return_normed_mag": 1.4263946574969883, "train/extr_return_normed_max": 1.4263946574969883, "train/extr_return_normed_mean": 0.34566278984076787, "train/extr_return_normed_min": -0.07542623170264011, "train/extr_return_normed_std": 0.321105941259948, "train/extr_return_rate": 0.8317894082869927, "train/extr_return_raw_mag": 11.608551331680186, "train/extr_return_raw_max": 11.608551331680186, "train/extr_return_raw_mean": 2.905546324966598, "train/extr_return_raw_min": -0.48410718866290836, "train/extr_return_raw_std": 2.5859776839722683, "train/extr_reward_mag": 1.0510354546734886, "train/extr_reward_max": 1.0510354546734886, "train/extr_reward_mean": 0.04848647105378391, "train/extr_reward_min": -0.470411981109285, "train/extr_reward_std": 0.20470379314718457, "train/image_loss_mean": 6.437560676658241, "train/image_loss_std": 11.975187935098244, "train/model_loss_mean": 14.433271060024735, "train/model_loss_std": 15.822559426300717, "train/model_opt_grad_norm": 47.77055596957241, "train/model_opt_grad_steps": 79229.55474452555, "train/model_opt_loss": 18325.61854185675, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1268.2481751824816, "train/policy_entropy_mag": 2.630933366552757, "train/policy_entropy_max": 2.630933366552757, "train/policy_entropy_mean": 0.6142370124367902, "train/policy_entropy_min": 0.0793750234437685, "train/policy_entropy_std": 0.7696315215451874, "train/policy_logprob_mag": 7.438383843776953, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.613855709559726, "train/policy_logprob_min": -7.438383843776953, "train/policy_logprob_std": 1.1478098043560112, "train/policy_randomness_mag": 0.9286040232999482, "train/policy_randomness_max": 0.9286040232999482, "train/policy_randomness_mean": 0.21679871273736884, "train/policy_randomness_min": 0.028015899995382686, "train/policy_randomness_std": 0.27164615135993403, "train/post_ent_mag": 61.41459524892542, "train/post_ent_max": 61.41459524892542, "train/post_ent_mean": 43.75582490350208, "train/post_ent_min": 20.58238156172481, "train/post_ent_std": 7.720600674622251, "train/prior_ent_mag": 71.24267132612911, "train/prior_ent_max": 71.24267132612911, "train/prior_ent_mean": 57.02106024749087, "train/prior_ent_min": 41.035350576804504, "train/prior_ent_std": 4.870948029260566, "train/rep_loss_mean": 13.221841220438046, "train/rep_loss_std": 9.416080836832089, "train/reward_avg": 0.03773736857204107, "train/reward_loss_mean": 0.062378079134182335, "train/reward_loss_std": 0.25518206468898885, "train/reward_max_data": 1.0233576698024778, "train/reward_max_pred": 1.014516847847152, "train/reward_neg_acc": 0.9915649799534875, "train/reward_neg_loss": 0.030481733483717823, "train/reward_pos_acc": 0.9782687965100699, "train/reward_pos_loss": 0.80218318692089, "train/reward_pred": 0.03714108265881991, "train/reward_rate": 0.04161439324817518, "train_stats/sum_log_reward": 11.186419957949791, "train_stats/max_log_achievement_collect_coal": 1.1975308641975309, "train_stats/max_log_achievement_collect_drink": 8.62962962962963, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 2.1728395061728394, "train_stats/max_log_achievement_collect_stone": 17.234567901234566, "train_stats/max_log_achievement_collect_wood": 11.666666666666666, "train_stats/max_log_achievement_defeat_skeleton": 0.14814814814814814, "train_stats/max_log_achievement_defeat_zombie": 1.2222222222222223, "train_stats/max_log_achievement_eat_cow": 0.2962962962962963, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.04938271604938271, "train_stats/max_log_achievement_make_stone_sword": 0.024691358024691357, "train_stats/max_log_achievement_make_wood_pickaxe": 1.8271604938271604, "train_stats/max_log_achievement_make_wood_sword": 1.5925925925925926, "train_stats/max_log_achievement_place_furnace": 2.6049382716049383, "train_stats/max_log_achievement_place_plant": 1.7407407407407407, "train_stats/max_log_achievement_place_stone": 4.54320987654321, "train_stats/max_log_achievement_place_table": 2.925925925925926, "train_stats/max_log_achievement_wake_up": 1.5185185185185186, "train_stats/mean_log_entropy": 0.6241806537648777, "eval_stats/sum_log_reward": 9.850000262260437, "eval_stats/max_log_achievement_collect_coal": 0.7083333333333334, "eval_stats/max_log_achievement_collect_drink": 5.833333333333333, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.4583333333333333, "eval_stats/max_log_achievement_collect_stone": 12.875, "eval_stats/max_log_achievement_collect_wood": 9.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.1666666666666667, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.4583333333333333, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 1.7083333333333333, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 3.8333333333333335, "eval_stats/max_log_achievement_place_table": 1.9583333333333333, "eval_stats/max_log_achievement_wake_up": 1.0416666666666667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.837051281152526e-06, "report/cont_loss_std": 4.195650399196893e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.0596678698202595e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.7057475310575683e-06, "report/cont_pred": 0.9951136708259583, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.673194885253906, "report/dyn_loss_std": 9.135623931884766, "report/image_loss_mean": 4.357592582702637, "report/image_loss_std": 10.0663423538208, "report/model_loss_mean": 12.02665901184082, "report/model_loss_std": 13.89548110961914, "report/post_ent_mag": 60.606468200683594, "report/post_ent_max": 60.606468200683594, "report/post_ent_mean": 43.15558624267578, "report/post_ent_min": 21.082439422607422, "report/post_ent_std": 7.617712020874023, "report/prior_ent_mag": 71.38375854492188, "report/prior_ent_max": 71.38375854492188, "report/prior_ent_mean": 56.26909255981445, "report/prior_ent_min": 41.01337432861328, "report/prior_ent_std": 4.895475387573242, "report/rep_loss_mean": 12.673194885253906, "report/rep_loss_std": 9.135623931884766, "report/reward_avg": 0.0502929650247097, "report/reward_loss_mean": 0.06514638662338257, "report/reward_loss_std": 0.24229080975055695, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0022938251495361, "report/reward_neg_acc": 0.9927685260772705, "report/reward_neg_loss": 0.02378331497311592, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7801365256309509, "report/reward_pred": 0.04711980000138283, "report/reward_rate": 0.0546875, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 2.79718142337515e-06, "eval/cont_loss_std": 2.0946949007338844e-05, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.79718142337515e-06, "eval/cont_pred": 0.9999971389770508, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 19.388721466064453, "eval/dyn_loss_std": 11.753056526184082, "eval/image_loss_mean": 16.449146270751953, "eval/image_loss_std": 20.986923217773438, "eval/model_loss_mean": 28.226795196533203, "eval/model_loss_std": 25.583354949951172, "eval/post_ent_mag": 61.5222282409668, "eval/post_ent_max": 61.5222282409668, "eval/post_ent_mean": 40.4752197265625, "eval/post_ent_min": 21.125797271728516, "eval/post_ent_std": 7.988641738891602, "eval/prior_ent_mag": 71.38375854492188, "eval/prior_ent_max": 71.38375854492188, "eval/prior_ent_mean": 56.99327087402344, "eval/prior_ent_min": 41.339359283447266, "eval/prior_ent_std": 4.576276779174805, "eval/rep_loss_mean": 19.388721466064453, "eval/rep_loss_std": 11.753056526184082, "eval/reward_avg": 0.05068359524011612, "eval/reward_loss_mean": 0.14441406726837158, "eval/reward_loss_std": 0.7919781804084778, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0913991928100586, "eval/reward_neg_acc": 0.985567033290863, "eval/reward_neg_loss": 0.04570900648832321, "eval/reward_pos_acc": 0.7407407760620117, "eval/reward_pos_loss": 1.917449712753296, "eval/reward_pred": 0.04065720736980438, "eval/reward_rate": 0.052734375, "replay/size": 1000000.0, "replay/inserts": 21968.0, "replay/samples": 21968.0, "replay/insert_wait_avg": 1.333279498545514e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.051945011891853e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 8072.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.284867022980311e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4528062343597, "timer/env.step_count": 2746.0, "timer/env.step_total": 207.83919095993042, "timer/env.step_frac": 0.20774512267322615, "timer/env.step_avg": 0.07568797922794261, "timer/env.step_min": 0.024357080459594727, "timer/env.step_max": 2.1744625568389893, "timer/replay._sample_count": 21968.0, "timer/replay._sample_total": 11.365160703659058, "timer/replay._sample_frac": 0.011360016817221787, "timer/replay._sample_avg": 0.0005173507239466067, "timer/replay._sample_min": 0.00042510032653808594, "timer/replay._sample_max": 0.01170969009399414, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3755.0, "timer/agent.policy_total": 65.5175244808197, "timer/agent.policy_frac": 0.06548787116448147, "timer/agent.policy_avg": 0.01744807576053787, "timer/agent.policy_min": 0.00976109504699707, "timer/agent.policy_max": 0.1730358600616455, "timer/dataset_train_count": 1373.0, "timer/dataset_train_total": 0.15543174743652344, "timer/dataset_train_frac": 0.00015536139882655592, "timer/dataset_train_avg": 0.00011320593403971117, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.005353450775146484, "timer/agent.train_count": 1373.0, "timer/agent.train_total": 617.3574934005737, "timer/agent.train_frac": 0.6170780766004024, "timer/agent.train_avg": 0.4496412916245985, "timer/agent.train_min": 0.43517565727233887, "timer/agent.train_max": 1.8633878231048584, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47479891777038574, "timer/agent.report_frac": 0.00047458402316596866, "timer/agent.report_avg": 0.23739945888519287, "timer/agent.report_min": 0.2308363914489746, "timer/agent.report_max": 0.24396252632141113, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.026545515911666e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 21.95776630753515}
{"step": 1281480, "time": 58406.7391872406, "episode/length": 128.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 1281840, "time": 58420.70789551735, "episode/length": 192.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 1281912, "time": 58424.53338623047, "episode/length": 199.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 1282440, "time": 58444.001115083694, "episode/length": 238.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 1283120, "time": 58468.987983226776, "episode/length": 204.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9658536585365853, "episode/intrinsic_return": 0.0}
{"step": 1283304, "time": 58476.63884806633, "episode/length": 173.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 1283408, "time": 58482.5825946331, "episode/length": 195.0, "episode/score": 11.100000038743019, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 1283568, "time": 58489.634001493454, "episode/length": 345.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9884393063583815, "episode/intrinsic_return": 0.0}
{"step": 1283872, "time": 58501.366582632065, "episode/length": 410.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9975669099756691, "episode/intrinsic_return": 0.0}
{"step": 1284680, "time": 58530.05759859085, "episode/length": 438.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9931662870159453, "episode/intrinsic_return": 0.0}
{"step": 1284816, "time": 58536.55269241333, "episode/length": 296.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9764309764309764, "episode/intrinsic_return": 0.0}
{"step": 1284832, "time": 58538.636848688126, "episode/length": 544.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.998165137614679, "episode/intrinsic_return": 0.0}
{"step": 1284904, "time": 58542.50385761261, "episode/length": 222.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 1284920, "time": 58544.72339248657, "episode/length": 168.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 1284992, "time": 58549.219173908234, "episode/length": 210.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1285720, "time": 58575.22954106331, "episode/length": 230.0, "episode/score": 10.100000038743019, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 1285768, "time": 58578.683641433716, "episode/length": 135.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 1286456, "time": 58605.51292729378, "episode/length": 204.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 1286584, "time": 58611.65984630585, "episode/length": 198.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 1286624, "time": 58614.78145647049, "episode/length": 212.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 1286688, "time": 58618.597586393356, "episode/length": 222.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 1287288, "time": 58640.312208652496, "episode/length": 82.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.927710843373494, "episode/intrinsic_return": 0.0}
{"step": 1287480, "time": 58648.43214559555, "episode/length": 219.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 1287616, "time": 58654.81270337105, "episode/length": 347.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9971264367816092, "episode/intrinsic_return": 0.0}
{"step": 1287816, "time": 58662.84648394585, "episode/length": 153.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 1288368, "time": 58683.31538748741, "episode/length": 324.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9815384615384616, "episode/intrinsic_return": 0.0}
{"step": 1288672, "time": 58695.33229517937, "episode/length": 657.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9984802431610942, "episode/intrinsic_return": 0.0}
{"step": 1288712, "time": 58698.27813768387, "episode/length": 281.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 1288864, "time": 58705.27894997597, "episode/length": 172.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 1289016, "time": 58711.80195689201, "episode/length": 174.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 1289112, "time": 58716.70310306549, "episode/length": 161.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 1289360, "time": 58726.992564201355, "episode/length": 258.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 1289840, "time": 58744.74105834961, "episode/length": 393.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9974619289340102, "episode/intrinsic_return": 0.0}
{"step": 1290016, "time": 58767.37089467049, "eval_episode/length": 43.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 1290016, "time": 58774.08078575134, "eval_episode/length": 163.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 1290016, "time": 58778.23774409294, "eval_episode/length": 218.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 1290016, "time": 58780.08606362343, "eval_episode/length": 225.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.995575221238938}
{"step": 1290016, "time": 58782.78558945656, "eval_episode/length": 249.0, "eval_episode/score": 13.100000023841858, "eval_episode/reward_rate": 0.996}
{"step": 1290016, "time": 58786.485288619995, "eval_episode/length": 293.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 1290016, "time": 58789.578316926956, "eval_episode/length": 281.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9964539007092199}
{"step": 1290016, "time": 58794.280824422836, "eval_episode/length": 394.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9974683544303797}
{"step": 1290344, "time": 58805.198325395584, "episode/length": 165.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 1290352, "time": 58807.4265332222, "episode/length": 185.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 1290520, "time": 58814.50343751907, "episode/length": 225.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 1290992, "time": 58832.410521030426, "episode/length": 289.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 1291312, "time": 58844.87624311447, "episode/length": 274.0, "episode/score": 13.100000016391277, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 1292040, "time": 58870.81503844261, "episode/length": 211.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 1292112, "time": 58875.14186310768, "episode/length": 139.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 1292304, "time": 58883.28286409378, "episode/length": 491.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9979674796747967, "episode/intrinsic_return": 0.0}
{"step": 1292536, "time": 58892.445205926895, "episode/length": 61.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 1292560, "time": 58895.09656214714, "episode/length": 155.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 1292648, "time": 58899.41497993469, "episode/length": 410.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 1292920, "time": 58910.343368291855, "episode/length": 384.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9896103896103896, "episode/intrinsic_return": 0.0}
{"step": 1293064, "time": 58916.64559364319, "episode/length": 317.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9968553459119497, "episode/intrinsic_return": 0.0}
{"step": 1293544, "time": 58934.31985116005, "episode/length": 77.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 1293952, "time": 58949.95658946037, "episode/length": 449.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9977777777777778, "episode/intrinsic_return": 0.0}
{"step": 1294096, "time": 58956.421115636826, "episode/length": 223.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1294232, "time": 58962.465925216675, "episode/length": 264.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 1294456, "time": 58973.503762960434, "episode/length": 239.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 1294640, "time": 58981.49379324913, "episode/length": 259.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9730769230769231, "episode/intrinsic_return": 0.0}
{"step": 1294928, "time": 58992.782044649124, "episode/length": 58.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 1295248, "time": 59005.2931470871, "episode/length": 272.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 1295256, "time": 59006.908296108246, "episode/length": 325.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 1295320, "time": 59010.73818182945, "episode/length": 221.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 1295592, "time": 59021.30152153969, "episode/length": 204.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 1296456, "time": 59052.11483216286, "episode/length": 190.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 1296904, "time": 59068.95365381241, "episode/length": 197.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 1297008, "time": 59074.445143938065, "episode/length": 176.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 1297128, "time": 59080.36649298668, "episode/length": 378.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9947229551451188, "episode/intrinsic_return": 0.0}
{"step": 1297232, "time": 59086.2171061039, "episode/length": 323.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9969135802469136, "episode/intrinsic_return": 0.0}
{"step": 1297264, "time": 59088.90827083588, "episode/length": 378.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9894459102902374, "episode/intrinsic_return": 0.0}
{"step": 1298160, "time": 59120.65191578865, "episode/length": 212.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 1298512, "time": 59134.13439536095, "episode/length": 406.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9852579852579852, "episode/intrinsic_return": 0.0}
{"step": 1298688, "time": 59141.70310020447, "episode/length": 429.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9976744186046511, "episode/intrinsic_return": 0.0}
{"step": 1298960, "time": 59152.5109000206, "episode/length": 215.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 1298960, "time": 59152.51940822601, "episode/length": 228.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 1299000, "time": 59156.9899764061, "episode/length": 104.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 1299088, "time": 59161.796568632126, "episode/length": 272.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 1299280, "time": 59169.7793238163, "episode/length": 251.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 1299328, "time": 59173.10217452049, "episode/length": 40.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 1300000, "time": 59218.78392291069, "eval_episode/length": 170.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9649122807017544}
{"step": 1300000, "time": 59220.82243704796, "eval_episode/length": 179.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 1300000, "time": 59222.84384012222, "eval_episode/length": 189.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9789473684210527}
{"step": 1300000, "time": 59224.542686223984, "eval_episode/length": 190.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 1300000, "time": 59226.31076335907, "eval_episode/length": 193.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 1300000, "time": 59233.058419942856, "eval_episode/length": 118.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9663865546218487}
{"step": 1300000, "time": 59235.69666099548, "eval_episode/length": 160.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9565217391304348}
{"step": 1300000, "time": 59241.29675102234, "eval_episode/length": 217.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 1300144, "time": 59246.18055129051, "episode/length": 203.0, "episode/score": 13.099999971687794, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 1300192, "time": 59249.425438165665, "episode/length": 397.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9899497487437185, "episode/intrinsic_return": 0.0}
{"step": 1300664, "time": 59266.82221078873, "episode/length": 196.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 1300880, "time": 59275.92145013809, "episode/length": 239.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 1301088, "time": 59284.58655548096, "episode/length": 299.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9766666666666667, "episode/intrinsic_return": 0.0}
{"step": 1301200, "time": 59289.93013238907, "episode/length": 233.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 1301384, "time": 59297.6185605526, "episode/length": 302.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 1301440, "time": 59301.36492586136, "episode/length": 43.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 1301720, "time": 59312.16758608818, "episode/length": 196.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 1301728, "time": 59314.47152018547, "episode/length": 191.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 1302024, "time": 59325.68255996704, "episode/length": 342.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9970845481049563, "episode/intrinsic_return": 0.0}
{"step": 1302416, "time": 59340.965953588486, "episode/length": 218.0, "episode/score": 13.099999964237213, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 1302800, "time": 59357.41076040268, "episode/length": 176.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 1302920, "time": 59362.871777296066, "episode/length": 184.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 1303112, "time": 59370.9208676815, "episode/length": 238.0, "episode/score": 13.099999971687794, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 1303904, "time": 59399.45094370842, "episode/length": 122.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.991869918699187, "episode/intrinsic_return": 0.0}
{"step": 1303905, "time": 59401.55464601517, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.637906554742908, "train/action_min": 0.0, "train/action_std": 3.4333345754772213, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.029534403313981727, "train/actor_opt_grad_steps": 80690.0, "train/actor_opt_loss": -7.482257126995647, "train/adv_mag": 0.4146862947349007, "train/adv_max": 0.3718676214099776, "train/adv_mean": 0.002102311158849403, "train/adv_min": -0.33812880516052246, "train/adv_std": 0.04394267883865123, "train/cont_avg": 0.9956297096631206, "train/cont_loss_mean": 0.0002380363627860382, "train/cont_loss_std": 0.007324459449076191, "train/cont_neg_acc": 0.9885736805327395, "train/cont_neg_loss": 0.03928767478194633, "train/cont_pos_acc": 0.999972162939978, "train/cont_pos_loss": 0.00011830260629185044, "train/cont_pred": 0.9956279029237464, "train/cont_rate": 0.9956297096631206, "train/dyn_loss_mean": 13.183229967212, "train/dyn_loss_std": 9.413887443271934, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.988787202547628, "train/extr_critic_critic_opt_grad_steps": 80690.0, "train/extr_critic_critic_opt_loss": 14933.053641677749, "train/extr_critic_mag": 10.637405503726175, "train/extr_critic_max": 10.637405503726175, "train/extr_critic_mean": 2.890429157737299, "train/extr_critic_min": -0.13780778857833104, "train/extr_critic_std": 2.5414279487961573, "train/extr_return_normed_mag": 1.4651387050642188, "train/extr_return_normed_max": 1.4651387050642188, "train/extr_return_normed_mean": 0.3514612153278175, "train/extr_return_normed_min": -0.07193636627379038, "train/extr_return_normed_std": 0.3266471563078833, "train/extr_return_rate": 0.8379502321811433, "train/extr_return_raw_mag": 11.661098933389, "train/extr_return_raw_max": 11.661098933389, "train/extr_return_raw_mean": 2.906959170990802, "train/extr_return_raw_min": -0.42192154837415574, "train/extr_return_raw_std": 2.5681438361499325, "train/extr_reward_mag": 1.048955465884919, "train/extr_reward_max": 1.048955465884919, "train/extr_reward_mean": 0.048100274214719206, "train/extr_reward_min": -0.4551315933254594, "train/extr_reward_std": 0.2041595681762019, "train/image_loss_mean": 6.600091487803358, "train/image_loss_std": 11.860687742842005, "train/model_loss_mean": 14.572985419144867, "train/model_loss_std": 15.7170773228855, "train/model_opt_grad_norm": 49.80391829740917, "train/model_opt_grad_steps": 80618.29787234042, "train/model_opt_loss": 18608.63626163564, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1276.595744680851, "train/policy_entropy_mag": 2.649800074015949, "train/policy_entropy_max": 2.649800074015949, "train/policy_entropy_mean": 0.6866008990199853, "train/policy_entropy_min": 0.07937502052555694, "train/policy_entropy_std": 0.8467007862760666, "train/policy_logprob_mag": 7.438383843036408, "train/policy_logprob_max": -0.009455660080656092, "train/policy_logprob_mean": -0.6869264908716188, "train/policy_logprob_min": -7.438383843036408, "train/policy_logprob_std": 1.1942153902764017, "train/policy_randomness_mag": 0.9352631446317579, "train/policy_randomness_max": 0.9352631446317579, "train/policy_randomness_mean": 0.24233998886659636, "train/policy_randomness_min": 0.028015898976554262, "train/policy_randomness_std": 0.2988482200084849, "train/post_ent_mag": 61.314461484868474, "train/post_ent_max": 61.314461484868474, "train/post_ent_mean": 43.78210002818006, "train/post_ent_min": 20.17705813198225, "train/post_ent_std": 7.709875620848743, "train/prior_ent_mag": 71.31635446751372, "train/prior_ent_max": 71.31635446751372, "train/prior_ent_mean": 57.02780846670164, "train/prior_ent_min": 40.9495011999252, "train/prior_ent_std": 4.92674928015851, "train/rep_loss_mean": 13.183229967212, "train/rep_loss_std": 9.413887443271934, "train/reward_avg": 0.038417691450750996, "train/reward_loss_mean": 0.06271796522939459, "train/reward_loss_std": 0.25867327339683016, "train/reward_max_data": 1.0241134809264054, "train/reward_max_pred": 1.0125746084443221, "train/reward_neg_acc": 0.9915845212361492, "train/reward_neg_loss": 0.030441224403309482, "train/reward_pos_acc": 0.9783836861028739, "train/reward_pos_loss": 0.8017305182227006, "train/reward_pred": 0.03777219318778168, "train/reward_rate": 0.042213818705673756, "train_stats/sum_log_reward": 11.009091165932743, "train_stats/max_log_achievement_collect_coal": 1.1363636363636365, "train_stats/max_log_achievement_collect_drink": 7.113636363636363, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.9772727272727273, "train_stats/max_log_achievement_collect_stone": 14.522727272727273, "train_stats/max_log_achievement_collect_wood": 9.636363636363637, "train_stats/max_log_achievement_defeat_skeleton": 0.1590909090909091, "train_stats/max_log_achievement_defeat_zombie": 1.3181818181818181, "train_stats/max_log_achievement_eat_cow": 0.375, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.011363636363636364, "train_stats/max_log_achievement_make_stone_sword": 0.022727272727272728, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5454545454545454, "train_stats/max_log_achievement_make_wood_sword": 1.0, "train_stats/max_log_achievement_place_furnace": 2.1363636363636362, "train_stats/max_log_achievement_place_plant": 1.5568181818181819, "train_stats/max_log_achievement_place_stone": 4.25, "train_stats/max_log_achievement_place_table": 2.284090909090909, "train_stats/max_log_achievement_wake_up": 1.6931818181818181, "train_stats/mean_log_entropy": 0.5907046918503263, "eval_stats/sum_log_reward": 10.53750029206276, "eval_stats/max_log_achievement_collect_coal": 1.5, "eval_stats/max_log_achievement_collect_drink": 5.625, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 15.1875, "eval_stats/max_log_achievement_collect_wood": 8.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.9375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.3125, "eval_stats/max_log_achievement_make_wood_sword": 0.8125, "eval_stats/max_log_achievement_place_furnace": 2.4375, "eval_stats/max_log_achievement_place_plant": 1.1875, "eval_stats/max_log_achievement_place_stone": 3.3125, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 9.95377831713995e-06, "report/cont_loss_std": 0.0002095467789331451, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0013638040982186794, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.352408945531351e-07, "report/cont_pred": 0.993172824382782, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.100324630737305, "report/dyn_loss_std": 9.351333618164062, "report/image_loss_mean": 7.334897994995117, "report/image_loss_std": 11.23391056060791, "report/model_loss_mean": 15.271074295043945, "report/model_loss_std": 15.129748344421387, "report/post_ent_mag": 62.79505920410156, "report/post_ent_max": 62.79505920410156, "report/post_ent_mean": 44.10138702392578, "report/post_ent_min": 22.27166748046875, "report/post_ent_std": 7.890030860900879, "report/prior_ent_mag": 71.36643981933594, "report/prior_ent_max": 71.36643981933594, "report/prior_ent_mean": 57.32469940185547, "report/prior_ent_min": 40.99915313720703, "report/prior_ent_std": 4.9150309562683105, "report/rep_loss_mean": 13.100324630737305, "report/rep_loss_std": 9.351333618164062, "report/reward_avg": 0.03544921800494194, "report/reward_loss_mean": 0.07597170770168304, "report/reward_loss_std": 0.2981022596359253, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9994136095046997, "report/reward_neg_acc": 0.9918534159660339, "report/reward_neg_loss": 0.04057527333498001, "report/reward_pos_acc": 0.9523809552192688, "report/reward_pos_loss": 0.9035741090774536, "report/reward_pred": 0.033072154968976974, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0002572557423263788, "eval/cont_loss_std": 0.006451619789004326, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.04940970242023468, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 6.450105138355866e-05, "eval/cont_pred": 0.9962069988250732, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.3422794342041, "eval/dyn_loss_std": 11.517797470092773, "eval/image_loss_mean": 8.69111442565918, "eval/image_loss_std": 13.245124816894531, "eval/model_loss_mean": 19.21253204345703, "eval/model_loss_std": 17.897859573364258, "eval/post_ent_mag": 60.637046813964844, "eval/post_ent_max": 60.637046813964844, "eval/post_ent_mean": 41.27188491821289, "eval/post_ent_min": 18.860090255737305, "eval/post_ent_std": 7.708650588989258, "eval/prior_ent_mag": 71.36643981933594, "eval/prior_ent_max": 71.36643981933594, "eval/prior_ent_mean": 56.83598327636719, "eval/prior_ent_min": 41.10651397705078, "eval/prior_ent_std": 5.266397476196289, "eval/rep_loss_mean": 17.3422794342041, "eval/rep_loss_std": 11.517797470092773, "eval/reward_avg": 0.08291015774011612, "eval/reward_loss_mean": 0.1157936155796051, "eval/reward_loss_std": 0.5205998420715332, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.999992847442627, "eval/reward_neg_acc": 0.9914621114730835, "eval/reward_neg_loss": 0.02656250260770321, "eval/reward_pos_acc": 0.931034505367279, "eval/reward_pos_loss": 1.0768228769302368, "eval/reward_pred": 0.07532903552055359, "eval/reward_rate": 0.0849609375, "replay/size": 1000000.0, "replay/inserts": 22600.0, "replay/samples": 22592.0, "replay/insert_wait_avg": 1.350113775877826e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.139178874472383e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6456.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2477829849262073e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.5183637142181, "timer/env.step_count": 2825.0, "timer/env.step_total": 223.17685198783875, "timer/env.step_frac": 0.22306122514267573, "timer/env.step_avg": 0.07900065557091637, "timer/env.step_min": 0.024456262588500977, "timer/env.step_max": 3.354628324508667, "timer/replay._sample_count": 22592.0, "timer/replay._sample_total": 11.665585041046143, "timer/replay._sample_frac": 0.01165954115798541, "timer/replay._sample_avg": 0.0005163591112361075, "timer/replay._sample_min": 0.00041413307189941406, "timer/replay._sample_max": 0.028717756271362305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3632.0, "timer/agent.policy_total": 62.229551792144775, "timer/agent.policy_frac": 0.06219731096301961, "timer/agent.policy_avg": 0.017133687167440743, "timer/agent.policy_min": 0.009818077087402344, "timer/agent.policy_max": 0.1288437843322754, "timer/dataset_train_count": 1412.0, "timer/dataset_train_total": 0.15314316749572754, "timer/dataset_train_frac": 0.00015306382476301095, "timer/dataset_train_avg": 0.00010845833392048692, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0005736351013183594, "timer/agent.train_count": 1412.0, "timer/agent.train_total": 637.2833216190338, "timer/agent.train_frac": 0.6369531482193399, "timer/agent.train_avg": 0.45133379718061883, "timer/agent.train_min": 0.437396764755249, "timer/agent.train_max": 1.9162070751190186, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47053027153015137, "timer/agent.report_frac": 0.0004702864920773715, "timer/agent.report_avg": 0.23526513576507568, "timer/agent.report_min": 0.2279658317565918, "timer/agent.report_max": 0.24256443977355957, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.883370172656742e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 22.58796123077075}
{"step": 1304056, "time": 59406.68293213844, "episode/length": 396.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9974811083123426, "episode/intrinsic_return": 0.0}
{"step": 1304128, "time": 59410.93420410156, "episode/length": 165.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 1304344, "time": 59419.698390483856, "episode/length": 240.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 1304464, "time": 59425.45782160759, "episode/length": 304.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9967213114754099, "episode/intrinsic_return": 0.0}
{"step": 1304608, "time": 59431.98296523094, "episode/length": 359.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9972222222222222, "episode/intrinsic_return": 0.0}
{"step": 1304648, "time": 59435.14257645607, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 1305488, "time": 59465.17741918564, "episode/length": 470.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9915074309978769, "episode/intrinsic_return": 0.0}
{"step": 1305840, "time": 59478.85830807686, "episode/length": 148.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 1305952, "time": 59484.233506441116, "episode/length": 227.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1306224, "time": 59494.90678906441, "episode/length": 289.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 1306376, "time": 59501.34094309807, "episode/length": 289.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 1307288, "time": 59533.7620780468, "episode/length": 334.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9880597014925373, "episode/intrinsic_return": 0.0}
{"step": 1307408, "time": 59539.72024679184, "episode/length": 195.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 1307792, "time": 59554.427884340286, "episode/length": 287.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 1307976, "time": 59562.08669900894, "episode/length": 453.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 1308856, "time": 59593.5104238987, "episode/length": 309.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 1308888, "time": 59596.26923418045, "episode/length": 366.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9945504087193461, "episode/intrinsic_return": 0.0}
{"step": 1309352, "time": 59613.513171195984, "episode/length": 194.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 1309408, "time": 59617.27593135834, "episode/length": 617.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 1309744, "time": 59630.34349489212, "episode/length": 291.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.976027397260274, "episode/intrinsic_return": 0.0}
{"step": 1309752, "time": 59631.94350385666, "episode/length": 111.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 1309776, "time": 59634.68658566475, "episode/length": 224.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1309840, "time": 59638.33979010582, "episode/length": 318.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9968652037617555, "episode/intrinsic_return": 0.0}
{"step": 1310008, "time": 59645.38908934593, "episode/length": 74.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1310088, "time": 59674.36510300636, "eval_episode/length": 190.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9790575916230366}
{"step": 1310088, "time": 59676.02734589577, "eval_episode/length": 191.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 1310088, "time": 59678.364258527756, "eval_episode/length": 207.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 1310088, "time": 59680.300095796585, "eval_episode/length": 213.0, "eval_episode/score": 12.100000016391277, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 1310088, "time": 59682.24058818817, "eval_episode/length": 222.0, "eval_episode/score": 12.100000031292439, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 1310088, "time": 59684.29746365547, "eval_episode/length": 232.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 1310088, "time": 59686.51842999458, "eval_episode/length": 242.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 1310088, "time": 59692.076323509216, "eval_episode/length": 108.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9541284403669725}
{"step": 1310328, "time": 59700.12796163559, "episode/length": 512.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9922027290448343, "episode/intrinsic_return": 0.0}
{"step": 1311224, "time": 59734.00407576561, "episode/length": 111.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 1311704, "time": 59752.0781083107, "episode/length": 351.0, "episode/score": 13.099999979138374, "episode/reward_rate": 0.9971590909090909, "episode/intrinsic_return": 0.0}
{"step": 1311720, "time": 59754.170998096466, "episode/length": 246.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 1312080, "time": 59768.11286497116, "episode/length": 340.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9853372434017595, "episode/intrinsic_return": 0.0}
{"step": 1312256, "time": 59775.66840457916, "episode/length": 301.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9801324503311258, "episode/intrinsic_return": 0.0}
{"step": 1312632, "time": 59789.7938888073, "episode/length": 175.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 1312800, "time": 59797.25148296356, "episode/length": 380.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.979002624671916, "episode/intrinsic_return": 0.0}
{"step": 1313320, "time": 59816.2051281929, "episode/length": 442.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9796839729119639, "episode/intrinsic_return": 0.0}
{"step": 1313424, "time": 59821.605348825455, "episode/length": 426.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9882903981264637, "episode/intrinsic_return": 0.0}
{"step": 1313520, "time": 59826.46050977707, "episode/length": 226.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 1313800, "time": 59837.54503273964, "episode/length": 214.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 1313896, "time": 59842.45166826248, "episode/length": 204.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 1314464, "time": 59863.32389545441, "episode/length": 228.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 1315048, "time": 59884.657395124435, "episode/length": 280.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9750889679715302, "episode/intrinsic_return": 0.0}
{"step": 1315080, "time": 59887.246643066406, "episode/length": 219.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 1315160, "time": 59891.590252161026, "episode/length": 429.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 1315352, "time": 59899.739376306534, "episode/length": 181.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 1315416, "time": 59903.402396440506, "episode/length": 236.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 1316312, "time": 59935.381616830826, "episode/length": 157.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 1316512, "time": 59943.93349766731, "episode/length": 255.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.96484375, "episode/intrinsic_return": 0.0}
{"step": 1316656, "time": 59950.31203007698, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 1316704, "time": 59953.57731103897, "episode/length": 48.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9387755102040817, "episode/intrinsic_return": 0.0}
{"step": 1316768, "time": 59957.482025146484, "episode/length": 210.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 1316920, "time": 59963.84886431694, "episode/length": 187.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 1317008, "time": 59968.64031004906, "episode/length": 206.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 1317704, "time": 59993.501808166504, "episode/length": 487.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9815573770491803, "episode/intrinsic_return": 0.0}
{"step": 1317952, "time": 60003.749394893646, "episode/length": 147.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 1318024, "time": 60007.529067993164, "episode/length": 188.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 1318672, "time": 60031.34199619293, "episode/length": 207.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 1318888, "time": 60039.950959444046, "episode/length": 682.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9970717423133236, "episode/intrinsic_return": 0.0}
{"step": 1319152, "time": 60052.63325166702, "episode/length": 278.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 1319344, "time": 60060.712968587875, "episode/length": 204.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 1319528, "time": 60068.38523316383, "episode/length": 358.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9860724233983287, "episode/intrinsic_return": 0.0}
{"step": 1320072, "time": 60103.94264101982, "eval_episode/length": 56.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 1320072, "time": 60110.154181957245, "eval_episode/length": 157.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 1320072, "time": 60111.82597446442, "eval_episode/length": 159.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9625}
{"step": 1320072, "time": 60113.79053902626, "eval_episode/length": 112.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9911504424778761}
{"step": 1320072, "time": 60115.852926015854, "eval_episode/length": 180.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.994475138121547}
{"step": 1320072, "time": 60117.768507003784, "eval_episode/length": 187.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 1320072, "time": 60121.14070367813, "eval_episode/length": 226.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 1320072, "time": 60125.19881081581, "eval_episode/length": 280.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9857651245551602}
{"step": 1320408, "time": 60136.599089860916, "episode/length": 297.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 1320976, "time": 60157.72772073746, "episode/length": 377.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 1321176, "time": 60165.810225725174, "episode/length": 205.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 1321240, "time": 60169.645370960236, "episode/length": 32.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 1321384, "time": 60176.067276239395, "episode/length": 278.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 1321656, "time": 60186.763939619064, "episode/length": 345.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9855491329479769, "episode/intrinsic_return": 0.0}
{"step": 1321800, "time": 60193.34100794792, "episode/length": 636.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9858712715855573, "episode/intrinsic_return": 0.0}
{"step": 1321928, "time": 60199.42188882828, "episode/length": 189.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 1321968, "time": 60202.58534550667, "episode/length": 327.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9847560975609756, "episode/intrinsic_return": 0.0}
{"step": 1322512, "time": 60222.52015662193, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 1323136, "time": 60245.331515073776, "episode/length": 218.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 1323704, "time": 60266.034252882004, "episode/length": 216.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1323736, "time": 60268.69804286957, "episode/length": 241.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9710743801652892, "episode/intrinsic_return": 0.0}
{"step": 1323952, "time": 60277.78658628464, "episode/length": 252.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 1323976, "time": 60280.000193595886, "episode/length": 662.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9834087481146304, "episode/intrinsic_return": 0.0}
{"step": 1324024, "time": 60283.17038011551, "episode/length": 188.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 1324040, "time": 60285.3843061924, "episode/length": 349.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9914285714285714, "episode/intrinsic_return": 0.0}
{"step": 1324680, "time": 60308.56133675575, "episode/length": 81.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9512195121951219, "episode/intrinsic_return": 0.0}
{"step": 1324936, "time": 60318.91883444786, "episode/length": 224.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1325104, "time": 60326.384850502014, "episode/length": 430.0, "episode/score": 13.099999979138374, "episode/reward_rate": 0.9976798143851509, "episode/intrinsic_return": 0.0}
{"step": 1325280, "time": 60333.91673231125, "episode/length": 192.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 1325456, "time": 60341.54570364952, "episode/length": 187.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 1325968, "time": 60360.52710390091, "episode/length": 63.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 1326552, "time": 60381.693064928055, "episode/length": 201.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 1326656, "time": 60387.0864713192, "episode/length": 193.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 1327017, "time": 60401.68792295456, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.589383250269397, "train/action_min": 0.0, "train/action_std": 3.4286425261661924, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.029012900154138432, "train/actor_opt_grad_steps": 82120.0, "train/actor_opt_loss": -5.971604272620431, "train/adv_mag": 0.40346983003205267, "train/adv_max": 0.3662532186713712, "train/adv_mean": 0.0020836208534217742, "train/adv_min": -0.32594098839266544, "train/adv_std": 0.043322755511978575, "train/cont_avg": 0.9956492456896552, "train/cont_loss_mean": 0.00020867250042142822, "train/cont_loss_std": 0.006431366273407015, "train/cont_neg_acc": 0.9945254875740535, "train/cont_neg_loss": 0.022067416097740187, "train/cont_pos_acc": 0.999972915649414, "train/cont_pos_loss": 9.561515552708646e-05, "train/cont_pred": 0.9956494664323741, "train/cont_rate": 0.9956492456896552, "train/dyn_loss_mean": 13.044159869489999, "train/dyn_loss_std": 9.39326787488214, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0237850476955546, "train/extr_critic_critic_opt_grad_steps": 82120.0, "train/extr_critic_critic_opt_loss": 15143.643318965518, "train/extr_critic_mag": 10.768333369287951, "train/extr_critic_max": 10.768333369287951, "train/extr_critic_mean": 2.8343654829880287, "train/extr_critic_min": -0.15038442365054427, "train/extr_critic_std": 2.5824432619686783, "train/extr_return_normed_mag": 1.4529373530683847, "train/extr_return_normed_max": 1.4529373530683847, "train/extr_return_normed_mean": 0.3421804016006404, "train/extr_return_normed_min": -0.06974224426366132, "train/extr_return_normed_std": 0.32483680556560385, "train/extr_return_rate": 0.813442929859819, "train/extr_return_raw_mag": 11.771550132488382, "train/extr_return_raw_max": 11.771550132488382, "train/extr_return_raw_mean": 2.851108262456697, "train/extr_return_raw_min": -0.4572939082466323, "train/extr_return_raw_std": 2.6090239483734656, "train/extr_reward_mag": 1.0428158595644195, "train/extr_reward_max": 1.0428158595644195, "train/extr_reward_mean": 0.04760171390812973, "train/extr_reward_min": -0.44813344643033787, "train/extr_reward_std": 0.20288627723167682, "train/image_loss_mean": 6.452560944392763, "train/image_loss_std": 12.093076021917936, "train/model_loss_mean": 14.34228190718026, "train/model_loss_std": 15.937791409985772, "train/model_opt_grad_norm": 49.67975719769796, "train/model_opt_grad_steps": 82046.86896551723, "train/model_opt_loss": 19592.859334590517, "train/model_opt_model_opt_grad_overflow": 0.006896551724137931, "train/model_opt_model_opt_grad_scale": 1362.0689655172414, "train/policy_entropy_mag": 2.6436389972423684, "train/policy_entropy_max": 2.6436389972423684, "train/policy_entropy_mean": 0.6853617522223242, "train/policy_entropy_min": 0.07937501658653391, "train/policy_entropy_std": 0.8416036511289662, "train/policy_logprob_mag": 7.438383881799106, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6845582822273517, "train/policy_logprob_min": -7.438383881799106, "train/policy_logprob_std": 1.1910043412241442, "train/policy_randomness_mag": 0.9330885554182118, "train/policy_randomness_max": 0.9330885554182118, "train/policy_randomness_mean": 0.24190262350542793, "train/policy_randomness_min": 0.028015897628562204, "train/policy_randomness_std": 0.2970491564479367, "train/post_ent_mag": 61.4805853745033, "train/post_ent_max": 61.4805853745033, "train/post_ent_mean": 43.91234167690935, "train/post_ent_min": 20.54528834902007, "train/post_ent_std": 7.763745646641172, "train/prior_ent_mag": 71.16596232447131, "train/prior_ent_max": 71.16596232447131, "train/prior_ent_mean": 57.042228988121295, "train/prior_ent_min": 40.534809559789196, "train/prior_ent_std": 4.8932539084862015, "train/rep_loss_mean": 13.044159869489999, "train/rep_loss_std": 9.39326787488214, "train/reward_avg": 0.03807314115993936, "train/reward_loss_mean": 0.0630165246283186, "train/reward_loss_std": 0.2599180206142623, "train/reward_max_data": 1.024137936789414, "train/reward_max_pred": 1.0178377135046597, "train/reward_neg_acc": 0.9919340244654952, "train/reward_neg_loss": 0.030243081368249037, "train/reward_pos_acc": 0.9740690190216591, "train/reward_pos_loss": 0.8145099870089827, "train/reward_pred": 0.03700462375478498, "train/reward_rate": 0.04185748922413793, "train_stats/sum_log_reward": 11.05180742079953, "train_stats/max_log_achievement_collect_coal": 0.9156626506024096, "train_stats/max_log_achievement_collect_drink": 7.072289156626506, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.9518072289156627, "train_stats/max_log_achievement_collect_stone": 17.40963855421687, "train_stats/max_log_achievement_collect_wood": 11.204819277108435, "train_stats/max_log_achievement_defeat_skeleton": 0.13253012048192772, "train_stats/max_log_achievement_defeat_zombie": 1.1927710843373494, "train_stats/max_log_achievement_eat_cow": 0.40963855421686746, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.012048192771084338, "train_stats/max_log_achievement_make_stone_sword": 0.012048192771084338, "train_stats/max_log_achievement_make_wood_pickaxe": 2.036144578313253, "train_stats/max_log_achievement_make_wood_sword": 1.144578313253012, "train_stats/max_log_achievement_place_furnace": 2.433734939759036, "train_stats/max_log_achievement_place_plant": 1.5783132530120483, "train_stats/max_log_achievement_place_stone": 5.421686746987952, "train_stats/max_log_achievement_place_table": 2.602409638554217, "train_stats/max_log_achievement_wake_up": 1.8674698795180722, "train_stats/mean_log_entropy": 0.6476400440715882, "eval_stats/sum_log_reward": 10.350000232458115, "eval_stats/max_log_achievement_collect_coal": 0.8125, "eval_stats/max_log_achievement_collect_drink": 5.125, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 15.0625, "eval_stats/max_log_achievement_collect_wood": 7.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.0625, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.4375, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_furnace": 2.375, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 3.1875, "eval_stats/max_log_achievement_place_table": 1.9375, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 1.1808435829152586e-06, "report/cont_loss_std": 1.214520580106182e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.442241207580082e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.1727679520845413e-06, "report/cont_pred": 0.999022364616394, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 11.666720390319824, "report/dyn_loss_std": 9.43380355834961, "report/image_loss_mean": 5.569980621337891, "report/image_loss_std": 12.699943542480469, "report/model_loss_mean": 12.618995666503906, "report/model_loss_std": 16.110170364379883, "report/post_ent_mag": 63.21827697753906, "report/post_ent_max": 63.21827697753906, "report/post_ent_mean": 45.56804656982422, "report/post_ent_min": 22.429306030273438, "report/post_ent_std": 8.130025863647461, "report/prior_ent_mag": 71.15095520019531, "report/prior_ent_max": 71.15095520019531, "report/prior_ent_mean": 56.865013122558594, "report/prior_ent_min": 33.92424011230469, "report/prior_ent_std": 5.402123928070068, "report/rep_loss_mean": 11.666720390319824, "report/rep_loss_std": 9.43380355834961, "report/reward_avg": 0.033203125, "report/reward_loss_mean": 0.04898218810558319, "report/reward_loss_std": 0.18042011559009552, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002995252609253, "report/reward_neg_acc": 0.9838219285011292, "report/reward_neg_loss": 0.026347730308771133, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6885673403739929, "report/reward_pred": 0.03478910028934479, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 8.678829885866435e-07, "eval/cont_loss_std": 9.295402378484141e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.028956648951862e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.586731610193965e-07, "eval/cont_pred": 0.9990226626396179, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 17.800674438476562, "eval/dyn_loss_std": 11.003338813781738, "eval/image_loss_mean": 9.079992294311523, "eval/image_loss_std": 14.845392227172852, "eval/model_loss_mean": 19.859670639038086, "eval/model_loss_std": 18.945556640625, "eval/post_ent_mag": 57.99321746826172, "eval/post_ent_max": 57.99321746826172, "eval/post_ent_mean": 41.528072357177734, "eval/post_ent_min": 19.051925659179688, "eval/post_ent_std": 7.83825159072876, "eval/prior_ent_mag": 71.15095520019531, "eval/prior_ent_max": 71.15095520019531, "eval/prior_ent_mean": 56.643524169921875, "eval/prior_ent_min": 45.81380081176758, "eval/prior_ent_std": 4.253072738647461, "eval/rep_loss_mean": 17.800674438476562, "eval/rep_loss_std": 11.003338813781738, "eval/reward_avg": 0.05341796576976776, "eval/reward_loss_mean": 0.09927208721637726, "eval/reward_loss_std": 0.5608376860618591, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0028948783874512, "eval/reward_neg_acc": 0.9865701794624329, "eval/reward_neg_loss": 0.027205292135477066, "eval/reward_pos_acc": 0.8750000596046448, "eval/reward_pos_loss": 1.3449980020523071, "eval/reward_pred": 0.05087541043758392, "eval/reward_rate": 0.0546875, "replay/size": 1000000.0, "replay/inserts": 23112.0, "replay/samples": 23120.0, "replay/insert_wait_avg": 1.3527304047571e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.056733022511624e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4904.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2795065588896659e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1068122386932, "timer/env.step_count": 2889.0, "timer/env.step_total": 215.32520747184753, "timer/env.step_frac": 0.21530221056074195, "timer/env.step_avg": 0.07453278209478974, "timer/env.step_min": 0.02443099021911621, "timer/env.step_max": 2.0714199542999268, "timer/replay._sample_count": 23120.0, "timer/replay._sample_total": 11.880656003952026, "timer/replay._sample_frac": 0.011879387140017298, "timer/replay._sample_avg": 0.0005138692043231845, "timer/replay._sample_min": 0.0004315376281738281, "timer/replay._sample_max": 0.00917506217956543, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3502.0, "timer/agent.policy_total": 61.63055729866028, "timer/agent.policy_frac": 0.06162397510392225, "timer/agent.policy_avg": 0.0175986742714621, "timer/agent.policy_min": 0.009716272354125977, "timer/agent.policy_max": 0.14141011238098145, "timer/dataset_train_count": 1445.0, "timer/dataset_train_total": 0.15786147117614746, "timer/dataset_train_frac": 0.0001578446114398339, "timer/dataset_train_avg": 0.00010924669285546537, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0005276203155517578, "timer/agent.train_count": 1445.0, "timer/agent.train_total": 650.8008198738098, "timer/agent.train_frac": 0.6507313138053945, "timer/agent.train_avg": 0.45038119022408984, "timer/agent.train_min": 0.43475794792175293, "timer/agent.train_max": 2.083571672439575, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4755737781524658, "timer/agent.report_frac": 0.00047552298647773005, "timer/agent.report_avg": 0.2377868890762329, "timer/agent.report_min": 0.22958898544311523, "timer/agent.report_max": 0.24598479270935059, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.099110505389274e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 23.109190139374544}
{"step": 1327296, "time": 60413.097782850266, "episode/length": 406.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9926289926289926, "episode/intrinsic_return": 0.0}
{"step": 1327368, "time": 60416.85483670235, "episode/length": 423.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9976415094339622, "episode/intrinsic_return": 0.0}
{"step": 1327416, "time": 60420.03387379646, "episode/length": 463.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9978448275862069, "episode/intrinsic_return": 0.0}
{"step": 1327704, "time": 60431.292543172836, "episode/length": 302.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 1328064, "time": 60445.37484383583, "episode/length": 95.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 1328256, "time": 60453.34138298035, "episode/length": 285.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 1328312, "time": 60456.54889512062, "episode/length": 219.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 1328536, "time": 60465.77780485153, "episode/length": 234.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 1328760, "time": 60475.06087779999, "episode/length": 509.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1329472, "time": 60501.12837910652, "episode/length": 88.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9550561797752809, "episode/intrinsic_return": 0.0}
{"step": 1329704, "time": 60510.47653341293, "episode/length": 180.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 1329720, "time": 60513.08967804909, "episode/length": 175.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 1329784, "time": 60517.2632625103, "episode/length": 301.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 1330056, "time": 60548.62870454788, "eval_episode/length": 161.0, "eval_episode/score": 10.100000016391277, "eval_episode/reward_rate": 0.9876543209876543}
{"step": 1330056, "time": 60550.67928290367, "eval_episode/length": 170.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 1330056, "time": 60552.69173192978, "eval_episode/length": 179.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 1330056, "time": 60555.388912677765, "eval_episode/length": 200.0, "eval_episode/score": 8.100000038743019, "eval_episode/reward_rate": 0.9900497512437811}
{"step": 1330056, "time": 60558.222898721695, "eval_episode/length": 224.0, "eval_episode/score": 12.100000023841858, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 1330056, "time": 60561.817895412445, "eval_episode/length": 268.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9962825278810409}
{"step": 1330056, "time": 60564.50585794449, "eval_episode/length": 291.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9828767123287672}
{"step": 1330056, "time": 60566.68583321571, "eval_episode/length": 303.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9967105263157895}
{"step": 1330240, "time": 60573.15213084221, "episode/length": 316.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9968454258675079, "episode/intrinsic_return": 0.0}
{"step": 1330544, "time": 60585.05132198334, "episode/length": 104.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 1331400, "time": 60615.329956531525, "episode/length": 357.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9860335195530726, "episode/intrinsic_return": 0.0}
{"step": 1331432, "time": 60618.20482635498, "episode/length": 205.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 1331576, "time": 60624.71874046326, "episode/length": 262.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 1331696, "time": 60630.62981629372, "episode/length": 181.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 1331720, "time": 60632.89162516594, "episode/length": 537.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.983271375464684, "episode/intrinsic_return": 0.0}
{"step": 1332056, "time": 60645.73804974556, "episode/length": 498.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9979959919839679, "episode/intrinsic_return": 0.0}
{"step": 1332072, "time": 60648.028495788574, "episode/length": 293.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9965986394557823, "episode/intrinsic_return": 0.0}
{"step": 1332192, "time": 60653.85102081299, "episode/length": 98.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 1332344, "time": 60660.37431502342, "episode/length": 224.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1332912, "time": 60681.589532613754, "episode/length": 148.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 1333000, "time": 60686.037677526474, "episode/length": 195.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 1333200, "time": 60694.62688279152, "episode/length": 202.0, "episode/score": 13.099999979138374, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 1333736, "time": 60714.32407259941, "episode/length": 207.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 1334008, "time": 60725.03022861481, "episode/length": 226.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 1334048, "time": 60728.11483311653, "episode/length": 293.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9863945578231292, "episode/intrinsic_return": 0.0}
{"step": 1334096, "time": 60731.3127117157, "episode/length": 218.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 1334368, "time": 60742.148518800735, "episode/length": 288.0, "episode/score": 13.099999994039536, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 1335112, "time": 60768.731696367264, "episode/length": 238.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9665271966527197, "episode/intrinsic_return": 0.0}
{"step": 1335200, "time": 60773.50995993614, "episode/length": 148.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 1335440, "time": 60784.82332587242, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 1335640, "time": 60792.89271616936, "episode/length": 329.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1335904, "time": 60803.70518875122, "episode/length": 225.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 1336384, "time": 60821.56665086746, "episode/length": 433.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9976958525345622, "episode/intrinsic_return": 0.0}
{"step": 1336440, "time": 60825.07795190811, "episode/length": 165.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 1336448, "time": 60827.704991817474, "episode/length": 155.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 1336688, "time": 60837.320774793625, "episode/length": 329.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.996969696969697, "episode/intrinsic_return": 0.0}
{"step": 1337392, "time": 60862.78211760521, "episode/length": 185.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 1337448, "time": 60866.01971197128, "episode/length": 124.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.0}
{"step": 1338008, "time": 60886.71683573723, "episode/length": 320.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9937694704049844, "episode/intrinsic_return": 0.0}
{"step": 1338264, "time": 60897.01658964157, "episode/length": 227.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1338368, "time": 60902.450112342834, "episode/length": 121.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 1338584, "time": 60911.037912130356, "episode/length": 274.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 1338792, "time": 60919.95934057236, "episode/length": 393.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9974619289340102, "episode/intrinsic_return": 0.0}
{"step": 1340040, "time": 60981.106088876724, "eval_episode/length": 91.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9891304347826086}
{"step": 1340040, "time": 60989.612087488174, "eval_episode/length": 202.0, "eval_episode/score": 13.100000001490116, "eval_episode/reward_rate": 0.9901477832512315}
{"step": 1340040, "time": 60991.911353588104, "eval_episode/length": 218.0, "eval_episode/score": 12.100000023841858, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 1340040, "time": 60994.363403081894, "eval_episode/length": 237.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9789915966386554}
{"step": 1340040, "time": 60998.13634252548, "eval_episode/length": 283.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9753521126760564}
{"step": 1340040, "time": 61001.38678383827, "eval_episode/length": 319.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9875}
{"step": 1340040, "time": 61003.68496608734, "eval_episode/length": 335.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 1340040, "time": 61005.54000329971, "eval_episode/length": 342.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9854227405247813}
{"step": 1340224, "time": 61012.1309902668, "episode/length": 346.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9740634005763689, "episode/intrinsic_return": 0.0}
{"step": 1340272, "time": 61015.40910959244, "episode/length": 250.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 1340400, "time": 61021.30106019974, "episode/length": 298.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9933110367892977, "episode/intrinsic_return": 0.0}
{"step": 1340456, "time": 61024.63766980171, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 1340504, "time": 61027.86377263069, "episode/length": 766.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9960886571056062, "episode/intrinsic_return": 0.0}
{"step": 1341192, "time": 61052.70152258873, "episode/length": 352.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9971671388101983, "episode/intrinsic_return": 0.0}
{"step": 1341600, "time": 61068.224556446075, "episode/length": 376.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9973474801061007, "episode/intrinsic_return": 0.0}
{"step": 1343000, "time": 61117.11185193062, "episode/length": 324.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9969230769230769, "episode/intrinsic_return": 0.0}
{"step": 1343280, "time": 61128.53790473938, "episode/length": 260.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 1343600, "time": 61143.0218873024, "episode/length": 386.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.979328165374677, "episode/intrinsic_return": 0.0}
{"step": 1343608, "time": 61144.571895837784, "episode/length": 416.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9784172661870504, "episode/intrinsic_return": 0.0}
{"step": 1343720, "time": 61149.956257104874, "episode/length": 436.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9908466819221968, "episode/intrinsic_return": 0.0}
{"step": 1344032, "time": 61162.46668744087, "episode/length": 446.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 1344376, "time": 61175.34689760208, "episode/length": 171.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.0}
{"step": 1345336, "time": 61209.203130960464, "episode/length": 1080.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9888991674375578, "episode/intrinsic_return": 0.0}
{"step": 1345592, "time": 61219.47946000099, "episode/length": 194.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 1345720, "time": 61225.42440986633, "episode/length": 264.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 1345744, "time": 61228.031883955, "episode/length": 307.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 1346192, "time": 61244.73763537407, "episode/length": 573.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9860627177700348, "episode/intrinsic_return": 0.0}
{"step": 1346400, "time": 61253.524025440216, "episode/length": 100.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1346568, "time": 61260.46909236908, "episode/length": 369.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9891891891891892, "episode/intrinsic_return": 0.0}
{"step": 1346688, "time": 61266.34767746925, "episode/length": 168.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 1347128, "time": 61282.6893184185, "episode/length": 343.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 1347208, "time": 61286.93664956093, "episode/length": 185.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 1348152, "time": 61320.56721329689, "episode/length": 218.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 1348256, "time": 61325.891526937485, "episode/length": 210.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1348280, "time": 61328.182604551315, "episode/length": 260.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 1348344, "time": 61332.11310839653, "episode/length": 206.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 1348912, "time": 61353.29523563385, "episode/length": 81.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1348968, "time": 61356.584174633026, "episode/length": 219.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9681818181818181, "episode/intrinsic_return": 0.0}
{"step": 1349624, "time": 61380.438735961914, "episode/length": 311.0, "episode/score": 12.099999964237213, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 1350024, "time": 61413.856684446335, "eval_episode/length": 110.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.990990990990991}
{"step": 1350024, "time": 61416.23090291023, "eval_episode/length": 127.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.96875}
{"step": 1350024, "time": 61418.576100349426, "eval_episode/length": 144.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.993103448275862}
{"step": 1350024, "time": 61422.317797899246, "eval_episode/length": 191.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 1350024, "time": 61427.458980321884, "eval_episode/length": 260.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 1350024, "time": 61429.62326478958, "eval_episode/length": 272.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9706959706959707}
{"step": 1350024, "time": 61432.01294064522, "eval_episode/length": 160.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 1350024, "time": 61434.56752228737, "eval_episode/length": 200.0, "eval_episode/score": 12.099999964237213, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 1350025, "time": 61435.69835829735, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.6650513543023004, "train/action_min": 0.0, "train/action_std": 3.51113359298971, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.028987905191671517, "train/actor_opt_grad_steps": 83565.0, "train/actor_opt_loss": -8.204359338482996, "train/adv_mag": 0.4223996578819222, "train/adv_max": 0.37237227004435325, "train/adv_mean": 0.0014583200780250315, "train/adv_min": -0.3527107181855374, "train/adv_std": 0.043090204165006675, "train/cont_avg": 0.9959174262152778, "train/cont_loss_mean": 9.990560696830168e-05, "train/cont_loss_std": 0.0029307265429332732, "train/cont_neg_acc": 0.9971064817574289, "train/cont_neg_loss": 0.009483154968964728, "train/cont_pos_acc": 0.9999931827187538, "train/cont_pos_loss": 5.409851047330802e-05, "train/cont_pred": 0.9959123979012171, "train/cont_rate": 0.9959174262152778, "train/dyn_loss_mean": 13.268006119463179, "train/dyn_loss_std": 9.371222900019752, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.995096022884051, "train/extr_critic_critic_opt_grad_steps": 83565.0, "train/extr_critic_critic_opt_loss": 15098.405883789062, "train/extr_critic_mag": 10.7544700966941, "train/extr_critic_max": 10.7544700966941, "train/extr_critic_mean": 2.785087422364288, "train/extr_critic_min": -0.13992897255553138, "train/extr_critic_std": 2.5575907834702067, "train/extr_return_normed_mag": 1.4425517444809277, "train/extr_return_normed_max": 1.4425517444809277, "train/extr_return_normed_mean": 0.3354076836258173, "train/extr_return_normed_min": -0.06992802299403895, "train/extr_return_normed_std": 0.32211450218326515, "train/extr_return_rate": 0.8211575402981706, "train/extr_return_raw_mag": 11.671593248844147, "train/extr_return_raw_max": 11.671593248844147, "train/extr_return_raw_mean": 2.7967563387420444, "train/extr_return_raw_min": -0.4525001732270337, "train/extr_return_raw_std": 2.582416063381566, "train/extr_reward_mag": 1.051569241616461, "train/extr_reward_max": 1.051569241616461, "train/extr_reward_mean": 0.04587541533530586, "train/extr_reward_min": -0.46483037289645934, "train/extr_reward_std": 0.20002705769406426, "train/image_loss_mean": 6.537337826357947, "train/image_loss_std": 12.322457492351532, "train/model_loss_mean": 14.561047792434692, "train/model_loss_std": 16.120707478788162, "train/model_opt_grad_norm": 47.00945341587067, "train/model_opt_grad_steps": 83490.51388888889, "train/model_opt_loss": 18683.90466986762, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1284.7222222222222, "train/policy_entropy_mag": 2.6334720700979233, "train/policy_entropy_max": 2.6334720700979233, "train/policy_entropy_mean": 0.6927176649785705, "train/policy_entropy_min": 0.0793750233327349, "train/policy_entropy_std": 0.845485717886024, "train/policy_logprob_mag": 7.438383877277374, "train/policy_logprob_max": -0.009455658385478374, "train/policy_logprob_mean": -0.6938530835840437, "train/policy_logprob_min": -7.438383877277374, "train/policy_logprob_std": 1.1984509179989498, "train/policy_randomness_mag": 0.9295000744362673, "train/policy_randomness_max": 0.9295000744362673, "train/policy_randomness_mean": 0.24449893925338984, "train/policy_randomness_min": 0.028015899976405006, "train/policy_randomness_std": 0.2984193553113275, "train/post_ent_mag": 61.21673968103197, "train/post_ent_max": 61.21673968103197, "train/post_ent_mean": 43.72621454132928, "train/post_ent_min": 20.06639066007402, "train/post_ent_std": 7.736047714948654, "train/prior_ent_mag": 71.16741471820407, "train/prior_ent_max": 71.16741471820407, "train/prior_ent_mean": 57.048299392064415, "train/prior_ent_min": 40.594104793336655, "train/prior_ent_std": 4.805019342237049, "train/rep_loss_mean": 13.268006119463179, "train/rep_loss_std": 9.371222900019752, "train/reward_avg": 0.03899468284928136, "train/reward_loss_mean": 0.0628064997597701, "train/reward_loss_std": 0.25890451379948193, "train/reward_max_data": 1.0201388936903741, "train/reward_max_pred": 1.0153747465875413, "train/reward_neg_acc": 0.991653412166569, "train/reward_neg_loss": 0.030269099593472976, "train/reward_pos_acc": 0.9774804669949744, "train/reward_pos_loss": 0.7969729863107204, "train/reward_pred": 0.038336184341460466, "train/reward_rate": 0.042643229166666664, "train_stats/sum_log_reward": 11.02405078501641, "train_stats/max_log_achievement_collect_coal": 1.1265822784810127, "train_stats/max_log_achievement_collect_drink": 8.063291139240507, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 2.088607594936709, "train_stats/max_log_achievement_collect_stone": 17.379746835443036, "train_stats/max_log_achievement_collect_wood": 11.443037974683545, "train_stats/max_log_achievement_defeat_skeleton": 0.06329113924050633, "train_stats/max_log_achievement_defeat_zombie": 1.1898734177215189, "train_stats/max_log_achievement_eat_cow": 0.4810126582278481, "train_stats/max_log_achievement_eat_plant": 0.02531645569620253, "train_stats/max_log_achievement_make_stone_pickaxe": 0.012658227848101266, "train_stats/max_log_achievement_make_stone_sword": 0.012658227848101266, "train_stats/max_log_achievement_make_wood_pickaxe": 2.1772151898734178, "train_stats/max_log_achievement_make_wood_sword": 1.0253164556962024, "train_stats/max_log_achievement_place_furnace": 2.4556962025316458, "train_stats/max_log_achievement_place_plant": 1.759493670886076, "train_stats/max_log_achievement_place_stone": 4.8734177215189876, "train_stats/max_log_achievement_place_table": 2.5822784810126582, "train_stats/max_log_achievement_wake_up": 1.9493670886075949, "train_stats/mean_log_entropy": 0.66060843007474, "eval_stats/sum_log_reward": 10.641666869322458, "eval_stats/max_log_achievement_collect_coal": 0.7916666666666666, "eval_stats/max_log_achievement_collect_drink": 5.125, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.4166666666666667, "eval_stats/max_log_achievement_collect_stone": 16.25, "eval_stats/max_log_achievement_collect_wood": 9.791666666666666, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.9166666666666666, "eval_stats/max_log_achievement_eat_cow": 0.3333333333333333, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.6666666666666667, "eval_stats/max_log_achievement_make_wood_sword": 0.9166666666666666, "eval_stats/max_log_achievement_place_furnace": 2.3333333333333335, "eval_stats/max_log_achievement_place_plant": 1.1666666666666667, "eval_stats/max_log_achievement_place_stone": 3.875, "eval_stats/max_log_achievement_place_table": 2.5416666666666665, "eval_stats/max_log_achievement_wake_up": 1.5416666666666667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 8.086890375125222e-06, "report/cont_loss_std": 0.000200674359803088, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.6919231711653993e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.060938853304833e-06, "report/cont_pred": 0.9970623850822449, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 13.811466217041016, "report/dyn_loss_std": 9.476275444030762, "report/image_loss_mean": 6.3068718910217285, "report/image_loss_std": 12.404036521911621, "report/model_loss_mean": 14.663114547729492, "report/model_loss_std": 16.43451499938965, "report/post_ent_mag": 61.42491912841797, "report/post_ent_max": 61.42491912841797, "report/post_ent_mean": 42.801856994628906, "report/post_ent_min": 21.31513023376465, "report/post_ent_std": 7.646340847015381, "report/prior_ent_mag": 70.82957458496094, "report/prior_ent_max": 70.82957458496094, "report/prior_ent_mean": 56.64387893676758, "report/prior_ent_min": 40.038917541503906, "report/prior_ent_std": 4.772101879119873, "report/rep_loss_mean": 13.811466217041016, "report/rep_loss_std": 9.476275444030762, "report/reward_avg": 0.05107422173023224, "report/reward_loss_mean": 0.06935496628284454, "report/reward_loss_std": 0.2441447377204895, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0054049491882324, "report/reward_neg_acc": 0.9865701794624329, "report/reward_neg_loss": 0.028683967888355255, "report/reward_pos_acc": 0.9821429252624512, "report/reward_pos_loss": 0.772382378578186, "report/reward_pred": 0.0510246604681015, "report/reward_rate": 0.0546875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.939427875186084e-06, "eval/cont_loss_std": 1.1398254173400346e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.8305288651608862e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.8878314449466416e-06, "eval/cont_pred": 0.9980450868606567, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.112491607666016, "eval/dyn_loss_std": 10.713679313659668, "eval/image_loss_mean": 8.49537467956543, "eval/image_loss_std": 14.412599563598633, "eval/model_loss_mean": 18.876792907714844, "eval/model_loss_std": 18.108871459960938, "eval/post_ent_mag": 59.4775390625, "eval/post_ent_max": 59.4775390625, "eval/post_ent_mean": 42.52076721191406, "eval/post_ent_min": 21.995338439941406, "eval/post_ent_std": 7.7529730796813965, "eval/prior_ent_mag": 70.82957458496094, "eval/prior_ent_max": 70.82957458496094, "eval/prior_ent_mean": 57.67265701293945, "eval/prior_ent_min": 45.286651611328125, "eval/prior_ent_std": 4.814509391784668, "eval/rep_loss_mean": 17.112491607666016, "eval/rep_loss_std": 10.713679313659668, "eval/reward_avg": 0.04160156100988388, "eval/reward_loss_mean": 0.11391983926296234, "eval/reward_loss_std": 0.5890430212020874, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0601112842559814, "eval/reward_neg_acc": 0.9795917868614197, "eval/reward_neg_loss": 0.059783440083265305, "eval/reward_pos_acc": 0.886363685131073, "eval/reward_pos_loss": 1.3196852207183838, "eval/reward_pred": 0.04499252885580063, "eval/reward_rate": 0.04296875, "replay/size": 1000000.0, "replay/inserts": 23008.0, "replay/samples": 23008.0, "replay/insert_wait_avg": 1.3513840289374552e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.086418740772571e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7672.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2583479021090288e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1033.961564540863, "timer/env.step_count": 2876.0, "timer/env.step_total": 210.10599970817566, "timer/env.step_frac": 0.20320484524149068, "timer/env.step_avg": 0.0730549373116049, "timer/env.step_min": 0.024378538131713867, "timer/env.step_max": 2.169430732727051, "timer/replay._sample_count": 23008.0, "timer/replay._sample_total": 11.887981414794922, "timer/replay._sample_frac": 0.011497508052994071, "timer/replay._sample_avg": 0.0005166890392383051, "timer/replay._sample_min": 0.0003781318664550781, "timer/replay._sample_max": 0.03441143035888672, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3835.0, "timer/agent.policy_total": 67.50757646560669, "timer/agent.policy_frac": 0.06529021849625895, "timer/agent.policy_avg": 0.017603018635099527, "timer/agent.policy_min": 0.009619951248168945, "timer/agent.policy_max": 0.19166088104248047, "timer/dataset_train_count": 1438.0, "timer/dataset_train_total": 0.15881133079528809, "timer/dataset_train_frac": 0.00015359500414873663, "timer/dataset_train_avg": 0.00011043903393274553, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.0010380744934082031, "timer/agent.train_count": 1438.0, "timer/agent.train_total": 649.0899107456207, "timer/agent.train_frac": 0.6277698639928198, "timer/agent.train_avg": 0.45138380441280995, "timer/agent.train_min": 0.43707752227783203, "timer/agent.train_max": 1.8905184268951416, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.474747896194458, "timer/agent.report_frac": 0.0004591542978730285, "timer/agent.report_avg": 0.237373948097229, "timer/agent.report_min": 0.23116254806518555, "timer/agent.report_max": 0.24358534812927246, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.7670496151268492e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 22.251983601715107}
{"step": 1350096, "time": 61438.18414020538, "episode/length": 543.0, "episode/score": 15.099999986588955, "episode/reward_rate": 0.9981617647058824, "episode/intrinsic_return": 0.0}
{"step": 1350112, "time": 61440.33527970314, "episode/length": 798.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9774718397997497, "episode/intrinsic_return": 0.0}
{"step": 1350656, "time": 61460.27897787094, "episode/length": 288.0, "episode/score": 13.099999964237213, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 1350936, "time": 61471.06315279007, "episode/length": 347.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 1351248, "time": 61483.44724750519, "episode/length": 202.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 1351864, "time": 61507.67228126526, "episode/length": 447.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9933035714285714, "episode/intrinsic_return": 0.0}
{"step": 1352032, "time": 61515.24058485031, "episode/length": 382.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9817232375979112, "episode/intrinsic_return": 0.0}
{"step": 1352232, "time": 61523.49687862396, "episode/length": 264.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 1352264, "time": 61526.66118168831, "episode/length": 200.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 1352552, "time": 61538.72852873802, "episode/length": 64.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 1352568, "time": 61540.93869614601, "episode/length": 164.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 1352568, "time": 61540.947154045105, "episode/length": 203.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1353120, "time": 61563.41794848442, "episode/length": 70.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 1353192, "time": 61567.14984250069, "episode/length": 386.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9819121447028424, "episode/intrinsic_return": 0.0}
{"step": 1353440, "time": 61577.46369290352, "episode/length": 565.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9893992932862191, "episode/intrinsic_return": 0.0}
{"step": 1354136, "time": 61602.44390511513, "episode/length": 195.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 1354312, "time": 61610.160767793655, "episode/length": 217.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1354328, "time": 61612.332667827606, "episode/length": 257.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 1354672, "time": 61625.73253560066, "episode/length": 304.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9868852459016394, "episode/intrinsic_return": 0.0}
{"step": 1354976, "time": 61637.60476183891, "episode/length": 222.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 1355640, "time": 61661.4322886467, "episode/length": 163.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 1355664, "time": 61664.043221235275, "episode/length": 190.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 1355816, "time": 61670.64527273178, "episode/length": 296.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 1356064, "time": 61680.93781375885, "episode/length": 367.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9972826086956522, "episode/intrinsic_return": 0.0}
{"step": 1356072, "time": 61682.53965449333, "episode/length": 219.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 1356384, "time": 61694.90808725357, "episode/length": 564.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.984070796460177, "episode/intrinsic_return": 0.0}
{"step": 1356896, "time": 61714.13088345528, "episode/length": 239.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 1356976, "time": 61718.48055887222, "episode/length": 163.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 1357248, "time": 61729.422560214996, "episode/length": 321.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.984472049689441, "episode/intrinsic_return": 0.0}
{"step": 1357776, "time": 61748.850068092346, "episode/length": 244.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 1357856, "time": 61753.21458864212, "episode/length": 75.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 1358248, "time": 61768.061432123184, "episode/length": 325.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9969325153374233, "episode/intrinsic_return": 0.0}
{"step": 1358456, "time": 61776.73509454727, "episode/length": 258.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 1358728, "time": 61787.62663578987, "episode/length": 332.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.993993993993994, "episode/intrinsic_return": 0.0}
{"step": 1358776, "time": 61790.796557188034, "episode/length": 234.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1358832, "time": 61794.562849760056, "episode/length": 344.0, "episode/score": 10.1000000461936, "episode/reward_rate": 0.9971014492753624, "episode/intrinsic_return": 0.0}
{"step": 1359576, "time": 61821.12567782402, "episode/length": 224.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1359856, "time": 61832.46084070206, "episode/length": 174.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 1359984, "time": 61840.24737930298, "episode/length": 216.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1360008, "time": 61861.9165520668, "eval_episode/length": 131.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9924242424242424}
{"step": 1360008, "time": 61865.27674818039, "eval_episode/length": 169.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9764705882352941}
{"step": 1360008, "time": 61867.712683439255, "eval_episode/length": 189.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 1360008, "time": 61870.21863269806, "eval_episode/length": 205.0, "eval_episode/score": 12.099999994039536, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 1360008, "time": 61873.31064105034, "eval_episode/length": 241.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9958677685950413}
{"step": 1360008, "time": 61879.63337469101, "eval_episode/length": 212.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 1360008, "time": 61881.61451673508, "eval_episode/length": 352.0, "eval_episode/score": 11.099999979138374, "eval_episode/reward_rate": 0.9971671388101983}
{"step": 1360008, "time": 61884.68564271927, "eval_episode/length": 382.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9973890339425587}
{"step": 1360024, "time": 61885.245738744736, "episode/length": 380.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 1360376, "time": 61898.63378119469, "episode/length": 314.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 1360440, "time": 61902.28366947174, "episode/length": 200.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 1361192, "time": 61929.34932613373, "episode/length": 201.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 1361392, "time": 61938.07710456848, "episode/length": 175.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 1361440, "time": 61941.32688999176, "episode/length": 197.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 1361568, "time": 61947.275619506836, "episode/length": 148.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 1361912, "time": 61960.258652448654, "episode/length": 235.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1362352, "time": 61977.15152812004, "episode/length": 238.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 1362584, "time": 61986.300260305405, "episode/length": 173.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 1362680, "time": 61991.14218759537, "episode/length": 487.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 1363456, "time": 62019.48302984238, "episode/length": 590.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.988155668358714, "episode/intrinsic_return": 0.0}
{"step": 1363464, "time": 62021.13519406319, "episode/length": 252.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 1363504, "time": 62024.391949653625, "episode/length": 263.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 1363680, "time": 62032.044065237045, "episode/length": 220.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 1364056, "time": 62046.0922999382, "episode/length": 68.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9130434782608695, "episode/intrinsic_return": 0.0}
{"step": 1364056, "time": 62046.100964307785, "episode/length": 212.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9671361502347418, "episode/intrinsic_return": 0.0}
{"step": 1364248, "time": 62055.72503948212, "episode/length": 334.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9970149253731343, "episode/intrinsic_return": 0.0}
{"step": 1364328, "time": 62060.08397054672, "episode/length": 217.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 1364936, "time": 62082.18724012375, "episode/length": 281.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.975177304964539, "episode/intrinsic_return": 0.0}
{"step": 1365320, "time": 62096.80374121666, "episode/length": 47.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 1365592, "time": 62107.64763331413, "episode/length": 157.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 1365760, "time": 62115.284901857376, "episode/length": 54.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1365768, "time": 62117.098596811295, "episode/length": 213.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 1365880, "time": 62122.57355284691, "episode/length": 302.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 1365944, "time": 62126.29463028908, "episode/length": 235.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1365960, "time": 62128.35457658768, "episode/length": 311.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9839743589743589, "episode/intrinsic_return": 0.0}
{"step": 1365968, "time": 62130.48740053177, "episode/length": 285.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9825174825174825, "episode/intrinsic_return": 0.0}
{"step": 1366520, "time": 62150.55222034454, "episode/length": 283.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 1367240, "time": 62176.52697777748, "episode/length": 184.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 1367352, "time": 62181.87331056595, "episode/length": 219.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9681818181818181, "episode/intrinsic_return": 0.0}
{"step": 1367456, "time": 62187.235973119736, "episode/length": 185.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 1367664, "time": 62195.91413640976, "episode/length": 214.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 1367688, "time": 62198.10118603706, "episode/length": 55.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 1367808, "time": 62204.044478178024, "episode/length": 160.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 1368112, "time": 62217.877710819244, "episode/length": 292.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 1369128, "time": 62253.73983836174, "episode/length": 179.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 1369336, "time": 62262.37800478935, "episode/length": 431.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 1369360, "time": 62264.97026371956, "episode/length": 237.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 1369464, "time": 62269.95658111572, "episode/length": 168.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 1369480, "time": 62272.17671561241, "episode/length": 226.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 1369616, "time": 62278.60078024864, "episode/length": 282.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 1369824, "time": 62287.23644447327, "episode/length": 482.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9834368530020704, "episode/intrinsic_return": 0.0}
{"step": 1370096, "time": 62318.31136274338, "eval_episode/length": 135.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 1370096, "time": 62320.80224633217, "eval_episode/length": 152.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 1370096, "time": 62326.111159324646, "eval_episode/length": 187.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 1370096, "time": 62328.599271297455, "eval_episode/length": 205.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 1370096, "time": 62330.20630288124, "eval_episode/length": 207.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 1370096, "time": 62335.60734248161, "eval_episode/length": 292.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9726962457337884}
{"step": 1370096, "time": 62337.46839237213, "eval_episode/length": 300.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9833887043189369}
{"step": 1370096, "time": 62340.29525351524, "eval_episode/length": 191.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 1370808, "time": 62364.208815574646, "episode/length": 165.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 1371008, "time": 62372.800253629684, "episode/length": 399.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9925, "episode/intrinsic_return": 0.0}
{"step": 1371160, "time": 62379.285384655, "episode/length": 253.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.968503937007874, "episode/intrinsic_return": 0.0}
{"step": 1371272, "time": 62384.54966902733, "episode/length": 225.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 1371384, "time": 62390.1796605587, "episode/length": 194.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 1371496, "time": 62395.68573284149, "episode/length": 234.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1371728, "time": 62405.40821480751, "episode/length": 295.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 1372553, "time": 62435.825390577316, "train_stats/sum_log_reward": 10.852809180034681, "train_stats/max_log_achievement_collect_coal": 1.1797752808988764, "train_stats/max_log_achievement_collect_drink": 6.943820224719101, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 2.269662921348315, "train_stats/max_log_achievement_collect_stone": 15.662921348314606, "train_stats/max_log_achievement_collect_wood": 10.640449438202246, "train_stats/max_log_achievement_defeat_skeleton": 0.15730337078651685, "train_stats/max_log_achievement_defeat_zombie": 1.3932584269662922, "train_stats/max_log_achievement_eat_cow": 0.43820224719101125, "train_stats/max_log_achievement_eat_plant": 0.02247191011235955, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.011235955056179775, "train_stats/max_log_achievement_make_wood_pickaxe": 1.8426966292134832, "train_stats/max_log_achievement_make_wood_sword": 0.9775280898876404, "train_stats/max_log_achievement_place_furnace": 2.2808988764044944, "train_stats/max_log_achievement_place_plant": 1.7191011235955056, "train_stats/max_log_achievement_place_stone": 4.269662921348314, "train_stats/max_log_achievement_place_table": 2.359550561797753, "train_stats/max_log_achievement_wake_up": 1.6629213483146068, "train_stats/mean_log_entropy": 0.6431176320890363, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.668268258231027, "train/action_min": 0.0, "train/action_std": 3.5177842770303998, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.02940661009134991, "train/actor_opt_grad_steps": 84985.0, "train/actor_opt_loss": -2.4480097355919757, "train/adv_mag": 0.3895023835556848, "train/adv_max": 0.34808924293943816, "train/adv_mean": 0.0023782940084402073, "train/adv_min": -0.3216900630721024, "train/adv_std": 0.04352156807269369, "train/cont_avg": 0.996142578125, "train/cont_loss_mean": 0.00021323765201982172, "train/cont_loss_std": 0.006456116593669289, "train/cont_neg_acc": 0.9887077298717223, "train/cont_neg_loss": 0.03371257897136578, "train/cont_pos_acc": 0.999971946648189, "train/cont_pos_loss": 6.992846369432267e-05, "train/cont_pred": 0.9961540311574936, "train/cont_rate": 0.996142578125, "train/dyn_loss_mean": 13.158007049560547, "train/dyn_loss_std": 9.365773527962821, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0010576107672282, "train/extr_critic_critic_opt_grad_steps": 84985.0, "train/extr_critic_critic_opt_loss": 15164.561669921875, "train/extr_critic_mag": 10.603331082207816, "train/extr_critic_max": 10.603331082207816, "train/extr_critic_mean": 2.740294535670962, "train/extr_critic_min": -0.1398971600191934, "train/extr_critic_std": 2.448943155152457, "train/extr_return_normed_mag": 1.461263311760766, "train/extr_return_normed_max": 1.461263311760766, "train/extr_return_normed_mean": 0.3309201013829027, "train/extr_return_normed_min": -0.07750830668623426, "train/extr_return_normed_std": 0.31497044712305067, "train/extr_return_rate": 0.8529074098382677, "train/extr_return_raw_mag": 11.631713478905814, "train/extr_return_raw_max": 11.631713478905814, "train/extr_return_raw_mean": 2.758949969496046, "train/extr_return_raw_min": -0.44724843368998596, "train/extr_return_raw_std": 2.472580346890858, "train/extr_reward_mag": 1.05048234803336, "train/extr_reward_max": 1.05048234803336, "train/extr_reward_mean": 0.04424122253965054, "train/extr_reward_min": -0.45678430455071584, "train/extr_reward_std": 0.19614858978560992, "train/image_loss_mean": 6.510829108101981, "train/image_loss_std": 11.816919916016715, "train/model_loss_mean": 14.467677818025862, "train/model_loss_std": 15.651455661228725, "train/model_opt_grad_norm": 46.2310588205461, "train/model_opt_grad_steps": 84909.2, "train/model_opt_loss": 18767.589467075893, "train/model_opt_model_opt_grad_overflow": 0.007142857142857143, "train/model_opt_model_opt_grad_scale": 1285.7142857142858, "train/policy_entropy_mag": 2.666361267226083, "train/policy_entropy_max": 2.666361267226083, "train/policy_entropy_mean": 0.72625803734575, "train/policy_entropy_min": 0.07937502222401756, "train/policy_entropy_std": 0.8646008632012776, "train/policy_logprob_mag": 7.438383872168405, "train/policy_logprob_max": -0.009455659253788846, "train/policy_logprob_mean": -0.7266140939933913, "train/policy_logprob_min": -7.438383872168405, "train/policy_logprob_std": 1.2113244559083667, "train/policy_randomness_mag": 0.9411085201161248, "train/policy_randomness_max": 0.9411085201161248, "train/policy_randomness_mean": 0.2563372179865837, "train/policy_randomness_min": 0.02801589956507087, "train/policy_randomness_std": 0.3051661637212549, "train/post_ent_mag": 61.299560574122836, "train/post_ent_max": 61.299560574122836, "train/post_ent_mean": 43.88936827523368, "train/post_ent_min": 20.360506684439525, "train/post_ent_std": 7.723207633835929, "train/prior_ent_mag": 71.12802707127162, "train/prior_ent_max": 71.12802707127162, "train/prior_ent_mean": 57.11686834607806, "train/prior_ent_min": 41.021609142848426, "train/prior_ent_std": 4.8416492496218, "train/rep_loss_mean": 13.158007049560547, "train/rep_loss_std": 9.365773527962821, "train/reward_avg": 0.036669921702040094, "train/reward_loss_mean": 0.061831293122044634, "train/reward_loss_std": 0.25399813428521156, "train/reward_max_data": 1.0271428636142186, "train/reward_max_pred": 1.023193952866963, "train/reward_neg_acc": 0.9910474338701794, "train/reward_neg_loss": 0.03101009700580367, "train/reward_pos_acc": 0.9771594302994865, "train/reward_pos_loss": 0.8021734139748982, "train/reward_pred": 0.036100429575890304, "train/reward_rate": 0.04019252232142857, "eval_stats/sum_log_reward": 10.97500029206276, "eval_stats/max_log_achievement_collect_coal": 0.8125, "eval_stats/max_log_achievement_collect_drink": 5.4375, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 13.625, "eval_stats/max_log_achievement_collect_wood": 10.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.0, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.875, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 2.0, "eval_stats/max_log_achievement_place_plant": 1.1875, "eval_stats/max_log_achievement_place_stone": 3.6875, "eval_stats/max_log_achievement_place_table": 2.3125, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 7.536449629697017e-06, "report/cont_loss_std": 0.00015862534928601235, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.7352885303553194e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.222934073070064e-06, "report/cont_pred": 0.9921807646751404, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 14.512529373168945, "report/dyn_loss_std": 10.183239936828613, "report/image_loss_mean": 8.639717102050781, "report/image_loss_std": 17.34800148010254, "report/model_loss_mean": 17.421100616455078, "report/model_loss_std": 21.519487380981445, "report/post_ent_mag": 59.426509857177734, "report/post_ent_max": 59.426509857177734, "report/post_ent_mean": 43.411537170410156, "report/post_ent_min": 22.99666976928711, "report/post_ent_std": 7.924139976501465, "report/prior_ent_mag": 71.03343200683594, "report/prior_ent_max": 71.03343200683594, "report/prior_ent_mean": 57.73600769042969, "report/prior_ent_min": 42.788917541503906, "report/prior_ent_std": 5.1111063957214355, "report/rep_loss_mean": 14.512529373168945, "report/rep_loss_std": 10.183239936828613, "report/reward_avg": 0.04355468600988388, "report/reward_loss_mean": 0.07385862618684769, "report/reward_loss_std": 0.24305860698223114, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0015552043914795, "report/reward_neg_acc": 0.9938398599624634, "report/reward_neg_loss": 0.03848237916827202, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7629879713058472, "report/reward_pred": 0.043370746076107025, "report/reward_rate": 0.048828125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.5688688108639326e-06, "eval/cont_loss_std": 6.150157332740491e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.84782610530965e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.457500161450298e-06, "eval/cont_pred": 0.9980455636978149, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.780765533447266, "eval/dyn_loss_std": 10.620346069335938, "eval/image_loss_mean": 12.672171592712402, "eval/image_loss_std": 21.6323184967041, "eval/model_loss_mean": 23.45326805114746, "eval/model_loss_std": 25.473339080810547, "eval/post_ent_mag": 58.81800842285156, "eval/post_ent_max": 58.81800842285156, "eval/post_ent_mean": 42.158470153808594, "eval/post_ent_min": 19.261165618896484, "eval/post_ent_std": 7.872844219207764, "eval/prior_ent_mag": 71.03343200683594, "eval/prior_ent_max": 71.03343200683594, "eval/prior_ent_mean": 58.14482879638672, "eval/prior_ent_min": 44.31645202636719, "eval/prior_ent_std": 4.20353364944458, "eval/rep_loss_mean": 17.780765533447266, "eval/rep_loss_std": 10.620346069335938, "eval/reward_avg": 0.05947265774011612, "eval/reward_loss_mean": 0.11263567954301834, "eval/reward_loss_std": 0.49030545353889465, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017852783203125, "eval/reward_neg_acc": 0.9822916984558105, "eval/reward_neg_loss": 0.045750148594379425, "eval/reward_pos_acc": 0.90625, "eval/reward_pos_loss": 1.1159186363220215, "eval/reward_pred": 0.060213640332221985, "eval/reward_rate": 0.0625, "replay/size": 1000000.0, "replay/inserts": 22528.0, "replay/samples": 22528.0, "replay/insert_wait_avg": 1.3652024790644646e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.133091879161921e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5688.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.259829256940324e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1013700962067, "timer/env.step_count": 2816.0, "timer/env.step_total": 225.53351068496704, "timer/env.step_frac": 0.22551065064861517, "timer/env.step_avg": 0.08009002510119569, "timer/env.step_min": 0.02448439598083496, "timer/env.step_max": 3.4763829708099365, "timer/replay._sample_count": 22528.0, "timer/replay._sample_total": 11.66384768486023, "timer/replay._sample_frac": 0.011662665439342617, "timer/replay._sample_avg": 0.0005177489206702871, "timer/replay._sample_min": 0.0004341602325439453, "timer/replay._sample_max": 0.009944438934326172, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3527.0, "timer/agent.policy_total": 61.009753704071045, "timer/agent.policy_frac": 0.061003569766334885, "timer/agent.policy_avg": 0.017297917126189694, "timer/agent.policy_min": 0.009730100631713867, "timer/agent.policy_max": 0.13065624237060547, "timer/dataset_train_count": 1408.0, "timer/dataset_train_total": 0.1537325382232666, "timer/dataset_train_frac": 0.00015371695592065633, "timer/dataset_train_avg": 0.00010918504135175185, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.00027680397033691406, "timer/agent.train_count": 1408.0, "timer/agent.train_total": 635.6678969860077, "timer/agent.train_frac": 0.6356034658015302, "timer/agent.train_avg": 0.4514686768366532, "timer/agent.train_min": 0.43795108795166016, "timer/agent.train_max": 1.788417100906372, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47692418098449707, "timer/agent.report_frac": 0.00047687584003471413, "timer/agent.report_avg": 0.23846209049224854, "timer/agent.report_min": 0.23238468170166016, "timer/agent.report_max": 0.24453949928283691, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 8.702278137207031e-05, "timer/dataset_eval_frac": 8.70139607584969e-08, "timer/dataset_eval_avg": 8.702278137207031e-05, "timer/dataset_eval_min": 8.702278137207031e-05, "timer/dataset_eval_max": 8.702278137207031e-05, "fps": 22.52536363326718}
{"step": 1372712, "time": 62441.11170387268, "episode/length": 165.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 1372824, "time": 62446.64346933365, "episode/length": 207.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 1373016, "time": 62454.77065324783, "episode/length": 275.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 1373088, "time": 62459.02845478058, "episode/length": 198.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 1373376, "time": 62470.30924630165, "episode/length": 504.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.998019801980198, "episode/intrinsic_return": 0.0}
{"step": 1373816, "time": 62486.72392368317, "episode/length": 350.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 1374024, "time": 62495.33442211151, "episode/length": 343.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 1374248, "time": 62504.49306488037, "episode/length": 177.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 1374440, "time": 62512.784225702286, "episode/length": 168.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 1374536, "time": 62517.66439628601, "episode/length": 350.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9971509971509972, "episode/intrinsic_return": 0.0}
{"step": 1374568, "time": 62520.335021972656, "episode/length": 231.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 1374768, "time": 62528.91513323784, "episode/length": 173.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 1375096, "time": 62541.42133188248, "episode/length": 259.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 1375512, "time": 62556.98120498657, "episode/length": 211.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 1376352, "time": 62589.1064016819, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 1376504, "time": 62595.53490972519, "episode/length": 257.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9844961240310077, "episode/intrinsic_return": 0.0}
{"step": 1376512, "time": 62597.79812550545, "episode/length": 310.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9935691318327974, "episode/intrinsic_return": 0.0}
{"step": 1376760, "time": 62607.61293268204, "episode/length": 207.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 1377304, "time": 62627.54414701462, "episode/length": 223.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1377960, "time": 62651.13511323929, "episode/length": 181.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 1378512, "time": 62671.65560722351, "episode/length": 249.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 1378696, "time": 62679.19531297684, "episode/length": 515.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 1379072, "time": 62693.812111377716, "episode/length": 566.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 1379552, "time": 62711.55017066002, "episode/length": 348.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.997134670487106, "episode/intrinsic_return": 0.0}
{"step": 1379568, "time": 62713.70023345947, "episode/length": 200.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 1379592, "time": 62715.89606499672, "episode/length": 64.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 1380080, "time": 62754.49999213219, "eval_episode/length": 143.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9652777777777778}
{"step": 1380080, "time": 62758.69637918472, "eval_episode/length": 199.0, "eval_episode/score": 13.100000008940697, "eval_episode/reward_rate": 0.995}
{"step": 1380080, "time": 62762.227617025375, "eval_episode/length": 240.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.995850622406639}
{"step": 1380080, "time": 62764.37448811531, "eval_episode/length": 253.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.984251968503937}
{"step": 1380080, "time": 62766.73830246925, "eval_episode/length": 69.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9857142857142858}
{"step": 1380080, "time": 62769.31229734421, "eval_episode/length": 292.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9965870307167235}
{"step": 1380080, "time": 62771.292285203934, "eval_episode/length": 302.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9966996699669967}
{"step": 1380080, "time": 62773.76902484894, "eval_episode/length": 321.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9813664596273292}
{"step": 1380208, "time": 62778.23024272919, "episode/length": 211.0, "episode/score": 11.100000038743019, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 1380216, "time": 62779.816251039505, "episode/length": 363.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 1380288, "time": 62784.04806423187, "episode/length": 754.0, "episode/score": 12.099999964237213, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 1380864, "time": 62805.16394996643, "episode/length": 158.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 1381432, "time": 62825.84810376167, "episode/length": 232.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 1381968, "time": 62845.93879389763, "episode/length": 218.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 1381968, "time": 62845.945721149445, "episode/length": 66.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 1382040, "time": 62851.502599954605, "episode/length": 417.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9976076555023924, "episode/intrinsic_return": 0.0}
{"step": 1382464, "time": 62868.135133743286, "episode/length": 271.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 1382568, "time": 62872.98697376251, "episode/length": 212.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 1383064, "time": 62891.33953714371, "episode/length": 356.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9971988795518207, "episode/intrinsic_return": 0.0}
{"step": 1383352, "time": 62902.75966691971, "episode/length": 172.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 1383360, "time": 62904.854293346405, "episode/length": 475.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9894957983193278, "episode/intrinsic_return": 0.0}
{"step": 1383640, "time": 62915.858117580414, "episode/length": 910.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.995609220636663, "episode/intrinsic_return": 0.0}
{"step": 1383768, "time": 62921.6095366478, "episode/length": 224.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 1384096, "time": 62934.49732923508, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 1384256, "time": 62941.39529180527, "episode/length": 210.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1384648, "time": 62957.890504837036, "episode/length": 197.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 1384784, "time": 62964.202795505524, "episode/length": 342.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9883381924198251, "episode/intrinsic_return": 0.0}
{"step": 1385104, "time": 62976.611741542816, "episode/length": 218.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 1385560, "time": 62993.554368019104, "episode/length": 182.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 1385664, "time": 62998.84632349014, "episode/length": 236.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9704641350210971, "episode/intrinsic_return": 0.0}
{"step": 1385720, "time": 63002.12299323082, "episode/length": 182.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 1385800, "time": 63006.52348613739, "episode/length": 304.0, "episode/score": 12.099999964237213, "episode/reward_rate": 0.9770491803278688, "episode/intrinsic_return": 0.0}
{"step": 1385888, "time": 63011.41103553772, "episode/length": 280.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 1387040, "time": 63052.203568935394, "episode/length": 164.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 1387280, "time": 63061.85004425049, "episode/length": 271.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 1387360, "time": 63066.24059844017, "episode/length": 39.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 1387448, "time": 63070.57470846176, "episode/length": 194.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 1387528, "time": 63074.77953147888, "episode/length": 342.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9883381924198251, "episode/intrinsic_return": 0.0}
{"step": 1387536, "time": 63077.01175189018, "episode/length": 360.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9889196675900277, "episode/intrinsic_return": 0.0}
{"step": 1387536, "time": 63077.020448207855, "episode/length": 246.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 1388224, "time": 63103.65133738518, "episode/length": 302.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.0}
{"step": 1388656, "time": 63119.88555288315, "episode/length": 171.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.0}
{"step": 1388864, "time": 63128.37049245834, "episode/length": 176.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 1388960, "time": 63133.2102701664, "episode/length": 177.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 1389064, "time": 63138.14376497269, "episode/length": 190.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 1389224, "time": 63145.13477087021, "episode/length": 211.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 1389848, "time": 63167.87604308128, "episode/length": 522.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9980879541108987, "episode/intrinsic_return": 0.0}
{"step": 1390064, "time": 63197.99513554573, "eval_episode/length": 173.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 1390064, "time": 63200.52831888199, "eval_episode/length": 193.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.979381443298969}
{"step": 1390064, "time": 63202.51187515259, "eval_episode/length": 201.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 1390064, "time": 63205.563739299774, "eval_episode/length": 231.0, "eval_episode/score": 12.099999994039536, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 1390064, "time": 63214.122015714645, "eval_episode/length": 386.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9948320413436692}
{"step": 1390064, "time": 63216.43011260033, "eval_episode/length": 402.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9925558312655087}
{"step": 1390064, "time": 63219.43967819214, "eval_episode/length": 433.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9792626728110599}
{"step": 1390064, "time": 63222.29392313957, "eval_episode/length": 458.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9825708061002179}
{"step": 1390824, "time": 63247.73011779785, "episode/length": 232.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 1390960, "time": 63254.76767921448, "episode/length": 216.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1391336, "time": 63269.337347745895, "episode/length": 496.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9979879275653923, "episode/intrinsic_return": 0.0}
{"step": 1391368, "time": 63271.91554379463, "episode/length": 392.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9949109414758269, "episode/intrinsic_return": 0.0}
{"step": 1391760, "time": 63287.01001787186, "episode/length": 336.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9970326409495549, "episode/intrinsic_return": 0.0}
{"step": 1392104, "time": 63299.92111778259, "episode/length": 430.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9907192575406032, "episode/intrinsic_return": 0.0}
{"step": 1392816, "time": 63327.70546460152, "episode/length": 180.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 1393040, "time": 63336.809923410416, "episode/length": 276.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 1393080, "time": 63339.60212016106, "episode/length": 217.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 1393408, "time": 63352.52772808075, "episode/length": 305.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9967320261437909, "episode/intrinsic_return": 0.0}
{"step": 1393784, "time": 63367.11922812462, "episode/length": 252.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 1393960, "time": 63374.521998643875, "episode/length": 636.0, "episode/score": 13.099999979138374, "episode/reward_rate": 0.9984301412872841, "episode/intrinsic_return": 0.0}
{"step": 1394288, "time": 63387.62784361839, "episode/length": 183.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 1394472, "time": 63395.171741724014, "episode/length": 577.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9844290657439446, "episode/intrinsic_return": 0.0}
{"step": 1394680, "time": 63403.80750107765, "episode/length": 158.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 1394800, "time": 63409.85944914818, "episode/length": 336.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9940652818991098, "episode/intrinsic_return": 0.0}
{"step": 1394896, "time": 63414.775428533554, "episode/length": 231.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 1395048, "time": 63421.262836933136, "episode/length": 94.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 1395376, "time": 63434.2815554142, "episode/length": 198.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 1395377, "time": 63436.51039624214, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.655895313182911, "train/action_min": 0.0, "train/action_std": 3.4846488179026784, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.028474966298554328, "train/actor_opt_grad_steps": 86400.0, "train/actor_opt_loss": -8.801898517808715, "train/adv_mag": 0.3936408935310124, "train/adv_max": 0.3550289035677076, "train/adv_mean": 0.0020175731404417055, "train/adv_min": -0.3296892262630529, "train/adv_std": 0.0425381100365332, "train/cont_avg": 0.9957386363636364, "train/cont_loss_mean": 0.0001855702867428479, "train/cont_loss_std": 0.005545334593707307, "train/cont_neg_acc": 0.9924242429799967, "train/cont_neg_loss": 0.023527424369728, "train/cont_pos_acc": 0.9999725130888132, "train/cont_pos_loss": 6.938627018003641e-05, "train/cont_pred": 0.9957483490030249, "train/cont_rate": 0.9957386363636364, "train/dyn_loss_mean": 13.177525433627041, "train/dyn_loss_std": 9.351183837943978, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9304592746954697, "train/extr_critic_critic_opt_grad_steps": 86400.0, "train/extr_critic_critic_opt_loss": 14811.391963505244, "train/extr_critic_mag": 10.778819044153174, "train/extr_critic_max": 10.778819044153174, "train/extr_critic_mean": 2.8973641495604614, "train/extr_critic_min": -0.15236335534315842, "train/extr_critic_std": 2.5946540265650184, "train/extr_return_normed_mag": 1.4481262952297718, "train/extr_return_normed_max": 1.4481262952297718, "train/extr_return_normed_mean": 0.34819913379379086, "train/extr_return_normed_min": -0.07134768689845826, "train/extr_return_normed_std": 0.32703419071394246, "train/extr_return_rate": 0.8533727130689821, "train/extr_return_raw_mag": 11.734206032919717, "train/extr_return_raw_max": 11.734206032919717, "train/extr_return_raw_mean": 2.9135130152002082, "train/extr_return_raw_min": -0.45036674400309584, "train/extr_return_raw_std": 2.6223553769238346, "train/extr_reward_mag": 1.0506385989956089, "train/extr_reward_max": 1.0506385989956089, "train/extr_reward_mean": 0.04791968675343307, "train/extr_reward_min": -0.456686557589711, "train/extr_reward_std": 0.20408625817382253, "train/image_loss_mean": 6.519192895689211, "train/image_loss_std": 12.065688196595731, "train/model_loss_mean": 14.489883656268352, "train/model_loss_std": 15.86780225980532, "train/model_opt_grad_norm": 44.7196045055256, "train/model_opt_grad_steps": 86322.77622377622, "train/model_opt_loss": 20158.83575994318, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1389.86013986014, "train/policy_entropy_mag": 2.6498388327085056, "train/policy_entropy_max": 2.6498388327085056, "train/policy_entropy_mean": 0.7125836983844117, "train/policy_entropy_min": 0.07937501949238611, "train/policy_entropy_std": 0.8546209510389742, "train/policy_logprob_mag": 7.43838388936503, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.7126445691068689, "train/policy_logprob_min": -7.43838388936503, "train/policy_logprob_std": 1.2099373524005597, "train/policy_randomness_mag": 0.9352768230271506, "train/policy_randomness_max": 0.9352768230271506, "train/policy_randomness_mean": 0.2515107787155605, "train/policy_randomness_min": 0.028015898579692507, "train/policy_randomness_std": 0.3016436882577576, "train/post_ent_mag": 61.24182190261521, "train/post_ent_max": 61.24182190261521, "train/post_ent_mean": 43.78992051344652, "train/post_ent_min": 20.368976846441523, "train/post_ent_std": 7.761661469519555, "train/prior_ent_mag": 71.16921484887183, "train/prior_ent_max": 71.16921484887183, "train/prior_ent_mean": 57.030639435027865, "train/prior_ent_min": 40.51352078097683, "train/prior_ent_std": 4.916616773271894, "train/rep_loss_mean": 13.177525433627041, "train/rep_loss_std": 9.351183837943978, "train/reward_avg": 0.04077045984201498, "train/reward_loss_mean": 0.06399005315416342, "train/reward_loss_std": 0.252538358935943, "train/reward_max_data": 1.0286713355071062, "train/reward_max_pred": 1.0221238202982015, "train/reward_neg_acc": 0.9913743009100427, "train/reward_neg_loss": 0.030163888187779413, "train/reward_pos_acc": 0.9812459337127792, "train/reward_pos_loss": 0.7902922025927297, "train/reward_pred": 0.0399113293815326, "train/reward_rate": 0.04460090690559441, "train_stats/sum_log_reward": 10.95714302857717, "train_stats/max_log_achievement_collect_coal": 0.8452380952380952, "train_stats/max_log_achievement_collect_drink": 7.261904761904762, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 2.2738095238095237, "train_stats/max_log_achievement_collect_stone": 13.845238095238095, "train_stats/max_log_achievement_collect_wood": 11.166666666666666, "train_stats/max_log_achievement_defeat_skeleton": 0.023809523809523808, "train_stats/max_log_achievement_defeat_zombie": 1.2738095238095237, "train_stats/max_log_achievement_eat_cow": 0.4523809523809524, "train_stats/max_log_achievement_eat_plant": 0.011904761904761904, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.011904761904761904, "train_stats/max_log_achievement_make_wood_pickaxe": 1.869047619047619, "train_stats/max_log_achievement_make_wood_sword": 1.0, "train_stats/max_log_achievement_place_furnace": 2.107142857142857, "train_stats/max_log_achievement_place_plant": 1.8333333333333333, "train_stats/max_log_achievement_place_stone": 4.464285714285714, "train_stats/max_log_achievement_place_table": 2.5595238095238093, "train_stats/max_log_achievement_wake_up": 1.9166666666666667, "train_stats/mean_log_entropy": 0.6291191453735033, "eval_stats/sum_log_reward": 10.91250029206276, "eval_stats/max_log_achievement_collect_coal": 0.875, "eval_stats/max_log_achievement_collect_drink": 8.4375, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.9375, "eval_stats/max_log_achievement_collect_stone": 11.8125, "eval_stats/max_log_achievement_collect_wood": 11.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.3125, "eval_stats/max_log_achievement_eat_cow": 0.3125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.3125, "eval_stats/max_log_achievement_make_wood_sword": 0.9375, "eval_stats/max_log_achievement_place_furnace": 1.5625, "eval_stats/max_log_achievement_place_plant": 1.6875, "eval_stats/max_log_achievement_place_stone": 4.5, "eval_stats/max_log_achievement_place_table": 2.6875, "eval_stats/max_log_achievement_wake_up": 1.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 2.5388100766576827e-05, "report/cont_loss_std": 0.0007426214870065451, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.012466473504900932, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.0415560609544627e-06, "report/cont_pred": 0.9980700016021729, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 12.741081237792969, "report/dyn_loss_std": 9.254880905151367, "report/image_loss_mean": 6.131579399108887, "report/image_loss_std": 10.478103637695312, "report/model_loss_mean": 13.829391479492188, "report/model_loss_std": 14.395920753479004, "report/post_ent_mag": 64.33793640136719, "report/post_ent_max": 64.33793640136719, "report/post_ent_mean": 43.805423736572266, "report/post_ent_min": 21.632951736450195, "report/post_ent_std": 7.304649829864502, "report/prior_ent_mag": 71.0869369506836, "report/prior_ent_max": 71.0869369506836, "report/prior_ent_mean": 56.96370315551758, "report/prior_ent_min": 42.61393737792969, "report/prior_ent_std": 4.940094470977783, "report/rep_loss_mean": 12.741081237792969, "report/rep_loss_std": 9.254880905151367, "report/reward_avg": 0.04531250149011612, "report/reward_loss_mean": 0.05313769727945328, "report/reward_loss_std": 0.1919502168893814, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0009064674377441, "report/reward_neg_acc": 0.9958974123001099, "report/reward_neg_loss": 0.02046852931380272, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7031872868537903, "report/reward_pred": 0.04441387578845024, "report/reward_rate": 0.0478515625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.2392654298309935e-06, "eval/cont_loss_std": 1.9050352420890704e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0002007916773436591, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.5670682879972446e-07, "eval/cont_pred": 0.9960941076278687, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 15.739744186401367, "eval/dyn_loss_std": 10.832621574401855, "eval/image_loss_mean": 9.34475326538086, "eval/image_loss_std": 13.119513511657715, "eval/model_loss_mean": 18.880943298339844, "eval/model_loss_std": 17.10361099243164, "eval/post_ent_mag": 65.34121704101562, "eval/post_ent_max": 65.34121704101562, "eval/post_ent_mean": 43.17978286743164, "eval/post_ent_min": 20.430784225463867, "eval/post_ent_std": 8.172966003417969, "eval/prior_ent_mag": 71.0869369506836, "eval/prior_ent_max": 71.0869369506836, "eval/prior_ent_mean": 57.233856201171875, "eval/prior_ent_min": 43.861812591552734, "eval/prior_ent_std": 5.0302276611328125, "eval/rep_loss_mean": 15.739744186401367, "eval/rep_loss_std": 10.832621574401855, "eval/reward_avg": 0.03281249850988388, "eval/reward_loss_mean": 0.09234248101711273, "eval/reward_loss_std": 0.5387741923332214, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006186962127686, "eval/reward_neg_acc": 0.9908813834190369, "eval/reward_neg_loss": 0.03140222653746605, "eval/reward_pos_acc": 0.8108108043670654, "eval/reward_pos_loss": 1.717965006828308, "eval/reward_pred": 0.026264939457178116, "eval/reward_rate": 0.0361328125, "replay/size": 1000000.0, "replay/inserts": 22824.0, "replay/samples": 22816.0, "replay/insert_wait_avg": 1.3757224171528515e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.125626188173869e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2521936096699381e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.6749999523163, "timer/env.step_count": 2853.0, "timer/env.step_total": 217.60253143310547, "timer/env.step_frac": 0.21745574881302576, "timer/env.step_avg": 0.07627147964707517, "timer/env.step_min": 0.0249478816986084, "timer/env.step_max": 3.447286367416382, "timer/replay._sample_count": 22816.0, "timer/replay._sample_total": 11.830217123031616, "timer/replay._sample_frac": 0.011822237113543702, "timer/replay._sample_avg": 0.0005185053086882722, "timer/replay._sample_min": 0.00037598609924316406, "timer/replay._sample_max": 0.027655601501464844, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3634.0, "timer/agent.policy_total": 62.5093035697937, "timer/agent.policy_frac": 0.06246713825445061, "timer/agent.policy_avg": 0.017201239287229966, "timer/agent.policy_min": 0.00978851318359375, "timer/agent.policy_max": 0.11423039436340332, "timer/dataset_train_count": 1426.0, "timer/dataset_train_total": 0.15815401077270508, "timer/dataset_train_frac": 0.0001580473288332789, "timer/dataset_train_avg": 0.00011090744093457579, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0008313655853271484, "timer/agent.train_count": 1426.0, "timer/agent.train_total": 643.2044677734375, "timer/agent.train_frac": 0.642770597650673, "timer/agent.train_avg": 0.45105502648908663, "timer/agent.train_min": 0.4353630542755127, "timer/agent.train_max": 1.804511308670044, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5131857395172119, "timer/agent.report_frac": 0.0005128395728300057, "timer/agent.report_avg": 0.25659286975860596, "timer/agent.report_min": 0.23818564414978027, "timer/agent.report_max": 0.27500009536743164, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8829188370513648e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 22.808272769348154}
{"step": 1395384, "time": 63436.53697037697, "episode/length": 287.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9756944444444444, "episode/intrinsic_return": 0.0}
{"step": 1395704, "time": 63449.45671105385, "episode/length": 217.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1395760, "time": 63453.11753344536, "episode/length": 119.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 1396016, "time": 63463.350356817245, "episode/length": 192.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 1396400, "time": 63477.985412597656, "episode/length": 86.0, "episode/score": 5.10000005364418, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 1396504, "time": 63482.81273174286, "episode/length": 181.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1396616, "time": 63488.28553009033, "episode/length": 214.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 1396992, "time": 63502.94939827919, "episode/length": 73.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9324324324324325, "episode/intrinsic_return": 0.0}
{"step": 1397400, "time": 63517.99150943756, "episode/length": 252.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 1397792, "time": 63533.14908742905, "episode/length": 221.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 1398184, "time": 63547.83375144005, "episode/length": 209.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1398440, "time": 63558.179532289505, "episode/length": 227.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1398568, "time": 63564.07761144638, "episode/length": 485.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9979423868312757, "episode/intrinsic_return": 0.0}
{"step": 1398872, "time": 63576.136647462845, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 1398952, "time": 63580.434022665024, "episode/length": 445.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9977578475336323, "episode/intrinsic_return": 0.0}
{"step": 1399368, "time": 63596.19298291206, "episode/length": 196.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 1399408, "time": 63599.386629104614, "episode/length": 120.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 1399416, "time": 63601.11553621292, "episode/length": 67.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 1400048, "time": 63648.216824769974, "eval_episode/length": 182.0, "eval_episode/score": 11.099999979138374, "eval_episode/reward_rate": 0.994535519125683}
{"step": 1400048, "time": 63651.421540260315, "eval_episode/length": 217.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 1400048, "time": 63655.31040740013, "eval_episode/length": 265.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9962406015037594}
{"step": 1400048, "time": 63657.0338306427, "eval_episode/length": 269.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 1400048, "time": 63661.79989171028, "eval_episode/length": 341.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9853801169590644}
{"step": 1400048, "time": 63663.68488240242, "eval_episode/length": 348.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.994269340974212}
{"step": 1400048, "time": 63666.43355321884, "eval_episode/length": 193.0, "eval_episode/score": 13.100000001490116, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 1400048, "time": 63666.440578222275, "eval_episode/length": 158.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9748427672955975}
{"step": 1400328, "time": 63675.69906759262, "episode/length": 219.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1400736, "time": 63691.5139400959, "episode/length": 318.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9811912225705329, "episode/intrinsic_return": 0.0}
{"step": 1401520, "time": 63721.524961709976, "episode/length": 262.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9771863117870723, "episode/intrinsic_return": 0.0}
{"step": 1401576, "time": 63724.79115819931, "episode/length": 155.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9551282051282052, "episode/intrinsic_return": 0.0}
{"step": 1402288, "time": 63750.67979311943, "episode/length": 416.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9976019184652278, "episode/intrinsic_return": 0.0}
{"step": 1402336, "time": 63753.8906519413, "episode/length": 199.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 1402456, "time": 63759.28546619415, "episode/length": 385.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9922279792746114, "episode/intrinsic_return": 0.0}
{"step": 1402488, "time": 63761.93353223801, "episode/length": 840.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.990487514863258, "episode/intrinsic_return": 0.0}
{"step": 1403352, "time": 63792.76515293121, "episode/length": 221.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 1403448, "time": 63797.817038059235, "episode/length": 806.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9888475836431226, "episode/intrinsic_return": 0.0}
{"step": 1403520, "time": 63802.11944055557, "episode/length": 513.0, "episode/score": 15.10000005364418, "episode/reward_rate": 0.9883268482490273, "episode/intrinsic_return": 0.0}
{"step": 1403584, "time": 63805.901372909546, "episode/length": 155.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 1403912, "time": 63818.24176740646, "episode/length": 202.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 1404304, "time": 63833.40036511421, "episode/length": 347.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.985632183908046, "episode/intrinsic_return": 0.0}
{"step": 1404560, "time": 63843.66372847557, "episode/length": 150.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 1405024, "time": 63861.32144188881, "episode/length": 196.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 1405120, "time": 63866.253105163574, "episode/length": 191.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 1405344, "time": 63875.558270692825, "episode/length": 227.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1405656, "time": 63887.40460896492, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 1405888, "time": 63897.09708571434, "episode/length": 424.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9929411764705882, "episode/intrinsic_return": 0.0}
{"step": 1406056, "time": 63904.12187051773, "episode/length": 449.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 1406528, "time": 63921.9567258358, "episode/length": 187.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 1406592, "time": 63925.7004442215, "episode/length": 183.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 1406992, "time": 63940.848130464554, "episode/length": 205.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 1407232, "time": 63950.75489616394, "episode/length": 196.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 1407456, "time": 63959.89993715286, "episode/length": 442.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9932279909706546, "episode/intrinsic_return": 0.0}
{"step": 1407744, "time": 63971.27078652382, "episode/length": 231.0, "episode/score": 13.099999971687794, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 1407888, "time": 63977.83712887764, "episode/length": 228.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 1408064, "time": 63985.35822510719, "episode/length": 191.0, "episode/score": 13.099999964237213, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 1408248, "time": 63992.89179968834, "episode/length": 206.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 1409080, "time": 64024.34320616722, "episode/length": 260.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 1409272, "time": 64032.46102190018, "episode/length": 226.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 1409528, "time": 64042.72174835205, "episode/length": 222.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 1409720, "time": 64050.81657218933, "episode/length": 228.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 1409816, "time": 64055.72352671623, "episode/length": 67.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 1409856, "time": 64059.02925133705, "episode/length": 661.0, "episode/score": 13.099999994039536, "episode/reward_rate": 0.9984894259818731, "episode/intrinsic_return": 0.0}
{"step": 1410016, "time": 64066.0841755867, "episode/length": 243.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 1410032, "time": 64084.141543865204, "eval_episode/length": 58.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 1410032, "time": 64091.714374780655, "eval_episode/length": 188.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9682539682539683}
{"step": 1410032, "time": 64093.67239046097, "eval_episode/length": 194.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9641025641025641}
{"step": 1410032, "time": 64096.604501247406, "eval_episode/length": 218.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 1410032, "time": 64098.52848982811, "eval_episode/length": 224.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 1410032, "time": 64100.680695295334, "eval_episode/length": 42.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 1410032, "time": 64103.30999040604, "eval_episode/length": 257.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 1410032, "time": 64106.29139947891, "eval_episode/length": 283.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9823943661971831}
{"step": 1410040, "time": 64106.34976053238, "episode/length": 350.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9971509971509972, "episode/intrinsic_return": 0.0}
{"step": 1411200, "time": 64147.578179359436, "episode/length": 368.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.989159891598916, "episode/intrinsic_return": 0.0}
{"step": 1411392, "time": 64155.828813791275, "episode/length": 208.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 1411488, "time": 64160.7739071846, "episode/length": 300.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 1411560, "time": 64164.58927536011, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9678899082568807, "episode/intrinsic_return": 0.0}
{"step": 1411680, "time": 64170.50294852257, "episode/length": 227.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1411696, "time": 64172.723747730255, "episode/length": 209.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 1411808, "time": 64178.102051734924, "episode/length": 220.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 1412704, "time": 64210.119572639465, "episode/length": 163.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 1412920, "time": 64219.02003669739, "episode/length": 214.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 1413504, "time": 64240.76918745041, "episode/length": 227.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 1413624, "time": 64246.47355008125, "episode/length": 257.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 1414232, "time": 64268.663576602936, "episode/length": 587.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 1414432, "time": 64277.557609558105, "episode/length": 341.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9883040935672515, "episode/intrinsic_return": 0.0}
{"step": 1414912, "time": 64295.40612769127, "episode/length": 387.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9768041237113402, "episode/intrinsic_return": 0.0}
{"step": 1415128, "time": 64304.12887144089, "episode/length": 202.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 1415504, "time": 64318.7978181839, "episode/length": 158.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 1415600, "time": 64323.674349069595, "episode/length": 334.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9880597014925373, "episode/intrinsic_return": 0.0}
{"step": 1415936, "time": 64336.71118974686, "episode/length": 288.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 1416360, "time": 64352.6360514164, "episode/length": 608.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 1416416, "time": 64356.45645046234, "episode/length": 247.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 1416456, "time": 64359.13422870636, "episode/length": 468.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.997867803837953, "episode/intrinsic_return": 0.0}
{"step": 1416512, "time": 64362.81406736374, "episode/length": 199.0, "episode/score": 11.100000038743019, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 1416792, "time": 64373.79989886284, "episode/length": 160.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 1417360, "time": 64396.78744387627, "episode/length": 124.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.0}
{"step": 1417752, "time": 64411.55052495003, "episode/length": 48.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9183673469387755, "episode/intrinsic_return": 0.0}
{"step": 1418040, "time": 64423.087252140045, "episode/length": 197.0, "episode/score": 13.099999994039536, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 1418280, "time": 64433.03469538689, "episode/length": 334.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.982089552238806, "episode/intrinsic_return": 0.0}
{"step": 1418288, "time": 64435.20680785179, "episode/length": 293.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1418289, "time": 64437.49042868614, "train_stats/sum_log_reward": 11.0047620733579, "train_stats/max_log_achievement_collect_coal": 0.9285714285714286, "train_stats/max_log_achievement_collect_drink": 6.357142857142857, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.9404761904761905, "train_stats/max_log_achievement_collect_stone": 13.976190476190476, "train_stats/max_log_achievement_collect_wood": 10.785714285714286, "train_stats/max_log_achievement_defeat_skeleton": 0.09523809523809523, "train_stats/max_log_achievement_defeat_zombie": 1.2738095238095237, "train_stats/max_log_achievement_eat_cow": 0.4642857142857143, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.011904761904761904, "train_stats/max_log_achievement_make_stone_sword": 0.03571428571428571, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4880952380952381, "train_stats/max_log_achievement_make_wood_sword": 1.2619047619047619, "train_stats/max_log_achievement_place_furnace": 2.119047619047619, "train_stats/max_log_achievement_place_plant": 1.5238095238095237, "train_stats/max_log_achievement_place_stone": 4.178571428571429, "train_stats/max_log_achievement_place_table": 2.880952380952381, "train_stats/max_log_achievement_wake_up": 2.0833333333333335, "train_stats/mean_log_entropy": 0.6526803714888436, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.776575475305944, "train/action_min": 0.0, "train/action_std": 3.7215599246792026, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.02734529032938547, "train/actor_opt_grad_steps": 87830.0, "train/actor_opt_loss": -10.394190309269653, "train/adv_mag": 0.412622156051489, "train/adv_max": 0.3705986692355229, "train/adv_mean": 0.0013704638496909122, "train/adv_min": -0.3235304664064954, "train/adv_std": 0.041253750870277835, "train/cont_avg": 0.9958205856643356, "train/cont_loss_mean": 0.0001977706097921608, "train/cont_loss_std": 0.006210401578306724, "train/cont_neg_acc": 0.994718310278906, "train/cont_neg_loss": 0.02275489151771952, "train/cont_pos_acc": 0.9999725135056289, "train/cont_pos_loss": 0.00010800285145367777, "train/cont_pred": 0.9958119359049764, "train/cont_rate": 0.9958205856643356, "train/dyn_loss_mean": 13.245374172717542, "train/dyn_loss_std": 9.329439163208008, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9402586434270952, "train/extr_critic_critic_opt_grad_steps": 87830.0, "train/extr_critic_critic_opt_loss": 14936.472499180507, "train/extr_critic_mag": 10.8941283592811, "train/extr_critic_max": 10.8941283592811, "train/extr_critic_mean": 2.7795394400616624, "train/extr_critic_min": -0.1693741383252444, "train/extr_critic_std": 2.651043252511458, "train/extr_return_normed_mag": 1.4487350545563065, "train/extr_return_normed_max": 1.4487350545563065, "train/extr_return_normed_mean": 0.3357336518022564, "train/extr_return_normed_min": -0.06773669490186901, "train/extr_return_normed_std": 0.32688184488903393, "train/extr_return_rate": 0.7889528220350092, "train/extr_return_raw_mag": 11.909431944360266, "train/extr_return_raw_max": 11.909431944360266, "train/extr_return_raw_mean": 2.790752119951315, "train/extr_return_raw_min": -0.5148389389464906, "train/extr_return_raw_std": 2.6780384762303813, "train/extr_reward_mag": 1.0498592119950514, "train/extr_reward_max": 1.0498592119950514, "train/extr_reward_mean": 0.046471472321586174, "train/extr_reward_min": -0.5127721991572347, "train/extr_reward_std": 0.2019127841804411, "train/image_loss_mean": 6.613972030319534, "train/image_loss_std": 12.054531030721598, "train/model_loss_mean": 14.626370750107132, "train/model_loss_std": 15.840825947848233, "train/model_opt_grad_norm": 44.996836535580506, "train/model_opt_grad_steps": 87751.76223776223, "train/model_opt_loss": 23597.178014368445, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1608.3916083916083, "train/policy_entropy_mag": 2.657397842073774, "train/policy_entropy_max": 2.657397842073774, "train/policy_entropy_mean": 0.7956276108751764, "train/policy_entropy_min": 0.07937502006550769, "train/policy_entropy_std": 0.8965877786382929, "train/policy_logprob_mag": 7.438383819339992, "train/policy_logprob_max": -0.009455658391222253, "train/policy_logprob_mean": -0.7952588358959118, "train/policy_logprob_min": -7.438383819339992, "train/policy_logprob_std": 1.2449049541166612, "train/policy_randomness_mag": 0.9379448223780918, "train/policy_randomness_max": 0.9379448223780918, "train/policy_randomness_mean": 0.28082163486030554, "train/policy_randomness_min": 0.028015898801125847, "train/policy_randomness_std": 0.3164561395044927, "train/post_ent_mag": 61.615728391634, "train/post_ent_max": 61.615728391634, "train/post_ent_mean": 43.7166415394603, "train/post_ent_min": 20.656296736710555, "train/post_ent_std": 7.824688981463026, "train/prior_ent_mag": 71.16236973475743, "train/prior_ent_max": 71.16236973475743, "train/prior_ent_mean": 57.080282411375244, "train/prior_ent_min": 40.60491865998382, "train/prior_ent_std": 4.914206654875429, "train/rep_loss_mean": 13.245374172717542, "train/rep_loss_std": 9.329439163208008, "train/reward_avg": 0.03989838248678854, "train/reward_loss_mean": 0.06497642476033498, "train/reward_loss_std": 0.26180419471714045, "train/reward_max_data": 1.0349650433013489, "train/reward_max_pred": 1.02060268975638, "train/reward_neg_acc": 0.9913942017755308, "train/reward_neg_loss": 0.031476387929926804, "train/reward_pos_acc": 0.9789803674171021, "train/reward_pos_loss": 0.7999588155246281, "train/reward_pred": 0.038960107804074155, "train/reward_rate": 0.04375409746503497, "eval_stats/sum_log_reward": 10.225000143051147, "eval_stats/max_log_achievement_collect_coal": 1.3125, "eval_stats/max_log_achievement_collect_drink": 5.0625, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 9.625, "eval_stats/max_log_achievement_collect_wood": 10.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.125, "eval_stats/max_log_achievement_eat_cow": 0.5625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 1.4375, "eval_stats/max_log_achievement_place_furnace": 1.375, "eval_stats/max_log_achievement_place_plant": 1.3125, "eval_stats/max_log_achievement_place_stone": 3.4375, "eval_stats/max_log_achievement_place_table": 2.8125, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 2.064740783680463e-06, "report/cont_loss_std": 3.091221151407808e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00018566317157819867, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.7054484260370373e-06, "report/cont_pred": 0.9980455636978149, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 13.642404556274414, "report/dyn_loss_std": 9.324950218200684, "report/image_loss_mean": 6.801557540893555, "report/image_loss_std": 12.332103729248047, "report/model_loss_mean": 15.024704933166504, "report/model_loss_std": 16.253480911254883, "report/post_ent_mag": 61.460060119628906, "report/post_ent_max": 61.460060119628906, "report/post_ent_mean": 43.16413116455078, "report/post_ent_min": 19.60818862915039, "report/post_ent_std": 7.889171123504639, "report/prior_ent_mag": 70.99972534179688, "report/prior_ent_max": 70.99972534179688, "report/prior_ent_mean": 57.037376403808594, "report/prior_ent_min": 44.026153564453125, "report/prior_ent_std": 4.382285118103027, "report/rep_loss_mean": 13.642404556274414, "report/rep_loss_std": 9.324950218200684, "report/reward_avg": 0.03398437425494194, "report/reward_loss_mean": 0.037701938301324844, "report/reward_loss_std": 0.17374803125858307, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018155574798584, "report/reward_neg_acc": 0.9959514141082764, "report/reward_neg_loss": 0.01044535543769598, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7857438325881958, "report/reward_pred": 0.03244452178478241, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.8812289656343637e-06, "eval/cont_loss_std": 6.324721471173689e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0007885700324550271, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.726432164010475e-07, "eval/cont_pred": 0.9970721006393433, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.959524154663086, "eval/dyn_loss_std": 10.1920747756958, "eval/image_loss_mean": 8.70905876159668, "eval/image_loss_std": 13.336172103881836, "eval/model_loss_mean": 19.616107940673828, "eval/model_loss_std": 17.55667495727539, "eval/post_ent_mag": 61.72833251953125, "eval/post_ent_max": 61.72833251953125, "eval/post_ent_mean": 41.82301330566406, "eval/post_ent_min": 19.413311004638672, "eval/post_ent_std": 7.062293529510498, "eval/prior_ent_mag": 70.99972534179688, "eval/prior_ent_max": 70.99972534179688, "eval/prior_ent_mean": 57.99969482421875, "eval/prior_ent_min": 45.49648666381836, "eval/prior_ent_std": 4.051551342010498, "eval/rep_loss_mean": 17.959524154663086, "eval/rep_loss_std": 10.1920747756958, "eval/reward_avg": 0.05400390550494194, "eval/reward_loss_mean": 0.1313326060771942, "eval/reward_loss_std": 0.7071923017501831, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0923819541931152, "eval/reward_neg_acc": 0.9824016690254211, "eval/reward_neg_loss": 0.04245426505804062, "eval/reward_pos_acc": 0.8793103694915771, "eval/reward_pos_loss": 1.611616611480713, "eval/reward_pred": 0.048063308000564575, "eval/reward_rate": 0.056640625, "replay/size": 1000000.0, "replay/inserts": 22912.0, "replay/samples": 22912.0, "replay/insert_wait_avg": 1.3530400045757186e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.094285786484873e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5288.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2635553478292908e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.9705803394318, "timer/env.step_count": 2864.0, "timer/env.step_total": 217.3757176399231, "timer/env.step_frac": 0.21716494161717562, "timer/env.step_avg": 0.0758993427513698, "timer/env.step_min": 0.024591684341430664, "timer/env.step_max": 1.8239374160766602, "timer/replay._sample_count": 22912.0, "timer/replay._sample_total": 11.839388132095337, "timer/replay._sample_frac": 0.01182790819694278, "timer/replay._sample_avg": 0.0005167330714077922, "timer/replay._sample_min": 0.0004296302795410156, "timer/replay._sample_max": 0.011285066604614258, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3525.0, "timer/agent.policy_total": 62.34009504318237, "timer/agent.policy_frac": 0.06227964764163466, "timer/agent.policy_avg": 0.01768513334558365, "timer/agent.policy_min": 0.009682416915893555, "timer/agent.policy_max": 0.1941514015197754, "timer/dataset_train_count": 1432.0, "timer/dataset_train_total": 0.1580066680908203, "timer/dataset_train_frac": 0.0001578534586273653, "timer/dataset_train_avg": 0.00011033985201872927, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0010535717010498047, "timer/agent.train_count": 1432.0, "timer/agent.train_total": 647.9674491882324, "timer/agent.train_frac": 0.6473391545318994, "timer/agent.train_avg": 0.45249123546664277, "timer/agent.train_min": 0.4368782043457031, "timer/agent.train_max": 1.9422693252563477, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4722597599029541, "timer/agent.report_frac": 0.00047180183831457823, "timer/agent.report_avg": 0.23612987995147705, "timer/agent.report_min": 0.23061585426330566, "timer/agent.report_max": 0.24164390563964844, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9773424886862575e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 22.889467999847593}
{"step": 1418528, "time": 64445.83360123634, "episode/length": 251.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 1418696, "time": 64452.910396814346, "episode/length": 445.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9798206278026906, "episode/intrinsic_return": 0.0}
{"step": 1419056, "time": 64466.976544857025, "episode/length": 282.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9752650176678446, "episode/intrinsic_return": 0.0}
{"step": 1419280, "time": 64476.14049530029, "episode/length": 357.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9888268156424581, "episode/intrinsic_return": 0.0}
{"step": 1419920, "time": 64499.507704496384, "episode/length": 234.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1419944, "time": 64501.673929691315, "episode/length": 273.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9744525547445255, "episode/intrinsic_return": 0.0}
{"step": 1420016, "time": 64526.25732636452, "eval_episode/length": 159.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.975}
{"step": 1420016, "time": 64530.69745159149, "eval_episode/length": 219.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 1420016, "time": 64533.839094400406, "eval_episode/length": 252.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9960474308300395}
{"step": 1420016, "time": 64536.78796625137, "eval_episode/length": 282.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9787985865724381}
{"step": 1420016, "time": 64538.93306398392, "eval_episode/length": 292.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9863481228668942}
{"step": 1420016, "time": 64540.541727781296, "eval_episode/length": 293.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 1420016, "time": 64544.7392475605, "eval_episode/length": 351.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 1420016, "time": 64546.80153846741, "eval_episode/length": 195.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 1420032, "time": 64547.36182260513, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 1420200, "time": 64554.49695920944, "episode/length": 239.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 1420200, "time": 64554.50546646118, "episode/length": 238.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 1420880, "time": 64581.36594748497, "episode/length": 116.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 1420968, "time": 64585.73591709137, "episode/length": 210.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 1421424, "time": 64603.2030916214, "episode/length": 340.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9970674486803519, "episode/intrinsic_return": 0.0}
{"step": 1421536, "time": 64608.88852238655, "episode/length": 166.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 1421640, "time": 64613.751259088516, "episode/length": 322.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9907120743034056, "episode/intrinsic_return": 0.0}
{"step": 1421672, "time": 64616.48500275612, "episode/length": 183.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 1422584, "time": 64649.27164912224, "episode/length": 201.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 1422624, "time": 64652.41044616699, "episode/length": 323.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9969135802469136, "episode/intrinsic_return": 0.0}
{"step": 1423088, "time": 64669.97046780586, "episode/length": 180.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 1423104, "time": 64672.12027716637, "episode/length": 277.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 1423264, "time": 64679.34075498581, "episode/length": 229.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 1423600, "time": 64692.350558042526, "episode/length": 240.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 1424696, "time": 64731.23312282562, "episode/length": 258.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 1424744, "time": 64734.4928855896, "episode/length": 184.0, "episode/score": 13.100000016391277, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 1424920, "time": 64742.11084628105, "episode/length": 624.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9856, "episode/intrinsic_return": 0.0}
{"step": 1425072, "time": 64749.04760289192, "episode/length": 247.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 1425152, "time": 64753.335488557816, "episode/length": 255.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 1425224, "time": 64757.27146911621, "episode/length": 460.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9934924078091106, "episode/intrinsic_return": 0.0}
{"step": 1425256, "time": 64759.885061979294, "episode/length": 41.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1425808, "time": 64782.34270143509, "episode/length": 402.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9975186104218362, "episode/intrinsic_return": 0.0}
{"step": 1425880, "time": 64786.25418996811, "episode/length": 100.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9405940594059405, "episode/intrinsic_return": 0.0}
{"step": 1426128, "time": 64796.50794959068, "episode/length": 315.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9810126582278481, "episode/intrinsic_return": 0.0}
{"step": 1426416, "time": 64807.92601776123, "episode/length": 157.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9810126582278481, "episode/intrinsic_return": 0.0}
{"step": 1426640, "time": 64817.22369146347, "episode/length": 236.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 1427240, "time": 64839.106447696686, "episode/length": 178.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 1427296, "time": 64842.744436979294, "episode/length": 324.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 1427704, "time": 64858.050054073334, "episode/length": 309.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9903225806451613, "episode/intrinsic_return": 0.0}
{"step": 1428112, "time": 64873.764070272446, "episode/length": 278.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 1428136, "time": 64875.95381760597, "episode/length": 186.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 1428488, "time": 64889.76340818405, "episode/length": 403.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1428608, "time": 64895.63257098198, "episode/length": 309.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9870967741935484, "episode/intrinsic_return": 0.0}
{"step": 1428984, "time": 64910.005187511444, "episode/length": 320.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9844236760124611, "episode/intrinsic_return": 0.0}
{"step": 1429616, "time": 64933.29092693329, "episode/length": 140.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 1429744, "time": 64939.357850790024, "episode/length": 312.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9936102236421726, "episode/intrinsic_return": 0.0}
{"step": 1429880, "time": 64945.303520679474, "episode/length": 217.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 1430000, "time": 64975.65920543671, "eval_episode/length": 191.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 1430000, "time": 64977.46191430092, "eval_episode/length": 197.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 1430000, "time": 64979.210151195526, "eval_episode/length": 198.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 1430000, "time": 64981.759330272675, "eval_episode/length": 221.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9819819819819819}
{"step": 1430000, "time": 64983.84980964661, "eval_episode/length": 234.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9744680851063829}
{"step": 1430000, "time": 64986.53067922592, "eval_episode/length": 67.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9264705882352942}
{"step": 1430000, "time": 64988.317058324814, "eval_episode/length": 263.0, "eval_episode/score": 13.099999979138374, "eval_episode/reward_rate": 0.9962121212121212}
{"step": 1430000, "time": 64990.99354338646, "eval_episode/length": 288.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9965397923875432}
{"step": 1430264, "time": 64999.83844304085, "episode/length": 159.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 1430592, "time": 65013.223804950714, "episode/length": 309.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 1430912, "time": 65025.67274260521, "episode/length": 161.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 1431240, "time": 65038.441475868225, "episode/length": 492.0, "episode/score": 14.100000008940697, "episode/reward_rate": 0.9817444219066938, "episode/intrinsic_return": 0.0}
{"step": 1432112, "time": 65069.976513147354, "episode/length": 278.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 1432136, "time": 65072.28594207764, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 1432192, "time": 65075.987147808075, "episode/length": 447.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9977678571428571, "episode/intrinsic_return": 0.0}
{"step": 1432232, "time": 65078.676986694336, "episode/length": 310.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.977491961414791, "episode/intrinsic_return": 0.0}
{"step": 1432520, "time": 65090.061549663544, "episode/length": 601.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 1432632, "time": 65095.51946544647, "episode/length": 295.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 1432704, "time": 65099.77646899223, "episode/length": 223.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 1433024, "time": 65112.14339542389, "episode/length": 48.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 1433568, "time": 65132.35658597946, "episode/length": 178.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 1433608, "time": 65135.37098526955, "episode/length": 186.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 1433744, "time": 65143.77142930031, "episode/length": 188.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 1434272, "time": 65163.21955323219, "episode/length": 82.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 1434352, "time": 65167.589262247086, "episode/length": 388.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9922879177377892, "episode/intrinsic_return": 0.0}
{"step": 1434872, "time": 65186.61878013611, "episode/length": 293.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 1434984, "time": 65192.086321115494, "episode/length": 284.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9964912280701754, "episode/intrinsic_return": 0.0}
{"step": 1435160, "time": 65199.72624564171, "episode/length": 198.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 1435248, "time": 65204.55600261688, "episode/length": 187.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 1435696, "time": 65221.38254451752, "episode/length": 333.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9910179640718563, "episode/intrinsic_return": 0.0}
{"step": 1435784, "time": 65225.78723406792, "episode/length": 66.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9253731343283582, "episode/intrinsic_return": 0.0}
{"step": 1435856, "time": 65230.0207362175, "episode/length": 457.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9978165938864629, "episode/intrinsic_return": 0.0}
{"step": 1436520, "time": 65254.007242918015, "episode/length": 169.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 1436752, "time": 65263.66374254227, "episode/length": 299.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 1437248, "time": 65282.166497945786, "episode/length": 182.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 1437416, "time": 65289.22281551361, "episode/length": 214.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 1437568, "time": 65296.29492139816, "episode/length": 411.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9927184466019418, "episode/intrinsic_return": 0.0}
{"step": 1437672, "time": 65301.28104138374, "episode/length": 335.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 1438712, "time": 65338.28562784195, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 1438864, "time": 65345.293624162674, "episode/length": 498.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9859719438877755, "episode/intrinsic_return": 0.0}
{"step": 1438872, "time": 65347.05712270737, "episode/length": 264.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9735849056603774, "episode/intrinsic_return": 0.0}
{"step": 1438984, "time": 65352.348632097244, "episode/length": 390.0, "episode/score": 13.099999964237213, "episode/reward_rate": 0.989769820971867, "episode/intrinsic_return": 0.0}
{"step": 1439272, "time": 65363.8221385479, "episode/length": 212.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 1439368, "time": 65369.1377696991, "episode/length": 243.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 1439416, "time": 65372.36669230461, "episode/length": 361.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9861878453038674, "episode/intrinsic_return": 0.0}
{"step": 1440088, "time": 65424.199981212616, "eval_episode/length": 210.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.995260663507109}
{"step": 1440088, "time": 65426.065031051636, "eval_episode/length": 216.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9631336405529954}
{"step": 1440088, "time": 65427.77492904663, "eval_episode/length": 219.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 1440088, "time": 65429.93469142914, "eval_episode/length": 230.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 1440088, "time": 65432.87008857727, "eval_episode/length": 257.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9961240310077519}
{"step": 1440088, "time": 65438.18339753151, "eval_episode/length": 333.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9850299401197605}
{"step": 1440088, "time": 65441.873935461044, "eval_episode/length": 378.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9947229551451188}
{"step": 1440088, "time": 65444.85628628731, "eval_episode/length": 177.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 1440089, "time": 65445.972641944885, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.827934713924632, "train/action_min": 0.0, "train/action_std": 3.7389932222226085, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.026968847624683642, "train/actor_opt_grad_steps": 89225.0, "train/actor_opt_loss": -11.12712846477242, "train/adv_mag": 0.3813322148121455, "train/adv_max": 0.34520253462388234, "train/adv_mean": 0.0011234253094685568, "train/adv_min": -0.3100601109292577, "train/adv_std": 0.04053770868545946, "train/cont_avg": 0.9962158203125, "train/cont_loss_mean": 0.000196974658530988, "train/cont_loss_std": 0.005632277786100517, "train/cont_neg_acc": 0.9966911765582421, "train/cont_neg_loss": 0.013645160590546284, "train/cont_pos_acc": 0.9999278779415524, "train/cont_pos_loss": 0.00014342557726186345, "train/cont_pred": 0.9961636495940825, "train/cont_rate": 0.9962158203125, "train/dyn_loss_mean": 13.013372217907625, "train/dyn_loss_std": 9.3175449441461, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9881139060153681, "train/extr_critic_critic_opt_grad_steps": 89225.0, "train/extr_critic_critic_opt_loss": 15038.537669462316, "train/extr_critic_mag": 10.731860434307771, "train/extr_critic_max": 10.731860434307771, "train/extr_critic_mean": 2.528841088799869, "train/extr_critic_min": -0.18938488644712112, "train/extr_critic_std": 2.573363615309491, "train/extr_return_normed_mag": 1.4551441161071552, "train/extr_return_normed_max": 1.4551441161071552, "train/extr_return_normed_mean": 0.31589067157577067, "train/extr_return_normed_min": -0.061162741402821505, "train/extr_return_normed_std": 0.32102048714809556, "train/extr_return_rate": 0.7350873524213538, "train/extr_return_raw_mag": 11.748750314993018, "train/extr_return_raw_max": 11.748750314993018, "train/extr_return_raw_mean": 2.537892778130139, "train/extr_return_raw_min": -0.5107671768568894, "train/extr_return_raw_std": 2.5957569304634545, "train/extr_reward_mag": 1.059179986224455, "train/extr_reward_max": 1.059179986224455, "train/extr_reward_mean": 0.044635619721649325, "train/extr_reward_min": -0.47435900744269877, "train/extr_reward_std": 0.1975112302119241, "train/image_loss_mean": 6.525743565138648, "train/image_loss_std": 12.361366016023299, "train/model_loss_mean": 14.395532797364627, "train/model_loss_std": 16.113134706721585, "train/model_opt_grad_norm": 45.14595714737387, "train/model_opt_grad_steps": 89145.63970588235, "train/model_opt_loss": 20763.842787798712, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1443.014705882353, "train/policy_entropy_mag": 2.668217545046526, "train/policy_entropy_max": 2.668217545046526, "train/policy_entropy_mean": 0.8294362951727474, "train/policy_entropy_min": 0.07937502570669441, "train/policy_entropy_std": 0.9089899545206743, "train/policy_logprob_mag": 7.4383838176727295, "train/policy_logprob_max": -0.009455659303485471, "train/policy_logprob_mean": -0.8290225379168987, "train/policy_logprob_min": -7.4383838176727295, "train/policy_logprob_std": 1.2598324663498823, "train/policy_randomness_mag": 0.9417637012460652, "train/policy_randomness_max": 0.9417637012460652, "train/policy_randomness_mean": 0.29275461417787213, "train/policy_randomness_min": 0.02801590077305103, "train/policy_randomness_std": 0.3208335622706834, "train/post_ent_mag": 61.38795316920561, "train/post_ent_max": 61.38795316920561, "train/post_ent_mean": 43.842070803922766, "train/post_ent_min": 20.506952916874607, "train/post_ent_std": 7.74011291475857, "train/prior_ent_mag": 71.10686464870678, "train/prior_ent_max": 71.10686464870678, "train/prior_ent_mean": 56.940915752859674, "train/prior_ent_min": 40.48096114046433, "train/prior_ent_std": 4.885933227398816, "train/rep_loss_mean": 13.013372217907625, "train/rep_loss_std": 9.3175449441461, "train/reward_avg": 0.03874655324034393, "train/reward_loss_mean": 0.06156886023852755, "train/reward_loss_std": 0.24632644291748018, "train/reward_max_data": 1.0264705945463741, "train/reward_max_pred": 1.024072535774287, "train/reward_neg_acc": 0.991924750892555, "train/reward_neg_loss": 0.029559464406167323, "train/reward_pos_acc": 0.9822177545112722, "train/reward_pos_loss": 0.7837881752673317, "train/reward_pred": 0.038142721374135685, "train/reward_rate": 0.04245892693014706, "train_stats/sum_log_reward": 11.186419981497306, "train_stats/max_log_achievement_collect_coal": 0.9506172839506173, "train_stats/max_log_achievement_collect_drink": 6.197530864197531, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 2.074074074074074, "train_stats/max_log_achievement_collect_stone": 13.444444444444445, "train_stats/max_log_achievement_collect_wood": 10.728395061728396, "train_stats/max_log_achievement_defeat_skeleton": 0.08641975308641975, "train_stats/max_log_achievement_defeat_zombie": 1.4814814814814814, "train_stats/max_log_achievement_eat_cow": 0.35802469135802467, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.012345679012345678, "train_stats/max_log_achievement_make_stone_sword": 0.037037037037037035, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4320987654320987, "train_stats/max_log_achievement_make_wood_sword": 1.2592592592592593, "train_stats/max_log_achievement_place_furnace": 2.123456790123457, "train_stats/max_log_achievement_place_plant": 1.7901234567901234, "train_stats/max_log_achievement_place_stone": 3.7777777777777777, "train_stats/max_log_achievement_place_table": 2.802469135802469, "train_stats/max_log_achievement_wake_up": 1.7901234567901234, "train_stats/mean_log_entropy": 0.7262072804165475, "eval_stats/sum_log_reward": 10.183333446582159, "eval_stats/max_log_achievement_collect_coal": 0.5833333333333334, "eval_stats/max_log_achievement_collect_drink": 5.208333333333333, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 2.3333333333333335, "eval_stats/max_log_achievement_collect_stone": 11.0, "eval_stats/max_log_achievement_collect_wood": 9.916666666666666, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 1.2916666666666667, "eval_stats/max_log_achievement_eat_cow": 0.3333333333333333, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.08333333333333333, "eval_stats/max_log_achievement_make_stone_sword": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.2916666666666667, "eval_stats/max_log_achievement_make_wood_sword": 1.0416666666666667, "eval_stats/max_log_achievement_place_furnace": 1.75, "eval_stats/max_log_achievement_place_plant": 1.6666666666666667, "eval_stats/max_log_achievement_place_stone": 3.25, "eval_stats/max_log_achievement_place_table": 2.2083333333333335, "eval_stats/max_log_achievement_wake_up": 1.4166666666666667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 4.17658111473429e-06, "report/cont_loss_std": 0.0001284400059375912, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0014228317886590958, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.152447605880297e-09, "report/cont_pred": 0.9970744848251343, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 13.103815078735352, "report/dyn_loss_std": 9.610262870788574, "report/image_loss_mean": 5.798587799072266, "report/image_loss_std": 12.464583396911621, "report/model_loss_mean": 13.730714797973633, "report/model_loss_std": 16.42755889892578, "report/post_ent_mag": 58.81018829345703, "report/post_ent_max": 58.81018829345703, "report/post_ent_mean": 42.85291290283203, "report/post_ent_min": 19.00064468383789, "report/post_ent_std": 7.552800178527832, "report/prior_ent_mag": 71.00407409667969, "report/prior_ent_max": 71.00407409667969, "report/prior_ent_mean": 56.047996520996094, "report/prior_ent_min": 41.11723327636719, "report/prior_ent_std": 4.817010402679443, "report/rep_loss_mean": 13.103815078735352, "report/rep_loss_std": 9.610262870788574, "report/reward_avg": 0.0400390625, "report/reward_loss_mean": 0.0698324516415596, "report/reward_loss_std": 0.31116268038749695, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002309799194336, "report/reward_neg_acc": 0.9755351543426514, "report/reward_neg_loss": 0.042529527097940445, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6927201151847839, "report/reward_pred": 0.04190925508737564, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.1516479389683809e-05, "eval/cont_loss_std": 0.0002827264543157071, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0047225914895534515, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.2971512407821137e-06, "eval/cont_pred": 0.998053789138794, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 15.975186347961426, "eval/dyn_loss_std": 11.408431053161621, "eval/image_loss_mean": 12.016551971435547, "eval/image_loss_std": 18.65224266052246, "eval/model_loss_mean": 21.72195816040039, "eval/model_loss_std": 23.439525604248047, "eval/post_ent_mag": 60.64802551269531, "eval/post_ent_max": 60.64802551269531, "eval/post_ent_mean": 43.09968185424805, "eval/post_ent_min": 18.491186141967773, "eval/post_ent_std": 8.179656028747559, "eval/prior_ent_mag": 71.00407409667969, "eval/prior_ent_max": 71.00407409667969, "eval/prior_ent_mean": 56.83153533935547, "eval/prior_ent_min": 43.48322296142578, "eval/prior_ent_std": 4.9679412841796875, "eval/rep_loss_mean": 15.975186347961426, "eval/rep_loss_std": 11.408431053161621, "eval/reward_avg": 0.06337890028953552, "eval/reward_loss_mean": 0.12028360366821289, "eval/reward_loss_std": 0.5653449296951294, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0048046112060547, "eval/reward_neg_acc": 0.9822361469268799, "eval/reward_neg_loss": 0.06830678880214691, "eval/reward_pos_acc": 0.9850746393203735, "eval/reward_pos_loss": 0.8626986742019653, "eval/reward_pred": 0.06620350480079651, "eval/reward_rate": 0.0654296875, "replay/size": 1000000.0, "replay/inserts": 21800.0, "replay/samples": 21808.0, "replay/insert_wait_avg": 1.3460588017734913e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.065103172643693e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 8432.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2602084501870896e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1008.4609034061432, "timer/env.step_count": 2725.0, "timer/env.step_total": 210.2871072292328, "timer/env.step_frac": 0.2085228158265474, "timer/env.step_avg": 0.07716958063458083, "timer/env.step_min": 0.024339675903320312, "timer/env.step_max": 3.619173526763916, "timer/replay._sample_count": 21808.0, "timer/replay._sample_total": 11.250083923339844, "timer/replay._sample_frac": 0.011155696651542904, "timer/replay._sample_avg": 0.0005158695856263684, "timer/replay._sample_min": 0.0003540515899658203, "timer/replay._sample_max": 0.00875234603881836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3779.0, "timer/agent.policy_total": 66.91653323173523, "timer/agent.policy_frac": 0.06635510906344533, "timer/agent.policy_avg": 0.017707471085402285, "timer/agent.policy_min": 0.009829998016357422, "timer/agent.policy_max": 0.18531012535095215, "timer/dataset_train_count": 1363.0, "timer/dataset_train_total": 0.14892148971557617, "timer/dataset_train_frac": 0.00014767205075832292, "timer/dataset_train_avg": 0.00010926008049565384, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.0003428459167480469, "timer/agent.train_count": 1363.0, "timer/agent.train_total": 617.128529548645, "timer/agent.train_frac": 0.6119508723285679, "timer/agent.train_avg": 0.4527722153695121, "timer/agent.train_min": 0.44020533561706543, "timer/agent.train_max": 1.841066598892212, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47468996047973633, "timer/agent.report_frac": 0.00047070735104994124, "timer/agent.report_avg": 0.23734498023986816, "timer/agent.report_min": 0.2295074462890625, "timer/agent.report_max": 0.24518251419067383, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.528594970703125e-05, "timer/dataset_eval_frac": 3.4989903513215664e-08, "timer/dataset_eval_avg": 3.528594970703125e-05, "timer/dataset_eval_min": 3.528594970703125e-05, "timer/dataset_eval_max": 3.528594970703125e-05, "fps": 21.616787937144736}
{"step": 1440512, "time": 65460.62703847885, "episode/length": 204.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 1441008, "time": 65479.15025806427, "episode/length": 198.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 1441024, "time": 65481.27081608772, "episode/length": 418.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9952267303102625, "episode/intrinsic_return": 0.0}
{"step": 1441064, "time": 65483.99955821037, "episode/length": 274.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9781818181818182, "episode/intrinsic_return": 0.0}
{"step": 1441168, "time": 65489.55691576004, "episode/length": 224.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1441384, "time": 65498.31556606293, "episode/length": 263.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 1442528, "time": 65541.18052339554, "episode/length": 182.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 1442552, "time": 65543.37094807625, "episode/length": 192.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 1442624, "time": 65547.60271000862, "episode/length": 488.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9959100204498977, "episode/intrinsic_return": 0.0}
{"step": 1442800, "time": 65555.1868481636, "episode/length": 221.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 1443208, "time": 65570.55904912949, "episode/length": 336.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9821958456973294, "episode/intrinsic_return": 0.0}
{"step": 1444152, "time": 65604.47171449661, "episode/length": 202.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 1444256, "time": 65609.82572960854, "episode/length": 358.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9888579387186629, "episode/intrinsic_return": 0.0}
{"step": 1444520, "time": 65620.13986897469, "episode/length": 214.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 1444632, "time": 65625.55442595482, "episode/length": 432.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9976905311778291, "episode/intrinsic_return": 0.0}
{"step": 1444960, "time": 65638.62761235237, "episode/length": 291.0, "episode/score": 13.100000038743019, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 1445392, "time": 65654.88317108154, "episode/length": 53.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 1445560, "time": 65662.07300019264, "episode/length": 293.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9965986394557823, "episode/intrinsic_return": 0.0}
{"step": 1445856, "time": 65673.925573349, "episode/length": 212.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 1445856, "time": 65673.93431162834, "episode/length": 166.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 1445968, "time": 65681.05516982079, "episode/length": 426.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9976580796252927, "episode/intrinsic_return": 0.0}
{"step": 1446504, "time": 65700.80985617638, "episode/length": 233.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 1446520, "time": 65703.01310944557, "episode/length": 282.0, "episode/score": 13.099999971687794, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 1446696, "time": 65710.50311994553, "episode/length": 162.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 1447128, "time": 65726.86503362656, "episode/length": 75.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 1447456, "time": 65739.95955252647, "episode/length": 236.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 1447560, "time": 65744.7946460247, "episode/length": 212.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 1447712, "time": 65752.02573728561, "episode/length": 217.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1448016, "time": 65764.05875515938, "episode/length": 164.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 1448736, "time": 65790.40884160995, "episode/length": 278.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.0}
{"step": 1449136, "time": 65805.65632200241, "episode/length": 409.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 1449192, "time": 65809.08088231087, "episode/length": 216.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1449312, "time": 65814.99574518204, "episode/length": 161.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 1449448, "time": 65821.0869319439, "episode/length": 1307.0, "episode/score": 13.099999964237213, "episode/reward_rate": 0.9992354740061162, "episode/intrinsic_return": 0.0}
{"step": 1449632, "time": 65829.35918688774, "episode/length": 111.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 1449824, "time": 65837.56365203857, "episode/length": 282.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9787985865724381, "episode/intrinsic_return": 0.0}
{"step": 1450072, "time": 65869.5944724083, "eval_episode/length": 157.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9620253164556962}
{"step": 1450072, "time": 65872.59813427925, "eval_episode/length": 188.0, "eval_episode/score": 12.100000023841858, "eval_episode/reward_rate": 0.9682539682539683}
{"step": 1450072, "time": 65876.10712242126, "eval_episode/length": 229.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 1450072, "time": 65879.19798541069, "eval_episode/length": 261.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9847328244274809}
{"step": 1450072, "time": 65880.96282744408, "eval_episode/length": 266.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9962546816479401}
{"step": 1450072, "time": 65882.79672002792, "eval_episode/length": 273.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9781021897810219}
{"step": 1450072, "time": 65885.27499246597, "eval_episode/length": 291.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9965753424657534}
{"step": 1450072, "time": 65887.80601930618, "eval_episode/length": 50.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 1450208, "time": 65892.66571521759, "episode/length": 311.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 1450824, "time": 65915.18704152107, "episode/length": 203.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 1450888, "time": 65918.91541147232, "episode/length": 218.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 1450976, "time": 65923.81952214241, "episode/length": 167.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 1451104, "time": 65929.914260149, "episode/length": 496.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9839034205231388, "episode/intrinsic_return": 0.0}
{"step": 1451264, "time": 65937.2108976841, "episode/length": 243.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 1451472, "time": 65945.83535480499, "episode/length": 72.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9178082191780822, "episode/intrinsic_return": 0.0}
{"step": 1451776, "time": 65957.93861222267, "episode/length": 243.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 1451928, "time": 65964.58189344406, "episode/length": 309.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9870967741935484, "episode/intrinsic_return": 0.0}
{"step": 1452120, "time": 65972.78028559685, "episode/length": 238.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 1452816, "time": 65998.57408213615, "episode/length": 229.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 1452912, "time": 66003.51221323013, "episode/length": 205.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 1452992, "time": 66007.76918244362, "episode/length": 235.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1453472, "time": 66025.99481630325, "episode/length": 249.0, "episode/score": 13.100000016391277, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 1453856, "time": 66040.60757780075, "episode/length": 216.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9861751152073732, "episode/intrinsic_return": 0.0}
{"step": 1453872, "time": 66042.76194190979, "episode/length": 119.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 1453872, "time": 66042.77079129219, "episode/length": 242.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 1454256, "time": 66059.11340546608, "episode/length": 47.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 1454456, "time": 66067.21993517876, "episode/length": 204.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 1454936, "time": 66085.32213687897, "episode/length": 513.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9980544747081712, "episode/intrinsic_return": 0.0}
{"step": 1454992, "time": 66089.01251745224, "episode/length": 139.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 1455216, "time": 66098.2053039074, "episode/length": 217.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 1455296, "time": 66102.50670480728, "episode/length": 439.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9863636363636363, "episode/intrinsic_return": 0.0}
{"step": 1455416, "time": 66108.08949875832, "episode/length": 302.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 1455560, "time": 66114.64249515533, "episode/length": 137.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 1455736, "time": 66122.19482946396, "episode/length": 234.0, "episode/score": 13.099999949336052, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1456256, "time": 66141.788905859, "episode/length": 249.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 1456512, "time": 66152.06093931198, "episode/length": 196.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 1456696, "time": 66159.659897089, "episode/length": 184.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 1456720, "time": 66162.32512187958, "episode/length": 122.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.959349593495935, "episode/intrinsic_return": 0.0}
{"step": 1456816, "time": 66167.23395228386, "episode/length": 189.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 1456912, "time": 66172.10029578209, "episode/length": 168.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 1457120, "time": 66180.69419884682, "episode/length": 265.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 1457440, "time": 66193.21130919456, "episode/length": 252.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9644268774703557, "episode/intrinsic_return": 0.0}
{"step": 1458048, "time": 66215.37145400047, "episode/length": 223.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1458384, "time": 66230.18035912514, "episode/length": 210.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1459080, "time": 66255.12020754814, "episode/length": 270.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 1459144, "time": 66258.98439502716, "episode/length": 290.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 1459448, "time": 66270.85910773277, "episode/length": 250.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 1459680, "time": 66280.69856381416, "episode/length": 319.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 1460056, "time": 66319.33754682541, "eval_episode/length": 206.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 1460056, "time": 66321.62984347343, "eval_episode/length": 220.0, "eval_episode/score": 12.099999971687794, "eval_episode/reward_rate": 0.995475113122172}
{"step": 1460056, "time": 66323.2301940918, "eval_episode/length": 222.0, "eval_episode/score": 12.099999971687794, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 1460056, "time": 66325.52129030228, "eval_episode/length": 238.0, "eval_episode/score": 11.100000031292439, "eval_episode/reward_rate": 0.99581589958159}
{"step": 1460056, "time": 66327.46872878075, "eval_episode/length": 246.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9959514170040485}
{"step": 1460056, "time": 66330.9849653244, "eval_episode/length": 289.0, "eval_episode/score": 10.099999971687794, "eval_episode/reward_rate": 0.996551724137931}
{"step": 1460056, "time": 66336.32121896744, "eval_episode/length": 165.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 1460056, "time": 66338.62995743752, "eval_episode/length": 384.0, "eval_episode/score": 12.100000016391277, "eval_episode/reward_rate": 0.9948051948051948}
{"step": 1460424, "time": 66351.27753520012, "episode/length": 254.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 1460648, "time": 66360.53628134727, "episode/length": 195.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.0}
{"step": 1460784, "time": 66367.0202999115, "episode/length": 533.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.99812734082397, "episode/intrinsic_return": 0.0}
{"step": 1460800, "time": 66369.11686658859, "episode/length": 206.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 1460808, "time": 66370.93193817139, "episode/length": 510.0, "episode/score": 14.099999979138374, "episode/reward_rate": 0.9980430528375733, "episode/intrinsic_return": 0.0}
{"step": 1461272, "time": 66388.36030340195, "episode/length": 227.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1461352, "time": 66392.7240550518, "episode/length": 208.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 1462120, "time": 66420.51944828033, "episode/length": 163.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 1462288, "time": 66428.11865854263, "episode/length": 232.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 1462424, "time": 66434.08790612221, "episode/length": 143.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 1462697, "time": 66446.33383083344, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.756548384545555, "train/action_min": 0.0, "train/action_std": 3.6547475633486894, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.026827385058810174, "train/actor_opt_grad_steps": 90615.0, "train/actor_opt_loss": -8.154087236124864, "train/adv_mag": 0.3885620763184319, "train/adv_max": 0.3569443637216595, "train/adv_mean": 0.0015499224901874878, "train/adv_min": -0.31663837399281247, "train/adv_std": 0.040991829314701994, "train/cont_avg": 0.9960593639964789, "train/cont_loss_mean": 0.00022926454074286104, "train/cont_loss_std": 0.007054238701619263, "train/cont_neg_acc": 0.9920833336455481, "train/cont_neg_loss": 0.01714118618224672, "train/cont_pos_acc": 0.9999447448152892, "train/cont_pos_loss": 0.00015105937151807172, "train/cont_pred": 0.9960282587669265, "train/cont_rate": 0.9960593639964789, "train/dyn_loss_mean": 13.046874536594874, "train/dyn_loss_std": 9.323746506596954, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9803437473068775, "train/extr_critic_critic_opt_grad_steps": 90615.0, "train/extr_critic_critic_opt_loss": 15056.298229808539, "train/extr_critic_mag": 10.617117700442462, "train/extr_critic_max": 10.617117700442462, "train/extr_critic_mean": 2.461426023026587, "train/extr_critic_min": -0.1759340116675471, "train/extr_critic_std": 2.551873082006481, "train/extr_return_normed_mag": 1.473717882599629, "train/extr_return_normed_max": 1.473717882599629, "train/extr_return_normed_mean": 0.309457718171704, "train/extr_return_normed_min": -0.061115000396966934, "train/extr_return_normed_std": 0.3223333309443904, "train/extr_return_rate": 0.7339527781160784, "train/extr_return_raw_mag": 11.769292368015773, "train/extr_return_raw_max": 11.769292368015773, "train/extr_return_raw_mean": 2.473816540039761, "train/extr_return_raw_min": -0.48552902955824223, "train/extr_return_raw_std": 2.574069773647147, "train/extr_reward_mag": 1.0489695760565745, "train/extr_reward_max": 1.0489695760565745, "train/extr_reward_mean": 0.04460851777292473, "train/extr_reward_min": -0.47011321950966206, "train/extr_reward_std": 0.19749969915604929, "train/image_loss_mean": 6.436604939715963, "train/image_loss_std": 12.144235268445081, "train/model_loss_mean": 14.326484592867569, "train/model_loss_std": 15.908538213917907, "train/model_opt_grad_norm": 44.914501942379374, "train/model_opt_grad_steps": 90534.57746478873, "train/model_opt_loss": 21872.695181833187, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1522.887323943662, "train/policy_entropy_mag": 2.6770701106165498, "train/policy_entropy_max": 2.6770701106165498, "train/policy_entropy_mean": 0.8173153820172162, "train/policy_entropy_min": 0.07937502273371522, "train/policy_entropy_std": 0.9003498252009002, "train/policy_logprob_mag": 7.438383864684844, "train/policy_logprob_max": -0.009455659229990462, "train/policy_logprob_mean": -0.8180252668303503, "train/policy_logprob_min": -7.438383864684844, "train/policy_logprob_std": 1.2562059432687893, "train/policy_randomness_mag": 0.9448882689778234, "train/policy_randomness_max": 0.9448882689778234, "train/policy_randomness_mean": 0.28847646482393774, "train/policy_randomness_min": 0.028015899747400215, "train/policy_randomness_std": 0.3177839776789638, "train/post_ent_mag": 61.64934451143507, "train/post_ent_max": 61.64934451143507, "train/post_ent_mean": 43.880976045635386, "train/post_ent_min": 20.460734971812073, "train/post_ent_std": 7.819030875891027, "train/prior_ent_mag": 71.1300838094362, "train/prior_ent_max": 71.1300838094362, "train/prior_ent_mean": 57.01058597296056, "train/prior_ent_min": 40.616630876568, "train/prior_ent_std": 4.933583820369882, "train/rep_loss_mean": 13.046874536594874, "train/rep_loss_std": 9.323746506596954, "train/reward_avg": 0.038620983434080235, "train/reward_loss_mean": 0.06152559242303103, "train/reward_loss_std": 0.24932602929397368, "train/reward_max_data": 1.0211267656003926, "train/reward_max_pred": 1.0181066805208232, "train/reward_neg_acc": 0.9916835267778853, "train/reward_neg_loss": 0.0295444893795, "train/reward_pos_acc": 0.9786369376619097, "train/reward_pos_loss": 0.792490305615143, "train/reward_pred": 0.037852567476286014, "train/reward_rate": 0.042115977112676055, "train_stats/sum_log_reward": 11.11162814151409, "train_stats/max_log_achievement_collect_coal": 0.7906976744186046, "train_stats/max_log_achievement_collect_drink": 6.232558139534884, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 2.0813953488372094, "train_stats/max_log_achievement_collect_stone": 13.267441860465116, "train_stats/max_log_achievement_collect_wood": 9.290697674418604, "train_stats/max_log_achievement_defeat_skeleton": 0.046511627906976744, "train_stats/max_log_achievement_defeat_zombie": 1.5465116279069768, "train_stats/max_log_achievement_eat_cow": 0.4069767441860465, "train_stats/max_log_achievement_eat_plant": 0.046511627906976744, "train_stats/max_log_achievement_make_stone_pickaxe": 0.011627906976744186, "train_stats/max_log_achievement_make_stone_sword": 0.011627906976744186, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4186046511627908, "train_stats/max_log_achievement_make_wood_sword": 1.069767441860465, "train_stats/max_log_achievement_place_furnace": 2.058139534883721, "train_stats/max_log_achievement_place_plant": 1.7209302325581395, "train_stats/max_log_achievement_place_stone": 4.058139534883721, "train_stats/max_log_achievement_place_table": 2.3488372093023258, "train_stats/max_log_achievement_wake_up": 1.6511627906976745, "train_stats/mean_log_entropy": 0.674966309652772, "eval_stats/sum_log_reward": 11.100000113248825, "eval_stats/max_log_achievement_collect_coal": 1.1875, "eval_stats/max_log_achievement_collect_drink": 5.25, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 12.0625, "eval_stats/max_log_achievement_collect_wood": 8.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.5625, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0625, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 1.8125, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_stone": 4.1875, "eval_stats/max_log_achievement_place_table": 2.3125, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.5417299437103793e-07, "report/cont_loss_std": 2.3098862129700137e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.180211933795363e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.006340776323668e-08, "report/cont_pred": 0.9960938692092896, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.2031888961792, "report/dyn_loss_std": 9.450701713562012, "report/image_loss_mean": 6.490550994873047, "report/image_loss_std": 12.912386894226074, "report/model_loss_mean": 14.4650297164917, "report/model_loss_std": 16.687101364135742, "report/post_ent_mag": 58.734619140625, "report/post_ent_max": 58.734619140625, "report/post_ent_mean": 42.917869567871094, "report/post_ent_min": 19.82583999633789, "report/post_ent_std": 7.663761615753174, "report/prior_ent_mag": 70.76121520996094, "report/prior_ent_max": 70.76121520996094, "report/prior_ent_mean": 56.38134002685547, "report/prior_ent_min": 41.85565948486328, "report/prior_ent_std": 4.481884002685547, "report/rep_loss_mean": 13.2031888961792, "report/rep_loss_std": 9.450701713562012, "report/reward_avg": 0.03056640550494194, "report/reward_loss_mean": 0.05256448686122894, "report/reward_loss_std": 0.23587258160114288, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.000472068786621, "report/reward_neg_acc": 0.9929220676422119, "report/reward_neg_loss": 0.029536256566643715, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7032763361930847, "report/reward_pred": 0.03277777135372162, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.1635157736454858e-06, "eval/cont_loss_std": 5.483670611283742e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.278619988122955e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.0735371890623355e-06, "eval/cont_pred": 0.9970684051513672, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.899906158447266, "eval/dyn_loss_std": 11.308215141296387, "eval/image_loss_mean": 9.87978458404541, "eval/image_loss_std": 14.714834213256836, "eval/model_loss_mean": 20.12965202331543, "eval/model_loss_std": 19.638286590576172, "eval/post_ent_mag": 59.02183151245117, "eval/post_ent_max": 59.02183151245117, "eval/post_ent_mean": 42.19218444824219, "eval/post_ent_min": 19.699573516845703, "eval/post_ent_std": 7.659548759460449, "eval/prior_ent_mag": 70.76121520996094, "eval/prior_ent_max": 70.76121520996094, "eval/prior_ent_mean": 56.734596252441406, "eval/prior_ent_min": 41.8872184753418, "eval/prior_ent_std": 4.674952983856201, "eval/rep_loss_mean": 16.899906158447266, "eval/rep_loss_std": 11.308215141296387, "eval/reward_avg": 0.056640625, "eval/reward_loss_mean": 0.10991977155208588, "eval/reward_loss_std": 0.5117939710617065, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0029652118682861, "eval/reward_neg_acc": 0.9865005612373352, "eval/reward_neg_loss": 0.06352101266384125, "eval/reward_pos_acc": 0.9672131538391113, "eval/reward_pos_loss": 0.8424116373062134, "eval/reward_pred": 0.06223595142364502, "eval/reward_rate": 0.0595703125, "replay/size": 1000000.0, "replay/inserts": 22608.0, "replay/samples": 22608.0, "replay/insert_wait_avg": 1.3624280374774e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.094715717744929e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5584.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2477267437473067e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3360593318939, "timer/env.step_count": 2826.0, "timer/env.step_total": 219.32542729377747, "timer/env.step_frac": 0.21925174569860142, "timer/env.step_avg": 0.07760984688385615, "timer/env.step_min": 0.02404308319091797, "timer/env.step_max": 3.336491823196411, "timer/replay._sample_count": 22608.0, "timer/replay._sample_total": 11.779853820800781, "timer/replay._sample_frac": 0.011775896420917116, "timer/replay._sample_avg": 0.000521048028167055, "timer/replay._sample_min": 0.00039577484130859375, "timer/replay._sample_max": 0.02929091453552246, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3524.0, "timer/agent.policy_total": 62.996991872787476, "timer/agent.policy_frac": 0.06297582825801762, "timer/agent.policy_avg": 0.01787655842020076, "timer/agent.policy_min": 0.00962686538696289, "timer/agent.policy_max": 0.15846705436706543, "timer/dataset_train_count": 1413.0, "timer/dataset_train_total": 0.15770912170410156, "timer/dataset_train_frac": 0.00015765613988706214, "timer/dataset_train_avg": 0.00011161296652802659, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.0007343292236328125, "timer/agent.train_count": 1413.0, "timer/agent.train_total": 643.6978559494019, "timer/agent.train_frac": 0.6434816079501481, "timer/agent.train_avg": 0.45555403818075146, "timer/agent.train_min": 0.4417557716369629, "timer/agent.train_max": 1.8350822925567627, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47809410095214844, "timer/agent.report_frac": 0.0004779334869438364, "timer/agent.report_avg": 0.23904705047607422, "timer/agent.report_min": 0.23296499252319336, "timer/agent.report_max": 0.24512910842895508, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.193735675283656e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 22.600082273508175}
{"step": 1463592, "time": 66476.8416955471, "episode/length": 350.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 1463736, "time": 66483.29689860344, "episode/length": 710.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9929676511954993, "episode/intrinsic_return": 0.0}
{"step": 1464064, "time": 66496.44724678993, "episode/length": 426.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9976580796252927, "episode/intrinsic_return": 0.0}
{"step": 1464184, "time": 66501.95688915253, "episode/length": 422.0, "episode/score": 15.100000001490116, "episode/reward_rate": 0.9881796690307328, "episode/intrinsic_return": 0.0}
{"step": 1464248, "time": 66505.79376721382, "episode/length": 265.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9849624060150376, "episode/intrinsic_return": 0.0}
{"step": 1464512, "time": 66516.62184381485, "episode/length": 260.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 1464560, "time": 66519.84967041016, "episode/length": 400.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9975062344139651, "episode/intrinsic_return": 0.0}
{"step": 1464608, "time": 66523.01347661018, "episode/length": 289.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 1465416, "time": 66551.86862802505, "episode/length": 209.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 1465480, "time": 66555.53851819038, "episode/length": 235.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 1465872, "time": 66570.8113026619, "episode/length": 163.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 1465888, "time": 66573.0735104084, "episode/length": 212.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 1465952, "time": 66576.85124564171, "episode/length": 235.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1466008, "time": 66580.11638092995, "episode/length": 174.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 1466176, "time": 66587.60939478874, "episode/length": 37.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 1466432, "time": 66599.91534471512, "episode/length": 272.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 1467632, "time": 66642.19538521767, "episode/length": 217.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1467776, "time": 66648.91957783699, "episode/length": 167.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 1467904, "time": 66654.89724302292, "episode/length": 243.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 1467944, "time": 66657.61637997627, "episode/length": 241.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 1467984, "time": 66660.83860468864, "episode/length": 320.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9844236760124611, "episode/intrinsic_return": 0.0}
{"step": 1468056, "time": 66664.6682844162, "episode/length": 442.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9954853273137697, "episode/intrinsic_return": 0.0}
{"step": 1468912, "time": 66695.54001569748, "episode/length": 341.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9883040935672515, "episode/intrinsic_return": 0.0}
{"step": 1469144, "time": 66704.74211883545, "episode/length": 188.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 1469344, "time": 66713.4421839714, "episode/length": 195.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 1469616, "time": 66724.22132444382, "episode/length": 213.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 1469632, "time": 66726.28485965729, "episode/length": 518.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9807321772639692, "episode/intrinsic_return": 0.0}
{"step": 1469824, "time": 66734.31676578522, "episode/length": 59.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 1469832, "time": 66736.20832872391, "episode/length": 235.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 1469952, "time": 66742.10622429848, "episode/length": 100.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1470040, "time": 66767.04481506348, "eval_episode/length": 165.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 1470040, "time": 66768.92084980011, "eval_episode/length": 170.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 1470040, "time": 66772.16803050041, "eval_episode/length": 205.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 1470040, "time": 66775.00579857826, "eval_episode/length": 232.0, "eval_episode/score": 12.100000016391277, "eval_episode/reward_rate": 0.9871244635193133}
{"step": 1470040, "time": 66777.12393307686, "eval_episode/length": 241.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9958677685950413}
{"step": 1470040, "time": 66783.94479870796, "eval_episode/length": 193.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.979381443298969}
{"step": 1470040, "time": 66787.32051539421, "eval_episode/length": 396.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9974811083123426}
{"step": 1470040, "time": 66790.89343452454, "eval_episode/length": 432.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9976905311778291}
{"step": 1470368, "time": 66802.33708834648, "episode/length": 297.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 1471312, "time": 66836.32155561447, "episode/length": 299.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 1471448, "time": 66842.35859966278, "episode/length": 423.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 1471480, "time": 66845.13985133171, "episode/length": 206.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 1471632, "time": 66852.13397407532, "episode/length": 209.0, "episode/score": 13.099999979138374, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 1471712, "time": 66856.48645949364, "episode/length": 261.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 1471928, "time": 66865.19180393219, "episode/length": 55.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 1472248, "time": 66877.70870375633, "episode/length": 234.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1472928, "time": 66902.69519209862, "episode/length": 411.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9927184466019418, "episode/intrinsic_return": 0.0}
{"step": 1472960, "time": 66905.38369512558, "episode/length": 205.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 1473200, "time": 66915.17558312416, "episode/length": 195.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 1473896, "time": 66940.31139087677, "episode/length": 272.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 1474056, "time": 66947.57220172882, "episode/length": 225.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 1474496, "time": 66964.29427027702, "episode/length": 320.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 1474616, "time": 66971.5450527668, "episode/length": 210.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.985781990521327, "episode/intrinsic_return": 0.0}
{"step": 1474840, "time": 66980.9245903492, "episode/length": 625.0, "episode/score": 13.099999964237213, "episode/reward_rate": 0.987220447284345, "episode/intrinsic_return": 0.0}
{"step": 1475640, "time": 67009.84615063667, "episode/length": 523.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.982824427480916, "episode/intrinsic_return": 0.0}
{"step": 1475968, "time": 67022.83502554893, "episode/length": 168.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 1476296, "time": 67035.31586456299, "episode/length": 299.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 1476432, "time": 67041.88884830475, "episode/length": 296.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9764309764309764, "episode/intrinsic_return": 0.0}
{"step": 1476544, "time": 67047.22106051445, "episode/length": 255.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 1476680, "time": 67053.17474961281, "episode/length": 434.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9977011494252873, "episode/intrinsic_return": 0.0}
{"step": 1477008, "time": 67066.13979005814, "episode/length": 270.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.981549815498155, "episode/intrinsic_return": 0.0}
{"step": 1477120, "time": 67071.6515955925, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 1477360, "time": 67081.22631311417, "episode/length": 549.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9890909090909091, "episode/intrinsic_return": 0.0}
{"step": 1477592, "time": 67090.52633452415, "episode/length": 28.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 1477968, "time": 67105.3223502636, "episode/length": 160.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 1478080, "time": 67110.74696040154, "episode/length": 222.0, "episode/score": 11.1000000461936, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 1478264, "time": 67118.41641569138, "episode/length": 214.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 1478408, "time": 67124.9855799675, "episode/length": 174.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1478640, "time": 67134.83564424515, "episode/length": 275.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9818840579710145, "episode/intrinsic_return": 0.0}
{"step": 1479248, "time": 67157.21820735931, "episode/length": 206.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 1479904, "time": 67180.94472956657, "episode/length": 347.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 1479920, "time": 67183.11714792252, "episode/length": 159.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 1480024, "time": 67203.27100229263, "eval_episode/length": 39.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9}
{"step": 1480024, "time": 67211.06389546394, "eval_episode/length": 178.0, "eval_episode/score": 13.100000001490116, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 1480024, "time": 67214.35631513596, "eval_episode/length": 215.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 1480024, "time": 67216.38370704651, "eval_episode/length": 219.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 1480024, "time": 67218.39679574966, "eval_episode/length": 227.0, "eval_episode/score": 12.099999979138374, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 1480024, "time": 67220.2343211174, "eval_episode/length": 230.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 1480024, "time": 67222.54449129105, "eval_episode/length": 205.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 1480024, "time": 67229.4729874134, "eval_episode/length": 316.0, "eval_episode/score": 13.100000001490116, "eval_episode/reward_rate": 0.9936908517350158}
{"step": 1480152, "time": 67233.81391119957, "episode/length": 217.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 1480528, "time": 67248.31410360336, "episode/length": 319.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.996875, "episode/intrinsic_return": 0.0}
{"step": 1480880, "time": 67261.81800913811, "episode/length": 349.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9828571428571429, "episode/intrinsic_return": 0.0}
{"step": 1481144, "time": 67272.17188072205, "episode/length": 152.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 1481168, "time": 67274.88751077652, "episode/length": 649.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9984615384615385, "episode/intrinsic_return": 0.0}
{"step": 1481296, "time": 67280.9018650055, "episode/length": 255.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 1481560, "time": 67291.24869632721, "episode/length": 411.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9878640776699029, "episode/intrinsic_return": 0.0}
{"step": 1482128, "time": 67312.36769390106, "episode/length": 277.0, "episode/score": 11.100000061094761, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 1482280, "time": 67318.86106038094, "episode/length": 138.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 1482640, "time": 67332.88126826286, "episode/length": 219.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 1482840, "time": 67343.10294246674, "episode/length": 335.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 1482944, "time": 67348.48397922516, "episode/length": 205.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 1483656, "time": 67374.1172773838, "episode/length": 190.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 1483776, "time": 67379.95909833908, "episode/length": 116.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9572649572649573, "episode/intrinsic_return": 0.0}
{"step": 1483808, "time": 67382.65157365799, "episode/length": 190.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 1484104, "time": 67393.96299338341, "episode/length": 182.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 1484472, "time": 67408.18857097626, "episode/length": 492.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9858012170385395, "episode/intrinsic_return": 0.0}
{"step": 1484776, "time": 67420.0256588459, "episode/length": 228.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 1485264, "time": 67438.69146728516, "episode/length": 181.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 1485360, "time": 67443.61159133911, "episode/length": 526.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9981024667931688, "episode/intrinsic_return": 0.0}
{"step": 1485369, "time": 67446.41978645325, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.794617564965647, "train/action_min": 0.0, "train/action_std": 3.693427890750533, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.026763195053060004, "train/actor_opt_grad_steps": 92030.0, "train/actor_opt_loss": -8.420075079518641, "train/adv_mag": 0.4072430410706405, "train/adv_max": 0.35867572084386296, "train/adv_mean": 0.0014928828828771707, "train/adv_min": -0.3342377000243951, "train/adv_std": 0.04073179608329813, "train/cont_avg": 0.9963361591312057, "train/cont_loss_mean": 4.0327467506498814e-05, "train/cont_loss_std": 0.0011997484914030283, "train/cont_neg_acc": 0.9964285714285714, "train/cont_neg_loss": 0.007027126964658237, "train/cont_pos_acc": 0.999999982245425, "train/cont_pos_loss": 1.408524197166352e-05, "train/cont_pred": 0.9963432791385245, "train/cont_rate": 0.9963361591312057, "train/dyn_loss_mean": 13.016294736388728, "train/dyn_loss_std": 9.24790874102437, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.961895078209275, "train/extr_critic_critic_opt_grad_steps": 92030.0, "train/extr_critic_critic_opt_loss": 15008.12053274601, "train/extr_critic_mag": 10.541589331119619, "train/extr_critic_max": 10.541589331119619, "train/extr_critic_mean": 2.4337456226348877, "train/extr_critic_min": -0.18105867230300363, "train/extr_critic_std": 2.5082377322176668, "train/extr_return_normed_mag": 1.4555597846389663, "train/extr_return_normed_max": 1.4555597846389663, "train/extr_return_normed_mean": 0.30697465376228306, "train/extr_return_normed_min": -0.06472557347849117, "train/extr_return_normed_std": 0.31789379688442176, "train/extr_return_rate": 0.7321776574385082, "train/extr_return_raw_mag": 11.585895917094346, "train/extr_return_raw_max": 11.585895917094346, "train/extr_return_raw_mean": 2.445626899705711, "train/extr_return_raw_min": -0.5127882682685311, "train/extr_return_raw_std": 2.5302691493474, "train/extr_reward_mag": 1.0510093743074025, "train/extr_reward_max": 1.0510093743074025, "train/extr_reward_mean": 0.04441543251064652, "train/extr_reward_min": -0.4695188255174786, "train/extr_reward_std": 0.19714096262522623, "train/image_loss_mean": 6.397384484608968, "train/image_loss_std": 11.870872713995318, "train/model_loss_mean": 14.269155299409906, "train/model_loss_std": 15.618739757132023, "train/model_opt_grad_norm": 44.896482900524816, "train/model_opt_grad_steps": 91948.31914893616, "train/model_opt_loss": 18460.90693567154, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1294.3262411347519, "train/policy_entropy_mag": 2.672007459275266, "train/policy_entropy_max": 2.672007459275266, "train/policy_entropy_mean": 0.8361833099777817, "train/policy_entropy_min": 0.07937502506988268, "train/policy_entropy_std": 0.9146803676659334, "train/policy_logprob_mag": 7.438383859945527, "train/policy_logprob_max": -0.009455658402954432, "train/policy_logprob_mean": -0.8364208754918254, "train/policy_logprob_min": -7.438383859945527, "train/policy_logprob_std": 1.261631449063619, "train/policy_randomness_mag": 0.9431013743928138, "train/policy_randomness_max": 0.9431013743928138, "train/policy_randomness_mean": 0.295136015994329, "train/policy_randomness_min": 0.028015900535363677, "train/policy_randomness_std": 0.32284202791274863, "train/post_ent_mag": 61.574883454234886, "train/post_ent_max": 61.574883454234886, "train/post_ent_mean": 43.84376747726549, "train/post_ent_min": 20.230328390784297, "train/post_ent_std": 7.776972659090732, "train/prior_ent_mag": 71.11153330701462, "train/prior_ent_max": 71.11153330701462, "train/prior_ent_mean": 56.97047408083652, "train/prior_ent_min": 40.66470194877462, "train/prior_ent_std": 4.903373390224808, "train/rep_loss_mean": 13.016294736388728, "train/rep_loss_std": 9.24790874102437, "train/reward_avg": 0.03911305950782823, "train/reward_loss_mean": 0.061953721739721634, "train/reward_loss_std": 0.25132826784401074, "train/reward_max_data": 1.0255319209809, "train/reward_max_pred": 1.0209121222191668, "train/reward_neg_acc": 0.9916699000284181, "train/reward_neg_loss": 0.029493643122837476, "train/reward_pos_acc": 0.9793576729213093, "train/reward_pos_loss": 0.7914902922954965, "train/reward_pred": 0.03830681750484815, "train/reward_rate": 0.042643229166666664, "train_stats/sum_log_reward": 11.278571634065537, "train_stats/max_log_achievement_collect_coal": 1.1428571428571428, "train_stats/max_log_achievement_collect_drink": 6.011904761904762, "train_stats/max_log_achievement_collect_iron": 0.011904761904761904, "train_stats/max_log_achievement_collect_sapling": 1.9047619047619047, "train_stats/max_log_achievement_collect_stone": 15.547619047619047, "train_stats/max_log_achievement_collect_wood": 10.642857142857142, "train_stats/max_log_achievement_defeat_skeleton": 0.13095238095238096, "train_stats/max_log_achievement_defeat_zombie": 1.3452380952380953, "train_stats/max_log_achievement_eat_cow": 0.5, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.07142857142857142, "train_stats/max_log_achievement_make_stone_sword": 0.047619047619047616, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3095238095238095, "train_stats/max_log_achievement_make_wood_sword": 1.2261904761904763, "train_stats/max_log_achievement_place_furnace": 2.4166666666666665, "train_stats/max_log_achievement_place_plant": 1.6547619047619047, "train_stats/max_log_achievement_place_stone": 4.583333333333333, "train_stats/max_log_achievement_place_table": 2.988095238095238, "train_stats/max_log_achievement_wake_up": 1.8452380952380953, "train_stats/mean_log_entropy": 0.7194290556723163, "eval_stats/sum_log_reward": 10.975000262260437, "eval_stats/max_log_achievement_collect_coal": 0.625, "eval_stats/max_log_achievement_collect_drink": 4.75, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.6875, "eval_stats/max_log_achievement_collect_stone": 11.0625, "eval_stats/max_log_achievement_collect_wood": 11.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.125, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1875, "eval_stats/max_log_achievement_make_wood_sword": 1.25, "eval_stats/max_log_achievement_place_furnace": 1.6875, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 3.5625, "eval_stats/max_log_achievement_place_table": 2.9375, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.0019672117196023464, "report/cont_loss_std": 0.06291578710079193, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.5052482669707388e-05, "report/cont_pos_acc": 0.999020516872406, "report/cont_pos_loss": 0.0019729183986783028, "report/cont_pred": 0.996224045753479, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.610318183898926, "report/dyn_loss_std": 9.209171295166016, "report/image_loss_mean": 7.8689494132995605, "report/image_loss_std": 11.791354179382324, "report/model_loss_mean": 15.492128372192383, "report/model_loss_std": 15.393400192260742, "report/post_ent_mag": 62.812103271484375, "report/post_ent_max": 62.812103271484375, "report/post_ent_mean": 44.946327209472656, "report/post_ent_min": 19.96721649169922, "report/post_ent_std": 7.425143718719482, "report/prior_ent_mag": 70.95547485351562, "report/prior_ent_max": 70.95547485351562, "report/prior_ent_mean": 57.484901428222656, "report/prior_ent_min": 38.497581481933594, "report/prior_ent_std": 4.9111857414245605, "report/rep_loss_mean": 12.610318183898926, "report/rep_loss_std": 9.209171295166016, "report/reward_avg": 0.02802734449505806, "report/reward_loss_mean": 0.05502009391784668, "report/reward_loss_std": 0.22224988043308258, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.00173020362854, "report/reward_neg_acc": 0.9848790168762207, "report/reward_neg_loss": 0.028222819790244102, "report/reward_pos_acc": 0.9375, "report/reward_pos_loss": 0.8857356309890747, "report/reward_pred": 0.025686077773571014, "report/reward_rate": 0.03125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 9.728428267408162e-06, "eval/cont_loss_std": 0.00029784513753838837, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0016536698676645756, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.918590607554506e-08, "eval/cont_pred": 0.9941502809524536, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 16.870567321777344, "eval/dyn_loss_std": 11.064841270446777, "eval/image_loss_mean": 9.981431007385254, "eval/image_loss_std": 14.604208946228027, "eval/model_loss_mean": 20.229740142822266, "eval/model_loss_std": 19.117034912109375, "eval/post_ent_mag": 61.54909133911133, "eval/post_ent_max": 61.54909133911133, "eval/post_ent_mean": 42.23895263671875, "eval/post_ent_min": 21.424236297607422, "eval/post_ent_std": 7.5649824142456055, "eval/prior_ent_mag": 70.95547485351562, "eval/prior_ent_max": 70.95547485351562, "eval/prior_ent_mean": 56.807525634765625, "eval/prior_ent_min": 42.94651412963867, "eval/prior_ent_std": 4.988298416137695, "eval/rep_loss_mean": 16.870567321777344, "eval/rep_loss_std": 11.064841270446777, "eval/reward_avg": 0.06806640326976776, "eval/reward_loss_mean": 0.1259579360485077, "eval/reward_loss_std": 0.5319845676422119, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0783612728118896, "eval/reward_neg_acc": 0.9789029955863953, "eval/reward_neg_loss": 0.054025959223508835, "eval/reward_pos_acc": 0.9605263471603394, "eval/reward_pos_loss": 1.0232146978378296, "eval/reward_pred": 0.0636180117726326, "eval/reward_rate": 0.07421875, "replay/size": 1000000.0, "replay/inserts": 22672.0, "replay/samples": 22672.0, "replay/insert_wait_avg": 1.3602646455515752e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.125602147405889e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6000.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2549161911010741e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 3.382563591003418e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0860967636108, "timer/env.step_count": 2834.0, "timer/env.step_total": 217.46637558937073, "timer/env.step_frac": 0.21744765405010225, "timer/env.step_avg": 0.07673478320020138, "timer/env.step_min": 0.024770021438598633, "timer/env.step_max": 1.8477206230163574, "timer/replay._sample_count": 22672.0, "timer/replay._sample_total": 11.758682250976562, "timer/replay._sample_frac": 0.011757669953645949, "timer/replay._sample_avg": 0.0005186433596937439, "timer/replay._sample_min": 0.00043487548828125, "timer/replay._sample_max": 0.020232677459716797, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3584.0, "timer/agent.policy_total": 63.936071157455444, "timer/agent.policy_frac": 0.06393056694254588, "timer/agent.policy_avg": 0.017839305568486452, "timer/agent.policy_min": 0.009669303894042969, "timer/agent.policy_max": 0.20667052268981934, "timer/dataset_train_count": 1417.0, "timer/dataset_train_total": 0.15856003761291504, "timer/dataset_train_frac": 0.00015854638728208785, "timer/dataset_train_avg": 0.0001118984033965526, "timer/dataset_train_min": 9.751319885253906e-05, "timer/dataset_train_max": 0.0010650157928466797, "timer/agent.train_count": 1417.0, "timer/agent.train_total": 641.5469496250153, "timer/agent.train_frac": 0.6414917192641034, "timer/agent.train_avg": 0.4527501408786276, "timer/agent.train_min": 0.4387483596801758, "timer/agent.train_max": 1.8836159706115723, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4797356128692627, "timer/agent.report_frac": 0.00047969431274141313, "timer/agent.report_avg": 0.23986780643463135, "timer/agent.report_min": 0.2330610752105713, "timer/agent.report_max": 0.2466745376586914, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8130970348480137e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 22.66974828533556}
{"step": 1485440, "time": 67448.89021110535, "episode/length": 207.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 1486016, "time": 67470.07257795334, "episode/length": 238.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 1486496, "time": 67488.07510113716, "episode/length": 214.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1486544, "time": 67491.3216509819, "episode/length": 258.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 1486960, "time": 67507.00067853928, "episode/length": 189.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 1487008, "time": 67510.19805121422, "episode/length": 680.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9970631424375918, "episode/intrinsic_return": 0.0}
{"step": 1487048, "time": 67512.91391015053, "episode/length": 222.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 1487200, "time": 67519.91726469994, "episode/length": 442.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9887133182844243, "episode/intrinsic_return": 0.0}
{"step": 1487480, "time": 67530.82144379616, "episode/length": 116.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 1487712, "time": 67540.32626533508, "episode/length": 151.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 1487872, "time": 67547.5342156887, "episode/length": 231.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 1488776, "time": 67579.58779835701, "episode/length": 226.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 1489120, "time": 67593.27863073349, "episode/length": 258.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 1489152, "time": 67595.91198563576, "episode/length": 243.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 1489336, "time": 67603.66960811615, "episode/length": 69.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 1489440, "time": 67609.26211857796, "episode/length": 509.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9862745098039216, "episode/intrinsic_return": 0.0}
{"step": 1489448, "time": 67610.9040555954, "episode/length": 216.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1489616, "time": 67618.40426802635, "episode/length": 217.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 1490008, "time": 67651.19455623627, "eval_episode/length": 107.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9907407407407407}
{"step": 1490008, "time": 67657.50730466843, "eval_episode/length": 207.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 1490008, "time": 67659.40841627121, "eval_episode/length": 213.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 1490008, "time": 67661.66224002838, "eval_episode/length": 228.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 1490008, "time": 67664.98863053322, "eval_episode/length": 266.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9737827715355806}
{"step": 1490008, "time": 67670.217441082, "eval_episode/length": 136.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9635036496350365}
{"step": 1490008, "time": 67672.4544506073, "eval_episode/length": 355.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9915730337078652}
{"step": 1490008, "time": 67674.80099630356, "eval_episode/length": 156.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9745222929936306}
{"step": 1490152, "time": 67679.66280579567, "episode/length": 333.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9970059880239521, "episode/intrinsic_return": 0.0}
{"step": 1490744, "time": 67701.49132847786, "episode/length": 162.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 1491048, "time": 67715.18172860146, "episode/length": 504.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1491144, "time": 67720.09474754333, "episode/length": 225.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 1491432, "time": 67731.58008384705, "episode/length": 247.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 1491456, "time": 67734.26251792908, "episode/length": 287.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 1491464, "time": 67735.99539780617, "episode/length": 230.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 1492136, "time": 67760.59066867828, "episode/length": 376.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9973474801061007, "episode/intrinsic_return": 0.0}
{"step": 1492424, "time": 67771.8885667324, "episode/length": 209.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 1492656, "time": 67781.55249238014, "episode/length": 188.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1493528, "time": 67812.55722808838, "episode/length": 257.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 1493600, "time": 67816.97218680382, "episode/length": 270.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 1493792, "time": 67825.07323694229, "episode/length": 342.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9854227405247813, "episode/intrinsic_return": 0.0}
{"step": 1494192, "time": 67840.11379265785, "episode/length": 191.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 1494440, "time": 67850.00729632378, "episode/length": 372.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9973190348525469, "episode/intrinsic_return": 0.0}
{"step": 1495184, "time": 67877.0576069355, "episode/length": 628.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.985691573926868, "episode/intrinsic_return": 0.0}
{"step": 1495392, "time": 67885.73693561554, "episode/length": 223.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1495448, "time": 67889.04081106186, "episode/length": 413.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 1495536, "time": 67893.83699250221, "episode/length": 388.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9922879177377892, "episode/intrinsic_return": 0.0}
{"step": 1495568, "time": 67896.46500182152, "episode/length": 221.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 1495848, "time": 67907.31498789787, "episode/length": 289.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 1495896, "time": 67910.51759314537, "episode/length": 181.0, "episode/score": 13.100000031292439, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 1496024, "time": 67916.46805381775, "episode/length": 228.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 1496584, "time": 67937.09036850929, "episode/length": 148.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 1497112, "time": 67956.8399887085, "episode/length": 207.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 1497336, "time": 67966.08111143112, "episode/length": 220.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 1497608, "time": 67976.98249006271, "episode/length": 197.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 1497728, "time": 67982.8659145832, "episode/length": 234.0, "episode/score": 14.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1497904, "time": 67990.44820594788, "episode/length": 339.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 1498520, "time": 68012.82790112495, "episode/length": 241.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 1498896, "time": 68027.66441774368, "episode/length": 145.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 1499064, "time": 68034.70518255234, "episode/length": 243.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 1499072, "time": 68036.84331226349, "episode/length": 68.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 1499616, "time": 68058.88173604012, "episode/length": 509.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 1499720, "time": 68063.81869649887, "episode/length": 263.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 1499864, "time": 68070.26975893974, "episode/length": 315.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9810126582278481, "episode/intrinsic_return": 0.0}
{"step": 1500096, "time": 68095.57729029655, "eval_episode/length": 49.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.94}
{"step": 1500096, "time": 68103.80583763123, "eval_episode/length": 191.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 1500096, "time": 68106.872392416, "eval_episode/length": 171.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 1500096, "time": 68108.86973643303, "eval_episode/length": 37.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8947368421052632}
{"step": 1500096, "time": 68113.42862081528, "eval_episode/length": 292.0, "eval_episode/score": 14.099999986588955, "eval_episode/reward_rate": 0.9965870307167235}
{"step": 1500096, "time": 68113.43756556511, "eval_episode/length": 292.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9965870307167235}
{"step": 1500096, "time": 68119.91321921349, "eval_episode/length": 357.0, "eval_episode/score": 13.100000008940697, "eval_episode/reward_rate": 0.9972067039106145}
{"step": 1500096, "time": 68121.7204322815, "eval_episode/length": 361.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.988950276243094}
{"step": 1500640, "time": 68140.16748857498, "episode/length": 217.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1500728, "time": 68144.51387643814, "episode/length": 206.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 1500936, "time": 68153.28524303436, "episode/length": 151.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 1501040, "time": 68158.65393567085, "episode/length": 391.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9923469387755102, "episode/intrinsic_return": 0.0}
{"step": 1501136, "time": 68163.55419445038, "episode/length": 258.0, "episode/score": 13.099999971687794, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 1501264, "time": 68169.41068649292, "episode/length": 205.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 1501360, "time": 68174.31151270866, "episode/length": 186.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 1501472, "time": 68179.66724181175, "episode/length": 696.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9885222381635581, "episode/intrinsic_return": 0.0}
{"step": 1502552, "time": 68217.63633680344, "episode/length": 188.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 1502728, "time": 68225.17958116531, "episode/length": 182.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 1503136, "time": 68240.82648301125, "episode/length": 221.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 1503432, "time": 68252.12319350243, "episode/length": 348.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9856733524355301, "episode/intrinsic_return": 0.0}
{"step": 1503768, "time": 68265.04142522812, "episode/length": 379.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9842105263157894, "episode/intrinsic_return": 0.0}
{"step": 1504224, "time": 68282.36002349854, "episode/length": 208.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 1504296, "time": 68286.08008980751, "episode/length": 394.0, "episode/score": 13.099999964237213, "episode/reward_rate": 0.9898734177215189, "episode/intrinsic_return": 0.0}
{"step": 1504536, "time": 68295.75896120071, "episode/length": 449.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 1504728, "time": 68303.94352817535, "episode/length": 406.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9803439803439803, "episode/intrinsic_return": 0.0}
{"step": 1504824, "time": 68308.85812854767, "episode/length": 173.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 1504904, "time": 68313.08605217934, "episode/length": 271.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 1505800, "time": 68344.97602820396, "episode/length": 196.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 1506064, "time": 68355.68987798691, "episode/length": 220.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 1506136, "time": 68359.61272263527, "episode/length": 295.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 1506184, "time": 68362.909668684, "episode/length": 205.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 1506488, "time": 68374.74933409691, "episode/length": 37.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 1506560, "time": 68378.9691259861, "episode/length": 216.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1507008, "time": 68395.73843336105, "episode/length": 150.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 1507352, "time": 68410.41606450081, "episode/length": 305.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 1507672, "time": 68422.91931247711, "episode/length": 200.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 1507784, "time": 68428.27036738396, "episode/length": 205.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 1507800, "time": 68430.46066856384, "episode/length": 98.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 1507832, "time": 68433.18268847466, "episode/length": 387.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 1507920, "time": 68437.92320370674, "episode/length": 169.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1508105, "time": 68448.97018170357, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.7729692792559, "train/action_min": 0.0, "train/action_std": 3.6882030430373614, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.02575725741632335, "train/actor_opt_grad_steps": 93450.0, "train/actor_opt_loss": -7.616626097188963, "train/adv_mag": 0.3802666863153031, "train/adv_max": 0.33015571388748144, "train/adv_mean": 0.0016408708698099554, "train/adv_min": -0.3139911756648884, "train/adv_std": 0.039701549844308334, "train/cont_avg": 0.9961074082167832, "train/cont_loss_mean": 0.00015993862478638163, "train/cont_loss_std": 0.0048830084419356585, "train/cont_neg_acc": 0.9953051650188338, "train/cont_neg_loss": 0.025041767785286936, "train/cont_pos_acc": 0.9999793917982729, "train/cont_pos_loss": 5.737524165372942e-05, "train/cont_pred": 0.9961012168364092, "train/cont_rate": 0.9961074082167832, "train/dyn_loss_mean": 13.013031012528426, "train/dyn_loss_std": 9.398636964651255, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9503324048502462, "train/extr_critic_critic_opt_grad_steps": 93450.0, "train/extr_critic_critic_opt_loss": 14978.034131883742, "train/extr_critic_mag": 10.535442639064122, "train/extr_critic_max": 10.535442639064122, "train/extr_critic_mean": 2.3242359969999407, "train/extr_critic_min": -0.18933811804631373, "train/extr_critic_std": 2.5045065704759186, "train/extr_return_normed_mag": 1.4685656132397953, "train/extr_return_normed_max": 1.4685656132397953, "train/extr_return_normed_mean": 0.2980452233052754, "train/extr_return_normed_min": -0.059383404525843536, "train/extr_return_normed_std": 0.321226562861796, "train/extr_return_rate": 0.7230368973491909, "train/extr_return_raw_mag": 11.547441309148615, "train/extr_return_raw_max": 11.547441309148615, "train/extr_return_raw_mean": 2.337141905631219, "train/extr_return_raw_min": -0.47538514831266204, "train/extr_return_raw_std": 2.5278926937730164, "train/extr_reward_mag": 1.050544670411757, "train/extr_reward_max": 1.050544670411757, "train/extr_reward_mean": 0.042955636991174904, "train/extr_reward_min": -0.45172707434300774, "train/extr_reward_std": 0.19379414044893706, "train/image_loss_mean": 6.585828054201353, "train/image_loss_std": 12.487531255175183, "train/model_loss_mean": 14.455761449320333, "train/model_loss_std": 16.304256719309134, "train/model_opt_grad_norm": 46.78367113233446, "train/model_opt_grad_steps": 93367.01398601399, "train/model_opt_loss": 22004.886022180945, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1520.979020979021, "train/policy_entropy_mag": 2.674380409134018, "train/policy_entropy_max": 2.674380409134018, "train/policy_entropy_mean": 0.8471530396621544, "train/policy_entropy_min": 0.07937502522360194, "train/policy_entropy_std": 0.9201951268669608, "train/policy_logprob_mag": 7.438383899368606, "train/policy_logprob_max": -0.009455658391222253, "train/policy_logprob_mean": -0.8474478354820838, "train/policy_logprob_min": -7.438383899368606, "train/policy_logprob_std": 1.266038976349197, "train/policy_randomness_mag": 0.9439389230488063, "train/policy_randomness_max": 0.9439389230488063, "train/policy_randomness_mean": 0.299007850718665, "train/policy_randomness_min": 0.028015900585618054, "train/policy_randomness_std": 0.3247884960024507, "train/post_ent_mag": 61.56883978676963, "train/post_ent_max": 61.56883978676963, "train/post_ent_mean": 43.98500301120998, "train/post_ent_min": 20.243475567210805, "train/post_ent_std": 7.852425248472841, "train/prior_ent_mag": 71.17020400254043, "train/prior_ent_max": 71.17020400254043, "train/prior_ent_mean": 57.08772661969378, "train/prior_ent_min": 40.839665206162245, "train/prior_ent_std": 4.875736039835257, "train/rep_loss_mean": 13.013031012528426, "train/rep_loss_std": 9.398636964651255, "train/reward_avg": 0.038418514875473674, "train/reward_loss_mean": 0.06195493355080798, "train/reward_loss_std": 0.2486025218988632, "train/reward_max_data": 1.0251748311769713, "train/reward_max_pred": 1.018826219585392, "train/reward_neg_acc": 0.9915094738240009, "train/reward_neg_loss": 0.030691835632013692, "train/reward_pos_acc": 0.98133288105051, "train/reward_pos_loss": 0.7802762985229492, "train/reward_pred": 0.037796074055604166, "train/reward_rate": 0.04192389641608392, "train_stats/sum_log_reward": 11.448837429978127, "train_stats/max_log_achievement_collect_coal": 1.1511627906976745, "train_stats/max_log_achievement_collect_drink": 6.441860465116279, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 2.0697674418604652, "train_stats/max_log_achievement_collect_stone": 13.011627906976743, "train_stats/max_log_achievement_collect_wood": 10.767441860465116, "train_stats/max_log_achievement_defeat_skeleton": 0.09302325581395349, "train_stats/max_log_achievement_defeat_zombie": 1.5116279069767442, "train_stats/max_log_achievement_eat_cow": 0.5, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.011627906976744186, "train_stats/max_log_achievement_make_stone_sword": 0.011627906976744186, "train_stats/max_log_achievement_make_wood_pickaxe": 1.1162790697674418, "train_stats/max_log_achievement_make_wood_sword": 1.4767441860465116, "train_stats/max_log_achievement_place_furnace": 2.13953488372093, "train_stats/max_log_achievement_place_plant": 1.872093023255814, "train_stats/max_log_achievement_place_stone": 3.511627906976744, "train_stats/max_log_achievement_place_table": 2.883720930232558, "train_stats/max_log_achievement_wake_up": 1.8837209302325582, "train_stats/mean_log_entropy": 0.7074686181406642, "eval_stats/sum_log_reward": 10.850000262260437, "eval_stats/max_log_achievement_collect_coal": 0.8125, "eval_stats/max_log_achievement_collect_drink": 4.75, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.9375, "eval_stats/max_log_achievement_collect_stone": 12.0625, "eval_stats/max_log_achievement_collect_wood": 10.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.5625, "eval_stats/max_log_achievement_eat_cow": 0.5, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0625, "eval_stats/max_log_achievement_make_wood_sword": 1.375, "eval_stats/max_log_achievement_place_furnace": 1.75, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 3.875, "eval_stats/max_log_achievement_place_table": 2.5, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 2.6590247216518037e-05, "report/cont_loss_std": 0.0008139675483107567, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00033063022419810295, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.5696885131765157e-05, "report/cont_pred": 0.9970460534095764, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.491247177124023, "report/dyn_loss_std": 8.949780464172363, "report/image_loss_mean": 7.211081504821777, "report/image_loss_std": 14.35205078125, "report/model_loss_mean": 14.756797790527344, "report/model_loss_std": 17.5947208404541, "report/post_ent_mag": 63.54860305786133, "report/post_ent_max": 63.54860305786133, "report/post_ent_mean": 44.70927429199219, "report/post_ent_min": 20.55365753173828, "report/post_ent_std": 7.719172954559326, "report/prior_ent_mag": 70.8277587890625, "report/prior_ent_max": 70.8277587890625, "report/prior_ent_mean": 57.44648361206055, "report/prior_ent_min": 42.021175384521484, "report/prior_ent_std": 5.385334014892578, "report/rep_loss_mean": 12.491247177124023, "report/rep_loss_std": 8.949780464172363, "report/reward_avg": 0.03125, "report/reward_loss_mean": 0.050940874963998795, "report/reward_loss_std": 0.18850001692771912, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0075607299804688, "report/reward_neg_acc": 0.9828281998634338, "report/reward_neg_loss": 0.029551535844802856, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6737480163574219, "report/reward_pred": 0.0328436940908432, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.022180549625773e-05, "eval/cont_loss_std": 0.0003230216389056295, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0052085136994719505, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.9022315096181046e-08, "eval/cont_pred": 0.9980570077896118, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 16.86409568786621, "eval/dyn_loss_std": 10.747857093811035, "eval/image_loss_mean": 7.973026275634766, "eval/image_loss_std": 10.988892555236816, "eval/model_loss_mean": 18.164081573486328, "eval/model_loss_std": 15.146297454833984, "eval/post_ent_mag": 62.96623992919922, "eval/post_ent_max": 62.96623992919922, "eval/post_ent_mean": 43.05274963378906, "eval/post_ent_min": 19.95244598388672, "eval/post_ent_std": 8.441344261169434, "eval/prior_ent_mag": 70.8277587890625, "eval/prior_ent_max": 70.8277587890625, "eval/prior_ent_mean": 57.69685363769531, "eval/prior_ent_min": 43.970680236816406, "eval/prior_ent_std": 4.638628005981445, "eval/rep_loss_mean": 16.86409568786621, "eval/rep_loss_std": 10.747857093811035, "eval/reward_avg": 0.04658202826976776, "eval/reward_loss_mean": 0.0725848600268364, "eval/reward_loss_std": 0.3522590100765228, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0053915977478027, "eval/reward_neg_acc": 0.9845996499061584, "eval/reward_neg_loss": 0.02516612596809864, "eval/reward_pos_acc": 0.9399999976158142, "eval/reward_pos_loss": 0.9963018298149109, "eval/reward_pred": 0.044092051684856415, "eval/reward_rate": 0.048828125, "replay/size": 1000000.0, "replay/inserts": 22736.0, "replay/samples": 22736.0, "replay/insert_wait_avg": 1.3658523895134814e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.152854182533946e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5864.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3258984111666192e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0559005737305, "timer/env.step_count": 2842.0, "timer/env.step_total": 219.28778386116028, "timer/env.step_frac": 0.21927552623343877, "timer/env.step_avg": 0.07715967060561586, "timer/env.step_min": 0.024700641632080078, "timer/env.step_max": 1.7775492668151855, "timer/replay._sample_count": 22736.0, "timer/replay._sample_total": 11.888361692428589, "timer/replay._sample_frac": 0.011887697163336824, "timer/replay._sample_avg": 0.0005228871258105466, "timer/replay._sample_min": 0.0004055500030517578, "timer/replay._sample_max": 0.028006792068481445, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3575.0, "timer/agent.policy_total": 62.13167715072632, "timer/agent.policy_frac": 0.062128204148469576, "timer/agent.policy_avg": 0.017379490112091278, "timer/agent.policy_min": 0.009696245193481445, "timer/agent.policy_max": 0.11380457878112793, "timer/dataset_train_count": 1421.0, "timer/dataset_train_total": 0.15923357009887695, "timer/dataset_train_frac": 0.00015922466934850833, "timer/dataset_train_avg": 0.00011205740330673958, "timer/dataset_train_min": 9.870529174804688e-05, "timer/dataset_train_max": 0.0005736351013183594, "timer/agent.train_count": 1421.0, "timer/agent.train_total": 641.5697128772736, "timer/agent.train_frac": 0.6415338507669481, "timer/agent.train_avg": 0.45149170505086106, "timer/agent.train_min": 0.43468546867370605, "timer/agent.train_max": 1.8318238258361816, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5223698616027832, "timer/agent.report_frac": 0.0005223406624600689, "timer/agent.report_avg": 0.2611849308013916, "timer/agent.report_min": 0.24410247802734375, "timer/agent.report_max": 0.27826738357543945, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.1707898530788156e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 22.734377569302097}
{"step": 1508192, "time": 68451.96106600761, "episode/length": 44.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 1508336, "time": 68459.12405538559, "episode/length": 230.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 1508448, "time": 68464.49449419975, "episode/length": 136.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 1509032, "time": 68485.37098479271, "episode/length": 169.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 1509144, "time": 68490.74021482468, "episode/length": 750.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9973368841544608, "episode/intrinsic_return": 0.0}
{"step": 1509520, "time": 68505.37770843506, "episode/length": 214.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 1509584, "time": 68509.7509496212, "episode/length": 224.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1510048, "time": 68527.3683898449, "episode/length": 213.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 1510080, "time": 68547.93307209015, "eval_episode/length": 102.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9611650485436893}
{"step": 1510080, "time": 68550.21383905411, "eval_episode/length": 116.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9914529914529915}
{"step": 1510080, "time": 68554.77831339836, "eval_episode/length": 181.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 1510080, "time": 68556.87430000305, "eval_episode/length": 190.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 1510080, "time": 68559.27362918854, "eval_episode/length": 207.0, "eval_episode/score": 11.100000038743019, "eval_episode/reward_rate": 0.9711538461538461}
{"step": 1510080, "time": 68561.02376699448, "eval_episode/length": 210.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9715639810426541}
{"step": 1510080, "time": 68562.92795228958, "eval_episode/length": 217.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 1510080, "time": 68569.7473461628, "eval_episode/length": 288.0, "eval_episode/score": 12.100000023841858, "eval_episode/reward_rate": 0.9757785467128027}
{"step": 1510232, "time": 68574.68283605576, "episode/length": 135.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 1510392, "time": 68581.62065386772, "episode/length": 308.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 1510400, "time": 68583.79417610168, "episode/length": 275.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 1510920, "time": 68602.95773863792, "episode/length": 308.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 1510976, "time": 68606.72904443741, "episode/length": 173.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 1511184, "time": 68615.49069690704, "episode/length": 97.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 1511552, "time": 68629.71620893478, "episode/length": 187.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 1512072, "time": 68648.82759690285, "episode/length": 318.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9811912225705329, "episode/intrinsic_return": 0.0}
{"step": 1512160, "time": 68653.71083664894, "episode/length": 220.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 1512496, "time": 68666.9091770649, "episode/length": 163.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 1512712, "time": 68675.61683106422, "episode/length": 309.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9870967741935484, "episode/intrinsic_return": 0.0}
{"step": 1512768, "time": 68679.32826924324, "episode/length": 75.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9342105263157895, "episode/intrinsic_return": 0.0}
{"step": 1513480, "time": 68704.97366952896, "episode/length": 319.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.990625, "episode/intrinsic_return": 0.0}
{"step": 1513856, "time": 68719.4604935646, "episode/length": 169.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 1513896, "time": 68722.24796485901, "episode/length": 607.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 1514000, "time": 68727.63202953339, "episode/length": 64.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 1514088, "time": 68731.94601082802, "episode/length": 316.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9968454258675079, "episode/intrinsic_return": 0.0}
{"step": 1514408, "time": 68744.28252673149, "episode/length": 204.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 1514552, "time": 68750.93209862709, "episode/length": 229.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 1514568, "time": 68753.06958556175, "episode/length": 311.0, "episode/score": 13.100000016391277, "episode/reward_rate": 0.9967948717948718, "episode/intrinsic_return": 0.0}
{"step": 1515656, "time": 68793.29078888893, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 1515720, "time": 68796.99409222603, "episode/length": 214.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 1516472, "time": 68824.11115550995, "episode/length": 297.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 1516672, "time": 68833.03339385986, "episode/length": 282.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9752650176678446, "episode/intrinsic_return": 0.0}
{"step": 1516768, "time": 68837.88402175903, "episode/length": 363.0, "episode/score": 13.100000031292439, "episode/reward_rate": 0.9972527472527473, "episode/intrinsic_return": 0.0}
{"step": 1517224, "time": 68854.62663006783, "episode/length": 780.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9935979513444302, "episode/intrinsic_return": 0.0}
{"step": 1517360, "time": 68861.4970395565, "episode/length": 212.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 1517688, "time": 68873.99749088287, "episode/length": 389.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 1518280, "time": 68895.57129001617, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 1518440, "time": 68902.6828687191, "episode/length": 208.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 1518544, "time": 68907.96551036835, "episode/length": 233.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 1518736, "time": 68916.01502943039, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 1519464, "time": 68943.09574627876, "episode/length": 262.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 1519504, "time": 68946.37588095665, "episode/length": 472.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9915433403805497, "episode/intrinsic_return": 0.0}
{"step": 1519792, "time": 68957.81224560738, "episode/length": 654.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9984732824427481, "episode/intrinsic_return": 0.0}
{"step": 1519960, "time": 68964.90510034561, "episode/length": 209.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 1520064, "time": 68991.1551194191, "eval_episode/length": 160.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 1520064, "time": 68993.6793460846, "eval_episode/length": 178.0, "eval_episode/score": 13.100000001490116, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 1520064, "time": 68995.73507380486, "eval_episode/length": 190.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 1520064, "time": 68997.65772533417, "eval_episode/length": 196.0, "eval_episode/score": 11.099999979138374, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 1520064, "time": 69000.3079521656, "eval_episode/length": 220.0, "eval_episode/score": 11.100000016391277, "eval_episode/reward_rate": 0.9864253393665159}
{"step": 1520064, "time": 69002.26156139374, "eval_episode/length": 226.0, "eval_episode/score": 12.099999994039536, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 1520064, "time": 69004.78819274902, "eval_episode/length": 246.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9757085020242915}
{"step": 1520064, "time": 69007.25004649162, "eval_episode/length": 68.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9855072463768116}
{"step": 1520328, "time": 69015.90113401413, "episode/length": 235.0, "episode/score": 12.099999949336052, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1520504, "time": 69023.68248558044, "episode/length": 351.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9971590909090909, "episode/intrinsic_return": 0.0}
{"step": 1520960, "time": 69040.9081504345, "episode/length": 186.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 1520968, "time": 69042.53785800934, "episode/length": 302.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.976897689768977, "episode/intrinsic_return": 0.0}
{"step": 1521816, "time": 69072.94428753853, "episode/length": 384.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9922077922077922, "episode/intrinsic_return": 0.0}
{"step": 1521848, "time": 69075.7088546753, "episode/length": 189.0, "episode/score": 12.099999964237213, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 1522624, "time": 69104.14314079285, "episode/length": 264.0, "episode/score": 13.099999994039536, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 1522840, "time": 69113.13763046265, "episode/length": 359.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 1522984, "time": 69119.589189291, "episode/length": 251.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 1523008, "time": 69122.23649954796, "episode/length": 255.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 1523256, "time": 69131.98767971992, "episode/length": 468.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9893390191897654, "episode/intrinsic_return": 0.0}
{"step": 1523504, "time": 69142.25337290764, "episode/length": 463.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9870689655172413, "episode/intrinsic_return": 0.0}
{"step": 1523776, "time": 69155.07803678513, "episode/length": 240.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 1524296, "time": 69174.28866577148, "episode/length": 208.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 1524440, "time": 69180.76738858223, "episode/length": 178.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 1524624, "time": 69188.74473714828, "episode/length": 204.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 1524688, "time": 69192.4381403923, "episode/length": 358.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9972144846796658, "episode/intrinsic_return": 0.0}
{"step": 1524864, "time": 69200.06664299965, "episode/length": 252.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 1525264, "time": 69215.13551139832, "episode/length": 71.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 1525496, "time": 69224.40602707863, "episode/length": 279.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 1525528, "time": 69227.23030233383, "episode/length": 218.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 1526168, "time": 69250.40029287338, "episode/length": 233.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 1526264, "time": 69255.32499909401, "episode/length": 174.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1526968, "time": 69280.81843018532, "episode/length": 212.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 1527680, "time": 69307.099401474, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 1527736, "time": 69310.39161229134, "episode/length": 388.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.987146529562982, "episode/intrinsic_return": 0.0}
{"step": 1527800, "time": 69314.36940646172, "episode/length": 283.0, "episode/score": 14.099999979138374, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 1528376, "time": 69335.68324422836, "episode/length": 359.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9972222222222222, "episode/intrinsic_return": 0.0}
{"step": 1528504, "time": 69341.49777245522, "episode/length": 507.0, "episode/score": 13.099999994039536, "episode/reward_rate": 0.9980314960629921, "episode/intrinsic_return": 0.0}
{"step": 1528520, "time": 69343.55781292915, "episode/length": 97.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 1529224, "time": 69368.93776321411, "episode/length": 89.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1529272, "time": 69372.10074305534, "episode/length": 287.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 1529480, "time": 69380.6989479065, "episode/length": 224.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1529656, "time": 69388.17180585861, "episode/length": 231.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 1529656, "time": 69388.18113183975, "episode/length": 159.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 1530048, "time": 69427.98698282242, "eval_episode/length": 210.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.976303317535545}
{"step": 1530048, "time": 69432.84295225143, "eval_episode/length": 276.0, "eval_episode/score": 13.100000016391277, "eval_episode/reward_rate": 0.9963898916967509}
{"step": 1530048, "time": 69434.9169895649, "eval_episode/length": 284.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9719298245614035}
{"step": 1530048, "time": 69438.3645722866, "eval_episode/length": 321.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9875776397515528}
{"step": 1530048, "time": 69441.89403247833, "eval_episode/length": 362.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9944903581267218}
{"step": 1530048, "time": 69445.65463209152, "eval_episode/length": 48.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9387755102040817}
{"step": 1530048, "time": 69447.89518666267, "eval_episode/length": 427.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9883177570093458}
{"step": 1530048, "time": 69449.9186425209, "eval_episode/length": 225.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.995575221238938}
{"step": 1530049, "time": 69450.52840423584, "train_stats/sum_log_reward": 11.327848283550408, "train_stats/max_log_achievement_collect_coal": 0.9746835443037974, "train_stats/max_log_achievement_collect_drink": 6.2025316455696204, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.8860759493670887, "train_stats/max_log_achievement_collect_stone": 13.670886075949367, "train_stats/max_log_achievement_collect_wood": 11.569620253164556, "train_stats/max_log_achievement_defeat_skeleton": 0.12658227848101267, "train_stats/max_log_achievement_defeat_zombie": 1.481012658227848, "train_stats/max_log_achievement_eat_cow": 0.43037974683544306, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.012658227848101266, "train_stats/max_log_achievement_make_stone_sword": 0.02531645569620253, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2025316455696202, "train_stats/max_log_achievement_make_wood_sword": 1.4303797468354431, "train_stats/max_log_achievement_place_furnace": 2.1772151898734178, "train_stats/max_log_achievement_place_plant": 1.7215189873417722, "train_stats/max_log_achievement_place_stone": 3.8354430379746836, "train_stats/max_log_achievement_place_table": 2.810126582278481, "train_stats/max_log_achievement_wake_up": 1.8481012658227849, "train_stats/mean_log_entropy": 0.7246009858348702, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.867901210367244, "train/action_min": 0.0, "train/action_std": 3.7323346973335654, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.026752163717237702, "train/actor_opt_grad_steps": 94850.0, "train/actor_opt_loss": -8.360239777741207, "train/adv_mag": 0.3920028797031319, "train/adv_max": 0.35526541528040473, "train/adv_mean": 0.001657288737045295, "train/adv_min": -0.3246672864813004, "train/adv_std": 0.04074007241449652, "train/cont_avg": 0.9961008781934306, "train/cont_loss_mean": 0.0001276411706094405, "train/cont_loss_std": 0.0036200161181832845, "train/cont_neg_acc": 0.9909737038968215, "train/cont_neg_loss": 0.025256816166221996, "train/cont_pos_acc": 0.9999928021953054, "train/cont_pos_loss": 2.8586836253866187e-05, "train/cont_pred": 0.9961354445366963, "train/cont_rate": 0.9961008781934306, "train/dyn_loss_mean": 12.942311579293579, "train/dyn_loss_std": 9.304654434649613, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9468884098268774, "train/extr_critic_critic_opt_grad_steps": 94850.0, "train/extr_critic_critic_opt_loss": 14899.665395472171, "train/extr_critic_mag": 10.521026325921943, "train/extr_critic_max": 10.521026325921943, "train/extr_critic_mean": 2.393438714264083, "train/extr_critic_min": -0.19832325242731694, "train/extr_critic_std": 2.543817889951441, "train/extr_return_normed_mag": 1.4661440918915463, "train/extr_return_normed_max": 1.4661440918915463, "train/extr_return_normed_mean": 0.3093431563708034, "train/extr_return_normed_min": -0.059501234251652324, "train/extr_return_normed_std": 0.3248937559606385, "train/extr_return_rate": 0.7261752410091623, "train/extr_return_raw_mag": 11.555431790595508, "train/extr_return_raw_max": 11.555431790595508, "train/extr_return_raw_mean": 2.406539316595036, "train/extr_return_raw_min": -0.5107324769462112, "train/extr_return_raw_std": 2.569490059448855, "train/extr_reward_mag": 1.0542698672218045, "train/extr_reward_max": 1.0542698672218045, "train/extr_reward_mean": 0.04377613643551395, "train/extr_reward_min": -0.4499124915060336, "train/extr_reward_std": 0.19593875349438103, "train/image_loss_mean": 6.3918870034879145, "train/image_loss_std": 11.987161173437634, "train/model_loss_mean": 14.218781526941452, "train/model_loss_std": 15.708435914812297, "train/model_opt_grad_norm": 45.241161095835, "train/model_opt_grad_steps": 94765.88321167883, "train/model_opt_loss": 21541.434106979927, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1514.5985401459855, "train/policy_entropy_mag": 2.6771446544758595, "train/policy_entropy_max": 2.6771446544758595, "train/policy_entropy_mean": 0.8562124606466641, "train/policy_entropy_min": 0.07937502279116289, "train/policy_entropy_std": 0.9336486776379773, "train/policy_logprob_mag": 7.4383838890242755, "train/policy_logprob_max": -0.009455661880817727, "train/policy_logprob_mean": -0.8557081216008123, "train/policy_logprob_min": -7.4383838890242755, "train/policy_logprob_std": 1.2674115060889808, "train/policy_randomness_mag": 0.9449145802616203, "train/policy_randomness_max": 0.9449145802616203, "train/policy_randomness_mean": 0.3022054275021936, "train/policy_randomness_min": 0.028015899764251534, "train/policy_randomness_std": 0.3295370108672302, "train/post_ent_mag": 61.46394944016951, "train/post_ent_max": 61.46394944016951, "train/post_ent_mean": 43.90620196822786, "train/post_ent_min": 20.20922348969174, "train/post_ent_std": 7.805051239737629, "train/prior_ent_mag": 71.26739095423343, "train/prior_ent_max": 71.26739095423343, "train/prior_ent_mean": 56.91399060548657, "train/prior_ent_min": 40.50564268905751, "train/prior_ent_std": 4.931969618275218, "train/rep_loss_mean": 12.942311579293579, "train/rep_loss_std": 9.304654434649613, "train/reward_avg": 0.03979527814327365, "train/reward_loss_mean": 0.06137999701891502, "train/reward_loss_std": 0.24464009430286657, "train/reward_max_data": 1.027007305709115, "train/reward_max_pred": 1.0232055805025309, "train/reward_neg_acc": 0.9917913962454692, "train/reward_neg_loss": 0.02866651873736486, "train/reward_pos_acc": 0.9801585239215489, "train/reward_pos_loss": 0.785922642171818, "train/reward_pred": 0.03899326050368539, "train/reward_rate": 0.04328951870437956, "eval_stats/sum_log_reward": 10.600000242392221, "eval_stats/max_log_achievement_collect_coal": 0.9166666666666666, "eval_stats/max_log_achievement_collect_drink": 5.333333333333333, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.4166666666666667, "eval_stats/max_log_achievement_collect_stone": 12.416666666666666, "eval_stats/max_log_achievement_collect_wood": 9.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.3333333333333333, "eval_stats/max_log_achievement_eat_cow": 0.375, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1666666666666667, "eval_stats/max_log_achievement_make_wood_sword": 1.0833333333333333, "eval_stats/max_log_achievement_place_furnace": 1.9583333333333333, "eval_stats/max_log_achievement_place_plant": 1.1666666666666667, "eval_stats/max_log_achievement_place_stone": 3.4583333333333335, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.3333333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.2050921213813126e-05, "report/cont_loss_std": 0.0002747025282587856, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0007288814522325993, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 9.239820428774692e-06, "report/cont_pred": 0.9960874319076538, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 11.982094764709473, "report/dyn_loss_std": 9.805896759033203, "report/image_loss_mean": 5.819664001464844, "report/image_loss_std": 11.630378723144531, "report/model_loss_mean": 13.078423500061035, "report/model_loss_std": 15.729168891906738, "report/post_ent_mag": 63.84088897705078, "report/post_ent_max": 63.84088897705078, "report/post_ent_mean": 44.44774627685547, "report/post_ent_min": 20.126510620117188, "report/post_ent_std": 7.854654312133789, "report/prior_ent_mag": 71.14671325683594, "report/prior_ent_max": 71.14671325683594, "report/prior_ent_mean": 56.66993713378906, "report/prior_ent_min": 39.42366027832031, "report/prior_ent_std": 5.259390830993652, "report/rep_loss_mean": 11.982094764709473, "report/rep_loss_std": 9.805896759033203, "report/reward_avg": 0.04374999925494194, "report/reward_loss_mean": 0.06949016451835632, "report/reward_loss_std": 0.2314823716878891, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.079117774963379, "report/reward_neg_acc": 0.9835560321807861, "report/reward_neg_loss": 0.032842859625816345, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7686634659767151, "report/reward_pred": 0.041561711579561234, "report/reward_rate": 0.0498046875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 4.4962711399421096e-05, "eval/cont_loss_std": 0.0013670452171936631, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.014673508703708649, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.9797184904746246e-06, "eval/cont_pred": 0.9971104860305786, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.209102630615234, "eval/dyn_loss_std": 11.032293319702148, "eval/image_loss_mean": 8.682547569274902, "eval/image_loss_std": 11.868699073791504, "eval/model_loss_mean": 19.130996704101562, "eval/model_loss_std": 16.525169372558594, "eval/post_ent_mag": 59.71046447753906, "eval/post_ent_max": 59.71046447753906, "eval/post_ent_mean": 41.52315139770508, "eval/post_ent_min": 19.765625, "eval/post_ent_std": 7.554915428161621, "eval/prior_ent_mag": 71.14671325683594, "eval/prior_ent_max": 71.14671325683594, "eval/prior_ent_mean": 57.10758972167969, "eval/prior_ent_min": 44.65117645263672, "eval/prior_ent_std": 4.680110454559326, "eval/rep_loss_mean": 17.209102630615234, "eval/rep_loss_std": 11.032293319702148, "eval/reward_avg": 0.05585937574505806, "eval/reward_loss_mean": 0.12294106185436249, "eval/reward_loss_std": 0.5918315052986145, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0088880062103271, "eval/reward_neg_acc": 0.979231595993042, "eval/reward_neg_loss": 0.045275378972291946, "eval/reward_pos_acc": 0.8852459788322449, "eval/reward_pos_loss": 1.3490403890609741, "eval/reward_pred": 0.048756323754787445, "eval/reward_rate": 0.0595703125, "replay/size": 1000000.0, "replay/inserts": 21944.0, "replay/samples": 21936.0, "replay/insert_wait_avg": 1.3551093173470325e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.124556531008797e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2987443516331334e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1004.0597155094147, "timer/env.step_count": 2743.0, "timer/env.step_total": 208.11877059936523, "timer/env.step_frac": 0.20727728379559093, "timer/env.step_avg": 0.07587268341209086, "timer/env.step_min": 0.024628639221191406, "timer/env.step_max": 3.3515424728393555, "timer/replay._sample_count": 21936.0, "timer/replay._sample_total": 11.368638038635254, "timer/replay._sample_frac": 0.011322671214696945, "timer/replay._sample_avg": 0.000518263951433044, "timer/replay._sample_min": 0.0004215240478515625, "timer/replay._sample_max": 0.010340452194213867, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3735.0, "timer/agent.policy_total": 66.22946429252625, "timer/agent.policy_frac": 0.06596167864271339, "timer/agent.policy_avg": 0.017732118953822287, "timer/agent.policy_min": 0.009982585906982422, "timer/agent.policy_max": 0.13489699363708496, "timer/dataset_train_count": 1371.0, "timer/dataset_train_total": 0.15533828735351562, "timer/dataset_train_frac": 0.00015471020792294607, "timer/dataset_train_avg": 0.00011330290835413248, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.0010526180267333984, "timer/agent.train_count": 1371.0, "timer/agent.train_total": 618.8424890041351, "timer/agent.train_frac": 0.616340322637247, "timer/agent.train_avg": 0.4513803712648688, "timer/agent.train_min": 0.4366767406463623, "timer/agent.train_max": 1.889533519744873, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47597622871398926, "timer/agent.report_frac": 0.0004740517136199418, "timer/agent.report_avg": 0.23798811435699463, "timer/agent.report_min": 0.23060989379882812, "timer/agent.report_max": 0.24536633491516113, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.063164095623272e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 21.854968498822508}
{"step": 1530056, "time": 69450.57234072685, "episode/length": 818.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9902319902319903, "episode/intrinsic_return": 0.0}
{"step": 1530656, "time": 69473.4182548523, "episode/length": 146.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 1530720, "time": 69477.32072687149, "episode/length": 556.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9982046678635548, "episode/intrinsic_return": 0.0}
{"step": 1530720, "time": 69477.32917737961, "episode/length": 132.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 1531168, "time": 69495.88714289665, "episode/length": 188.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 1531224, "time": 69499.31968212128, "episode/length": 145.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 1531568, "time": 69512.90964818001, "episode/length": 286.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9965156794425087, "episode/intrinsic_return": 0.0}
{"step": 1531984, "time": 69530.53361320496, "episode/length": 94.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1532208, "time": 69539.90542554855, "episode/length": 185.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 1532312, "time": 69544.94347882271, "episode/length": 206.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 1532320, "time": 69547.05794167519, "episode/length": 199.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 1532496, "time": 69554.63802480698, "episode/length": 496.0, "episode/score": 13.1000000461936, "episode/reward_rate": 0.9979879275653923, "episode/intrinsic_return": 0.0}
{"step": 1533016, "time": 69574.05342793465, "episode/length": 473.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9810126582278481, "episode/intrinsic_return": 0.0}
{"step": 1533312, "time": 69586.04268217087, "episode/length": 267.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 1533344, "time": 69588.81648755074, "episode/length": 141.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 1533568, "time": 69598.13893890381, "episode/length": 197.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 1533608, "time": 69600.8390352726, "episode/length": 254.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 1533752, "time": 69607.2725288868, "episode/length": 156.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 1534064, "time": 69619.67963004112, "episode/length": 61.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 1534128, "time": 69623.41037869453, "episode/length": 225.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 1534360, "time": 69632.58119797707, "episode/length": 255.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 1535176, "time": 69662.01015043259, "episode/length": 269.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 1535216, "time": 69665.10560488701, "episode/length": 200.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 1535312, "time": 69669.96063518524, "episode/length": 249.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 1535352, "time": 69672.72390055656, "episode/length": 250.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 1535792, "time": 69689.81020617485, "episode/length": 254.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 1535872, "time": 69694.12513923645, "episode/length": 217.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1535896, "time": 69696.62512350082, "episode/length": 191.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 1536904, "time": 69732.90279817581, "episode/length": 354.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9915492957746479, "episode/intrinsic_return": 0.0}
{"step": 1537176, "time": 69743.9073445797, "episode/length": 162.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 1537192, "time": 69746.12894797325, "episode/length": 246.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 1537232, "time": 69749.27233171463, "episode/length": 239.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 1538352, "time": 69788.79604005814, "episode/length": 306.0, "episode/score": 12.10000005364418, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 1538544, "time": 69797.18199777603, "episode/length": 204.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 1538632, "time": 69801.51905012131, "episode/length": 431.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9976851851851852, "episode/intrinsic_return": 0.0}
{"step": 1538640, "time": 69803.6877913475, "episode/length": 175.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 1538872, "time": 69812.93754410744, "episode/length": 439.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9931818181818182, "episode/intrinsic_return": 0.0}
{"step": 1539176, "time": 69824.943410635, "episode/length": 249.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 1539480, "time": 69837.46193146706, "episode/length": 460.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9978308026030369, "episode/intrinsic_return": 0.0}
{"step": 1540032, "time": 69879.72361397743, "eval_episode/length": 192.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9637305699481865}
{"step": 1540032, "time": 69881.37680840492, "eval_episode/length": 195.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 1540032, "time": 69883.38688850403, "eval_episode/length": 204.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 1540032, "time": 69885.39303040504, "eval_episode/length": 212.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9812206572769953}
{"step": 1540032, "time": 69887.40150165558, "eval_episode/length": 218.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9680365296803652}
{"step": 1540032, "time": 69891.04126787186, "eval_episode/length": 263.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9962121212121212}
{"step": 1540032, "time": 69893.38771796227, "eval_episode/length": 73.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9864864864864865}
{"step": 1540032, "time": 69900.33556723595, "eval_episode/length": 158.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 1540288, "time": 69910.89789843559, "episode/length": 205.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 1540352, "time": 69914.65080189705, "episode/length": 225.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 1540376, "time": 69916.95706868172, "episode/length": 397.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.992462311557789, "episode/intrinsic_return": 0.0}
{"step": 1540416, "time": 69920.69815778732, "episode/length": 257.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 1540888, "time": 69938.059933424, "episode/length": 251.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 1541176, "time": 69949.47655582428, "episode/length": 317.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 1541504, "time": 69962.404088974, "episode/length": 290.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9862542955326461, "episode/intrinsic_return": 0.0}
{"step": 1541872, "time": 69976.50940155983, "episode/length": 197.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 1541992, "time": 69981.88928389549, "episode/length": 196.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 1542248, "time": 69992.2072417736, "episode/length": 169.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1542832, "time": 70014.11872887611, "episode/length": 104.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 1542872, "time": 70016.80194306374, "episode/length": 170.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 1543056, "time": 70024.85312795639, "episode/length": 334.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 1543656, "time": 70046.86699843407, "episode/length": 222.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 1543800, "time": 70053.27959418297, "episode/length": 539.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9981481481481481, "episode/intrinsic_return": 0.0}
{"step": 1544488, "time": 70078.3168952465, "episode/length": 178.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 1544512, "time": 70081.04262280464, "episode/length": 204.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 1544904, "time": 70095.79627871513, "episode/length": 568.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9982425307557118, "episode/intrinsic_return": 0.0}
{"step": 1545112, "time": 70104.6380751133, "episode/length": 181.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 1545128, "time": 70106.79019165039, "episode/length": 286.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9965156794425087, "episode/intrinsic_return": 0.0}
{"step": 1545144, "time": 70108.92450332642, "episode/length": 495.0, "episode/score": 15.099999971687794, "episode/reward_rate": 0.9979838709677419, "episode/intrinsic_return": 0.0}
{"step": 1545240, "time": 70113.83790826797, "episode/length": 373.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9893048128342246, "episode/intrinsic_return": 0.0}
{"step": 1545720, "time": 70131.8413131237, "episode/length": 239.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 1546136, "time": 70147.49379563332, "episode/length": 205.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 1546424, "time": 70158.93104028702, "episode/length": 189.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1546760, "time": 70172.10363125801, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 1546776, "time": 70174.33025527, "episode/length": 207.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 1546792, "time": 70176.48072004318, "episode/length": 193.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 1547032, "time": 70186.56288719177, "episode/length": 235.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1547080, "time": 70189.74153327942, "episode/length": 320.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9875389408099688, "episode/intrinsic_return": 0.0}
{"step": 1547448, "time": 70203.73694133759, "episode/length": 81.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1547480, "time": 70206.43984293938, "episode/length": 219.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1547496, "time": 70208.58139395714, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1548560, "time": 70248.3009762764, "episode/length": 266.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 1548720, "time": 70255.38791131973, "episode/length": 244.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 1548888, "time": 70262.55279684067, "episode/length": 225.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 1549128, "time": 70272.54765415192, "episode/length": 209.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 1549344, "time": 70281.83778429031, "episode/length": 320.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9750778816199377, "episode/intrinsic_return": 0.0}
{"step": 1549896, "time": 70301.71370005608, "episode/length": 299.0, "episode/score": 13.100000038743019, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.0}
{"step": 1550016, "time": 70329.2090895176, "eval_episode/length": 179.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 1550016, "time": 70331.94937634468, "eval_episode/length": 204.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9853658536585366}
{"step": 1550016, "time": 70333.8868291378, "eval_episode/length": 211.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 1550016, "time": 70336.6014122963, "eval_episode/length": 233.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 1550016, "time": 70339.04077482224, "eval_episode/length": 253.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9724409448818898}
{"step": 1550016, "time": 70341.54132628441, "eval_episode/length": 272.0, "eval_episode/score": 13.100000001490116, "eval_episode/reward_rate": 0.9926739926739927}
{"step": 1550016, "time": 70344.72177147865, "eval_episode/length": 294.0, "eval_episode/score": 11.099999971687794, "eval_episode/reward_rate": 0.9966101694915255}
{"step": 1550016, "time": 70348.75664591789, "eval_episode/length": 166.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 1550560, "time": 70367.31535625458, "episode/length": 151.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 1550632, "time": 70371.14564085007, "episode/length": 258.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 1550880, "time": 70381.38290381432, "episode/length": 269.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1551168, "time": 70392.74618268013, "episode/length": 516.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9980657640232108, "episode/intrinsic_return": 0.0}
{"step": 1551256, "time": 70397.301933527, "episode/length": 265.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 1551304, "time": 70400.51447749138, "episode/length": 477.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9874476987447699, "episode/intrinsic_return": 0.0}
{"step": 1551376, "time": 70404.75141882896, "episode/length": 310.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9967845659163987, "episode/intrinsic_return": 0.0}
{"step": 1551776, "time": 70419.91535401344, "episode/length": 234.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1552592, "time": 70449.10781884193, "episode/length": 244.0, "episode/score": 12.1000000461936, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 1552593, "time": 70451.42815256119, "train_stats/sum_log_reward": 11.214942811549395, "train_stats/max_log_achievement_collect_coal": 0.8160919540229885, "train_stats/max_log_achievement_collect_drink": 6.32183908045977, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.9425287356321839, "train_stats/max_log_achievement_collect_stone": 13.827586206896552, "train_stats/max_log_achievement_collect_wood": 10.850574712643677, "train_stats/max_log_achievement_defeat_skeleton": 0.034482758620689655, "train_stats/max_log_achievement_defeat_zombie": 1.471264367816092, "train_stats/max_log_achievement_eat_cow": 0.4367816091954023, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.06896551724137931, "train_stats/max_log_achievement_make_stone_sword": 0.04597701149425287, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5402298850574712, "train_stats/max_log_achievement_make_wood_sword": 1.0574712643678161, "train_stats/max_log_achievement_place_furnace": 2.2413793103448274, "train_stats/max_log_achievement_place_plant": 1.7701149425287357, "train_stats/max_log_achievement_place_stone": 3.632183908045977, "train_stats/max_log_achievement_place_table": 2.8735632183908044, "train_stats/max_log_achievement_wake_up": 1.6551724137931034, "train_stats/mean_log_entropy": 0.7144707150157841, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.933943511746454, "train/action_min": 0.0, "train/action_std": 3.8226545736299338, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.026559728019415065, "train/actor_opt_grad_steps": 96240.0, "train/actor_opt_loss": -7.429667499312695, "train/adv_mag": 0.4206944037202402, "train/adv_max": 0.36791004451876835, "train/adv_mean": 0.0016016510093296921, "train/adv_min": -0.35424710556547695, "train/adv_std": 0.04039648229401585, "train/cont_avg": 0.9960106382978723, "train/cont_loss_mean": 0.00015388384586372545, "train/cont_loss_std": 0.004795210984031255, "train/cont_neg_acc": 0.9967026384614355, "train/cont_neg_loss": 0.016139987931757145, "train/cont_pos_acc": 0.9999721844991049, "train/cont_pos_loss": 5.849974376665256e-05, "train/cont_pred": 0.9960063087179306, "train/cont_rate": 0.9960106382978723, "train/dyn_loss_mean": 12.88956873467628, "train/dyn_loss_std": 9.217762236899517, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.929021713158763, "train/extr_critic_critic_opt_grad_steps": 96240.0, "train/extr_critic_critic_opt_loss": 14805.982754321809, "train/extr_critic_mag": 10.662744177148697, "train/extr_critic_max": 10.662744177148697, "train/extr_critic_mean": 2.4379674153970488, "train/extr_critic_min": -0.20155568072136412, "train/extr_critic_std": 2.5554717787614107, "train/extr_return_normed_mag": 1.4754209400068783, "train/extr_return_normed_max": 1.4754209400068783, "train/extr_return_normed_mean": 0.31220079630824693, "train/extr_return_normed_min": -0.0582956051823835, "train/extr_return_normed_std": 0.32177549072191225, "train/extr_return_rate": 0.7322256765889783, "train/extr_return_raw_mag": 11.775239112529349, "train/extr_return_raw_max": 11.775239112529349, "train/extr_return_raw_mean": 2.450793202041734, "train/extr_return_raw_min": -0.5194214577159137, "train/extr_return_raw_std": 2.5796869731118495, "train/extr_reward_mag": 1.0603569196471085, "train/extr_reward_max": 1.0603569196471085, "train/extr_reward_mean": 0.0440706313845325, "train/extr_reward_min": -0.4703050818003661, "train/extr_reward_std": 0.19682732795147187, "train/image_loss_mean": 6.333647846330142, "train/image_loss_std": 11.767014753733966, "train/model_loss_mean": 14.130675484948124, "train/model_loss_std": 15.4989145157185, "train/model_opt_grad_norm": 44.172230091500786, "train/model_opt_grad_steps": 96154.7304964539, "train/model_opt_loss": 19969.159532912236, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1418.4397163120568, "train/policy_entropy_mag": 2.677918613379729, "train/policy_entropy_max": 2.677918613379729, "train/policy_entropy_mean": 0.8727482565751312, "train/policy_entropy_min": 0.0793750229562428, "train/policy_entropy_std": 0.9386089427251343, "train/policy_logprob_mag": 7.4383838903819415, "train/policy_logprob_max": -0.009455658402954432, "train/policy_logprob_mean": -0.8724648123937295, "train/policy_logprob_min": -7.4383838903819415, "train/policy_logprob_std": 1.2733352725387466, "train/policy_randomness_mag": 0.9451877517057649, "train/policy_randomness_max": 0.9451877517057649, "train/policy_randomness_mean": 0.30804183962920034, "train/policy_randomness_min": 0.028015899874851213, "train/policy_randomness_std": 0.33128776586224845, "train/post_ent_mag": 61.66400181655343, "train/post_ent_max": 61.66400181655343, "train/post_ent_mean": 43.96342468261719, "train/post_ent_min": 20.177113012219152, "train/post_ent_std": 7.825023177667712, "train/prior_ent_mag": 71.16962211013686, "train/prior_ent_max": 71.16962211013686, "train/prior_ent_mean": 56.95562438423752, "train/prior_ent_min": 40.21384462397149, "train/prior_ent_std": 4.876954667111661, "train/rep_loss_mean": 12.88956873467628, "train/rep_loss_std": 9.217762236899517, "train/reward_avg": 0.039807042318350035, "train/reward_loss_mean": 0.06313251030254871, "train/reward_loss_std": 0.2558125251151146, "train/reward_max_data": 1.0269503610353943, "train/reward_max_pred": 1.0227394662004836, "train/reward_neg_acc": 0.9913224112902973, "train/reward_neg_loss": 0.030078693253404284, "train/reward_pos_acc": 0.976924736449059, "train/reward_pos_loss": 0.7934110033596661, "train/reward_pred": 0.03897482415674426, "train/reward_rate": 0.043363530585106384, "eval_stats/sum_log_reward": 11.162500351667404, "eval_stats/max_log_achievement_collect_coal": 1.1875, "eval_stats/max_log_achievement_collect_drink": 4.3125, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.8125, "eval_stats/max_log_achievement_collect_stone": 9.375, "eval_stats/max_log_achievement_collect_wood": 10.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.8125, "eval_stats/max_log_achievement_eat_cow": 0.5625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 1.0625, "eval_stats/max_log_achievement_place_furnace": 1.5, "eval_stats/max_log_achievement_place_plant": 1.8125, "eval_stats/max_log_achievement_place_stone": 2.8125, "eval_stats/max_log_achievement_place_table": 2.4375, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.8871123756980523e-06, "report/cont_loss_std": 1.1262079169682693e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.759479674656177e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.8632048295330605e-06, "report/cont_pred": 0.9951153993606567, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 10.958189964294434, "report/dyn_loss_std": 9.078277587890625, "report/image_loss_mean": 7.1003570556640625, "report/image_loss_std": 13.914216041564941, "report/model_loss_mean": 13.750143051147461, "report/model_loss_std": 17.70224952697754, "report/post_ent_mag": 60.47162628173828, "report/post_ent_max": 60.47162628173828, "report/post_ent_mean": 45.435089111328125, "report/post_ent_min": 18.19289779663086, "report/post_ent_std": 7.551675796508789, "report/prior_ent_mag": 71.40615844726562, "report/prior_ent_max": 71.40615844726562, "report/prior_ent_mean": 56.967796325683594, "report/prior_ent_min": 43.622962951660156, "report/prior_ent_std": 5.11090612411499, "report/rep_loss_mean": 10.958189964294434, "report/rep_loss_std": 9.078277587890625, "report/reward_avg": 0.04150390625, "report/reward_loss_mean": 0.07487054169178009, "report/reward_loss_std": 0.3545988202095032, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006330013275146, "report/reward_neg_acc": 0.9969293475151062, "report/reward_neg_loss": 0.03421357646584511, "report/reward_pos_acc": 0.9574467539787292, "report/reward_pos_loss": 0.920016348361969, "report/reward_pred": 0.03998253494501114, "report/reward_rate": 0.0458984375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.9451695152383763e-06, "eval/cont_loss_std": 1.2769408385793213e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.673606210621074e-06, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.930548023665324e-06, "eval/cont_pred": 0.9960918426513672, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 15.189840316772461, "eval/dyn_loss_std": 11.573457717895508, "eval/image_loss_mean": 7.271284103393555, "eval/image_loss_std": 12.723255157470703, "eval/model_loss_mean": 16.552780151367188, "eval/model_loss_std": 17.419788360595703, "eval/post_ent_mag": 62.98807907104492, "eval/post_ent_max": 62.98807907104492, "eval/post_ent_mean": 43.306541442871094, "eval/post_ent_min": 20.081172943115234, "eval/post_ent_std": 8.32176399230957, "eval/prior_ent_mag": 71.40615844726562, "eval/prior_ent_max": 71.40615844726562, "eval/prior_ent_mean": 57.137840270996094, "eval/prior_ent_min": 43.00819778442383, "eval/prior_ent_std": 5.154752731323242, "eval/rep_loss_mean": 15.189840316772461, "eval/rep_loss_std": 11.573457717895508, "eval/reward_avg": 0.05302734300494194, "eval/reward_loss_mean": 0.16759072244167328, "eval/reward_loss_std": 0.7969666719436646, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0028550624847412, "eval/reward_neg_acc": 0.9855222105979919, "eval/reward_neg_loss": 0.06821659207344055, "eval/reward_pos_acc": 0.7719298601150513, "eval/reward_pos_loss": 1.853463888168335, "eval/reward_pred": 0.04708360508084297, "eval/reward_rate": 0.0556640625, "replay/size": 1000000.0, "replay/inserts": 22544.0, "replay/samples": 22544.0, "replay/insert_wait_avg": 1.36511134627527e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.15851794988065e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5616.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2576410233804642e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.8995563983917, "timer/env.step_count": 2818.0, "timer/env.step_total": 224.89728093147278, "timer/env.step_frac": 0.22469515496713446, "timer/env.step_avg": 0.07980740984083491, "timer/env.step_min": 0.024389266967773438, "timer/env.step_max": 3.408893346786499, "timer/replay._sample_count": 22544.0, "timer/replay._sample_total": 11.698724269866943, "timer/replay._sample_frac": 0.01168821006571658, "timer/replay._sample_avg": 0.0005189285073574762, "timer/replay._sample_min": 0.00038695335388183594, "timer/replay._sample_max": 0.011268377304077148, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3520.0, "timer/agent.policy_total": 63.02298331260681, "timer/agent.policy_frac": 0.06296634153719372, "timer/agent.policy_avg": 0.017904256622899663, "timer/agent.policy_min": 0.009865999221801758, "timer/agent.policy_max": 0.2612948417663574, "timer/dataset_train_count": 1409.0, "timer/dataset_train_total": 0.16104722023010254, "timer/dataset_train_frac": 0.00016090247937526343, "timer/dataset_train_avg": 0.00011429894977296135, "timer/dataset_train_min": 9.870529174804688e-05, "timer/dataset_train_max": 0.0005834102630615234, "timer/agent.train_count": 1409.0, "timer/agent.train_total": 637.1039998531342, "timer/agent.train_frac": 0.6365314039559283, "timer/agent.train_avg": 0.45216749457284183, "timer/agent.train_min": 0.43764543533325195, "timer/agent.train_max": 1.9416604042053223, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47579360008239746, "timer/agent.report_frac": 0.0004753659815720965, "timer/agent.report_avg": 0.23789680004119873, "timer/agent.report_min": 0.22871875762939453, "timer/agent.report_max": 0.24707484245300293, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 3.358680642669763e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 22.52342769867966}
{"step": 1552880, "time": 70461.58248233795, "episode/length": 196.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 1552888, "time": 70463.24107050896, "episode/length": 214.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 1552952, "time": 70467.03366422653, "episode/length": 211.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 1553392, "time": 70483.85344195366, "episode/length": 353.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 1553400, "time": 70485.4376938343, "episode/length": 252.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 1553576, "time": 70493.10387420654, "episode/length": 224.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 1553920, "time": 70506.53269815445, "episode/length": 379.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 1553960, "time": 70509.23562717438, "episode/length": 170.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 1554024, "time": 70512.99140763283, "episode/length": 133.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1554096, "time": 70517.51084685326, "episode/length": 150.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 1555096, "time": 70552.99772167206, "episode/length": 189.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 1555160, "time": 70556.81414270401, "episode/length": 220.0, "episode/score": 8.100000038743019, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 1555776, "time": 70579.52191019058, "episode/length": 209.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 1555992, "time": 70588.14712882042, "episode/length": 245.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 1556648, "time": 70614.07081460953, "episode/length": 193.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 1556696, "time": 70617.2739405632, "episode/length": 411.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 1556912, "time": 70626.43413352966, "episode/length": 373.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 1557224, "time": 70638.37177014351, "episode/length": 542.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9871086556169429, "episode/intrinsic_return": 0.0}
{"step": 1557952, "time": 70664.84659266472, "episode/length": 498.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9879759519038076, "episode/intrinsic_return": 0.0}
{"step": 1558232, "time": 70675.86113929749, "episode/length": 279.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 1558672, "time": 70692.67596650124, "episode/length": 219.0, "episode/score": 13.100000016391277, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 1558976, "time": 70704.6107699871, "episode/length": 37.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 1559368, "time": 70719.24314332008, "episode/length": 448.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9844097995545658, "episode/intrinsic_return": 0.0}
{"step": 1559424, "time": 70723.01471233368, "episode/length": 346.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9913544668587896, "episode/intrinsic_return": 0.0}
{"step": 1559840, "time": 70738.97879362106, "episode/length": 392.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9949109414758269, "episode/intrinsic_return": 0.0}
{"step": 1559888, "time": 70742.67912983894, "episode/length": 241.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 1560000, "time": 70767.74081516266, "eval_episode/length": 132.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9624060150375939}
{"step": 1560000, "time": 70771.75383377075, "eval_episode/length": 183.0, "eval_episode/score": 12.099999979138374, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 1560000, "time": 70773.50043725967, "eval_episode/length": 186.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.983957219251337}
{"step": 1560000, "time": 70776.52158689499, "eval_episode/length": 217.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 1560000, "time": 70778.46829366684, "eval_episode/length": 224.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 1560000, "time": 70781.1022002697, "eval_episode/length": 248.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9959839357429718}
{"step": 1560000, "time": 70783.79328083992, "eval_episode/length": 272.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 1560000, "time": 70790.04924058914, "eval_episode/length": 187.0, "eval_episode/score": 13.100000001490116, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 1560184, "time": 70796.13457012177, "episode/length": 627.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9888535031847133, "episode/intrinsic_return": 0.0}
{"step": 1560256, "time": 70800.29519152641, "episode/length": 252.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 1561416, "time": 70841.80017566681, "episode/length": 255.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 1561520, "time": 70847.15456700325, "episode/length": 157.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 1561736, "time": 70855.92101597786, "episode/length": 563.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.99822695035461, "episode/intrinsic_return": 0.0}
{"step": 1562048, "time": 70868.32557821274, "episode/length": 275.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 1562296, "time": 70878.16420292854, "episode/length": 358.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9832869080779945, "episode/intrinsic_return": 0.0}
{"step": 1562344, "time": 70881.46439218521, "episode/length": 269.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 1562800, "time": 70898.6828353405, "episode/length": 62.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 1562968, "time": 70905.67376947403, "episode/length": 180.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 1563280, "time": 70918.24698472023, "episode/length": 423.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9976415094339622, "episode/intrinsic_return": 0.0}
{"step": 1563352, "time": 70922.03140974045, "episode/length": 201.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 1563360, "time": 70924.0689637661, "episode/length": 242.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 1563704, "time": 70937.02000141144, "episode/length": 206.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 1563904, "time": 70945.54725050926, "episode/length": 615.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 1563928, "time": 70947.80238008499, "episode/length": 197.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 1564032, "time": 70953.0488269329, "episode/length": 132.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9548872180451128, "episode/intrinsic_return": 0.0}
{"step": 1565088, "time": 70992.22543692589, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 1565248, "time": 70999.45267558098, "episode/length": 164.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 1565376, "time": 71005.4324464798, "episode/length": 251.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 1565464, "time": 71009.808852911, "episode/length": 194.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 1565816, "time": 71023.20384812355, "episode/length": 222.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 1566216, "time": 71038.3494606018, "episode/length": 426.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 1566512, "time": 71050.13427519798, "episode/length": 394.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9974683544303797, "episode/intrinsic_return": 0.0}
{"step": 1567256, "time": 71076.77483868599, "episode/length": 179.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 1567296, "time": 71080.07745170593, "episode/length": 134.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1567456, "time": 71087.07235002518, "episode/length": 521.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 1567840, "time": 71101.72612452507, "episode/length": 323.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 1568152, "time": 71113.57884907722, "episode/length": 335.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 1568304, "time": 71120.62469696999, "episode/length": 365.0, "episode/score": 14.100000031292439, "episode/reward_rate": 0.9972677595628415, "episode/intrinsic_return": 0.0}
{"step": 1568496, "time": 71128.69328427315, "episode/length": 154.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 1568768, "time": 71139.56859374046, "episode/length": 281.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 1569008, "time": 71149.23101878166, "episode/length": 489.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 1569032, "time": 71151.40386772156, "episode/length": 216.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1569768, "time": 71177.99162602425, "episode/length": 288.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 1569872, "time": 71183.24041604996, "episode/length": 214.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 1569896, "time": 71185.39791727066, "episode/length": 174.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 1570088, "time": 71217.86773824692, "eval_episode/length": 235.0, "eval_episode/score": 13.100000001490116, "eval_episode/reward_rate": 0.9957627118644068}
{"step": 1570088, "time": 71220.37318658829, "eval_episode/length": 249.0, "eval_episode/score": 12.099999971687794, "eval_episode/reward_rate": 0.996}
{"step": 1570088, "time": 71224.4577600956, "eval_episode/length": 258.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9961389961389961}
{"step": 1570088, "time": 71226.18601965904, "eval_episode/length": 262.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9809885931558935}
{"step": 1570088, "time": 71230.59834933281, "eval_episode/length": 326.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9847094801223242}
{"step": 1570088, "time": 71233.21176147461, "eval_episode/length": 351.0, "eval_episode/score": 13.099999971687794, "eval_episode/reward_rate": 0.9971590909090909}
{"step": 1570088, "time": 71236.90526390076, "eval_episode/length": 161.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 1570088, "time": 71240.19700098038, "eval_episode/length": 172.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 1570176, "time": 71243.39650154114, "episode/length": 291.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.976027397260274, "episode/intrinsic_return": 0.0}
{"step": 1570504, "time": 71255.8506295681, "episode/length": 186.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 1570840, "time": 71268.9220392704, "episode/length": 258.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 1571072, "time": 71278.52480816841, "episode/length": 254.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 1571736, "time": 71302.48610854149, "episode/length": 194.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 1572000, "time": 71313.25584602356, "episode/length": 186.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 1572112, "time": 71318.68314433098, "episode/length": 279.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 1572160, "time": 71322.00767588615, "episode/length": 298.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.0}
{"step": 1572808, "time": 71345.37478542328, "episode/length": 216.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1573424, "time": 71370.11461997032, "episode/length": 639.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.996875, "episode/intrinsic_return": 0.0}
{"step": 1574016, "time": 71391.89570474625, "episode/length": 73.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 1574256, "time": 71401.6832792759, "episode/length": 426.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9929742388758782, "episode/intrinsic_return": 0.0}
{"step": 1574536, "time": 71412.5788128376, "episode/length": 579.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9982758620689656, "episode/intrinsic_return": 0.0}
{"step": 1574632, "time": 71417.61162519455, "episode/length": 227.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1575016, "time": 71432.1837940216, "episode/length": 376.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9734748010610079, "episode/intrinsic_return": 0.0}
{"step": 1575440, "time": 71448.3595058918, "episode/length": 409.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 1575465, "time": 71451.68026590347, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.903656646088287, "train/action_min": 0.0, "train/action_std": 3.747368500782893, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.02628507515272269, "train/actor_opt_grad_steps": 97660.0, "train/actor_opt_loss": -8.211016538259866, "train/adv_mag": 0.3760172590300753, "train/adv_max": 0.3426940171243428, "train/adv_mean": 0.0016171360292880556, "train/adv_min": -0.3064712353728034, "train/adv_std": 0.03978023249525707, "train/cont_avg": 0.9963259396853147, "train/cont_loss_mean": 0.000150525375714524, "train/cont_loss_std": 0.004622187899775037, "train/cont_neg_acc": 0.9963768115942029, "train/cont_neg_loss": 0.02093634876591157, "train/cont_pos_acc": 0.9999657173256774, "train/cont_pos_loss": 9.737892915445962e-05, "train/cont_pred": 0.9963103015939673, "train/cont_rate": 0.9963259396853147, "train/dyn_loss_mean": 13.08932750541847, "train/dyn_loss_std": 9.307287596322439, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9489630552438589, "train/extr_critic_critic_opt_grad_steps": 97660.0, "train/extr_critic_critic_opt_loss": 14785.509704163025, "train/extr_critic_mag": 10.671657655622576, "train/extr_critic_max": 10.671657655622576, "train/extr_critic_mean": 2.4053523002804575, "train/extr_critic_min": -0.18149253371712212, "train/extr_critic_std": 2.518641461025585, "train/extr_return_normed_mag": 1.4693399617721985, "train/extr_return_normed_max": 1.4693399617721985, "train/extr_return_normed_mean": 0.30617824353121376, "train/extr_return_normed_min": -0.05434483823112466, "train/extr_return_normed_std": 0.3185883652080189, "train/extr_return_rate": 0.732577613808892, "train/extr_return_raw_mag": 11.697644440444199, "train/extr_return_raw_max": 11.697644440444199, "train/extr_return_raw_mean": 2.418257546591592, "train/extr_return_raw_min": -0.4590813542579438, "train/extr_return_raw_std": 2.542338682221366, "train/extr_reward_mag": 1.05371420533507, "train/extr_reward_max": 1.05371420533507, "train/extr_reward_mean": 0.043952911011093145, "train/extr_reward_min": -0.4234038733102225, "train/extr_reward_std": 0.19589623225318803, "train/image_loss_mean": 6.37961468663249, "train/image_loss_std": 12.094106680863387, "train/model_loss_mean": 14.298159752692376, "train/model_loss_std": 15.874460507106114, "train/model_opt_grad_norm": 46.295141673588255, "train/model_opt_grad_steps": 97573.14685314686, "train/model_opt_loss": 15541.402989100743, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1088.2867132867134, "train/policy_entropy_mag": 2.6686892009281613, "train/policy_entropy_max": 2.6686892009281613, "train/policy_entropy_mean": 0.8573161178118699, "train/policy_entropy_min": 0.0793750211596489, "train/policy_entropy_std": 0.9236855056736019, "train/policy_logprob_mag": 7.438383876026927, "train/policy_logprob_max": -0.009455658391222253, "train/policy_logprob_mean": -0.8567032186718254, "train/policy_logprob_min": -7.438383876026927, "train/policy_logprob_std": 1.2683875160617428, "train/policy_randomness_mag": 0.9419301785789169, "train/policy_randomness_max": 0.9419301785789169, "train/policy_randomness_mean": 0.3025949667175333, "train/policy_randomness_min": 0.028015899204916053, "train/policy_randomness_std": 0.3260204455444029, "train/post_ent_mag": 61.486195170796, "train/post_ent_max": 61.486195170796, "train/post_ent_mean": 43.711935190054085, "train/post_ent_min": 20.267621700580303, "train/post_ent_std": 7.773851648077264, "train/prior_ent_mag": 71.15026946167846, "train/prior_ent_max": 71.15026946167846, "train/prior_ent_mean": 56.89172157874474, "train/prior_ent_min": 40.635720739831456, "train/prior_ent_std": 4.839162803196407, "train/rep_loss_mean": 13.08932750541847, "train/rep_loss_std": 9.307287596322439, "train/reward_avg": 0.0408264584839344, "train/reward_loss_mean": 0.06479815328558841, "train/reward_loss_std": 0.2620073713205911, "train/reward_max_data": 1.030769238105187, "train/reward_max_pred": 1.0249349854209207, "train/reward_neg_acc": 0.9909466667608782, "train/reward_neg_loss": 0.03103592746949696, "train/reward_pos_acc": 0.978862432749955, "train/reward_pos_loss": 0.7952419477742869, "train/reward_pred": 0.04009131067334772, "train/reward_rate": 0.04436188811188811, "train_stats/sum_log_reward": 11.530379965335507, "train_stats/max_log_achievement_collect_coal": 1.0886075949367089, "train_stats/max_log_achievement_collect_drink": 6.30379746835443, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 2.0632911392405062, "train_stats/max_log_achievement_collect_stone": 15.215189873417721, "train_stats/max_log_achievement_collect_wood": 10.632911392405063, "train_stats/max_log_achievement_defeat_skeleton": 0.08860759493670886, "train_stats/max_log_achievement_defeat_zombie": 1.5316455696202531, "train_stats/max_log_achievement_eat_cow": 0.5949367088607594, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.06329113924050633, "train_stats/max_log_achievement_make_stone_sword": 0.08860759493670886, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5822784810126582, "train_stats/max_log_achievement_make_wood_sword": 1.2784810126582278, "train_stats/max_log_achievement_place_furnace": 2.367088607594937, "train_stats/max_log_achievement_place_plant": 1.7974683544303798, "train_stats/max_log_achievement_place_stone": 4.1645569620253164, "train_stats/max_log_achievement_place_table": 3.151898734177215, "train_stats/max_log_achievement_wake_up": 2.088607594936709, "train_stats/mean_log_entropy": 0.7653338931783845, "eval_stats/sum_log_reward": 11.47500029206276, "eval_stats/max_log_achievement_collect_coal": 0.875, "eval_stats/max_log_achievement_collect_drink": 5.9375, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.5625, "eval_stats/max_log_achievement_collect_stone": 14.5, "eval_stats/max_log_achievement_collect_wood": 10.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 1.5, "eval_stats/max_log_achievement_eat_cow": 0.4375, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.125, "eval_stats/max_log_achievement_make_stone_sword": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 1.5, "eval_stats/max_log_achievement_place_furnace": 2.25, "eval_stats/max_log_achievement_place_plant": 1.3125, "eval_stats/max_log_achievement_place_stone": 3.5625, "eval_stats/max_log_achievement_place_table": 2.9375, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 4.015756985609187e-06, "report/cont_loss_std": 0.00010001339251175523, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00037808899651281536, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.283715614088578e-06, "report/cont_pred": 0.9980443716049194, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 12.808687210083008, "report/dyn_loss_std": 8.976305961608887, "report/image_loss_mean": 5.646468162536621, "report/image_loss_std": 13.127037048339844, "report/model_loss_mean": 13.397008895874023, "report/model_loss_std": 16.41373634338379, "report/post_ent_mag": 58.20866394042969, "report/post_ent_max": 58.20866394042969, "report/post_ent_mean": 43.24292755126953, "report/post_ent_min": 18.607933044433594, "report/post_ent_std": 7.840339660644531, "report/prior_ent_mag": 70.95951843261719, "report/prior_ent_max": 70.95951843261719, "report/prior_ent_mean": 56.62837219238281, "report/prior_ent_min": 43.09959411621094, "report/prior_ent_std": 4.261420726776123, "report/rep_loss_mean": 12.808687210083008, "report/rep_loss_std": 8.976305961608887, "report/reward_avg": 0.04902343451976776, "report/reward_loss_mean": 0.06532467901706696, "report/reward_loss_std": 0.2525540292263031, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0995478630065918, "report/reward_neg_acc": 0.9897119998931885, "report/reward_neg_loss": 0.026569435372948647, "report/reward_pos_acc": 0.9807692766189575, "report/reward_pos_loss": 0.7897496819496155, "report/reward_pred": 0.04764924943447113, "report/reward_rate": 0.05078125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.686608243289811e-06, "eval/cont_loss_std": 3.431540244491771e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0005039740353822708, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.1073931577575422e-07, "eval/cont_pred": 0.9970716238021851, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.409624099731445, "eval/dyn_loss_std": 11.069709777832031, "eval/image_loss_mean": 11.598514556884766, "eval/image_loss_std": 21.247814178466797, "eval/model_loss_mean": 22.15252685546875, "eval/model_loss_std": 25.447418212890625, "eval/post_ent_mag": 58.4318733215332, "eval/post_ent_max": 58.4318733215332, "eval/post_ent_mean": 42.02561950683594, "eval/post_ent_min": 20.685684204101562, "eval/post_ent_std": 7.6975860595703125, "eval/prior_ent_mag": 70.95951843261719, "eval/prior_ent_max": 70.95951843261719, "eval/prior_ent_mean": 57.33204650878906, "eval/prior_ent_min": 45.60608673095703, "eval/prior_ent_std": 4.5896148681640625, "eval/rep_loss_mean": 17.409624099731445, "eval/rep_loss_std": 11.069709777832031, "eval/reward_avg": 0.0537109375, "eval/reward_loss_mean": 0.10823525488376617, "eval/reward_loss_std": 0.5186505913734436, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023212432861328, "eval/reward_neg_acc": 0.9844880700111389, "eval/reward_neg_loss": 0.05636616051197052, "eval/reward_pos_acc": 0.9473684430122375, "eval/reward_pos_loss": 0.9881898760795593, "eval/reward_pred": 0.054022789001464844, "eval/reward_rate": 0.0556640625, "replay/size": 1000000.0, "replay/inserts": 22872.0, "replay/samples": 22880.0, "replay/insert_wait_avg": 1.4006153358867762e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.16271021649554e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6464.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2653815274191375e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.4603137969970703e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2352299690247, "timer/env.step_count": 2859.0, "timer/env.step_total": 209.7978675365448, "timer/env.step_frac": 0.20974852839670707, "timer/env.step_avg": 0.07338155562663337, "timer/env.step_min": 0.02428150177001953, "timer/env.step_max": 2.3233652114868164, "timer/replay._sample_count": 22880.0, "timer/replay._sample_total": 11.86763620376587, "timer/replay._sample_frac": 0.011864845236588385, "timer/replay._sample_avg": 0.0005186903935212355, "timer/replay._sample_min": 0.0004031658172607422, "timer/replay._sample_max": 0.025801897048950195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3667.0, "timer/agent.policy_total": 63.70979380607605, "timer/agent.policy_frac": 0.06369481087768626, "timer/agent.policy_avg": 0.01737381887266868, "timer/agent.policy_min": 0.010014533996582031, "timer/agent.policy_max": 0.10638165473937988, "timer/dataset_train_count": 1430.0, "timer/dataset_train_total": 0.16148853302001953, "timer/dataset_train_frac": 0.0001614505550109653, "timer/dataset_train_avg": 0.00011292904406994373, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.00044155120849609375, "timer/agent.train_count": 1430.0, "timer/agent.train_total": 646.4352474212646, "timer/agent.train_frac": 0.6462832222389162, "timer/agent.train_avg": 0.45205262057431095, "timer/agent.train_min": 0.4382908344268799, "timer/agent.train_max": 1.8073549270629883, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4808228015899658, "timer/agent.report_frac": 0.0004807097242564191, "timer/agent.report_avg": 0.2404114007949829, "timer/agent.report_min": 0.23117971420288086, "timer/agent.report_max": 0.24964308738708496, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.000110626220703125, "timer/dataset_eval_frac": 1.106002042205121e-07, "timer/dataset_eval_avg": 0.000110626220703125, "timer/dataset_eval_min": 0.000110626220703125, "timer/dataset_eval_max": 0.000110626220703125, "fps": 22.866275433431877}
{"step": 1575968, "time": 71468.74783658981, "episode/length": 166.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 1576040, "time": 71472.60763144493, "episode/length": 252.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 1576256, "time": 71481.83250617981, "episode/length": 517.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9826254826254827, "episode/intrinsic_return": 0.0}
{"step": 1576344, "time": 71486.1140139103, "episode/length": 225.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 1576824, "time": 71503.89860653877, "episode/length": 635.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 1577368, "time": 71523.96146249771, "episode/length": 388.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9922879177377892, "episode/intrinsic_return": 0.0}
{"step": 1577680, "time": 71536.45784258842, "episode/length": 177.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 1577696, "time": 71538.63293409348, "episode/length": 168.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 1577800, "time": 71543.63880753517, "episode/length": 219.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1577936, "time": 71550.09640264511, "episode/length": 138.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 1578376, "time": 71566.42012429237, "episode/length": 419.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 1579072, "time": 71591.70965528488, "episode/length": 173.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 1579208, "time": 71597.8893198967, "episode/length": 470.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9830148619957537, "episode/intrinsic_return": 0.0}
{"step": 1579432, "time": 71607.1860806942, "episode/length": 44.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 1579760, "time": 71620.19433283806, "episode/length": 257.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 1580072, "time": 71654.48084449768, "eval_episode/length": 201.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.995049504950495}
{"step": 1580072, "time": 71660.2313542366, "eval_episode/length": 284.0, "eval_episode/score": 12.099999994039536, "eval_episode/reward_rate": 0.9964912280701754}
{"step": 1580072, "time": 71663.10106015205, "eval_episode/length": 301.0, "eval_episode/score": 13.100000008940697, "eval_episode/reward_rate": 0.9966887417218543}
{"step": 1580072, "time": 71664.91882658005, "eval_episode/length": 304.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9967213114754099}
{"step": 1580072, "time": 71668.23136377335, "eval_episode/length": 339.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9882352941176471}
{"step": 1580072, "time": 71670.30577087402, "eval_episode/length": 346.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9913544668587896}
{"step": 1580072, "time": 71672.76083993912, "eval_episode/length": 163.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 1580072, "time": 71675.2972137928, "eval_episode/length": 45.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8913043478260869}
{"step": 1580200, "time": 71679.67917370796, "episode/length": 227.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1580248, "time": 71682.93150734901, "episode/length": 534.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9850467289719627, "episode/intrinsic_return": 0.0}
{"step": 1580352, "time": 71688.35441994667, "episode/length": 318.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.987460815047022, "episode/intrinsic_return": 0.0}
{"step": 1580984, "time": 71711.24935007095, "episode/length": 221.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 1581440, "time": 71730.48373103142, "episode/length": 209.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 1581448, "time": 71732.20364809036, "episode/length": 438.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9863325740318907, "episode/intrinsic_return": 0.0}
{"step": 1582016, "time": 71753.28172326088, "episode/length": 207.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 1582024, "time": 71754.97598290443, "episode/length": 581.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 1582128, "time": 71760.27456092834, "episode/length": 240.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 1582432, "time": 71772.07076931, "episode/length": 180.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 1582688, "time": 71782.41742992401, "episode/length": 304.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.980327868852459, "episode/intrinsic_return": 0.0}
{"step": 1583040, "time": 71795.90766954422, "episode/length": 450.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9800443458980045, "episode/intrinsic_return": 0.0}
{"step": 1583216, "time": 71803.53964304924, "episode/length": 220.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 1584184, "time": 71837.86418700218, "episode/length": 342.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9970845481049563, "episode/intrinsic_return": 0.0}
{"step": 1584224, "time": 71841.05154323578, "episode/length": 223.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1584808, "time": 71862.07827305794, "episode/length": 348.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9856733524355301, "episode/intrinsic_return": 0.0}
{"step": 1584960, "time": 71869.13590812683, "episode/length": 217.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 1585040, "time": 71873.40824866295, "episode/length": 249.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.968, "episode/intrinsic_return": 0.0}
{"step": 1585144, "time": 71878.33872389793, "episode/length": 376.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.986737400530504, "episode/intrinsic_return": 0.0}
{"step": 1585848, "time": 71903.8453195095, "episode/length": 477.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.997907949790795, "episode/intrinsic_return": 0.0}
{"step": 1585976, "time": 71909.7296257019, "episode/length": 218.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 1586208, "time": 71919.41349673271, "episode/length": 174.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 1586456, "time": 71929.78977322578, "episode/length": 283.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 1586952, "time": 71948.26064562798, "episode/length": 238.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 1587856, "time": 71981.03443694115, "episode/length": 234.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 1587872, "time": 71983.53351259232, "episode/length": 647.0, "episode/score": 14.100000008940697, "episode/reward_rate": 0.9984567901234568, "episode/intrinsic_return": 0.0}
{"step": 1587992, "time": 71989.22420334816, "episode/length": 222.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 1588104, "time": 71994.56668782234, "episode/length": 205.0, "episode/score": 13.099999964237213, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 1588224, "time": 72000.54868340492, "episode/length": 407.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 1588712, "time": 72018.46034097672, "episode/length": 60.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 1589336, "time": 72042.99968934059, "episode/length": 523.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 1589400, "time": 72046.7688100338, "episode/length": 443.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 1589872, "time": 72064.60086321831, "episode/length": 251.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 1590056, "time": 72094.91550946236, "eval_episode/length": 203.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 1590056, "time": 72097.44747281075, "eval_episode/length": 223.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 1590056, "time": 72099.82944464684, "eval_episode/length": 241.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9752066115702479}
{"step": 1590056, "time": 72102.26150274277, "eval_episode/length": 262.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.973384030418251}
{"step": 1590056, "time": 72105.39591813087, "eval_episode/length": 295.0, "eval_episode/score": 11.100000031292439, "eval_episode/reward_rate": 0.9966216216216216}
{"step": 1590056, "time": 72110.25911164284, "eval_episode/length": 365.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9890710382513661}
{"step": 1590056, "time": 72119.28885316849, "eval_episode/length": 256.0, "eval_episode/score": 12.099999994039536, "eval_episode/reward_rate": 0.9961089494163424}
{"step": 1590056, "time": 72119.29552316666, "eval_episode/length": 114.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9478260869565217}
{"step": 1590192, "time": 72124.13101291656, "episode/length": 274.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 1590240, "time": 72127.41723632812, "episode/length": 410.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9975669099756691, "episode/intrinsic_return": 0.0}
{"step": 1590536, "time": 72138.88286542892, "episode/length": 227.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1591184, "time": 72162.49850845337, "episode/length": 384.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9922077922077922, "episode/intrinsic_return": 0.0}
{"step": 1591600, "time": 72178.38217902184, "episode/length": 274.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9745454545454545, "episode/intrinsic_return": 0.0}
{"step": 1591888, "time": 72189.62392091751, "episode/length": 205.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 1592184, "time": 72201.11026191711, "episode/length": 288.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.986159169550173, "episode/intrinsic_return": 0.0}
{"step": 1592208, "time": 72203.75704193115, "episode/length": 541.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.988929889298893, "episode/intrinsic_return": 0.0}
{"step": 1592296, "time": 72208.26098680496, "episode/length": 219.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 1592496, "time": 72216.90890574455, "episode/length": 394.0, "episode/score": 14.100000023841858, "episode/reward_rate": 0.9974683544303797, "episode/intrinsic_return": 0.0}
{"step": 1592568, "time": 72220.64305090904, "episode/length": 296.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 1592912, "time": 72234.20975279808, "episode/length": 76.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.948051948051948, "episode/intrinsic_return": 0.0}
{"step": 1592920, "time": 72235.87132525444, "episode/length": 216.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1593368, "time": 72252.83023452759, "episode/length": 147.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 1593712, "time": 72266.5013062954, "episode/length": 263.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9734848484848485, "episode/intrinsic_return": 0.0}
{"step": 1594288, "time": 72287.82462716103, "episode/length": 259.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9730769230769231, "episode/intrinsic_return": 0.0}
{"step": 1594320, "time": 72290.56800961494, "episode/length": 227.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1594384, "time": 72294.51640057564, "episode/length": 311.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9967948717948718, "episode/intrinsic_return": 0.0}
{"step": 1594960, "time": 72315.46283960342, "episode/length": 79.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 1595168, "time": 72324.2048304081, "episode/length": 224.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1595392, "time": 72333.54338431358, "episode/length": 209.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 1595576, "time": 72341.1207845211, "episode/length": 332.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996996996996997, "episode/intrinsic_return": 0.0}
{"step": 1595752, "time": 72348.70929551125, "episode/length": 397.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9974874371859297, "episode/intrinsic_return": 0.0}
{"step": 1596000, "time": 72358.91918969154, "episode/length": 213.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 1597136, "time": 72399.14145970345, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 1597176, "time": 72401.8180987835, "episode/length": 222.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 1597184, "time": 72403.95888543129, "episode/length": 251.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 1597296, "time": 72409.53672933578, "episode/length": 291.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9828767123287672, "episode/intrinsic_return": 0.0}
{"step": 1597552, "time": 72421.76306462288, "episode/length": 578.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9879101899827288, "episode/intrinsic_return": 0.0}
{"step": 1597984, "time": 72438.06541085243, "episode/length": 247.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 1598329, "time": 72452.17142438889, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.745927407707967, "train/action_min": 0.0, "train/action_std": 3.554960014114917, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.02619700082643351, "train/actor_opt_grad_steps": 99085.0, "train/actor_opt_loss": -7.627813516630673, "train/adv_mag": 0.39378268040821585, "train/adv_max": 0.3473892539319858, "train/adv_mean": 0.0015621162974479325, "train/adv_min": -0.3169414297166005, "train/adv_std": 0.03918059911369018, "train/cont_avg": 0.9958599251760564, "train/cont_loss_mean": 0.00012744955416236012, "train/cont_loss_std": 0.003819269919913367, "train/cont_neg_acc": 0.9950354619229094, "train/cont_neg_loss": 0.01810142206073927, "train/cont_pos_acc": 0.9999861629076408, "train/cont_pos_loss": 4.547333003186813e-05, "train/cont_pred": 0.9958697557449341, "train/cont_rate": 0.9958599251760564, "train/dyn_loss_mean": 12.790731953902982, "train/dyn_loss_std": 9.245725692158015, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9165807097730502, "train/extr_critic_critic_opt_grad_steps": 99085.0, "train/extr_critic_critic_opt_loss": 14815.817609760123, "train/extr_critic_mag": 10.65919467764841, "train/extr_critic_max": 10.65919467764841, "train/extr_critic_mean": 2.3594617314741644, "train/extr_critic_min": -0.19485258216589268, "train/extr_critic_std": 2.5563773638765577, "train/extr_return_normed_mag": 1.4755721184569346, "train/extr_return_normed_max": 1.4755721184569346, "train/extr_return_normed_mean": 0.30245052152116536, "train/extr_return_normed_min": -0.06117244172369091, "train/extr_return_normed_std": 0.32556228003871274, "train/extr_return_rate": 0.721499083537451, "train/extr_return_raw_mag": 11.65982805171483, "train/extr_return_raw_max": 11.65982805171483, "train/extr_return_raw_mean": 2.3718361678257796, "train/extr_return_raw_min": -0.5086448727778985, "train/extr_return_raw_std": 2.5781812172540475, "train/extr_reward_mag": 1.052707210393019, "train/extr_reward_max": 1.052707210393019, "train/extr_reward_mean": 0.04192642498971291, "train/extr_reward_min": -0.46460039682791265, "train/extr_reward_std": 0.19221517060634116, "train/image_loss_mean": 6.274479496646935, "train/image_loss_std": 11.864035549298139, "train/model_loss_mean": 14.010665248817121, "train/model_loss_std": 15.577085333810725, "train/model_opt_grad_norm": 42.170249979260944, "train/model_opt_grad_steps": 98997.0, "train/model_opt_loss": 14155.884714045995, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1007.9225352112676, "train/policy_entropy_mag": 2.6733423689721336, "train/policy_entropy_max": 2.6733423689721336, "train/policy_entropy_mean": 0.8645289557080873, "train/policy_entropy_min": 0.07937501969052033, "train/policy_entropy_std": 0.9201554483930829, "train/policy_logprob_mag": 7.438383851252811, "train/policy_logprob_max": -0.009455658397047033, "train/policy_logprob_mean": -0.8660168727518807, "train/policy_logprob_min": -7.438383851252811, "train/policy_logprob_std": 1.2749816674581715, "train/policy_randomness_mag": 0.9435725400985127, "train/policy_randomness_max": 0.9435725400985127, "train/policy_randomness_mean": 0.30514078524330973, "train/policy_randomness_min": 0.028015898711139887, "train/policy_randomness_std": 0.3247744923746082, "train/post_ent_mag": 61.73208733679543, "train/post_ent_max": 61.73208733679543, "train/post_ent_mean": 44.18214591120331, "train/post_ent_min": 20.22676700269672, "train/post_ent_std": 7.833653409716109, "train/prior_ent_mag": 71.04501305163747, "train/prior_ent_max": 71.04501305163747, "train/prior_ent_mean": 57.06854202377964, "train/prior_ent_min": 40.65784180332238, "train/prior_ent_std": 4.846994077655631, "train/rep_loss_mean": 12.790731953902982, "train/rep_loss_std": 9.245725692158015, "train/reward_avg": 0.039191103173078785, "train/reward_loss_mean": 0.061619065597023764, "train/reward_loss_std": 0.24401762200073457, "train/reward_max_data": 1.0260563442404842, "train/reward_max_pred": 1.0228748279558102, "train/reward_neg_acc": 0.9916913261715795, "train/reward_neg_loss": 0.02929652125482828, "train/reward_pos_acc": 0.9813065277019017, "train/reward_pos_loss": 0.780724050713257, "train/reward_pred": 0.03858377942553078, "train/reward_rate": 0.043065030809859156, "train_stats/sum_log_reward": 11.317948876283108, "train_stats/max_log_achievement_collect_coal": 1.2179487179487178, "train_stats/max_log_achievement_collect_drink": 8.307692307692308, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.8846153846153846, "train_stats/max_log_achievement_collect_stone": 16.205128205128204, "train_stats/max_log_achievement_collect_wood": 9.756410256410257, "train_stats/max_log_achievement_defeat_skeleton": 0.08974358974358974, "train_stats/max_log_achievement_defeat_zombie": 1.5, "train_stats/max_log_achievement_eat_cow": 0.48717948717948717, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.02564102564102564, "train_stats/max_log_achievement_make_stone_sword": 0.038461538461538464, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4871794871794872, "train_stats/max_log_achievement_make_wood_sword": 1.1923076923076923, "train_stats/max_log_achievement_place_furnace": 2.5384615384615383, "train_stats/max_log_achievement_place_plant": 1.6923076923076923, "train_stats/max_log_achievement_place_stone": 4.089743589743589, "train_stats/max_log_achievement_place_table": 2.871794871794872, "train_stats/max_log_achievement_wake_up": 2.0384615384615383, "train_stats/mean_log_entropy": 0.7463097132933445, "eval_stats/sum_log_reward": 10.475000157952309, "eval_stats/max_log_achievement_collect_coal": 1.0, "eval_stats/max_log_achievement_collect_drink": 5.25, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 14.0, "eval_stats/max_log_achievement_collect_wood": 11.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.8125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.125, "eval_stats/max_log_achievement_make_stone_sword": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 1.0, "eval_stats/max_log_achievement_place_furnace": 2.3125, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 3.4375, "eval_stats/max_log_achievement_place_table": 3.3125, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.2422747103264555e-05, "report/cont_loss_std": 0.0011134909000247717, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.010718530975282192, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.659727512849713e-08, "report/cont_pred": 0.9951688051223755, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.335068702697754, "report/dyn_loss_std": 8.307060241699219, "report/image_loss_mean": 6.193079471588135, "report/image_loss_std": 10.094118118286133, "report/model_loss_mean": 13.652785301208496, "report/model_loss_std": 13.30835247039795, "report/post_ent_mag": 62.376251220703125, "report/post_ent_max": 62.376251220703125, "report/post_ent_mean": 44.79350662231445, "report/post_ent_min": 20.493831634521484, "report/post_ent_std": 7.86936092376709, "report/prior_ent_mag": 71.03898620605469, "report/prior_ent_max": 71.03898620605469, "report/prior_ent_mean": 57.509033203125, "report/prior_ent_min": 42.33807373046875, "report/prior_ent_std": 4.6887102127075195, "report/rep_loss_mean": 12.335068702697754, "report/rep_loss_std": 8.307060241699219, "report/reward_avg": 0.04208984225988388, "report/reward_loss_mean": 0.05861186981201172, "report/reward_loss_std": 0.23535674810409546, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.013288974761963, "report/reward_neg_acc": 0.9938524961471558, "report/reward_neg_loss": 0.023623112589120865, "report/reward_pos_acc": 0.9791666865348816, "report/reward_pos_loss": 0.7700499296188354, "report/reward_pred": 0.04107218608260155, "report/reward_rate": 0.046875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.00016454927390441298, "eval/cont_loss_std": 0.005110433790832758, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.08324892073869705, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.95754205378762e-06, "eval/cont_pred": 0.9981951713562012, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 16.761499404907227, "eval/dyn_loss_std": 11.057029724121094, "eval/image_loss_mean": 9.308411598205566, "eval/image_loss_std": 12.037034034729004, "eval/model_loss_mean": 19.515579223632812, "eval/model_loss_std": 16.404598236083984, "eval/post_ent_mag": 61.17567443847656, "eval/post_ent_max": 61.17567443847656, "eval/post_ent_mean": 43.814598083496094, "eval/post_ent_min": 20.3050479888916, "eval/post_ent_std": 8.09173583984375, "eval/prior_ent_mag": 71.03898620605469, "eval/prior_ent_max": 71.03898620605469, "eval/prior_ent_mean": 57.940673828125, "eval/prior_ent_min": 45.99757385253906, "eval/prior_ent_std": 4.443554878234863, "eval/rep_loss_mean": 16.761499404907227, "eval/rep_loss_std": 11.057029724121094, "eval/reward_avg": 0.05449219048023224, "eval/reward_loss_mean": 0.1501062512397766, "eval/reward_loss_std": 0.82426917552948, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.089627981185913, "eval/reward_neg_acc": 0.9844560027122498, "eval/reward_neg_loss": 0.06902725994586945, "eval/reward_pos_acc": 0.8644067645072937, "eval/reward_pos_loss": 1.4762285947799683, "eval/reward_pred": 0.049370020627975464, "eval/reward_rate": 0.0576171875, "replay/size": 1000000.0, "replay/inserts": 22864.0, "replay/samples": 22864.0, "replay/insert_wait_avg": 1.358570879034599e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.168526676837342e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2794374182150026e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4417271614075, "timer/env.step_count": 2858.0, "timer/env.step_total": 208.1372618675232, "timer/env.step_frac": 0.2080453625800667, "timer/env.step_avg": 0.07282619379549447, "timer/env.step_min": 0.024843931198120117, "timer/env.step_max": 2.1062631607055664, "timer/replay._sample_count": 22864.0, "timer/replay._sample_total": 11.885418891906738, "timer/replay._sample_frac": 0.011880171097650738, "timer/replay._sample_avg": 0.000519831127182765, "timer/replay._sample_min": 0.00042700767517089844, "timer/replay._sample_max": 0.00898289680480957, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3725.0, "timer/agent.policy_total": 66.21343755722046, "timer/agent.policy_frac": 0.06618420219745376, "timer/agent.policy_avg": 0.017775419478448445, "timer/agent.policy_min": 0.010022640228271484, "timer/agent.policy_max": 0.189100980758667, "timer/dataset_train_count": 1429.0, "timer/dataset_train_total": 0.17051219940185547, "timer/dataset_train_frac": 0.0001704369127881705, "timer/dataset_train_avg": 0.00011932274275847129, "timer/dataset_train_min": 9.870529174804688e-05, "timer/dataset_train_max": 0.010404825210571289, "timer/agent.train_count": 1429.0, "timer/agent.train_total": 646.542781829834, "timer/agent.train_frac": 0.6462573124216792, "timer/agent.train_avg": 0.4524442140166788, "timer/agent.train_min": 0.4381103515625, "timer/agent.train_max": 1.9810712337493896, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4775817394256592, "timer/agent.report_frac": 0.0004773708717455444, "timer/agent.report_avg": 0.2387908697128296, "timer/agent.report_min": 0.23249125480651855, "timer/agent.report_max": 0.24509048461914062, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9074223776051905e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 22.85359369417192}
{"step": 1598496, "time": 72457.9033305645, "episode/length": 342.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9825072886297376, "episode/intrinsic_return": 0.0}
{"step": 1598704, "time": 72466.69715213776, "episode/length": 189.0, "episode/score": 10.100000038743019, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 1598984, "time": 72477.6621863842, "episode/length": 225.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 1599128, "time": 72484.13608837128, "episode/length": 248.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 1599464, "time": 72497.21439194679, "episode/length": 94.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 1600040, "time": 72540.84197807312, "eval_episode/length": 207.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 1600040, "time": 72543.01049280167, "eval_episode/length": 218.0, "eval_episode/score": 12.099999971687794, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 1600040, "time": 72544.80380797386, "eval_episode/length": 222.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 1600040, "time": 72547.23070240021, "eval_episode/length": 237.0, "eval_episode/score": 12.099999994039536, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 1600040, "time": 72551.04374361038, "eval_episode/length": 285.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9825174825174825}
{"step": 1600040, "time": 72554.76245808601, "eval_episode/length": 328.0, "eval_episode/score": 12.100000023841858, "eval_episode/reward_rate": 0.9969604863221885}
{"step": 1600040, "time": 72557.51557016373, "eval_episode/length": 143.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9652777777777778}
{"step": 1600040, "time": 72561.78178095818, "eval_episode/length": 192.0, "eval_episode/score": 8.100000031292439, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 1600216, "time": 72567.76429319382, "episode/length": 214.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 1600480, "time": 72578.46668362617, "episode/length": 365.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 1601032, "time": 72598.73489356041, "episode/length": 466.0, "episode/score": 15.100000008940697, "episode/reward_rate": 0.9892933618843683, "episode/intrinsic_return": 0.0}
{"step": 1601328, "time": 72610.56930398941, "episode/length": 232.0, "episode/score": 13.100000016391277, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 1601440, "time": 72616.03562259674, "episode/length": 431.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 1601592, "time": 72622.64965486526, "episode/length": 325.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9846625766871165, "episode/intrinsic_return": 0.0}
{"step": 1601984, "time": 72637.7867512703, "episode/length": 356.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9971988795518207, "episode/intrinsic_return": 0.0}
{"step": 1602400, "time": 72653.72241973877, "episode/length": 272.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 1602536, "time": 72659.662951231, "episode/length": 256.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9883268482490273, "episode/intrinsic_return": 0.0}
{"step": 1602760, "time": 72668.8946788311, "episode/length": 215.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 1602808, "time": 72672.11436748505, "episode/length": 170.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 1603224, "time": 72688.30048155785, "episode/length": 57.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 1603568, "time": 72701.87440657616, "episode/length": 197.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 1603800, "time": 72711.37106895447, "episode/length": 1176.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 1603824, "time": 72714.07939958572, "episode/length": 311.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 1604144, "time": 72726.63039588928, "episode/length": 200.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 1604416, "time": 72737.62248110771, "episode/length": 352.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9886685552407932, "episode/intrinsic_return": 0.0}
{"step": 1604864, "time": 72754.52010536194, "episode/length": 256.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9688715953307393, "episode/intrinsic_return": 0.0}
{"step": 1605232, "time": 72768.65112042427, "episode/length": 207.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 1605304, "time": 72772.44417142868, "episode/length": 184.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 1605424, "time": 72778.3635776043, "episode/length": 125.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 1605664, "time": 72790.64571237564, "episode/length": 189.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 1606560, "time": 72822.8555431366, "episode/length": 416.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.988009592326139, "episode/intrinsic_return": 0.0}
{"step": 1606576, "time": 72825.00125670433, "episode/length": 213.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 1606600, "time": 72827.45057439804, "episode/length": 524.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9885714285714285, "episode/intrinsic_return": 0.0}
{"step": 1606760, "time": 72834.45485019684, "episode/length": 181.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 1606872, "time": 72839.81343364716, "episode/length": 204.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 1606904, "time": 72842.99628424644, "episode/length": 387.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 1607032, "time": 72849.2801296711, "episode/length": 58.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9491525423728814, "episode/intrinsic_return": 0.0}
{"step": 1607328, "time": 72861.28759050369, "episode/length": 207.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 1607384, "time": 72864.66607904434, "episode/length": 244.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 1608240, "time": 72895.56297135353, "episode/length": 113.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 1608328, "time": 72900.0642311573, "episode/length": 215.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 1608392, "time": 72903.79783439636, "episode/length": 226.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 1608576, "time": 72912.00163912773, "episode/length": 208.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 1608808, "time": 72921.43400788307, "episode/length": 221.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 1608952, "time": 72927.97226047516, "episode/length": 259.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 1609280, "time": 72940.87815523148, "episode/length": 58.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 1609992, "time": 72966.53245401382, "episode/length": 325.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9969325153374233, "episode/intrinsic_return": 0.0}
{"step": 1610024, "time": 72989.88108348846, "eval_episode/length": 154.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 1610024, "time": 72991.9735982418, "eval_episode/length": 164.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9636363636363636}
{"step": 1610024, "time": 72994.53420829773, "eval_episode/length": 182.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 1610024, "time": 72997.60122537613, "eval_episode/length": 213.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 1610024, "time": 73000.02109122276, "eval_episode/length": 231.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.978448275862069}
{"step": 1610024, "time": 73002.14750409126, "eval_episode/length": 244.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9755102040816327}
{"step": 1610024, "time": 73004.20080566406, "eval_episode/length": 256.0, "eval_episode/score": 12.099999979138374, "eval_episode/reward_rate": 0.9961089494163424}
{"step": 1610024, "time": 73008.79821062088, "eval_episode/length": 321.0, "eval_episode/score": 14.099999986588955, "eval_episode/reward_rate": 0.9875776397515528}
{"step": 1610032, "time": 73009.33393526077, "episode/length": 212.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 1610136, "time": 73014.2812256813, "episode/length": 194.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 1610312, "time": 73021.91174268723, "episode/length": 169.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 1610328, "time": 73024.0880074501, "episode/length": 445.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9977578475336323, "episode/intrinsic_return": 0.0}
{"step": 1610568, "time": 73033.86925315857, "episode/length": 160.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 1610688, "time": 73039.88680171967, "episode/length": 305.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 1611112, "time": 73055.54986476898, "episode/length": 339.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 1611552, "time": 73072.44634437561, "episode/length": 154.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 1611560, "time": 73074.06449151039, "episode/length": 190.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 1611976, "time": 73089.88531327248, "episode/length": 229.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9652173913043478, "episode/intrinsic_return": 0.0}
{"step": 1612208, "time": 73099.72077226639, "episode/length": 234.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1612856, "time": 73123.21515083313, "episode/length": 357.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 1613040, "time": 73131.31578540802, "episode/length": 240.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 1613056, "time": 73133.43410658836, "episode/length": 187.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 1613560, "time": 73151.99098777771, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 1613672, "time": 73157.39668226242, "episode/length": 263.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 1613816, "time": 73163.79210567474, "episode/length": 390.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9923273657289002, "episode/intrinsic_return": 0.0}
{"step": 1613840, "time": 73168.16142249107, "episode/length": 408.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9926650366748166, "episode/intrinsic_return": 0.0}
{"step": 1614576, "time": 73194.60355257988, "episode/length": 214.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 1614616, "time": 73197.41349816322, "episode/length": 300.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9800664451827242, "episode/intrinsic_return": 0.0}
{"step": 1614816, "time": 73205.96277856827, "episode/length": 219.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 1614936, "time": 73211.31131482124, "episode/length": 236.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 1615400, "time": 73228.77244639397, "episode/length": 215.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 1615440, "time": 73231.95854210854, "episode/length": 234.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 1616056, "time": 73254.36711597443, "episode/length": 276.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 1616064, "time": 73256.52938699722, "episode/length": 180.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 1616136, "time": 73260.2935347557, "episode/length": 149.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 1616168, "time": 73262.94706201553, "episode/length": 293.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 1616320, "time": 73269.97828555107, "episode/length": 217.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9678899082568807, "episode/intrinsic_return": 0.0}
{"step": 1616368, "time": 73273.24896860123, "episode/length": 193.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 1617056, "time": 73298.19972968102, "episode/length": 206.0, "episode/score": 13.099999971687794, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 1617472, "time": 73314.07195186615, "episode/length": 166.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 1617552, "time": 73318.42286539078, "episode/length": 185.0, "episode/score": 14.100000008940697, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 1617552, "time": 73318.43232512474, "episode/length": 263.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 1617640, "time": 73324.63676023483, "episode/length": 183.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 1617856, "time": 73333.9547548294, "episode/length": 224.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 1617992, "time": 73340.01421737671, "episode/length": 208.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 1618464, "time": 73357.73248505592, "episode/length": 58.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 1618496, "time": 73360.31887793541, "episode/length": 179.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 1618928, "time": 73376.70519781113, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 1619008, "time": 73381.06176447868, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 1619032, "time": 73383.24832987785, "episode/length": 173.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 1619112, "time": 73387.53300523758, "episode/length": 194.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 1619808, "time": 73412.91837358475, "episode/length": 429.0, "episode/score": 14.099999979138374, "episode/reward_rate": 0.9976744186046511, "episode/intrinsic_return": 0.0}
{"step": 1620008, "time": 73437.15677475929, "eval_episode/length": 63.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.984375}
{"step": 1620008, "time": 73438.79264593124, "eval_episode/length": 64.0, "eval_episode/score": 8.099999964237213, "eval_episode/reward_rate": 0.9846153846153847}
{"step": 1620008, "time": 73444.97460150719, "eval_episode/length": 169.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9647058823529412}
{"step": 1620008, "time": 73447.08244252205, "eval_episode/length": 180.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.994475138121547}
{"step": 1620008, "time": 73450.38039255142, "eval_episode/length": 216.0, "eval_episode/score": 10.099999971687794, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 1620008, "time": 73452.75686573982, "eval_episode/length": 235.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9788135593220338}
{"step": 1620008, "time": 73461.73178339005, "eval_episode/length": 287.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9756944444444444}
{"step": 1620008, "time": 73463.45902776718, "eval_episode/length": 352.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9830028328611898}
{"step": 1620009, "time": 73464.53931927681, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.8391014547909, "train/action_min": 0.0, "train/action_std": 3.6485390295000637, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.025876738322789177, "train/actor_opt_grad_steps": 100475.0, "train/actor_opt_loss": -9.931461014072685, "train/adv_mag": 0.3823818991727689, "train/adv_max": 0.34448929503560066, "train/adv_mean": 0.0013263809643149216, "train/adv_min": -0.3031733439249151, "train/adv_std": 0.03936617958414204, "train/cont_avg": 0.9960434857536765, "train/cont_loss_mean": 0.0001087967970390647, "train/cont_loss_std": 0.0032859481227861206, "train/cont_neg_acc": 0.9927149975477759, "train/cont_neg_loss": 0.021692123646170697, "train/cont_pos_acc": 0.9999999820309526, "train/cont_pos_loss": 1.8817098133685222e-05, "train/cont_pred": 0.9960660110501682, "train/cont_rate": 0.9960434857536765, "train/dyn_loss_mean": 12.881498252644258, "train/dyn_loss_std": 9.314361326834735, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9564132313517963, "train/extr_critic_critic_opt_grad_steps": 100475.0, "train/extr_critic_critic_opt_loss": 14754.16164263557, "train/extr_critic_mag": 10.669180512428284, "train/extr_critic_max": 10.669180512428284, "train/extr_critic_mean": 2.3851227076614605, "train/extr_critic_min": -0.2203536480665207, "train/extr_critic_std": 2.548155869631206, "train/extr_return_normed_mag": 1.4811420396846884, "train/extr_return_normed_max": 1.4811420396846884, "train/extr_return_normed_mean": 0.3107174247065011, "train/extr_return_normed_min": -0.05845225318882834, "train/extr_return_normed_std": 0.32641620408086214, "train/extr_return_rate": 0.7283854548107175, "train/extr_return_raw_mag": 11.607608654919792, "train/extr_return_raw_max": 11.607608654919792, "train/extr_return_raw_mean": 2.395557543810676, "train/extr_return_raw_min": -0.5107006802059272, "train/extr_return_raw_std": 2.5692955080200646, "train/extr_reward_mag": 1.0511867193614735, "train/extr_reward_max": 1.0511867193614735, "train/extr_reward_mean": 0.04304879102582002, "train/extr_reward_min": -0.43887684538083915, "train/extr_reward_std": 0.19454206608454971, "train/image_loss_mean": 6.373277828973882, "train/image_loss_std": 12.333939026383792, "train/model_loss_mean": 14.166820406913757, "train/model_loss_std": 16.108464262064764, "train/model_opt_grad_norm": 45.714876132541235, "train/model_opt_grad_steps": 100386.10294117648, "train/model_opt_loss": 19621.889892578125, "train/model_opt_model_opt_grad_overflow": 0.007352941176470588, "train/model_opt_model_opt_grad_scale": 1369.485294117647, "train/policy_entropy_mag": 2.6884697535458733, "train/policy_entropy_max": 2.6884697535458733, "train/policy_entropy_mean": 0.8598070159992751, "train/policy_entropy_min": 0.07937501825611382, "train/policy_entropy_std": 0.9304865120964891, "train/policy_logprob_mag": 7.438383873771219, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.8604455011732438, "train/policy_logprob_min": -7.438383873771219, "train/policy_logprob_std": 1.2753987286020727, "train/policy_randomness_mag": 0.9489118430544349, "train/policy_randomness_max": 0.9489118430544349, "train/policy_randomness_mean": 0.30347414314746857, "train/policy_randomness_min": 0.02801589819821803, "train/policy_randomness_std": 0.3284209030954277, "train/post_ent_mag": 61.624867607565484, "train/post_ent_max": 61.624867607565484, "train/post_ent_mean": 43.8935409153209, "train/post_ent_min": 20.15429681890151, "train/post_ent_std": 7.864349407308242, "train/prior_ent_mag": 71.07660630170037, "train/prior_ent_max": 71.07660630170037, "train/prior_ent_mean": 56.86006400164436, "train/prior_ent_min": 40.438263444339526, "train/prior_ent_std": 4.864981710910797, "train/rep_loss_mean": 12.881498252644258, "train/rep_loss_std": 9.314361326834735, "train/reward_avg": 0.04148380025563871, "train/reward_loss_mean": 0.06453497529796817, "train/reward_loss_std": 0.2587775374379228, "train/reward_max_data": 1.0294117717181934, "train/reward_max_pred": 1.0211638834546595, "train/reward_neg_acc": 0.991327187155976, "train/reward_neg_loss": 0.030783353763742045, "train/reward_pos_acc": 0.9823072828790721, "train/reward_pos_loss": 0.7815391324898776, "train/reward_pred": 0.040816442075404614, "train/reward_rate": 0.045058306525735295, "train_stats/sum_log_reward": 11.361363752321763, "train_stats/max_log_achievement_collect_coal": 1.0795454545454546, "train_stats/max_log_achievement_collect_drink": 6.318181818181818, "train_stats/max_log_achievement_collect_iron": 0.03409090909090909, "train_stats/max_log_achievement_collect_sapling": 1.7386363636363635, "train_stats/max_log_achievement_collect_stone": 14.329545454545455, "train_stats/max_log_achievement_collect_wood": 10.159090909090908, "train_stats/max_log_achievement_defeat_skeleton": 0.09090909090909091, "train_stats/max_log_achievement_defeat_zombie": 1.4204545454545454, "train_stats/max_log_achievement_eat_cow": 0.5340909090909091, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.10227272727272728, "train_stats/max_log_achievement_make_stone_sword": 0.03409090909090909, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5909090909090908, "train_stats/max_log_achievement_make_wood_sword": 1.0568181818181819, "train_stats/max_log_achievement_place_furnace": 2.4431818181818183, "train_stats/max_log_achievement_place_plant": 1.6136363636363635, "train_stats/max_log_achievement_place_stone": 3.3181818181818183, "train_stats/max_log_achievement_place_table": 2.7045454545454546, "train_stats/max_log_achievement_wake_up": 1.7613636363636365, "train_stats/mean_log_entropy": 0.6755460839379918, "eval_stats/sum_log_reward": 10.725000143051147, "eval_stats/max_log_achievement_collect_coal": 1.1666666666666667, "eval_stats/max_log_achievement_collect_drink": 5.708333333333333, "eval_stats/max_log_achievement_collect_iron": 0.041666666666666664, "eval_stats/max_log_achievement_collect_sapling": 1.5416666666666667, "eval_stats/max_log_achievement_collect_stone": 12.708333333333334, "eval_stats/max_log_achievement_collect_wood": 8.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.5, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.08333333333333333, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.8333333333333334, "eval_stats/max_log_achievement_place_furnace": 1.9583333333333333, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 3.2083333333333335, "eval_stats/max_log_achievement_place_table": 2.4166666666666665, "eval_stats/max_log_achievement_wake_up": 1.3333333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.5713843822595663e-05, "report/cont_loss_std": 0.00026682004681788385, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.001193248201161623, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.22538976938813e-05, "report/cont_pred": 0.9970616698265076, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 11.331562995910645, "report/dyn_loss_std": 9.169516563415527, "report/image_loss_mean": 6.075742244720459, "report/image_loss_std": 11.435677528381348, "report/model_loss_mean": 12.926694869995117, "report/model_loss_std": 15.085761070251465, "report/post_ent_mag": 64.04928588867188, "report/post_ent_max": 64.04928588867188, "report/post_ent_mean": 44.55204772949219, "report/post_ent_min": 22.164981842041016, "report/post_ent_std": 8.109423637390137, "report/prior_ent_mag": 71.05308532714844, "report/prior_ent_max": 71.05308532714844, "report/prior_ent_mean": 56.272117614746094, "report/prior_ent_min": 41.586151123046875, "report/prior_ent_std": 5.439944267272949, "report/rep_loss_mean": 11.331562995910645, "report/rep_loss_std": 9.169516563415527, "report/reward_avg": 0.0322265625, "report/reward_loss_mean": 0.05200021713972092, "report/reward_loss_std": 0.21357396245002747, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0021846294403076, "report/reward_neg_acc": 0.988877534866333, "report/reward_neg_loss": 0.025832783430814743, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7914171814918518, "report/reward_pred": 0.02995636686682701, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 5.0780890887835994e-05, "eval/cont_loss_std": 0.0011830131988972425, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00036953832022845745, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.953085954184644e-05, "eval/cont_pred": 0.9960465431213379, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 15.71389389038086, "eval/dyn_loss_std": 10.946155548095703, "eval/image_loss_mean": 9.339162826538086, "eval/image_loss_std": 17.4301815032959, "eval/model_loss_mean": 18.88814926147461, "eval/model_loss_std": 21.428279876708984, "eval/post_ent_mag": 62.866119384765625, "eval/post_ent_max": 62.866119384765625, "eval/post_ent_mean": 42.753780364990234, "eval/post_ent_min": 20.639835357666016, "eval/post_ent_std": 7.809438705444336, "eval/prior_ent_mag": 71.05308532714844, "eval/prior_ent_max": 71.05308532714844, "eval/prior_ent_mean": 56.48113250732422, "eval/prior_ent_min": 45.48618698120117, "eval/prior_ent_std": 4.535456657409668, "eval/rep_loss_mean": 15.71389389038086, "eval/rep_loss_std": 10.946155548095703, "eval/reward_avg": 0.05683593824505806, "eval/reward_loss_mean": 0.12059833109378815, "eval/reward_loss_std": 0.6160486340522766, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0634572505950928, "eval/reward_neg_acc": 0.9813278317451477, "eval/reward_neg_loss": 0.04373425617814064, "eval/reward_pos_acc": 0.8833333849906921, "eval/reward_pos_loss": 1.3555476665496826, "eval/reward_pred": 0.051448944956064224, "eval/reward_rate": 0.05859375, "replay/size": 1000000.0, "replay/inserts": 21680.0, "replay/samples": 21680.0, "replay/insert_wait_avg": 1.3560606544748003e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.160117807423497e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 8696.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2788129927592202e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1012.3349969387054, "timer/env.step_count": 2710.0, "timer/env.step_total": 221.6456162929535, "timer/env.step_frac": 0.21894493123640732, "timer/env.step_avg": 0.08178805029260276, "timer/env.step_min": 0.02474045753479004, "timer/env.step_max": 3.4892263412475586, "timer/replay._sample_count": 21680.0, "timer/replay._sample_total": 11.260990858078003, "timer/replay._sample_frac": 0.011123779077213736, "timer/replay._sample_avg": 0.000519418397512823, "timer/replay._sample_min": 0.00043320655822753906, "timer/replay._sample_max": 0.028805255889892578, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3797.0, "timer/agent.policy_total": 67.14758610725403, "timer/agent.policy_frac": 0.06632941300094129, "timer/agent.policy_avg": 0.017684378748289185, "timer/agent.policy_min": 0.009851217269897461, "timer/agent.policy_max": 0.19383668899536133, "timer/dataset_train_count": 1355.0, "timer/dataset_train_total": 0.15143370628356934, "timer/dataset_train_frac": 0.00014958853219685568, "timer/dataset_train_avg": 0.00011175919282920246, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.000690460205078125, "timer/agent.train_count": 1355.0, "timer/agent.train_total": 612.7031183242798, "timer/agent.train_frac": 0.605237515424331, "timer/agent.train_avg": 0.45217942311754966, "timer/agent.train_min": 0.43965888023376465, "timer/agent.train_max": 1.9417788982391357, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4712064266204834, "timer/agent.report_frac": 0.000465464918278444, "timer/agent.report_avg": 0.2356032133102417, "timer/agent.report_min": 0.22909927368164062, "timer/agent.report_max": 0.24210715293884277, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.132329823269733e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 21.415543376635203}
{"step": 1620264, "time": 73473.03111171722, "episode/length": 224.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1620560, "time": 73484.72114300728, "episode/length": 337.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9881656804733728, "episode/intrinsic_return": 0.0}
{"step": 1620600, "time": 73487.59856295586, "episode/length": 208.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 1621056, "time": 73504.97671890259, "episode/length": 242.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 1621488, "time": 73521.19091033936, "episode/length": 306.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 1621928, "time": 73537.54463481903, "episode/length": 207.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 1622240, "time": 73551.97506284714, "episode/length": 467.0, "episode/score": 15.100000008940697, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 1622624, "time": 73566.71121549606, "episode/length": 451.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9977876106194691, "episode/intrinsic_return": 0.0}
{"step": 1622768, "time": 73573.2322704792, "episode/length": 213.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 1622840, "time": 73577.11795258522, "episode/length": 284.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9964912280701754, "episode/intrinsic_return": 0.0}
{"step": 1623024, "time": 73585.12237024307, "episode/length": 302.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 1623144, "time": 73590.56845736504, "episode/length": 206.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 1624040, "time": 73622.64574980736, "episode/length": 149.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9533333333333334, "episode/intrinsic_return": 0.0}
{"step": 1624352, "time": 73635.02809929848, "episode/length": 38.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 1624392, "time": 73637.88747382164, "episode/length": 170.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 1624760, "time": 73651.97288513184, "episode/length": 314.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9968253968253968, "episode/intrinsic_return": 0.0}
{"step": 1624776, "time": 73654.10058307648, "episode/length": 250.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 1624912, "time": 73660.493278265, "episode/length": 285.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 1625192, "time": 73671.36952519417, "episode/length": 407.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9975490196078431, "episode/intrinsic_return": 0.0}
{"step": 1625592, "time": 73686.59934401512, "episode/length": 305.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9967320261437909, "episode/intrinsic_return": 0.0}
{"step": 1625944, "time": 73700.25986599922, "episode/length": 193.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 1626032, "time": 73705.16026759148, "episode/length": 156.0, "episode/score": 13.099999964237213, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 1626816, "time": 73733.54190301895, "episode/length": 237.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 1626872, "time": 73736.82215166092, "episode/length": 882.0, "episode/score": 14.1000000461936, "episode/reward_rate": 0.9988674971687429, "episode/intrinsic_return": 0.0}
{"step": 1626928, "time": 73740.50594758987, "episode/length": 321.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9906832298136646, "episode/intrinsic_return": 0.0}
{"step": 1627584, "time": 73764.34639930725, "episode/length": 204.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 1627648, "time": 73768.18097043037, "episode/length": 256.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 1627872, "time": 73777.35435795784, "episode/length": 388.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9922879177377892, "episode/intrinsic_return": 0.0}
{"step": 1628296, "time": 73793.12817192078, "episode/length": 170.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 1628448, "time": 73800.08782052994, "episode/length": 406.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9877149877149877, "episode/intrinsic_return": 0.0}
{"step": 1628456, "time": 73801.74189019203, "episode/length": 204.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 1629352, "time": 73833.8046503067, "episode/length": 309.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9903225806451613, "episode/intrinsic_return": 0.0}
{"step": 1629752, "time": 73849.255661726, "episode/length": 262.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.973384030418251, "episode/intrinsic_return": 0.0}
{"step": 1629808, "time": 73853.08810019493, "episode/length": 471.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1630096, "time": 73886.84874629974, "eval_episode/length": 104.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9904761904761905}
{"step": 1630096, "time": 73893.06860780716, "eval_episode/length": 183.0, "eval_episode/score": 13.100000001490116, "eval_episode/reward_rate": 0.9836956521739131}
{"step": 1630096, "time": 73896.41986894608, "eval_episode/length": 210.0, "eval_episode/score": 12.099999994039536, "eval_episode/reward_rate": 0.995260663507109}
{"step": 1630096, "time": 73898.64425373077, "eval_episode/length": 221.0, "eval_episode/score": 10.099999971687794, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 1630096, "time": 73902.25069880486, "eval_episode/length": 266.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9925093632958801}
{"step": 1630096, "time": 73904.33109116554, "eval_episode/length": 275.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 1630096, "time": 73906.4804918766, "eval_episode/length": 286.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9965156794425087}
{"step": 1630096, "time": 73910.53163528442, "eval_episode/length": 342.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9825072886297376}
{"step": 1630184, "time": 73913.3061568737, "episode/length": 235.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1630320, "time": 73921.64293074608, "episode/length": 232.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 1630720, "time": 73936.96968317032, "episode/length": 283.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 1631008, "time": 73948.43164682388, "episode/length": 427.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9929906542056075, "episode/intrinsic_return": 0.0}
{"step": 1631688, "time": 73973.01575684547, "episode/length": 241.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 1631976, "time": 73984.58038711548, "episode/length": 223.0, "episode/score": 13.099999994039536, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1632024, "time": 73987.90636110306, "episode/length": 518.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9788053949903661, "episode/intrinsic_return": 0.0}
{"step": 1632368, "time": 74001.35521030426, "episode/length": 376.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9973474801061007, "episode/intrinsic_return": 0.0}
{"step": 1632648, "time": 74012.24058961868, "episode/length": 240.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 1633064, "time": 74027.8763616085, "episode/length": 406.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9901719901719902, "episode/intrinsic_return": 0.0}
{"step": 1633560, "time": 74046.39799714088, "episode/length": 197.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 1633696, "time": 74052.73926663399, "episode/length": 208.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 1634088, "time": 74067.58845376968, "episode/length": 214.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 1634368, "time": 74078.92064976692, "episode/length": 505.0, "episode/score": 14.100000008940697, "episode/reward_rate": 0.9980237154150198, "episode/intrinsic_return": 0.0}
{"step": 1634608, "time": 74088.80788469315, "episode/length": 449.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9977777777777778, "episode/intrinsic_return": 0.0}
{"step": 1634648, "time": 74091.67460727692, "episode/length": 369.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9837837837837838, "episode/intrinsic_return": 0.0}
{"step": 1634672, "time": 74094.34209513664, "episode/length": 200.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 1635248, "time": 74115.41957235336, "episode/length": 210.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1635312, "time": 74119.3603527546, "episode/length": 201.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 1636104, "time": 74147.59132385254, "episode/length": 431.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 1636104, "time": 74147.59988474846, "episode/length": 216.0, "episode/score": 13.099999971687794, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1636208, "time": 74154.75286531448, "episode/length": 264.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 1636328, "time": 74160.19820713997, "episode/length": 209.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 1636656, "time": 74173.06893134117, "episode/length": 255.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 1637256, "time": 74194.8050839901, "episode/length": 242.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 1637456, "time": 74203.3697514534, "episode/length": 155.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1637744, "time": 74214.77538537979, "episode/length": 204.0, "episode/score": 13.099999994039536, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 1637904, "time": 74221.7696223259, "episode/length": 224.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9688888888888889, "episode/intrinsic_return": 0.0}
{"step": 1638352, "time": 74238.6099410057, "episode/length": 387.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9974226804123711, "episode/intrinsic_return": 0.0}
{"step": 1638528, "time": 74247.88452768326, "episode/length": 233.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 1638704, "time": 74255.45646357536, "episode/length": 296.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 1638848, "time": 74262.02758455276, "episode/length": 521.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 1638992, "time": 74268.65243268013, "episode/length": 216.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1639408, "time": 74284.7707722187, "episode/length": 187.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 1639664, "time": 74295.05756616592, "episode/length": 239.0, "episode/score": 13.099999971687794, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 1639864, "time": 74303.35019183159, "episode/length": 300.0, "episode/score": 13.100000016391277, "episode/reward_rate": 0.9800664451827242, "episode/intrinsic_return": 0.0}
{"step": 1640080, "time": 74333.76921844482, "eval_episode/length": 175.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 1640080, "time": 74336.5715072155, "eval_episode/length": 201.0, "eval_episode/score": 11.099999971687794, "eval_episode/reward_rate": 0.995049504950495}
{"step": 1640080, "time": 74338.4760518074, "eval_episode/length": 208.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 1640080, "time": 74340.71965622902, "eval_episode/length": 221.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.972972972972973}
{"step": 1640080, "time": 74343.62892603874, "eval_episode/length": 249.0, "eval_episode/score": 13.100000008940697, "eval_episode/reward_rate": 0.996}
{"step": 1640080, "time": 74345.76934933662, "eval_episode/length": 39.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.975}
{"step": 1640080, "time": 74349.12755131721, "eval_episode/length": 51.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 1640080, "time": 74351.77582883835, "eval_episode/length": 117.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9915254237288136}
{"step": 1640096, "time": 74352.3335545063, "episode/length": 217.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 1640304, "time": 74361.04159402847, "episode/length": 199.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 1640432, "time": 74366.92608952522, "episode/length": 179.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 1640920, "time": 74384.77015089989, "episode/length": 258.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 1641152, "time": 74394.43331766129, "episode/length": 217.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 1641272, "time": 74399.68770766258, "episode/length": 175.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 1641280, "time": 74401.71758699417, "episode/length": 343.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 1641328, "time": 74404.87882256508, "episode/length": 207.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 1641400, "time": 74408.6720085144, "episode/length": 162.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 1641496, "time": 74413.40269851685, "episode/length": 148.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 1642480, "time": 74448.85187029839, "episode/length": 255.0, "episode/score": 13.099999994039536, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 1642744, "time": 74459.6177482605, "episode/length": 182.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 1642824, "time": 74463.84370350838, "episode/length": 208.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 1642825, "time": 74466.61702036858, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.052996015215253, "train/action_min": 0.0, "train/action_std": 3.854932429907205, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.024873139688393452, "train/actor_opt_grad_steps": 101870.0, "train/actor_opt_loss": -8.811733923383526, "train/adv_mag": 0.3498531936348735, "train/adv_max": 0.32489718475958684, "train/adv_mean": 0.0012624811221170463, "train/adv_min": -0.28795683071329875, "train/adv_std": 0.038080464136767224, "train/cont_avg": 0.9959981424825175, "train/cont_loss_mean": 0.0001397901289334771, "train/cont_loss_std": 0.004281865116444942, "train/cont_neg_acc": 0.9883802818580413, "train/cont_neg_loss": 0.020083049437577667, "train/cont_pos_acc": 0.9999725614394341, "train/cont_pos_loss": 6.967099797274554e-05, "train/cont_pred": 0.9959988052194769, "train/cont_rate": 0.9959981424825175, "train/dyn_loss_mean": 12.818841500715775, "train/dyn_loss_std": 9.33202230680239, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9386859448639663, "train/extr_critic_critic_opt_grad_steps": 101870.0, "train/extr_critic_critic_opt_loss": 14637.41402152535, "train/extr_critic_mag": 10.753888236892807, "train/extr_critic_max": 10.753888236892807, "train/extr_critic_mean": 2.2805967330932617, "train/extr_critic_min": -0.2355392012562785, "train/extr_critic_std": 2.5873742270302937, "train/extr_return_normed_mag": 1.4720695127140393, "train/extr_return_normed_max": 1.4720695127140393, "train/extr_return_normed_mean": 0.29729773896140654, "train/extr_return_normed_min": -0.05219385469449567, "train/extr_return_normed_std": 0.32582451642810045, "train/extr_return_rate": 0.6785429789052977, "train/extr_return_raw_mag": 11.700853887971464, "train/extr_return_raw_max": 11.700853887971464, "train/extr_return_raw_mean": 2.2907073747861637, "train/extr_return_raw_min": -0.5090825679627332, "train/extr_return_raw_std": 2.610267850068899, "train/extr_reward_mag": 1.063123667990411, "train/extr_reward_max": 1.063123667990411, "train/extr_reward_mean": 0.041771383239672735, "train/extr_reward_min": -0.4435104581859562, "train/extr_reward_std": 0.19192402919272442, "train/image_loss_mean": 6.338735760508717, "train/image_loss_std": 12.156231556739007, "train/model_loss_mean": 14.093649890872982, "train/model_loss_std": 15.929546676315628, "train/model_opt_grad_norm": 45.13431282310219, "train/model_opt_grad_steps": 101779.70629370629, "train/model_opt_loss": 18875.63607681381, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1337.4125874125873, "train/policy_entropy_mag": 2.6952665552392707, "train/policy_entropy_max": 2.6952665552392707, "train/policy_entropy_mean": 0.9360532314627321, "train/policy_entropy_min": 0.07937501891926452, "train/policy_entropy_std": 0.971210347605752, "train/policy_logprob_mag": 7.438383862688825, "train/policy_logprob_max": -0.009455658391222253, "train/policy_logprob_mean": -0.9359854122141859, "train/policy_logprob_min": -7.438383862688825, "train/policy_logprob_std": 1.2981949777869912, "train/policy_randomness_mag": 0.9513108163446813, "train/policy_randomness_max": 0.9513108163446813, "train/policy_randomness_mean": 0.3303857169576458, "train/policy_randomness_min": 0.028015898475488583, "train/policy_randomness_std": 0.3427946357043473, "train/post_ent_mag": 61.407079950079215, "train/post_ent_max": 61.407079950079215, "train/post_ent_mean": 43.94061682107565, "train/post_ent_min": 20.170206103291545, "train/post_ent_std": 7.818761562134003, "train/prior_ent_mag": 71.10735353056367, "train/prior_ent_max": 71.10735353056367, "train/prior_ent_mean": 56.8584293552212, "train/prior_ent_min": 40.40960095812391, "train/prior_ent_std": 4.937968417481109, "train/rep_loss_mean": 12.818841500715775, "train/rep_loss_std": 9.33202230680239, "train/reward_avg": 0.04039895629601462, "train/reward_loss_mean": 0.06346951326081803, "train/reward_loss_std": 0.2527731698709768, "train/reward_max_data": 1.0356643441673758, "train/reward_max_pred": 1.0335229510193937, "train/reward_neg_acc": 0.9912719876616152, "train/reward_neg_loss": 0.030425083478326564, "train/reward_pos_acc": 0.9802161592703599, "train/reward_pos_loss": 0.7852320337628985, "train/reward_pred": 0.03969362328623558, "train/reward_rate": 0.04390433784965035, "train_stats/sum_log_reward": 11.593976164438638, "train_stats/max_log_achievement_collect_coal": 0.9518072289156626, "train_stats/max_log_achievement_collect_drink": 6.963855421686747, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 2.0843373493975905, "train_stats/max_log_achievement_collect_stone": 15.325301204819278, "train_stats/max_log_achievement_collect_wood": 10.506024096385541, "train_stats/max_log_achievement_defeat_skeleton": 0.12048192771084337, "train_stats/max_log_achievement_defeat_zombie": 1.6144578313253013, "train_stats/max_log_achievement_eat_cow": 0.46987951807228917, "train_stats/max_log_achievement_eat_plant": 0.012048192771084338, "train_stats/max_log_achievement_make_stone_pickaxe": 0.10843373493975904, "train_stats/max_log_achievement_make_stone_sword": 0.060240963855421686, "train_stats/max_log_achievement_make_wood_pickaxe": 1.6506024096385543, "train_stats/max_log_achievement_make_wood_sword": 1.2891566265060241, "train_stats/max_log_achievement_place_furnace": 2.3855421686746987, "train_stats/max_log_achievement_place_plant": 1.9156626506024097, "train_stats/max_log_achievement_place_stone": 4.180722891566265, "train_stats/max_log_achievement_place_table": 2.746987951807229, "train_stats/max_log_achievement_wake_up": 1.963855421686747, "train_stats/mean_log_entropy": 0.7794779761728033, "eval_stats/sum_log_reward": 10.725000202655792, "eval_stats/max_log_achievement_collect_coal": 0.6875, "eval_stats/max_log_achievement_collect_drink": 5.5625, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 10.1875, "eval_stats/max_log_achievement_collect_wood": 8.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.0625, "eval_stats/max_log_achievement_eat_cow": 0.375, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.125, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.375, "eval_stats/max_log_achievement_make_wood_sword": 1.0625, "eval_stats/max_log_achievement_place_furnace": 1.5625, "eval_stats/max_log_achievement_place_plant": 1.6875, "eval_stats/max_log_achievement_place_stone": 3.125, "eval_stats/max_log_achievement_place_table": 1.9375, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 6.3673410295450594e-06, "report/cont_loss_std": 0.00012855400564149022, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.002584062749519944, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.3229265505287913e-06, "report/cont_pred": 0.9980506300926208, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 12.279624938964844, "report/dyn_loss_std": 8.9020357131958, "report/image_loss_mean": 6.49560546875, "report/image_loss_std": 15.279863357543945, "report/model_loss_mean": 13.912647247314453, "report/model_loss_std": 18.301605224609375, "report/post_ent_mag": 62.592063903808594, "report/post_ent_max": 62.592063903808594, "report/post_ent_mean": 44.45722198486328, "report/post_ent_min": 21.473512649536133, "report/post_ent_std": 8.039074897766113, "report/prior_ent_mag": 71.02548217773438, "report/prior_ent_max": 71.02548217773438, "report/prior_ent_mean": 56.919166564941406, "report/prior_ent_min": 42.16728210449219, "report/prior_ent_std": 4.259951591491699, "report/rep_loss_mean": 12.279624938964844, "report/rep_loss_std": 8.9020357131958, "report/reward_avg": 0.03369140625, "report/reward_loss_mean": 0.04926091060042381, "report/reward_loss_std": 0.21168850362300873, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011446475982666, "report/reward_neg_acc": 0.9888550639152527, "report/reward_neg_loss": 0.01947908289730549, "report/reward_pos_acc": 0.9729729294776917, "report/reward_pos_loss": 0.8437111377716064, "report/reward_pred": 0.03142644092440605, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0006858594715595245, "eval/cont_loss_std": 0.021783458068966866, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00015154827269725502, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.0006874295067973435, "eval/cont_pred": 0.9965760707855225, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.77176284790039, "eval/dyn_loss_std": 11.10904312133789, "eval/image_loss_mean": 10.754663467407227, "eval/image_loss_std": 15.207169532775879, "eval/model_loss_mean": 20.947307586669922, "eval/model_loss_std": 19.778331756591797, "eval/post_ent_mag": 60.960628509521484, "eval/post_ent_max": 60.960628509521484, "eval/post_ent_mean": 42.510589599609375, "eval/post_ent_min": 20.946575164794922, "eval/post_ent_std": 8.121842384338379, "eval/prior_ent_mag": 71.02548217773438, "eval/prior_ent_max": 71.02548217773438, "eval/prior_ent_mean": 57.2441291809082, "eval/prior_ent_min": 44.26433563232422, "eval/prior_ent_std": 4.326649188995361, "eval/rep_loss_mean": 16.77176284790039, "eval/rep_loss_std": 11.10904312133789, "eval/reward_avg": 0.05224609375, "eval/reward_loss_mean": 0.12890154123306274, "eval/reward_loss_std": 0.7154629826545715, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.009969711303711, "eval/reward_neg_acc": 0.9834539890289307, "eval/reward_neg_loss": 0.0340544767677784, "eval/reward_pos_acc": 0.8245614171028137, "eval/reward_pos_loss": 1.737973690032959, "eval/reward_pred": 0.04451863467693329, "eval/reward_rate": 0.0556640625, "replay/size": 1000000.0, "replay/inserts": 22816.0, "replay/samples": 22816.0, "replay/insert_wait_avg": 1.3486177857761464e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.237855130124728e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5360.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.317574017083467e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1002.064523935318, "timer/env.step_count": 2852.0, "timer/env.step_total": 216.05437707901, "timer/env.step_frac": 0.21560924662866923, "timer/env.step_avg": 0.07575539168268233, "timer/env.step_min": 0.024591445922851562, "timer/env.step_max": 3.4386885166168213, "timer/replay._sample_count": 22816.0, "timer/replay._sample_total": 11.849820613861084, "timer/replay._sample_frac": 0.011825406778521954, "timer/replay._sample_avg": 0.0005193645079707699, "timer/replay._sample_min": 0.000392913818359375, "timer/replay._sample_max": 0.025877714157104492, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3522.0, "timer/agent.policy_total": 61.0907256603241, "timer/agent.policy_frac": 0.06096486224301004, "timer/agent.policy_avg": 0.017345464412357778, "timer/agent.policy_min": 0.009915351867675781, "timer/agent.policy_max": 0.09289789199829102, "timer/dataset_train_count": 1426.0, "timer/dataset_train_total": 0.1600661277770996, "timer/dataset_train_frac": 0.00015973634826277084, "timer/dataset_train_avg": 0.00011224833644957897, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.0010170936584472656, "timer/agent.train_count": 1426.0, "timer/agent.train_total": 645.374936580658, "timer/agent.train_frac": 0.6440452896647163, "timer/agent.train_avg": 0.452577094376338, "timer/agent.train_min": 0.4389839172363281, "timer/agent.train_max": 1.818866491317749, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4754765033721924, "timer/agent.report_frac": 0.00047449689317899033, "timer/agent.report_avg": 0.2377382516860962, "timer/agent.report_min": 0.23003840446472168, "timer/agent.report_max": 0.2454380989074707, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.719329833984375e-05, "timer/dataset_eval_frac": 3.711667008605179e-08, "timer/dataset_eval_avg": 3.719329833984375e-05, "timer/dataset_eval_min": 3.719329833984375e-05, "timer/dataset_eval_max": 3.719329833984375e-05, "fps": 22.76863928320852}
{"step": 1643032, "time": 74473.48465299606, "episode/length": 263.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9734848484848485, "episode/intrinsic_return": 0.0}
{"step": 1643088, "time": 74477.29195713997, "episode/length": 219.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 1643200, "time": 74482.64038085938, "episode/length": 224.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1643336, "time": 74488.60608315468, "episode/length": 257.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9728682170542635, "episode/intrinsic_return": 0.0}
{"step": 1643936, "time": 74511.27519369125, "episode/length": 304.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 1644296, "time": 74524.97149705887, "episode/length": 183.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 1644944, "time": 74549.0394411087, "episode/length": 217.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1644992, "time": 74552.3701198101, "episode/length": 244.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 1645432, "time": 74568.97593998909, "episode/length": 261.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 1645576, "time": 74575.40755867958, "episode/length": 353.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9887005649717514, "episode/intrinsic_return": 0.0}
{"step": 1645936, "time": 74589.44620680809, "episode/length": 249.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 1646112, "time": 74597.62099575996, "episode/length": 377.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 1646360, "time": 74607.34475874901, "episode/length": 484.0, "episode/score": 15.100000001490116, "episode/reward_rate": 0.9835051546391752, "episode/intrinsic_return": 0.0}
{"step": 1646496, "time": 74613.62149333954, "episode/length": 193.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 1646592, "time": 74618.61528015137, "episode/length": 286.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 1646752, "time": 74627.55648565292, "episode/length": 48.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 1647184, "time": 74643.71978330612, "episode/length": 273.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 1647200, "time": 74645.86041378975, "episode/length": 220.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 1647456, "time": 74656.69885444641, "episode/length": 167.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1647560, "time": 74661.7104742527, "episode/length": 247.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 1647848, "time": 74673.172560215, "episode/length": 238.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 1648040, "time": 74681.34331583977, "episode/length": 192.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 1648472, "time": 74697.76200509071, "episode/length": 234.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1648944, "time": 74715.5498509407, "episode/length": 172.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 1648944, "time": 74715.5592417717, "episode/length": 217.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1649104, "time": 74724.51293969154, "episode/length": 205.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 1649320, "time": 74733.17531490326, "episode/length": 183.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 1649544, "time": 74742.42408633232, "episode/length": 187.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 1649728, "time": 74750.56440711021, "episode/length": 317.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9968553459119497, "episode/intrinsic_return": 0.0}
{"step": 1649832, "time": 74755.4632768631, "episode/length": 63.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 1650064, "time": 74785.91119742393, "eval_episode/length": 161.0, "eval_episode/score": 13.100000001490116, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 1650064, "time": 74789.30955004692, "eval_episode/length": 198.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 1650064, "time": 74791.10564017296, "eval_episode/length": 204.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9804878048780488}
{"step": 1650064, "time": 74794.56711769104, "eval_episode/length": 244.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9959183673469387}
{"step": 1650064, "time": 74796.35696029663, "eval_episode/length": 248.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9799196787148594}
{"step": 1650064, "time": 74798.48705673218, "eval_episode/length": 260.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9808429118773946}
{"step": 1650064, "time": 74803.05854177475, "eval_episode/length": 281.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.975177304964539}
{"step": 1650064, "time": 74806.71454191208, "eval_episode/length": 323.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9907407407407407}
{"step": 1650272, "time": 74813.76720666885, "episode/length": 439.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9977272727272727, "episode/intrinsic_return": 0.0}
{"step": 1650520, "time": 74823.50050401688, "episode/length": 255.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 1650560, "time": 74826.6484746933, "episode/length": 201.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 1650624, "time": 74830.31489300728, "episode/length": 189.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 1651200, "time": 74851.37841653824, "episode/length": 206.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 1651216, "time": 74853.5195403099, "episode/length": 185.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 1652056, "time": 74883.45196723938, "episode/length": 186.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 1652104, "time": 74886.64956951141, "episode/length": 228.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 1652176, "time": 74890.90216732025, "episode/length": 206.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 1652248, "time": 74894.66769695282, "episode/length": 412.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9782082324455206, "episode/intrinsic_return": 0.0}
{"step": 1652664, "time": 74910.53385567665, "episode/length": 254.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9725490196078431, "episode/intrinsic_return": 0.0}
{"step": 1653000, "time": 74923.45953965187, "episode/length": 395.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9873737373737373, "episode/intrinsic_return": 0.0}
{"step": 1653256, "time": 74934.0636510849, "episode/length": 254.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 1653368, "time": 74939.4147131443, "episode/length": 270.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704797047970479, "episode/intrinsic_return": 0.0}
{"step": 1653400, "time": 74942.14097356796, "episode/length": 167.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1653800, "time": 74957.56891942024, "episode/length": 211.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 1654328, "time": 74977.01772594452, "episode/length": 268.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 1654432, "time": 74982.43601536751, "episode/length": 220.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 1654584, "time": 74989.07705330849, "episode/length": 197.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 1655176, "time": 75012.55617284775, "episode/length": 225.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 1655192, "time": 75014.6981806755, "episode/length": 241.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 1655744, "time": 75035.34834170341, "episode/length": 163.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 1655760, "time": 75037.6621029377, "episode/length": 294.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.976271186440678, "episode/intrinsic_return": 0.0}
{"step": 1655968, "time": 75046.31665563583, "episode/length": 204.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 1656272, "time": 75058.46088051796, "episode/length": 136.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 1656280, "time": 75060.48519158363, "episode/length": 309.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 1656424, "time": 75067.28594350815, "episode/length": 229.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 1656464, "time": 75070.47059512138, "episode/length": 158.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 1656792, "time": 75082.99927687645, "episode/length": 567.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 1656864, "time": 75087.23842191696, "episode/length": 139.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 1657328, "time": 75104.43763327599, "episode/length": 195.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 1657976, "time": 75127.9076757431, "episode/length": 211.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9669811320754716, "episode/intrinsic_return": 0.0}
{"step": 1658232, "time": 75138.4178173542, "episode/length": 282.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 1658408, "time": 75146.11856126785, "episode/length": 192.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 1658440, "time": 75148.86344051361, "episode/length": 138.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 1658544, "time": 75154.1899793148, "episode/length": 259.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 1658656, "time": 75159.6182615757, "episode/length": 232.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 1659096, "time": 75175.9397892952, "episode/length": 352.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9915014164305949, "episode/intrinsic_return": 0.0}
{"step": 1659152, "time": 75179.68910288811, "episode/length": 340.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9970674486803519, "episode/intrinsic_return": 0.0}
{"step": 1659320, "time": 75186.74637079239, "episode/length": 167.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 1659664, "time": 75200.27262759209, "episode/length": 156.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 1659848, "time": 75208.47114419937, "episode/length": 148.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 1660024, "time": 75216.02426195145, "episode/length": 87.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9431818181818182, "episode/intrinsic_return": 0.0}
{"step": 1660048, "time": 75243.55873417854, "eval_episode/length": 146.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 1660048, "time": 75246.82533407211, "eval_episode/length": 182.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 1660048, "time": 75249.2653567791, "eval_episode/length": 200.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 1660048, "time": 75251.17845964432, "eval_episode/length": 206.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 1660048, "time": 75253.53918933868, "eval_episode/length": 222.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 1660048, "time": 75255.58256173134, "eval_episode/length": 231.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 1660048, "time": 75258.34329462051, "eval_episode/length": 252.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9960474308300395}
{"step": 1660048, "time": 75260.24558472633, "eval_episode/length": 259.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9961538461538462}
{"step": 1660440, "time": 75273.34047341347, "episode/length": 236.0, "episode/score": 13.100000016391277, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 1660504, "time": 75277.12787652016, "episode/length": 257.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 1660664, "time": 75284.11346077919, "episode/length": 101.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 1660784, "time": 75290.10464859009, "episode/length": 210.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 1660824, "time": 75292.93758535385, "episode/length": 208.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 1660856, "time": 75295.72763609886, "episode/length": 327.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9969512195121951, "episode/intrinsic_return": 0.0}
{"step": 1661000, "time": 75302.09467291832, "episode/length": 166.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 1661624, "time": 75324.87138438225, "episode/length": 147.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 1661960, "time": 75337.92404007912, "episode/length": 41.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 1661960, "time": 75337.93151426315, "episode/length": 181.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 1662048, "time": 75344.38944530487, "episode/length": 130.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 1662288, "time": 75354.14177823067, "episode/length": 282.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 1663232, "time": 75389.87367463112, "episode/length": 320.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9844236760124611, "episode/intrinsic_return": 0.0}
{"step": 1663272, "time": 75392.64508605003, "episode/length": 301.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 1663376, "time": 75398.06758451462, "episode/length": 318.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9968652037617555, "episode/intrinsic_return": 0.0}
{"step": 1663776, "time": 75413.3588821888, "episode/length": 215.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 1663984, "time": 75421.90859413147, "episode/length": 399.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 1664336, "time": 75435.28968453407, "episode/length": 255.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 1664352, "time": 75437.51662945747, "episode/length": 298.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.0}
{"step": 1664976, "time": 75460.23919057846, "episode/length": 217.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 1664984, "time": 75461.85814166069, "episode/length": 213.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 1665049, "time": 75466.73362970352, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.095144078351449, "train/action_min": 0.0, "train/action_std": 3.949534184690835, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.024959136326999767, "train/actor_opt_grad_steps": 103275.0, "train/actor_opt_loss": -8.532000084286151, "train/adv_mag": 0.3781602870726931, "train/adv_max": 0.34891402743000915, "train/adv_mean": 0.0014713798718467065, "train/adv_min": -0.2992789007831311, "train/adv_std": 0.03863993789190832, "train/cont_avg": 0.9959168365036232, "train/cont_loss_mean": 9.830334591858933e-05, "train/cont_loss_std": 0.003029665754334711, "train/cont_neg_acc": 0.9971014494481294, "train/cont_neg_loss": 0.0086500304228633, "train/cont_pos_acc": 0.9999715426693792, "train/cont_pos_loss": 5.746417571565441e-05, "train/cont_pred": 0.99590088578238, "train/cont_rate": 0.9959168365036232, "train/dyn_loss_mean": 12.832803961159527, "train/dyn_loss_std": 9.332942907361018, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9546574928622314, "train/extr_critic_critic_opt_grad_steps": 103275.0, "train/extr_critic_critic_opt_loss": 14729.338102921196, "train/extr_critic_mag": 10.645839342172595, "train/extr_critic_max": 10.645839342172595, "train/extr_critic_mean": 2.262449048999427, "train/extr_critic_min": -0.2542270655217378, "train/extr_critic_std": 2.5488429980865424, "train/extr_return_normed_mag": 1.466924760652625, "train/extr_return_normed_max": 1.466924760652625, "train/extr_return_normed_mean": 0.29887561824010767, "train/extr_return_normed_min": -0.05122109783975327, "train/extr_return_normed_std": 0.3237758194082889, "train/extr_return_rate": 0.6815510256134946, "train/extr_return_raw_mag": 11.542861185212066, "train/extr_return_raw_max": 11.542861185212066, "train/extr_return_raw_mean": 2.274123044549555, "train/extr_return_raw_min": -0.5037183407424153, "train/extr_return_raw_std": 2.5692550786163495, "train/extr_reward_mag": 1.0524727658949036, "train/extr_reward_max": 1.0524727658949036, "train/extr_reward_mean": 0.041416388207479664, "train/extr_reward_min": -0.412504898465198, "train/extr_reward_std": 0.1906520676785621, "train/image_loss_mean": 6.323823600575544, "train/image_loss_std": 12.025145029676134, "train/model_loss_mean": 14.088145276774531, "train/model_loss_std": 15.795348146687383, "train/model_opt_grad_norm": 44.17563045888707, "train/model_opt_grad_steps": 103183.44927536232, "train/model_opt_loss": 18113.283903702446, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1286.231884057971, "train/policy_entropy_mag": 2.689158824906833, "train/policy_entropy_max": 2.689158824906833, "train/policy_entropy_mean": 0.922519298783247, "train/policy_entropy_min": 0.07937502245540204, "train/policy_entropy_std": 0.9648246652838113, "train/policy_logprob_mag": 7.438383879868881, "train/policy_logprob_max": -0.009455659278277039, "train/policy_logprob_mean": -0.9221402365660322, "train/policy_logprob_min": -7.438383879868881, "train/policy_logprob_std": 1.2938241457593613, "train/policy_randomness_mag": 0.9491550585497981, "train/policy_randomness_max": 0.9491550585497981, "train/policy_randomness_mean": 0.3256088294412779, "train/policy_randomness_min": 0.02801589968789747, "train/policy_randomness_std": 0.34054077017134515, "train/post_ent_mag": 61.85742469455885, "train/post_ent_max": 61.85742469455885, "train/post_ent_mean": 43.992236676423445, "train/post_ent_min": 20.33805274963379, "train/post_ent_std": 7.912324535673943, "train/prior_ent_mag": 71.10495172030684, "train/prior_ent_max": 71.10495172030684, "train/prior_ent_mean": 56.89825881736866, "train/prior_ent_min": 40.47758948284647, "train/prior_ent_std": 4.949026284010514, "train/rep_loss_mean": 12.832803961159527, "train/rep_loss_std": 9.332942907361018, "train/reward_avg": 0.04111823443647312, "train/reward_loss_mean": 0.06454114899363207, "train/reward_loss_std": 0.254580303594686, "train/reward_max_data": 1.034057979134546, "train/reward_max_pred": 1.028508016164752, "train/reward_neg_acc": 0.9911190776721291, "train/reward_neg_loss": 0.030835436562589115, "train/reward_pos_acc": 0.980554944795111, "train/reward_pos_loss": 0.789793751809908, "train/reward_pred": 0.04020319198784621, "train/reward_rate": 0.044645889945652176, "train_stats/sum_log_reward": 10.919149190821546, "train_stats/max_log_achievement_collect_coal": 0.9361702127659575, "train_stats/max_log_achievement_collect_drink": 5.691489361702128, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.6808510638297873, "train_stats/max_log_achievement_collect_stone": 13.27659574468085, "train_stats/max_log_achievement_collect_wood": 9.691489361702128, "train_stats/max_log_achievement_defeat_skeleton": 0.0851063829787234, "train_stats/max_log_achievement_defeat_zombie": 1.3936170212765957, "train_stats/max_log_achievement_eat_cow": 0.5425531914893617, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.05319148936170213, "train_stats/max_log_achievement_make_stone_sword": 0.0425531914893617, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4680851063829787, "train_stats/max_log_achievement_make_wood_sword": 1.1170212765957446, "train_stats/max_log_achievement_place_furnace": 2.074468085106383, "train_stats/max_log_achievement_place_plant": 1.5957446808510638, "train_stats/max_log_achievement_place_stone": 3.148936170212766, "train_stats/max_log_achievement_place_table": 2.627659574468085, "train_stats/max_log_achievement_wake_up": 1.5, "train_stats/mean_log_entropy": 0.6829285222165128, "eval_stats/sum_log_reward": 11.287500262260437, "eval_stats/max_log_achievement_collect_coal": 0.9375, "eval_stats/max_log_achievement_collect_drink": 4.1875, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.4375, "eval_stats/max_log_achievement_collect_stone": 15.375, "eval_stats/max_log_achievement_collect_wood": 10.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 2.0, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.625, "eval_stats/max_log_achievement_make_wood_sword": 1.0625, "eval_stats/max_log_achievement_place_furnace": 2.5625, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 3.4375, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00021391082555055618, "report/cont_loss_std": 0.006804253440350294, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.04378875344991684, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.902284858753774e-08, "report/cont_pred": 0.9953093528747559, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 9.531675338745117, "report/dyn_loss_std": 8.777698516845703, "report/image_loss_mean": 4.8210248947143555, "report/image_loss_std": 8.229053497314453, "report/model_loss_mean": 10.602045059204102, "report/model_loss_std": 11.87373161315918, "report/post_ent_mag": 59.06781768798828, "report/post_ent_max": 59.06781768798828, "report/post_ent_mean": 46.433223724365234, "report/post_ent_min": 19.617231369018555, "report/post_ent_std": 7.4479780197143555, "report/prior_ent_mag": 71.21592712402344, "report/prior_ent_max": 71.21592712402344, "report/prior_ent_mean": 56.12665557861328, "report/prior_ent_min": 42.83704376220703, "report/prior_ent_std": 4.845927715301514, "report/rep_loss_mean": 9.531675338745117, "report/rep_loss_std": 8.777698516845703, "report/reward_avg": 0.04814453050494194, "report/reward_loss_mean": 0.06180226430296898, "report/reward_loss_std": 0.21408186852931976, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0064692497253418, "report/reward_neg_acc": 0.9979424476623535, "report/reward_neg_loss": 0.024507757276296616, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7589227557182312, "report/reward_pred": 0.046008650213479996, "report/reward_rate": 0.05078125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 4.367115309378278e-07, "eval/cont_loss_std": 6.5925646595133e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00011900875688297674, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.831182185531361e-08, "eval/cont_pred": 0.9970706105232239, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.222307205200195, "eval/dyn_loss_std": 11.32395076751709, "eval/image_loss_mean": 9.764886856079102, "eval/image_loss_std": 13.722586631774902, "eval/model_loss_mean": 19.59912872314453, "eval/model_loss_std": 18.10133171081543, "eval/post_ent_mag": 62.93293380737305, "eval/post_ent_max": 62.93293380737305, "eval/post_ent_mean": 43.156429290771484, "eval/post_ent_min": 19.55316162109375, "eval/post_ent_std": 8.60610294342041, "eval/prior_ent_mag": 70.7448959350586, "eval/prior_ent_max": 70.7448959350586, "eval/prior_ent_mean": 57.54298400878906, "eval/prior_ent_min": 44.3465576171875, "eval/prior_ent_std": 4.424837589263916, "eval/rep_loss_mean": 16.222307205200195, "eval/rep_loss_std": 11.32395076751709, "eval/reward_avg": 0.06074219197034836, "eval/reward_loss_mean": 0.10085953772068024, "eval/reward_loss_std": 0.4155649244785309, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017938613891602, "eval/reward_neg_acc": 0.9853862524032593, "eval/reward_neg_loss": 0.04352029040455818, "eval/reward_pos_acc": 0.939393937587738, "eval/reward_pos_loss": 0.9331474900245667, "eval/reward_pred": 0.0586262010037899, "eval/reward_rate": 0.064453125, "replay/size": 1000000.0, "replay/inserts": 22224.0, "replay/samples": 22224.0, "replay/insert_wait_avg": 1.371979627616119e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.140711410170927e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4672.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2794586077128372e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1065628528595, "timer/env.step_count": 2778.0, "timer/env.step_total": 236.61530423164368, "timer/env.step_frac": 0.23659009251642685, "timer/env.step_avg": 0.0851746955477479, "timer/env.step_min": 0.02454996109008789, "timer/env.step_max": 3.5594124794006348, "timer/replay._sample_count": 22224.0, "timer/replay._sample_total": 11.52528691291809, "timer/replay._sample_frac": 0.011524058876327709, "timer/replay._sample_avg": 0.0005185964233674447, "timer/replay._sample_min": 0.00039505958557128906, "timer/replay._sample_max": 0.013297080993652344, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3362.0, "timer/agent.policy_total": 59.91077947616577, "timer/agent.policy_frac": 0.059904395892840606, "timer/agent.policy_avg": 0.017819981997669772, "timer/agent.policy_min": 0.009879589080810547, "timer/agent.policy_max": 0.23034381866455078, "timer/dataset_train_count": 1389.0, "timer/dataset_train_total": 0.1549999713897705, "timer/dataset_train_frac": 0.00015498345591056264, "timer/dataset_train_avg": 0.00011159105211646545, "timer/dataset_train_min": 9.72747802734375e-05, "timer/dataset_train_max": 0.001032114028930664, "timer/agent.train_count": 1389.0, "timer/agent.train_total": 627.0433232784271, "timer/agent.train_frac": 0.6269765108727526, "timer/agent.train_avg": 0.4514350779542312, "timer/agent.train_min": 0.4388394355773926, "timer/agent.train_max": 1.7460155487060547, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4944148063659668, "timer/agent.report_frac": 0.0004943621257275036, "timer/agent.report_avg": 0.2472074031829834, "timer/agent.report_min": 0.24698615074157715, "timer/agent.report_max": 0.24742865562438965, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8130394678875332e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 22.221260927437356}
{"step": 1665200, "time": 75471.90042304993, "episode/length": 227.0, "episode/score": 13.099999994039536, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1665408, "time": 75480.54967594147, "episode/length": 430.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 1665448, "time": 75483.33219146729, "episode/length": 57.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 1665688, "time": 75493.15995144844, "episode/length": 168.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 1665736, "time": 75496.5225982666, "episode/length": 244.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 1666480, "time": 75523.51462674141, "episode/length": 159.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 1667208, "time": 75549.6841161251, "episode/length": 183.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 1667232, "time": 75552.39018774033, "episode/length": 227.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1667328, "time": 75557.34119534492, "episode/length": 204.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 1667384, "time": 75560.60012054443, "episode/length": 424.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9976470588235294, "episode/intrinsic_return": 0.0}
{"step": 1667416, "time": 75563.31768107414, "episode/length": 382.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9921671018276762, "episode/intrinsic_return": 0.0}
{"step": 1668320, "time": 75595.71177268028, "episode/length": 417.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9976076555023924, "episode/intrinsic_return": 0.0}
{"step": 1668448, "time": 75601.85742688179, "episode/length": 154.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 1669056, "time": 75624.16036295891, "episode/length": 208.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 1669456, "time": 75639.41482019424, "episode/length": 265.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 1669688, "time": 75648.73317527771, "episode/length": 529.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9981132075471698, "episode/intrinsic_return": 0.0}
{"step": 1669792, "time": 75654.15339827538, "episode/length": 319.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.996875, "episode/intrinsic_return": 0.0}
{"step": 1669880, "time": 75658.52993106842, "episode/length": 194.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 1670032, "time": 75686.13299512863, "eval_episode/length": 158.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 1670032, "time": 75688.57385230064, "eval_episode/length": 174.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9657142857142857}
{"step": 1670032, "time": 75690.35771250725, "eval_episode/length": 175.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9659090909090909}
{"step": 1670032, "time": 75692.92882680893, "eval_episode/length": 195.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 1670032, "time": 75698.96252584457, "eval_episode/length": 293.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 1670032, "time": 75701.06201672554, "eval_episode/length": 108.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.963302752293578}
{"step": 1670032, "time": 75703.75027179718, "eval_episode/length": 152.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9607843137254902}
{"step": 1670032, "time": 75708.0129582882, "eval_episode/length": 382.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9869451697127938}
{"step": 1670568, "time": 75726.0037047863, "episode/length": 138.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9568345323741008, "episode/intrinsic_return": 0.0}
{"step": 1670656, "time": 75730.70223665237, "episode/length": 107.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 1670832, "time": 75738.34422922134, "episode/length": 426.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9976580796252927, "episode/intrinsic_return": 0.0}
{"step": 1671024, "time": 75746.35753750801, "episode/length": 567.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9841549295774648, "episode/intrinsic_return": 0.0}
{"step": 1671880, "time": 75778.81362986565, "episode/length": 249.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 1671968, "time": 75784.00367975235, "episode/length": 174.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9828571428571429, "episode/intrinsic_return": 0.0}
{"step": 1672344, "time": 75798.30392622948, "episode/length": 46.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 1672416, "time": 75802.55130553246, "episode/length": 197.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 1672504, "time": 75807.04830694199, "episode/length": 506.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9861932938856016, "episode/intrinsic_return": 0.0}
{"step": 1672592, "time": 75811.84478616714, "episode/length": 441.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9841628959276018, "episode/intrinsic_return": 0.0}
{"step": 1672928, "time": 75824.77777314186, "episode/length": 63.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.921875, "episode/intrinsic_return": 0.0}
{"step": 1673504, "time": 75846.09672832489, "episode/length": 355.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9859550561797753, "episode/intrinsic_return": 0.0}
{"step": 1673624, "time": 75851.49642515182, "episode/length": 139.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 1673648, "time": 75854.14084506035, "episode/length": 327.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1674296, "time": 75877.77220106125, "episode/length": 212.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 1674368, "time": 75882.06627488136, "episode/length": 179.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 1674712, "time": 75895.21395516396, "episode/length": 295.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 1674784, "time": 75899.54063868523, "episode/length": 636.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9984301412872841, "episode/intrinsic_return": 0.0}
{"step": 1675008, "time": 75908.68998193741, "episode/length": 169.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1675520, "time": 75927.74224972725, "episode/length": 236.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9704641350210971, "episode/intrinsic_return": 0.0}
{"step": 1675976, "time": 75944.61687898636, "episode/length": 200.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 1676560, "time": 75966.33483862877, "episode/length": 230.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 1676648, "time": 75970.76281571388, "episode/length": 595.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9848993288590604, "episode/intrinsic_return": 0.0}
{"step": 1676688, "time": 75973.95814919472, "episode/length": 298.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.0}
{"step": 1676904, "time": 75982.69746303558, "episode/length": 264.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 1677072, "time": 75990.24798631668, "episode/length": 445.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 1677768, "time": 76015.2216463089, "episode/length": 280.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 1678032, "time": 76025.9864127636, "episode/length": 167.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 1678088, "time": 76029.22985434532, "episode/length": 190.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 1678136, "time": 76032.36632847786, "episode/length": 185.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 1678240, "time": 76037.76161456108, "episode/length": 282.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 1678480, "time": 76047.58010482788, "episode/length": 196.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 1678640, "time": 76054.63087821007, "episode/length": 195.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 1679408, "time": 76084.16689276695, "episode/length": 549.0, "episode/score": 14.099999994039536, "episode/reward_rate": 0.9981818181818182, "episode/intrinsic_return": 0.0}
{"step": 1679952, "time": 76104.23376584053, "episode/length": 272.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 1680016, "time": 76122.59786367416, "eval_episode/length": 38.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 1680016, "time": 76130.30480003357, "eval_episode/length": 171.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 1680016, "time": 76132.92741966248, "eval_episode/length": 192.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 1680016, "time": 76134.78334355354, "eval_episode/length": 198.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.964824120603015}
{"step": 1680016, "time": 76137.84712338448, "eval_episode/length": 192.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 1680016, "time": 76140.09731507301, "eval_episode/length": 244.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 1680016, "time": 76142.79657030106, "eval_episode/length": 273.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9708029197080292}
{"step": 1680016, "time": 76145.66127705574, "eval_episode/length": 302.0, "eval_episode/score": 12.099999994039536, "eval_episode/reward_rate": 0.9966996699669967}
{"step": 1680144, "time": 76150.01707434654, "episode/length": 250.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 1680464, "time": 76162.41267323494, "episode/length": 303.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 1680704, "time": 76172.02483487129, "episode/length": 307.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9967532467532467, "episode/intrinsic_return": 0.0}
{"step": 1680976, "time": 76182.7930316925, "episode/length": 311.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9967948717948718, "episode/intrinsic_return": 0.0}
{"step": 1681168, "time": 76191.03319692612, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1681280, "time": 76196.55162000656, "episode/length": 101.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 1681936, "time": 76220.37642002106, "episode/length": 411.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9975728155339806, "episode/intrinsic_return": 0.0}
{"step": 1682104, "time": 76227.55914592743, "episode/length": 268.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 1682192, "time": 76232.37848758698, "episode/length": 185.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 1682216, "time": 76234.55529808998, "episode/length": 154.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 1682232, "time": 76236.64415740967, "episode/length": 260.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9731800766283525, "episode/intrinsic_return": 0.0}
{"step": 1682888, "time": 76260.49894142151, "episode/length": 599.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.985, "episode/intrinsic_return": 0.0}
{"step": 1683496, "time": 76282.70891237259, "episode/length": 157.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 1683576, "time": 76286.97515845299, "episode/length": 204.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 1683584, "time": 76289.07176566124, "episode/length": 184.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 1683888, "time": 76300.92347860336, "episode/length": 339.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1684136, "time": 76310.97775745392, "episode/length": 239.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 1684624, "time": 76329.4549844265, "episode/length": 91.0, "episode/score": 11.1000000461936, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 1684784, "time": 76336.69121146202, "episode/length": 236.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 1685000, "time": 76345.38131332397, "episode/length": 464.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9978494623655914, "episode/intrinsic_return": 0.0}
{"step": 1685232, "time": 76355.13581752777, "episode/length": 206.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 1685344, "time": 76360.52024912834, "episode/length": 69.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 1685376, "time": 76363.16096329689, "episode/length": 223.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1685768, "time": 76378.00178456306, "episode/length": 203.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 1686304, "time": 76398.0507748127, "episode/length": 350.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9857549857549858, "episode/intrinsic_return": 0.0}
{"step": 1686448, "time": 76404.54618215561, "episode/length": 531.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9981203007518797, "episode/intrinsic_return": 0.0}
{"step": 1686536, "time": 76408.96406269073, "episode/length": 238.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 1686696, "time": 76416.03677201271, "episode/length": 211.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 1686808, "time": 76421.36487960815, "episode/length": 182.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 1686864, "time": 76425.14766144753, "episode/length": 185.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 1687112, "time": 76435.01102876663, "episode/length": 234.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1687760, "time": 76460.66444087029, "episode/length": 248.0, "episode/score": 14.100000023841858, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 1687873, "time": 76466.72552871704, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.059856281413898, "train/action_min": 0.0, "train/action_std": 3.8902571601467533, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.025286891152496105, "train/actor_opt_grad_steps": 104680.0, "train/actor_opt_loss": -7.534302909917139, "train/adv_mag": 0.38493082646306576, "train/adv_max": 0.3322581027771209, "train/adv_mean": 0.0014263049003596286, "train/adv_min": -0.3229112590734775, "train/adv_std": 0.03912353786555203, "train/cont_avg": 0.9962030157342657, "train/cont_loss_mean": 0.00012085958754825865, "train/cont_loss_std": 0.0035406640302877808, "train/cont_neg_acc": 0.9944444446698993, "train/cont_neg_loss": 0.013582421186764424, "train/cont_pos_acc": 0.9999794088877164, "train/cont_pos_loss": 6.95287737198455e-05, "train/cont_pred": 0.9961824779743915, "train/cont_rate": 0.9962030157342657, "train/dyn_loss_mean": 12.764493348715188, "train/dyn_loss_std": 9.299062382091176, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9406766262087789, "train/extr_critic_critic_opt_grad_steps": 104680.0, "train/extr_critic_critic_opt_loss": 14869.505791083917, "train/extr_critic_mag": 10.67331812265036, "train/extr_critic_max": 10.67331812265036, "train/extr_critic_mean": 2.251793664652151, "train/extr_critic_min": -0.23541411153086417, "train/extr_critic_std": 2.5343076249102614, "train/extr_return_normed_mag": 1.4773685473662157, "train/extr_return_normed_max": 1.4773685473662157, "train/extr_return_normed_mean": 0.2965279975971142, "train/extr_return_normed_min": -0.05491803889976932, "train/extr_return_normed_std": 0.3235789479075612, "train/extr_return_rate": 0.6855455445242928, "train/extr_return_raw_mag": 11.592310111839454, "train/extr_return_raw_max": 11.592310111839454, "train/extr_return_raw_mean": 2.263069019451008, "train/extr_return_raw_min": -0.514127277827763, "train/extr_return_raw_std": 2.557078465715155, "train/extr_reward_mag": 1.055171219619004, "train/extr_reward_max": 1.055171219619004, "train/extr_reward_mean": 0.042019690927508825, "train/extr_reward_min": -0.4510551866117891, "train/extr_reward_std": 0.19258721714670007, "train/image_loss_mean": 6.180035077608549, "train/image_loss_std": 11.68035627578522, "train/model_loss_mean": 13.901204415968248, "train/model_loss_std": 15.455694065227375, "train/model_opt_grad_norm": 41.60166098366321, "train/model_opt_grad_steps": 104587.1048951049, "train/model_opt_loss": 18121.074116313375, "train/model_opt_model_opt_grad_overflow": 0.006993006993006993, "train/model_opt_model_opt_grad_scale": 1293.7062937062938, "train/policy_entropy_mag": 2.69698850258247, "train/policy_entropy_max": 2.69698850258247, "train/policy_entropy_mean": 0.9054991890500476, "train/policy_entropy_min": 0.07937502058652732, "train/policy_entropy_std": 0.9594225591712898, "train/policy_logprob_mag": 7.438383869357876, "train/policy_logprob_max": -0.009455658391222253, "train/policy_logprob_mean": -0.9061741139088477, "train/policy_logprob_min": -7.438383869357876, "train/policy_logprob_std": 1.2960705565405892, "train/policy_randomness_mag": 0.9519185894852752, "train/policy_randomness_max": 0.9519185894852752, "train/policy_randomness_mean": 0.31960147952699997, "train/policy_randomness_min": 0.02801589907466115, "train/policy_randomness_std": 0.3386340612298125, "train/post_ent_mag": 61.906271180906494, "train/post_ent_max": 61.906271180906494, "train/post_ent_mean": 43.85993359972547, "train/post_ent_min": 20.27212607110297, "train/post_ent_std": 7.884185737663215, "train/prior_ent_mag": 71.05189439466783, "train/prior_ent_max": 71.05189439466783, "train/prior_ent_mean": 56.73070173997145, "train/prior_ent_min": 40.24533964037062, "train/prior_ent_std": 4.89566083387895, "train/rep_loss_mean": 12.764493348715188, "train/rep_loss_std": 9.299062382091176, "train/reward_avg": 0.04095143143582594, "train/reward_loss_mean": 0.062352389461927483, "train/reward_loss_std": 0.24815665602267206, "train/reward_max_data": 1.031468538971214, "train/reward_max_pred": 1.0242734305508487, "train/reward_neg_acc": 0.9917432378222059, "train/reward_neg_loss": 0.028979250106152956, "train/reward_pos_acc": 0.98163133026003, "train/reward_pos_loss": 0.7835196385850439, "train/reward_pred": 0.040280763737180016, "train/reward_rate": 0.044423350087412584, "train_stats/sum_log_reward": 11.017647322486429, "train_stats/max_log_achievement_collect_coal": 0.8117647058823529, "train_stats/max_log_achievement_collect_drink": 6.929411764705883, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.6941176470588235, "train_stats/max_log_achievement_collect_stone": 14.188235294117646, "train_stats/max_log_achievement_collect_wood": 10.305882352941177, "train_stats/max_log_achievement_defeat_skeleton": 0.03529411764705882, "train_stats/max_log_achievement_defeat_zombie": 1.3294117647058823, "train_stats/max_log_achievement_eat_cow": 0.5764705882352941, "train_stats/max_log_achievement_eat_plant": 0.011764705882352941, "train_stats/max_log_achievement_make_stone_pickaxe": 0.07058823529411765, "train_stats/max_log_achievement_make_stone_sword": 0.047058823529411764, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4352941176470588, "train_stats/max_log_achievement_make_wood_sword": 1.1764705882352942, "train_stats/max_log_achievement_place_furnace": 2.364705882352941, "train_stats/max_log_achievement_place_plant": 1.5411764705882354, "train_stats/max_log_achievement_place_stone": 3.4705882352941178, "train_stats/max_log_achievement_place_table": 2.835294117647059, "train_stats/max_log_achievement_wake_up": 1.8823529411764706, "train_stats/mean_log_entropy": 0.7513316983685774, "eval_stats/sum_log_reward": 10.787500232458115, "eval_stats/max_log_achievement_collect_coal": 0.75, "eval_stats/max_log_achievement_collect_drink": 4.875, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.5625, "eval_stats/max_log_achievement_collect_stone": 11.6875, "eval_stats/max_log_achievement_collect_wood": 8.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 2.1875, "eval_stats/max_log_achievement_eat_cow": 0.4375, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 0.9375, "eval_stats/max_log_achievement_place_furnace": 2.0625, "eval_stats/max_log_achievement_place_plant": 1.5625, "eval_stats/max_log_achievement_place_stone": 2.1875, "eval_stats/max_log_achievement_place_table": 2.3125, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 2.113309528795071e-05, "report/cont_loss_std": 0.000604769738856703, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.01930926740169525, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.278613465023227e-06, "report/cont_pred": 0.9990399479866028, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 12.155516624450684, "report/dyn_loss_std": 9.350699424743652, "report/image_loss_mean": 5.261421203613281, "report/image_loss_std": 12.503364562988281, "report/model_loss_mean": 12.605899810791016, "report/model_loss_std": 16.411556243896484, "report/post_ent_mag": 61.37118911743164, "report/post_ent_max": 61.37118911743164, "report/post_ent_mean": 44.55042266845703, "report/post_ent_min": 20.919832229614258, "report/post_ent_std": 8.167264938354492, "report/prior_ent_mag": 70.93358612060547, "report/prior_ent_max": 70.93358612060547, "report/prior_ent_mean": 56.743507385253906, "report/prior_ent_min": 43.71393585205078, "report/prior_ent_std": 4.451900959014893, "report/rep_loss_mean": 12.155516624450684, "report/rep_loss_std": 9.350699424743652, "report/reward_avg": 0.03818359225988388, "report/reward_loss_mean": 0.05114737153053284, "report/reward_loss_std": 0.1882443130016327, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0005464553833008, "report/reward_neg_acc": 0.9908443689346313, "report/reward_neg_loss": 0.023221462965011597, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.7206880450248718, "report/reward_pred": 0.03894448280334473, "report/reward_rate": 0.0400390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 6.740568778695888e-07, "eval/cont_loss_std": 3.6589578940038336e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 4.169838211964816e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.535152922675479e-07, "eval/cont_pred": 0.9970700144767761, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 15.871553421020508, "eval/dyn_loss_std": 11.169987678527832, "eval/image_loss_mean": 8.534297943115234, "eval/image_loss_std": 13.46153736114502, "eval/model_loss_mean": 18.184192657470703, "eval/model_loss_std": 17.873153686523438, "eval/post_ent_mag": 61.23200988769531, "eval/post_ent_max": 61.23200988769531, "eval/post_ent_mean": 43.112152099609375, "eval/post_ent_min": 21.008960723876953, "eval/post_ent_std": 8.167630195617676, "eval/prior_ent_mag": 70.93358612060547, "eval/prior_ent_max": 70.93358612060547, "eval/prior_ent_mean": 56.689453125, "eval/prior_ent_min": 43.99205780029297, "eval/prior_ent_std": 4.718630313873291, "eval/rep_loss_mean": 15.871553421020508, "eval/rep_loss_std": 11.169987678527832, "eval/reward_avg": 0.05830077826976776, "eval/reward_loss_mean": 0.12696200609207153, "eval/reward_loss_std": 0.5236336588859558, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0025990009307861, "eval/reward_neg_acc": 0.9771072268486023, "eval/reward_neg_loss": 0.05950770899653435, "eval/reward_pos_acc": 0.8571429252624512, "eval/reward_pos_loss": 1.1559077501296997, "eval/reward_pred": 0.05562100559473038, "eval/reward_rate": 0.0615234375, "replay/size": 1000000.0, "replay/inserts": 22824.0, "replay/samples": 22816.0, "replay/insert_wait_avg": 1.3566480951479681e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.278922145196131e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5488.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2642527460704393e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9740319252014, "timer/env.step_count": 2853.0, "timer/env.step_total": 219.72645545005798, "timer/env.step_frac": 0.21973216147126273, "timer/env.step_avg": 0.0770159325096593, "timer/env.step_min": 0.024576425552368164, "timer/env.step_max": 1.9641869068145752, "timer/replay._sample_count": 22816.0, "timer/replay._sample_total": 11.912092208862305, "timer/replay._sample_frac": 0.011912401550996812, "timer/replay._sample_avg": 0.0005220938029830954, "timer/replay._sample_min": 0.0004336833953857422, "timer/replay._sample_max": 0.019189834594726562, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3539.0, "timer/agent.policy_total": 61.56165432929993, "timer/agent.policy_frac": 0.06156325300845889, "timer/agent.policy_avg": 0.01739521173475556, "timer/agent.policy_min": 0.009922504425048828, "timer/agent.policy_max": 0.1037750244140625, "timer/dataset_train_count": 1426.0, "timer/dataset_train_total": 0.15917229652404785, "timer/dataset_train_frac": 0.00015917643002948904, "timer/dataset_train_avg": 0.00011162152631419906, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.000820159912109375, "timer/agent.train_count": 1426.0, "timer/agent.train_total": 644.2552466392517, "timer/agent.train_frac": 0.6442719771421448, "timer/agent.train_avg": 0.4517918980639914, "timer/agent.train_min": 0.43641114234924316, "timer/agent.train_max": 1.8769605159759521, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47571611404418945, "timer/agent.report_frac": 0.00047572846779662503, "timer/agent.report_avg": 0.23785805702209473, "timer/agent.report_min": 0.23011231422424316, "timer/agent.report_max": 0.2456037998199463, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9803096316729696e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 22.82426018532568}
{"step": 1688136, "time": 76475.7682030201, "episode/length": 179.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 1688232, "time": 76480.60045409203, "episode/length": 240.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 1688408, "time": 76488.4021821022, "episode/length": 233.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 1688656, "time": 76498.88048672676, "episode/length": 230.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 1688744, "time": 76503.22578883171, "episode/length": 203.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 1688984, "time": 76512.88954305649, "episode/length": 316.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9968454258675079, "episode/intrinsic_return": 0.0}
{"step": 1689008, "time": 76515.49644422531, "episode/length": 155.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1689536, "time": 76535.14172244072, "episode/length": 162.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 1690000, "time": 76574.34766483307, "eval_episode/length": 153.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9805194805194806}
{"step": 1690000, "time": 76577.07405304909, "eval_episode/length": 170.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 1690000, "time": 76578.7899851799, "eval_episode/length": 174.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 1690000, "time": 76581.84629535675, "eval_episode/length": 205.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 1690000, "time": 76583.95587229729, "eval_episode/length": 217.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 1690000, "time": 76588.502982378, "eval_episode/length": 279.0, "eval_episode/score": 12.100000023841858, "eval_episode/reward_rate": 0.9964285714285714}
{"step": 1690000, "time": 76594.0616633892, "eval_episode/length": 366.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.989100817438692}
{"step": 1690000, "time": 76596.01215672493, "eval_episode/length": 218.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9771689497716894}
{"step": 1690104, "time": 76599.33185839653, "episode/length": 211.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 1690392, "time": 76610.83116841316, "episode/length": 216.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1690400, "time": 76612.87835788727, "episode/length": 282.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9752650176678446, "episode/intrinsic_return": 0.0}
{"step": 1690480, "time": 76617.14141559601, "episode/length": 451.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 1690576, "time": 76621.97706890106, "episode/length": 228.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 1690640, "time": 76625.75077009201, "episode/length": 203.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 1691016, "time": 76639.9787414074, "episode/length": 253.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 1691264, "time": 76650.14743423462, "episode/length": 108.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9541284403669725, "episode/intrinsic_return": 0.0}
{"step": 1692528, "time": 76694.7917060852, "episode/length": 302.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.976897689768977, "episode/intrinsic_return": 0.0}
{"step": 1692776, "time": 76704.99113845825, "episode/length": 219.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 1693120, "time": 76718.63037538528, "episode/length": 447.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9977678571428571, "episode/intrinsic_return": 0.0}
{"step": 1693120, "time": 76718.6404800415, "episode/length": 309.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 1693208, "time": 76724.79908776283, "episode/length": 328.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9878419452887538, "episode/intrinsic_return": 0.0}
{"step": 1693904, "time": 76750.26488375664, "episode/length": 427.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9929906542056075, "episode/intrinsic_return": 0.0}
{"step": 1693928, "time": 76752.50448870659, "episode/length": 332.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.996996996996997, "episode/intrinsic_return": 0.0}
{"step": 1694544, "time": 76775.27370524406, "episode/length": 177.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 1694656, "time": 76780.59983420372, "episode/length": 531.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 1694800, "time": 76787.22188973427, "episode/length": 209.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 1695184, "time": 76801.91294717789, "episode/length": 331.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9969879518072289, "episode/intrinsic_return": 0.0}
{"step": 1695376, "time": 76809.9920732975, "episode/length": 183.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 1695424, "time": 76813.13586449623, "episode/length": 109.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 1695528, "time": 76818.13620305061, "episode/length": 343.0, "episode/score": 13.100000038743019, "episode/reward_rate": 0.997093023255814, "episode/intrinsic_return": 0.0}
{"step": 1695992, "time": 76837.369805336, "episode/length": 100.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1696192, "time": 76846.0082552433, "episode/length": 191.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 1696384, "time": 76854.2540473938, "episode/length": 306.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 1696464, "time": 76858.60195446014, "episode/length": 406.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9901719901719902, "episode/intrinsic_return": 0.0}
{"step": 1697016, "time": 76878.81712937355, "episode/length": 276.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9711191335740073, "episode/intrinsic_return": 0.0}
{"step": 1697216, "time": 76887.54858016968, "episode/length": 223.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1697240, "time": 76889.69818973541, "episode/length": 232.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 1697320, "time": 76893.96004486084, "episode/length": 223.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 1697512, "time": 76902.00718569756, "episode/length": 189.0, "episode/score": 13.100000016391277, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 1697600, "time": 76906.98943924904, "episode/length": 175.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 1697616, "time": 76909.18625855446, "episode/length": 46.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 1698208, "time": 76930.79253149033, "episode/length": 148.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 1698328, "time": 76936.55361104012, "episode/length": 242.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 1698576, "time": 76946.89398002625, "episode/length": 263.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 1698936, "time": 76960.41819620132, "episode/length": 164.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 1699344, "time": 76976.25464344025, "episode/length": 217.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1699464, "time": 76981.68988370895, "episode/length": 156.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9554140127388535, "episode/intrinsic_return": 0.0}
{"step": 1699552, "time": 76986.54877734184, "episode/length": 291.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.976027397260274, "episode/intrinsic_return": 0.0}
{"step": 1700088, "time": 77024.5673289299, "eval_episode/length": 117.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9915254237288136}
{"step": 1700088, "time": 77027.21642565727, "eval_episode/length": 136.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 1700088, "time": 77031.24333572388, "eval_episode/length": 187.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 1700088, "time": 77033.64898896217, "eval_episode/length": 203.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 1700088, "time": 77036.3477036953, "eval_episode/length": 227.0, "eval_episode/score": 14.100000008940697, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 1700088, "time": 77039.6425921917, "eval_episode/length": 264.0, "eval_episode/score": 13.100000008940697, "eval_episode/reward_rate": 0.9962264150943396}
{"step": 1700088, "time": 77042.81544399261, "eval_episode/length": 163.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 1700088, "time": 77048.68532013893, "eval_episode/length": 277.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9964028776978417}
{"step": 1700136, "time": 77050.34208345413, "episode/length": 351.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 1700160, "time": 77053.04312491417, "episode/length": 228.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 1700272, "time": 77058.40582466125, "episode/length": 344.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9971014492753624, "episode/intrinsic_return": 0.0}
{"step": 1700520, "time": 77068.17953324318, "episode/length": 47.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 1700752, "time": 77077.93048262596, "episode/length": 226.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 1701120, "time": 77092.13143372536, "episode/length": 206.0, "episode/score": 13.099999971687794, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 1701160, "time": 77094.90683174133, "episode/length": 200.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 1701536, "time": 77109.36695861816, "episode/length": 171.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 1701848, "time": 77121.20854783058, "episode/length": 312.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.987220447284345, "episode/intrinsic_return": 0.0}
{"step": 1702184, "time": 77134.1431491375, "episode/length": 178.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 1702328, "time": 77140.72957634926, "episode/length": 468.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.997867803837953, "episode/intrinsic_return": 0.0}
{"step": 1702968, "time": 77164.11974143982, "episode/length": 230.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 1703168, "time": 77172.88008213043, "episode/length": 361.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9834254143646409, "episode/intrinsic_return": 0.0}
{"step": 1703208, "time": 77175.70287394524, "episode/length": 255.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 1703392, "time": 77183.98517537117, "episode/length": 231.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 1703456, "time": 77187.71914100647, "episode/length": 60.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 1703472, "time": 77189.89962077141, "episode/length": 160.0, "episode/score": 12.1000000461936, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 1703704, "time": 77198.94777154922, "episode/length": 231.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 1704040, "time": 77213.60609579086, "episode/length": 213.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 1704960, "time": 77246.4040529728, "episode/length": 223.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1704984, "time": 77248.70572638512, "episode/length": 198.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 1705080, "time": 77253.56185817719, "episode/length": 171.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 1705152, "time": 77257.85326504707, "episode/length": 211.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 1706336, "time": 77299.42920255661, "episode/length": 286.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9965156794425087, "episode/intrinsic_return": 0.0}
{"step": 1706456, "time": 77304.92549610138, "episode/length": 183.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 1706704, "time": 77315.11444544792, "episode/length": 202.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9852216748768473, "episode/intrinsic_return": 0.0}
{"step": 1706944, "time": 77324.9334397316, "episode/length": 433.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9930875576036866, "episode/intrinsic_return": 0.0}
{"step": 1707024, "time": 77329.37015843391, "episode/length": 233.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 1707968, "time": 77362.83612442017, "episode/length": 375.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 1708056, "time": 77367.28410458565, "episode/length": 214.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 1708200, "time": 77373.77121448517, "episode/length": 959.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 1708432, "time": 77383.4309284687, "episode/length": 175.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 1708608, "time": 77391.45309233665, "episode/length": 207.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 1708624, "time": 77393.729626894, "episode/length": 239.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 1708632, "time": 77395.40467715263, "episode/length": 53.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 1708856, "time": 77404.58804750443, "episode/length": 299.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.0}
{"step": 1709016, "time": 77411.43895316124, "episode/length": 130.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 1709032, "time": 77413.53669118881, "episode/length": 727.0, "episode/score": 15.100000008940697, "episode/reward_rate": 0.9986263736263736, "episode/intrinsic_return": 0.0}
{"step": 1710072, "time": 77475.2947921753, "eval_episode/length": 252.0, "eval_episode/score": 11.100000016391277, "eval_episode/reward_rate": 0.9960474308300395}
{"step": 1710072, "time": 77482.71305418015, "eval_episode/length": 329.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9848484848484849}
{"step": 1710072, "time": 77484.50270462036, "eval_episode/length": 331.0, "eval_episode/score": 14.100000008940697, "eval_episode/reward_rate": 0.9969879518072289}
{"step": 1710072, "time": 77490.29024839401, "eval_episode/length": 427.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9976635514018691}
{"step": 1710072, "time": 77492.07868695259, "eval_episode/length": 429.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9790697674418605}
{"step": 1710072, "time": 77494.45465993881, "eval_episode/length": 446.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9955257270693513}
{"step": 1710072, "time": 77496.24635767937, "eval_episode/length": 197.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 1710072, "time": 77505.07121276855, "eval_episode/length": 281.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9858156028368794}
{"step": 1710073, "time": 77506.27659201622, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.155446004524506, "train/action_min": 0.0, "train/action_std": 3.9824513771551118, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.025618518159972677, "train/actor_opt_grad_steps": 106090.0, "train/actor_opt_loss": -7.889245288674351, "train/adv_mag": 0.4094845090838645, "train/adv_max": 0.35948732313063503, "train/adv_mean": 0.0015723430075003497, "train/adv_min": -0.338704800112642, "train/adv_std": 0.03946774704850835, "train/cont_avg": 0.9959532374100719, "train/cont_loss_mean": 0.00015862749274766992, "train/cont_loss_std": 0.00486470736748018, "train/cont_neg_acc": 0.9933574886425681, "train/cont_neg_loss": 0.01945323904016956, "train/cont_pos_acc": 0.9999788056174628, "train/cont_pos_loss": 8.509430069416879e-05, "train/cont_pred": 0.9959504184105413, "train/cont_rate": 0.9959532374100719, "train/dyn_loss_mean": 12.599992861850657, "train/dyn_loss_std": 9.26746396538165, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8997304636797459, "train/extr_critic_critic_opt_grad_steps": 106090.0, "train/extr_critic_critic_opt_loss": 14727.112824584083, "train/extr_critic_mag": 10.562411280844708, "train/extr_critic_max": 10.562411280844708, "train/extr_critic_mean": 2.227035829060369, "train/extr_critic_min": -0.24440947625276854, "train/extr_critic_std": 2.5398032905386505, "train/extr_return_normed_mag": 1.4845738745421815, "train/extr_return_normed_max": 1.4845738745421815, "train/extr_return_normed_mean": 0.2965196172753684, "train/extr_return_normed_min": -0.055914978918840556, "train/extr_return_normed_std": 0.3261296734106626, "train/extr_return_rate": 0.6803404508734778, "train/extr_return_raw_mag": 11.572259470713224, "train/extr_return_raw_max": 11.572259470713224, "train/extr_return_raw_mean": 2.239401300176442, "train/extr_return_raw_min": -0.52946628040547, "train/extr_return_raw_std": 2.562006035297037, "train/extr_reward_mag": 1.0551445209722725, "train/extr_reward_max": 1.0551445209722725, "train/extr_reward_mean": 0.042251639041326026, "train/extr_reward_min": -0.43662782452946947, "train/extr_reward_std": 0.19324725887758268, "train/image_loss_mean": 6.236000136505786, "train/image_loss_std": 12.088022417301755, "train/model_loss_mean": 13.860194631617704, "train/model_loss_std": 15.812003218012748, "train/model_opt_grad_norm": 46.497686989873436, "train/model_opt_grad_steps": 105995.85611510792, "train/model_opt_loss": 21451.948171931206, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1537.769784172662, "train/policy_entropy_mag": 2.7152932290550615, "train/policy_entropy_max": 2.7152932290550615, "train/policy_entropy_mean": 0.9382378759144021, "train/policy_entropy_min": 0.07937501751476055, "train/policy_entropy_std": 0.9764157121987651, "train/policy_logprob_mag": 7.4383839017195665, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.938448210414365, "train/policy_logprob_min": -7.4383839017195665, "train/policy_logprob_std": 1.3081790354612062, "train/policy_randomness_mag": 0.9583793522642671, "train/policy_randomness_max": 0.9583793522642671, "train/policy_randomness_mean": 0.33115680172717826, "train/policy_randomness_min": 0.028015897937601418, "train/policy_randomness_std": 0.34463189745978484, "train/post_ent_mag": 61.73291117167301, "train/post_ent_max": 61.73291117167301, "train/post_ent_mean": 44.02069558342584, "train/post_ent_min": 20.250607373903122, "train/post_ent_std": 7.880973140112788, "train/prior_ent_mag": 71.14236719145191, "train/prior_ent_max": 71.14236719145191, "train/prior_ent_mean": 56.72508083316062, "train/prior_ent_min": 40.57994057634752, "train/prior_ent_std": 4.9306612769476805, "train/rep_loss_mean": 12.599992861850657, "train/rep_loss_std": 9.26746396538165, "train/reward_avg": 0.04109993232615131, "train/reward_loss_mean": 0.06404024134758565, "train/reward_loss_std": 0.2493809243972353, "train/reward_max_data": 1.0309352591741, "train/reward_max_pred": 1.0217378877049728, "train/reward_neg_acc": 0.9905400357658057, "train/reward_neg_loss": 0.030857013431277207, "train/reward_pos_acc": 0.9831804320108977, "train/reward_pos_loss": 0.7786619903372346, "train/reward_pred": 0.0404836355688439, "train/reward_rate": 0.04463382419064748, "train_stats/sum_log_reward": 11.320930381153905, "train_stats/max_log_achievement_collect_coal": 1.127906976744186, "train_stats/max_log_achievement_collect_drink": 6.27906976744186, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.813953488372093, "train_stats/max_log_achievement_collect_stone": 13.686046511627907, "train_stats/max_log_achievement_collect_wood": 9.755813953488373, "train_stats/max_log_achievement_defeat_skeleton": 0.08139534883720931, "train_stats/max_log_achievement_defeat_zombie": 1.5813953488372092, "train_stats/max_log_achievement_eat_cow": 0.5, "train_stats/max_log_achievement_eat_plant": 0.011627906976744186, "train_stats/max_log_achievement_make_stone_pickaxe": 0.011627906976744186, "train_stats/max_log_achievement_make_stone_sword": 0.023255813953488372, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5, "train_stats/max_log_achievement_make_wood_sword": 1.372093023255814, "train_stats/max_log_achievement_place_furnace": 2.0813953488372094, "train_stats/max_log_achievement_place_plant": 1.7325581395348837, "train_stats/max_log_achievement_place_stone": 3.813953488372093, "train_stats/max_log_achievement_place_table": 2.7325581395348837, "train_stats/max_log_achievement_wake_up": 1.9883720930232558, "train_stats/mean_log_entropy": 0.7358234172990156, "eval_stats/sum_log_reward": 11.100000262260437, "eval_stats/max_log_achievement_collect_coal": 0.75, "eval_stats/max_log_achievement_collect_drink": 7.875, "eval_stats/max_log_achievement_collect_iron": 0.041666666666666664, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 13.625, "eval_stats/max_log_achievement_collect_wood": 10.541666666666666, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 1.4166666666666667, "eval_stats/max_log_achievement_eat_cow": 0.16666666666666666, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.08333333333333333, "eval_stats/max_log_achievement_make_stone_sword": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5833333333333333, "eval_stats/max_log_achievement_make_wood_sword": 1.25, "eval_stats/max_log_achievement_place_furnace": 2.2083333333333335, "eval_stats/max_log_achievement_place_plant": 1.6666666666666667, "eval_stats/max_log_achievement_place_stone": 3.2916666666666665, "eval_stats/max_log_achievement_place_table": 3.0, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.3164143638277892e-05, "report/cont_loss_std": 0.0002967298205476254, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0030600600875914097, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.2155322792750667e-06, "report/cont_pred": 0.9961044788360596, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 11.694363594055176, "report/dyn_loss_std": 8.789538383483887, "report/image_loss_mean": 4.294813632965088, "report/image_loss_std": 7.7072601318359375, "report/model_loss_mean": 11.36446762084961, "report/model_loss_std": 11.419816970825195, "report/post_ent_mag": 62.55463409423828, "report/post_ent_max": 62.55463409423828, "report/post_ent_mean": 45.092159271240234, "report/post_ent_min": 18.109127044677734, "report/post_ent_std": 7.852696895599365, "report/prior_ent_mag": 71.00401306152344, "report/prior_ent_max": 71.00401306152344, "report/prior_ent_mean": 56.89775848388672, "report/prior_ent_min": 40.67357635498047, "report/prior_ent_std": 4.433016300201416, "report/rep_loss_mean": 11.694363594055176, "report/rep_loss_std": 8.789538383483887, "report/reward_avg": 0.04111327975988388, "report/reward_loss_mean": 0.053022753447294235, "report/reward_loss_std": 0.22919774055480957, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.1182708740234375, "report/reward_neg_acc": 0.9989786148071289, "report/reward_neg_loss": 0.018039414659142494, "report/reward_pos_acc": 0.9777777791023254, "report/reward_pos_loss": 0.8141047358512878, "report/reward_pred": 0.039102986454963684, "report/reward_rate": 0.0439453125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.00019949085253756493, "eval/cont_loss_std": 0.004933421965688467, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.06725402176380157, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.4648136331961723e-06, "eval/cont_pred": 0.9972532987594604, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.4936580657959, "eval/dyn_loss_std": 10.843865394592285, "eval/image_loss_mean": 8.776713371276855, "eval/image_loss_std": 15.045153617858887, "eval/model_loss_mean": 18.80510711669922, "eval/model_loss_std": 19.323575973510742, "eval/post_ent_mag": 59.41086196899414, "eval/post_ent_max": 59.41086196899414, "eval/post_ent_mean": 42.735862731933594, "eval/post_ent_min": 21.94837760925293, "eval/post_ent_std": 7.4393110275268555, "eval/prior_ent_mag": 71.00401306152344, "eval/prior_ent_max": 71.00401306152344, "eval/prior_ent_mean": 56.52031707763672, "eval/prior_ent_min": 41.689823150634766, "eval/prior_ent_std": 5.314602851867676, "eval/rep_loss_mean": 16.4936580657959, "eval/rep_loss_std": 10.843865394592285, "eval/reward_avg": 0.06416015326976776, "eval/reward_loss_mean": 0.13199907541275024, "eval/reward_loss_std": 0.5568119883537292, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0000357627868652, "eval/reward_neg_acc": 0.9884936809539795, "eval/reward_neg_loss": 0.06732160598039627, "eval/reward_pos_acc": 0.9411764740943909, "eval/reward_pos_loss": 1.0412880182266235, "eval/reward_pred": 0.062051594257354736, "eval/reward_rate": 0.06640625, "replay/size": 1000000.0, "replay/inserts": 22200.0, "replay/samples": 22208.0, "replay/insert_wait_avg": 1.3696288203333948e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.256510114807216e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 11048.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2497121574738853e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1039.4466569423676, "timer/env.step_count": 2775.0, "timer/env.step_total": 218.16276025772095, "timer/env.step_frac": 0.20988355564052485, "timer/env.step_avg": 0.07861721090368322, "timer/env.step_min": 0.02431774139404297, "timer/env.step_max": 3.450451135635376, "timer/replay._sample_count": 22208.0, "timer/replay._sample_total": 11.550584554672241, "timer/replay._sample_frac": 0.011112243689973853, "timer/replay._sample_avg": 0.0005201091748321434, "timer/replay._sample_min": 0.00039696693420410156, "timer/replay._sample_max": 0.009228944778442383, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4156.0, "timer/agent.policy_total": 75.12079787254333, "timer/agent.policy_frac": 0.07226998843165112, "timer/agent.policy_avg": 0.018075264165674527, "timer/agent.policy_min": 0.009817123413085938, "timer/agent.policy_max": 0.13581275939941406, "timer/dataset_train_count": 1388.0, "timer/dataset_train_total": 0.15614891052246094, "timer/dataset_train_frac": 0.00015022311099810353, "timer/dataset_train_avg": 0.00011249921507381911, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.000858306884765625, "timer/agent.train_count": 1388.0, "timer/agent.train_total": 626.5386791229248, "timer/agent.train_frac": 0.6027617434125467, "timer/agent.train_avg": 0.4513967428839516, "timer/agent.train_min": 0.4380471706390381, "timer/agent.train_max": 1.7958636283874512, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5071403980255127, "timer/agent.report_frac": 0.00048789458760425, "timer/agent.report_avg": 0.25357019901275635, "timer/agent.report_min": 0.23354601860046387, "timer/agent.report_max": 0.27359437942504883, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.7065739397095622e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 21.357035036143543}
{"step": 1710200, "time": 77510.37530589104, "episode/length": 267.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 1710728, "time": 77529.79070353508, "episode/length": 264.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 1711104, "time": 77544.38344454765, "episode/length": 309.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 1711328, "time": 77553.73610973358, "episode/length": 336.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9970326409495549, "episode/intrinsic_return": 0.0}
{"step": 1711336, "time": 77555.38370323181, "episode/length": 287.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 1711728, "time": 77570.4589779377, "episode/length": 411.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 1712344, "time": 77594.43567609787, "episode/length": 415.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9927884615384616, "episode/intrinsic_return": 0.0}
{"step": 1712680, "time": 77607.68458580971, "episode/length": 309.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 1713000, "time": 77620.0447025299, "episode/length": 208.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 1713128, "time": 77626.49694943428, "episode/length": 533.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 1713376, "time": 77636.5658826828, "episode/length": 46.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 1713880, "time": 77655.00999593735, "episode/length": 191.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 1713904, "time": 77657.86490082741, "episode/length": 396.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9899244332493703, "episode/intrinsic_return": 0.0}
{"step": 1714032, "time": 77663.73177218437, "episode/length": 287.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9756944444444444, "episode/intrinsic_return": 0.0}
{"step": 1714144, "time": 77669.07096624374, "episode/length": 350.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 1714664, "time": 77687.90708446503, "episode/length": 444.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9842696629213483, "episode/intrinsic_return": 0.0}
{"step": 1714896, "time": 77697.5292608738, "episode/length": 189.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 1715792, "time": 77729.88295149803, "episode/length": 238.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 1716264, "time": 77747.28979730606, "episode/length": 447.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 1716544, "time": 77758.43962860107, "episode/length": 329.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9787878787878788, "episode/intrinsic_return": 0.0}
{"step": 1716552, "time": 77760.19730591774, "episode/length": 300.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9966777408637874, "episode/intrinsic_return": 0.0}
{"step": 1716608, "time": 77763.94194960594, "episode/length": 434.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 1716768, "time": 77770.9223036766, "episode/length": 233.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 1717352, "time": 77792.00412011147, "episode/length": 194.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 1718000, "time": 77815.62202358246, "episode/length": 216.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1718072, "time": 77819.46068024635, "episode/length": 425.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 1718088, "time": 77821.66864418983, "episode/length": 506.0, "episode/score": 13.100000068545341, "episode/reward_rate": 0.9783037475345168, "episode/intrinsic_return": 0.0}
{"step": 1718400, "time": 77834.0998351574, "episode/length": 203.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 1718416, "time": 77836.44051480293, "episode/length": 233.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 1718584, "time": 77843.51276540756, "episode/length": 253.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 1718672, "time": 77848.28241801262, "episode/length": 257.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 1719064, "time": 77862.81641554832, "episode/length": 213.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 1719280, "time": 77872.09986233711, "episode/length": 150.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 1720056, "time": 77920.93245697021, "eval_episode/length": 168.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 1720056, "time": 77924.18304514885, "eval_episode/length": 202.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9704433497536946}
{"step": 1720056, "time": 77927.07040810585, "eval_episode/length": 227.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 1720056, "time": 77929.85454630852, "eval_episode/length": 252.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9683794466403162}
{"step": 1720056, "time": 77932.54613089561, "eval_episode/length": 276.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9963898916967509}
{"step": 1720056, "time": 77936.24561476707, "eval_episode/length": 325.0, "eval_episode/score": 13.100000008940697, "eval_episode/reward_rate": 0.9969325153374233}
{"step": 1720056, "time": 77942.30343866348, "eval_episode/length": 257.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9806201550387597}
{"step": 1720056, "time": 77944.51502275467, "eval_episode/length": 211.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 1720104, "time": 77946.16584944725, "episode/length": 210.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 1720112, "time": 77948.29603552818, "episode/length": 190.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 1720216, "time": 77953.11482477188, "episode/length": 276.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9711191335740073, "episode/intrinsic_return": 0.0}
{"step": 1720352, "time": 77961.58484911919, "episode/length": 282.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 1720488, "time": 77967.63951563835, "episode/length": 226.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 1721248, "time": 77995.13206791878, "episode/length": 245.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 1721440, "time": 78003.07627606392, "episode/length": 296.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 1721616, "time": 78010.66931080818, "episode/length": 188.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 1721768, "time": 78017.55180644989, "episode/length": 159.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 1721872, "time": 78022.98848986626, "episode/length": 206.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 1722032, "time": 78029.92963838577, "episode/length": 239.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 1722088, "time": 78033.29610323906, "episode/length": 460.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9848156182212582, "episode/intrinsic_return": 0.0}
{"step": 1722224, "time": 78039.73422265053, "episode/length": 233.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 1722864, "time": 78062.86884474754, "episode/length": 155.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 1722904, "time": 78065.47736525536, "episode/length": 182.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 1723192, "time": 78076.9216992855, "episode/length": 242.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 1723392, "time": 78085.57521653175, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 1723792, "time": 78100.54818367958, "episode/length": 212.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 1723864, "time": 78104.23986458778, "episode/length": 248.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 1724552, "time": 78128.92961382866, "episode/length": 210.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1724624, "time": 78133.19049167633, "episode/length": 214.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 1724648, "time": 78135.49356341362, "episode/length": 302.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 1725152, "time": 78154.41319584846, "episode/length": 219.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 1725488, "time": 78167.34574627876, "episode/length": 202.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 1725584, "time": 78172.16302490234, "episode/length": 223.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1725632, "time": 78175.36522889137, "episode/length": 59.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 1726160, "time": 78194.72901415825, "episode/length": 188.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 1726304, "time": 78201.38347744942, "episode/length": 218.0, "episode/score": 14.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 1727000, "time": 78226.51712322235, "episode/length": 170.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 1727160, "time": 78233.6063079834, "episode/length": 208.0, "episode/score": 13.100000016391277, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 1727304, "time": 78240.045637846, "episode/length": 513.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9863813229571985, "episode/intrinsic_return": 0.0}
{"step": 1727912, "time": 78262.1507024765, "episode/length": 200.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 1728072, "time": 78269.14699101448, "episode/length": 310.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9967845659163987, "episode/intrinsic_return": 0.0}
{"step": 1728112, "time": 78272.35751700401, "episode/length": 759.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9986842105263158, "episode/intrinsic_return": 0.0}
{"step": 1728904, "time": 78302.19254851341, "episode/length": 237.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1729016, "time": 78307.56356859207, "episode/length": 231.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 1729600, "time": 78329.09602332115, "episode/length": 210.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1729800, "time": 78337.27017998695, "episode/length": 311.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775641025641025, "episode/intrinsic_return": 0.0}
{"step": 1729840, "time": 78340.47640681267, "episode/length": 220.0, "episode/score": 14.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 1729992, "time": 78347.03817629814, "episode/length": 234.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1730040, "time": 78371.73351430893, "eval_episode/length": 187.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9627659574468085}
{"step": 1730040, "time": 78374.8803730011, "eval_episode/length": 220.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.995475113122172}
{"step": 1730040, "time": 78377.22559428215, "eval_episode/length": 234.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9957446808510638}
{"step": 1730040, "time": 78380.46396398544, "eval_episode/length": 249.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.984}
{"step": 1730040, "time": 78386.5007045269, "eval_episode/length": 315.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9778481012658228}
{"step": 1730040, "time": 78389.57097101212, "eval_episode/length": 335.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9851190476190477}
{"step": 1730040, "time": 78391.93830704689, "eval_episode/length": 342.0, "eval_episode/score": 11.099999971687794, "eval_episode/reward_rate": 0.9970845481049563}
{"step": 1730040, "time": 78398.68636155128, "eval_episode/length": 253.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9763779527559056}
{"step": 1730744, "time": 78422.52541136742, "episode/length": 215.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 1730952, "time": 78431.03780603409, "episode/length": 168.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.0}
{"step": 1731096, "time": 78437.5746576786, "episode/length": 273.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 1731200, "time": 78442.83879327774, "episode/length": 821.0, "episode/score": 15.099999986588955, "episode/reward_rate": 0.9939172749391727, "episode/intrinsic_return": 0.0}
{"step": 1731216, "time": 78445.08692598343, "episode/length": 58.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9322033898305084, "episode/intrinsic_return": 0.0}
{"step": 1731808, "time": 78466.6666636467, "episode/length": 226.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 1732264, "time": 78483.26131272316, "episode/length": 307.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 1732768, "time": 78502.21422457695, "episode/length": 195.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 1732809, "time": 78506.20570039749, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.980782092457086, "train/action_min": 0.0, "train/action_std": 3.8061314283961982, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.02548500875824354, "train/actor_opt_grad_steps": 107495.0, "train/actor_opt_loss": -9.867408212641594, "train/adv_mag": 0.37936694815125266, "train/adv_max": 0.34042987752128656, "train/adv_mean": 0.001431326391354214, "train/adv_min": -0.3232739828002285, "train/adv_std": 0.03894279327925662, "train/cont_avg": 0.9962931888204225, "train/cont_loss_mean": 7.939487516765298e-05, "train/cont_loss_std": 0.002424236467796093, "train/cont_neg_acc": 0.9967153285541673, "train/cont_neg_loss": 0.01209593107801515, "train/cont_pos_acc": 0.9999861826359386, "train/cont_pos_loss": 2.872334404933251e-05, "train/cont_pred": 0.9963014516192423, "train/cont_rate": 0.9962931888204225, "train/dyn_loss_mean": 12.718374823180723, "train/dyn_loss_std": 9.297862032769432, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9155720736778957, "train/extr_critic_critic_opt_grad_steps": 107495.0, "train/extr_critic_critic_opt_loss": 14736.029530699823, "train/extr_critic_mag": 10.557900019094978, "train/extr_critic_max": 10.557900019094978, "train/extr_critic_mean": 2.161225103156667, "train/extr_critic_min": -0.2594185941655871, "train/extr_critic_std": 2.4846852312625294, "train/extr_return_normed_mag": 1.474031603252384, "train/extr_return_normed_max": 1.474031603252384, "train/extr_return_normed_mean": 0.2892438216318547, "train/extr_return_normed_min": -0.05474794321549191, "train/extr_return_normed_std": 0.31822952858998743, "train/extr_return_rate": 0.6611223013048441, "train/extr_return_raw_mag": 11.509331629309855, "train/extr_return_raw_max": 11.509331629309855, "train/extr_return_raw_mean": 2.1725145402088972, "train/extr_return_raw_min": -0.5391121303111734, "train/extr_return_raw_std": 2.508710350788815, "train/extr_reward_mag": 1.062834385415198, "train/extr_reward_max": 1.062834385415198, "train/extr_reward_mean": 0.04120298372712773, "train/extr_reward_min": -0.45422143919367186, "train/extr_reward_std": 0.1908961949004254, "train/image_loss_mean": 6.236865446601115, "train/image_loss_std": 12.29330324790847, "train/model_loss_mean": 13.93183092332222, "train/model_loss_std": 16.01877396543261, "train/model_opt_grad_norm": 43.51034355163574, "train/model_opt_grad_steps": 107399.68309859154, "train/model_opt_loss": 19457.69930815361, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1399.6478873239437, "train/policy_entropy_mag": 2.7545904240138093, "train/policy_entropy_max": 2.7545904240138093, "train/policy_entropy_mean": 0.9338951534788373, "train/policy_entropy_min": 0.07937501769670298, "train/policy_entropy_std": 0.9844509031571133, "train/policy_logprob_mag": 7.438383844536795, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.9331874406673539, "train/policy_logprob_min": -7.438383844536795, "train/policy_logprob_std": 1.3132026086390858, "train/policy_randomness_mag": 0.9722495356076201, "train/policy_randomness_max": 0.9722495356076201, "train/policy_randomness_mean": 0.329624006760792, "train/policy_randomness_min": 0.028015898055278918, "train/policy_randomness_std": 0.3474679666925484, "train/post_ent_mag": 61.6122014757613, "train/post_ent_max": 61.6122014757613, "train/post_ent_mean": 43.87117474515673, "train/post_ent_min": 19.96522212364304, "train/post_ent_std": 7.895577031122127, "train/prior_ent_mag": 71.12657611470827, "train/prior_ent_max": 71.12657611470827, "train/prior_ent_mean": 56.68284429630763, "train/prior_ent_min": 40.2180927975077, "train/prior_ent_std": 4.91396807952666, "train/rep_loss_mean": 12.718374823180723, "train/rep_loss_std": 9.297862032769432, "train/reward_avg": 0.041190993276910046, "train/reward_loss_mean": 0.06386129007163183, "train/reward_loss_std": 0.2528080070312594, "train/reward_max_data": 1.033098599440615, "train/reward_max_pred": 1.0301604027479467, "train/reward_neg_acc": 0.9911761628070348, "train/reward_neg_loss": 0.030146691456279705, "train/reward_pos_acc": 0.9784580166910736, "train/reward_pos_loss": 0.786746213973408, "train/reward_pred": 0.04043411220830511, "train/reward_rate": 0.044708681778169015, "train_stats/sum_log_reward": 11.470370634102528, "train_stats/max_log_achievement_collect_coal": 1.0123456790123457, "train_stats/max_log_achievement_collect_drink": 6.037037037037037, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.7901234567901234, "train_stats/max_log_achievement_collect_stone": 13.432098765432098, "train_stats/max_log_achievement_collect_wood": 10.345679012345679, "train_stats/max_log_achievement_defeat_skeleton": 0.08641975308641975, "train_stats/max_log_achievement_defeat_zombie": 1.5925925925925926, "train_stats/max_log_achievement_eat_cow": 0.6790123456790124, "train_stats/max_log_achievement_eat_plant": 0.012345679012345678, "train_stats/max_log_achievement_make_stone_pickaxe": 0.06172839506172839, "train_stats/max_log_achievement_make_stone_sword": 0.08641975308641975, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4567901234567902, "train_stats/max_log_achievement_make_wood_sword": 1.1604938271604939, "train_stats/max_log_achievement_place_furnace": 2.2839506172839505, "train_stats/max_log_achievement_place_plant": 1.691358024691358, "train_stats/max_log_achievement_place_stone": 3.246913580246914, "train_stats/max_log_achievement_place_table": 2.925925925925926, "train_stats/max_log_achievement_wake_up": 2.0123456790123457, "train_stats/mean_log_entropy": 0.7553231712476707, "eval_stats/sum_log_reward": 11.787500143051147, "eval_stats/max_log_achievement_collect_coal": 0.75, "eval_stats/max_log_achievement_collect_drink": 5.125, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.9375, "eval_stats/max_log_achievement_collect_stone": 12.75, "eval_stats/max_log_achievement_collect_wood": 12.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 2.3125, "eval_stats/max_log_achievement_eat_cow": 0.3125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_stone_sword": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 2.0625, "eval_stats/max_log_achievement_place_plant": 1.8125, "eval_stats/max_log_achievement_place_stone": 3.5625, "eval_stats/max_log_achievement_place_table": 3.25, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 9.893010428640991e-07, "report/cont_loss_std": 2.1495083274203353e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002784391399472952, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.7407128893864865e-07, "report/cont_pred": 0.9970710277557373, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 11.413447380065918, "report/dyn_loss_std": 9.27823257446289, "report/image_loss_mean": 7.27143669128418, "report/image_loss_std": 12.399517059326172, "report/model_loss_mean": 14.169661521911621, "report/model_loss_std": 16.279178619384766, "report/post_ent_mag": 62.66480255126953, "report/post_ent_max": 62.66480255126953, "report/post_ent_mean": 45.16445541381836, "report/post_ent_min": 18.251684188842773, "report/post_ent_std": 7.924304962158203, "report/prior_ent_mag": 71.29383087158203, "report/prior_ent_max": 71.29383087158203, "report/prior_ent_mean": 56.71637725830078, "report/prior_ent_min": 39.085670471191406, "report/prior_ent_std": 5.6715474128723145, "report/rep_loss_mean": 11.413447380065918, "report/rep_loss_std": 9.27823257446289, "report/reward_avg": 0.02646484412252903, "report/reward_loss_mean": 0.05015476420521736, "report/reward_loss_std": 0.23100927472114563, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0970146656036377, "report/reward_neg_acc": 0.9899396300315857, "report/reward_neg_loss": 0.024214405566453934, "report/reward_pos_acc": 0.9333333969116211, "report/reward_pos_loss": 0.9096453189849854, "report/reward_pred": 0.025134537369012833, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.4118024864728795e-06, "eval/cont_loss_std": 2.8368614948703907e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0002607302158139646, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.3938641529875895e-07, "eval/cont_pred": 0.9951183795928955, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.21085548400879, "eval/dyn_loss_std": 10.487112998962402, "eval/image_loss_mean": 7.745426654815674, "eval/image_loss_std": 11.554512977600098, "eval/model_loss_mean": 18.181873321533203, "eval/model_loss_std": 15.374052047729492, "eval/post_ent_mag": 59.879737854003906, "eval/post_ent_max": 59.879737854003906, "eval/post_ent_mean": 42.74653625488281, "eval/post_ent_min": 18.998811721801758, "eval/post_ent_std": 8.373528480529785, "eval/prior_ent_mag": 71.29383087158203, "eval/prior_ent_max": 71.29383087158203, "eval/prior_ent_mean": 57.6378173828125, "eval/prior_ent_min": 45.875431060791016, "eval/prior_ent_std": 4.1324462890625, "eval/rep_loss_mean": 17.21085548400879, "eval/rep_loss_std": 10.487112998962402, "eval/reward_avg": 0.04316405951976776, "eval/reward_loss_mean": 0.10993409901857376, "eval/reward_loss_std": 0.6386198997497559, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0041241645812988, "eval/reward_neg_acc": 0.9928131699562073, "eval/reward_neg_loss": 0.056578125804662704, "eval/reward_pos_acc": 0.8999999761581421, "eval/reward_pos_loss": 1.149308443069458, "eval/reward_pred": 0.04210250824689865, "eval/reward_rate": 0.048828125, "replay/size": 1000000.0, "replay/inserts": 22736.0, "replay/samples": 22736.0, "replay/insert_wait_avg": 1.3551352982115023e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.222903272452948e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7056.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2793035463951613e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9745235443115, "timer/env.step_count": 2842.0, "timer/env.step_total": 213.2849292755127, "timer/env.step_frac": 0.21329036315799846, "timer/env.step_avg": 0.0750474768738609, "timer/env.step_min": 0.024840831756591797, "timer/env.step_max": 2.089445114135742, "timer/replay._sample_count": 22736.0, "timer/replay._sample_total": 11.816103458404541, "timer/replay._sample_frac": 0.011816404498510144, "timer/replay._sample_avg": 0.0005197089839199745, "timer/replay._sample_min": 0.0004303455352783203, "timer/replay._sample_max": 0.010034322738647461, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3724.0, "timer/agent.policy_total": 65.24657154083252, "timer/agent.policy_frac": 0.06524823383457055, "timer/agent.policy_avg": 0.017520561638247185, "timer/agent.policy_min": 0.009786367416381836, "timer/agent.policy_max": 0.16735339164733887, "timer/dataset_train_count": 1421.0, "timer/dataset_train_total": 0.1586916446685791, "timer/dataset_train_frac": 0.00015869568767223403, "timer/dataset_train_avg": 0.00011167603424952788, "timer/dataset_train_min": 9.72747802734375e-05, "timer/dataset_train_max": 0.0007040500640869141, "timer/agent.train_count": 1421.0, "timer/agent.train_total": 638.1259484291077, "timer/agent.train_frac": 0.6381422060307426, "timer/agent.train_avg": 0.4490682254955015, "timer/agent.train_min": 0.4358820915222168, "timer/agent.train_max": 1.8009707927703857, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4798417091369629, "timer/agent.report_frac": 0.0004798539341144523, "timer/agent.report_avg": 0.23992085456848145, "timer/agent.report_min": 0.23225688934326172, "timer/agent.report_max": 0.24758481979370117, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.0518355624534756e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 22.736161711019555}
{"step": 1732856, "time": 78507.71326851845, "episode/length": 836.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9904420549581839, "episode/intrinsic_return": 0.0}
{"step": 1732872, "time": 78509.9696214199, "episode/length": 221.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 1733184, "time": 78522.30214977264, "episode/length": 417.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 1733288, "time": 78527.31793141365, "episode/length": 258.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 1733400, "time": 78532.72853469849, "episode/length": 198.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 1733632, "time": 78542.25698900223, "episode/length": 42.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 1733928, "time": 78553.54225349426, "episode/length": 207.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 1734416, "time": 78571.85732531548, "episode/length": 205.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 1734920, "time": 78590.3565583229, "episode/length": 62.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 1735008, "time": 78595.14376139641, "episode/length": 268.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 1735208, "time": 78603.24224543571, "episode/length": 531.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9906015037593985, "episode/intrinsic_return": 0.0}
{"step": 1735528, "time": 78615.66780400276, "episode/length": 292.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9761092150170648, "episode/intrinsic_return": 0.0}
{"step": 1735784, "time": 78626.00047278404, "episode/length": 231.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 1735784, "time": 78626.00960302353, "episode/length": 268.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9739776951672863, "episode/intrinsic_return": 0.0}
{"step": 1735912, "time": 78633.56565713882, "episode/length": 313.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9840764331210191, "episode/intrinsic_return": 0.0}
{"step": 1736576, "time": 78657.6963903904, "episode/length": 195.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 1736768, "time": 78667.61463499069, "episode/length": 194.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 1737152, "time": 78682.18849134445, "episode/length": 170.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 1737216, "time": 78685.87866091728, "episode/length": 162.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 1737640, "time": 78701.47707533836, "episode/length": 231.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 1737936, "time": 78713.25691771507, "episode/length": 300.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.973421926910299, "episode/intrinsic_return": 0.0}
{"step": 1738168, "time": 78722.40753531456, "episode/length": 198.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 1738464, "time": 78734.20908594131, "episode/length": 155.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 1738632, "time": 78741.28337168694, "episode/length": 232.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 1738672, "time": 78744.44388651848, "episode/length": 189.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 1738792, "time": 78749.8529548645, "episode/length": 483.0, "episode/score": 13.099999964237213, "episode/reward_rate": 0.9855371900826446, "episode/intrinsic_return": 0.0}
{"step": 1739000, "time": 78758.59026384354, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1739632, "time": 78781.7556951046, "episode/length": 78.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 1739656, "time": 78784.02894806862, "episode/length": 185.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 1740024, "time": 78819.60022091866, "eval_episode/length": 183.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 1740024, "time": 78821.56669449806, "eval_episode/length": 190.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 1740024, "time": 78823.3275334835, "eval_episode/length": 194.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 1740024, "time": 78825.65158724785, "eval_episode/length": 208.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9712918660287081}
{"step": 1740024, "time": 78827.68409633636, "eval_episode/length": 211.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9622641509433962}
{"step": 1740024, "time": 78829.9297349453, "eval_episode/length": 223.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9732142857142857}
{"step": 1740024, "time": 78831.76830863953, "eval_episode/length": 229.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 1740024, "time": 78833.47404742241, "eval_episode/length": 230.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 1740096, "time": 78836.12360811234, "episode/length": 269.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 1740208, "time": 78841.5472061634, "episode/length": 196.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 1740264, "time": 78844.78355836868, "episode/length": 923.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 1740304, "time": 78847.89402151108, "episode/length": 203.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 1741096, "time": 78875.77481007576, "episode/length": 179.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 1741232, "time": 78882.12177586555, "episode/length": 120.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9421487603305785, "episode/intrinsic_return": 0.0}
{"step": 1741288, "time": 78885.35211157799, "episode/length": 352.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9971671388101983, "episode/intrinsic_return": 0.0}
{"step": 1741312, "time": 78888.27263855934, "episode/length": 209.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1741536, "time": 78897.47970080376, "episode/length": 179.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 1741912, "time": 78911.50687766075, "episode/length": 389.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 1742144, "time": 78921.26666331291, "episode/length": 229.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 1742824, "time": 78945.5643196106, "episode/length": 198.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 1742952, "time": 78951.66486930847, "episode/length": 231.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 1743080, "time": 78958.2258489132, "episode/length": 220.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 1743280, "time": 78966.69762945175, "episode/length": 383.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 1743632, "time": 78980.443764925, "episode/length": 292.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 1744032, "time": 78995.56993889809, "episode/length": 264.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 1744088, "time": 78998.90269446373, "episode/length": 318.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9780564263322884, "episode/intrinsic_return": 0.0}
{"step": 1744312, "time": 79008.10088944435, "episode/length": 169.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 1744408, "time": 79012.87341928482, "episode/length": 282.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 1744704, "time": 79024.66809391975, "episode/length": 234.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1745256, "time": 79046.51452040672, "episode/length": 202.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 1745960, "time": 79072.04512763023, "episode/length": 240.0, "episode/score": 14.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 1746248, "time": 79083.53093647957, "episode/length": 241.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 1746328, "time": 79087.85706233978, "episode/length": 279.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9678571428571429, "episode/intrinsic_return": 0.0}
{"step": 1746408, "time": 79092.09626078606, "episode/length": 249.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 1746448, "time": 79095.20508432388, "episode/length": 395.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 1746600, "time": 79101.88914370537, "episode/length": 236.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9704641350210971, "episode/intrinsic_return": 0.0}
{"step": 1747104, "time": 79120.67801141739, "episode/length": 230.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 1747592, "time": 79138.60413622856, "episode/length": 203.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 1747704, "time": 79144.04186582565, "episode/length": 181.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 1747832, "time": 79149.86783504486, "episode/length": 593.0, "episode/score": 14.100000023841858, "episode/reward_rate": 0.9983164983164983, "episode/intrinsic_return": 0.0}
{"step": 1747888, "time": 79153.50960540771, "episode/length": 184.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 1748144, "time": 79163.76559019089, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 1748312, "time": 79170.85299777985, "episode/length": 247.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9717741935483871, "episode/intrinsic_return": 0.0}
{"step": 1748400, "time": 79175.60649347305, "episode/length": 243.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 1748656, "time": 79185.784907341, "episode/length": 102.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 1748752, "time": 79190.613063097, "episode/length": 205.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 1749192, "time": 79206.60293292999, "episode/length": 199.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 1749248, "time": 79210.3072104454, "episode/length": 169.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 1749944, "time": 79235.14881205559, "episode/length": 279.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1750008, "time": 79256.02002620697, "eval_episode/length": 88.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9550561797752809}
{"step": 1750008, "time": 79259.82813620567, "eval_episode/length": 137.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 1750008, "time": 79264.22968935966, "eval_episode/length": 197.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.98989898989899}
{"step": 1750008, "time": 79266.03587603569, "eval_episode/length": 202.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 1750008, "time": 79269.55009126663, "eval_episode/length": 243.0, "eval_episode/score": 12.100000023841858, "eval_episode/reward_rate": 0.9959016393442623}
{"step": 1750008, "time": 79273.37561440468, "eval_episode/length": 202.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9704433497536946}
{"step": 1750008, "time": 79275.82207560539, "eval_episode/length": 308.0, "eval_episode/score": 12.100000031292439, "eval_episode/reward_rate": 0.9967637540453075}
{"step": 1750008, "time": 79277.60428190231, "eval_episode/length": 309.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9967741935483871}
{"step": 1750112, "time": 79281.34907960892, "episode/length": 245.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 1750472, "time": 79294.84288454056, "episode/length": 258.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 1750680, "time": 79303.36612677574, "episode/length": 240.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 1750768, "time": 79308.29009890556, "episode/length": 306.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9804560260586319, "episode/intrinsic_return": 0.0}
{"step": 1751040, "time": 79319.11430668831, "episode/length": 33.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.8823529411764706, "episode/intrinsic_return": 0.0}
{"step": 1751528, "time": 79336.9305574894, "episode/length": 60.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 1751680, "time": 79343.86698102951, "episode/length": 303.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 1751824, "time": 79350.28939723969, "episode/length": 328.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9908814589665653, "episode/intrinsic_return": 0.0}
{"step": 1751856, "time": 79353.04671740532, "episode/length": 217.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 1752376, "time": 79371.86255025864, "episode/length": 237.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 1752848, "time": 79389.56829237938, "episode/length": 270.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 1752904, "time": 79392.782705307, "episode/length": 171.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 1752992, "time": 79397.64939117432, "episode/length": 145.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 1753104, "time": 79404.79448318481, "episode/length": 155.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 1753200, "time": 79409.72384142876, "episode/length": 189.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 1753856, "time": 79433.4558839798, "episode/length": 118.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 1754152, "time": 79444.90566468239, "episode/length": 525.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9885931558935361, "episode/intrinsic_return": 0.0}
{"step": 1754184, "time": 79447.56055092812, "episode/length": 690.0, "episode/score": 14.100000008940697, "episode/reward_rate": 0.9985528219971056, "episode/intrinsic_return": 0.0}
{"step": 1754448, "time": 79458.36713981628, "episode/length": 155.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 1754480, "time": 79461.04003167152, "episode/length": 203.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 1754608, "time": 79466.95293068886, "episode/length": 278.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 1755016, "time": 79482.07529878616, "episode/length": 66.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 1755657, "time": 79506.44902467728, "train_stats/sum_log_reward": 11.219565381174503, "train_stats/max_log_achievement_collect_coal": 0.9456521739130435, "train_stats/max_log_achievement_collect_drink": 5.793478260869565, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.826086956521739, "train_stats/max_log_achievement_collect_stone": 13.445652173913043, "train_stats/max_log_achievement_collect_wood": 10.282608695652174, "train_stats/max_log_achievement_defeat_skeleton": 0.15217391304347827, "train_stats/max_log_achievement_defeat_zombie": 1.3478260869565217, "train_stats/max_log_achievement_eat_cow": 0.5760869565217391, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.06521739130434782, "train_stats/max_log_achievement_make_stone_sword": 0.08695652173913043, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2391304347826086, "train_stats/max_log_achievement_make_wood_sword": 1.173913043478261, "train_stats/max_log_achievement_place_furnace": 2.097826086956522, "train_stats/max_log_achievement_place_plant": 1.7282608695652173, "train_stats/max_log_achievement_place_stone": 3.619565217391304, "train_stats/max_log_achievement_place_table": 2.9565217391304346, "train_stats/max_log_achievement_wake_up": 1.8043478260869565, "train_stats/mean_log_entropy": 0.7009642512901969, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.093830242023602, "train/action_min": 0.0, "train/action_std": 3.845112437134856, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.025325572834565088, "train/actor_opt_grad_steps": 108920.0, "train/actor_opt_loss": -8.494817430479126, "train/adv_mag": 0.37686340427482046, "train/adv_max": 0.34631969639054544, "train/adv_mean": 0.001501944254217248, "train/adv_min": -0.3094691837375814, "train/adv_std": 0.03897077290640844, "train/cont_avg": 0.995936680506993, "train/cont_loss_mean": 0.00014069731138489303, "train/cont_loss_std": 0.004437348716030961, "train/cont_neg_acc": 0.9952043239951979, "train/cont_neg_loss": 0.012950160299711338, "train/cont_pos_acc": 0.9999862909317017, "train/cont_pos_loss": 6.870828107519078e-05, "train/cont_pred": 0.9959456687206989, "train/cont_rate": 0.995936680506993, "train/dyn_loss_mean": 12.630792424395368, "train/dyn_loss_std": 9.267461509971351, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9002452734467032, "train/extr_critic_critic_opt_grad_steps": 108920.0, "train/extr_critic_critic_opt_loss": 14835.917005845717, "train/extr_critic_mag": 10.520166140336256, "train/extr_critic_max": 10.520166140336256, "train/extr_critic_mean": 2.1600479987951426, "train/extr_critic_min": -0.2576318020587201, "train/extr_critic_std": 2.5414030435202006, "train/extr_return_normed_mag": 1.4833101217563336, "train/extr_return_normed_max": 1.4833101217563336, "train/extr_return_normed_mean": 0.2917705446064889, "train/extr_return_normed_min": -0.05345785272652869, "train/extr_return_normed_std": 0.3276593935239565, "train/extr_return_rate": 0.6474477700837009, "train/extr_return_raw_mag": 11.498091514293964, "train/extr_return_raw_max": 11.498091514293964, "train/extr_return_raw_mean": 2.1718079130966346, "train/extr_return_raw_min": -0.5297853348555265, "train/extr_return_raw_std": 2.5644507866639357, "train/extr_reward_mag": 1.054374079604249, "train/extr_reward_max": 1.054374079604249, "train/extr_reward_mean": 0.04170642065053636, "train/extr_reward_min": -0.4532293147974081, "train/extr_reward_std": 0.19176952030275252, "train/image_loss_mean": 6.300826552864555, "train/image_loss_std": 12.213187141018315, "train/model_loss_mean": 13.943824347916182, "train/model_loss_std": 15.956280114767434, "train/model_opt_grad_norm": 41.24263019161624, "train/model_opt_grad_steps": 108823.51748251748, "train/model_opt_loss": 19811.357408216783, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1416.0839160839162, "train/policy_entropy_mag": 2.791215373085929, "train/policy_entropy_max": 2.791215373085929, "train/policy_entropy_mean": 0.958041689195833, "train/policy_entropy_min": 0.07937501631416641, "train/policy_entropy_std": 1.0051537110255315, "train/policy_logprob_mag": 7.438383846016197, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.9582094854408211, "train/policy_logprob_min": -7.438383846016197, "train/policy_logprob_std": 1.3271925332662942, "train/policy_randomness_mag": 0.9851765357531034, "train/policy_randomness_max": 0.9851765357531034, "train/policy_randomness_mean": 0.3381466726948331, "train/policy_randomness_min": 0.028015897524627773, "train/policy_randomness_std": 0.35477515200634935, "train/post_ent_mag": 61.441059539368105, "train/post_ent_max": 61.441059539368105, "train/post_ent_mean": 43.96290972516253, "train/post_ent_min": 19.959863355943373, "train/post_ent_std": 7.845026369695063, "train/prior_ent_mag": 71.16555610069862, "train/prior_ent_max": 71.16555610069862, "train/prior_ent_mean": 56.681346946662956, "train/prior_ent_min": 40.476053518015185, "train/prior_ent_std": 4.922669474061553, "train/rep_loss_mean": 12.630792424395368, "train/rep_loss_std": 9.267461509971351, "train/reward_avg": 0.040749972451712704, "train/reward_loss_mean": 0.06438159359084976, "train/reward_loss_std": 0.25369283108861296, "train/reward_max_data": 1.0251748311769713, "train/reward_max_pred": 1.0210863176759306, "train/reward_neg_acc": 0.9905279749756927, "train/reward_neg_loss": 0.03059429274806818, "train/reward_pos_acc": 0.9767430962382496, "train/reward_pos_loss": 0.7995235048807584, "train/reward_pred": 0.0399984334810422, "train/reward_rate": 0.044389204545454544, "eval_stats/sum_log_reward": 11.600000262260437, "eval_stats/max_log_achievement_collect_coal": 0.9375, "eval_stats/max_log_achievement_collect_drink": 4.75, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 13.0625, "eval_stats/max_log_achievement_collect_wood": 8.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 1.625, "eval_stats/max_log_achievement_eat_cow": 0.4375, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.125, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.4375, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 2.1875, "eval_stats/max_log_achievement_place_plant": 1.5625, "eval_stats/max_log_achievement_place_stone": 3.3125, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 3.0204041649994906e-06, "report/cont_loss_std": 3.5161490814061835e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.159761248156428e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.9963284760015085e-06, "report/cont_pred": 0.9960907697677612, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.284144401550293, "report/dyn_loss_std": 9.674882888793945, "report/image_loss_mean": 5.766556739807129, "report/image_loss_std": 10.540691375732422, "report/model_loss_mean": 13.814558029174805, "report/model_loss_std": 14.715197563171387, "report/post_ent_mag": 61.02259826660156, "report/post_ent_max": 61.02259826660156, "report/post_ent_mean": 43.73411560058594, "report/post_ent_min": 19.803115844726562, "report/post_ent_std": 7.9616241455078125, "report/prior_ent_mag": 71.46066284179688, "report/prior_ent_max": 71.46066284179688, "report/prior_ent_mean": 56.694393157958984, "report/prior_ent_min": 41.32310485839844, "report/prior_ent_std": 4.772061824798584, "report/rep_loss_mean": 13.284144401550293, "report/rep_loss_std": 9.674882888793945, "report/reward_avg": 0.04052734375, "report/reward_loss_mean": 0.07751079648733139, "report/reward_loss_std": 0.3475514352321625, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0662174224853516, "report/reward_neg_acc": 0.9928498864173889, "report/reward_neg_loss": 0.0354134775698185, "report/reward_pos_acc": 0.9111111164093018, "report/reward_pos_loss": 0.9933614134788513, "report/reward_pred": 0.03660409897565842, "report/reward_rate": 0.0439453125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.0917492545559071e-05, "eval/cont_loss_std": 0.0002843388356268406, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0030367409344762564, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.0267289073672146e-06, "eval/cont_pred": 0.9970771670341492, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.077190399169922, "eval/dyn_loss_std": 11.593365669250488, "eval/image_loss_mean": 9.536341667175293, "eval/image_loss_std": 19.830795288085938, "eval/model_loss_mean": 19.890056610107422, "eval/model_loss_std": 23.767061233520508, "eval/post_ent_mag": 57.64865493774414, "eval/post_ent_max": 57.64865493774414, "eval/post_ent_mean": 41.76766586303711, "eval/post_ent_min": 20.074321746826172, "eval/post_ent_std": 7.532782077789307, "eval/prior_ent_mag": 71.46066284179688, "eval/prior_ent_max": 71.46066284179688, "eval/prior_ent_mean": 56.0606575012207, "eval/prior_ent_min": 43.376220703125, "eval/prior_ent_std": 4.882031440734863, "eval/rep_loss_mean": 17.077190399169922, "eval/rep_loss_std": 11.593365669250488, "eval/reward_avg": 0.04443359375, "eval/reward_loss_mean": 0.10739076882600784, "eval/reward_loss_std": 0.551841676235199, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006418228149414, "eval/reward_neg_acc": 0.9815762639045715, "eval/reward_neg_loss": 0.062466707080602646, "eval/reward_pos_acc": 0.9361701607704163, "eval/reward_pos_loss": 1.0412378311157227, "eval/reward_pred": 0.048925936222076416, "eval/reward_rate": 0.0458984375, "replay/size": 1000000.0, "replay/inserts": 22848.0, "replay/samples": 22848.0, "replay/insert_wait_avg": 1.3516021041976972e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.114663158812109e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4328.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2648083586349064e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2486419677734, "timer/env.step_count": 2856.0, "timer/env.step_total": 229.9061279296875, "timer/env.step_frac": 0.22984897782754973, "timer/env.step_avg": 0.0804993445131959, "timer/env.step_min": 0.024297475814819336, "timer/env.step_max": 3.32072377204895, "timer/replay._sample_count": 22848.0, "timer/replay._sample_total": 11.911916971206665, "timer/replay._sample_frac": 0.011908955904976325, "timer/replay._sample_avg": 0.0005213549094540733, "timer/replay._sample_min": 0.00038743019104003906, "timer/replay._sample_max": 0.011668920516967773, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3397.0, "timer/agent.policy_total": 58.58946394920349, "timer/agent.policy_frac": 0.05857489977086233, "timer/agent.policy_avg": 0.01724741358528216, "timer/agent.policy_min": 0.00996088981628418, "timer/agent.policy_max": 0.10417318344116211, "timer/dataset_train_count": 1428.0, "timer/dataset_train_total": 0.15725278854370117, "timer/dataset_train_frac": 0.00015721369862031529, "timer/dataset_train_avg": 0.00011012100038074312, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0008177757263183594, "timer/agent.train_count": 1428.0, "timer/agent.train_total": 640.9644777774811, "timer/agent.train_frac": 0.64080514672484, "timer/agent.train_avg": 0.44885467631476267, "timer/agent.train_min": 0.4360842704772949, "timer/agent.train_max": 1.8029675483703613, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4750332832336426, "timer/agent.report_frac": 0.00047491519938394226, "timer/agent.report_avg": 0.2375166416168213, "timer/agent.report_min": 0.23060321807861328, "timer/agent.report_max": 0.2444300651550293, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.884147686972668e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 22.842004691545775}
{"step": 1755688, "time": 79507.23473024368, "episode/length": 322.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9814241486068112, "episode/intrinsic_return": 0.0}
{"step": 1755712, "time": 79509.96870851517, "episode/length": 190.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 1755856, "time": 79516.54745078087, "episode/length": 212.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 1755904, "time": 79520.2998239994, "episode/length": 161.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 1755920, "time": 79522.42125916481, "episode/length": 183.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 1756120, "time": 79530.55707883835, "episode/length": 137.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 1756560, "time": 79547.27209210396, "episode/length": 337.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 1757464, "time": 79579.22668147087, "episode/length": 221.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 1757504, "time": 79582.85518598557, "episode/length": 199.0, "episode/score": 13.099999979138374, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 1757552, "time": 79586.18018102646, "episode/length": 229.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 1757608, "time": 79589.30443954468, "episode/length": 130.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 1758112, "time": 79608.58462929726, "episode/length": 639.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 1758152, "time": 79611.34750986099, "episode/length": 286.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9686411149825784, "episode/intrinsic_return": 0.0}
{"step": 1758304, "time": 79618.3579955101, "episode/length": 99.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 1758584, "time": 79629.19415569305, "episode/length": 307.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9967532467532467, "episode/intrinsic_return": 0.0}
{"step": 1758888, "time": 79641.30546975136, "episode/length": 370.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9784366576819407, "episode/intrinsic_return": 0.0}
{"step": 1759056, "time": 79648.83579087257, "episode/length": 198.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9849246231155779, "episode/intrinsic_return": 0.0}
{"step": 1759464, "time": 79663.99428629875, "episode/length": 163.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 1760056, "time": 79685.9737648964, "episode/length": 183.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 1760064, "time": 79688.15954208374, "episode/length": 313.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9872611464968153, "episode/intrinsic_return": 0.0}
{"step": 1760096, "time": 79708.6207704544, "eval_episode/length": 98.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.98989898989899}
{"step": 1760096, "time": 79712.48595118523, "eval_episode/length": 149.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.96}
{"step": 1760096, "time": 79716.84444928169, "eval_episode/length": 203.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 1760096, "time": 79718.60612940788, "eval_episode/length": 207.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 1760096, "time": 79720.27277040482, "eval_episode/length": 209.0, "eval_episode/score": 9.100000016391277, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 1760096, "time": 79722.0100722313, "eval_episode/length": 211.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 1760096, "time": 79723.79757618904, "eval_episode/length": 216.0, "eval_episode/score": 13.099999994039536, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 1760096, "time": 79728.04974722862, "eval_episode/length": 61.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9193548387096774}
{"step": 1760112, "time": 79728.63209986687, "episode/length": 249.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 1760192, "time": 79733.00050115585, "episode/length": 235.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1760640, "time": 79749.64617204666, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 1760680, "time": 79752.3911588192, "episode/length": 151.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 1761288, "time": 79775.23654961586, "episode/length": 459.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9847826086956522, "episode/intrinsic_return": 0.0}
{"step": 1761416, "time": 79782.74579453468, "episode/length": 152.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 1762088, "time": 79807.27958083153, "episode/length": 252.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9841897233201581, "episode/intrinsic_return": 0.0}
{"step": 1762264, "time": 79814.77526664734, "episode/length": 268.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 1762304, "time": 79818.13895964622, "episode/length": 207.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 1762776, "time": 79835.84308099747, "episode/length": 339.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9794117647058823, "episode/intrinsic_return": 0.0}
{"step": 1762936, "time": 79842.82857966423, "episode/length": 189.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 1762992, "time": 79846.73042488098, "episode/length": 491.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 1763104, "time": 79852.16081881523, "episode/length": 302.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 1763504, "time": 79867.39266967773, "episode/length": 276.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 1763840, "time": 79880.45349431038, "episode/length": 191.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 1764016, "time": 79888.15204048157, "episode/length": 218.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 1764080, "time": 79891.994328022, "episode/length": 248.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 1764384, "time": 79903.95131754875, "episode/length": 200.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9651741293532339, "episode/intrinsic_return": 0.0}
{"step": 1764760, "time": 79918.28653788567, "episode/length": 220.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 1764976, "time": 79927.43051791191, "episode/length": 183.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 1765096, "time": 79932.91982507706, "episode/length": 248.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 1765776, "time": 79958.19729971886, "episode/length": 241.0, "episode/score": 14.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 1765856, "time": 79962.59632611275, "episode/length": 183.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 1765936, "time": 79967.03583788872, "episode/length": 239.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 1766152, "time": 79975.77249097824, "episode/length": 258.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 1766416, "time": 79986.56005525589, "episode/length": 179.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 1766792, "time": 80000.62282013893, "episode/length": 106.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 1767176, "time": 80015.17196083069, "episode/length": 529.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9924528301886792, "episode/intrinsic_return": 0.0}
{"step": 1767744, "time": 80036.49154090881, "episode/length": 235.0, "episode/score": 13.100000031292439, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1767792, "time": 80039.71658682823, "episode/length": 204.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 1767904, "time": 80045.15302324295, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 1768376, "time": 80062.57791852951, "episode/length": 197.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 1768776, "time": 80077.83685564995, "episode/length": 199.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 1768808, "time": 80080.47245717049, "episode/length": 378.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9894459102902374, "episode/intrinsic_return": 0.0}
{"step": 1768808, "time": 80080.48383903503, "episode/length": 505.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9980237154150198, "episode/intrinsic_return": 0.0}
{"step": 1769232, "time": 80098.41326403618, "episode/length": 52.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9245283018867925, "episode/intrinsic_return": 0.0}
{"step": 1769304, "time": 80102.11163258553, "episode/length": 188.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 1769504, "time": 80112.53009414673, "episode/length": 550.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9909255898366606, "episode/intrinsic_return": 0.0}
{"step": 1769544, "time": 80115.26588511467, "episode/length": 204.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 1770080, "time": 80157.65167689323, "eval_episode/length": 159.0, "eval_episode/score": 12.100000016391277, "eval_episode/reward_rate": 0.975}
{"step": 1770080, "time": 80159.59523105621, "eval_episode/length": 167.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 1770080, "time": 80161.29693198204, "eval_episode/length": 170.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 1770080, "time": 80173.45753407478, "eval_episode/length": 404.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9876543209876543}
{"step": 1770080, "time": 80176.8944838047, "eval_episode/length": 440.0, "eval_episode/score": 13.100000008940697, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 1770080, "time": 80179.84395933151, "eval_episode/length": 310.0, "eval_episode/score": 13.100000008940697, "eval_episode/reward_rate": 0.977491961414791}
{"step": 1770080, "time": 80182.97030472755, "eval_episode/length": 505.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9980237154150198}
{"step": 1770080, "time": 80184.55881762505, "eval_episode/length": 506.0, "eval_episode/score": 14.099999986588955, "eval_episode/reward_rate": 0.9980276134122288}
{"step": 1770344, "time": 80193.29749941826, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 1770808, "time": 80210.7949590683, "episode/length": 187.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 1770848, "time": 80213.9124405384, "episode/length": 387.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9974226804123711, "episode/intrinsic_return": 0.0}
{"step": 1770880, "time": 80216.58895969391, "episode/length": 205.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 1771288, "time": 80231.65956950188, "episode/length": 222.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 1771376, "time": 80236.52189660072, "episode/length": 374.0, "episode/score": 14.100000008940697, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 1771448, "time": 80240.52168774605, "episode/length": 237.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 1772344, "time": 80272.50488972664, "episode/length": 191.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 1772624, "time": 80283.71088647842, "episode/length": 217.0, "episode/score": 13.099999971687794, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1772760, "time": 80289.66560602188, "episode/length": 493.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9919028340080972, "episode/intrinsic_return": 0.0}
{"step": 1772976, "time": 80298.9152598381, "episode/length": 210.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1773272, "time": 80310.4904191494, "episode/length": 302.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9834983498349835, "episode/intrinsic_return": 0.0}
{"step": 1773568, "time": 80322.32709598541, "episode/length": 402.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9875930521091811, "episode/intrinsic_return": 0.0}
{"step": 1773656, "time": 80326.7322921753, "episode/length": 47.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 1773792, "time": 80333.13765573502, "episode/length": 301.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9900662251655629, "episode/intrinsic_return": 0.0}
{"step": 1773888, "time": 80338.0289568901, "episode/length": 192.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 1774440, "time": 80358.05712389946, "episode/length": 182.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 1774456, "time": 80360.1367995739, "episode/length": 375.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9973404255319149, "episode/intrinsic_return": 0.0}
{"step": 1774576, "time": 80365.89717411995, "episode/length": 243.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 1775208, "time": 80388.72787666321, "episode/length": 78.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 1775224, "time": 80390.91343045235, "episode/length": 206.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 1775912, "time": 80415.82357859612, "episode/length": 183.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 1776088, "time": 80423.50193357468, "episode/length": 274.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 1776096, "time": 80425.58004784584, "episode/length": 304.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9770491803278688, "episode/intrinsic_return": 0.0}
{"step": 1776640, "time": 80445.68110179901, "episode/length": 272.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 1777008, "time": 80459.92703032494, "episode/length": 136.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 1777160, "time": 80466.44675564766, "episode/length": 549.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9981818181818182, "episode/intrinsic_return": 0.0}
{"step": 1777480, "time": 80478.95973277092, "episode/length": 281.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 1777504, "time": 80481.6013686657, "episode/length": 286.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9965156794425087, "episode/intrinsic_return": 0.0}
{"step": 1777592, "time": 80485.90780925751, "episode/length": 474.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9831578947368421, "episode/intrinsic_return": 0.0}
{"step": 1778073, "time": 80509.44141888618, "train_stats/sum_log_reward": 11.706741777698646, "train_stats/max_log_achievement_collect_coal": 0.9438202247191011, "train_stats/max_log_achievement_collect_drink": 5.49438202247191, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.8314606741573034, "train_stats/max_log_achievement_collect_stone": 13.191011235955056, "train_stats/max_log_achievement_collect_wood": 10.426966292134832, "train_stats/max_log_achievement_defeat_skeleton": 0.12359550561797752, "train_stats/max_log_achievement_defeat_zombie": 1.5617977528089888, "train_stats/max_log_achievement_eat_cow": 0.6404494382022472, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0898876404494382, "train_stats/max_log_achievement_make_stone_sword": 0.10112359550561797, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3258426966292134, "train_stats/max_log_achievement_make_wood_sword": 1.1573033707865168, "train_stats/max_log_achievement_place_furnace": 2.101123595505618, "train_stats/max_log_achievement_place_plant": 1.7303370786516854, "train_stats/max_log_achievement_place_stone": 3.3820224719101124, "train_stats/max_log_achievement_place_table": 3.168539325842697, "train_stats/max_log_achievement_wake_up": 1.898876404494382, "train_stats/mean_log_entropy": 0.7628540644484959, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.033815220424107, "train/action_min": 0.0, "train/action_std": 3.7897223234176636, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.02548770402957286, "train/actor_opt_grad_steps": 110335.0, "train/actor_opt_loss": -10.508013652717429, "train/adv_mag": 0.3895384750195912, "train/adv_max": 0.34685696512460706, "train/adv_mean": 0.0012964793675207277, "train/adv_min": -0.3243594824203423, "train/adv_std": 0.039359659834631855, "train/cont_avg": 0.9961704799107143, "train/cont_loss_mean": 0.00026100030553704657, "train/cont_loss_std": 0.008150248892146855, "train/cont_neg_acc": 0.9866666670356478, "train/cont_neg_loss": 0.043963783983891905, "train/cont_pos_acc": 0.9999719798564911, "train/cont_pos_loss": 9.809814465564187e-05, "train/cont_pred": 0.9961872896977834, "train/cont_rate": 0.9961704799107143, "train/dyn_loss_mean": 12.690683685030256, "train/dyn_loss_std": 9.220050750459944, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8660535186529159, "train/extr_critic_critic_opt_grad_steps": 110335.0, "train/extr_critic_critic_opt_loss": 14735.631877790178, "train/extr_critic_mag": 10.436229385648454, "train/extr_critic_max": 10.436229385648454, "train/extr_critic_mean": 2.1347523050648824, "train/extr_critic_min": -0.26996632133211407, "train/extr_critic_std": 2.5049602729933604, "train/extr_return_normed_mag": 1.4970064682619912, "train/extr_return_normed_max": 1.4970064682619912, "train/extr_return_normed_mean": 0.29421702953321593, "train/extr_return_normed_min": -0.056177763381440725, "train/extr_return_normed_std": 0.32702664967094147, "train/extr_return_rate": 0.6477823078632354, "train/extr_return_raw_mag": 11.434695543561663, "train/extr_return_raw_max": 11.434695543561663, "train/extr_return_raw_mean": 2.144763654470444, "train/extr_return_raw_min": -0.5623656185609954, "train/extr_return_raw_std": 2.5265901940209523, "train/extr_reward_mag": 1.0545085838862829, "train/extr_reward_max": 1.0545085838862829, "train/extr_reward_mean": 0.041991461680403776, "train/extr_reward_min": -0.49873095495360237, "train/extr_reward_std": 0.1927235720413072, "train/image_loss_mean": 5.9724130494253975, "train/image_loss_std": 11.784502581187658, "train/model_loss_mean": 13.652641487121581, "train/model_loss_std": 15.542935507638115, "train/model_opt_grad_norm": 43.30649367741176, "train/model_opt_grad_steps": 110237.35714285714, "train/model_opt_loss": 19414.794601004465, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1419.642857142857, "train/policy_entropy_mag": 2.810974698407309, "train/policy_entropy_max": 2.810974698407309, "train/policy_entropy_mean": 0.9757469556161336, "train/policy_entropy_min": 0.07937501573136875, "train/policy_entropy_std": 1.0187543277229583, "train/policy_logprob_mag": 7.4383838108607705, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.9741307135139193, "train/policy_logprob_min": -7.4383838108607705, "train/policy_logprob_std": 1.334535906144551, "train/policy_randomness_mag": 0.9921507115874971, "train/policy_randomness_max": 0.9921507115874971, "train/policy_randomness_mean": 0.34439585911376136, "train/policy_randomness_min": 0.028015897343201295, "train/policy_randomness_std": 0.359575574525765, "train/post_ent_mag": 60.953388513837545, "train/post_ent_max": 60.953388513837545, "train/post_ent_mean": 43.70663397652762, "train/post_ent_min": 20.08204402923584, "train/post_ent_std": 7.735080208097186, "train/prior_ent_mag": 71.19183763776506, "train/prior_ent_max": 71.19183763776506, "train/prior_ent_mean": 56.49417931692941, "train/prior_ent_min": 40.34958011082241, "train/prior_ent_std": 4.8480539117540635, "train/rep_loss_mean": 12.690683685030256, "train/rep_loss_std": 9.220050750459944, "train/reward_avg": 0.04243722086373184, "train/reward_loss_mean": 0.06555727198719978, "train/reward_loss_std": 0.2594950215092727, "train/reward_max_data": 1.0235714341912951, "train/reward_max_pred": 1.0190139549119133, "train/reward_neg_acc": 0.9911027482577732, "train/reward_neg_loss": 0.030843448998140437, "train/reward_pos_acc": 0.9793268007891519, "train/reward_pos_loss": 0.7882218441792896, "train/reward_pred": 0.04156230394063251, "train/reward_rate": 0.04572405133928571, "eval_stats/sum_log_reward": 11.787500262260437, "eval_stats/max_log_achievement_collect_coal": 0.875, "eval_stats/max_log_achievement_collect_drink": 6.1875, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 12.8125, "eval_stats/max_log_achievement_collect_wood": 10.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.75, "eval_stats/max_log_achievement_eat_cow": 0.625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1875, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 2.0, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_stone": 3.25, "eval_stats/max_log_achievement_place_table": 2.875, "eval_stats/max_log_achievement_wake_up": 1.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 9.467959898756817e-06, "report/cont_loss_std": 0.0002635729033499956, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.001821652869693935, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.75981971451256e-07, "report/cont_pred": 0.9951255321502686, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.078758239746094, "report/dyn_loss_std": 8.908485412597656, "report/image_loss_mean": 4.91540002822876, "report/image_loss_std": 9.658502578735352, "report/model_loss_mean": 12.23979663848877, "report/model_loss_std": 13.49917221069336, "report/post_ent_mag": 58.13237762451172, "report/post_ent_max": 58.13237762451172, "report/post_ent_mean": 43.908302307128906, "report/post_ent_min": 18.47168731689453, "report/post_ent_std": 7.513641357421875, "report/prior_ent_mag": 71.38232421875, "report/prior_ent_max": 71.38232421875, "report/prior_ent_mean": 56.26318359375, "report/prior_ent_min": 40.852046966552734, "report/prior_ent_std": 4.647115230560303, "report/rep_loss_mean": 12.078758239746094, "report/rep_loss_std": 8.908485412597656, "report/reward_avg": 0.05087890475988388, "report/reward_loss_mean": 0.07713140547275543, "report/reward_loss_std": 0.30820074677467346, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0023634433746338, "report/reward_neg_acc": 0.9927685260772705, "report/reward_neg_loss": 0.031600773334503174, "report/reward_pos_acc": 0.9642857313156128, "report/reward_pos_loss": 0.8641610145568848, "report/reward_pred": 0.048544466495513916, "report/reward_rate": 0.0546875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 5.016583600081503e-06, "eval/cont_loss_std": 0.00014967186143621802, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00016288249753415585, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.707648258772679e-06, "eval/cont_pred": 0.9980425238609314, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 18.246667861938477, "eval/dyn_loss_std": 11.011777877807617, "eval/image_loss_mean": 9.226197242736816, "eval/image_loss_std": 14.940254211425781, "eval/model_loss_mean": 20.344219207763672, "eval/model_loss_std": 19.47019386291504, "eval/post_ent_mag": 58.90752410888672, "eval/post_ent_max": 58.90752410888672, "eval/post_ent_mean": 41.61945343017578, "eval/post_ent_min": 19.29263687133789, "eval/post_ent_std": 8.035408020019531, "eval/prior_ent_mag": 71.38232421875, "eval/prior_ent_max": 71.38232421875, "eval/prior_ent_mean": 57.40150451660156, "eval/prior_ent_min": 43.94215393066406, "eval/prior_ent_std": 4.347064018249512, "eval/rep_loss_mean": 18.246667861938477, "eval/rep_loss_std": 11.011777877807617, "eval/reward_avg": 0.06191406026482582, "eval/reward_loss_mean": 0.17001613974571228, "eval/reward_loss_std": 0.8163095712661743, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017998218536377, "eval/reward_neg_acc": 0.9916317462921143, "eval/reward_neg_loss": 0.04676573723554611, "eval/reward_pos_acc": 0.7647058963775635, "eval/reward_pos_loss": 1.9027714729309082, "eval/reward_pred": 0.0490657240152359, "eval/reward_rate": 0.06640625, "replay/size": 1000000.0, "replay/inserts": 22416.0, "replay/samples": 22416.0, "replay/insert_wait_avg": 1.3623873222563457e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.777544227180781e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6232.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.246303281673877e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4761445522308, "timer/env.step_count": 2802.0, "timer/env.step_total": 226.64665699005127, "timer/env.step_frac": 0.226538791778477, "timer/env.step_avg": 0.08088745788367283, "timer/env.step_min": 0.02433013916015625, "timer/env.step_max": 3.30353045463562, "timer/replay._sample_count": 22416.0, "timer/replay._sample_total": 11.729307889938354, "timer/replay._sample_frac": 0.011723725701813587, "timer/replay._sample_avg": 0.000523256062184973, "timer/replay._sample_min": 0.00042510032653808594, "timer/replay._sample_max": 0.02611064910888672, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3581.0, "timer/agent.policy_total": 63.51683330535889, "timer/agent.policy_frac": 0.06348660450448444, "timer/agent.policy_avg": 0.01773717768929318, "timer/agent.policy_min": 0.009669780731201172, "timer/agent.policy_max": 0.12795352935791016, "timer/dataset_train_count": 1401.0, "timer/dataset_train_total": 0.15473556518554688, "timer/dataset_train_frac": 0.0001546619237531143, "timer/dataset_train_avg": 0.00011044651333729256, "timer/dataset_train_min": 9.703636169433594e-05, "timer/dataset_train_max": 0.0005211830139160156, "timer/agent.train_count": 1401.0, "timer/agent.train_total": 632.7085292339325, "timer/agent.train_frac": 0.6324074118899707, "timer/agent.train_avg": 0.45161208367875266, "timer/agent.train_min": 0.4369981288909912, "timer/agent.train_max": 1.8792610168457031, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.478863000869751, "timer/agent.report_frac": 0.00047863510137372543, "timer/agent.report_avg": 0.2394315004348755, "timer/agent.report_min": 0.2301938533782959, "timer/agent.report_max": 0.24866914749145508, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7881698036255903e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 22.405005671268107}
{"step": 1778280, "time": 80516.2426378727, "episode/length": 204.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 1779064, "time": 80544.44381141663, "episode/length": 256.0, "episode/score": 14.100000038743019, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 1779072, "time": 80546.69955563545, "episode/length": 195.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 1779576, "time": 80565.37010574341, "episode/length": 434.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 1779872, "time": 80577.99504709244, "episode/length": 298.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9765886287625418, "episode/intrinsic_return": 0.0}
{"step": 1780040, "time": 80585.21521568298, "episode/length": 493.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9817813765182186, "episode/intrinsic_return": 0.0}
{"step": 1780064, "time": 80608.90746045113, "eval_episode/length": 168.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 1780064, "time": 80611.31495547295, "eval_episode/length": 185.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 1780064, "time": 80613.29054522514, "eval_episode/length": 194.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 1780064, "time": 80614.97734808922, "eval_episode/length": 197.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 1780064, "time": 80617.24852633476, "eval_episode/length": 211.0, "eval_episode/score": 14.100000008940697, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 1780064, "time": 80619.31058907509, "eval_episode/length": 221.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9864864864864865}
{"step": 1780064, "time": 80622.16613221169, "eval_episode/length": 249.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.996}
{"step": 1780064, "time": 80625.48971676826, "eval_episode/length": 287.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9965277777777778}
{"step": 1780080, "time": 80626.06070947647, "episode/length": 224.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1780648, "time": 80646.84296011925, "episode/length": 196.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 1780840, "time": 80654.85862970352, "episode/length": 405.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 1780912, "time": 80659.43823623657, "episode/length": 468.0, "episode/score": 14.099999964237213, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 1780936, "time": 80661.59361386299, "episode/length": 35.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1781096, "time": 80668.59361839294, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 1781376, "time": 80679.97374892235, "episode/length": 187.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 1782208, "time": 80710.05941224098, "episode/length": 392.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9974554707379135, "episode/intrinsic_return": 0.0}
{"step": 1782336, "time": 80716.07429146767, "episode/length": 186.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.983957219251337, "episode/intrinsic_return": 0.0}
{"step": 1782408, "time": 80720.07111620903, "episode/length": 183.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 1782560, "time": 80727.1014740467, "episode/length": 309.0, "episode/score": 14.100000008940697, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 1783160, "time": 80748.90524411201, "episode/length": 280.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9928825622775801, "episode/intrinsic_return": 0.0}
{"step": 1783488, "time": 80761.75728082657, "episode/length": 430.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9907192575406032, "episode/intrinsic_return": 0.0}
{"step": 1783648, "time": 80768.84134340286, "episode/length": 318.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9811912225705329, "episode/intrinsic_return": 0.0}
{"step": 1783824, "time": 80776.55934381485, "episode/length": 305.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9771241830065359, "episode/intrinsic_return": 0.0}
{"step": 1784224, "time": 80791.67351198196, "episode/length": 207.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 1784432, "time": 80800.28043460846, "episode/length": 252.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 1784792, "time": 80814.06845068932, "episode/length": 203.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1785064, "time": 80824.81863117218, "episode/length": 196.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 1785480, "time": 80840.54438471794, "episode/length": 228.0, "episode/score": 13.099999994039536, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 1785624, "time": 80846.8949816227, "episode/length": 410.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 1785656, "time": 80849.6312456131, "episode/length": 178.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 1786040, "time": 80865.9512245655, "episode/length": 478.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9853862212943633, "episode/intrinsic_return": 0.0}
{"step": 1786512, "time": 80883.97469592094, "episode/length": 259.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 1786664, "time": 80890.36917161942, "episode/length": 354.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9915492957746479, "episode/intrinsic_return": 0.0}
{"step": 1786928, "time": 80901.43635940552, "episode/length": 180.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 1787040, "time": 80906.80951094627, "episode/length": 280.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9715302491103203, "episode/intrinsic_return": 0.0}
{"step": 1787088, "time": 80910.13129258156, "episode/length": 252.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 1787176, "time": 80914.45333695412, "episode/length": 193.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 1787496, "time": 80927.15301632881, "episode/length": 181.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 1787576, "time": 80931.53810787201, "episode/length": 239.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 1787680, "time": 80936.87384414673, "episode/length": 126.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 1788064, "time": 80951.41826105118, "episode/length": 121.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9508196721311475, "episode/intrinsic_return": 0.0}
{"step": 1788312, "time": 80961.19833827019, "episode/length": 224.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1788320, "time": 80963.29946136475, "episode/length": 159.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 1788648, "time": 80975.80197906494, "episode/length": 183.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 1789080, "time": 80992.19792628288, "episode/length": 197.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 1789296, "time": 81001.35624742508, "episode/length": 121.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9590163934426229, "episode/intrinsic_return": 0.0}
{"step": 1789448, "time": 81007.92201018333, "episode/length": 314.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 1789848, "time": 81022.95040416718, "episode/length": 222.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 1790048, "time": 81046.72896003723, "eval_episode/length": 49.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.98}
{"step": 1790048, "time": 81049.07373023033, "eval_episode/length": 66.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9701492537313433}
{"step": 1790048, "time": 81054.7007496357, "eval_episode/length": 157.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9620253164556962}
{"step": 1790048, "time": 81059.13582110405, "eval_episode/length": 218.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9817351598173516}
{"step": 1790048, "time": 81061.25820422173, "eval_episode/length": 230.0, "eval_episode/score": 14.100000008940697, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 1790048, "time": 81065.80367660522, "eval_episode/length": 255.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.984375}
{"step": 1790048, "time": 81069.14352655411, "eval_episode/length": 220.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9728506787330317}
{"step": 1790048, "time": 81072.93143463135, "eval_episode/length": 288.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.986159169550173}
{"step": 1790104, "time": 81074.5996954441, "episode/length": 223.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1790448, "time": 81088.11541366577, "episode/length": 224.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1790672, "time": 81097.325111866, "episode/length": 373.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9893048128342246, "episode/intrinsic_return": 0.0}
{"step": 1790912, "time": 81107.06250333786, "episode/length": 201.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 1790928, "time": 81109.16693854332, "episode/length": 418.0, "episode/score": 13.100000038743019, "episode/reward_rate": 0.9976133651551312, "episode/intrinsic_return": 0.0}
{"step": 1791624, "time": 81134.07770323753, "episode/length": 221.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 1791760, "time": 81140.52350282669, "episode/length": 288.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 1791952, "time": 81148.70450782776, "episode/length": 187.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 1792520, "time": 81169.25945615768, "episode/length": 429.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9976744186046511, "episode/intrinsic_return": 0.0}
{"step": 1792592, "time": 81173.58179783821, "episode/length": 207.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 1793312, "time": 81199.42184662819, "episode/length": 210.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 1793520, "time": 81208.0592622757, "episode/length": 195.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 1793568, "time": 81211.364528656, "episode/length": 225.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 1793656, "time": 81215.77828860283, "episode/length": 132.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 1793816, "time": 81222.79502940178, "episode/length": 161.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1793824, "time": 81224.91041469574, "episode/length": 464.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9763440860215054, "episode/intrinsic_return": 0.0}
{"step": 1794968, "time": 81266.79338645935, "episode/length": 174.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 1795000, "time": 81269.57201123238, "episode/length": 540.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9981515711645101, "episode/intrinsic_return": 0.0}
{"step": 1795224, "time": 81278.76246070862, "episode/length": 174.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 1795304, "time": 81282.94828224182, "episode/length": 248.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 1795488, "time": 81291.20705938339, "episode/length": 245.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 1795512, "time": 81293.53225660324, "episode/length": 574.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9965217391304347, "episode/intrinsic_return": 0.0}
{"step": 1795944, "time": 81309.67181038857, "episode/length": 53.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 1796472, "time": 81329.32189273834, "episode/length": 183.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 1796808, "time": 81342.31351494789, "episode/length": 187.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 1796880, "time": 81346.70450901985, "episode/length": 382.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9843342036553525, "episode/intrinsic_return": 0.0}
{"step": 1796944, "time": 81350.44297337532, "episode/length": 181.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 1797912, "time": 81384.51506614685, "episode/length": 531.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9849624060150376, "episode/intrinsic_return": 0.0}
{"step": 1798272, "time": 81398.58621764183, "episode/length": 290.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 1798312, "time": 81401.83323073387, "episode/length": 187.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 1798392, "time": 81406.75984621048, "episode/length": 180.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 1798600, "time": 81415.3863325119, "episode/length": 453.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9977973568281938, "episode/intrinsic_return": 0.0}
{"step": 1799080, "time": 81433.07462310791, "episode/length": 481.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 1799368, "time": 81444.54960107803, "episode/length": 361.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9861878453038674, "episode/intrinsic_return": 0.0}
{"step": 1800032, "time": 81490.65251278877, "eval_episode/length": 192.0, "eval_episode/score": 11.100000031292439, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 1800032, "time": 81495.10185241699, "eval_episode/length": 253.0, "eval_episode/score": 12.100000023841858, "eval_episode/reward_rate": 0.9724409448818898}
{"step": 1800032, "time": 81497.45611596107, "eval_episode/length": 266.0, "eval_episode/score": 13.100000008940697, "eval_episode/reward_rate": 0.9962546816479401}
{"step": 1800032, "time": 81500.61459183693, "eval_episode/length": 302.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.976897689768977}
{"step": 1800032, "time": 81503.10271048546, "eval_episode/length": 321.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.984472049689441}
{"step": 1800032, "time": 81504.88189101219, "eval_episode/length": 324.0, "eval_episode/score": 14.100000008940697, "eval_episode/reward_rate": 0.9846153846153847}
{"step": 1800032, "time": 81511.70022654533, "eval_episode/length": 245.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9715447154471545}
{"step": 1800032, "time": 81514.34005260468, "eval_episode/length": 207.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9711538461538461}
{"step": 1800033, "time": 81514.94812512398, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.988931697650547, "train/action_min": 0.0, "train/action_std": 3.711715512032056, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.024958325074101888, "train/actor_opt_grad_steps": 111720.0, "train/actor_opt_loss": -5.445978502379255, "train/adv_mag": 0.3710704054275568, "train/adv_max": 0.3477443606749068, "train/adv_mean": 0.0017287508782337549, "train/adv_min": -0.2902994406049269, "train/adv_std": 0.038929399864299455, "train/cont_avg": 0.9960581090328468, "train/cont_loss_mean": 4.861897306910083e-05, "train/cont_loss_std": 0.0014582463748682455, "train/cont_neg_acc": 0.9975308643447028, "train/cont_neg_loss": 0.007462288719243252, "train/cont_pos_acc": 0.9999928248189661, "train/cont_pos_loss": 2.3019270511268734e-05, "train/cont_pred": 0.9960579367449683, "train/cont_rate": 0.9960581090328468, "train/dyn_loss_mean": 12.409874749009626, "train/dyn_loss_std": 9.19321724968235, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8951958069836137, "train/extr_critic_critic_opt_grad_steps": 111720.0, "train/extr_critic_critic_opt_loss": 14848.397432424727, "train/extr_critic_mag": 10.469734943696182, "train/extr_critic_max": 10.469734943696182, "train/extr_critic_mean": 2.1331867301551095, "train/extr_critic_min": -0.2755592017278184, "train/extr_critic_std": 2.5096620495301964, "train/extr_return_normed_mag": 1.4761456834138744, "train/extr_return_normed_max": 1.4761456834138744, "train/extr_return_normed_mean": 0.28932222212753156, "train/extr_return_normed_min": -0.05287946483297069, "train/extr_return_normed_std": 0.3231642001519238, "train/extr_return_rate": 0.6588679819646543, "train/extr_return_raw_mag": 11.451767232296241, "train/extr_return_raw_max": 11.451767232296241, "train/extr_return_raw_mean": 2.1467343847246934, "train/extr_return_raw_min": -0.5362399306393018, "train/extr_return_raw_std": 2.533574556782298, "train/extr_reward_mag": 1.0552965776763694, "train/extr_reward_max": 1.0552965776763694, "train/extr_reward_mean": 0.04254928459651279, "train/extr_reward_min": -0.4729795995419913, "train/extr_reward_std": 0.19406190786483515, "train/image_loss_mean": 5.937365486674065, "train/image_loss_std": 11.654454269548403, "train/model_loss_mean": 13.447427394616343, "train/model_loss_std": 15.35965598586702, "train/model_opt_grad_norm": 41.46537673560372, "train/model_opt_grad_steps": 111621.25547445256, "train/model_opt_loss": 20127.565550866788, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1496.3503649635036, "train/policy_entropy_mag": 2.80376055814924, "train/policy_entropy_max": 2.80376055814924, "train/policy_entropy_mean": 0.9286241044093223, "train/policy_entropy_min": 0.0793750159931879, "train/policy_entropy_std": 1.0005133534870008, "train/policy_logprob_mag": 7.438383882063149, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.9273924362050355, "train/policy_logprob_min": -7.438383882063149, "train/policy_logprob_std": 1.32228611507555, "train/policy_randomness_mag": 0.9896044356979593, "train/policy_randomness_max": 0.9896044356979593, "train/policy_randomness_mean": 0.32776355884806085, "train/policy_randomness_min": 0.028015897452940038, "train/policy_randomness_std": 0.353137308228625, "train/post_ent_mag": 61.87555346523758, "train/post_ent_max": 61.87555346523758, "train/post_ent_mean": 44.01293251984311, "train/post_ent_min": 20.05730337992202, "train/post_ent_std": 7.86616118632964, "train/prior_ent_mag": 71.2535265623218, "train/prior_ent_max": 71.2535265623218, "train/prior_ent_mean": 56.57248169836337, "train/prior_ent_min": 39.638934114553635, "train/prior_ent_std": 4.967613693571439, "train/rep_loss_mean": 12.409874749009626, "train/rep_loss_std": 9.19321724968235, "train/reward_avg": 0.04130360349523325, "train/reward_loss_mean": 0.06408848374211876, "train/reward_loss_std": 0.2553292317111997, "train/reward_max_data": 1.029197087253097, "train/reward_max_pred": 1.023852416198619, "train/reward_neg_acc": 0.991064147357523, "train/reward_neg_loss": 0.030125462164572122, "train/reward_pos_acc": 0.9807901164911089, "train/reward_pos_loss": 0.7929688600728112, "train/reward_pred": 0.04060626220311562, "train/reward_rate": 0.044914746806569344, "train_stats/sum_log_reward": 11.85000011920929, "train_stats/max_log_achievement_collect_coal": 1.35, "train_stats/max_log_achievement_collect_drink": 6.2375, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.9375, "train_stats/max_log_achievement_collect_stone": 14.525, "train_stats/max_log_achievement_collect_wood": 10.4125, "train_stats/max_log_achievement_defeat_skeleton": 0.1, "train_stats/max_log_achievement_defeat_zombie": 1.7, "train_stats/max_log_achievement_eat_cow": 0.65, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0625, "train_stats/max_log_achievement_make_stone_sword": 0.075, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3625, "train_stats/max_log_achievement_make_wood_sword": 1.25, "train_stats/max_log_achievement_place_furnace": 2.4625, "train_stats/max_log_achievement_place_plant": 1.85, "train_stats/max_log_achievement_place_stone": 3.225, "train_stats/max_log_achievement_place_table": 3.2875, "train_stats/max_log_achievement_wake_up": 1.95, "train_stats/mean_log_entropy": 0.7514445884153247, "eval_stats/sum_log_reward": 11.05833351612091, "eval_stats/max_log_achievement_collect_coal": 1.0, "eval_stats/max_log_achievement_collect_drink": 4.625, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 12.791666666666666, "eval_stats/max_log_achievement_collect_wood": 9.458333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.16666666666666666, "eval_stats/max_log_achievement_defeat_zombie": 1.75, "eval_stats/max_log_achievement_eat_cow": 0.5833333333333334, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.16666666666666666, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.2083333333333333, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 2.1666666666666665, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 2.5, "eval_stats/max_log_achievement_place_table": 3.0833333333333335, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 3.234438281651819e-07, "report/cont_loss_std": 3.154629212076543e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.484861008473672e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.2199866123173706e-07, "report/cont_pred": 0.9970703125, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.534843444824219, "report/dyn_loss_std": 9.320696830749512, "report/image_loss_mean": 6.025412082672119, "report/image_loss_std": 11.723602294921875, "report/model_loss_mean": 13.602132797241211, "report/model_loss_std": 15.643468856811523, "report/post_ent_mag": 60.19269943237305, "report/post_ent_max": 60.19269943237305, "report/post_ent_mean": 44.01362609863281, "report/post_ent_min": 21.01584243774414, "report/post_ent_std": 7.429792881011963, "report/prior_ent_mag": 71.23114013671875, "report/prior_ent_max": 71.23114013671875, "report/prior_ent_mean": 56.843528747558594, "report/prior_ent_min": 42.64826583862305, "report/prior_ent_std": 4.763843536376953, "report/rep_loss_mean": 12.534843444824219, "report/rep_loss_std": 9.320696830749512, "report/reward_avg": 0.0361328125, "report/reward_loss_mean": 0.055814750492572784, "report/reward_loss_std": 0.1897011399269104, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006229877471924, "report/reward_neg_acc": 0.9928789734840393, "report/reward_neg_loss": 0.027484014630317688, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.7350612878799438, "report/reward_pred": 0.03576720505952835, "report/reward_rate": 0.0400390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.433945883240085e-05, "eval/cont_loss_std": 0.0007663786527700722, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 4.902538421447389e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.4266924810945056e-05, "eval/cont_pred": 0.9970465898513794, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.472604751586914, "eval/dyn_loss_std": 11.5989990234375, "eval/image_loss_mean": 8.091426849365234, "eval/image_loss_std": 11.444884300231934, "eval/model_loss_mean": 18.078689575195312, "eval/model_loss_std": 16.166608810424805, "eval/post_ent_mag": 60.22881317138672, "eval/post_ent_max": 60.22881317138672, "eval/post_ent_mean": 42.908939361572266, "eval/post_ent_min": 20.057483673095703, "eval/post_ent_std": 8.183121681213379, "eval/prior_ent_mag": 71.23114013671875, "eval/prior_ent_max": 71.23114013671875, "eval/prior_ent_mean": 57.3628044128418, "eval/prior_ent_min": 39.12405014038086, "eval/prior_ent_std": 4.801514625549316, "eval/rep_loss_mean": 16.472604751586914, "eval/rep_loss_std": 11.5989990234375, "eval/reward_avg": 0.04326171800494194, "eval/reward_loss_mean": 0.10367625951766968, "eval/reward_loss_std": 0.5290140509605408, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001668930053711, "eval/reward_neg_acc": 0.9856703877449036, "eval/reward_neg_loss": 0.0441862978041172, "eval/reward_pos_acc": 0.8936169743537903, "eval/reward_pos_loss": 1.3403080701828003, "eval/reward_pred": 0.042322732508182526, "eval/reward_rate": 0.0458984375, "replay/size": 1000000.0, "replay/inserts": 21960.0, "replay/samples": 21952.0, "replay/insert_wait_avg": 1.352352305622483e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.228655806783337e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 8712.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.231090424803006e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1008.0296766757965, "timer/env.step_count": 2745.0, "timer/env.step_total": 210.1252565383911, "timer/env.step_frac": 0.2084514587222533, "timer/env.step_avg": 0.07654836303766525, "timer/env.step_min": 0.024232864379882812, "timer/env.step_max": 2.3745453357696533, "timer/replay._sample_count": 21952.0, "timer/replay._sample_total": 11.403797149658203, "timer/replay._sample_frac": 0.011312957756625556, "timer/replay._sample_avg": 0.0005194878439166456, "timer/replay._sample_min": 0.0003833770751953125, "timer/replay._sample_max": 0.008795976638793945, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3834.0, "timer/agent.policy_total": 67.57723140716553, "timer/agent.policy_frac": 0.06703893047079384, "timer/agent.policy_avg": 0.0176257776231522, "timer/agent.policy_min": 0.009956598281860352, "timer/agent.policy_max": 0.3185126781463623, "timer/dataset_train_count": 1372.0, "timer/dataset_train_total": 0.15317606925964355, "timer/dataset_train_frac": 0.00015195591241398362, "timer/dataset_train_avg": 0.00011164436534959443, "timer/dataset_train_min": 9.775161743164062e-05, "timer/dataset_train_max": 0.0010645389556884766, "timer/agent.train_count": 1372.0, "timer/agent.train_total": 617.6477885246277, "timer/agent.train_frac": 0.6127277825405493, "timer/agent.train_avg": 0.45018060388092396, "timer/agent.train_min": 0.43674635887145996, "timer/agent.train_max": 1.7770509719848633, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47963786125183105, "timer/agent.report_frac": 0.000475817202955318, "timer/agent.report_avg": 0.23981893062591553, "timer/agent.report_min": 0.23413538932800293, "timer/agent.report_max": 0.24550247192382812, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 3.334923607029107e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 21.784783284815944}
{"step": 1800168, "time": 81519.57138299942, "episode/length": 221.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 1800352, "time": 81527.57480764389, "episode/length": 304.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9967213114754099, "episode/intrinsic_return": 0.0}
{"step": 1800360, "time": 81529.21890902519, "episode/length": 219.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 1800832, "time": 81546.83436512947, "episode/length": 218.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 1801008, "time": 81554.29514527321, "episode/length": 515.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 1801400, "time": 81568.99391412735, "episode/length": 385.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9870466321243523, "episode/intrinsic_return": 0.0}
{"step": 1801880, "time": 81586.81582307816, "episode/length": 190.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 1801960, "time": 81591.04595637321, "episode/length": 199.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 1802056, "time": 81595.96601486206, "episode/length": 235.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1802176, "time": 81601.89015245438, "episode/length": 167.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1802424, "time": 81613.40744566917, "episode/length": 45.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 1802520, "time": 81618.42062520981, "episode/length": 188.0, "episode/score": 13.099999971687794, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 1802520, "time": 81618.43205094337, "episode/length": 530.0, "episode/score": 13.100000031292439, "episode/reward_rate": 0.9962335216572504, "episode/intrinsic_return": 0.0}
{"step": 1803280, "time": 81647.77558732033, "episode/length": 164.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 1803624, "time": 81660.67435312271, "episode/length": 180.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 1803768, "time": 81666.98306584358, "episode/length": 155.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 1803864, "time": 81671.7676217556, "episode/length": 247.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9879032258064516, "episode/intrinsic_return": 0.0}
{"step": 1804216, "time": 81685.18982338905, "episode/length": 351.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9971590909090909, "episode/intrinsic_return": 0.0}
{"step": 1804272, "time": 81688.84418654442, "episode/length": 230.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 1804288, "time": 81691.0479221344, "episode/length": 614.0, "episode/score": 15.099999979138374, "episode/reward_rate": 0.9983739837398374, "episode/intrinsic_return": 0.0}
{"step": 1804400, "time": 81696.4109146595, "episode/length": 234.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 1804960, "time": 81716.8013715744, "episode/length": 166.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 1805016, "time": 81719.97668099403, "episode/length": 216.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1805560, "time": 81739.96157646179, "episode/length": 223.0, "episode/score": 13.099999994039536, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1805592, "time": 81742.59767746925, "episode/length": 71.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 1805880, "time": 81753.95518136024, "episode/length": 184.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 1805952, "time": 81758.17009210587, "episode/length": 207.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 1806016, "time": 81762.02339458466, "episode/length": 224.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1806104, "time": 81766.46760034561, "episode/length": 228.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 1806392, "time": 81777.76479101181, "episode/length": 178.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 1807168, "time": 81805.86434841156, "episode/length": 196.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 1807320, "time": 81812.40473270416, "episode/length": 219.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 1807560, "time": 81822.18372750282, "episode/length": 192.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 1807664, "time": 81827.62713170052, "episode/length": 222.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 1807672, "time": 81829.25322389603, "episode/length": 195.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 1807936, "time": 81839.94879341125, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 1808048, "time": 81845.3279261589, "episode/length": 90.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 1808368, "time": 81857.76836967468, "episode/length": 301.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 1809080, "time": 81883.17125296593, "episode/length": 189.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 1809176, "time": 81888.0768969059, "episode/length": 188.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 1809328, "time": 81895.04494071007, "episode/length": 119.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 1809376, "time": 81898.25125598907, "episode/length": 36.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 1809392, "time": 81900.76438879967, "episode/length": 181.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 1809504, "time": 81906.59918737411, "episode/length": 228.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 1809512, "time": 81908.33733057976, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 1809816, "time": 81920.25314950943, "episode/length": 743.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 1810016, "time": 81946.38565659523, "eval_episode/length": 95.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9895833333333334}
{"step": 1810016, "time": 81951.20953845978, "eval_episode/length": 168.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 1810016, "time": 81953.71579313278, "eval_episode/length": 186.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 1810016, "time": 81956.48966121674, "eval_episode/length": 211.0, "eval_episode/score": 11.099999971687794, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 1810016, "time": 81958.92797136307, "eval_episode/length": 230.0, "eval_episode/score": 11.099999979138374, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 1810016, "time": 81960.73732161522, "eval_episode/length": 236.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9957805907172996}
{"step": 1810016, "time": 81962.45242905617, "eval_episode/length": 239.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 1810016, "time": 81965.05200839043, "eval_episode/length": 167.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 1810088, "time": 81967.261510849, "episode/length": 364.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9917808219178083, "episode/intrinsic_return": 0.0}
{"step": 1810768, "time": 81993.68999385834, "episode/length": 173.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 1810816, "time": 81996.92182278633, "episode/length": 177.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 1811280, "time": 82014.34987258911, "episode/length": 182.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 1811376, "time": 82019.15685367584, "episode/length": 274.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9745454545454545, "episode/intrinsic_return": 0.0}
{"step": 1811408, "time": 82021.87788391113, "episode/length": 237.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 1812448, "time": 82058.5978500843, "episode/length": 203.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 1812496, "time": 82061.80174255371, "episode/length": 215.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 1812904, "time": 82077.11070299149, "episode/length": 423.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9787735849056604, "episode/intrinsic_return": 0.0}
{"step": 1813104, "time": 82085.73119568825, "episode/length": 227.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 1813464, "time": 82099.31308174133, "episode/length": 516.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9903288201160542, "episode/intrinsic_return": 0.0}
{"step": 1813840, "time": 82113.86115527153, "episode/length": 307.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9805194805194806, "episode/intrinsic_return": 0.0}
{"step": 1814504, "time": 82137.83039283752, "episode/length": 199.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 1814648, "time": 82144.41370797157, "episode/length": 192.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 1815136, "time": 82162.8419778347, "episode/length": 78.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9493670886075949, "episode/intrinsic_return": 0.0}
{"step": 1815152, "time": 82164.88986444473, "episode/length": 467.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9978632478632479, "episode/intrinsic_return": 0.0}
{"step": 1815224, "time": 82168.70786523819, "episode/length": 340.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9912023460410557, "episode/intrinsic_return": 0.0}
{"step": 1815608, "time": 82183.25380373001, "episode/length": 267.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 1815680, "time": 82187.57244038582, "episode/length": 229.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 1815712, "time": 82190.2093424797, "episode/length": 407.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 1816320, "time": 82212.34088277817, "episode/length": 778.0, "episode/score": 15.099999986588955, "episode/reward_rate": 0.9987163029525032, "episode/intrinsic_return": 0.0}
{"step": 1816768, "time": 82229.16049361229, "episode/length": 203.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 1816880, "time": 82234.56733679771, "episode/length": 278.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 1817112, "time": 82243.831107378, "episode/length": 235.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 1817144, "time": 82246.68166708946, "episode/length": 248.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 1818168, "time": 82282.9752008915, "episode/length": 230.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 1818672, "time": 82303.76024413109, "episode/length": 223.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 1818720, "time": 82307.12630319595, "episode/length": 388.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9922879177377892, "episode/intrinsic_return": 0.0}
{"step": 1818776, "time": 82310.38170051575, "episode/length": 203.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 1818960, "time": 82318.51436901093, "episode/length": 273.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9744525547445255, "episode/intrinsic_return": 0.0}
{"step": 1819696, "time": 82344.99345254898, "episode/length": 190.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 1819776, "time": 82349.20372462273, "episode/length": 511.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 1819936, "time": 82356.25430202484, "episode/length": 527.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.990530303030303, "episode/intrinsic_return": 0.0}
{"step": 1820000, "time": 82375.14650940895, "eval_episode/length": 42.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.8837209302325582}
{"step": 1820000, "time": 82379.40401220322, "eval_episode/length": 102.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9902912621359223}
{"step": 1820000, "time": 82383.57111763954, "eval_episode/length": 156.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9617834394904459}
{"step": 1820000, "time": 82386.77499055862, "eval_episode/length": 191.0, "eval_episode/score": 13.100000001490116, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 1820000, "time": 82388.47042107582, "eval_episode/length": 193.0, "eval_episode/score": 13.100000001490116, "eval_episode/reward_rate": 0.979381443298969}
{"step": 1820000, "time": 82393.34721827507, "eval_episode/length": 221.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 1820000, "time": 82396.72833943367, "eval_episode/length": 258.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9961389961389961}
{"step": 1820000, "time": 82398.96569132805, "eval_episode/length": 229.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 1820504, "time": 82415.80033874512, "episode/length": 222.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 1820720, "time": 82424.92204165459, "episode/length": 242.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 1820736, "time": 82427.34413671494, "episode/length": 452.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9867549668874173, "episode/intrinsic_return": 0.0}
{"step": 1821008, "time": 82437.97884893417, "episode/length": 291.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 1821056, "time": 82441.21952176094, "episode/length": 41.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1821256, "time": 82449.39153814316, "episode/length": 184.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 1821376, "time": 82455.15343761444, "episode/length": 301.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9801324503311258, "episode/intrinsic_return": 0.0}
{"step": 1821408, "time": 82457.95038366318, "episode/length": 213.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 1821496, "time": 82462.21043515205, "episode/length": 194.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 1822552, "time": 82499.50355362892, "episode/length": 142.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.958041958041958, "episode/intrinsic_return": 0.0}
{"step": 1822648, "time": 82504.35929512978, "episode/length": 173.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 1822720, "time": 82508.68140172958, "episode/length": 247.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 1822824, "time": 82513.50601577759, "episode/length": 220.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 1822825, "time": 82516.20804905891, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.98774815272618, "train/action_min": 0.0, "train/action_std": 3.7296488051647905, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.02564166834043873, "train/actor_opt_grad_steps": 113120.0, "train/actor_opt_loss": -8.694401175500108, "train/adv_mag": 0.39131619557217284, "train/adv_max": 0.35243754620318646, "train/adv_mean": 0.001521494633182753, "train/adv_min": -0.3192474249151203, "train/adv_std": 0.03972383464810315, "train/cont_avg": 0.9959093640734266, "train/cont_loss_mean": 8.017970873711829e-05, "train/cont_loss_std": 0.002350431642700921, "train/cont_neg_acc": 0.9989939642624116, "train/cont_neg_loss": 0.005749498353958496, "train/cont_pos_acc": 0.999986236745661, "train/cont_pos_loss": 5.374515712070199e-05, "train/cont_pred": 0.9958998948544056, "train/cont_rate": 0.9959093640734266, "train/dyn_loss_mean": 12.67952737608156, "train/dyn_loss_std": 9.273502696644176, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8868577467811691, "train/extr_critic_critic_opt_grad_steps": 113120.0, "train/extr_critic_critic_opt_loss": 14823.528176901224, "train/extr_critic_mag": 10.359324635325612, "train/extr_critic_max": 10.359324635325612, "train/extr_critic_mean": 2.1884940762619873, "train/extr_critic_min": -0.2680055003066163, "train/extr_critic_std": 2.492891343323501, "train/extr_return_normed_mag": 1.490104652784921, "train/extr_return_normed_max": 1.490104652784921, "train/extr_return_normed_mean": 0.2997719411041353, "train/extr_return_normed_min": -0.055012331520031384, "train/extr_return_normed_std": 0.3262691086197233, "train/extr_return_rate": 0.6773210228323103, "train/extr_return_raw_mag": 11.375162177986198, "train/extr_return_raw_max": 11.375162177986198, "train/extr_return_raw_mean": 2.2002148607394076, "train/extr_return_raw_min": -0.5345469115080533, "train/extr_return_raw_std": 2.5151688469039812, "train/extr_reward_mag": 1.0573642487292523, "train/extr_reward_max": 1.0573642487292523, "train/extr_reward_mean": 0.042529178965654404, "train/extr_reward_min": -0.45554090963376986, "train/extr_reward_std": 0.19398055803942513, "train/image_loss_mean": 6.068779035048052, "train/image_loss_std": 12.099512627074768, "train/model_loss_mean": 13.742586849452731, "train/model_loss_std": 15.850333207137101, "train/model_opt_grad_norm": 42.59811405368618, "train/model_opt_grad_steps": 113019.94405594406, "train/model_opt_loss": 20778.367726999564, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1512.2377622377621, "train/policy_entropy_mag": 2.8107571801939213, "train/policy_entropy_max": 2.8107571801939213, "train/policy_entropy_mean": 0.9362607314870074, "train/policy_entropy_min": 0.07937501709569585, "train/policy_entropy_std": 0.9984365605807805, "train/policy_logprob_mag": 7.438383896034081, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.9366792882239068, "train/policy_logprob_min": -7.438383896034081, "train/policy_logprob_std": 1.3249776530099082, "train/policy_randomness_mag": 0.9920739339781808, "train/policy_randomness_max": 0.9920739339781808, "train/policy_randomness_mean": 0.33045895939523523, "train/policy_randomness_min": 0.028015897824214056, "train/policy_randomness_std": 0.35240429139637447, "train/post_ent_mag": 61.65559990089256, "train/post_ent_max": 61.65559990089256, "train/post_ent_mean": 43.76971227472479, "train/post_ent_min": 20.153786332457216, "train/post_ent_std": 7.86979086415751, "train/prior_ent_mag": 71.17069377765789, "train/prior_ent_max": 71.17069377765789, "train/prior_ent_mean": 56.550516221906754, "train/prior_ent_min": 39.86855809671896, "train/prior_ent_std": 4.928326940203046, "train/rep_loss_mean": 12.67952737608156, "train/rep_loss_std": 9.273502696644176, "train/reward_avg": 0.04305479657295701, "train/reward_loss_mean": 0.06601119601538966, "train/reward_loss_std": 0.2591724003945197, "train/reward_max_data": 1.032167839837241, "train/reward_max_pred": 1.0263335579758757, "train/reward_neg_acc": 0.9913281756681163, "train/reward_neg_loss": 0.030818853768279086, "train/reward_pos_acc": 0.9786734189186896, "train/reward_pos_loss": 0.790891211766463, "train/reward_pred": 0.04227072710392775, "train/reward_rate": 0.04667012674825175, "train_stats/sum_log_reward": 11.295652467271555, "train_stats/max_log_achievement_collect_coal": 0.7934782608695652, "train_stats/max_log_achievement_collect_drink": 5.532608695652174, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.815217391304348, "train_stats/max_log_achievement_collect_stone": 13.902173913043478, "train_stats/max_log_achievement_collect_wood": 10.73913043478261, "train_stats/max_log_achievement_defeat_skeleton": 0.07608695652173914, "train_stats/max_log_achievement_defeat_zombie": 1.5978260869565217, "train_stats/max_log_achievement_eat_cow": 0.6195652173913043, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.05434782608695652, "train_stats/max_log_achievement_make_stone_sword": 0.06521739130434782, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3695652173913044, "train_stats/max_log_achievement_make_wood_sword": 1.434782608695652, "train_stats/max_log_achievement_place_furnace": 2.3260869565217392, "train_stats/max_log_achievement_place_plant": 1.7282608695652173, "train_stats/max_log_achievement_place_stone": 3.3043478260869565, "train_stats/max_log_achievement_place_table": 3.3152173913043477, "train_stats/max_log_achievement_wake_up": 1.8369565217391304, "train_stats/mean_log_entropy": 0.7087732927630777, "eval_stats/sum_log_reward": 10.850000232458115, "eval_stats/max_log_achievement_collect_coal": 0.9375, "eval_stats/max_log_achievement_collect_drink": 3.625, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.1875, "eval_stats/max_log_achievement_collect_stone": 13.5, "eval_stats/max_log_achievement_collect_wood": 9.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.4375, "eval_stats/max_log_achievement_eat_cow": 0.4375, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.4375, "eval_stats/max_log_achievement_make_wood_sword": 1.1875, "eval_stats/max_log_achievement_place_furnace": 2.375, "eval_stats/max_log_achievement_place_plant": 1.0625, "eval_stats/max_log_achievement_place_stone": 2.6875, "eval_stats/max_log_achievement_place_table": 2.9375, "eval_stats/max_log_achievement_wake_up": 0.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.00032716980786062777, "report/cont_loss_std": 0.010182349942624569, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.11061879992485046, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.1003612548374804e-06, "report/cont_pred": 0.9973446130752563, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.453964233398438, "report/dyn_loss_std": 9.366755485534668, "report/image_loss_mean": 6.695114612579346, "report/image_loss_std": 12.886726379394531, "report/model_loss_mean": 14.226592063903809, "report/model_loss_std": 16.701074600219727, "report/post_ent_mag": 62.06021499633789, "report/post_ent_max": 62.06021499633789, "report/post_ent_mean": 45.2349739074707, "report/post_ent_min": 21.973407745361328, "report/post_ent_std": 8.165432929992676, "report/prior_ent_mag": 71.0957260131836, "report/prior_ent_max": 71.0957260131836, "report/prior_ent_mean": 57.57440185546875, "report/prior_ent_min": 43.18010711669922, "report/prior_ent_std": 4.74302339553833, "report/rep_loss_mean": 12.453964233398438, "report/rep_loss_std": 9.366755485534668, "report/reward_avg": 0.03291015699505806, "report/reward_loss_mean": 0.058771584182977676, "report/reward_loss_std": 0.2876889705657959, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011849403381348, "report/reward_neg_acc": 0.9908907413482666, "report/reward_neg_loss": 0.023920288309454918, "report/reward_pos_acc": 0.944444477558136, "report/reward_pos_loss": 1.015246033668518, "report/reward_pred": 0.029188700020313263, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.4285572433436755e-05, "eval/cont_loss_std": 0.0003311743785161525, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.005305306985974312, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.931323135475395e-06, "eval/cont_pred": 0.998053252696991, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 16.73942756652832, "eval/dyn_loss_std": 10.976637840270996, "eval/image_loss_mean": 10.417929649353027, "eval/image_loss_std": 16.182357788085938, "eval/model_loss_mean": 20.56707763671875, "eval/model_loss_std": 20.536109924316406, "eval/post_ent_mag": 63.83216857910156, "eval/post_ent_max": 63.83216857910156, "eval/post_ent_mean": 43.03078842163086, "eval/post_ent_min": 21.493270874023438, "eval/post_ent_std": 7.994297027587891, "eval/prior_ent_mag": 71.0957260131836, "eval/prior_ent_max": 71.0957260131836, "eval/prior_ent_mean": 57.246543884277344, "eval/prior_ent_min": 43.80238723754883, "eval/prior_ent_std": 4.828220844268799, "eval/rep_loss_mean": 16.73942756652832, "eval/rep_loss_std": 10.976637840270996, "eval/reward_avg": 0.04501952975988388, "eval/reward_loss_mean": 0.10547657310962677, "eval/reward_loss_std": 0.4586845338344574, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011708736419678, "eval/reward_neg_acc": 0.9682050943374634, "eval/reward_neg_loss": 0.04901175945997238, "eval/reward_pos_acc": 0.8979591727256775, "eval/reward_pos_loss": 1.2290111780166626, "eval/reward_pred": 0.040691036731004715, "eval/reward_rate": 0.0478515625, "replay/size": 1000000.0, "replay/inserts": 22792.0, "replay/samples": 22800.0, "replay/insert_wait_avg": 1.3836897143400439e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.293829466167249e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4296.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2631855863432644e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.1861424446106, "timer/env.step_count": 2849.0, "timer/env.step_total": 229.4050896167755, "timer/env.step_frac": 0.22913330487838535, "timer/env.step_avg": 0.08052126697675518, "timer/env.step_min": 0.024039506912231445, "timer/env.step_max": 3.5164635181427, "timer/replay._sample_count": 22800.0, "timer/replay._sample_total": 11.904699325561523, "timer/replay._sample_frac": 0.011890595385682875, "timer/replay._sample_avg": 0.0005221359353316458, "timer/replay._sample_min": 0.0004115104675292969, "timer/replay._sample_max": 0.02926468849182129, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3386.0, "timer/agent.policy_total": 60.55068397521973, "timer/agent.policy_frac": 0.06047894732878768, "timer/agent.policy_avg": 0.01788265917756046, "timer/agent.policy_min": 0.009931564331054688, "timer/agent.policy_max": 0.14488720893859863, "timer/dataset_train_count": 1425.0, "timer/dataset_train_total": 0.15919256210327148, "timer/dataset_train_frac": 0.00015900396075655692, "timer/dataset_train_avg": 0.00011171407866896244, "timer/dataset_train_min": 9.703636169433594e-05, "timer/dataset_train_max": 0.0006406307220458984, "timer/agent.train_count": 1425.0, "timer/agent.train_total": 641.0836799144745, "timer/agent.train_frac": 0.6403241642449538, "timer/agent.train_avg": 0.44988328415050843, "timer/agent.train_min": 0.43488001823425293, "timer/agent.train_max": 1.8795740604400635, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48999881744384766, "timer/agent.report_frac": 0.0004894182976278622, "timer/agent.report_avg": 0.24499940872192383, "timer/agent.report_min": 0.22899270057678223, "timer/agent.report_max": 0.26100611686706543, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.00051505841321e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 22.764381821104454}
{"step": 1823000, "time": 82522.017080307, "episode/length": 248.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 1823072, "time": 82526.4393286705, "episode/length": 196.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 1823320, "time": 82536.16163229942, "episode/length": 74.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9466666666666667, "episode/intrinsic_return": 0.0}
{"step": 1823928, "time": 82558.36752223969, "episode/length": 318.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9968652037617555, "episode/intrinsic_return": 0.0}
{"step": 1824000, "time": 82562.56400227547, "episode/length": 436.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9977116704805492, "episode/intrinsic_return": 0.0}
{"step": 1824088, "time": 82566.93507647514, "episode/length": 157.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 1824184, "time": 82571.87676167488, "episode/length": 203.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 1824344, "time": 82579.00369310379, "episode/length": 158.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 1824624, "time": 82590.27044606209, "episode/length": 202.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 1825168, "time": 82610.44573879242, "episode/length": 154.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 1825376, "time": 82619.11492371559, "episode/length": 148.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 1825736, "time": 82632.65430021286, "episode/length": 216.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1825968, "time": 82642.39883327484, "episode/length": 330.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9848942598187311, "episode/intrinsic_return": 0.0}
{"step": 1826008, "time": 82645.18322777748, "episode/length": 239.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 1826088, "time": 82649.58659768105, "episode/length": 429.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.986046511627907, "episode/intrinsic_return": 0.0}
{"step": 1827088, "time": 82687.06123185158, "episode/length": 213.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 1827104, "time": 82689.19391822815, "episode/length": 241.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 1827328, "time": 82698.55123114586, "episode/length": 372.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9865951742627346, "episode/intrinsic_return": 0.0}
{"step": 1827344, "time": 82700.64742302895, "episode/length": 171.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 1827472, "time": 82706.55631279945, "episode/length": 216.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1827536, "time": 82710.34732103348, "episode/length": 190.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 1828616, "time": 82748.59321284294, "episode/length": 315.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9810126582278481, "episode/intrinsic_return": 0.0}
{"step": 1828960, "time": 82762.29990553856, "episode/length": 185.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 1829000, "time": 82765.09434485435, "episode/length": 236.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 1829016, "time": 82767.21153140068, "episode/length": 210.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 1829392, "time": 82781.78868484497, "episode/length": 595.0, "episode/score": 16.099999986588955, "episode/reward_rate": 0.9899328859060402, "episode/intrinsic_return": 0.0}
{"step": 1829456, "time": 82785.5010650158, "episode/length": 295.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 1829528, "time": 82789.4251973629, "episode/length": 248.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 1830024, "time": 82807.83509659767, "episode/length": 334.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.991044776119403, "episode/intrinsic_return": 0.0}
{"step": 1830088, "time": 82828.004737854, "eval_episode/length": 65.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9848484848484849}
{"step": 1830088, "time": 82830.89463567734, "eval_episode/length": 94.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9894736842105263}
{"step": 1830088, "time": 82836.01054525375, "eval_episode/length": 170.0, "eval_episode/score": 12.099999971687794, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 1830088, "time": 82840.01449847221, "eval_episode/length": 221.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 1830088, "time": 82842.21082806587, "eval_episode/length": 230.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 1830088, "time": 82844.46723151207, "eval_episode/length": 178.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 1830088, "time": 82846.74520468712, "eval_episode/length": 254.0, "eval_episode/score": 12.099999971687794, "eval_episode/reward_rate": 0.996078431372549}
{"step": 1830088, "time": 82848.78192639351, "eval_episode/length": 262.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.973384030418251}
{"step": 1830352, "time": 82857.95309472084, "episode/length": 168.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 1830648, "time": 82869.21740317345, "episode/length": 210.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 1830872, "time": 82878.55693554878, "episode/length": 231.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 1830904, "time": 82881.26636958122, "episode/length": 171.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 1831952, "time": 82918.68179941177, "episode/length": 319.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 1832304, "time": 82932.23325061798, "episode/length": 243.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 1832440, "time": 82938.25717496872, "episode/length": 223.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1832592, "time": 82945.31998300552, "episode/length": 210.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1832704, "time": 82950.68797039986, "episode/length": 228.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 1832928, "time": 82959.81707024574, "episode/length": 538.0, "episode/score": 15.100000008940697, "episode/reward_rate": 0.9981447124304267, "episode/intrinsic_return": 0.0}
{"step": 1833208, "time": 82970.64750599861, "episode/length": 468.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9957356076759062, "episode/intrinsic_return": 0.0}
{"step": 1833576, "time": 82984.78920602798, "episode/length": 443.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 1834616, "time": 83021.95866417885, "episode/length": 210.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 1834840, "time": 83031.3411333561, "episode/length": 266.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 1834848, "time": 83033.4813053608, "episode/length": 361.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.988950276243094, "episode/intrinsic_return": 0.0}
{"step": 1835008, "time": 83040.72147631645, "episode/length": 320.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9750778816199377, "episode/intrinsic_return": 0.0}
{"step": 1835064, "time": 83046.1183719635, "episode/length": 344.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9768115942028985, "episode/intrinsic_return": 0.0}
{"step": 1835328, "time": 83056.99426198006, "episode/length": 264.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.969811320754717, "episode/intrinsic_return": 0.0}
{"step": 1835544, "time": 83065.59402489662, "episode/length": 368.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.997289972899729, "episode/intrinsic_return": 0.0}
{"step": 1836744, "time": 83107.95838284492, "episode/length": 237.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 1837128, "time": 83122.79465961456, "episode/length": 47.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 1837280, "time": 83129.68463778496, "episode/length": 303.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 1837392, "time": 83135.15447044373, "episode/length": 230.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 1837432, "time": 83137.87537550926, "episode/length": 295.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9831081081081081, "episode/intrinsic_return": 0.0}
{"step": 1837688, "time": 83148.34543824196, "episode/length": 513.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9980544747081712, "episode/intrinsic_return": 0.0}
{"step": 1837792, "time": 83153.54771924019, "episode/length": 307.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9967532467532467, "episode/intrinsic_return": 0.0}
{"step": 1839176, "time": 83201.78410291672, "episode/length": 217.0, "episode/score": 12.100000038743019, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1839320, "time": 83208.35617351532, "episode/length": 254.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 1839336, "time": 83210.50809931755, "episode/length": 589.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9898305084745763, "episode/intrinsic_return": 0.0}
{"step": 1839344, "time": 83212.63931941986, "episode/length": 541.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.992619926199262, "episode/intrinsic_return": 0.0}
{"step": 1839416, "time": 83216.4420132637, "episode/length": 215.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 1839464, "time": 83219.61804437637, "episode/length": 258.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 1840072, "time": 83241.80230164528, "episode/length": 284.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9964912280701754, "episode/intrinsic_return": 0.0}
{"step": 1840072, "time": 83262.65095758438, "eval_episode/length": 166.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 1840072, "time": 83264.4121325016, "eval_episode/length": 170.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 1840072, "time": 83267.4039452076, "eval_episode/length": 195.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 1840072, "time": 83269.32673120499, "eval_episode/length": 203.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 1840072, "time": 83271.84392046928, "eval_episode/length": 224.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 1840072, "time": 83274.07263731956, "eval_episode/length": 237.0, "eval_episode/score": 15.099999986588955, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 1840072, "time": 83276.9270529747, "eval_episode/length": 264.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 1840072, "time": 83281.05950212479, "eval_episode/length": 320.0, "eval_episode/score": 14.100000008940697, "eval_episode/reward_rate": 0.9781931464174455}
{"step": 1840408, "time": 83294.00271463394, "episode/length": 409.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9780487804878049, "episode/intrinsic_return": 0.0}
{"step": 1840552, "time": 83300.53109240532, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 1840912, "time": 83314.52714514732, "episode/length": 196.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 1840960, "time": 83317.70493364334, "episode/length": 201.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 1841168, "time": 83326.43637633324, "episode/length": 212.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 1841632, "time": 83343.7707130909, "episode/length": 194.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 1842208, "time": 83364.81537938118, "episode/length": 224.0, "episode/score": 16.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1842536, "time": 83377.22413516045, "episode/length": 401.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9975124378109452, "episode/intrinsic_return": 0.0}
{"step": 1842696, "time": 83384.32899880409, "episode/length": 216.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1842944, "time": 83394.58299040794, "episode/length": 253.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9724409448818898, "episode/intrinsic_return": 0.0}
{"step": 1843104, "time": 83401.72481155396, "episode/length": 318.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9843260188087775, "episode/intrinsic_return": 0.0}
{"step": 1843360, "time": 83413.91240978241, "episode/length": 273.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 1843368, "time": 83415.67175197601, "episode/length": 216.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1843520, "time": 83422.82051968575, "episode/length": 512.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9961013645224172, "episode/intrinsic_return": 0.0}
{"step": 1844016, "time": 83441.19678354263, "episode/length": 113.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1844048, "time": 83443.8504626751, "episode/length": 168.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 1844056, "time": 83445.5177719593, "episode/length": 230.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 1844600, "time": 83465.50357484818, "episode/length": 154.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 1845072, "time": 83483.49353981018, "episode/length": 193.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 1845360, "time": 83494.76518464088, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 1845913, "time": 83516.1432762146, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.022900899251302, "train/action_min": 0.0, "train/action_std": 3.69621894425816, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.02504970111315035, "train/actor_opt_grad_steps": 114555.0, "train/actor_opt_loss": -7.2556685147962225, "train/adv_mag": 0.3993492219597101, "train/adv_max": 0.3617071046804388, "train/adv_mean": 0.0014991362681560834, "train/adv_min": -0.3219151721439428, "train/adv_std": 0.038758480067675315, "train/cont_avg": 0.9962632921006944, "train/cont_loss_mean": 0.00014887558983921344, "train/cont_loss_std": 0.0046717892409478485, "train/cont_neg_acc": 0.9941314559587291, "train/cont_neg_loss": 0.02988344475811669, "train/cont_pos_acc": 0.9999863567451636, "train/cont_pos_loss": 2.7568796075251435e-05, "train/cont_pred": 0.9962752978834841, "train/cont_rate": 0.9962632921006944, "train/dyn_loss_mean": 12.531632741292318, "train/dyn_loss_std": 9.250470962789324, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8959412396781974, "train/extr_critic_critic_opt_grad_steps": 114555.0, "train/extr_critic_critic_opt_loss": 14712.272148980035, "train/extr_critic_mag": 10.501834425661299, "train/extr_critic_max": 10.501834425661299, "train/extr_critic_mean": 2.1198413686619864, "train/extr_critic_min": -0.26300308108329773, "train/extr_critic_std": 2.4716324135661125, "train/extr_return_normed_mag": 1.486604315539201, "train/extr_return_normed_max": 1.486604315539201, "train/extr_return_normed_mean": 0.2899579345766041, "train/extr_return_normed_min": -0.053967910314289234, "train/extr_return_normed_std": 0.3218526384896702, "train/extr_return_rate": 0.6710001956671476, "train/extr_return_raw_mag": 11.399910807609558, "train/extr_return_raw_max": 11.399910807609558, "train/extr_return_raw_mean": 2.131461347142855, "train/extr_return_raw_min": -0.533037981018424, "train/extr_return_raw_std": 2.49330638266272, "train/extr_reward_mag": 1.060344590081109, "train/extr_reward_max": 1.060344590081109, "train/extr_reward_mean": 0.04110600787680596, "train/extr_reward_min": -0.4682407271530893, "train/extr_reward_std": 0.19021973696847758, "train/image_loss_mean": 5.955111662546794, "train/image_loss_std": 11.858979281451967, "train/model_loss_mean": 13.538782782024807, "train/model_loss_std": 15.612398240301344, "train/model_opt_grad_norm": 42.361836552619934, "train/model_opt_grad_steps": 114453.65972222222, "train/model_opt_loss": 17852.363966200086, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1319.4444444444443, "train/policy_entropy_mag": 2.8077591359615326, "train/policy_entropy_max": 2.8077591359615326, "train/policy_entropy_mean": 0.9597003199160099, "train/policy_entropy_min": 0.07937501655477616, "train/policy_entropy_std": 1.0109349807931318, "train/policy_logprob_mag": 7.438383877277374, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.9599337267378966, "train/policy_logprob_min": -7.438383877277374, "train/policy_logprob_std": 1.334473691880703, "train/policy_randomness_mag": 0.9910157587793138, "train/policy_randomness_max": 0.9910157587793138, "train/policy_randomness_mean": 0.338732101333638, "train/policy_randomness_min": 0.028015897622228496, "train/policy_randomness_std": 0.35681569079558056, "train/post_ent_mag": 61.52699110243056, "train/post_ent_max": 61.52699110243056, "train/post_ent_mean": 43.910796801249184, "train/post_ent_min": 20.076285587416756, "train/post_ent_std": 7.866043809387419, "train/prior_ent_mag": 71.22102525499132, "train/prior_ent_max": 71.22102525499132, "train/prior_ent_mean": 56.537473890516495, "train/prior_ent_min": 40.20788722568088, "train/prior_ent_std": 4.873179684082667, "train/rep_loss_mean": 12.531632741292318, "train/rep_loss_std": 9.250470962789324, "train/reward_avg": 0.04098646354395896, "train/reward_loss_mean": 0.06454271168654992, "train/reward_loss_std": 0.260170119193693, "train/reward_max_data": 1.028472229010529, "train/reward_max_pred": 1.025357613960902, "train/reward_neg_acc": 0.9905860564774938, "train/reward_neg_loss": 0.030780626422104735, "train/reward_pos_acc": 0.977294586184952, "train/reward_pos_loss": 0.7961885444819927, "train/reward_pred": 0.040453625170307025, "train/reward_rate": 0.04437255859375, "train_stats/sum_log_reward": 11.368292808532715, "train_stats/max_log_achievement_collect_coal": 0.9024390243902439, "train_stats/max_log_achievement_collect_drink": 5.926829268292683, "train_stats/max_log_achievement_collect_iron": 0.024390243902439025, "train_stats/max_log_achievement_collect_sapling": 1.7073170731707317, "train_stats/max_log_achievement_collect_stone": 13.731707317073171, "train_stats/max_log_achievement_collect_wood": 9.71951219512195, "train_stats/max_log_achievement_defeat_skeleton": 0.07317073170731707, "train_stats/max_log_achievement_defeat_zombie": 1.646341463414634, "train_stats/max_log_achievement_eat_cow": 0.5487804878048781, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.07317073170731707, "train_stats/max_log_achievement_make_stone_sword": 0.06097560975609756, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4268292682926829, "train_stats/max_log_achievement_make_wood_sword": 1.3902439024390243, "train_stats/max_log_achievement_place_furnace": 2.1219512195121952, "train_stats/max_log_achievement_place_plant": 1.6341463414634145, "train_stats/max_log_achievement_place_stone": 3.902439024390244, "train_stats/max_log_achievement_place_table": 2.926829268292683, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.8174452370986706, "eval_stats/sum_log_reward": 11.537500351667404, "eval_stats/max_log_achievement_collect_coal": 0.8125, "eval_stats/max_log_achievement_collect_drink": 8.125, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.9375, "eval_stats/max_log_achievement_collect_stone": 9.75, "eval_stats/max_log_achievement_collect_wood": 8.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 1.6875, "eval_stats/max_log_achievement_eat_cow": 0.5, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.125, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 1.3125, "eval_stats/max_log_achievement_place_furnace": 1.25, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_stone": 3.3125, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 6.001089332130505e-07, "report/cont_loss_std": 3.6897699828841724e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.6366143326158635e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.704242198589782e-07, "report/cont_pred": 0.9941401481628418, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.925529479980469, "report/dyn_loss_std": 9.09537124633789, "report/image_loss_mean": 6.746035575866699, "report/image_loss_std": 10.634016990661621, "report/model_loss_mean": 15.178555488586426, "report/model_loss_std": 14.268052101135254, "report/post_ent_mag": 63.300148010253906, "report/post_ent_max": 63.300148010253906, "report/post_ent_mean": 42.798851013183594, "report/post_ent_min": 20.888423919677734, "report/post_ent_std": 8.161837577819824, "report/prior_ent_mag": 71.32818603515625, "report/prior_ent_max": 71.32818603515625, "report/prior_ent_mean": 56.874473571777344, "report/prior_ent_min": 42.4901237487793, "report/prior_ent_std": 5.147650241851807, "report/rep_loss_mean": 13.925529479980469, "report/rep_loss_std": 9.09537124633789, "report/reward_avg": 0.05107422173023224, "report/reward_loss_mean": 0.07720142602920532, "report/reward_loss_std": 0.2738225758075714, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0029795169830322, "report/reward_neg_acc": 0.9948240518569946, "report/reward_neg_loss": 0.036137405782938004, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7611297965049744, "report/reward_pred": 0.048602234572172165, "report/reward_rate": 0.056640625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 8.629122748970985e-05, "eval/cont_loss_std": 0.002701387507840991, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.7449481674702838e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.662902109790593e-05, "eval/cont_pred": 0.9950346946716309, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 15.588191986083984, "eval/dyn_loss_std": 10.802694320678711, "eval/image_loss_mean": 7.665602207183838, "eval/image_loss_std": 11.474154472351074, "eval/model_loss_mean": 17.128982543945312, "eval/model_loss_std": 15.863107681274414, "eval/post_ent_mag": 61.607330322265625, "eval/post_ent_max": 61.607330322265625, "eval/post_ent_mean": 43.348480224609375, "eval/post_ent_min": 20.96146011352539, "eval/post_ent_std": 8.259675979614258, "eval/prior_ent_mag": 71.32818603515625, "eval/prior_ent_max": 71.32818603515625, "eval/prior_ent_mean": 57.09560775756836, "eval/prior_ent_min": 43.591636657714844, "eval/prior_ent_std": 4.8923020362854, "eval/rep_loss_mean": 15.588191986083984, "eval/rep_loss_std": 10.802694320678711, "eval/reward_avg": 0.05107421800494194, "eval/reward_loss_mean": 0.11037880182266235, "eval/reward_loss_std": 0.561457633972168, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0042023658752441, "eval/reward_neg_acc": 0.992776095867157, "eval/reward_neg_loss": 0.04742057994008064, "eval/reward_pos_acc": 0.9090908765792847, "eval/reward_pos_loss": 1.219588279724121, "eval/reward_pred": 0.04650333523750305, "eval/reward_rate": 0.0537109375, "replay/size": 1000000.0, "replay/inserts": 23088.0, "replay/samples": 23088.0, "replay/insert_wait_avg": 1.3675403859329489e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.270505890611634e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4672.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2764987880236481e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9731543064117, "timer/env.step_count": 2886.0, "timer/env.step_total": 216.6101689338684, "timer/env.step_frac": 0.21661598414020494, "timer/env.step_avg": 0.075055498591084, "timer/env.step_min": 0.024013757705688477, "timer/env.step_max": 3.767671823501587, "timer/replay._sample_count": 23088.0, "timer/replay._sample_total": 12.107033491134644, "timer/replay._sample_frac": 0.012107358521571677, "timer/replay._sample_avg": 0.0005243864124711817, "timer/replay._sample_min": 0.0004298686981201172, "timer/replay._sample_max": 0.028055429458618164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3470.0, "timer/agent.policy_total": 59.949629068374634, "timer/agent.policy_frac": 0.059951238500953664, "timer/agent.policy_avg": 0.017276550163796724, "timer/agent.policy_min": 0.009793281555175781, "timer/agent.policy_max": 0.11307358741760254, "timer/dataset_train_count": 1443.0, "timer/dataset_train_total": 0.16105151176452637, "timer/dataset_train_frac": 0.00016105583542013466, "timer/dataset_train_avg": 0.00011160880926162603, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.00034880638122558594, "timer/agent.train_count": 1443.0, "timer/agent.train_total": 650.8740272521973, "timer/agent.train_frac": 0.6508915008859892, "timer/agent.train_avg": 0.45105615194192467, "timer/agent.train_min": 0.43818187713623047, "timer/agent.train_max": 1.7684614658355713, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47536325454711914, "timer/agent.report_frac": 0.00047537601634599315, "timer/agent.report_avg": 0.23768162727355957, "timer/agent.report_min": 0.2297983169555664, "timer/agent.report_max": 0.24556493759155273, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5987625122070312e-05, "timer/dataset_eval_frac": 2.5988322796620985e-08, "timer/dataset_eval_avg": 2.5987625122070312e-05, "timer/dataset_eval_min": 2.5987625122070312e-05, "timer/dataset_eval_max": 2.5987625122070312e-05, "fps": 23.088212397259557}
{"step": 1845960, "time": 83517.57984423637, "episode/length": 427.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 1846040, "time": 83521.91527938843, "episode/length": 179.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1846544, "time": 83540.98140597343, "episode/length": 311.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9967948717948718, "episode/intrinsic_return": 0.0}
{"step": 1846696, "time": 83547.62464785576, "episode/length": 468.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9786780383795309, "episode/intrinsic_return": 0.0}
{"step": 1846704, "time": 83549.75875043869, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 1848112, "time": 83599.45670390129, "episode/length": 268.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 1848280, "time": 83606.5831515789, "episode/length": 216.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1848616, "time": 83619.5942838192, "episode/length": 569.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9982456140350877, "episode/intrinsic_return": 0.0}
{"step": 1848680, "time": 83623.39800477028, "episode/length": 246.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 1849224, "time": 83643.70428419113, "episode/length": 518.0, "episode/score": 13.100000016391277, "episode/reward_rate": 0.9980732177263969, "episode/intrinsic_return": 0.0}
{"step": 1849464, "time": 83653.4368326664, "episode/length": 427.0, "episode/score": 15.100000001490116, "episode/reward_rate": 0.9883177570093458, "episode/intrinsic_return": 0.0}
{"step": 1849832, "time": 83667.73158311844, "episode/length": 391.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9974489795918368, "episode/intrinsic_return": 0.0}
{"step": 1849928, "time": 83672.64598202705, "episode/length": 226.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 1849952, "time": 83675.3159520626, "episode/length": 822.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9987849331713244, "episode/intrinsic_return": 0.0}
{"step": 1850056, "time": 83703.0647161007, "eval_episode/length": 210.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.995260663507109}
{"step": 1850056, "time": 83708.02218461037, "eval_episode/length": 283.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9823943661971831}
{"step": 1850056, "time": 83710.12470722198, "eval_episode/length": 296.0, "eval_episode/score": 10.100000016391277, "eval_episode/reward_rate": 0.9831649831649831}
{"step": 1850056, "time": 83712.8260486126, "eval_episode/length": 320.0, "eval_episode/score": 13.100000008940697, "eval_episode/reward_rate": 0.9968847352024922}
{"step": 1850056, "time": 83714.52212500572, "eval_episode/length": 321.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.984472049689441}
{"step": 1850056, "time": 83717.65439748764, "eval_episode/length": 349.0, "eval_episode/score": 14.100000008940697, "eval_episode/reward_rate": 0.9685714285714285}
{"step": 1850056, "time": 83725.79440879822, "eval_episode/length": 165.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9578313253012049}
{"step": 1850056, "time": 83728.37663221359, "eval_episode/length": 120.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9586776859504132}
{"step": 1850264, "time": 83735.42458987236, "episode/length": 197.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 1850544, "time": 83746.77829790115, "episode/length": 282.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9717314487632509, "episode/intrinsic_return": 0.0}
{"step": 1851120, "time": 83767.7810947895, "episode/length": 312.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.987220447284345, "episode/intrinsic_return": 0.0}
{"step": 1851152, "time": 83770.49270439148, "episode/length": 210.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1851624, "time": 83790.05280709267, "episode/length": 211.0, "episode/score": 13.099999994039536, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 1851720, "time": 83794.92636704445, "episode/length": 74.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1851896, "time": 83802.5566072464, "episode/length": 203.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1852184, "time": 83814.04895401001, "episode/length": 369.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9837837837837838, "episode/intrinsic_return": 0.0}
{"step": 1852400, "time": 83823.20305347443, "episode/length": 305.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 1852984, "time": 83844.36161875725, "episode/length": 393.0, "episode/score": 14.100000008940697, "episode/reward_rate": 0.9974619289340102, "episode/intrinsic_return": 0.0}
{"step": 1853144, "time": 83851.37263965607, "episode/length": 324.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9907692307692307, "episode/intrinsic_return": 0.0}
{"step": 1853232, "time": 83856.11698818207, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 1853456, "time": 83865.3136472702, "episode/length": 194.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 1853752, "time": 83876.81544303894, "episode/length": 195.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 1853968, "time": 83885.79402422905, "episode/length": 292.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9761092150170648, "episode/intrinsic_return": 0.0}
{"step": 1854056, "time": 83890.06245112419, "episode/length": 37.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.8947368421052632, "episode/intrinsic_return": 0.0}
{"step": 1854616, "time": 83910.75935935974, "episode/length": 432.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9953810623556582, "episode/intrinsic_return": 0.0}
{"step": 1855024, "time": 83926.68920063972, "episode/length": 195.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 1855056, "time": 83929.33940839767, "episode/length": 54.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1855080, "time": 83931.58030319214, "episode/length": 334.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 1855216, "time": 83937.96485447884, "episode/length": 278.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 1855280, "time": 83941.60411310196, "episode/length": 266.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 1855312, "time": 83944.34302282333, "episode/length": 156.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9808917197452229, "episode/intrinsic_return": 0.0}
{"step": 1855776, "time": 83961.65550971031, "episode/length": 225.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 1856208, "time": 83978.30177807808, "episode/length": 147.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 1856432, "time": 83987.56923532486, "episode/length": 168.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 1856704, "time": 83998.41766166687, "episode/length": 205.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 1856832, "time": 84004.38765001297, "episode/length": 201.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1857448, "time": 84026.76550292969, "episode/length": 526.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9943074003795066, "episode/intrinsic_return": 0.0}
{"step": 1858200, "time": 84053.86656022072, "episode/length": 364.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9945205479452055, "episode/intrinsic_return": 0.0}
{"step": 1858264, "time": 84057.64014649391, "episode/length": 228.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 1858560, "time": 84069.70000243187, "episode/length": 215.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 1859040, "time": 84087.98644757271, "episode/length": 291.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 1859368, "time": 84100.5243332386, "episode/length": 506.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9901380670611439, "episode/intrinsic_return": 0.0}
{"step": 1859648, "time": 84113.95798778534, "episode/length": 483.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 1859992, "time": 84127.14435529709, "episode/length": 223.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1860040, "time": 84153.70246195793, "eval_episode/length": 201.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9801980198019802}
{"step": 1860040, "time": 84155.69244289398, "eval_episode/length": 210.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.976303317535545}
{"step": 1860040, "time": 84158.53746175766, "eval_episode/length": 235.0, "eval_episode/score": 13.099999971687794, "eval_episode/reward_rate": 0.9957627118644068}
{"step": 1860040, "time": 84160.5772049427, "eval_episode/length": 245.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9959349593495935}
{"step": 1860040, "time": 84164.03604269028, "eval_episode/length": 285.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.986013986013986}
{"step": 1860040, "time": 84168.10165548325, "eval_episode/length": 335.0, "eval_episode/score": 12.099999979138374, "eval_episode/reward_rate": 0.9970238095238095}
{"step": 1860040, "time": 84170.62395191193, "eval_episode/length": 354.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9971830985915493}
{"step": 1860040, "time": 84174.26127076149, "eval_episode/length": 187.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 1860080, "time": 84175.8619980812, "episode/length": 189.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 1860208, "time": 84181.80324625969, "episode/length": 242.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 1860744, "time": 84201.63308858871, "episode/length": 411.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 1861056, "time": 84214.19638442993, "episode/length": 605.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9851485148514851, "episode/intrinsic_return": 0.0}
{"step": 1861272, "time": 84223.00119018555, "episode/length": 237.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 1861360, "time": 84227.9870839119, "episode/length": 289.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 1861848, "time": 84246.2551074028, "episode/length": 204.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9853658536585366, "episode/intrinsic_return": 0.0}
{"step": 1862064, "time": 84255.53008890152, "episode/length": 301.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9801324503311258, "episode/intrinsic_return": 0.0}
{"step": 1862352, "time": 84267.12782073021, "episode/length": 283.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 1862800, "time": 84284.00453162193, "episode/length": 217.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1863400, "time": 84305.89307522774, "episode/length": 193.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 1863456, "time": 84309.67021107674, "episode/length": 261.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 1864120, "time": 84334.10280323029, "episode/length": 256.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 1864128, "time": 84336.26147985458, "episode/length": 165.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 1864624, "time": 84354.5905406475, "episode/length": 418.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9952267303102625, "episode/intrinsic_return": 0.0}
{"step": 1864840, "time": 84363.13006162643, "episode/length": 310.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9967845659163987, "episode/intrinsic_return": 0.0}
{"step": 1864864, "time": 84365.79642415047, "episode/length": 608.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9819376026272578, "episode/intrinsic_return": 0.0}
{"step": 1865032, "time": 84372.77818727493, "episode/length": 535.0, "episode/score": 13.100000031292439, "episode/reward_rate": 0.9981343283582089, "episode/intrinsic_return": 0.0}
{"step": 1865080, "time": 84376.11004686356, "episode/length": 202.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 1865976, "time": 84407.94614505768, "episode/length": 168.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 1866016, "time": 84411.0793197155, "episode/length": 326.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9969418960244648, "episode/intrinsic_return": 0.0}
{"step": 1866368, "time": 84424.57918787003, "episode/length": 166.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 1866368, "time": 84424.5884642601, "episode/length": 280.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 1866712, "time": 84439.46178102493, "episode/length": 233.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 1867136, "time": 84455.523594141, "episode/length": 375.0, "episode/score": 12.1000000461936, "episode/reward_rate": 0.9973404255319149, "episode/intrinsic_return": 0.0}
{"step": 1867528, "time": 84470.25685811043, "episode/length": 305.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9967320261437909, "episode/intrinsic_return": 0.0}
{"step": 1867528, "time": 84470.26585125923, "episode/length": 193.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 1867840, "time": 84486.39744734764, "episode/length": 227.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1867936, "time": 84491.30600976944, "episode/length": 195.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 1868104, "time": 84498.40635347366, "episode/length": 216.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1868136, "time": 84501.18314433098, "episode/length": 408.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9975550122249389, "episode/intrinsic_return": 0.0}
{"step": 1868505, "time": 84516.17391586304, "train_stats/sum_log_reward": 11.334568076663547, "train_stats/max_log_achievement_collect_coal": 0.9876543209876543, "train_stats/max_log_achievement_collect_drink": 6.432098765432099, "train_stats/max_log_achievement_collect_iron": 0.012345679012345678, "train_stats/max_log_achievement_collect_sapling": 1.8518518518518519, "train_stats/max_log_achievement_collect_stone": 14.222222222222221, "train_stats/max_log_achievement_collect_wood": 10.481481481481481, "train_stats/max_log_achievement_defeat_skeleton": 0.04938271604938271, "train_stats/max_log_achievement_defeat_zombie": 1.876543209876543, "train_stats/max_log_achievement_eat_cow": 0.6790123456790124, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.06172839506172839, "train_stats/max_log_achievement_make_stone_sword": 0.06172839506172839, "train_stats/max_log_achievement_make_wood_pickaxe": 1.271604938271605, "train_stats/max_log_achievement_make_wood_sword": 1.4074074074074074, "train_stats/max_log_achievement_place_furnace": 2.271604938271605, "train_stats/max_log_achievement_place_plant": 1.7530864197530864, "train_stats/max_log_achievement_place_stone": 4.271604938271605, "train_stats/max_log_achievement_place_table": 3.271604938271605, "train_stats/max_log_achievement_wake_up": 2.2222222222222223, "train_stats/mean_log_entropy": 0.8451616320713067, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.999052440021055, "train/action_min": 0.0, "train/action_std": 3.709032839917122, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.024804318072736687, "train/actor_opt_grad_steps": 115980.0, "train/actor_opt_loss": -8.946358999673356, "train/adv_mag": 0.3619349239565802, "train/adv_max": 0.33022914689483374, "train/adv_mean": 0.0014351996577851365, "train/adv_min": -0.2940410299504057, "train/adv_std": 0.03838417830989293, "train/cont_avg": 0.9961699357269503, "train/cont_loss_mean": 0.0002097986847550775, "train/cont_loss_std": 0.0064060976448111415, "train/cont_neg_acc": 0.9878571433680398, "train/cont_neg_loss": 0.04617323248539021, "train/cont_pos_acc": 0.9999860842177208, "train/cont_pos_loss": 4.3323116956114374e-05, "train/cont_pred": 0.9961862496450438, "train/cont_rate": 0.9961699357269503, "train/dyn_loss_mean": 12.522402858057767, "train/dyn_loss_std": 9.25554319476405, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8506495343877915, "train/extr_critic_critic_opt_grad_steps": 115980.0, "train/extr_critic_critic_opt_loss": 14543.104762300532, "train/extr_critic_mag": 10.458282105466152, "train/extr_critic_max": 10.458282105466152, "train/extr_critic_mean": 2.1479624027901507, "train/extr_critic_min": -0.2742025869112488, "train/extr_critic_std": 2.4866348572656616, "train/extr_return_normed_mag": 1.4917320139864658, "train/extr_return_normed_max": 1.4917320139864658, "train/extr_return_normed_mean": 0.29457320494854705, "train/extr_return_normed_min": -0.052601034845496324, "train/extr_return_normed_std": 0.32426990388978455, "train/extr_return_rate": 0.6677429982533691, "train/extr_return_raw_mag": 11.415105210973861, "train/extr_return_raw_max": 11.415105210973861, "train/extr_return_raw_mean": 2.159059078558117, "train/extr_return_raw_min": -0.5248984175053895, "train/extr_return_raw_std": 2.50706931800707, "train/extr_reward_mag": 1.0526633803726089, "train/extr_reward_max": 1.0526633803726089, "train/extr_reward_mean": 0.042008649703141644, "train/extr_reward_min": -0.4396999305021678, "train/extr_reward_std": 0.19276333045452199, "train/image_loss_mean": 5.9680989414242145, "train/image_loss_std": 11.906939134530141, "train/model_loss_mean": 13.54604963884286, "train/model_loss_std": 15.646027970821299, "train/model_opt_grad_norm": 44.789677545533955, "train/model_opt_grad_steps": 115877.36170212766, "train/model_opt_loss": 16932.562056737588, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.8125282737380224, "train/policy_entropy_max": 2.8125282737380224, "train/policy_entropy_mean": 0.9468546763379523, "train/policy_entropy_min": 0.07937501666816414, "train/policy_entropy_std": 1.000267301890867, "train/policy_logprob_mag": 7.438383873472822, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.9453850151799249, "train/policy_logprob_min": -7.438383873472822, "train/policy_logprob_std": 1.3232208710190252, "train/policy_randomness_mag": 0.9926990570751488, "train/policy_randomness_max": 0.9926990570751488, "train/policy_randomness_mean": 0.33419815403349856, "train/policy_randomness_min": 0.02801589770837033, "train/policy_randomness_std": 0.3530504627430693, "train/post_ent_mag": 61.50719097489161, "train/post_ent_max": 61.50719097489161, "train/post_ent_mean": 43.79593734200119, "train/post_ent_min": 20.208896109398374, "train/post_ent_std": 7.853657938909869, "train/prior_ent_mag": 71.21568071081283, "train/prior_ent_max": 71.21568071081283, "train/prior_ent_mean": 56.42995828939668, "train/prior_ent_min": 39.76956275507068, "train/prior_ent_std": 4.936550441363179, "train/rep_loss_mean": 12.522402858057767, "train/rep_loss_std": 9.25554319476405, "train/reward_avg": 0.0428288450715601, "train/reward_loss_mean": 0.06429923286146307, "train/reward_loss_std": 0.25256950339526996, "train/reward_max_data": 1.0276595810626417, "train/reward_max_pred": 1.021932508928556, "train/reward_neg_acc": 0.9910163832894454, "train/reward_neg_loss": 0.02992678242108078, "train/reward_pos_acc": 0.9820103556551831, "train/reward_pos_loss": 0.7766971951680826, "train/reward_pred": 0.04214730519299389, "train/reward_rate": 0.04605080895390071, "eval_stats/sum_log_reward": 11.475000262260437, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 5.125, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.4375, "eval_stats/max_log_achievement_collect_stone": 13.0625, "eval_stats/max_log_achievement_collect_wood": 9.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.1875, "eval_stats/max_log_achievement_defeat_zombie": 1.75, "eval_stats/max_log_achievement_eat_cow": 0.8125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0, "eval_stats/max_log_achievement_make_wood_sword": 1.25, "eval_stats/max_log_achievement_place_furnace": 2.3125, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 3.125, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 3.0033183975319844e-06, "report/cont_loss_std": 1.0749500688689295e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.0316052541602403e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.952448539872421e-06, "report/cont_pred": 0.9970674514770508, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 13.04083251953125, "report/dyn_loss_std": 9.141979217529297, "report/image_loss_mean": 6.872016906738281, "report/image_loss_std": 11.93780517578125, "report/model_loss_mean": 14.75312614440918, "report/model_loss_std": 15.822591781616211, "report/post_ent_mag": 63.164730072021484, "report/post_ent_max": 63.164730072021484, "report/post_ent_mean": 43.24749755859375, "report/post_ent_min": 19.21516227722168, "report/post_ent_std": 7.539486885070801, "report/prior_ent_mag": 71.16500854492188, "report/prior_ent_max": 71.16500854492188, "report/prior_ent_mean": 56.423404693603516, "report/prior_ent_min": 42.90684509277344, "report/prior_ent_std": 5.224492073059082, "report/rep_loss_mean": 13.04083251953125, "report/rep_loss_std": 9.141979217529297, "report/reward_avg": 0.03984374925494194, "report/reward_loss_mean": 0.056608304381370544, "report/reward_loss_std": 0.23450666666030884, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0953986644744873, "report/reward_neg_acc": 0.9918534159660339, "report/reward_neg_loss": 0.02596222795546055, "report/reward_pos_acc": 0.9761905074119568, "report/reward_pos_loss": 0.7731427550315857, "report/reward_pred": 0.038665127009153366, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 3.896298221661709e-05, "eval/cont_loss_std": 0.0011049031745642424, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00019565447291824967, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.880981603288092e-05, "eval/cont_pred": 0.9989854693412781, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 15.99479866027832, "eval/dyn_loss_std": 11.203583717346191, "eval/image_loss_mean": 8.105203628540039, "eval/image_loss_std": 14.335081100463867, "eval/model_loss_mean": 17.81206703186035, "eval/model_loss_std": 18.733247756958008, "eval/post_ent_mag": 61.225189208984375, "eval/post_ent_max": 61.225189208984375, "eval/post_ent_mean": 42.54231643676758, "eval/post_ent_min": 19.68286895751953, "eval/post_ent_std": 8.266365051269531, "eval/prior_ent_mag": 71.16500854492188, "eval/prior_ent_max": 71.16500854492188, "eval/prior_ent_mean": 56.478302001953125, "eval/prior_ent_min": 41.231544494628906, "eval/prior_ent_std": 4.636706829071045, "eval/rep_loss_mean": 15.99479866027832, "eval/rep_loss_std": 11.203583717346191, "eval/reward_avg": 0.03583984449505806, "eval/reward_loss_mean": 0.1099456399679184, "eval/reward_loss_std": 0.537828803062439, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.116727352142334, "eval/reward_neg_acc": 0.9796748757362366, "eval/reward_neg_loss": 0.043415963649749756, "eval/reward_pos_acc": 0.75, "eval/reward_pos_loss": 1.746575951576233, "eval/reward_pred": 0.029102403670549393, "eval/reward_rate": 0.0390625, "replay/size": 1000000.0, "replay/inserts": 22592.0, "replay/samples": 22592.0, "replay/insert_wait_avg": 1.3730491355863576e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.311829722299117e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6960.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2807462407254624e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0215272903442, "timer/env.step_count": 2824.0, "timer/env.step_total": 212.68299007415771, "timer/env.step_frac": 0.21267841168423943, "timer/env.step_avg": 0.0753126735390077, "timer/env.step_min": 0.02414846420288086, "timer/env.step_max": 3.4080145359039307, "timer/replay._sample_count": 22592.0, "timer/replay._sample_total": 11.883508920669556, "timer/replay._sample_frac": 0.0118832531064297, "timer/replay._sample_avg": 0.000526005175312923, "timer/replay._sample_min": 0.00040221214294433594, "timer/replay._sample_max": 0.011400461196899414, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3694.0, "timer/agent.policy_total": 66.56389927864075, "timer/agent.policy_frac": 0.0665624663691012, "timer/agent.policy_avg": 0.018019463800390025, "timer/agent.policy_min": 0.009882450103759766, "timer/agent.policy_max": 0.21365857124328613, "timer/dataset_train_count": 1412.0, "timer/dataset_train_total": 0.1604747772216797, "timer/dataset_train_frac": 0.00016047132270892382, "timer/dataset_train_avg": 0.00011365069208334255, "timer/dataset_train_min": 9.72747802734375e-05, "timer/dataset_train_max": 0.0006389617919921875, "timer/agent.train_count": 1412.0, "timer/agent.train_total": 639.6451587677002, "timer/agent.train_frac": 0.6396313892370707, "timer/agent.train_avg": 0.45300648637939106, "timer/agent.train_min": 0.43865036964416504, "timer/agent.train_max": 1.96602463722229, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4743306636810303, "timer/agent.report_frac": 0.0004743204528469256, "timer/agent.report_avg": 0.23716533184051514, "timer/agent.report_min": 0.2311568260192871, "timer/agent.report_max": 0.24317383766174316, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.2424228752025966e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 22.591155844668847}
{"step": 1868536, "time": 84516.95024633408, "episode/length": 125.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 1868856, "time": 84529.71435689926, "episode/length": 267.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 1868952, "time": 84534.51026320457, "episode/length": 226.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 1869160, "time": 84543.10959076881, "episode/length": 164.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 1869240, "time": 84547.42777395248, "episode/length": 162.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 1869832, "time": 84569.03384685516, "episode/length": 287.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 1869872, "time": 84572.44884300232, "episode/length": 166.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 1870024, "time": 84595.06491589546, "eval_episode/length": 66.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9850746268656716}
{"step": 1870024, "time": 84603.62145996094, "eval_episode/length": 218.0, "eval_episode/score": 13.099999994039536, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 1870024, "time": 84606.08772230148, "eval_episode/length": 236.0, "eval_episode/score": 13.099999971687794, "eval_episode/reward_rate": 0.9957805907172996}
{"step": 1870024, "time": 84607.73618936539, "eval_episode/length": 238.0, "eval_episode/score": 11.099999979138374, "eval_episode/reward_rate": 0.99581589958159}
{"step": 1870024, "time": 84610.00630760193, "eval_episode/length": 187.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 1870024, "time": 84611.96761488914, "eval_episode/length": 262.0, "eval_episode/score": 13.100000016391277, "eval_episode/reward_rate": 0.9961977186311787}
{"step": 1870024, "time": 84614.28485679626, "eval_episode/length": 278.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9713261648745519}
{"step": 1870024, "time": 84622.57581186295, "eval_episode/length": 207.0, "eval_episode/score": 14.100000008940697, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 1870248, "time": 84630.2269539833, "episode/length": 263.0, "episode/score": 13.100000038743019, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 1870392, "time": 84636.57128071785, "episode/length": 191.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 1870592, "time": 84645.11083698273, "episode/length": 310.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9967845659163987, "episode/intrinsic_return": 0.0}
{"step": 1870976, "time": 84659.74347996712, "episode/length": 216.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1870992, "time": 84661.8823158741, "episode/length": 74.0, "episode/score": 9.1000000461936, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 1871168, "time": 84669.45505189896, "episode/length": 250.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 1871528, "time": 84683.20609688759, "episode/length": 206.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 1871928, "time": 84698.38734269142, "episode/length": 209.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 1872040, "time": 84703.72886252403, "episode/length": 180.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 1872224, "time": 84711.82827496529, "episode/length": 298.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.0}
{"step": 1872256, "time": 84714.58147525787, "episode/length": 412.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9975786924939467, "episode/intrinsic_return": 0.0}
{"step": 1872592, "time": 84727.648280859, "episode/length": 41.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1872704, "time": 84733.055175066, "episode/length": 215.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 1872880, "time": 84740.85881233215, "episode/length": 213.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 1873080, "time": 84749.64194917679, "episode/length": 260.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9731800766283525, "episode/intrinsic_return": 0.0}
{"step": 1873152, "time": 84753.85299682617, "episode/length": 152.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 1873640, "time": 84771.77052664757, "episode/length": 199.0, "episode/score": 13.099999971687794, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 1873864, "time": 84780.84881067276, "episode/length": 158.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 1873960, "time": 84785.9559328556, "episode/length": 303.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 1874208, "time": 84796.16082525253, "episode/length": 247.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 1874440, "time": 84805.50621676445, "episode/length": 216.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 1874440, "time": 84805.51476931572, "episode/length": 194.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 1874488, "time": 84810.94794750214, "episode/length": 166.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 1875256, "time": 84838.70878624916, "episode/length": 173.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 1875576, "time": 84851.23546671867, "episode/length": 201.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 1876040, "time": 84870.4442088604, "episode/length": 299.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.0}
{"step": 1876264, "time": 84879.62055182457, "episode/length": 227.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 1876376, "time": 84885.03552937508, "episode/length": 139.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 1876376, "time": 84885.04428195953, "episode/length": 241.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 1876488, "time": 84892.38662314415, "episode/length": 425.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 1876656, "time": 84899.97886681557, "episode/length": 270.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.974169741697417, "episode/intrinsic_return": 0.0}
{"step": 1877624, "time": 84934.23927235603, "episode/length": 197.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 1877936, "time": 84946.80494737625, "episode/length": 194.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 1877976, "time": 84949.5866560936, "episode/length": 213.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 1878712, "time": 84976.19751667976, "episode/length": 562.0, "episode/score": 13.099999994039536, "episode/reward_rate": 0.9982238010657194, "episode/intrinsic_return": 0.0}
{"step": 1878872, "time": 84983.2645790577, "episode/length": 276.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 1879256, "time": 84997.8699028492, "episode/length": 459.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9934782608695653, "episode/intrinsic_return": 0.0}
{"step": 1879328, "time": 85002.13501954079, "episode/length": 168.0, "episode/score": 13.100000031292439, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 1879520, "time": 85010.31269407272, "episode/length": 236.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 1879752, "time": 85019.55091047287, "episode/length": 407.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 1879960, "time": 85028.07022213936, "episode/length": 252.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 1880008, "time": 85055.96654391289, "eval_episode/length": 186.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9679144385026738}
{"step": 1880008, "time": 85057.88856339455, "eval_episode/length": 193.0, "eval_episode/score": 12.099999971687794, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 1880008, "time": 85059.5673699379, "eval_episode/length": 195.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 1880008, "time": 85061.37009501457, "eval_episode/length": 199.0, "eval_episode/score": 13.100000008940697, "eval_episode/reward_rate": 0.995}
{"step": 1880008, "time": 85063.53715729713, "eval_episode/length": 212.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 1880008, "time": 85071.82189035416, "eval_episode/length": 167.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 1880008, "time": 85074.46895742416, "eval_episode/length": 378.0, "eval_episode/score": 10.100000016391277, "eval_episode/reward_rate": 0.9841688654353562}
{"step": 1880008, "time": 85076.99737524986, "eval_episode/length": 203.0, "eval_episode/score": 12.099999971687794, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 1880256, "time": 85085.5927324295, "episode/length": 192.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 1880328, "time": 85089.50748872757, "episode/length": 181.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 1880336, "time": 85091.56634092331, "episode/length": 494.0, "episode/score": 15.099999986588955, "episode/reward_rate": 0.9878787878787879, "episode/intrinsic_return": 0.0}
{"step": 1880976, "time": 85114.88102507591, "episode/length": 181.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 1881104, "time": 85120.63977837563, "episode/length": 221.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 1881120, "time": 85122.76248693466, "episode/length": 232.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 1881280, "time": 85129.79247355461, "episode/length": 190.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 1881552, "time": 85140.56066274643, "episode/length": 152.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 1881616, "time": 85144.37721014023, "episode/length": 169.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1881912, "time": 85155.70730376244, "episode/length": 243.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 1882304, "time": 85170.85262799263, "episode/length": 245.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.967479674796748, "episode/intrinsic_return": 0.0}
{"step": 1882672, "time": 85184.79315805435, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 1882824, "time": 85191.36889743805, "episode/length": 192.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 1882912, "time": 85196.11328649521, "episode/length": 169.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 1883016, "time": 85200.89030575752, "episode/length": 236.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 1883328, "time": 85213.31878614426, "episode/length": 213.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 1883640, "time": 85225.47165632248, "episode/length": 215.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 1884216, "time": 85248.8651561737, "episode/length": 71.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 1884288, "time": 85253.26790809631, "episode/length": 158.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 1884424, "time": 85259.26765179634, "episode/length": 188.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 1884576, "time": 85266.43898367882, "episode/length": 433.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9976958525345622, "episode/intrinsic_return": 0.0}
{"step": 1884832, "time": 85276.97734451294, "episode/length": 269.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 1884928, "time": 85281.87834477425, "episode/length": 199.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 1885416, "time": 85299.87676262856, "episode/length": 388.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9897172236503856, "episode/intrinsic_return": 0.0}
{"step": 1886184, "time": 85327.94756603241, "episode/length": 219.0, "episode/score": 13.099999994039536, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 1886344, "time": 85335.1043381691, "episode/length": 176.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 1886576, "time": 85345.21543478966, "episode/length": 468.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9829424307036247, "episode/intrinsic_return": 0.0}
{"step": 1886632, "time": 85348.51377534866, "episode/length": 292.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 1886864, "time": 85358.32146430016, "episode/length": 253.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 1887616, "time": 85385.85122895241, "episode/length": 158.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 1888096, "time": 85404.19020533562, "episode/length": 238.0, "episode/score": 13.100000068545341, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 1888160, "time": 85408.00657129288, "episode/length": 197.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 1888176, "time": 85410.3600332737, "episode/length": 163.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 1888824, "time": 85433.9492456913, "episode/length": 530.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9868173258003766, "episode/intrinsic_return": 0.0}
{"step": 1889112, "time": 85445.51523256302, "episode/length": 309.0, "episode/score": 13.099999964237213, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 1889224, "time": 85450.81866574287, "episode/length": 475.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726890756302521, "episode/intrinsic_return": 0.0}
{"step": 1889592, "time": 85465.23475599289, "episode/length": 178.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 1889920, "time": 85478.41779065132, "episode/length": 217.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 1890096, "time": 85502.79982471466, "eval_episode/length": 67.0, "eval_episode/score": 3.100000023841858, "eval_episode/reward_rate": 0.9852941176470589}
{"step": 1890096, "time": 85509.27082777023, "eval_episode/length": 171.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9651162790697675}
{"step": 1890096, "time": 85512.76347517967, "eval_episode/length": 207.0, "eval_episode/score": 13.100000008940697, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 1890096, "time": 85514.77959895134, "eval_episode/length": 215.0, "eval_episode/score": 12.099999971687794, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 1890096, "time": 85517.13379645348, "eval_episode/length": 226.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.973568281938326}
{"step": 1890096, "time": 85521.24783611298, "eval_episode/length": 277.0, "eval_episode/score": 13.100000008940697, "eval_episode/reward_rate": 0.9964028776978417}
{"step": 1890096, "time": 85524.14607620239, "eval_episode/length": 301.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9735099337748344}
{"step": 1890096, "time": 85530.46906805038, "eval_episode/length": 98.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.98989898989899}
{"step": 1890096, "time": 85530.47712111473, "eval_episode/length": 228.0, "eval_episode/score": 12.099999994039536, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 1890097, "time": 85531.09031033516, "train_stats/sum_log_reward": 11.506977059120356, "train_stats/max_log_achievement_collect_coal": 1.058139534883721, "train_stats/max_log_achievement_collect_drink": 5.767441860465116, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.6162790697674418, "train_stats/max_log_achievement_collect_stone": 12.546511627906977, "train_stats/max_log_achievement_collect_wood": 9.674418604651162, "train_stats/max_log_achievement_defeat_skeleton": 0.10465116279069768, "train_stats/max_log_achievement_defeat_zombie": 1.4069767441860466, "train_stats/max_log_achievement_eat_cow": 0.6744186046511628, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.03488372093023256, "train_stats/max_log_achievement_make_stone_sword": 0.06976744186046512, "train_stats/max_log_achievement_make_wood_pickaxe": 1.255813953488372, "train_stats/max_log_achievement_make_wood_sword": 1.3953488372093024, "train_stats/max_log_achievement_place_furnace": 1.9534883720930232, "train_stats/max_log_achievement_place_plant": 1.4883720930232558, "train_stats/max_log_achievement_place_stone": 3.3255813953488373, "train_stats/max_log_achievement_place_table": 3.011627906976744, "train_stats/max_log_achievement_wake_up": 1.6162790697674418, "train_stats/mean_log_entropy": 0.6852193762396657, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.006005407262731, "train/action_min": 0.0, "train/action_std": 3.7166837303726763, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.024277502408734074, "train/actor_opt_grad_steps": 117360.0, "train/actor_opt_loss": -8.527648752210316, "train/adv_mag": 0.3611997811882584, "train/adv_max": 0.33831921142560467, "train/adv_mean": 0.0017101872882550298, "train/adv_min": -0.28979981111155617, "train/adv_std": 0.0379340844573798, "train/cont_avg": 0.9963686342592593, "train/cont_loss_mean": 0.00016902014251522142, "train/cont_loss_std": 0.005276299913693358, "train/cont_neg_acc": 0.991290727504214, "train/cont_neg_loss": 0.02156841090887487, "train/cont_pos_acc": 0.9999636460233617, "train/cont_pos_loss": 8.279364856623193e-05, "train/cont_pred": 0.9963626755608452, "train/cont_rate": 0.9963686342592593, "train/dyn_loss_mean": 12.384684209470395, "train/dyn_loss_std": 9.284779746444137, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8376920964982775, "train/extr_critic_critic_opt_grad_steps": 117360.0, "train/extr_critic_critic_opt_loss": 14718.595008680555, "train/extr_critic_mag": 10.480648874353479, "train/extr_critic_max": 10.480648874353479, "train/extr_critic_mean": 2.0782901181115045, "train/extr_critic_min": -0.28207554199077467, "train/extr_critic_std": 2.471687259497466, "train/extr_return_normed_mag": 1.4704892335114657, "train/extr_return_normed_max": 1.4704892335114657, "train/extr_return_normed_mean": 0.2823028037945429, "train/extr_return_normed_min": -0.05522069864759774, "train/extr_return_normed_std": 0.31817149299162406, "train/extr_return_rate": 0.6634249958727095, "train/extr_return_raw_mag": 11.409955639309354, "train/extr_return_raw_max": 11.409955639309354, "train/extr_return_raw_mean": 2.091716678054244, "train/extr_return_raw_min": -0.5557460122638278, "train/extr_return_raw_std": 2.4958312202382973, "train/extr_reward_mag": 1.0543113496568468, "train/extr_reward_max": 1.0543113496568468, "train/extr_reward_mean": 0.03957270783268743, "train/extr_reward_min": -0.47697315834186693, "train/extr_reward_std": 0.18698008766880742, "train/image_loss_mean": 6.037072054545084, "train/image_loss_std": 11.990688659526684, "train/model_loss_mean": 13.531243055838125, "train/model_loss_std": 15.761603051644784, "train/model_opt_grad_norm": 44.692099281593606, "train/model_opt_grad_steps": 117255.5925925926, "train/model_opt_loss": 13096.309816261573, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 967.5925925925926, "train/policy_entropy_mag": 2.803887566813716, "train/policy_entropy_max": 2.803887566813716, "train/policy_entropy_mean": 0.9644962553624754, "train/policy_entropy_min": 0.07937501740676385, "train/policy_entropy_std": 1.0007954893288789, "train/policy_logprob_mag": 7.4383839077419704, "train/policy_logprob_max": -0.009455658440236691, "train/policy_logprob_mean": -0.9662721523532161, "train/policy_logprob_min": -7.4383839077419704, "train/policy_logprob_std": 1.3354274952853167, "train/policy_randomness_mag": 0.9896492657838044, "train/policy_randomness_max": 0.9896492657838044, "train/policy_randomness_mean": 0.3404248553293723, "train/policy_randomness_min": 0.02801589793353169, "train/policy_randomness_std": 0.3532368885146247, "train/post_ent_mag": 61.36063817342122, "train/post_ent_max": 61.36063817342122, "train/post_ent_mean": 43.92255898934823, "train/post_ent_min": 20.087389310201008, "train/post_ent_std": 7.86739690568712, "train/prior_ent_mag": 71.20769393355758, "train/prior_ent_max": 71.20769393355758, "train/prior_ent_mean": 56.40692446673358, "train/prior_ent_min": 40.2049363454183, "train/prior_ent_std": 4.9565874523586695, "train/rep_loss_mean": 12.384684209470395, "train/rep_loss_std": 9.284779746444137, "train/reward_avg": 0.039688946223921245, "train/reward_loss_mean": 0.06319157321144034, "train/reward_loss_std": 0.2522729668352339, "train/reward_max_data": 1.0281481548591895, "train/reward_max_pred": 1.0249812267444751, "train/reward_neg_acc": 0.9912068155076769, "train/reward_neg_loss": 0.03101537592571091, "train/reward_pos_acc": 0.9799699045993664, "train/reward_pos_loss": 0.7840315514140659, "train/reward_pred": 0.039164939702109054, "train/reward_rate": 0.04296875, "eval_stats/sum_log_reward": 11.620000219345092, "eval_stats/max_log_achievement_collect_coal": 0.76, "eval_stats/max_log_achievement_collect_drink": 4.8, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.56, "eval_stats/max_log_achievement_collect_stone": 10.44, "eval_stats/max_log_achievement_collect_wood": 9.04, "eval_stats/max_log_achievement_defeat_skeleton": 0.04, "eval_stats/max_log_achievement_defeat_zombie": 1.64, "eval_stats/max_log_achievement_eat_cow": 0.8, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.24, "eval_stats/max_log_achievement_make_wood_sword": 1.16, "eval_stats/max_log_achievement_place_furnace": 1.6, "eval_stats/max_log_achievement_place_plant": 1.52, "eval_stats/max_log_achievement_place_stone": 3.36, "eval_stats/max_log_achievement_place_table": 3.0, "eval_stats/max_log_achievement_wake_up": 1.28, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 2.4950534225354204e-06, "report/cont_loss_std": 5.8411085774423555e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0006409759516827762, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.190076646817033e-07, "report/cont_pred": 0.9970716238021851, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 13.17938232421875, "report/dyn_loss_std": 9.582756996154785, "report/image_loss_mean": 5.912997245788574, "report/image_loss_std": 10.004216194152832, "report/model_loss_mean": 13.897451400756836, "report/model_loss_std": 14.153609275817871, "report/post_ent_mag": 64.2882080078125, "report/post_ent_max": 64.2882080078125, "report/post_ent_mean": 43.71080017089844, "report/post_ent_min": 21.14476203918457, "report/post_ent_std": 8.162652015686035, "report/prior_ent_mag": 70.75819396972656, "report/prior_ent_max": 70.75819396972656, "report/prior_ent_mean": 56.69145965576172, "report/prior_ent_min": 40.527462005615234, "report/prior_ent_std": 4.764586925506592, "report/rep_loss_mean": 13.17938232421875, "report/rep_loss_std": 9.582756996154785, "report/reward_avg": 0.04658202826976776, "report/reward_loss_mean": 0.0768221914768219, "report/reward_loss_std": 0.3540771007537842, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.007807731628418, "report/reward_neg_acc": 0.9938335418701172, "report/reward_neg_loss": 0.036502230912446976, "report/reward_pos_acc": 0.960784375667572, "report/reward_pos_loss": 0.8460639715194702, "report/reward_pred": 0.04780496656894684, "report/reward_rate": 0.0498046875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.00017060824029613286, "eval/cont_loss_std": 0.004682653583586216, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.08710640668869019, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.794833330379333e-07, "eval/cont_pred": 0.9982061386108398, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 16.733001708984375, "eval/dyn_loss_std": 10.988492012023926, "eval/image_loss_mean": 9.4462890625, "eval/image_loss_std": 16.16778564453125, "eval/model_loss_mean": 19.58168601989746, "eval/model_loss_std": 20.54440689086914, "eval/post_ent_mag": 59.8991584777832, "eval/post_ent_max": 59.8991584777832, "eval/post_ent_mean": 42.00754928588867, "eval/post_ent_min": 20.98868179321289, "eval/post_ent_std": 7.616106033325195, "eval/prior_ent_mag": 70.75819396972656, "eval/prior_ent_max": 70.75819396972656, "eval/prior_ent_mean": 56.78080749511719, "eval/prior_ent_min": 42.75503158569336, "eval/prior_ent_std": 4.421623229980469, "eval/rep_loss_mean": 16.733001708984375, "eval/rep_loss_std": 10.988492012023926, "eval/reward_avg": 0.03017578087747097, "eval/reward_loss_mean": 0.09542469680309296, "eval/reward_loss_std": 0.5519653558731079, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0007445812225342, "eval/reward_neg_acc": 0.9838709235191345, "eval/reward_neg_loss": 0.05117742717266083, "eval/reward_pos_acc": 0.90625, "eval/reward_pos_loss": 1.4670900106430054, "eval/reward_pred": 0.033703505992889404, "eval/reward_rate": 0.03125, "replay/size": 1000000.0, "replay/inserts": 21592.0, "replay/samples": 21584.0, "replay/insert_wait_avg": 1.3707743259923199e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.369835329727387e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 9808.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2734780303805726e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1014.8813328742981, "timer/env.step_count": 2699.0, "timer/env.step_total": 217.40076160430908, "timer/env.step_frac": 0.2142129868411286, "timer/env.step_avg": 0.08054863342138165, "timer/env.step_min": 0.024577856063842773, "timer/env.step_max": 3.8294169902801514, "timer/replay._sample_count": 21584.0, "timer/replay._sample_total": 11.361177921295166, "timer/replay._sample_frac": 0.01119458753775536, "timer/replay._sample_avg": 0.0005263703632920296, "timer/replay._sample_min": 0.0004363059997558594, "timer/replay._sample_max": 0.00936269760131836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3925.0, "timer/agent.policy_total": 70.11526727676392, "timer/agent.policy_frac": 0.06908715827710303, "timer/agent.policy_avg": 0.01786376236350673, "timer/agent.policy_min": 0.009818315505981445, "timer/agent.policy_max": 0.14143776893615723, "timer/dataset_train_count": 1349.0, "timer/dataset_train_total": 0.1528644561767578, "timer/dataset_train_frac": 0.00015062298539260984, "timer/dataset_train_avg": 0.00011331686892272633, "timer/dataset_train_min": 9.751319885253906e-05, "timer/dataset_train_max": 0.00042247772216796875, "timer/agent.train_count": 1349.0, "timer/agent.train_total": 610.4757115840912, "timer/agent.train_frac": 0.601524229295982, "timer/agent.train_avg": 0.45253944520688744, "timer/agent.train_min": 0.43524980545043945, "timer/agent.train_max": 1.9692509174346924, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4733610153198242, "timer/agent.report_frac": 0.0004664200631015588, "timer/agent.report_avg": 0.2366805076599121, "timer/agent.report_min": 0.22835755348205566, "timer/agent.report_max": 0.24500346183776855, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.124470811843707e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 21.275060921746523}
{"step": 1890768, "time": 85554.45457434654, "episode/length": 818.0, "episode/score": 14.100000008940697, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 1890792, "time": 85556.65199017525, "episode/length": 195.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 1891024, "time": 85566.50185132027, "episode/length": 365.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9863387978142076, "episode/intrinsic_return": 0.0}
{"step": 1891056, "time": 85569.10462236404, "episode/length": 429.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9930232558139535, "episode/intrinsic_return": 0.0}
{"step": 1891176, "time": 85574.54592847824, "episode/length": 50.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 1891296, "time": 85580.66164135933, "episode/length": 212.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 1891416, "time": 85586.19778990746, "episode/length": 323.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 1891600, "time": 85594.505453825, "episode/length": 209.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 1892488, "time": 85628.38930225372, "episode/length": 178.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 1892544, "time": 85632.18265604973, "episode/length": 428.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9976689976689976, "episode/intrinsic_return": 0.0}
{"step": 1892656, "time": 85637.72438597679, "episode/length": 203.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1892800, "time": 85644.32429742813, "episode/length": 202.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 1893184, "time": 85659.2921860218, "episode/length": 79.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 1893224, "time": 85662.03228163719, "episode/length": 225.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 1893248, "time": 85664.65166044235, "episode/length": 243.0, "episode/score": 14.100000001490116, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 1893384, "time": 85670.77790784836, "episode/length": 222.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 1893680, "time": 85682.75325059891, "episode/length": 127.0, "episode/score": 8.1000000461936, "episode/reward_rate": 0.953125, "episode/intrinsic_return": 0.0}
{"step": 1893888, "time": 85691.43990921974, "episode/length": 174.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 1894056, "time": 85698.79210019112, "episode/length": 407.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9877450980392157, "episode/intrinsic_return": 0.0}
{"step": 1894464, "time": 85715.11431479454, "episode/length": 207.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 1894520, "time": 85718.49824118614, "episode/length": 166.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 1894728, "time": 85727.36352443695, "episode/length": 167.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 1894888, "time": 85734.56407594681, "episode/length": 207.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 1895448, "time": 85755.46866440773, "episode/length": 220.0, "episode/score": 13.100000031292439, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 1895496, "time": 85758.83021068573, "episode/length": 280.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9715302491103203, "episode/intrinsic_return": 0.0}
{"step": 1895504, "time": 85760.94090747833, "episode/length": 201.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 1895736, "time": 85770.32679414749, "episode/length": 209.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 1896048, "time": 85782.82204437256, "episode/length": 197.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 1896216, "time": 85790.0948586464, "episode/length": 211.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9858490566037735, "episode/intrinsic_return": 0.0}
{"step": 1896624, "time": 85806.0656774044, "episode/length": 236.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 1896824, "time": 85814.39778375626, "episode/length": 171.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 1896992, "time": 85822.03753376007, "episode/length": 186.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 1897088, "time": 85826.85103964806, "episode/length": 168.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 1897520, "time": 85843.31280231476, "episode/length": 65.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 1897632, "time": 85848.93750166893, "episode/length": 265.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 1897672, "time": 85852.19008135796, "episode/length": 181.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 1897688, "time": 85854.87624549866, "episode/length": 204.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 1898064, "time": 85870.20858621597, "episode/length": 179.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9611111111111111, "episode/intrinsic_return": 0.0}
{"step": 1898512, "time": 85887.35140299797, "episode/length": 210.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 1898640, "time": 85893.38651752472, "episode/length": 193.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 1898944, "time": 85905.34705209732, "episode/length": 177.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 1899424, "time": 85923.73061203957, "episode/length": 223.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1899904, "time": 85942.02250480652, "episode/length": 276.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 1899928, "time": 85944.29789710045, "episode/length": 281.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 1900056, "time": 85950.24542617798, "episode/length": 248.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 1900080, "time": 85969.77670049667, "eval_episode/length": 65.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9242424242424242}
{"step": 1900080, "time": 85976.20725035667, "eval_episode/length": 166.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 1900080, "time": 85979.27724981308, "eval_episode/length": 198.0, "eval_episode/score": 13.099999994039536, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 1900080, "time": 85983.00276565552, "eval_episode/length": 240.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.995850622406639}
{"step": 1900080, "time": 85984.82369685173, "eval_episode/length": 244.0, "eval_episode/score": 13.099999994039536, "eval_episode/reward_rate": 0.9959183673469387}
{"step": 1900080, "time": 85987.85810661316, "eval_episode/length": 275.0, "eval_episode/score": 13.100000008940697, "eval_episode/reward_rate": 0.9963768115942029}
{"step": 1900080, "time": 85996.25986504555, "eval_episode/length": 372.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9865951742627346}
{"step": 1900080, "time": 86000.88845324516, "eval_episode/length": 188.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 1900456, "time": 86013.52298140526, "episode/length": 188.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 1900856, "time": 86030.65109443665, "episode/length": 292.0, "episode/score": 11.100000038743019, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 1900864, "time": 86032.86358332634, "episode/length": 179.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 1901448, "time": 86054.12149381638, "episode/length": 819.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.998780487804878, "episode/intrinsic_return": 0.0}
{"step": 1901616, "time": 86061.66399240494, "episode/length": 194.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 1901800, "time": 86069.44984483719, "episode/length": 394.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9898734177215189, "episode/intrinsic_return": 0.0}
{"step": 1902352, "time": 86090.38427782059, "episode/length": 186.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 1902632, "time": 86101.32827949524, "episode/length": 340.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9970674486803519, "episode/intrinsic_return": 0.0}
{"step": 1902784, "time": 86108.32797765732, "episode/length": 290.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9725085910652921, "episode/intrinsic_return": 0.0}
{"step": 1903160, "time": 86122.82164025307, "episode/length": 192.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 1903288, "time": 86128.72962474823, "episode/length": 229.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 1903416, "time": 86134.74939489365, "episode/length": 318.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9749216300940439, "episode/intrinsic_return": 0.0}
{"step": 1903664, "time": 86145.0713186264, "episode/length": 466.0, "episode/score": 9.1000000461936, "episode/reward_rate": 0.9957173447537473, "episode/intrinsic_return": 0.0}
{"step": 1903736, "time": 86149.11554789543, "episode/length": 55.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 1904488, "time": 86176.72239971161, "episode/length": 266.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 1904488, "time": 86176.73085069656, "episode/length": 165.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 1904792, "time": 86190.8279645443, "episode/length": 269.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9703703703703703, "episode/intrinsic_return": 0.0}
{"step": 1905056, "time": 86201.71793651581, "episode/length": 283.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9683098591549296, "episode/intrinsic_return": 0.0}
{"step": 1905064, "time": 86203.32014536858, "episode/length": 174.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 1905616, "time": 86224.37334108353, "episode/length": 274.0, "episode/score": 15.100000031292439, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 1905960, "time": 86237.69625544548, "episode/length": 277.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9856115107913669, "episode/intrinsic_return": 0.0}
{"step": 1906320, "time": 86251.8895111084, "episode/length": 228.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 1906368, "time": 86255.08331751823, "episode/length": 570.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9982486865148862, "episode/intrinsic_return": 0.0}
{"step": 1906936, "time": 86275.98235225677, "episode/length": 305.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 1907056, "time": 86281.91818284988, "episode/length": 248.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 1907536, "time": 86300.05387449265, "episode/length": 196.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 1907680, "time": 86306.71826457977, "episode/length": 327.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9908536585365854, "episode/intrinsic_return": 0.0}
{"step": 1908192, "time": 86326.35468435287, "episode/length": 63.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 1908232, "time": 86329.14224243164, "episode/length": 232.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 1908304, "time": 86333.39785909653, "episode/length": 438.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9977220956719818, "episode/intrinsic_return": 0.0}
{"step": 1908336, "time": 86336.1559817791, "episode/length": 251.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 1908520, "time": 86343.75974917412, "episode/length": 197.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 1909048, "time": 86365.47060060501, "episode/length": 188.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 1909928, "time": 86397.28604960442, "episode/length": 538.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9981447124304267, "episode/intrinsic_return": 0.0}
{"step": 1909968, "time": 86400.53455162048, "episode/length": 221.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
