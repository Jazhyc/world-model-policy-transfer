{"step": 1560, "time": 144.44161820411682, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 144.45711946487427, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 145.29886388778687, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 145.3078052997589, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 145.31750655174255, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 145.32427501678467, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 145.33125758171082, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 145.337064743042, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 260.38194942474365, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.385009765625, "train/action_min": 0.0, "train/action_std": 2.247141122817993, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0006161404307931662, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.1213785409927368, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.7353378534317017, "train/cont_loss_std": 0.30063924193382263, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.4970703125, "train/cont_pos_loss": 0.7353378534317017, "train/cont_pred": 0.49989330768585205, "train/cont_rate": 1.0, "train/dyn_loss_mean": 11.272039413452148, "train/dyn_loss_std": 0.4000547528266907, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.7587199211120605, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 26031.982421875, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 4933.89794921875, "train/image_loss_std": 38.6506462097168, "train/model_loss_mean": 4946.9384765625, "train/model_loss_std": 38.64381408691406, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 49469384.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9213240146636963, "train/policy_entropy_max": 1.9213240146636963, "train/policy_entropy_mean": 1.579580545425415, "train/policy_entropy_min": 0.6656676530838013, "train/policy_entropy_std": 0.15905259549617767, "train/policy_logprob_mag": 4.7900590896606445, "train/policy_logprob_max": -0.16089671850204468, "train/policy_logprob_mean": -1.590004324913025, "train/policy_logprob_min": -4.7900590896606445, "train/policy_logprob_std": 0.783314049243927, "train/policy_randomness_mag": 0.9873653054237366, "train/policy_randomness_max": 0.9873653054237366, "train/policy_randomness_mean": 0.8117438554763794, "train/policy_randomness_min": 0.34208551049232483, "train/policy_randomness_std": 0.08173687011003494, "train/post_ent_mag": 105.68446350097656, "train/post_ent_max": 105.68446350097656, "train/post_ent_mean": 105.22731018066406, "train/post_ent_min": 104.8712158203125, "train/post_ent_std": 0.16026253998279572, "train/prior_ent_mag": 106.43263244628906, "train/prior_ent_max": 106.43263244628906, "train/prior_ent_mean": 105.43997955322266, "train/prior_ent_min": 104.33587646484375, "train/prior_ent_std": 0.3142126500606537, "train/rep_loss_mean": 11.272039413452148, "train/rep_loss_std": 0.4000547528266907, "train/reward_avg": 0.0, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 0.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.7721130847930908, "report/cont_loss_std": 0.3086393475532532, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.4453125, "report/cont_pos_loss": 0.7721130847930908, "report/cont_pred": 0.4826556146144867, "report/cont_rate": 1.0, "report/dyn_loss_mean": 11.38603687286377, "report/dyn_loss_std": 0.45148321986198425, "report/image_loss_mean": 4930.642578125, "report/image_loss_std": 36.76647186279297, "report/model_loss_mean": 4943.7880859375, "report/model_loss_std": 36.72998809814453, "report/post_ent_mag": 105.67393493652344, "report/post_ent_max": 105.67393493652344, "report/post_ent_mean": 105.24794006347656, "report/post_ent_min": 104.66207122802734, "report/post_ent_std": 0.1571175456047058, "report/prior_ent_mag": 106.237548828125, "report/prior_ent_max": 106.237548828125, "report/prior_ent_mean": 105.40699768066406, "report/prior_ent_min": 104.15382385253906, "report/prior_ent_std": 0.3137330710887909, "report/rep_loss_mean": 11.38603687286377, "report/rep_loss_std": 0.45148321986198425, "report/reward_avg": 0.0, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.7306325435638428, "eval/cont_loss_std": 0.2758055031299591, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.482421875, "eval/cont_pos_loss": 0.7306325435638428, "eval/cont_pred": 0.49914008378982544, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 11.39714241027832, "eval/dyn_loss_std": 0.4296210706233978, "eval/image_loss_mean": 4927.5458984375, "eval/image_loss_std": 41.5127067565918, "eval/model_loss_mean": 4940.65625, "eval/model_loss_std": 41.48544692993164, "eval/post_ent_mag": 105.73595428466797, "eval/post_ent_max": 105.73595428466797, "eval/post_ent_mean": 105.20812225341797, "eval/post_ent_min": 104.85271453857422, "eval/post_ent_std": 0.1527550369501114, "eval/prior_ent_mag": 106.5069808959961, "eval/prior_ent_max": 106.5069808959961, "eval/prior_ent_mean": 105.42838287353516, "eval/prior_ent_min": 104.35426330566406, "eval/prior_ent_std": 0.29530832171440125, "eval/rep_loss_mean": 11.39714241027832, "eval/rep_loss_std": 0.4296210706233978, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.4740448575484494e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.42929322378976e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.4083544035705421e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.408512387956892e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 142.04181742668152, "timer/env.step_count": 196.0, "timer/env.step_total": 1.299992561340332, "timer/env.step_frac": 0.009152181976349014, "timer/env.step_avg": 0.006632615108879245, "timer/env.step_min": 0.006123542785644531, "timer/env.step_max": 0.015218019485473633, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.07692956924438477, "timer/replay._sample_frac": 0.0005415980352693946, "timer/replay._sample_avg": 0.0006868711539677211, "timer/replay._sample_min": 0.0003409385681152344, "timer/replay._sample_max": 0.0019109249114990234, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.0491185188293457, "timer/agent.save_frac": 0.01442616375904265, "timer/agent.save_avg": 2.0491185188293457, "timer/agent.save_min": 2.0491185188293457, "timer/agent.save_max": 2.0491185188293457, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 22.875777006149292, "timer/agent.policy_frac": 0.1610495938490593, "timer/agent.policy_avg": 0.07888198967637687, "timer/agent.policy_min": 0.00917196273803711, "timer/agent.policy_max": 17.757269382476807, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.147125244140625e-05, "timer/dataset_train_frac": 2.2156329038560024e-07, "timer/dataset_train_avg": 3.147125244140625e-05, "timer/dataset_train_min": 3.147125244140625e-05, "timer/dataset_train_max": 3.147125244140625e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 89.14232778549194, "timer/agent.train_frac": 0.6275780569444277, "timer/agent.train_avg": 89.14232778549194, "timer/agent.train_min": 89.14232778549194, "timer/agent.train_max": 89.14232778549194, "timer/agent.report_count": 2.0, "timer/agent.report_total": 23.554430961608887, "timer/agent.report_frac": 0.165827440033757, "timer/agent.report_avg": 11.777215480804443, "timer/agent.report_min": 0.24320721626281738, "timer/agent.report_max": 23.31122374534607, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.790855407714844e-05, "timer/dataset_eval_frac": 2.6688305432810936e-07, "timer/dataset_eval_avg": 3.790855407714844e-05, "timer/dataset_eval_min": 3.790855407714844e-05, "timer/dataset_eval_max": 3.790855407714844e-05}
{"step": 2312, "time": 283.0355477333069, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 283.04305124282837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 283.04969120025635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 283.0571255683899, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 283.06444668769836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 283.0711352825165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 283.0795736312866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 283.0873878002167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 353.8988928794861, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 353.91467237472534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 353.9260895252228, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 353.9370012283325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 353.9473991394043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 353.9663598537445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 353.9759976863861, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 353.98496985435486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 5392, "time": 377.3451192378998, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 6512, "time": 411.36096572875977, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 423.9302246570587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 423.9467692375183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 423.95558643341064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 423.9681828022003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 423.9802017211914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 423.9913115501404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 7704, "time": 447.3813707828522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 8824, "time": 481.93595790863037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 495.09210753440857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 495.1079845428467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 495.11958169937134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 495.12700366973877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 495.1376178264618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 495.14704298973083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9400, "time": 499.5272080898285, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 10016, "time": 518.5899510383606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 526.0821497440338, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 526.0884835720062, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 526.0965828895569, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 526.1030905246735, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 526.1116654872894, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 526.1191477775574, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 526.126268863678, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 526.1331498622894, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 11136, "time": 558.1357862949371, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 570.7194242477417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 570.7267479896545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 570.7356677055359, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 570.7434351444244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 570.7536993026733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11712, "time": 575.6174285411835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 12328, "time": 594.0606236457825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13448, "time": 627.8541340827942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 640.9098131656647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 640.9190793037415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 640.9293694496155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 640.9409012794495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 640.9523057937622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 14024, "time": 645.3224973678589, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 14640, "time": 664.1793372631073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 15024, "time": 675.8386979103088, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 15760, "time": 698.2303459644318, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 710.8786952495575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 710.8863925933838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 710.8949012756348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 710.9043419361115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 710.9131999015808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16952, "time": 734.7176306247711, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 17336, "time": 746.2518973350525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18072, "time": 768.6482813358307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 781.7648656368256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 781.7731642723083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 781.781715631485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 781.7911713123322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 781.8022673130035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18720, "time": 788.7438752651215, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 19264, "time": 805.2135071754456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 19648, "time": 816.9541392326355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 835.8052642345428, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 835.814065694809, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 835.8228223323822, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 835.8303060531616, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 835.8389236927032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 835.8474543094635, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 835.8561625480652, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 835.8643717765808, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20384, "time": 845.599182844162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 858.2672715187073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 858.2756588459015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 858.2841317653656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 858.2962591648102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 21032, "time": 865.058652639389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 21576, "time": 881.56050157547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 21960, "time": 893.1673321723938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 22136, "time": 898.5104026794434, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 22696, "time": 915.6683399677277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 928.7476966381073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 928.7573115825653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 928.7667846679688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23344, "time": 935.6064743995667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23888, "time": 952.1115198135376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 24272, "time": 963.7844803333282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 24448, "time": 969.2413773536682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25008, "time": 986.7037990093231, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 999.435316324234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 999.4426393508911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 999.4506437778473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25656, "time": 1006.2402338981628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 26000, "time": 1016.9588613510132, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 26200, "time": 1022.8296208381653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 26584, "time": 1034.4641313552856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 26760, "time": 1039.775507926941, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1069.7773234844208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1069.7847406864166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1069.791270494461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27968, "time": 1076.6161544322968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 28312, "time": 1086.883749961853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 28512, "time": 1093.1489706039429, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 28896, "time": 1104.8100922107697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29072, "time": 1110.17604470253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1139.8106997013092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1139.8189492225647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1139.8274972438812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1145.100441455841, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1145.1088535785675, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1145.119764328003, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1145.1304080486298, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1145.1388993263245, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1145.1485011577606, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1145.1585478782654, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1145.1684670448303, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30280, "time": 1151.9946641921997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30624, "time": 1162.6064853668213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30824, "time": 1168.397916316986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31208, "time": 1180.0268790721893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31384, "time": 1185.3455865383148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1215.3668444156647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1215.375888824463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1215.3853631019592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32592, "time": 1222.1331021785736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32936, "time": 1232.7750730514526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 33065, "time": 1237.6967380046844, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9996907965180837, "train/action_min": 0.0, "train/action_std": 2.0005844401829136, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00024454745876651286, "train/actor_opt_grad_steps": 990.0, "train/actor_opt_loss": 2.1473839214942676, "train/adv_mag": 0.0006913252372786526, "train/adv_max": 0.0006912742698212215, "train/adv_mean": 0.00040937652449509273, "train/adv_min": 5.5362922026131e-05, "train/adv_std": 0.000190158129726349, "train/cont_avg": 0.9968769828680203, "train/cont_loss_mean": 0.02527174098734145, "train/cont_loss_std": 0.3032959086639808, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.749909652176724, "train/cont_pos_acc": 0.9970950859452262, "train/cont_pos_loss": 0.007356947664419666, "train/cont_pred": 0.994063824263926, "train/cont_rate": 0.9968769828680203, "train/dyn_loss_mean": 1.0674684562053778, "train/dyn_loss_std": 0.005074129615178176, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.3061139560139114, "train/extr_critic_critic_opt_grad_steps": 990.0, "train/extr_critic_critic_opt_loss": 6799.307322235882, "train/extr_critic_mag": 0.003812570862358597, "train/extr_critic_max": 0.003812562995755733, "train/extr_critic_mean": 0.0038027612949081985, "train/extr_critic_min": 0.0037935173450992796, "train/extr_critic_std": 2.4774622153220197e-06, "train/extr_return_normed_mag": 0.0011860939276659053, "train/extr_return_normed_max": 0.0011860783343016427, "train/extr_return_normed_mean": 0.0009098922935455241, "train/extr_return_normed_min": 0.0005598546835964049, "train/extr_return_normed_std": 0.00019009647003192005, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.004488347503861737, "train/extr_return_raw_max": 0.004488323180283855, "train/extr_return_raw_mean": 0.0042121372919434515, "train/extr_return_raw_min": 0.0038620995300910313, "train/extr_return_raw_std": 0.00019009646972237436, "train/extr_reward_mag": 7.621709465375407e-05, "train/extr_reward_max": 7.621527928386242e-05, "train/extr_reward_mean": 7.611637569227173e-05, "train/extr_reward_min": 7.577414440019481e-05, "train/extr_reward_std": 4.7553094260382023e-08, "train/image_loss_mean": 26.1230298658918, "train/image_loss_std": 0.38048690466711366, "train/model_loss_mean": 26.896593226696634, "train/model_loss_std": 0.6662982915183009, "train/model_opt_grad_norm": 103.90501021852299, "train/model_opt_grad_steps": 980.0, "train/model_opt_loss": 512.4572703124303, "train/model_opt_model_opt_grad_overflow": 0.005076142131979695, "train/model_opt_model_opt_grad_scale": 14.524508248730964, "train/policy_entropy_mag": 1.9457730635773711, "train/policy_entropy_max": 1.9457730635773711, "train/policy_entropy_mean": 1.9408848551929299, "train/policy_entropy_min": 1.8559337509465097, "train/policy_entropy_std": 0.003331165616566003, "train/policy_logprob_mag": 2.434318085007256, "train/policy_logprob_max": -1.4536119471800508, "train/policy_logprob_mean": -1.940892367798665, "train/policy_logprob_min": -2.434318085007256, "train/policy_logprob_std": 0.0858488411354232, "train/policy_randomness_mag": 0.9999296111503834, "train/policy_randomness_max": 0.9999296111503834, "train/policy_randomness_mean": 0.9974175615964203, "train/policy_randomness_min": 0.9537613357081631, "train/policy_randomness_std": 0.0017118805849234465, "train/post_ent_mag": 77.9610181314691, "train/post_ent_max": 77.9610181314691, "train/post_ent_mean": 77.92340978632119, "train/post_ent_min": 77.66660277855578, "train/post_ent_std": 0.052092500380831325, "train/prior_ent_mag": 82.88947300015367, "train/prior_ent_max": 82.88947300015367, "train/prior_ent_mean": 82.77458899638374, "train/prior_ent_min": 82.45571117110664, "train/prior_ent_std": 0.06661379308000132, "train/rep_loss_mean": 1.0674684562053778, "train/rep_loss_std": 0.005074129615178176, "train/reward_avg": 0.00014213136123105655, "train/reward_loss_mean": 0.10781064217787255, "train/reward_loss_std": 0.06883626035905221, "train/reward_max_data": 0.13101205668473606, "train/reward_max_pred": 7.617171040646316e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.10545845322640669, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.885549033560403, "train/reward_pred": 7.60535098527213e-05, "train/reward_rate": 0.00023794416243654823, "train_stats/mean_log_entropy": 1.925912747175797, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.009826993569731712, "report/cont_loss_std": 0.16825276613235474, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.391285419464111, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004566524177789688, "report/cont_pred": 0.9954440593719482, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.29381656646728516, "report/image_loss_std": 0.08162440359592438, "report/model_loss_mean": 0.9042725563049316, "report/model_loss_std": 0.18509578704833984, "report/post_ent_mag": 64.22138977050781, "report/post_ent_max": 64.22138977050781, "report/post_ent_mean": 64.19197082519531, "report/post_ent_min": 64.05793762207031, "report/post_ent_std": 0.029806382954120636, "report/prior_ent_mag": 70.74655151367188, "report/prior_ent_max": 70.74655151367188, "report/prior_ent_mean": 70.66239929199219, "report/prior_ent_min": 70.52526092529297, "report/prior_ent_std": 0.02779124677181244, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0006289193406701088, "report/reward_loss_std": 9.541683994029881e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 9.298324584960938e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0006289193406701088, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 9.261409286409616e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.004566524177789688, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004566524177789688, "eval/cont_pred": 0.9954440593719482, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2728019058704376, "eval/image_loss_std": 0.07097457349300385, "eval/model_loss_mean": 0.8779973983764648, "eval/model_loss_std": 0.07097446918487549, "eval/post_ent_mag": 64.21936798095703, "eval/post_ent_max": 64.21936798095703, "eval/post_ent_mean": 64.19242095947266, "eval/post_ent_min": 64.05598449707031, "eval/post_ent_std": 0.029817048460245132, "eval/prior_ent_mag": 70.732177734375, "eval/prior_ent_max": 70.732177734375, "eval/prior_ent_mean": 70.6612548828125, "eval/prior_ent_min": 70.51390838623047, "eval/prior_ent_std": 0.02751251496374607, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0006289086304605007, "eval/reward_loss_std": 9.812099506234517e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 9.298324584960938e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0006289086304605007, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 9.261688683182001e-05, "eval/reward_rate": 0.0, "replay/size": 32561.0, "replay/inserts": 31504.0, "replay/samples": 31504.0, "replay/insert_wait_avg": 1.3618405062635276e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.759218887243857e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10304.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2343730068536778e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 977.3045661449432, "timer/env.step_count": 3938.0, "timer/env.step_total": 38.39243936538696, "timer/env.step_frac": 0.039284006946605235, "timer/env.step_avg": 0.009749222794664033, "timer/env.step_min": 0.007963895797729492, "timer/env.step_max": 0.03521227836608887, "timer/replay._sample_count": 31504.0, "timer/replay._sample_total": 16.316747426986694, "timer/replay._sample_frac": 0.016695662736284374, "timer/replay._sample_avg": 0.0005179262134010505, "timer/replay._sample_min": 0.00035500526428222656, "timer/replay._sample_max": 0.00988459587097168, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4805.0, "timer/agent.policy_total": 50.479084730148315, "timer/agent.policy_frac": 0.05165133416829018, "timer/agent.policy_avg": 0.010505532722195279, "timer/agent.policy_min": 0.008751630783081055, "timer/agent.policy_max": 0.09149765968322754, "timer/dataset_train_count": 1969.0, "timer/dataset_train_total": 0.20832204818725586, "timer/dataset_train_frac": 0.00021315980238279149, "timer/dataset_train_avg": 0.00010580093864258805, "timer/dataset_train_min": 8.344650268554688e-05, "timer/dataset_train_max": 0.0010728836059570312, "timer/agent.train_count": 1969.0, "timer/agent.train_total": 874.1708471775055, "timer/agent.train_frac": 0.8944712605055587, "timer/agent.train_avg": 0.4439669107046752, "timer/agent.train_min": 0.43334221839904785, "timer/agent.train_max": 0.6811130046844482, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4728074073791504, "timer/agent.report_frac": 0.00048378716702836803, "timer/agent.report_avg": 0.2364037036895752, "timer/agent.report_min": 0.2298729419708252, "timer/agent.report_max": 0.2429344654083252, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 3.439769015499985e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 32.235125456708104}
{"step": 33136, "time": 1239.8997149467468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 33520, "time": 1251.5160233974457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 33696, "time": 1256.8804256916046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 33880, "time": 1262.2514905929565, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1286.374195575714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1286.3812801837921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34904, "time": 1293.1240785121918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35248, "time": 1303.8043947219849, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35448, "time": 1309.5987763404846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35832, "time": 1321.1105031967163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36008, "time": 1326.482838153839, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36192, "time": 1332.2156419754028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36528, "time": 1342.2896077632904, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1356.3926742076874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1356.4110822677612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 37216, "time": 1363.1369156837463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 37560, "time": 1373.2584145069122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 37760, "time": 1379.4601595401764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38144, "time": 1391.1545071601868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38320, "time": 1396.4473271369934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38840, "time": 1412.3312504291534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1426.3696043491364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1426.3819389343262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39528, "time": 1433.0993702411652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39872, "time": 1443.638666152954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 1450.0021603107452, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 40040, "time": 1453.7141597270966, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1453.721420764923, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1453.728926897049, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1453.7367079257965, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1453.7438139915466, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1453.7504913806915, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1453.75741147995, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40072, "time": 1454.7214095592499, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40456, "time": 1466.2533752918243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40632, "time": 1471.5352897644043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40720, "time": 1474.3848881721497, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 41152, "time": 1487.9363644123077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1501.8755731582642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1501.882520198822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41800, "time": 1507.3373448848724, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 41840, "time": 1508.7685396671295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41880, "time": 1509.7772550582886, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 42184, "time": 1518.9023759365082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42384, "time": 1525.147331237793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42768, "time": 1536.853334903717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43032, "time": 1544.574818611145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43464, "time": 1557.7075033187866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44112, "time": 1577.5542929172516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44152, "time": 1578.537338733673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44192, "time": 1579.9597370624542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44496, "time": 1589.0964488983154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44696, "time": 1594.8592374324799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45080, "time": 1606.4371395111084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45344, "time": 1614.5610609054565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45776, "time": 1627.597428560257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46424, "time": 1646.8182158470154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46464, "time": 1648.2405052185059, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46504, "time": 1649.2275488376617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46808, "time": 1658.4598474502563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47008, "time": 1664.692991733551, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47392, "time": 1676.2040848731995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47656, "time": 1683.896024942398, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48088, "time": 1696.9517481327057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48736, "time": 1716.6904745101929, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48776, "time": 1717.7059683799744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48816, "time": 1719.1318809986115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49120, "time": 1728.2869131565094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49320, "time": 1734.568636894226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49704, "time": 1746.168863773346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49968, "time": 1754.3273229599, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 1756.873235464096, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 50024, "time": 1761.0569713115692, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1761.072716474533, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1761.0796175003052, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1761.0883584022522, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1761.0979118347168, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1761.1080496311188, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1761.1162469387054, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50400, "time": 1772.657151222229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51048, "time": 1791.9352579116821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51088, "time": 1793.3534719944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51128, "time": 1794.3432643413544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51432, "time": 1803.4740166664124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51632, "time": 1809.7788155078888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52016, "time": 1821.3942687511444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52280, "time": 1829.121859073639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52544, "time": 1837.3312900066376, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 52712, "time": 1842.239339351654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53360, "time": 1861.907062292099, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53400, "time": 1862.9047875404358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53744, "time": 1873.5564813613892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53944, "time": 1879.3294689655304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54328, "time": 1890.8292770385742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54592, "time": 1899.062576532364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54856, "time": 1906.826756477356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55024, "time": 1912.0911684036255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55672, "time": 1931.5439960956573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55712, "time": 1932.9793057441711, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56056, "time": 1943.091067790985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56256, "time": 1949.3256433010101, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56640, "time": 1960.955811738968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56904, "time": 1968.6737117767334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57168, "time": 1976.8830082416534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57336, "time": 1981.7140090465546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57984, "time": 2001.8530609607697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58024, "time": 2002.843858718872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58368, "time": 2013.368817806244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58568, "time": 2019.3558807373047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58952, "time": 2031.0403599739075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59216, "time": 2039.2730526924133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59480, "time": 2047.052041053772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59648, "time": 2052.306336402893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 2068.0222363471985, "eval_episode/length": 259.0, "eval_episode/score": 0.19062499701976776, "eval_episode/reward_rate": 0.0038461538461538464}
{"step": 60008, "time": 2068.546255350113, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2068.55424284935, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2068.5614976882935, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2068.5685822963715, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2068.577696084976, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2068.5883769989014, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2068.598273038864, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60296, "time": 2077.3125972747803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60336, "time": 2078.729027032852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60680, "time": 2088.8295855522156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60880, "time": 2095.0433382987976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61264, "time": 2106.6141731739044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61528, "time": 2114.2763254642487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61792, "time": 2122.417038679123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61960, "time": 2127.2342467308044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62608, "time": 2147.021603822708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62648, "time": 2148.007562637329, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62992, "time": 2158.574870109558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63192, "time": 2164.3460166454315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63528, "time": 2174.5382692813873, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 63840, "time": 2184.2117445468903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64104, "time": 2191.914167881012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64272, "time": 2197.332981109619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64920, "time": 2216.5690681934357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64960, "time": 2217.9939799308777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65304, "time": 2228.2298278808594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65504, "time": 2234.4776859283447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65577, "time": 2237.873598575592, "train_stats/mean_log_entropy": 1.9350844601280668, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9993908511006775, "train/action_min": 0.0, "train/action_std": 1.999743293658853, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00017800758903858475, "train/actor_opt_grad_steps": 2990.0, "train/actor_opt_loss": 1.2089741582170201, "train/adv_mag": 0.0006566912100966928, "train/adv_max": 0.0006542887281754922, "train/adv_mean": 0.0003615659354899807, "train/adv_min": 5.730684718181347e-06, "train/adv_std": 0.0001713553693273443, "train/cont_avg": 0.9962428802339901, "train/cont_loss_mean": 0.024844216685191604, "train/cont_loss_std": 0.3361760921835936, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.661775959600316, "train/cont_pos_acc": 0.9999999859062909, "train/cont_pos_loss": 0.003579759348661001, "train/cont_pred": 0.9964269690325694, "train/cont_rate": 0.9962428802339901, "train/dyn_loss_mean": 1.000000145634994, "train/dyn_loss_std": 1.2078779959463942e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08003620977692416, "train/extr_critic_critic_opt_grad_steps": 2990.0, "train/extr_critic_critic_opt_loss": 7483.773329260314, "train/extr_critic_mag": 0.02064233871516336, "train/extr_critic_max": 0.02064233871516336, "train/extr_critic_mean": 0.02059380368792952, "train/extr_critic_min": 0.0205507272570004, "train/extr_critic_std": 1.2854179646217187e-05, "train/extr_return_normed_mag": 0.0012820288676566678, "train/extr_return_normed_max": 0.0012801067646721314, "train/extr_return_normed_mean": 0.0010222996420250934, "train/extr_return_normed_min": 0.0006876384674254897, "train/extr_return_normed_std": 0.00016984274908156356, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.021213158621026084, "train/extr_return_raw_max": 0.021213158621026084, "train/extr_return_raw_mean": 0.020955352557667076, "train/extr_return_raw_min": 0.02062069032377944, "train/extr_return_raw_std": 0.0001698427495139096, "train/extr_reward_mag": 0.00011908420788243486, "train/extr_reward_max": 0.00011908420788243486, "train/extr_reward_mean": 0.00011897701299101288, "train/extr_reward_min": 0.00011874537162592845, "train/extr_reward_std": 4.405583576767525e-08, "train/image_loss_mean": 0.2709287634036811, "train/image_loss_std": 0.08393665388446724, "train/model_loss_mean": 0.898311485210663, "train/model_loss_std": 0.3929300308227539, "train/model_opt_grad_norm": 79.2950417654855, "train/model_opt_grad_steps": 2980.0, "train/model_opt_loss": 51.78970436509607, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 57.727832512315274, "train/policy_entropy_mag": 1.9458874751781594, "train/policy_entropy_max": 1.9458874751781594, "train/policy_entropy_mean": 1.9447493324138847, "train/policy_entropy_min": 1.9243105368073938, "train/policy_entropy_std": 0.0008147915006899665, "train/policy_logprob_mag": 2.203041111894429, "train/policy_logprob_max": -1.6793573302001201, "train/policy_logprob_mean": -1.9447353502799725, "train/policy_logprob_min": -2.203041111894429, "train/policy_logprob_std": 0.04777154113565173, "train/policy_randomness_mag": 0.9999884079242575, "train/policy_randomness_max": 0.9999884079242575, "train/policy_randomness_mean": 0.999403515179169, "train/policy_randomness_min": 0.9889000527964437, "train/policy_randomness_std": 0.00041872003371483217, "train/post_ent_mag": 55.69558122005369, "train/post_ent_max": 55.69558122005369, "train/post_ent_mean": 55.65486447564487, "train/post_ent_min": 55.51819026176565, "train/post_ent_std": 0.03390178486264398, "train/prior_ent_mag": 62.222976646987085, "train/prior_ent_max": 62.222976646987085, "train/prior_ent_mean": 61.86524356409834, "train/prior_ent_min": 61.537022200711256, "train/prior_ent_std": 0.1112478271108396, "train/rep_loss_mean": 1.000000145634994, "train/rep_loss_std": 1.2078779959463942e-06, "train/reward_avg": 0.00014440978064633026, "train/reward_loss_mean": 0.002538395414743664, "train/reward_loss_std": 0.06307650410894858, "train/reward_max_data": 0.12863300513164164, "train/reward_max_pred": 0.00011907657379000058, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.000432011239968121, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.756151008605958, "train/reward_pred": 0.00011896335960278664, "train/reward_rate": 0.00021647937192118227, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.02012466825544834, "report/cont_loss_std": 0.30084890127182007, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.570223808288574, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0038168325554579496, "report/cont_pred": 0.9961901903152466, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2577770948410034, "report/image_loss_std": 0.0851627066731453, "report/model_loss_mean": 0.8783109188079834, "report/model_loss_std": 0.31052547693252563, "report/post_ent_mag": 49.3609619140625, "report/post_ent_max": 49.3609619140625, "report/post_ent_mean": 49.324485778808594, "report/post_ent_min": 49.11631774902344, "report/post_ent_std": 0.05404017120599747, "report/prior_ent_mag": 55.7535514831543, "report/prior_ent_max": 55.7535514831543, "report/prior_ent_mean": 54.98238754272461, "report/prior_ent_min": 54.89763641357422, "report/prior_ent_std": 0.14973664283752441, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00040912628173828125, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0001672506332397461, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00040912628173828125, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00016702921129763126, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0038168332539498806, "eval/cont_loss_std": 1.035313061947818e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0038168332539498806, "eval/cont_pred": 0.9961901903152466, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.27493929862976074, "eval/image_loss_std": 0.0824015811085701, "eval/model_loss_mean": 0.8791652917861938, "eval/model_loss_std": 0.0824015811085701, "eval/post_ent_mag": 49.36053466796875, "eval/post_ent_max": 49.36053466796875, "eval/post_ent_mean": 49.3278694152832, "eval/post_ent_min": 49.113197326660156, "eval/post_ent_std": 0.050345782190561295, "eval/prior_ent_mag": 55.7535514831543, "eval/prior_ent_max": 55.7535514831543, "eval/prior_ent_mean": 54.97203063964844, "eval/prior_ent_min": 54.89621353149414, "eval/prior_ent_std": 0.13672195374965668, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00040912628173828125, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0001672506332397461, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00040912628173828125, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0001670285128057003, "eval/reward_rate": 0.0, "replay/size": 65073.0, "replay/inserts": 32512.0, "replay/samples": 32512.0, "replay/insert_wait_avg": 1.3366312257886871e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.633213601713105e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17240.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1347569396339073e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1606259346008, "timer/env.step_count": 4064.0, "timer/env.step_total": 38.896567821502686, "timer/env.step_frac": 0.03889032102734074, "timer/env.step_avg": 0.009571005861590228, "timer/env.step_min": 0.007897138595581055, "timer/env.step_max": 0.03551197052001953, "timer/replay._sample_count": 32512.0, "timer/replay._sample_total": 16.459513187408447, "timer/replay._sample_frac": 0.016456869787318255, "timer/replay._sample_avg": 0.0005062596329788524, "timer/replay._sample_min": 0.00033545494079589844, "timer/replay._sample_max": 0.02860736846923828, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4931.0, "timer/agent.policy_total": 50.75400972366333, "timer/agent.policy_frac": 0.050745858622694935, "timer/agent.policy_avg": 0.010292843180625295, "timer/agent.policy_min": 0.008416414260864258, "timer/agent.policy_max": 0.08148646354675293, "timer/dataset_train_count": 2032.0, "timer/dataset_train_total": 0.2035694122314453, "timer/dataset_train_frac": 0.00020353671895573746, "timer/dataset_train_avg": 0.00010018179735799474, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.000400543212890625, "timer/agent.train_count": 2032.0, "timer/agent.train_total": 897.2017407417297, "timer/agent.train_frac": 0.8970576500183047, "timer/agent.train_avg": 0.4415362897351032, "timer/agent.train_min": 0.4315311908721924, "timer/agent.train_max": 0.8232204914093018, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4646620750427246, "timer/agent.report_frac": 0.0004645874502493245, "timer/agent.report_avg": 0.2323310375213623, "timer/agent.report_min": 0.22258377075195312, "timer/agent.report_max": 0.24207830429077148, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9559155841560688e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 32.5062635718252}
{"step": 65840, "time": 2245.8003404140472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66152, "time": 2254.992333650589, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66416, "time": 2263.240432739258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66584, "time": 2268.072783470154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67232, "time": 2287.8395092487335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67272, "time": 2288.824797153473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67616, "time": 2299.337017059326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67816, "time": 2305.153136253357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68152, "time": 2315.2624378204346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68464, "time": 2325.007134437561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68728, "time": 2332.732634782791, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68896, "time": 2338.0205132961273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69544, "time": 2357.377995491028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69584, "time": 2358.8195044994354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69928, "time": 2368.923952817917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 2377.688739299774, "eval_episode/length": 186.0, "eval_episode/score": 0.41874998807907104, "eval_episode/reward_rate": 0.0053475935828877}
{"step": 70096, "time": 2378.942462205887, "eval_episode/length": 253.0, "eval_episode/score": 0.20937499403953552, "eval_episode/reward_rate": 0.003937007874015748}
{"step": 70096, "time": 2379.5863168239594, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2379.5947058200836, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2379.6042606830597, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2379.612681388855, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2379.6215858459473, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2379.6310319900513, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70128, "time": 2380.5946640968323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70464, "time": 2390.6841204166412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70776, "time": 2399.8724501132965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71040, "time": 2408.12167429924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71168, "time": 2411.975361585617, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 71208, "time": 2412.966451883316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71896, "time": 2433.626716852188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72240, "time": 2444.256777048111, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72440, "time": 2450.055329799652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72776, "time": 2460.1547470092773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73088, "time": 2469.9791901111603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73352, "time": 2477.7309896945953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73480, "time": 2481.6055767536163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73520, "time": 2483.036923646927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74208, "time": 2504.3961732387543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74552, "time": 2514.6152818202972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74752, "time": 2520.8937153816223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75088, "time": 2531.179496049881, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75400, "time": 2540.4186623096466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75664, "time": 2548.6229906082153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75792, "time": 2552.49173784256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75832, "time": 2553.482244491577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76520, "time": 2574.393821954727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76864, "time": 2585.0204515457153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77064, "time": 2590.951297044754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77400, "time": 2601.150177001953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77712, "time": 2610.798582792282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77976, "time": 2618.6035051345825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78104, "time": 2622.477377653122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78144, "time": 2623.91189289093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78832, "time": 2644.723929643631, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79176, "time": 2655.002004146576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79376, "time": 2661.3178668022156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79712, "time": 2671.502135038376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79984, "time": 2679.795201063156, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 80024, "time": 2680.78586769104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 2688.0534868240356, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2688.0618901252747, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2688.0719561576843, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2688.0804691314697, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2688.0886600017548, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2688.097846508026, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2688.1064999103546, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2688.1160378456116, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80416, "time": 2698.286592245102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80456, "time": 2699.303410053253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81144, "time": 2720.2296979427338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81488, "time": 2730.858227491379, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81688, "time": 2736.8066918849945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82024, "time": 2747.445935487747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82296, "time": 2755.7379007339478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82336, "time": 2757.165266275406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82728, "time": 2768.8851087093353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82768, "time": 2770.3179652690887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83456, "time": 2791.1305816173553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83800, "time": 2801.4323008060455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84000, "time": 2807.696367740631, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84336, "time": 2817.9213955402374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84608, "time": 2826.2630734443665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84648, "time": 2827.2577834129333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84792, "time": 2831.628345966339, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 85080, "time": 2840.406482934952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85768, "time": 2861.386703491211, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86112, "time": 2872.034663438797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86312, "time": 2878.4118399620056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86648, "time": 2888.7086424827576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86920, "time": 2896.9723999500275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86960, "time": 2898.4048748016357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87104, "time": 2902.7868599891663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87392, "time": 2911.510133743286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88080, "time": 2932.4895293712616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88424, "time": 2942.697496652603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88624, "time": 2949.087493419647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88960, "time": 2959.2654910087585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89232, "time": 2967.5327384471893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89272, "time": 2968.5221316814423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89416, "time": 2972.8832852840424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89704, "time": 2981.7251381874084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 2998.9963788986206, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 2999.003490924835, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 2999.0101351737976, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 2999.0166730880737, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 2999.02294754982, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 2999.0290970802307, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 2999.035064458847, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 2999.0413024425507, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90392, "time": 3009.334577322006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90736, "time": 3020.003838300705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90936, "time": 3025.84979224205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91272, "time": 3036.1648948192596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91384, "time": 3039.5952022075653, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 91544, "time": 3044.4853801727295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91584, "time": 3045.92369222641, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91728, "time": 3050.286988258362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92704, "time": 3080.0024790763855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93048, "time": 3090.1894204616547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93248, "time": 3096.6036942005157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93584, "time": 3106.769143104553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93696, "time": 3110.155306339264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93856, "time": 3115.0224318504333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93896, "time": 3116.041732311249, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94040, "time": 3120.4133067131042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95016, "time": 3150.207499027252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95360, "time": 3160.9786546230316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95560, "time": 3166.854164123535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95896, "time": 3177.078171491623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96008, "time": 3180.4712414741516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96168, "time": 3185.30450797081, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96208, "time": 3186.845875263214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96352, "time": 3191.1872448921204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97328, "time": 3220.7488713264465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97672, "time": 3230.916417837143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97872, "time": 3237.203766822815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97881, "time": 3238.2209570407867, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9996189835047957, "train/action_min": 0.0, "train/action_std": 2.00032915101193, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 6.086442107795784e-05, "train/actor_opt_grad_steps": 5015.0, "train/actor_opt_loss": -4.863706025765231, "train/adv_mag": 0.0002779838822708271, "train/adv_max": 0.0001960411428077386, "train/adv_mean": 4.3555278996719416e-05, "train/adv_min": -0.00012892947559899623, "train/adv_std": 6.462263012967879e-05, "train/cont_avg": 0.9965530244430693, "train/cont_loss_mean": 0.023044176289055605, "train/cont_loss_std": 0.32019660541428124, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.646130490303039, "train/cont_pos_acc": 0.999999985246375, "train/cont_pos_loss": 0.003596376940045543, "train/cont_pred": 0.9964102733843397, "train/cont_rate": 0.9965530244430693, "train/dyn_loss_mean": 1.0040206448866589, "train/dyn_loss_std": 0.00011192538111590513, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.023896292686499288, "train/extr_critic_critic_opt_grad_steps": 5015.0, "train/extr_critic_critic_opt_loss": 9040.518211440285, "train/extr_critic_mag": 0.027915966392743706, "train/extr_critic_max": 0.027915966392743706, "train/extr_critic_mean": 0.027846730480173436, "train/extr_critic_min": 0.027801387380845477, "train/extr_critic_std": 1.5179086446769363e-05, "train/extr_return_normed_mag": 0.00039953165825935876, "train/extr_return_normed_max": 0.00030005702029655475, "train/extr_return_normed_mean": 0.0001878927193613458, "train/extr_return_normed_min": 6.286447664888779e-05, "train/extr_return_normed_std": 6.0376733129618116e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.02800243633734708, "train/extr_return_raw_max": 0.02800243633734708, "train/extr_return_raw_mean": 0.02789027332374365, "train/extr_return_raw_min": 0.02776524379369941, "train/extr_return_raw_std": 6.03767327694222e-05, "train/extr_reward_mag": 9.059846991359598e-05, "train/extr_reward_max": 9.059846991359598e-05, "train/extr_reward_mean": 9.052808537931149e-05, "train/extr_reward_min": 9.044326177918085e-05, "train/extr_reward_std": 2.7473879548166503e-08, "train/image_loss_mean": 0.26137265939228604, "train/image_loss_std": 0.08510513660857583, "train/model_loss_mean": 0.8890023473465797, "train/model_loss_std": 0.3764717622779974, "train/model_opt_grad_norm": 63.80454947216676, "train/model_opt_grad_steps": 5005.0, "train/model_opt_loss": 209.01983397077805, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 235.53527227722773, "train/policy_entropy_mag": 1.9458964095257296, "train/policy_entropy_max": 1.9458964095257296, "train/policy_entropy_mean": 1.9452182042716752, "train/policy_entropy_min": 1.9296070195660733, "train/policy_entropy_std": 0.000525126130248669, "train/policy_logprob_mag": 2.1612756122456918, "train/policy_logprob_max": -1.720403036858776, "train/policy_logprob_mean": -1.945171638290481, "train/policy_logprob_min": -2.1612756122456918, "train/policy_logprob_std": 0.037128502964088234, "train/policy_randomness_mag": 0.9999929997000364, "train/policy_randomness_max": 0.9999929997000364, "train/policy_randomness_mean": 0.9996444668510173, "train/policy_randomness_min": 0.9916219073947113, "train/policy_randomness_std": 0.0002698614769920679, "train/post_ent_mag": 48.703036922039374, "train/post_ent_max": 48.703036922039374, "train/post_ent_mean": 48.680519368388865, "train/post_ent_min": 48.5436263509316, "train/post_ent_std": 0.03193900633677103, "train/prior_ent_mag": 51.476938077718906, "train/prior_ent_max": 51.476938077718906, "train/prior_ent_mean": 51.32716075028523, "train/prior_ent_min": 51.073324146837294, "train/prior_ent_std": 0.06819423384005481, "train/rep_loss_mean": 1.0040206448866589, "train/rep_loss_std": 0.00011192538111590513, "train/reward_avg": 0.00011031651211122171, "train/reward_loss_mean": 0.0021731049758336035, "train/reward_loss_std": 0.0593680986575962, "train/reward_max_data": 0.10775061877499713, "train/reward_max_pred": 9.073833427806891e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00023514556326490762, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.049920378504572, "train/reward_pred": 9.064360102177551e-05, "train/reward_rate": 0.00019337871287128714, "train_stats/mean_log_entropy": 1.9384366837995393, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.02003992162644863, "report/cont_loss_std": 0.3080270290374756, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.702561855316162, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0033429861068725586, "report/cont_pred": 0.9966623783111572, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.272056519985199, "report/image_loss_std": 0.09038618206977844, "report/model_loss_mean": 0.8923115134239197, "report/model_loss_std": 0.32163694500923157, "report/post_ent_mag": 48.44038391113281, "report/post_ent_max": 48.44038391113281, "report/post_ent_mean": 48.42108154296875, "report/post_ent_min": 48.29179382324219, "report/post_ent_std": 0.0280874315649271, "report/prior_ent_mag": 50.706787109375, "report/prior_ent_max": 50.706787109375, "report/prior_ent_mean": 50.68024826049805, "report/prior_ent_min": 50.3961181640625, "report/prior_ent_std": 0.04886246845126152, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00021505355834960938, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 8.535385131835938e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00021505355834960938, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 8.535373490303755e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0033429863397032022, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0033429863397032022, "eval/cont_pred": 0.9966623783111572, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.27165478467941284, "eval/image_loss_std": 0.08589232712984085, "eval/model_loss_mean": 0.8752128481864929, "eval/model_loss_std": 0.08589232712984085, "eval/post_ent_mag": 48.442222595214844, "eval/post_ent_max": 48.442222595214844, "eval/post_ent_mean": 48.422630310058594, "eval/post_ent_min": 48.288909912109375, "eval/post_ent_std": 0.02615978568792343, "eval/prior_ent_mag": 50.708457946777344, "eval/prior_ent_max": 50.708457946777344, "eval/prior_ent_mean": 50.68272399902344, "eval/prior_ent_min": 50.3961181640625, "eval/prior_ent_std": 0.04570402950048447, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00021505355834960938, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 8.535385131835938e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00021505355834960938, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 8.535373490303755e-05, "eval/reward_rate": 0.0, "replay/size": 97377.0, "replay/inserts": 32304.0, "replay/samples": 32304.0, "replay/insert_wait_avg": 1.348307842426574e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.496909285607227e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24176.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1749402324496119e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.331116437912, "timer/env.step_count": 4038.0, "timer/env.step_total": 39.26603317260742, "timer/env.step_frac": 0.03925303584720047, "timer/env.step_avg": 0.00972412906701521, "timer/env.step_min": 0.007850408554077148, "timer/env.step_max": 0.05502915382385254, "timer/replay._sample_count": 32304.0, "timer/replay._sample_total": 16.901792287826538, "timer/replay._sample_frac": 0.016896197679036797, "timer/replay._sample_avg": 0.0005232105091575823, "timer/replay._sample_min": 0.00037789344787597656, "timer/replay._sample_max": 0.011426687240600586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4905.0, "timer/agent.policy_total": 51.583231925964355, "timer/agent.policy_frac": 0.05156615752356834, "timer/agent.policy_avg": 0.010516459108249613, "timer/agent.policy_min": 0.008887290954589844, "timer/agent.policy_max": 0.08518505096435547, "timer/dataset_train_count": 2019.0, "timer/dataset_train_total": 0.2073960304260254, "timer/dataset_train_frac": 0.0002073273809221728, "timer/dataset_train_avg": 0.00010272215474295463, "timer/dataset_train_min": 8.845329284667969e-05, "timer/dataset_train_max": 0.00026535987854003906, "timer/agent.train_count": 2019.0, "timer/agent.train_total": 895.8338134288788, "timer/agent.train_frac": 0.8955372863126175, "timer/agent.train_avg": 0.4437017401827037, "timer/agent.train_min": 0.43384575843811035, "timer/agent.train_max": 0.9626972675323486, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4734950065612793, "timer/agent.report_frac": 0.00047333827647724476, "timer/agent.report_avg": 0.23674750328063965, "timer/agent.report_min": 0.22867178916931152, "timer/agent.report_max": 0.24482321739196777, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.098415591986323e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 32.29279858331611}
{"step": 98208, "time": 3248.211840391159, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98320, "time": 3252.06556892395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98480, "time": 3256.917316675186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98520, "time": 3257.9274513721466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98664, "time": 3262.2874290943146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99640, "time": 3291.9850857257843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99984, "time": 3302.671677350998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 3310.00549864769, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3310.012037038803, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3310.0185742378235, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3310.025463819504, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3310.0337982177734, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3310.04217505455, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3310.048926115036, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3310.0570120811462, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100184, "time": 3313.9531841278076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100520, "time": 3324.1111073493958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100632, "time": 3327.506980895996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100792, "time": 3332.3259925842285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100832, "time": 3333.756223678589, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100976, "time": 3338.223727941513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101448, "time": 3352.309720993042, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 101952, "time": 3368.1023712158203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102296, "time": 3378.4589953422546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102496, "time": 3384.7589151859283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102832, "time": 3394.9313695430756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102944, "time": 3398.3821794986725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103016, "time": 3400.3488743305206, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 103104, "time": 3403.2133691310883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103336, "time": 3409.9805257320404, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 103760, "time": 3422.9930596351624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103768, "time": 3423.020589828491, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 104264, "time": 3438.0350291728973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104808, "time": 3454.5709800720215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105144, "time": 3464.8201973438263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105256, "time": 3468.210434436798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105328, "time": 3470.606998682022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105416, "time": 3473.0787303447723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106000, "time": 3491.0701444149017, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 106072, "time": 3493.039073705673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106080, "time": 3493.508799314499, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106576, "time": 3509.0050196647644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107120, "time": 3525.650884628296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107456, "time": 3535.806342124939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107568, "time": 3539.191274881363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107728, "time": 3544.012202501297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108312, "time": 3561.4881405830383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108384, "time": 3563.87521982193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108392, "time": 3563.904485464096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108888, "time": 3578.972715139389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109432, "time": 3595.4408223629, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109768, "time": 3605.669922351837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109880, "time": 3609.0720365047455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 3618.9833478927612, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3618.9905767440796, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3618.9994599819183, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3619.0073647499084, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3619.017053604126, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3619.0253932476044, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3619.035389184952, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3619.0448067188263, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110040, "time": 3619.0758678913116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110376, "time": 3629.131423473358, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 110624, "time": 3636.871612071991, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110696, "time": 3638.8436398506165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110704, "time": 3639.3092155456543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111200, "time": 3654.2374260425568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111744, "time": 3670.7996735572815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112080, "time": 3681.033176422119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112192, "time": 3684.43533039093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112688, "time": 3699.5603013038635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112936, "time": 3706.8632905483246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113008, "time": 3709.260591506958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113016, "time": 3709.2887258529663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113072, "time": 3711.212254047394, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 113512, "time": 3724.2772133350372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114056, "time": 3740.9215035438538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114504, "time": 3754.522432565689, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114888, "time": 3766.8946475982666, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 115000, "time": 3770.304118156433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115248, "time": 3778.0825157165527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115320, "time": 3780.061502456665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115328, "time": 3780.5308644771576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115384, "time": 3782.004796743393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116368, "time": 3811.9897513389587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116816, "time": 3825.587725162506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117200, "time": 3837.204785823822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117312, "time": 3840.6095402240753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117560, "time": 3848.0199027061462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117632, "time": 3850.4127814769745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117640, "time": 3850.44229722023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117696, "time": 3852.3542709350586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118680, "time": 3881.980401277542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119128, "time": 3895.5214037895203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119384, "time": 3903.2953786849976, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 119512, "time": 3907.2785053253174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119624, "time": 3910.681818962097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119872, "time": 3918.4590549468994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119952, "time": 3920.9119436740875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120008, "time": 3922.4059269428253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 3928.0535082817078, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3928.0600879192352, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3928.0674591064453, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3928.0743129253387, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3928.0826346874237, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3928.090375185013, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3928.098459005356, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3928.105931043625, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120992, "time": 3957.4593715667725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121440, "time": 3971.0349922180176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121696, "time": 3978.771836042404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121824, "time": 3982.677130460739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121936, "time": 3986.062623977661, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122184, "time": 3993.343766450882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122264, "time": 3995.919934272766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122320, "time": 3997.83447432518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123304, "time": 4027.8661534786224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123752, "time": 4041.3613002300262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124008, "time": 4049.1065349578857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124136, "time": 4052.978286743164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124248, "time": 4056.4193329811096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124496, "time": 4064.0820004940033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124576, "time": 4066.4700934886932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124632, "time": 4067.9505767822266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125616, "time": 4097.826236963272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126064, "time": 4111.501190662384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126320, "time": 4119.245181560516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126448, "time": 4123.1091096401215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126560, "time": 4126.486268520355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126808, "time": 4133.7271547317505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126888, "time": 4136.17658829689, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126944, "time": 4138.101365566254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127928, "time": 4167.549971580505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127960, "time": 4168.54129576683, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 128376, "time": 4181.226491928101, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128632, "time": 4189.003077507019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128760, "time": 4192.889659404755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129120, "time": 4203.9835205078125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129200, "time": 4206.493367195129, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129256, "time": 4207.98863196373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 4234.185761213303, "eval_episode/length": 167.0, "eval_episode/score": 0.4781250059604645, "eval_episode/reward_rate": 0.005952380952380952}
{"step": 130000, "time": 4234.533363819122, "eval_episode/length": 186.0, "eval_episode/score": 0.41874998807907104, "eval_episode/reward_rate": 0.0053475935828877}
{"step": 130000, "time": 4236.475607872009, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4236.484861373901, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4236.494231939316, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4236.504113197327, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4236.51287984848, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4236.520807504654, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130041, "time": 4238.5011875629425, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.001757569574005, "train/action_min": 0.0, "train/action_std": 2.0001051402210597, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 6.273753366819543e-05, "train/actor_opt_grad_steps": 7030.0, "train/actor_opt_loss": -4.092084166237075, "train/adv_mag": 0.00029122302151141473, "train/adv_max": 0.0002402591227150675, "train/adv_mean": 8.393581197391336e-05, "train/adv_min": -9.635531005278155e-05, "train/adv_std": 6.99125930736389e-05, "train/cont_avg": 0.9964921486318408, "train/cont_loss_mean": 0.02339322324981218, "train/cont_loss_std": 0.32245779576936373, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.658101240793864, "train/cont_pos_acc": 0.9999999854695144, "train/cont_pos_loss": 0.003531707611759726, "train/cont_pred": 0.9964746583753558, "train/cont_rate": 0.9964921486318408, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.017047182140195398, "train/extr_critic_critic_opt_grad_steps": 7030.0, "train/extr_critic_critic_opt_loss": 9344.2090329602, "train/extr_critic_mag": 0.02963001929705416, "train/extr_critic_max": 0.02963001929705416, "train/extr_critic_mean": 0.029561153626931246, "train/extr_critic_min": 0.029515447308175007, "train/extr_critic_std": 1.7136084936805202e-05, "train/extr_return_normed_mag": 0.00045558140237829576, "train/extr_return_normed_max": 0.000398939503217811, "train/extr_return_normed_mean": 0.00028053248721630214, "train/extr_return_normed_min": 0.00014601917520387848, "train/extr_return_normed_std": 6.498027561694054e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.029763498422295892, "train/extr_return_raw_max": 0.029763498422295892, "train/extr_return_raw_mean": 0.029645092979963147, "train/extr_return_raw_min": 0.02951057809428196, "train/extr_return_raw_std": 6.498027574222231e-05, "train/extr_reward_mag": 0.00010211194925640353, "train/extr_reward_max": 0.00010211194925640353, "train/extr_reward_mean": 0.00010206513827902945, "train/extr_reward_min": 0.00010197672677870414, "train/extr_reward_std": 2.6368949377253923e-08, "train/image_loss_mean": 0.256649311798722, "train/image_loss_std": 0.08323178584895917, "train/model_loss_mean": 0.8821137224263813, "train/model_loss_std": 0.37320680078582386, "train/model_opt_grad_norm": 56.378238099131416, "train/model_opt_grad_steps": 7020.0, "train/model_opt_loss": 841.6124641076842, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 954.6019900497513, "train/policy_entropy_mag": 1.9458989367556216, "train/policy_entropy_max": 1.9458989367556216, "train/policy_entropy_mean": 1.9453516083570261, "train/policy_entropy_min": 1.935986763209253, "train/policy_entropy_std": 0.0003876585877658012, "train/policy_logprob_mag": 2.1242373084547506, "train/policy_logprob_max": -1.7648208242150683, "train/policy_logprob_mean": -1.9453584400575552, "train/policy_logprob_min": -2.1242373084547506, "train/policy_logprob_std": 0.03342351369300292, "train/policy_randomness_mag": 0.999994299305019, "train/policy_randomness_max": 0.999994299305019, "train/policy_randomness_mean": 0.9997130193520541, "train/policy_randomness_min": 0.9949004469226249, "train/policy_randomness_std": 0.00019921712420674606, "train/post_ent_mag": 48.27189742510591, "train/post_ent_max": 48.27189742510591, "train/post_ent_mean": 48.25128574276445, "train/post_ent_min": 48.10458708046681, "train/post_ent_std": 0.03144784253183289, "train/prior_ent_mag": 50.7706927778709, "train/prior_ent_max": 50.7706927778709, "train/prior_ent_mean": 50.742308184875185, "train/prior_ent_min": 50.45388425760601, "train/prior_ent_std": 0.05048677768206122, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00010816280016807645, "train/reward_loss_mean": 0.0020711640595685488, "train/reward_loss_std": 0.053353561298469535, "train/reward_max_data": 0.1021455233518164, "train/reward_max_pred": 0.00010212381087725435, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00023997937582794632, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.676380171920314, "train/reward_pred": 0.00010206831667794666, "train/reward_rate": 0.000189482276119403, "train_stats/mean_log_entropy": 1.9374224276378238, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02558591589331627, "report/cont_loss_std": 0.35306814312934875, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.663632392883301, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003475925652310252, "report/cont_pred": 0.996530294418335, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.26672059297561646, "report/image_loss_std": 0.08214071393013, "report/model_loss_mean": 0.89252769947052, "report/model_loss_std": 0.36393383145332336, "report/post_ent_mag": 48.46830368041992, "report/post_ent_max": 48.46830368041992, "report/post_ent_mean": 48.446266174316406, "report/post_ent_min": 48.29077911376953, "report/post_ent_std": 0.034344904124736786, "report/prior_ent_mag": 50.833656311035156, "report/prior_ent_max": 50.833656311035156, "report/prior_ent_mean": 50.796470642089844, "report/prior_ent_min": 50.49687194824219, "report/prior_ent_std": 0.0540667288005352, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00022125244140625, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.00010609626770019531, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00022125244140625, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00010609626770019531, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003475925885140896, "eval/cont_loss_std": 9.313225746154785e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003475925885140896, "eval/cont_pred": 0.996530294418335, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.25506675243377686, "eval/image_loss_std": 0.07378754019737244, "eval/model_loss_mean": 0.8587639331817627, "eval/model_loss_std": 0.07378754019737244, "eval/post_ent_mag": 48.46831512451172, "eval/post_ent_max": 48.46831512451172, "eval/post_ent_mean": 48.449005126953125, "eval/post_ent_min": 48.28840255737305, "eval/post_ent_std": 0.03128277510404587, "eval/prior_ent_mag": 50.82752990722656, "eval/prior_ent_max": 50.82752990722656, "eval/prior_ent_mean": 50.80009078979492, "eval/prior_ent_min": 50.49687194824219, "eval/prior_ent_std": 0.048991356045007706, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00022125244140625, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00010609626770019531, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00022125244140625, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00010609626770019531, "eval/reward_rate": 0.0, "replay/size": 129537.0, "replay/inserts": 32160.0, "replay/samples": 32160.0, "replay/insert_wait_avg": 1.3094191527485255e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.85306021941835e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 33424.0, "eval_replay/inserts": 9248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1678076120396385e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.265645980835, "timer/env.step_count": 4020.0, "timer/env.step_total": 38.176968812942505, "timer/env.step_frac": 0.038166829947965615, "timer/env.step_avg": 0.009496758411179728, "timer/env.step_min": 0.007701396942138672, "timer/env.step_max": 0.03426933288574219, "timer/replay._sample_count": 32160.0, "timer/replay._sample_total": 16.84553837776184, "timer/replay._sample_frac": 0.016841064616633452, "timer/replay._sample_avg": 0.0005238040540348831, "timer/replay._sample_min": 0.0003807544708251953, "timer/replay._sample_max": 0.036432743072509766, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5176.0, "timer/agent.policy_total": 53.809914112091064, "timer/agent.policy_frac": 0.05379562352091622, "timer/agent.policy_avg": 0.010396042139121148, "timer/agent.policy_min": 0.008892536163330078, "timer/agent.policy_max": 0.08969736099243164, "timer/dataset_train_count": 2010.0, "timer/dataset_train_total": 0.19797849655151367, "timer/dataset_train_frac": 0.0001979259183268071, "timer/dataset_train_avg": 9.849676445348939e-05, "timer/dataset_train_min": 8.58306884765625e-05, "timer/dataset_train_max": 0.00033164024353027344, "timer/agent.train_count": 2010.0, "timer/agent.train_total": 892.3301072120667, "timer/agent.train_frac": 0.8920931262585455, "timer/agent.train_avg": 0.44394532697117745, "timer/agent.train_min": 0.4327075481414795, "timer/agent.train_max": 0.6864686012268066, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4618103504180908, "timer/agent.report_frac": 0.00046168770493487394, "timer/agent.report_avg": 0.2309051752090454, "timer/agent.report_min": 0.2207479476928711, "timer/agent.report_max": 0.24106240272521973, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.1701249710934655e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 32.150928292667416}
{"step": 130240, "time": 4244.502162694931, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130272, "time": 4245.468502998352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130688, "time": 4258.014634609222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130944, "time": 4265.8003013134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131072, "time": 4269.798126220703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131432, "time": 4280.816965103149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131512, "time": 4283.261122703552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131568, "time": 4285.183195352554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132552, "time": 4314.64763879776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132584, "time": 4315.613118171692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133000, "time": 4328.260318994522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133104, "time": 4331.625658035278, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 133384, "time": 4339.856470823288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133744, "time": 4350.91255402565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133824, "time": 4353.313684225082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133880, "time": 4354.7965342998505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134864, "time": 4384.84520983696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134896, "time": 4385.966998338699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135312, "time": 4398.507179021835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135416, "time": 4401.405853033066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135696, "time": 4410.067697525024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136056, "time": 4420.773909807205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136136, "time": 4423.202397823334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136192, "time": 4425.097534894943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137176, "time": 4454.581524610519, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137208, "time": 4455.55322933197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137624, "time": 4468.060225725174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137728, "time": 4471.420187950134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138008, "time": 4479.737200975418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138368, "time": 4490.805300474167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138448, "time": 4493.213463783264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138504, "time": 4494.67489361763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139488, "time": 4525.173156738281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139520, "time": 4526.136812448502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139936, "time": 4538.74972653389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140040, "time": 4541.666940450668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 4545.243305206299, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 140088, "time": 4548.883322715759, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4548.891916513443, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4548.900604248047, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4548.909248113632, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4548.916813373566, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4548.925968647003, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4548.93616437912, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140320, "time": 4556.1537075042725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140680, "time": 4566.856986999512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140760, "time": 4569.29129242897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140816, "time": 4571.197791814804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141800, "time": 4600.681685686111, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141832, "time": 4601.645103216171, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142248, "time": 4614.167456626892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142328, "time": 4616.58132982254, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 142352, "time": 4617.547808170319, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142632, "time": 4625.845680713654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142992, "time": 4636.91472864151, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143072, "time": 4639.313080072403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143128, "time": 4640.787899494171, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144112, "time": 4670.802451848984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144560, "time": 4684.277407169342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144640, "time": 4686.817665576935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144664, "time": 4687.324372053146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144944, "time": 4695.978493690491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145304, "time": 4706.621003866196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145384, "time": 4709.033361911774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145440, "time": 4710.963157176971, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146424, "time": 4740.525261878967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146872, "time": 4754.158585071564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146952, "time": 4756.567802429199, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146976, "time": 4757.519272565842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147256, "time": 4765.73544549942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147616, "time": 4777.330965280533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147696, "time": 4779.759562492371, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147752, "time": 4781.22750210762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148736, "time": 4811.142872810364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149184, "time": 4824.607568740845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149264, "time": 4827.027863025665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149288, "time": 4827.533146619797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149568, "time": 4836.212671756744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149928, "time": 4846.8486223220825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150008, "time": 4849.305411815643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150064, "time": 4851.238009691238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 4856.55423951149, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4856.561618566513, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4856.570574522018, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4856.580453872681, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4856.589357852936, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4856.595828533173, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4856.603152751923, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4856.611330270767, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 151048, "time": 4886.063128948212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151496, "time": 4899.696040153503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151576, "time": 4902.094175815582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151600, "time": 4903.041341543198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151880, "time": 4911.285105228424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152240, "time": 4922.37467956543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152320, "time": 4924.802115917206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152376, "time": 4926.373906135559, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153360, "time": 4956.458467721939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153808, "time": 4969.93172287941, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153888, "time": 4972.358350753784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153912, "time": 4972.8672506809235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154192, "time": 4981.537658214569, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154552, "time": 4992.2003309726715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154632, "time": 4994.60550570488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154688, "time": 4996.525093793869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155672, "time": 5026.533412218094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156080, "time": 5039.067792415619, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 156120, "time": 5040.073164701462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156200, "time": 5042.481395483017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156224, "time": 5043.432890415192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156504, "time": 5051.7117302417755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156944, "time": 5065.175977230072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157000, "time": 5066.643877744675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157984, "time": 5096.629438400269, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158392, "time": 5108.814194440842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158432, "time": 5110.259986400604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158512, "time": 5112.677490711212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158536, "time": 5113.1815440654755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158816, "time": 5121.814604282379, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159256, "time": 5134.81103181839, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159312, "time": 5136.857627153397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 5162.9300973415375, "eval_episode/length": 211.0, "eval_episode/score": 0.34062498807907104, "eval_episode/reward_rate": 0.0047169811320754715}
{"step": 160056, "time": 5164.303786277771, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5164.310430765152, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5164.3176691532135, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5164.326817274094, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5164.3340945243835, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5164.3429226875305, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5164.3497977256775, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160296, "time": 5171.728250980377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160704, "time": 5184.239620923996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160744, "time": 5185.229821681976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160824, "time": 5187.67239522934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160848, "time": 5188.618049144745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161128, "time": 5196.977581977844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161568, "time": 5210.497533559799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161624, "time": 5211.976133346558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162473, "time": 5238.727960824966, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9975165943107984, "train/action_min": 0.0, "train/action_std": 2.000547160606573, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 8.019093507701285e-05, "train/actor_opt_grad_steps": 9045.0, "train/actor_opt_loss": -6.782433636910697, "train/adv_mag": 0.0003080666341846532, "train/adv_max": 0.00014312494324870628, "train/adv_mean": -5.706184517951235e-05, "train/adv_min": -0.0002546265334038451, "train/adv_std": 7.040176467286289e-05, "train/cont_avg": 0.9964998452970297, "train/cont_loss_mean": 0.023316429750440588, "train/cont_loss_std": 0.322657644238074, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.647632281780243, "train/cont_pos_acc": 0.9999999890823176, "train/cont_pos_loss": 0.0035636825129703275, "train/cont_pred": 0.9964427838821223, "train/cont_rate": 0.9964998452970297, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.013322882746152653, "train/extr_critic_critic_opt_grad_steps": 9045.0, "train/extr_critic_critic_opt_loss": 9314.256797261758, "train/extr_critic_mag": 0.02947542927052715, "train/extr_critic_max": 0.02947542927052715, "train/extr_critic_mean": 0.029390513841616044, "train/extr_critic_min": 0.02932143270379246, "train/extr_critic_std": 2.8338219123898482e-05, "train/extr_return_normed_mag": 0.0003497504749067939, "train/extr_return_normed_max": 0.00012421024280904544, "train/extr_return_normed_mean": -2.033222159243991e-05, "train/extr_return_normed_min": -0.00014952361805014092, "train/extr_return_normed_std": 6.2180939996306e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0294779917999807, "train/extr_return_raw_max": 0.0294779917999807, "train/extr_return_raw_mean": 0.029333451052777248, "train/extr_return_raw_min": 0.02920425793912151, "train/extr_return_raw_std": 6.21809401426356e-05, "train/extr_reward_mag": 7.931253697612499e-05, "train/extr_reward_max": 7.931253697612499e-05, "train/extr_reward_mean": 7.92753916996817e-05, "train/extr_reward_min": 7.924644073637405e-05, "train/extr_reward_std": 1.5917314892436713e-08, "train/image_loss_mean": 0.2486889603556973, "train/image_loss_std": 0.08433533002539437, "train/model_loss_mean": 0.8738929514247592, "train/model_loss_std": 0.37373809553313964, "train/model_opt_grad_norm": 48.66341556888996, "train/model_opt_grad_steps": 9034.554455445545, "train/model_opt_loss": 2334.8124299002166, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2673.267326732673, "train/policy_entropy_mag": 1.9458847394083987, "train/policy_entropy_max": 1.9458847394083987, "train/policy_entropy_mean": 1.9445729857624168, "train/policy_entropy_min": 1.9312149351186092, "train/policy_entropy_std": 0.000944006050871178, "train/policy_logprob_mag": 2.201245620699212, "train/policy_logprob_max": -1.707245363457368, "train/policy_logprob_mean": -1.9445541678088727, "train/policy_logprob_min": -2.201245620699212, "train/policy_logprob_std": 0.049251780153648686, "train/policy_randomness_mag": 0.999986999105699, "train/policy_randomness_max": 0.999986999105699, "train/policy_randomness_mean": 0.9993128897530017, "train/policy_randomness_min": 0.992448211601465, "train/policy_randomness_std": 0.0004851231630286432, "train/post_ent_mag": 57.92085726898495, "train/post_ent_max": 57.92085726898495, "train/post_ent_mean": 57.51192502692194, "train/post_ent_min": 57.09146205033406, "train/post_ent_std": 0.17484424585974453, "train/prior_ent_mag": 56.13486327747307, "train/prior_ent_max": 56.13486327747307, "train/prior_ent_mean": 55.72870685086392, "train/prior_ent_min": 55.45356089525884, "train/prior_ent_std": 0.12637680477582583, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 8.99664247650561e-05, "train/reward_loss_mean": 0.0018875468199574712, "train/reward_loss_std": 0.05183756141925165, "train/reward_max_data": 0.08726794545603271, "train/reward_max_pred": 7.957102048515093e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00018386247342782057, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.135545551776886, "train/reward_pred": 7.953431623259393e-05, "train/reward_rate": 0.00016920637376237623, "train_stats/mean_log_entropy": 1.9376787147690764, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.008685450069606304, "report/cont_loss_std": 0.18118584156036377, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.803802013397217, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0030206230003386736, "report/cont_pred": 0.9969837665557861, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.21880991756916046, "report/image_loss_std": 0.08662272244691849, "report/model_loss_mean": 0.8276527523994446, "report/model_loss_std": 0.20618511736392975, "report/post_ent_mag": 67.675048828125, "report/post_ent_max": 67.675048828125, "report/post_ent_mean": 66.05488586425781, "report/post_ent_min": 65.41766357421875, "report/post_ent_std": 0.6384634375572205, "report/prior_ent_mag": 63.740501403808594, "report/prior_ent_max": 63.740501403808594, "report/prior_ent_mean": 62.56915283203125, "report/prior_ent_min": 62.17641067504883, "report/prior_ent_std": 0.3729745149612427, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00015735626220703125, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 7.259845733642578e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00015735626220703125, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.259845733642578e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0030206232331693172, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0030206232331693172, "eval/cont_pred": 0.9969837665557861, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2401469647884369, "eval/image_loss_std": 0.08482293784618378, "eval/model_loss_mean": 0.8433250188827515, "eval/model_loss_std": 0.08482293784618378, "eval/post_ent_mag": 67.65147399902344, "eval/post_ent_max": 67.65147399902344, "eval/post_ent_mean": 66.00099182128906, "eval/post_ent_min": 65.4094009399414, "eval/post_ent_std": 0.5806718468666077, "eval/prior_ent_mag": 63.532379150390625, "eval/prior_ent_max": 63.532379150390625, "eval/prior_ent_mean": 62.542118072509766, "eval/prior_ent_min": 62.16051483154297, "eval/prior_ent_std": 0.33315810561180115, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00015735626220703125, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 7.259845733642578e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00015735626220703125, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.259845733642578e-05, "eval/reward_rate": 0.0, "replay/size": 161969.0, "replay/inserts": 32432.0, "replay/samples": 32432.0, "replay/insert_wait_avg": 1.2386709701620891e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.530124514692219e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 40360.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1082889024499103e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2034945487976, "timer/env.step_count": 4054.0, "timer/env.step_total": 37.22076869010925, "timer/env.step_frac": 0.03721319600757837, "timer/env.step_avg": 0.009181245360165085, "timer/env.step_min": 0.007466793060302734, "timer/env.step_max": 0.04050946235656738, "timer/replay._sample_count": 32432.0, "timer/replay._sample_total": 17.076409101486206, "timer/replay._sample_frac": 0.017072934852311785, "timer/replay._sample_avg": 0.0005265296343576161, "timer/replay._sample_min": 0.00037670135498046875, "timer/replay._sample_max": 0.02864241600036621, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4921.0, "timer/agent.policy_total": 50.57915663719177, "timer/agent.policy_frac": 0.05056886614859166, "timer/agent.policy_avg": 0.010278227319079816, "timer/agent.policy_min": 0.008571386337280273, "timer/agent.policy_max": 0.6431827545166016, "timer/dataset_train_count": 2027.0, "timer/dataset_train_total": 0.20319175720214844, "timer/dataset_train_frac": 0.00020315041719966235, "timer/dataset_train_avg": 0.00010024260345443928, "timer/dataset_train_min": 8.606910705566406e-05, "timer/dataset_train_max": 0.0010793209075927734, "timer/agent.train_count": 2027.0, "timer/agent.train_total": 899.1498730182648, "timer/agent.train_frac": 0.8989669381468026, "timer/agent.train_avg": 0.4435865185092574, "timer/agent.train_min": 0.43395328521728516, "timer/agent.train_max": 0.6762032508850098, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4850809574127197, "timer/agent.report_frac": 0.0004849822661652916, "timer/agent.report_avg": 0.24254047870635986, "timer/agent.report_min": 0.23503541946411133, "timer/agent.report_max": 0.2500455379486084, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.7206878662109375e-05, "timer/dataset_eval_frac": 4.719727427407649e-08, "timer/dataset_eval_avg": 4.7206878662109375e-05, "timer/dataset_eval_min": 4.7206878662109375e-05, "timer/dataset_eval_max": 4.7206878662109375e-05, "fps": 32.42475729498517}
{"step": 162608, "time": 5242.8015768527985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163016, "time": 5254.932504892349, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163056, "time": 5256.470983028412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163136, "time": 5258.910134553909, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163160, "time": 5259.440819263458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163440, "time": 5268.111469984055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163880, "time": 5281.782152414322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163936, "time": 5283.696896076202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164920, "time": 5313.266850709915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165328, "time": 5325.956584215164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165368, "time": 5326.952787637711, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165448, "time": 5329.384828567505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165472, "time": 5330.334841012955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165496, "time": 5330.844801425934, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 165752, "time": 5338.599011182785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166192, "time": 5352.1548001766205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166248, "time": 5353.625939130783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167232, "time": 5383.647390842438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167640, "time": 5395.722185134888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167760, "time": 5399.549669504166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167784, "time": 5400.061408519745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167808, "time": 5401.026847362518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168064, "time": 5408.795527458191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168504, "time": 5421.8503704071045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168560, "time": 5423.760307312012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169544, "time": 5453.263657331467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169952, "time": 5465.881417274475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 5474.046843528748, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5474.056047916412, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5474.066891908646, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5474.0753762722015, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5474.0831298828125, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5474.092210292816, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5474.1025993824005, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5474.113974809647, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170072, "time": 5475.082388877869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170096, "time": 5476.024143457413, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170120, "time": 5476.530963897705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170376, "time": 5484.247376203537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170816, "time": 5497.781359434128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170872, "time": 5499.270407676697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171856, "time": 5529.224483251572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172264, "time": 5541.740114688873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172384, "time": 5545.575502872467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172408, "time": 5546.083823680878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172432, "time": 5547.058179140091, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172688, "time": 5554.786914348602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173128, "time": 5567.973752975464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173184, "time": 5569.893399715424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174168, "time": 5599.441349983215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174576, "time": 5611.962295532227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174696, "time": 5615.370163202286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174720, "time": 5616.379205226898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174744, "time": 5616.885596036911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175000, "time": 5624.625685214996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175360, "time": 5635.704675197601, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 175440, "time": 5638.117637395859, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176480, "time": 5669.474863529205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176888, "time": 5681.65770149231, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177008, "time": 5685.500594615936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177032, "time": 5686.00625371933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177056, "time": 5686.953279972076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177312, "time": 5694.689337015152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177672, "time": 5705.3253083229065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177752, "time": 5707.872920036316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178792, "time": 5739.313420534134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179200, "time": 5751.827605724335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179320, "time": 5755.273339986801, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179344, "time": 5756.217355012894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179368, "time": 5756.725810289383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179624, "time": 5764.414350986481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179984, "time": 5775.563265800476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 5781.690771818161, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5781.6969294548035, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5781.702624320984, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5781.70906662941, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5781.714997768402, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5781.721801280975, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5781.727192401886, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5781.733053922653, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180064, "time": 5783.161265850067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181104, "time": 5815.040202856064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181512, "time": 5827.150737762451, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181632, "time": 5830.998421907425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181656, "time": 5831.509595155716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181680, "time": 5832.4524874687195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181936, "time": 5840.175633192062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182296, "time": 5850.815400123596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182376, "time": 5853.23860001564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183416, "time": 5884.676753759384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183824, "time": 5897.239021539688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183944, "time": 5900.616965293884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183968, "time": 5901.586382627487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183992, "time": 5902.094026565552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184144, "time": 5906.888305187225, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 184248, "time": 5909.794323205948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184608, "time": 5920.9374215602875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184688, "time": 5923.351169347763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185728, "time": 5954.860349416733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186136, "time": 5966.939979314804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186256, "time": 5970.798901557922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186280, "time": 5971.30894780159, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186456, "time": 5976.658461332321, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186560, "time": 5980.010988473892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186920, "time": 5990.63574552536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187000, "time": 5993.069599151611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188040, "time": 6024.492277622223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188448, "time": 6037.5749452114105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188568, "time": 6040.952046632767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188592, "time": 6041.913833618164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188768, "time": 6047.209979534149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188872, "time": 6050.103954553604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189232, "time": 6061.192458152771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189312, "time": 6063.607350587845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 6085.918445110321, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 190008, "time": 6089.543806552887, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6089.552045345306, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6089.561104059219, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6089.568427801132, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6089.576096057892, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6089.5852246284485, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6089.594877004623, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190352, "time": 6100.294242143631, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190760, "time": 6112.351898431778, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 190760, "time": 6112.359754562378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190880, "time": 6116.213158130646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190904, "time": 6116.72102189064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191080, "time": 6122.026118278503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191184, "time": 6125.38908457756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191544, "time": 6136.064529180527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192664, "time": 6169.949491739273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193072, "time": 6182.476458787918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193072, "time": 6182.486169338226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193192, "time": 6185.942206144333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193216, "time": 6186.8864278793335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193392, "time": 6192.212807178497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193496, "time": 6195.11390709877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193856, "time": 6206.158845663071, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194921, "time": 6239.139664649963, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0014347771705663, "train/action_min": 0.0, "train/action_std": 2.002227490758661, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00015871960288323713, "train/actor_opt_grad_steps": 11070.0, "train/actor_opt_loss": -6.298824872367377, "train/adv_mag": 0.0004580281674861908, "train/adv_max": 0.0003448864399212335, "train/adv_mean": -3.350621767706937e-05, "train/adv_min": -0.000399444371535273, "train/adv_std": 9.917451533344987e-05, "train/cont_avg": 0.9964112530788177, "train/cont_loss_mean": 0.02381691970665173, "train/cont_loss_std": 0.3279192406094184, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.66145400762558, "train/cont_pos_acc": 0.9999999823828636, "train/cont_pos_loss": 0.0035117000669442813, "train/cont_pred": 0.9964945753806917, "train/cont_rate": 0.9964112530788177, "train/dyn_loss_mean": 1.0038273023267097, "train/dyn_loss_std": 0.0001474805796685803, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.004830527856253234, "train/extr_critic_critic_opt_grad_steps": 11070.0, "train/extr_critic_critic_opt_loss": 9006.58187249846, "train/extr_critic_mag": 0.02797688404327543, "train/extr_critic_max": 0.02797688404327543, "train/extr_critic_mean": 0.027714112590025798, "train/extr_critic_min": 0.027467876819554222, "train/extr_critic_std": 6.860200776518558e-05, "train/extr_return_normed_mag": 0.00041518242011222934, "train/extr_return_normed_max": 0.0003097252232100576, "train/extr_return_normed_mean": 4.286678874473966e-05, "train/extr_return_normed_min": -0.00018777605604949256, "train/extr_return_normed_std": 7.530059944203879e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.02794746072788544, "train/extr_return_raw_max": 0.02794746072788544, "train/extr_return_raw_mean": 0.0276806036404935, "train/extr_return_raw_min": 0.02744995944862589, "train/extr_return_raw_std": 7.530059949580203e-05, "train/extr_reward_mag": 7.819659604227602e-05, "train/extr_reward_max": 7.819659604227602e-05, "train/extr_reward_mean": 7.808359635244307e-05, "train/extr_reward_min": 7.797109669652479e-05, "train/extr_reward_std": 5.1233907898341353e-08, "train/image_loss_mean": 0.22376868466438332, "train/image_loss_std": 0.09186527033891584, "train/model_loss_mean": 0.8513083408031558, "train/model_loss_std": 0.37030219227956435, "train/model_opt_grad_norm": 44.06392025125438, "train/model_opt_grad_steps": 11057.620689655172, "train/model_opt_loss": 2191.3082918815426, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2573.8916256157636, "train/policy_entropy_mag": 1.9457069793945463, "train/policy_entropy_max": 1.9457069793945463, "train/policy_entropy_mean": 1.9337706513005524, "train/policy_entropy_min": 1.8289280566088673, "train/policy_entropy_std": 0.009258831700360577, "train/policy_logprob_mag": 2.697892549589937, "train/policy_logprob_max": -1.2778465081318258, "train/policy_logprob_mean": -1.9336512288436514, "train/policy_logprob_min": -2.697892549589937, "train/policy_logprob_std": 0.14826361827662426, "train/policy_randomness_mag": 0.9998956522330862, "train/policy_randomness_max": 0.9998956522330862, "train/policy_randomness_mean": 0.9937615890808293, "train/policy_randomness_min": 0.939883154894918, "train/policy_randomness_std": 0.00475809856528976, "train/post_ent_mag": 72.24633631212959, "train/post_ent_max": 72.24633631212959, "train/post_ent_mean": 71.40463095228073, "train/post_ent_min": 70.87348618530875, "train/post_ent_std": 0.30693632397305204, "train/prior_ent_mag": 70.49919840620069, "train/prior_ent_max": 70.49919840620069, "train/prior_ent_mean": 68.25434978842148, "train/prior_ent_min": 67.01536191742996, "train/prior_ent_std": 0.6679927908581466, "train/rep_loss_mean": 1.0038273023267097, "train/rep_loss_std": 0.0001474805796685803, "train/reward_avg": 7.097216048753899e-05, "train/reward_loss_mean": 0.001426340030331917, "train/reward_loss_std": 0.03637720942565185, "train/reward_max_data": 0.06371613320311889, "train/reward_max_pred": 7.818132785740744e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00017494333867388526, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.986576557159424, "train/reward_pred": 7.808083046704825e-05, "train/reward_rate": 0.00012507697044334976, "train_stats/mean_log_entropy": 1.924022989314899, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020044919103384018, "report/cont_loss_std": 0.30739372968673706, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.690882682800293, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00338232540525496, "report/cont_pred": 0.9966232776641846, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1711348593235016, "report/image_loss_std": 0.0991135761141777, "report/model_loss_mean": 0.7913713455200195, "report/model_loss_std": 0.32326287031173706, "report/post_ent_mag": 72.85847473144531, "report/post_ent_max": 72.85847473144531, "report/post_ent_mean": 72.47021484375, "report/post_ent_min": 72.08856201171875, "report/post_ent_std": 0.18473730981349945, "report/prior_ent_mag": 72.08572387695312, "report/prior_ent_max": 72.08572387695312, "report/prior_ent_mean": 68.3816909790039, "report/prior_ent_min": 66.55606079101562, "report/prior_ent_std": 1.0179468393325806, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.000191541388630867, "report/reward_loss_std": 5.089318051432201e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 8.249282836914062e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.000191541388630867, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 8.23362497612834e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.00338232540525496, "eval/cont_loss_std": 6.984919309616089e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00338232540525496, "eval/cont_pred": 0.9966232776641846, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2120993435382843, "eval/image_loss_std": 0.09487895667552948, "eval/model_loss_mean": 0.8156731724739075, "eval/model_loss_std": 0.09487887471914291, "eval/post_ent_mag": 72.86708068847656, "eval/post_ent_max": 72.86708068847656, "eval/post_ent_mean": 72.41258239746094, "eval/post_ent_min": 72.06465911865234, "eval/post_ent_std": 0.17150728404521942, "eval/prior_ent_mag": 71.21289825439453, "eval/prior_ent_max": 71.21289825439453, "eval/prior_ent_mean": 68.04009246826172, "eval/prior_ent_min": 66.53703308105469, "eval/prior_ent_std": 0.9195649027824402, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001914631575345993, "eval/reward_loss_std": 6.156964786896424e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 8.249282836914062e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001914631575345993, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 8.230435196310282e-05, "eval/reward_rate": 0.0, "replay/size": 194417.0, "replay/inserts": 32448.0, "replay/samples": 32448.0, "replay/insert_wait_avg": 1.2418075190963595e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.673657152074329e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 47296.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1532845656627053e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.398868560791, "timer/env.step_count": 4056.0, "timer/env.step_total": 37.19004273414612, "timer/env.step_frac": 0.03717521470975774, "timer/env.step_avg": 0.009169142685933461, "timer/env.step_min": 0.007404327392578125, "timer/env.step_max": 0.03884124755859375, "timer/replay._sample_count": 32448.0, "timer/replay._sample_total": 17.200971603393555, "timer/replay._sample_frac": 0.017194113412122784, "timer/replay._sample_avg": 0.0005301088388619808, "timer/replay._sample_min": 0.00041747093200683594, "timer/replay._sample_max": 0.02580547332763672, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4923.0, "timer/agent.policy_total": 50.347132444381714, "timer/agent.policy_frac": 0.05032705856296386, "timer/agent.policy_avg": 0.010226921073406808, "timer/agent.policy_min": 0.008452415466308594, "timer/agent.policy_max": 0.08731603622436523, "timer/dataset_train_count": 2028.0, "timer/dataset_train_total": 0.20789122581481934, "timer/dataset_train_frac": 0.00020780833760227955, "timer/dataset_train_avg": 0.00010251046637811604, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.00033473968505859375, "timer/agent.train_count": 2028.0, "timer/agent.train_total": 899.6568312644958, "timer/agent.train_frac": 0.8992981295138546, "timer/agent.train_avg": 0.44361776689570803, "timer/agent.train_min": 0.43385863304138184, "timer/agent.train_max": 0.6725997924804688, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47951245307922363, "timer/agent.report_frac": 0.00047932126689534057, "timer/agent.report_avg": 0.23975622653961182, "timer/agent.report_min": 0.23331308364868164, "timer/agent.report_max": 0.246199369430542, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.788385176306077e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 32.43452459419382}
{"step": 194976, "time": 6240.801047086716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195384, "time": 6252.989886522293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195384, "time": 6253.001012563705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195504, "time": 6256.847553253174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195528, "time": 6257.356469154358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195704, "time": 6262.68070435524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195808, "time": 6266.064053297043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196168, "time": 6276.869723320007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197288, "time": 6311.245580434799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197696, "time": 6323.7423532009125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197696, "time": 6323.751166343689, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197816, "time": 6327.165057897568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197840, "time": 6328.110965251923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198016, "time": 6333.420299530029, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198120, "time": 6336.423514842987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198480, "time": 6347.510623931885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199520, "time": 6379.091977596283, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 199600, "time": 6381.4934141635895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200008, "time": 6393.590920686722, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200008, "time": 6393.600291728973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 6402.302658319473, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6402.309121370316, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6402.314382314682, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6402.3213040828705, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6402.328219413757, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6402.333852767944, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6402.340451717377, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6402.346260309219, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200128, "time": 6403.331399440765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200152, "time": 6403.836429357529, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200328, "time": 6409.152144908905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200432, "time": 6412.510588645935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200896, "time": 6426.55881524086, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 201704, "time": 6451.4521725177765, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 201832, "time": 6455.318265676498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201840, "time": 6455.903465270996, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.0}
{"step": 202320, "time": 6470.374121904373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202320, "time": 6470.382457733154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202464, "time": 6474.756725549698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202640, "time": 6480.053302764893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203208, "time": 6497.041492462158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204016, "time": 6521.705919265747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204144, "time": 6525.572928905487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204152, "time": 6525.6006054878235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204632, "time": 6540.1228148937225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204632, "time": 6540.131822824478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204776, "time": 6544.479912042618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204952, "time": 6550.3806982040405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205520, "time": 6567.721165418625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206096, "time": 6585.219884395599, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 206328, "time": 6591.982422113419, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206456, "time": 6595.843961715698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206464, "time": 6596.309824228287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206944, "time": 6610.924106121063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206944, "time": 6610.931633710861, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207000, "time": 6612.421095609665, "episode/length": 6.0, "episode/score": 0.981249988079071, "episode/reward_rate": 0.14285714285714285, "episode/intrinsic_return": 0.0}
{"step": 207088, "time": 6615.287704229355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207832, "time": 6637.649246454239, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208408, "time": 6655.026119709015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208640, "time": 6662.245547056198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208768, "time": 6666.1852786540985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208776, "time": 6666.213034391403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209256, "time": 6680.660516500473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209312, "time": 6682.56804227829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209400, "time": 6685.022575616837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 6710.804265737534, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6710.814972162247, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6710.8257791996, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6710.834231376648, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6710.842956542969, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6710.853594303131, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6710.863246679306, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6710.871158361435, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210144, "time": 6712.833530426025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210448, "time": 6722.10826253891, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 210720, "time": 6730.4236369133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210952, "time": 6737.161417961121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211088, "time": 6741.501479387283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211288, "time": 6747.328769683838, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 211568, "time": 6756.097385883331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211624, "time": 6757.572104215622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211712, "time": 6760.461742639542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212456, "time": 6782.712447404861, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213032, "time": 6800.634373426437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213264, "time": 6807.985057830811, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213400, "time": 6811.903320550919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213600, "time": 6818.268227815628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213880, "time": 6826.489397525787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213936, "time": 6828.402497768402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214024, "time": 6830.834116220474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214768, "time": 6853.56290769577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215344, "time": 6870.921923875809, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215576, "time": 6877.788911581039, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215712, "time": 6882.129273414612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215912, "time": 6887.951073884964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216192, "time": 6896.621431827545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216248, "time": 6898.09876704216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216336, "time": 6900.9947056770325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217080, "time": 6923.316547632217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217656, "time": 6940.7258043289185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217888, "time": 6947.950238227844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218024, "time": 6951.818611383438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218224, "time": 6958.1140151023865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218504, "time": 6966.393935680389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218560, "time": 6968.31872677803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218648, "time": 6970.754241943359, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219392, "time": 6993.358315706253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219968, "time": 7010.95880651474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 7019.208588838577, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7019.218161582947, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7019.22904753685, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7019.23686337471, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7019.247669219971, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7019.256912469864, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7019.266839981079, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7019.277439594269, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220200, "time": 7023.225950241089, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220336, "time": 7027.625921010971, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220536, "time": 7033.42431640625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220816, "time": 7042.127883672714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220872, "time": 7043.597533226013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220960, "time": 7046.485287666321, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221704, "time": 7069.1952402591705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222280, "time": 7086.656211853027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222512, "time": 7093.884878158569, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222648, "time": 7097.75972533226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222848, "time": 7104.0546452999115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223128, "time": 7112.263933181763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223184, "time": 7114.194643497467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223272, "time": 7116.697926044464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224016, "time": 7139.39208483696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224592, "time": 7156.864020109177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224824, "time": 7163.6347987651825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224960, "time": 7167.978344202042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225160, "time": 7173.843390226364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225440, "time": 7182.6259162425995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225496, "time": 7184.091150760651, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225584, "time": 7186.9604845047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226328, "time": 7209.282912015915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226904, "time": 7226.637010097504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227136, "time": 7233.833839178085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227272, "time": 7237.816833972931, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227289, "time": 7239.306865692139, "train_stats/mean_log_entropy": 1.8281148278107078, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.3208388526840964, "train/action_min": 0.0, "train/action_std": 1.8505236671702696, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0003848844085896957, "train/actor_opt_grad_steps": 13095.0, "train/actor_opt_loss": 1.6912360834972102, "train/adv_mag": 0.0020001659096025005, "train/adv_max": 0.0019013150825653927, "train/adv_mean": 0.0004363696600682605, "train/adv_min": -0.0011152284736237904, "train/adv_std": 0.00041134350915556997, "train/cont_avg": 0.9967173963490099, "train/cont_loss_mean": 0.022112835424555704, "train/cont_loss_std": 0.3096111033824024, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.665751948723426, "train/cont_pos_acc": 0.9999999858365201, "train/cont_pos_loss": 0.0034964330987728174, "train/cont_pred": 0.9965097558970498, "train/cont_rate": 0.9967173963490099, "train/dyn_loss_mean": 1.0000038790230703, "train/dyn_loss_std": 0.00011850985981371843, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.01020568917089921, "train/extr_critic_critic_opt_grad_steps": 13095.0, "train/extr_critic_critic_opt_loss": 9849.54989170792, "train/extr_critic_mag": 0.034041945296939054, "train/extr_critic_max": 0.034041945296939054, "train/extr_critic_mean": 0.03310290901082577, "train/extr_critic_min": 0.032061331342942645, "train/extr_critic_std": 0.0002559401040667977, "train/extr_return_normed_mag": 0.0030812839746917828, "train/extr_return_normed_max": 0.003067626036924891, "train/extr_return_normed_mean": 0.001597924969958328, "train/extr_return_normed_min": 9.841752229350629e-05, "train/extr_return_normed_std": 0.00046797996505894377, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.035008951726526315, "train/extr_return_raw_max": 0.035008951726526315, "train/extr_return_raw_mean": 0.03353925240179985, "train/extr_return_raw_min": 0.032039743211894935, "train/extr_return_raw_std": 0.00046797996430253234, "train/extr_reward_mag": 0.0002498892274233374, "train/extr_reward_max": 0.0002498892274233374, "train/extr_reward_mean": 0.00014998494272263222, "train/extr_reward_min": 4.5018030865357655e-05, "train/extr_reward_std": 7.58989844265661e-05, "train/image_loss_mean": 0.19558876738099767, "train/image_loss_std": 0.09987839292919282, "train/model_loss_mean": 0.8192339784438067, "train/model_loss_std": 0.35928750410676, "train/model_opt_grad_norm": 41.054804811383235, "train/model_opt_grad_steps": 13080.663366336634, "train/model_opt_loss": 2099.213419394918, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2561.8811881188117, "train/policy_entropy_mag": 1.939904253671665, "train/policy_entropy_max": 1.939904253671665, "train/policy_entropy_mean": 1.8360367340616661, "train/policy_entropy_min": 1.4047458676418456, "train/policy_entropy_std": 0.043629703526892286, "train/policy_logprob_mag": 3.8724467530108915, "train/policy_logprob_max": -0.7077015804329722, "train/policy_logprob_mean": -1.8358525568896, "train/policy_logprob_min": -3.8724467530108915, "train/policy_logprob_std": 0.36612684921462935, "train/policy_randomness_mag": 0.9969136413961354, "train/policy_randomness_max": 0.9969136413961354, "train/policy_randomness_mean": 0.9435362901427958, "train/policy_randomness_min": 0.7218966169817613, "train/policy_randomness_std": 0.022421233672971403, "train/post_ent_mag": 73.64581468789885, "train/post_ent_max": 73.64581468789885, "train/post_ent_mean": 73.2179950676342, "train/post_ent_min": 72.78711760870301, "train/post_ent_std": 0.1929392824963768, "train/prior_ent_mag": 73.02264411850732, "train/prior_ent_max": 73.02264411850732, "train/prior_ent_mean": 69.02948470162873, "train/prior_ent_min": 67.14665203283329, "train/prior_ent_std": 1.1466094163974914, "train/rep_loss_mean": 1.0000038790230703, "train/rep_loss_std": 0.00011850985981371843, "train/reward_avg": 7.717019357052309e-05, "train/reward_loss_mean": 0.0015300239279571145, "train/reward_loss_std": 0.042138950681452826, "train/reward_max_data": 0.07662438217661169, "train/reward_max_pred": 0.0002454477961700742, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00018976082626095107, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.924361264264142, "train/reward_pred": 8.507830316735671e-05, "train/reward_rate": 0.000135365099009901, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025638660416007042, "report/cont_loss_std": 0.3586723804473877, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.753177642822266, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0031777259428054094, "report/cont_pred": 0.9968271851539612, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.20647020637989044, "report/image_loss_std": 0.11045808345079422, "report/model_loss_mean": 0.8400110006332397, "report/model_loss_std": 0.5486262440681458, "report/post_ent_mag": 73.5968017578125, "report/post_ent_max": 73.5968017578125, "report/post_ent_mean": 73.13744354248047, "report/post_ent_min": 72.63227844238281, "report/post_ent_std": 0.21794399619102478, "report/prior_ent_mag": 74.38592529296875, "report/prior_ent_max": 74.38592529296875, "report/prior_ent_mean": 70.83518981933594, "report/prior_ent_min": 68.90808868408203, "report/prior_ent_std": 1.1110373735427856, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0005828857538290322, "report/reward_loss_mean": 0.007902147248387337, "report/reward_loss_std": 0.24816638231277466, "report/reward_max_data": 0.596875011920929, "report/reward_max_pred": 0.0004782676696777344, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00014316067972686142, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 7.945344924926758, "report/reward_pred": 6.128463428467512e-05, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02002342790365219, "eval/cont_loss_std": 0.3107715845108032, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.753177642822266, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0031777259428054094, "eval/cont_pred": 0.9968271851539612, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19109900295734406, "eval/image_loss_std": 0.1001749038696289, "eval/model_loss_mean": 0.81125807762146, "eval/model_loss_std": 0.3275979161262512, "eval/post_ent_mag": 73.58553314208984, "eval/post_ent_max": 73.58553314208984, "eval/post_ent_mean": 73.12997436523438, "eval/post_ent_min": 72.60325622558594, "eval/post_ent_std": 0.21603387594223022, "eval/prior_ent_mag": 74.29962158203125, "eval/prior_ent_max": 74.29962158203125, "eval/prior_ent_mean": 70.70845031738281, "eval/prior_ent_min": 68.59786224365234, "eval/prior_ent_std": 1.0717930793762207, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00013566110283136368, "eval/reward_loss_std": 0.00021355232456699014, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0004628896713256836, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00013566110283136368, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.748681724071503e-05, "eval/reward_rate": 0.0, "replay/size": 226785.0, "replay/inserts": 32368.0, "replay/samples": 32368.0, "replay/insert_wait_avg": 1.229157968729484e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.670893860051848e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 54232.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1087357654153544e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1502315998077, "timer/env.step_count": 4046.0, "timer/env.step_total": 36.95208668708801, "timer/env.step_frac": 0.03694653614985487, "timer/env.step_avg": 0.009132992260773113, "timer/env.step_min": 0.007595062255859375, "timer/env.step_max": 0.0388035774230957, "timer/replay._sample_count": 32368.0, "timer/replay._sample_total": 17.181478261947632, "timer/replay._sample_frac": 0.01717889744870098, "timer/replay._sample_avg": 0.000530816802457601, "timer/replay._sample_min": 0.00036716461181640625, "timer/replay._sample_max": 0.01171565055847168, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4913.0, "timer/agent.policy_total": 50.41990351676941, "timer/agent.policy_frac": 0.05041232999178471, "timer/agent.policy_avg": 0.01026254905694472, "timer/agent.policy_min": 0.008799552917480469, "timer/agent.policy_max": 0.08127450942993164, "timer/dataset_train_count": 2023.0, "timer/dataset_train_total": 0.20756053924560547, "timer/dataset_train_frac": 0.00020752936177757854, "timer/dataset_train_avg": 0.00010260036542046736, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.0004680156707763672, "timer/agent.train_count": 2023.0, "timer/agent.train_total": 899.5474226474762, "timer/agent.train_frac": 0.8994123024983851, "timer/agent.train_avg": 0.44466011994437776, "timer/agent.train_min": 0.43419814109802246, "timer/agent.train_max": 1.2129230499267578, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48421144485473633, "timer/agent.report_frac": 0.0004841387119215155, "timer/agent.report_avg": 0.24210572242736816, "timer/agent.report_min": 0.23800373077392578, "timer/agent.report_max": 0.24620771408081055, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5272369384765625e-05, "timer/dataset_eval_frac": 2.526857324658193e-08, "timer/dataset_eval_avg": 2.5272369384765625e-05, "timer/dataset_eval_min": 2.5272369384765625e-05, "timer/dataset_eval_max": 2.5272369384765625e-05, "fps": 32.36260959327197}
{"step": 227472, "time": 7244.8568658828735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227752, "time": 7253.113162994385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227808, "time": 7255.051094055176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227896, "time": 7257.494753837585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228640, "time": 7280.185753583908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229216, "time": 7297.6610062122345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229408, "time": 7303.998482465744, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 229584, "time": 7309.325443744659, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229784, "time": 7315.152379512787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 7328.596764802933, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7328.604525089264, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7328.614123344421, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7328.622707366943, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7328.633985042572, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7328.6416738033295, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7328.650710105896, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7328.660698413849, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230064, "time": 7329.148200273514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230120, "time": 7330.612754821777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230120, "time": 7330.6194841861725, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 230952, "time": 7355.741119146347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231528, "time": 7373.138036251068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231720, "time": 7378.938821077347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231896, "time": 7384.260047674179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232096, "time": 7390.607652664185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232376, "time": 7398.836950302124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232432, "time": 7400.768716573715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232432, "time": 7400.776350975037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233264, "time": 7425.916495323181, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233840, "time": 7443.271538257599, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234032, "time": 7449.1289875507355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234208, "time": 7454.425703048706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234408, "time": 7460.216646671295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234688, "time": 7468.8728721141815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234744, "time": 7470.340981721878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234744, "time": 7470.3509953022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235576, "time": 7495.4972603321075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236152, "time": 7512.939266443253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236344, "time": 7518.727523326874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236520, "time": 7524.073615550995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236720, "time": 7530.31526350975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237000, "time": 7538.601215600967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237056, "time": 7540.505112171173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237056, "time": 7540.5137774944305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237888, "time": 7566.151452302933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238464, "time": 7583.431908607483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238656, "time": 7589.21026134491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238832, "time": 7594.524964570999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239032, "time": 7600.407603502274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239312, "time": 7609.060553312302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239368, "time": 7610.528482913971, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239368, "time": 7610.53716135025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239800, "time": 7623.530752420425, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 7635.302062511444, "eval_episode/length": 210.0, "eval_episode/score": 0.34375, "eval_episode/reward_rate": 0.004739336492890996}
{"step": 240032, "time": 7636.6244740486145, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7636.630373477936, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7636.637357711792, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7636.644036531448, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7636.652649641037, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7636.6597990989685, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7636.667860746384, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240200, "time": 7641.483928442001, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240968, "time": 7664.599622488022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241144, "time": 7669.9009647369385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241344, "time": 7676.152276754379, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241624, "time": 7684.37779712677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241680, "time": 7686.382151842117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241680, "time": 7686.392030477524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242112, "time": 7699.370243310928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242504, "time": 7710.876614332199, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 242512, "time": 7711.360683679581, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242664, "time": 7715.773415088654, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 243456, "time": 7739.790863752365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243936, "time": 7754.277827739716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243992, "time": 7755.759300947189, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243992, "time": 7755.768813610077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244424, "time": 7768.748626470566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244560, "time": 7773.07276725769, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 244816, "time": 7780.836271762848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244824, "time": 7780.863389492035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244976, "time": 7785.668787240982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245768, "time": 7809.537602424622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246248, "time": 7824.275701522827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246304, "time": 7826.185003519058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246736, "time": 7839.298625469208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246872, "time": 7843.171986579895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247032, "time": 7848.013929367065, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 247128, "time": 7850.944081544876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247136, "time": 7851.418836116791, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247288, "time": 7855.801230669022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248560, "time": 7894.478859424591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248616, "time": 7896.04572558403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249048, "time": 7908.998593568802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249184, "time": 7913.310170173645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249344, "time": 7918.130828857422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249440, "time": 7921.033815860748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249448, "time": 7921.061914920807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249600, "time": 7925.91858124733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 7942.26731300354, "eval_episode/length": 220.0, "eval_episode/score": 0.3125, "eval_episode/reward_rate": 0.004524886877828055}
{"step": 250016, "time": 7943.43808221817, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 7943.443912744522, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 7943.450478553772, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 7943.456607580185, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 7943.463355064392, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 7943.469486951828, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 7943.4752905368805, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250872, "time": 7969.042993783951, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250928, "time": 7970.938595056534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251360, "time": 7983.919205904007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251496, "time": 7987.872789859772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251656, "time": 7992.692276239395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251752, "time": 7995.562752485275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251760, "time": 7996.0255818367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251912, "time": 8000.375453472137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253184, "time": 8038.889459609985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253240, "time": 8040.367731332779, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253672, "time": 8053.418301820755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253808, "time": 8057.725657463074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253864, "time": 8059.187527418137, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 253968, "time": 8063.04040312767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254064, "time": 8065.927873373032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254072, "time": 8065.955763101578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254384, "time": 8075.52464222908, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 255432, "time": 8106.959183454514, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 255496, "time": 8108.908032417297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255552, "time": 8110.819447517395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255984, "time": 8123.854206562042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256120, "time": 8127.743892669678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256376, "time": 8135.384592294693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256384, "time": 8135.914590120316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256664, "time": 8144.070820569992, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 256696, "time": 8145.028732776642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257112, "time": 8157.492147684097, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 257640, "time": 8173.367045879364, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 257864, "time": 8180.11067032814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258432, "time": 8197.492549657822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258456, "time": 8197.99637889862, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 258688, "time": 8205.220722436905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258696, "time": 8205.248250484467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258976, "time": 8213.886769294739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259424, "time": 8227.439475297928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259801, "time": 8239.518129110336, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.102153404086244, "train/action_min": 0.0, "train/action_std": 1.9030389563710082, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0017686350744471008, "train/actor_opt_grad_steps": 15125.0, "train/actor_opt_loss": 7.367369667499089, "train/adv_mag": 0.012350257796545824, "train/adv_max": 0.012170426127519094, "train/adv_mean": 0.0014882711917340095, "train/adv_min": -0.0031723824749682462, "train/adv_std": 0.001617028514624062, "train/cont_avg": 0.996548521752451, "train/cont_loss_mean": 0.023047135050600284, "train/cont_loss_std": 0.3152982735092676, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.662287191244272, "train/cont_pos_acc": 0.9999999845144796, "train/cont_pos_loss": 0.0035116401941552027, "train/cont_pred": 0.9964946055529165, "train/cont_rate": 0.996548521752451, "train/dyn_loss_mean": 1.0000071180801766, "train/dyn_loss_std": 0.00020309972177190002, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.058776792101721806, "train/extr_critic_critic_opt_grad_steps": 15125.0, "train/extr_critic_critic_opt_loss": 12885.131199257046, "train/extr_critic_mag": 0.07524604423373353, "train/extr_critic_max": 0.07524604423373353, "train/extr_critic_mean": 0.07266231314005221, "train/extr_critic_min": 0.06942137257725585, "train/extr_critic_std": 0.0008505461528508094, "train/extr_return_normed_mag": 0.016876417942637324, "train/extr_return_normed_max": 0.016864034767244376, "train/extr_return_normed_mean": 0.005515753226154518, "train/extr_return_normed_min": 0.0008254312344041525, "train/extr_return_normed_std": 0.001846656871088735, "train/extr_return_rate": 3.191380885397723e-07, "train/extr_return_raw_mag": 0.08549883757151809, "train/extr_return_raw_max": 0.08549883757151809, "train/extr_return_raw_mean": 0.07415055965676028, "train/extr_return_raw_min": 0.06946023400215541, "train/extr_return_raw_std": 0.0018466568795060191, "train/extr_reward_mag": 0.006135260941935521, "train/extr_reward_max": 0.006135260941935521, "train/extr_reward_mean": 0.0004410714226312349, "train/extr_reward_min": -0.00012326766462887034, "train/extr_reward_std": 0.0006858662186905527, "train/image_loss_mean": 0.18201185280785842, "train/image_loss_std": 0.1049015158969982, "train/model_loss_mean": 0.80662554648577, "train/model_loss_std": 0.36546270856085944, "train/model_opt_grad_norm": 37.484973454239345, "train/model_opt_grad_steps": 15108.754901960785, "train/model_opt_loss": 2175.301860136144, "train/model_opt_model_opt_grad_overflow": 0.00980392156862745, "train/model_opt_model_opt_grad_scale": 2671.5686274509803, "train/policy_entropy_mag": 1.8109666997311162, "train/policy_entropy_max": 1.8109666997311162, "train/policy_entropy_mean": 1.2579853132951493, "train/policy_entropy_min": 0.38287321952920333, "train/policy_entropy_std": 0.2709201213118492, "train/policy_logprob_mag": 5.611695476606781, "train/policy_logprob_max": -0.0994898576252893, "train/policy_logprob_mean": -1.2584918274306784, "train/policy_logprob_min": -5.611695476606781, "train/policy_logprob_std": 0.9050679960671593, "train/policy_randomness_mag": 0.9306528407569025, "train/policy_randomness_max": 0.9306528407569025, "train/policy_randomness_mean": 0.646476605943605, "train/policy_randomness_min": 0.19675792437777215, "train/policy_randomness_std": 0.13922540956706392, "train/post_ent_mag": 72.90087374518899, "train/post_ent_max": 72.90087374518899, "train/post_ent_mean": 72.45351761462642, "train/post_ent_min": 71.90654851876053, "train/post_ent_std": 0.19939621165394783, "train/prior_ent_mag": 74.07022696850346, "train/prior_ent_max": 74.07022696850346, "train/prior_ent_mean": 70.59500507279938, "train/prior_ent_min": 68.2664265352137, "train/prior_ent_std": 1.011438637971878, "train/rep_loss_mean": 1.0000071180801766, "train/rep_loss_std": 0.00020309972177190002, "train/reward_avg": 9.810503901212988e-05, "train/reward_loss_mean": 0.0015622661426188606, "train/reward_loss_std": 0.040759820532109775, "train/reward_max_data": 0.08820465740327742, "train/reward_max_pred": 0.0018470871682260551, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0001879605189934213, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.483781452836661, "train/reward_pred": 8.17518476990289e-05, "train/reward_rate": 0.00016276041666666666, "train_stats/mean_log_entropy": 1.2722581874611032, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014592831954360008, "report/cont_loss_std": 0.24817685782909393, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.6247076988220215, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003614139510318637, "report/cont_pred": 0.9963923096656799, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0000617504119873, "report/dyn_loss_std": 0.0019725309684872627, "report/image_loss_mean": 0.1885179877281189, "report/image_loss_std": 0.10836562514305115, "report/model_loss_mean": 0.8033840656280518, "report/model_loss_std": 0.26930466294288635, "report/post_ent_mag": 71.68629455566406, "report/post_ent_max": 71.68629455566406, "report/post_ent_mean": 71.1251220703125, "report/post_ent_min": 70.47123718261719, "report/post_ent_std": 0.24002765119075775, "report/prior_ent_mag": 73.579833984375, "report/prior_ent_max": 73.579833984375, "report/prior_ent_mean": 70.12074279785156, "report/prior_ent_min": 67.43267059326172, "report/prior_ent_std": 1.0024608373641968, "report/rep_loss_mean": 1.0000617504119873, "report/rep_loss_std": 0.0019725309684872627, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0002362225204706192, "report/reward_loss_std": 0.0010056884493678808, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.005378842353820801, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0002362225204706192, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00010251009371131659, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.02557152882218361, "eval/cont_loss_std": 0.3506315350532532, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.6247076988220215, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0036141392774879932, "eval/cont_pred": 0.9963923096656799, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16324560344219208, "eval/image_loss_std": 0.09372932463884354, "eval/model_loss_mean": 0.7952464818954468, "eval/model_loss_std": 0.49625149369239807, "eval/post_ent_mag": 71.67315673828125, "eval/post_ent_max": 71.67315673828125, "eval/post_ent_mean": 71.13153839111328, "eval/post_ent_min": 70.41581726074219, "eval/post_ent_std": 0.23529796302318573, "eval/prior_ent_mag": 73.31430053710938, "eval/prior_ent_max": 73.31430053710938, "eval/prior_ent_mean": 70.078125, "eval/prior_ent_min": 67.50914764404297, "eval/prior_ent_std": 0.9371184706687927, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007293701055459678, "eval/reward_loss_mean": 0.006429300643503666, "eval/reward_loss_std": 0.1977969855070114, "eval/reward_max_data": 0.746874988079071, "eval/reward_max_pred": 0.0053282976150512695, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0002452145563438535, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.332749366760254, "eval/reward_pred": 0.00010917044710367918, "eval/reward_rate": 0.0009765625, "replay/size": 259297.0, "replay/inserts": 32512.0, "replay/samples": 32512.0, "replay/insert_wait_avg": 1.2277691500393424e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.737530615386062e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 61168.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1095951172719777e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1962349414825, "timer/env.step_count": 4064.0, "timer/env.step_total": 37.18516993522644, "timer/env.step_frac": 0.03717787433723143, "timer/env.step_avg": 0.00914989417697501, "timer/env.step_min": 0.007393836975097656, "timer/env.step_max": 0.05696225166320801, "timer/replay._sample_count": 32512.0, "timer/replay._sample_total": 17.047163248062134, "timer/replay._sample_frac": 0.01704381865530567, "timer/replay._sample_avg": 0.0005243344995097851, "timer/replay._sample_min": 0.0003974437713623047, "timer/replay._sample_max": 0.010930776596069336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4931.0, "timer/agent.policy_total": 50.177552700042725, "timer/agent.policy_frac": 0.05016770804279064, "timer/agent.policy_avg": 0.010175938491186925, "timer/agent.policy_min": 0.008730649948120117, "timer/agent.policy_max": 0.09353780746459961, "timer/dataset_train_count": 2032.0, "timer/dataset_train_total": 0.20701003074645996, "timer/dataset_train_frac": 0.00020696941611519993, "timer/dataset_train_avg": 0.00010187501513113187, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0006089210510253906, "timer/agent.train_count": 2032.0, "timer/agent.train_total": 899.8202891349792, "timer/agent.train_frac": 0.8996437475968144, "timer/agent.train_avg": 0.44282494544044254, "timer/agent.train_min": 0.43413686752319336, "timer/agent.train_max": 0.6900725364685059, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47659778594970703, "timer/agent.report_frac": 0.00047650427916036983, "timer/agent.report_avg": 0.23829889297485352, "timer/agent.report_min": 0.23178815841674805, "timer/agent.report_max": 0.24480962753295898, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7174385453638808e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 32.50509616688273}
{"step": 259952, "time": 8244.029094219208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 8250.38198184967, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8250.391380548477, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8250.400748729706, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8250.410264492035, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8250.42049241066, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8250.429325819016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8250.436756134033, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8250.4456179142, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260176, "time": 8255.822571277618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260496, "time": 8265.418827295303, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 260744, "time": 8272.60477924347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260768, "time": 8273.571262598038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261000, "time": 8280.299120664597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261008, "time": 8280.765684604645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261288, "time": 8289.040115118027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261736, "time": 8302.447586297989, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262008, "time": 8310.58499956131, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 262160, "time": 8315.897441148758, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 262488, "time": 8325.527235746384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262808, "time": 8335.183710336685, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 263056, "time": 8342.875425338745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263080, "time": 8343.381148576736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263152, "time": 8345.898357868195, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 263320, "time": 8350.729521036148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263600, "time": 8359.339275360107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263736, "time": 8363.214572668076, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 263800, "time": 8365.144768238068, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 263960, "time": 8369.944617986679, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 264248, "time": 8378.675924301147, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 264320, "time": 8381.075511693954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264472, "time": 8385.439538955688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265312, "time": 8410.963384389877, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 265384, "time": 8412.922423362732, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 265392, "time": 8413.41383266449, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265464, "time": 8415.360732078552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265632, "time": 8420.668967962265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266048, "time": 8433.186281442642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266176, "time": 8437.094002962112, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 266272, "time": 8440.0115172863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266312, "time": 8441.00493144989, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 266632, "time": 8450.63727402687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267560, "time": 8478.598736047745, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 267696, "time": 8482.890081644058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267944, "time": 8490.097150802612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268360, "time": 8502.640019416809, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268392, "time": 8503.607534646988, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 268472, "time": 8506.021610498428, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 268488, "time": 8506.506005048752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268584, "time": 8509.379128932953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269056, "time": 8523.746441602707, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 269664, "time": 8542.044834375381, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 269744, "time": 8544.46839427948, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 269784, "time": 8545.460987329483, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 8556.03232216835, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 270088, "time": 8556.132111787796, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 270088, "time": 8556.233629703522, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 270088, "time": 8556.9139046669, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 270088, "time": 8558.685252666473, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 270088, "time": 8560.468435287476, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8560.478053808212, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8560.486340522766, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8560.494204044342, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270256, "time": 8565.757113456726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270376, "time": 8569.568580627441, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 270784, "time": 8582.0377099514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270800, "time": 8582.521031141281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270896, "time": 8586.367144584656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270992, "time": 8589.251950502396, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 271016, "time": 8589.753146409988, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 271336, "time": 8599.36054635048, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 271368, "time": 8600.330954313278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271768, "time": 8612.329768180847, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 272096, "time": 8622.460672616959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272288, "time": 8628.221045732498, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 273096, "time": 8652.35069990158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273112, "time": 8652.836429357529, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273304, "time": 8658.592715024948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273648, "time": 8669.133424282074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273680, "time": 8670.099167585373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273984, "time": 8679.294854164124, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 274080, "time": 8682.18469953537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274408, "time": 8691.822483062744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274600, "time": 8697.570784807205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275408, "time": 8722.155424833298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275424, "time": 8722.645401716232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275520, "time": 8725.542626619339, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 275616, "time": 8728.426212787628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275920, "time": 8737.636140346527, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 275960, "time": 8738.640182495117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276296, "time": 8748.713143587112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276536, "time": 8755.914331197739, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 276720, "time": 8761.629162311554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277016, "time": 8770.39592051506, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 277344, "time": 8780.488817453384, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 277720, "time": 8791.557892799377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277832, "time": 8794.910581588745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277928, "time": 8797.881747245789, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278272, "time": 8808.394147157669, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278592, "time": 8818.495116710663, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 278728, "time": 8822.369095563889, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 278848, "time": 8826.287060499191, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 278848, "time": 8826.295328378677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279032, "time": 8831.600529432297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279568, "time": 8847.893143415451, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 279656, "time": 8850.315367937088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279848, "time": 8856.159548282623, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 279968, "time": 8859.990784168243, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 8864.19366145134, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 280072, "time": 8865.414860963821, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 280072, "time": 8865.43936419487, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 280072, "time": 8865.646946430206, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 280072, "time": 8867.887984514236, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8867.897862195969, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8867.906524181366, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8867.915329933167, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280144, "time": 8870.307146072388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280552, "time": 8882.306434392929, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 280600, "time": 8883.761641979218, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 280608, "time": 8884.232468366623, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 281040, "time": 8897.260187149048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281160, "time": 8900.701154708862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281344, "time": 8906.461151123047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281616, "time": 8914.622337341309, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 281800, "time": 8919.992091417313, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 281880, "time": 8922.421283483505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282040, "time": 8927.206240177155, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 282248, "time": 8933.43265247345, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 282280, "time": 8934.402911424637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282864, "time": 8952.219160556793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282920, "time": 8953.677103281021, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283056, "time": 8957.987407922745, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 283280, "time": 8964.718231201172, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 283352, "time": 8966.669714927673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283672, "time": 8976.39008307457, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 283856, "time": 8982.198990821838, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 283928, "time": 8984.131399154663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284112, "time": 8989.87881731987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284352, "time": 8997.10173535347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284512, "time": 9001.922038555145, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 285000, "time": 9016.45392036438, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 285368, "time": 9027.492882013321, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285592, "time": 9034.216324090958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285664, "time": 9036.63455080986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285672, "time": 9036.661711931229, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 286168, "time": 9051.618229866028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286200, "time": 9052.60372209549, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 286400, "time": 9058.829044818878, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 286664, "time": 9066.597892999649, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286792, "time": 9070.927120923996, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 286888, "time": 9073.833510398865, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 287072, "time": 9079.569387674332, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 287272, "time": 9085.344245672226, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 287328, "time": 9087.266542196274, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 287376, "time": 9088.714116573334, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 287496, "time": 9092.100912094116, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 287608, "time": 9095.450967550278, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 287984, "time": 9107.056020736694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288040, "time": 9108.526750087738, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 288120, "time": 9110.959326982498, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 288480, "time": 9122.017706871033, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 288832, "time": 9132.679052352905, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 288880, "time": 9134.117729663849, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 289200, "time": 9143.723140001297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289232, "time": 9144.706246137619, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 289240, "time": 9144.73173046112, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 289584, "time": 9155.283414363861, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289640, "time": 9156.856164932251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289712, "time": 9159.246157169342, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 289808, "time": 9162.12659573555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289832, "time": 9162.632219314575, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 289992, "time": 9167.45727777481, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 9170.08826303482, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 290056, "time": 9170.295757293701, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 290056, "time": 9170.478027582169, "eval_episode/length": 21.0, "eval_episode/score": 0.934374988079071, "eval_episode/reward_rate": 0.045454545454545456}
{"step": 290056, "time": 9170.761944293976, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 290056, "time": 9171.048135757446, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 290056, "time": 9174.76560139656, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9174.773440361023, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9174.78110408783, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9174.789109230042, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290192, "time": 9179.107131958008, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 290248, "time": 9180.564512491226, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 290264, "time": 9181.046300411224, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 290432, "time": 9186.378311872482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291552, "time": 9220.102882385254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291952, "time": 9232.225594758987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292120, "time": 9237.05850481987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292185, "time": 9240.000992536545, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.683826710918162, "train/action_min": 0.0, "train/action_std": 1.4609952262132475, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.003023811063607048, "train/actor_opt_grad_steps": 17155.0, "train/actor_opt_loss": 16.09084701947499, "train/adv_mag": 0.02784956681846392, "train/adv_max": 0.027492647750837967, "train/adv_mean": 0.004899896142302565, "train/adv_min": -0.0069830838849048804, "train/adv_std": 0.004542846962265523, "train/cont_avg": 0.9963789836014851, "train/cont_loss_mean": 0.023887625923103624, "train/cont_loss_std": 0.32579454405657604, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.605801231861115, "train/cont_pos_acc": 0.999999984066085, "train/cont_pos_loss": 0.0036055013055608857, "train/cont_pred": 0.9964005525159364, "train/cont_rate": 0.9963789836014851, "train/dyn_loss_mean": 1.0000057385699583, "train/dyn_loss_std": 0.00016068909293482088, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.47120691006910975, "train/extr_critic_critic_opt_grad_steps": 17155.0, "train/extr_critic_critic_opt_loss": 8511.772118898902, "train/extr_critic_mag": 0.18254536862420565, "train/extr_critic_max": 0.18254536862420565, "train/extr_critic_mean": 0.17857000773938575, "train/extr_critic_min": 0.1709417175538469, "train/extr_critic_std": 0.0020388491075479607, "train/extr_return_normed_mag": 0.039262335526176015, "train/extr_return_normed_max": 0.03924085616622821, "train/extr_return_normed_mean": 0.014911560875742285, "train/extr_return_normed_min": 0.0027119529498095558, "train/extr_return_normed_std": 0.00518746558855758, "train/extr_return_rate": 2.9006808083320016e-06, "train/extr_return_raw_mag": 0.20779917308009496, "train/extr_return_raw_max": 0.20779917308009496, "train/extr_return_raw_mean": 0.18346988738025768, "train/extr_return_raw_min": 0.17127026982679225, "train/extr_return_raw_std": 0.005187465597778595, "train/extr_reward_mag": 0.018401846437170955, "train/extr_reward_max": 0.018401846437170955, "train/extr_reward_mean": 0.001175939141758856, "train/extr_reward_min": -2.4392463193081394e-05, "train/extr_reward_std": 0.0029358646119506753, "train/image_loss_mean": 0.1688192209026011, "train/image_loss_std": 0.10599758247337719, "train/model_loss_mean": 0.795054162787919, "train/model_loss_std": 0.38460939528770965, "train/model_opt_grad_norm": 36.17087488835401, "train/model_opt_grad_steps": 17136.925742574258, "train/model_opt_loss": 2272.5440178295175, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2858.910891089109, "train/policy_entropy_mag": 1.6041972507344615, "train/policy_entropy_max": 1.6041972507344615, "train/policy_entropy_mean": 0.569808197862441, "train/policy_entropy_min": 0.07783148422984794, "train/policy_entropy_std": 0.3204193913405485, "train/policy_logprob_mag": 6.530317061018236, "train/policy_logprob_max": -0.01094848930946376, "train/policy_logprob_mean": -0.5696701779961586, "train/policy_logprob_min": -6.530317061018236, "train/policy_logprob_std": 0.9089976982905132, "train/policy_randomness_mag": 0.8243943559061183, "train/policy_randomness_max": 0.8243943559061183, "train/policy_randomness_mean": 0.29282350473032137, "train/policy_randomness_min": 0.03999747300870938, "train/policy_randomness_std": 0.16466300425553085, "train/post_ent_mag": 66.25617335102346, "train/post_ent_max": 66.25617335102346, "train/post_ent_mean": 65.60351099826322, "train/post_ent_min": 64.92643108934459, "train/post_ent_std": 0.23901065254565512, "train/prior_ent_mag": 68.55369067428136, "train/prior_ent_max": 68.55369067428136, "train/prior_ent_mean": 65.85658182956205, "train/prior_ent_min": 63.21622062909721, "train/prior_ent_std": 0.905877009181693, "train/rep_loss_mean": 1.0000057385699583, "train/rep_loss_std": 0.00016068909293482088, "train/reward_avg": 0.00016891932642861907, "train/reward_loss_mean": 0.0023438470820794895, "train/reward_loss_std": 0.05979359596619027, "train/reward_max_data": 0.15977722789981577, "train/reward_max_pred": 0.009860002168334357, "train/reward_neg_acc": 0.9999999997049275, "train/reward_neg_loss": 0.00037410346747060203, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 6.535962293732841, "train/reward_pred": 0.00014409844505388548, "train/reward_rate": 0.00029973700495049504, "train_stats/mean_log_entropy": 0.5791525531124759, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.004172413609921932, "report/cont_loss_std": 0.0013754902174696326, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004172413609921932, "report/cont_pred": 0.9958372116088867, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.12351977825164795, "report/image_loss_std": 0.09840002655982971, "report/model_loss_mean": 0.7280426025390625, "report/model_loss_std": 0.09809976816177368, "report/post_ent_mag": 61.29879379272461, "report/post_ent_max": 61.29879379272461, "report/post_ent_mean": 60.55589294433594, "report/post_ent_min": 59.9527702331543, "report/post_ent_std": 0.24704033136367798, "report/prior_ent_mag": 63.3083610534668, "report/prior_ent_max": 63.3083610534668, "report/prior_ent_mean": 60.882659912109375, "report/prior_ent_min": 58.93906784057617, "report/prior_ent_std": 0.8770143985748291, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0003503975458443165, "report/reward_loss_std": 0.0017834447789937258, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.011071920394897461, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0003503975458443165, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00014939915854483843, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02042405866086483, "eval/cont_loss_std": 0.3022540807723999, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.596172332763672, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004040861967951059, "eval/cont_pred": 0.9959685206413269, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20781385898590088, "eval/image_loss_std": 0.1153109222650528, "eval/model_loss_mean": 0.8284246921539307, "eval/model_loss_std": 0.3228943347930908, "eval/post_ent_mag": 61.35447311401367, "eval/post_ent_max": 61.35447311401367, "eval/post_ent_mean": 60.547386169433594, "eval/post_ent_min": 59.910587310791016, "eval/post_ent_std": 0.2556605637073517, "eval/prior_ent_mag": 63.72283935546875, "eval/prior_ent_max": 63.72283935546875, "eval/prior_ent_mean": 61.00398254394531, "eval/prior_ent_min": 59.077171325683594, "eval/prior_ent_std": 0.895153284072876, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00018675392493605614, "eval/reward_loss_std": 0.0009397116373293102, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.005456328392028809, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00018675392493605614, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.82911665737629e-05, "eval/reward_rate": 0.0, "replay/size": 291681.0, "replay/inserts": 32384.0, "replay/samples": 32384.0, "replay/insert_wait_avg": 1.2232645933807131e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.836508892270416e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 70416.0, "eval_replay/inserts": 9248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1013453394483942e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4418845176697, "timer/env.step_count": 4048.0, "timer/env.step_total": 37.05193829536438, "timer/env.step_frac": 0.037035572849119326, "timer/env.step_avg": 0.009153146812095943, "timer/env.step_min": 0.007483959197998047, "timer/env.step_max": 0.04518604278564453, "timer/replay._sample_count": 32384.0, "timer/replay._sample_total": 16.71303677558899, "timer/replay._sample_frac": 0.01670565480537296, "timer/replay._sample_avg": 0.0005160893273094426, "timer/replay._sample_min": 0.0003910064697265625, "timer/replay._sample_max": 0.011250019073486328, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5204.0, "timer/agent.policy_total": 52.31562399864197, "timer/agent.policy_frac": 0.052292516745102324, "timer/agent.policy_avg": 0.010052963873682161, "timer/agent.policy_min": 0.0075528621673583984, "timer/agent.policy_max": 0.08522391319274902, "timer/dataset_train_count": 2024.0, "timer/dataset_train_total": 0.2055191993713379, "timer/dataset_train_frac": 0.0002054284237314017, "timer/dataset_train_avg": 0.00010154110640876378, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.0007359981536865234, "timer/agent.train_count": 2024.0, "timer/agent.train_total": 895.4810009002686, "timer/agent.train_frac": 0.8950854764862183, "timer/agent.train_avg": 0.44243132455546863, "timer/agent.train_min": 0.4323151111602783, "timer/agent.train_max": 1.3102142810821533, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4860982894897461, "timer/agent.report_frac": 0.00048588358505612, "timer/agent.report_avg": 0.24304914474487305, "timer/agent.report_min": 0.23610281944274902, "timer/agent.report_max": 0.24999547004699707, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.0504098835998905e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 32.368905082699676}
{"step": 292304, "time": 9243.590710163116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292456, "time": 9248.04840707779, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 292504, "time": 9249.502403259277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292560, "time": 9251.409410238266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292576, "time": 9251.89803481102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292696, "time": 9255.292027950287, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 292744, "time": 9256.724360227585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292792, "time": 9258.18567276001, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 293864, "time": 9290.447086334229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294208, "time": 9301.060483932495, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 294432, "time": 9307.864518880844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294816, "time": 9319.41003370285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294872, "time": 9320.88933801651, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 294872, "time": 9320.898152828217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294888, "time": 9321.391737222672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295008, "time": 9325.664461612701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295056, "time": 9327.106694698334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295104, "time": 9328.543910264969, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295232, "time": 9332.393232822418, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 295440, "time": 9338.757221460342, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 295528, "time": 9341.185823202133, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 296520, "time": 9371.099891424179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297184, "time": 9391.216673135757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297184, "time": 9391.225982904434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297264, "time": 9393.639597654343, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 297320, "time": 9395.100925207138, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297368, "time": 9396.617824077606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297544, "time": 9401.909336090088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297752, "time": 9408.174689292908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297840, "time": 9411.026484489441, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298016, "time": 9416.314375400543, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 298480, "time": 9430.347103118896, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 298528, "time": 9431.8032412529, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 299376, "time": 9457.35404753685, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 299432, "time": 9458.82813668251, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 299496, "time": 9460.764001607895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299496, "time": 9460.771045207977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299552, "time": 9462.684758901596, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 299632, "time": 9465.103749990463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299856, "time": 9471.82983970642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 9477.725242137909, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 300040, "time": 9477.802911758423, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 300040, "time": 9478.856051445007, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 300040, "time": 9478.932221889496, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 300040, "time": 9479.436366558075, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 300040, "time": 9481.718280553818, "eval_episode/length": 159.0, "eval_episode/score": 0.503125011920929, "eval_episode/reward_rate": 0.00625}
{"step": 300040, "time": 9481.84668469429, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 300040, "time": 9481.99303483963, "eval_episode/length": 239.0, "eval_episode/score": 0.25312501192092896, "eval_episode/reward_rate": 0.004166666666666667}
{"step": 300216, "time": 9487.351397037506, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 300304, "time": 9490.233501672745, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 300656, "time": 9500.81102180481, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 300696, "time": 9501.795923948288, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 300776, "time": 9504.232185125351, "episode/length": 286.0, "episode/score": 0.10625000298023224, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.0}
{"step": 300928, "time": 9509.010512828827, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 301328, "time": 9521.129737138748, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 301616, "time": 9529.772543668747, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 301648, "time": 9530.734892368317, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 301656, "time": 9530.760773658752, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 301792, "time": 9535.080789804459, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 301808, "time": 9535.566043376923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302616, "time": 9559.636847734451, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302968, "time": 9570.179116725922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303048, "time": 9572.588955163956, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
