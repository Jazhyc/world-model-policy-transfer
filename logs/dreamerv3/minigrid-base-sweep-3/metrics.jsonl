{"step": 1560, "time": 107.65491032600403, "eval_episode/length": 182.0, "eval_episode/score": 0.4312500059604645, "eval_episode/reward_rate": 0.00546448087431694}
{"step": 1560, "time": 131.63104844093323, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 131.64013814926147, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 131.6471974849701, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 131.6538655757904, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 131.66079664230347, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 131.66770839691162, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 131.67558455467224, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 131.68319511413574, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 251.9951617717743, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.356689453125, "train/action_min": 0.0, "train/action_std": 2.234095335006714, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0006041413871571422, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.0872703790664673, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.7338331937789917, "train/cont_loss_std": 0.30886268615722656, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.5029296875, "train/cont_pos_loss": 0.7338331937789917, "train/cont_pred": 0.5018062591552734, "train/cont_rate": 1.0, "train/dyn_loss_mean": 11.2598876953125, "train/dyn_loss_std": 0.40639692544937134, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.539689540863037, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 25235.87890625, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 4935.29296875, "train/image_loss_std": 37.859474182128906, "train/model_loss_mean": 4948.32421875, "train/model_loss_std": 37.8515510559082, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 49483244.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9406359195709229, "train/policy_entropy_max": 1.9406359195709229, "train/policy_entropy_mean": 1.582807183265686, "train/policy_entropy_min": 0.6340340971946716, "train/policy_entropy_std": 0.15874996781349182, "train/policy_logprob_mag": 4.737586498260498, "train/policy_logprob_max": -0.18717829883098602, "train/policy_logprob_mean": -1.5896981954574585, "train/policy_logprob_min": -4.737586498260498, "train/policy_logprob_std": 0.784751296043396, "train/policy_randomness_mag": 0.9972896575927734, "train/policy_randomness_max": 0.9972896575927734, "train/policy_randomness_mean": 0.8134020566940308, "train/policy_randomness_min": 0.32582908868789673, "train/policy_randomness_std": 0.08158134669065475, "train/post_ent_mag": 105.65184020996094, "train/post_ent_max": 105.65184020996094, "train/post_ent_mean": 105.23779296875, "train/post_ent_min": 104.84977722167969, "train/post_ent_std": 0.15793168544769287, "train/prior_ent_mag": 106.38599395751953, "train/prior_ent_max": 106.38599395751953, "train/prior_ent_mean": 105.45213317871094, "train/prior_ent_min": 104.28263854980469, "train/prior_ent_std": 0.3317694067955017, "train/rep_loss_mean": 11.2598876953125, "train/rep_loss_std": 0.40639692544937134, "train/reward_avg": 0.0, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 0.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.7517202496528625, "report/cont_loss_std": 0.30447548627853394, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.4716796875, "report/cont_pos_loss": 0.7517202496528625, "report/cont_pred": 0.4921284019947052, "report/cont_rate": 1.0, "report/dyn_loss_mean": 11.400564193725586, "report/dyn_loss_std": 0.45425984263420105, "report/image_loss_mean": 4930.9501953125, "report/image_loss_std": 39.556297302246094, "report/model_loss_mean": 4944.08349609375, "report/model_loss_std": 39.554237365722656, "report/post_ent_mag": 105.67018127441406, "report/post_ent_max": 105.67018127441406, "report/post_ent_mean": 105.2440185546875, "report/post_ent_min": 104.70077514648438, "report/post_ent_std": 0.15602999925613403, "report/prior_ent_mag": 106.13672637939453, "report/prior_ent_max": 106.13672637939453, "report/prior_ent_mean": 105.41650390625, "report/prior_ent_min": 104.4444580078125, "report/prior_ent_std": 0.2970505952835083, "report/rep_loss_mean": 11.400564193725586, "report/rep_loss_std": 0.45425984263420105, "report/reward_avg": 0.0, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.7245990633964539, "eval/cont_loss_std": 0.27556681632995605, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.5068359375, "eval/cont_pos_loss": 0.7245990633964539, "eval/cont_pred": 0.5020435452461243, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 11.385530471801758, "eval/dyn_loss_std": 0.4139966368675232, "eval/image_loss_mean": 4927.07373046875, "eval/image_loss_std": 41.42363739013672, "eval/model_loss_mean": 4940.17138671875, "eval/model_loss_std": 41.40325164794922, "eval/post_ent_mag": 105.68858337402344, "eval/post_ent_max": 105.68858337402344, "eval/post_ent_mean": 105.22066497802734, "eval/post_ent_min": 104.88358306884766, "eval/post_ent_std": 0.1498301774263382, "eval/prior_ent_mag": 106.30752563476562, "eval/prior_ent_max": 106.30752563476562, "eval/prior_ent_mean": 105.43766784667969, "eval/prior_ent_min": 104.51127624511719, "eval/prior_ent_std": 0.29460200667381287, "eval/rep_loss_mean": 11.385530471801758, "eval/rep_loss_std": 0.4139966368675232, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.5182549251964212e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.748603820800781e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.314700074546977e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.032437597002302e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 147.1274642944336, "timer/env.step_count": 196.0, "timer/env.step_total": 1.363821029663086, "timer/env.step_frac": 0.009269656322858848, "timer/env.step_avg": 0.006958270559505541, "timer/env.step_min": 0.006171464920043945, "timer/env.step_max": 0.015253782272338867, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.10645866394042969, "timer/replay._sample_frac": 0.0007235811780687192, "timer/replay._sample_avg": 0.0009505237851824079, "timer/replay._sample_min": 0.0003485679626464844, "timer/replay._sample_max": 0.006295442581176758, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.086638927459717, "timer/agent.save_frac": 0.014182524911079178, "timer/agent.save_avg": 2.086638927459717, "timer/agent.save_min": 2.086638927459717, "timer/agent.save_max": 2.086638927459717, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 22.543010234832764, "timer/agent.policy_frac": 0.1532209526137103, "timer/agent.policy_avg": 0.07773451805114746, "timer/agent.policy_min": 0.009075403213500977, "timer/agent.policy_max": 17.153792142868042, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.314018249511719e-05, "timer/dataset_train_frac": 2.2524810479161512e-07, "timer/dataset_train_avg": 3.314018249511719e-05, "timer/dataset_train_min": 3.314018249511719e-05, "timer/dataset_train_max": 3.314018249511719e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 93.47375631332397, "timer/agent.train_frac": 0.6353250004109563, "timer/agent.train_avg": 93.47375631332397, "timer/agent.train_min": 93.47375631332397, "timer/agent.train_max": 93.47375631332397, "timer/agent.report_count": 2.0, "timer/agent.report_total": 24.288530826568604, "timer/agent.report_frac": 0.16508495502894038, "timer/agent.report_avg": 12.144265413284302, "timer/agent.report_min": 0.24603867530822754, "timer/agent.report_max": 24.042492151260376, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.8623809814453125e-05, "timer/dataset_eval_frac": 2.62519373929796e-07, "timer/dataset_eval_avg": 3.8623809814453125e-05, "timer/dataset_eval_min": 3.8623809814453125e-05, "timer/dataset_eval_max": 3.8623809814453125e-05}
{"step": 2312, "time": 275.08104729652405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 275.08868956565857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 275.09981298446655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 275.11290669441223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 275.1205940246582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 275.1280930042267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 275.135240316391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 275.1426033973694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 346.54515862464905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 346.5587377548218, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 346.5717942714691, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 346.5799160003662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 346.5876154899597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 346.5948078632355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 346.6022117137909, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 346.6096861362457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 417.38499426841736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 417.3935012817383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 417.4132363796234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 417.422075510025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 417.431170463562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 417.4506950378418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 417.46862506866455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 417.47650623321533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 489.43786215782166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 489.4468126296997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 489.45413279533386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 489.46127438545227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 489.46835684776306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 489.4757556915283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 489.48514914512634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 489.4921245574951, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 520.1078147888184, "eval_episode/length": 237.0, "eval_episode/score": 0.2593750059604645, "eval_episode/reward_rate": 0.004201680672268907}
{"step": 10088, "time": 521.1355891227722, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 521.1430535316467, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 521.1496071815491, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 521.1559274196625, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 521.1622588634491, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 521.1685528755188, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 521.1748352050781, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 11560, "time": 566.516993522644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 566.5255088806152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 566.5330922603607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 566.5429804325104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 566.5525417327881, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 566.560802936554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 566.5679273605347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 566.5750086307526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13088, "time": 613.6646127700806, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 13832, "time": 636.1853361129761, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 637.6540715694427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 637.6630353927612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 637.6706464290619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 637.6810204982758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 637.6879875659943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 637.6955418586731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 14040, "time": 642.5935349464417, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 14392, "time": 653.3492407798767, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 14664, "time": 661.7927222251892, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 16144, "time": 707.3915915489197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 708.394481420517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 708.406831741333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 708.4192519187927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 708.4262025356293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16352, "time": 713.7971351146698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16704, "time": 725.1296226978302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16976, "time": 733.4744346141815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18456, "time": 778.8985388278961, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 780.4726853370667, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 780.4971346855164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 780.5176451206207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 780.5312106609344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 780.5471239089966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18664, "time": 785.5259482860565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 19016, "time": 796.2985830307007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 833.192803144455, "eval_episode/length": 229.0, "eval_episode/score": 0.28437501192092896, "eval_episode/reward_rate": 0.004347826086956522}
{"step": 20072, "time": 834.9551589488983, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 834.9649906158447, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 834.9721586704254, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 834.979339838028, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 834.9882822036743, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 834.9989132881165, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 835.0055894851685, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20768, "time": 856.7128422260284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 857.7141494750977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 857.7225937843323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 857.7301924228668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 857.7376847267151, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 857.7450692653656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20976, "time": 863.0775203704834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 21328, "time": 874.0927004814148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 21328, "time": 874.0996062755585, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 23080, "time": 927.5293686389923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 928.977103471756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 928.987560749054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 928.995124578476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 929.0024058818817, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23288, "time": 934.051860332489, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23640, "time": 944.8168892860413, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23640, "time": 944.8257546424866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25392, "time": 999.6640179157257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1000.6875474452972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1000.6966545581818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1000.7052302360535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1000.7132678031921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25600, "time": 1006.1663074493408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25952, "time": 1016.897866487503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25952, "time": 1016.9098145961761, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27704, "time": 1070.6377484798431, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1072.0945250988007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1072.1035590171814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1072.1120166778564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1072.1216580867767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27912, "time": 1077.1010839939117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 28264, "time": 1088.1859412193298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 28264, "time": 1088.1941723823547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30016, "time": 1142.2997951507568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1143.3212082386017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1143.3294990062714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1143.3439357280731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1143.355572462082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1149.1088881492615, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1149.116816997528, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1149.125649213791, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1149.1326839923859, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1149.1392016410828, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1149.1455478668213, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1149.1519892215729, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1149.1612861156464, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30224, "time": 1154.51331949234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30576, "time": 1165.3714065551758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30576, "time": 1165.3798098564148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32328, "time": 1219.2667722702026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1220.7069182395935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1220.7149391174316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1220.7222049236298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1220.7300336360931, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32536, "time": 1225.6279163360596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32601, "time": 1228.6005940437317, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9995066849226806, "train/action_min": 0.0, "train/action_std": 2.0004741930470025, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00015208029767516977, "train/actor_opt_grad_steps": 975.0, "train/actor_opt_loss": -1.0409959910303046, "train/adv_mag": 0.00040651731754571966, "train/adv_max": 0.0004064631062710728, "train/adv_mean": 0.0002421705310121777, "train/adv_min": 3.479826441598936e-05, "train/adv_std": 0.00011247365567555976, "train/cont_avg": 0.9970048727448454, "train/cont_loss_mean": 0.024663516175539052, "train/cont_loss_std": 0.2974265923895888, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.766932542507465, "train/cont_pos_acc": 0.9969343890234367, "train/cont_pos_loss": 0.007414037506830083, "train/cont_pred": 0.9940769942765383, "train/cont_rate": 0.9970048727448454, "train/dyn_loss_mean": 1.0686381938531226, "train/dyn_loss_std": 0.005652043040848269, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.371328509575927, "train/extr_critic_critic_opt_grad_steps": 975.0, "train/extr_critic_critic_opt_loss": 5734.71871193168, "train/extr_critic_mag": 0.0013312076784900784, "train/extr_critic_max": 0.0013312033771239605, "train/extr_critic_mean": 0.0013270965542895021, "train/extr_critic_min": 0.0013243279506250755, "train/extr_critic_std": 9.061328398941272e-07, "train/extr_return_normed_mag": 0.0006531171573954847, "train/extr_return_normed_max": 0.0006531070264471387, "train/extr_return_normed_mean": 0.0004904633223009177, "train/extr_return_normed_min": 0.00028455415978327316, "train/extr_return_normed_std": 0.0001124634357634952, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0017319262623838407, "train/extr_return_raw_max": 0.0017319114862288472, "train/extr_return_raw_mean": 0.0015692678402619044, "train/extr_return_raw_min": 0.0013633586168115394, "train/extr_return_raw_std": 0.00011246343675721154, "train/extr_reward_mag": 4.234449150636024e-05, "train/extr_reward_max": 4.234203358286435e-05, "train/extr_reward_mean": 4.22603945476872e-05, "train/extr_reward_min": 4.2016358719658604e-05, "train/extr_reward_std": 3.814127446981413e-08, "train/image_loss_mean": 26.51118494462721, "train/image_loss_std": 0.399126426652842, "train/model_loss_mean": 27.28515638334235, "train/model_loss_std": 0.6487005809610037, "train/model_opt_grad_norm": 102.25338819731085, "train/model_opt_grad_steps": 965.0, "train/model_opt_loss": 519.8544080626104, "train/model_opt_model_opt_grad_overflow": 0.005154639175257732, "train/model_opt_model_opt_grad_scale": 14.447084407216495, "train/policy_entropy_mag": 1.9457815043705027, "train/policy_entropy_max": 1.9457815043705027, "train/policy_entropy_mean": 1.940921172653277, "train/policy_entropy_min": 1.8641030665525455, "train/policy_entropy_std": 0.0032188532521141714, "train/policy_logprob_mag": 2.4024527662808133, "train/policy_logprob_max": -1.472741193070854, "train/policy_logprob_mean": -1.9409249228300507, "train/policy_logprob_min": -2.4024527662808133, "train/policy_logprob_std": 0.0857290732722307, "train/policy_randomness_mag": 0.9999339503725779, "train/policy_randomness_max": 0.9999339503725779, "train/policy_randomness_mean": 0.9974362275649592, "train/policy_randomness_min": 0.9579595319696308, "train/policy_randomness_std": 0.001654163460228016, "train/post_ent_mag": 77.61075489791398, "train/post_ent_max": 77.61075489791398, "train/post_ent_mean": 77.57616629059781, "train/post_ent_min": 77.3399058469792, "train/post_ent_std": 0.04665560390531402, "train/prior_ent_mag": 83.56519490664768, "train/prior_ent_max": 83.56519490664768, "train/prior_ent_mean": 83.45121438724479, "train/prior_ent_min": 83.00988285811906, "train/prior_ent_std": 0.08770736706318315, "train/rep_loss_mean": 1.0686381938531226, "train/rep_loss_std": 0.005652043040848269, "train/reward_avg": 4.901689433459116e-05, "train/reward_loss_mean": 0.10812651104601004, "train/reward_loss_std": 0.0325071824528418, "train/reward_max_data": 0.04478092814229198, "train/reward_max_pred": 4.224863249002044e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.10700211436553743, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.366372632980347, "train/reward_pred": 4.2179964252353945e-05, "train/reward_rate": 0.0001208118556701031, "train_stats/mean_log_entropy": 1.926521516682809, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020065195858478546, "report/cont_loss_std": 0.3255501985549927, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.025856018066406, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002418405842036009, "report/cont_pred": 0.9975844025611877, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2606324255466461, "report/image_loss_std": 0.08357764035463333, "report/model_loss_mean": 0.8813284635543823, "report/model_loss_std": 0.3397057354450226, "report/post_ent_mag": 64.47997283935547, "report/post_ent_max": 64.47997283935547, "report/post_ent_mean": 64.45606994628906, "report/post_ent_min": 64.34286499023438, "report/post_ent_std": 0.02445986308157444, "report/prior_ent_mag": 73.43743896484375, "report/prior_ent_max": 73.43743896484375, "report/prior_ent_mean": 73.36627197265625, "report/prior_ent_min": 72.98816680908203, "report/prior_ent_std": 0.06544282287359238, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0006308555603027344, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 7.915496826171875e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0006308555603027344, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.903727237135172e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.002418405842036009, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002418405842036009, "eval/cont_pred": 0.9975844025611877, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.25625675916671753, "eval/image_loss_std": 0.08065047860145569, "eval/model_loss_mean": 0.8593060374259949, "eval/model_loss_std": 0.08065047860145569, "eval/post_ent_mag": 64.48319244384766, "eval/post_ent_max": 64.48319244384766, "eval/post_ent_mean": 64.4577407836914, "eval/post_ent_min": 64.33172607421875, "eval/post_ent_std": 0.022973697632551193, "eval/prior_ent_mag": 73.43338012695312, "eval/prior_ent_max": 73.43338012695312, "eval/prior_ent_mean": 73.36763763427734, "eval/prior_ent_min": 72.98816680908203, "eval/prior_ent_std": 0.06011456623673439, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0006308555603027344, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 7.915496826171875e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0006308555603027344, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.903773803263903e-05, "eval/reward_rate": 0.0, "replay/size": 32097.0, "replay/inserts": 31040.0, "replay/samples": 31040.0, "replay/insert_wait_avg": 1.33891541933276e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.187804025473054e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10304.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2515600439861433e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 976.5944933891296, "timer/env.step_count": 3880.0, "timer/env.step_total": 39.42630124092102, "timer/env.step_frac": 0.040371209860192596, "timer/env.step_avg": 0.010161417845598202, "timer/env.step_min": 0.008245229721069336, "timer/env.step_max": 0.03697991371154785, "timer/replay._sample_count": 31040.0, "timer/replay._sample_total": 16.541332006454468, "timer/replay._sample_frac": 0.016937769072453167, "timer/replay._sample_avg": 0.0005329037373213424, "timer/replay._sample_min": 0.00036525726318359375, "timer/replay._sample_max": 0.011629581451416016, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4747.0, "timer/agent.policy_total": 51.76839566230774, "timer/agent.policy_frac": 0.05300910051484422, "timer/agent.policy_avg": 0.010905497295619916, "timer/agent.policy_min": 0.009272098541259766, "timer/agent.policy_max": 0.09038567543029785, "timer/dataset_train_count": 1940.0, "timer/dataset_train_total": 0.21365714073181152, "timer/dataset_train_frac": 0.00021877774468126007, "timer/dataset_train_avg": 0.00011013254676897501, "timer/dataset_train_min": 8.082389831542969e-05, "timer/dataset_train_max": 0.00035500526428222656, "timer/agent.train_count": 1940.0, "timer/agent.train_total": 870.6175584793091, "timer/agent.train_frac": 0.8914831737970967, "timer/agent.train_avg": 0.4487719373604686, "timer/agent.train_min": 0.43622422218322754, "timer/agent.train_max": 0.7314231395721436, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47589802742004395, "timer/agent.report_frac": 0.00048730361541207223, "timer/agent.report_avg": 0.23794901371002197, "timer/agent.report_min": 0.23103117942810059, "timer/agent.report_max": 0.24486684799194336, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.2957904633490534e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 31.78338118226669}
{"step": 32888, "time": 1237.7514157295227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32888, "time": 1237.7614641189575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 33264, "time": 1249.472477197647, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 33552, "time": 1258.2989132404327, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 34640, "time": 1291.7339701652527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1292.7458946704865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1292.7537393569946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1292.7610383033752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34848, "time": 1298.0987906455994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35200, "time": 1308.8735349178314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35576, "time": 1320.2402851581573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35864, "time": 1329.1439321041107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36952, "time": 1362.5679981708527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1364.0419561862946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1364.0506575107574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1364.058622598648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 37160, "time": 1369.0858502388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 37512, "time": 1379.9300837516785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 37888, "time": 1391.7644600868225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38176, "time": 1400.555002450943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39264, "time": 1433.9337334632874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1434.9524915218353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1434.965747833252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1434.9732580184937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39472, "time": 1440.4096443653107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39824, "time": 1451.6202235221863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 1463.5239701271057, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1463.5327105522156, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1463.5404942035675, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1463.5468771457672, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1463.553103685379, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1463.5594131946564, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1463.5664160251617, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1463.576245546341, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40200, "time": 1468.512315273285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40488, "time": 1477.4764893054962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40960, "time": 1492.2704765796661, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 41576, "time": 1511.2650527954102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1512.7136805057526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1512.7275421619415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1512.7384278774261, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41784, "time": 1517.6578574180603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42136, "time": 1528.4528079032898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42504, "time": 1539.794340133667, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 42512, "time": 1540.28773021698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43272, "time": 1563.333306312561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43888, "time": 1582.419909954071, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1583.4165585041046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1583.4247024059296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44096, "time": 1588.791608095169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44448, "time": 1599.6071791648865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44816, "time": 1610.790779352188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44824, "time": 1610.821459054947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45144, "time": 1620.6642849445343, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 45584, "time": 1634.3161268234253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46200, "time": 1652.9625124931335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1654.4110133647919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46408, "time": 1659.321903705597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46760, "time": 1670.0610463619232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47128, "time": 1681.3362138271332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47136, "time": 1681.8052172660828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47456, "time": 1691.5403454303741, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47896, "time": 1704.6956951618195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48512, "time": 1723.722587108612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1724.7244634628296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48720, "time": 1730.0879139900208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49072, "time": 1740.947546005249, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49440, "time": 1752.7603242397308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49448, "time": 1752.791671037674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49768, "time": 1762.5202453136444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 1775.999053478241, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1776.007423400879, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1776.015392780304, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1776.033721446991, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1776.041143655777, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1776.048368215561, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1776.055341720581, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1776.062245130539, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50208, "time": 1781.9211065769196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50824, "time": 1800.6476881504059, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1802.1000454425812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51032, "time": 1806.9847764968872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51384, "time": 1817.654232263565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51752, "time": 1828.8589506149292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51760, "time": 1829.3291540145874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52080, "time": 1839.1746249198914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52520, "time": 1852.3772835731506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53136, "time": 1871.5326881408691, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1872.5236387252808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53344, "time": 1877.8616857528687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53696, "time": 1888.6055998802185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54064, "time": 1899.8486523628235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54072, "time": 1899.8802978992462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54392, "time": 1909.5686705112457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54832, "time": 1923.2683947086334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55448, "time": 1941.7905588150024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 1943.2469506263733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55656, "time": 1948.122623205185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56008, "time": 1958.9894173145294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56376, "time": 1970.238513469696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56384, "time": 1970.7092957496643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56704, "time": 1980.5772941112518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57144, "time": 1993.742684841156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57760, "time": 2013.23073387146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57800, "time": 2014.2245361804962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57968, "time": 2019.5667362213135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58320, "time": 2030.2369441986084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58688, "time": 2041.5759994983673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58696, "time": 2041.6060976982117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59016, "time": 2051.3540947437286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59456, "time": 2064.94832611084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59808, "time": 2075.8028197288513, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 2088.0297513008118, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2088.0375933647156, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2088.0442242622375, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2088.0507996082306, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2088.057219028473, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2088.06347823143, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2088.0698754787445, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2088.076637983322, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60072, "time": 2090.0268411636353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60112, "time": 2091.487576007843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60280, "time": 2096.378695011139, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60632, "time": 2107.214893102646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61000, "time": 2118.444491624832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61008, "time": 2118.9228839874268, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61768, "time": 2142.162841796875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62120, "time": 2152.9004974365234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62384, "time": 2161.2984249591827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62424, "time": 2162.3107476234436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62592, "time": 2167.676116466522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62944, "time": 2178.389890909195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63312, "time": 2189.5605478286743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63320, "time": 2189.5898060798645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64080, "time": 2212.951125383377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64320, "time": 2220.2745044231415, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 64432, "time": 2223.7753994464874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64569, "time": 2228.639160633087, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9995374823335426, "train/action_min": 0.0, "train/action_std": 1.999645725566538, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00019071385288418297, "train/actor_opt_grad_steps": 2940.0, "train/actor_opt_loss": 1.6840974793362258, "train/adv_mag": 0.0006829820685650236, "train/adv_max": 0.0006829820685650236, "train/adv_mean": 0.00038649147611076885, "train/adv_min": 2.1165775032199207e-05, "train/adv_std": 0.00018060425854078612, "train/cont_avg": 0.9965157820351759, "train/cont_loss_mean": 0.023267430965858864, "train/cont_loss_std": 0.31896982579459005, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.671718253990529, "train/cont_pos_acc": 0.9999999865215627, "train/cont_pos_loss": 0.0035252613928075413, "train/cont_pred": 0.9964812209258727, "train/cont_rate": 0.9965157820351759, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08373072220190386, "train/extr_critic_critic_opt_grad_steps": 2940.0, "train/extr_critic_critic_opt_loss": 6045.091994395807, "train/extr_critic_mag": 0.015049751080460284, "train/extr_critic_max": 0.015049751080460284, "train/extr_critic_mean": 0.015007950927144917, "train/extr_critic_min": 0.014975795194731285, "train/extr_critic_std": 1.0535164938877423e-05, "train/extr_return_normed_mag": 0.0013452489209834055, "train/extr_return_normed_max": 0.0013452489209834055, "train/extr_return_normed_mean": 0.0010745635703112463, "train/extr_return_normed_min": 0.0007260907488177769, "train/extr_return_normed_std": 0.0001798954053719624, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.01566513118582155, "train/extr_return_raw_max": 0.01566513118582155, "train/extr_return_raw_mean": 0.015394446662341679, "train/extr_return_raw_min": 0.015045973013655924, "train/extr_return_raw_std": 0.00017989540554563476, "train/extr_reward_mag": 0.00010631252173802361, "train/extr_reward_max": 0.00010631252173802361, "train/extr_reward_mean": 0.00010616091608266398, "train/extr_reward_min": 0.00010597346416070833, "train/extr_reward_std": 5.4161090240841404e-08, "train/image_loss_mean": 0.27043959902758574, "train/image_loss_std": 0.08621595537842218, "train/model_loss_mean": 0.8965525474380608, "train/model_loss_std": 0.3864599721290957, "train/model_opt_grad_norm": 80.38966868031564, "train/model_opt_grad_steps": 2930.0, "train/model_opt_loss": 50.54440077585192, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 56.434516331658294, "train/policy_entropy_mag": 1.9458858439670734, "train/policy_entropy_max": 1.9458858439670734, "train/policy_entropy_mean": 1.9447061182865546, "train/policy_entropy_min": 1.9210243422781403, "train/policy_entropy_std": 0.0008696459526846644, "train/policy_logprob_mag": 2.2243634935599474, "train/policy_logprob_max": -1.6671890355833812, "train/policy_logprob_mean": -1.9446869118129788, "train/policy_logprob_min": -2.2243634935599474, "train/policy_logprob_std": 0.04867670993933726, "train/policy_randomness_mag": 0.999987568687554, "train/policy_randomness_max": 0.999987568687554, "train/policy_randomness_mean": 0.9993813049853147, "train/policy_randomness_min": 0.9872112837269078, "train/policy_randomness_std": 0.0004469096409355819, "train/post_ent_mag": 57.170525977359944, "train/post_ent_max": 57.170525977359944, "train/post_ent_mean": 57.13852287177465, "train/post_ent_min": 57.04080844284901, "train/post_ent_std": 0.02278549087481882, "train/prior_ent_mag": 64.3507254327362, "train/prior_ent_max": 64.3507254327362, "train/prior_ent_mean": 64.2694822148462, "train/prior_ent_min": 63.676995703922444, "train/prior_ent_std": 0.10231137467576332, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00014794124405884918, "train/reward_loss_mean": 0.002845492567305439, "train/reward_loss_std": 0.07276359412577758, "train/reward_max_data": 0.14060929664714852, "train/reward_max_pred": 0.00010639399140324424, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00043249800441501167, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.241837918758392, "train/reward_pred": 0.00010622515350149654, "train/reward_rate": 0.00026008951005025124, "train_stats/mean_log_entropy": 1.9367873837462568, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.03095763921737671, "report/cont_loss_std": 0.3852907717227936, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.531312465667725, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003968651872128248, "report/cont_pred": 0.9960393309593201, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2735448479652405, "report/image_loss_std": 0.07790598273277283, "report/model_loss_mean": 0.9047413468360901, "report/model_loss_std": 0.3896769881248474, "report/post_ent_mag": 51.20104217529297, "report/post_ent_max": 51.20104217529297, "report/post_ent_mean": 51.15558624267578, "report/post_ent_min": 51.09450149536133, "report/post_ent_std": 0.014859449118375778, "report/prior_ent_mag": 55.99235153198242, "report/prior_ent_max": 55.99235153198242, "report/prior_ent_mean": 55.883880615234375, "report/prior_ent_min": 54.51483917236328, "report/prior_ent_std": 0.24098633229732513, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00023887958377599716, "report/reward_loss_std": 8.543329954591172e-08, "report/reward_max_data": 0.0, "report/reward_max_pred": 6.639957427978516e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00023887958377599716, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 6.639643106609583e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0039686523377895355, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0039686523377895355, "eval/cont_pred": 0.9960393309593201, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.25382161140441895, "eval/image_loss_std": 0.08025643974542618, "eval/model_loss_mean": 0.8580291271209717, "eval/model_loss_std": 0.08025642484426498, "eval/post_ent_mag": 51.1994743347168, "eval/post_ent_max": 51.1994743347168, "eval/post_ent_mean": 51.155792236328125, "eval/post_ent_min": 51.094966888427734, "eval/post_ent_std": 0.013844726607203484, "eval/prior_ent_mag": 55.994422912597656, "eval/prior_ent_max": 55.994422912597656, "eval/prior_ent_mean": 55.898990631103516, "eval/prior_ent_min": 54.51483917236328, "eval/prior_ent_std": 0.21381191909313202, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00023888563737273216, "eval/reward_loss_std": 6.758187254263248e-08, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 6.639957427978516e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00023888563737273216, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 6.639747880399227e-05, "eval/reward_rate": 0.0, "replay/size": 64065.0, "replay/inserts": 31968.0, "replay/samples": 31968.0, "replay/insert_wait_avg": 1.3060964740909732e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.957205161437377e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17240.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.212373599324122e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0255768299103, "timer/env.step_count": 3996.0, "timer/env.step_total": 40.13598346710205, "timer/env.step_frac": 0.04013495694213488, "timer/env.step_avg": 0.010044039906682196, "timer/env.step_min": 0.008284807205200195, "timer/env.step_max": 0.039946794509887695, "timer/replay._sample_count": 31968.0, "timer/replay._sample_total": 16.783193826675415, "timer/replay._sample_frac": 0.016782764576760412, "timer/replay._sample_avg": 0.0005249998068904972, "timer/replay._sample_min": 0.00036835670471191406, "timer/replay._sample_max": 0.011331558227539062, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4863.0, "timer/agent.policy_total": 52.038493156433105, "timer/agent.policy_frac": 0.05203716221078623, "timer/agent.policy_avg": 0.010700903384008453, "timer/agent.policy_min": 0.009099721908569336, "timer/agent.policy_max": 0.08621335029602051, "timer/dataset_train_count": 1998.0, "timer/dataset_train_total": 0.2128744125366211, "timer/dataset_train_frac": 0.0002128689680232328, "timer/dataset_train_avg": 0.00010654375001832887, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.0009882450103759766, "timer/agent.train_count": 1998.0, "timer/agent.train_total": 893.2289161682129, "timer/agent.train_frac": 0.8932060707884655, "timer/agent.train_avg": 0.44706151960371016, "timer/agent.train_min": 0.4349100589752197, "timer/agent.train_max": 0.8434731960296631, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47519898414611816, "timer/agent.report_frac": 0.0004751868303733821, "timer/agent.report_avg": 0.23759949207305908, "timer/agent.report_min": 0.23084235191345215, "timer/agent.report_max": 0.24435663223266602, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.3377747377251294e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 31.96667547593968}
{"step": 64696, "time": 2232.2879424095154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64736, "time": 2233.73353266716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64904, "time": 2238.638279914856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65256, "time": 2249.402025938034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65624, "time": 2261.16201710701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65632, "time": 2261.6337978839874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66632, "time": 2291.801219701767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66744, "time": 2295.193470478058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67008, "time": 2303.4042756557465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67048, "time": 2304.4007272720337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67216, "time": 2309.73614859581, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67568, "time": 2320.4924821853638, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67936, "time": 2331.6782126426697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67944, "time": 2331.708151102066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68944, "time": 2362.4687712192535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69056, "time": 2365.873281955719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69320, "time": 2373.8227796554565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69360, "time": 2375.262538909912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69528, "time": 2380.149546146393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69880, "time": 2390.8107039928436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 2403.4545726776123, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2403.4618277549744, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2403.468193769455, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2403.4745280742645, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2403.4806337356567, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2403.486669063568, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2403.492717027664, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2403.49888920784, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70248, "time": 2407.9204185009003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70256, "time": 2408.3933873176575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71256, "time": 2438.6173045635223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71368, "time": 2442.020777463913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71632, "time": 2450.2665572166443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71672, "time": 2451.2595698833466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71776, "time": 2454.630688428879, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 72192, "time": 2467.379847764969, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72560, "time": 2478.529723882675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72568, "time": 2478.612118244171, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73568, "time": 2509.652351140976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73680, "time": 2513.0840537548065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73944, "time": 2521.5410103797913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73984, "time": 2522.9864332675934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74088, "time": 2525.951225757599, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74504, "time": 2538.70166683197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74872, "time": 2549.949457883835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74880, "time": 2550.5170154571533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75880, "time": 2580.91752576828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75992, "time": 2584.362329721451, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76256, "time": 2592.6057426929474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76296, "time": 2593.632050514221, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76400, "time": 2597.019693136215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76816, "time": 2609.6816210746765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77184, "time": 2620.9892740249634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77192, "time": 2621.020768880844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78192, "time": 2652.0729200839996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78304, "time": 2655.5037035942078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78568, "time": 2663.4044392108917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78608, "time": 2664.860815048218, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78704, "time": 2667.818158388138, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 78712, "time": 2667.8600080013275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79128, "time": 2680.7262196540833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79496, "time": 2692.034151315689, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79504, "time": 2692.5090293884277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 2715.8742804527283, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2715.8823461532593, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2715.8894743919373, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2715.8978910446167, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2715.9116084575653, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2715.9189665317535, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2715.9257192611694, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2715.93199467659, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80504, "time": 2728.668083190918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80616, "time": 2732.1987426280975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80880, "time": 2740.4927599430084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81016, "time": 2744.432759284973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81024, "time": 2744.9061286449432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81336, "time": 2754.276123523712, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 81440, "time": 2757.70525932312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81808, "time": 2769.0518431663513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81816, "time": 2769.0835676193237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82816, "time": 2800.374133348465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83192, "time": 2811.6046149730682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83328, "time": 2816.065688610077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83336, "time": 2816.0959453582764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83648, "time": 2825.9278786182404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83752, "time": 2828.854949951172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84120, "time": 2840.002168416977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84128, "time": 2840.4736371040344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85128, "time": 2870.7499108314514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85504, "time": 2882.555155992508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85640, "time": 2886.556974887848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85648, "time": 2887.0319476127625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85960, "time": 2896.42449760437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86064, "time": 2899.8704392910004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86432, "time": 2911.197785139084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86440, "time": 2911.2286615371704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87264, "time": 2936.7648067474365, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 87440, "time": 2942.2041761875153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87816, "time": 2953.9111609458923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87952, "time": 2958.291308403015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87960, "time": 2958.3212327957153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88272, "time": 2968.0224311351776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88376, "time": 2971.118973016739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88744, "time": 2982.3873631954193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89576, "time": 3008.131546497345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89752, "time": 3013.6148250102997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 3029.4414761066437, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3029.448617696762, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3029.455151081085, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3029.4621634483337, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3029.4686341285706, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3029.4748640060425, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3029.481017112732, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3029.487483739853, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90128, "time": 3032.0582950115204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90264, "time": 3035.967696905136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90272, "time": 3036.435567378998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90584, "time": 3045.703358888626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90688, "time": 3049.0990245342255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91056, "time": 3060.320918083191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91888, "time": 3085.864894628525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92064, "time": 3091.350048303604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92440, "time": 3102.6453013420105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92576, "time": 3106.9880719184875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92584, "time": 3107.0173921585083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92896, "time": 3116.684564590454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93000, "time": 3119.646407842636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93368, "time": 3130.996504306793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94200, "time": 3156.453576564789, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94376, "time": 3161.8071076869965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94432, "time": 3163.743963241577, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 94752, "time": 3173.5378334522247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94888, "time": 3177.4861941337585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94896, "time": 3177.962257385254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95208, "time": 3187.536968946457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95312, "time": 3190.9845809936523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95680, "time": 3202.3314628601074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96521, "time": 3229.0497477054596, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.999875793457031, "train/action_min": 0.0, "train/action_std": 2.000421824455261, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 5.695069764897198e-05, "train/actor_opt_grad_steps": 4935.0, "train/actor_opt_loss": -3.7897478447388857, "train/adv_mag": 0.0002566886320710182, "train/adv_max": 0.00023840393871068954, "train/adv_mean": 9.975737881404712e-05, "train/adv_min": -6.835144944489002e-05, "train/adv_std": 6.175347615339889e-05, "train/cont_avg": 0.9964794921875, "train/cont_loss_mean": 0.02345351197523996, "train/cont_loss_std": 0.3245060629420914, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.663880444052231, "train/cont_pos_acc": 0.9999999871850014, "train/cont_pos_loss": 0.0035294440283905716, "train/cont_pred": 0.9964769551157951, "train/cont_rate": 0.9964794921875, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.023348107836209237, "train/extr_critic_critic_opt_grad_steps": 4935.0, "train/extr_critic_critic_opt_loss": 8169.1016845703125, "train/extr_critic_mag": 0.023559197783470154, "train/extr_critic_max": 0.023559197783470154, "train/extr_critic_mean": 0.023492174874991178, "train/extr_critic_min": 0.023450894355773924, "train/extr_critic_std": 1.69500436628911e-05, "train/extr_return_normed_mag": 0.00040726320818066595, "train/extr_return_normed_max": 0.00039249580353498456, "train/extr_return_normed_mean": 0.0002907369403556004, "train/extr_return_normed_min": 0.0001623567193746567, "train/extr_return_normed_std": 5.7125728516211894e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0236936972849071, "train/extr_return_raw_max": 0.0236936972849071, "train/extr_return_raw_mean": 0.02359193959273398, "train/extr_return_raw_min": 0.023463558200746776, "train/extr_return_raw_std": 5.712572912955238e-05, "train/extr_reward_mag": 8.641958236694337e-05, "train/extr_reward_max": 8.641958236694337e-05, "train/extr_reward_mean": 8.634579016870702e-05, "train/extr_reward_min": 8.625864982604981e-05, "train/extr_reward_std": 2.9981370037179824e-08, "train/image_loss_mean": 0.2626587230712175, "train/image_loss_std": 0.08540075935423375, "train/model_loss_mean": 0.888001075387001, "train/model_loss_std": 0.37564743354916574, "train/model_opt_grad_norm": 65.6705107307434, "train/model_opt_grad_steps": 4925.0, "train/model_opt_loss": 199.80441570281982, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 225.0, "train/policy_entropy_mag": 1.9458973759412765, "train/policy_entropy_max": 1.9458973759412765, "train/policy_entropy_mean": 1.9452497202157975, "train/policy_entropy_min": 1.9310784620046615, "train/policy_entropy_std": 0.0004971936167567037, "train/policy_logprob_mag": 2.148935889005661, "train/policy_logprob_max": -1.7270355826616288, "train/policy_logprob_mean": -1.9452296948432923, "train/policy_logprob_min": -2.148935889005661, "train/policy_logprob_std": 0.03625064807012677, "train/policy_randomness_mag": 0.9999934968352318, "train/policy_randomness_max": 0.9999934968352318, "train/policy_randomness_mean": 0.9996606624126434, "train/policy_randomness_min": 0.992378080189228, "train/policy_randomness_std": 0.00025550698075676336, "train/post_ent_mag": 46.72196371078491, "train/post_ent_max": 46.72196371078491, "train/post_ent_mean": 46.69074909210205, "train/post_ent_min": 46.58123512268067, "train/post_ent_std": 0.027123793102800844, "train/prior_ent_mag": 52.56642698287964, "train/prior_ent_max": 52.56642698287964, "train/prior_ent_mean": 52.48535995483398, "train/prior_ent_min": 51.54706649780273, "train/prior_ent_std": 0.16235576171427965, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0001016693125711754, "train/reward_loss_mean": 0.0018888187361881137, "train/reward_loss_std": 0.05218870100851888, "train/reward_max_data": 0.10001562595367432, "train/reward_max_pred": 8.639872074127197e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00022888876119395719, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.708828379126157, "train/reward_pred": 8.634394151158631e-05, "train/reward_rate": 0.0001708984375, "train_stats/mean_log_entropy": 1.9364007743059006, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014790466986596584, "report/cont_loss_std": 0.2433481365442276, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.515749931335449, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0040253764018416405, "report/cont_pred": 0.9959827661514282, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.26783159375190735, "report/image_loss_std": 0.09441934525966644, "report/model_loss_mean": 0.8828166723251343, "report/model_loss_std": 0.26067036390304565, "report/post_ent_mag": 43.53722381591797, "report/post_ent_max": 43.53722381591797, "report/post_ent_mean": 43.508968353271484, "report/post_ent_min": 43.340606689453125, "report/post_ent_std": 0.04087257385253906, "report/prior_ent_mag": 49.519309997558594, "report/prior_ent_max": 49.519309997558594, "report/prior_ent_mean": 49.46630859375, "report/prior_ent_min": 48.9051513671875, "report/prior_ent_std": 0.09480957686901093, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.000194549560546875, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 8.428096771240234e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.000194549560546875, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 8.428096771240234e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.004025740083307028, "eval/cont_loss_std": 7.413095318042906e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004025740083307028, "eval/cont_pred": 0.9959824085235596, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2740457057952881, "eval/image_loss_std": 0.10105200856924057, "eval/model_loss_mean": 0.8782660365104675, "eval/model_loss_std": 0.10105207562446594, "eval/post_ent_mag": 43.53935241699219, "eval/post_ent_max": 43.53935241699219, "eval/post_ent_mean": 43.510562896728516, "eval/post_ent_min": 43.34603500366211, "eval/post_ent_std": 0.038973841816186905, "eval/prior_ent_mag": 49.52399826049805, "eval/prior_ent_max": 49.52399826049805, "eval/prior_ent_mean": 49.46980285644531, "eval/prior_ent_min": 48.9051513671875, "eval/prior_ent_std": 0.0898950845003128, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.000194549560546875, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 8.428096771240234e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.000194549560546875, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 8.428096771240234e-05, "eval/reward_rate": 0.0, "replay/size": 96017.0, "replay/inserts": 31952.0, "replay/samples": 31952.0, "replay/insert_wait_avg": 1.328165792618982e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.006482704556102e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24176.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1980396103556455e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3916325569153, "timer/env.step_count": 3994.0, "timer/env.step_total": 39.92676019668579, "timer/env.step_frac": 0.03991112969891243, "timer/env.step_avg": 0.009996685076786627, "timer/env.step_min": 0.007840394973754883, "timer/env.step_max": 0.06635093688964844, "timer/replay._sample_count": 31952.0, "timer/replay._sample_total": 16.864078760147095, "timer/replay._sample_frac": 0.01685747682339561, "timer/replay._sample_avg": 0.0005277941524833217, "timer/replay._sample_min": 0.0003955364227294922, "timer/replay._sample_max": 0.011701583862304688, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4861.0, "timer/agent.policy_total": 52.216877460479736, "timer/agent.policy_frac": 0.052196435636929384, "timer/agent.policy_avg": 0.010742003180514242, "timer/agent.policy_min": 0.008925199508666992, "timer/agent.policy_max": 0.09202837944030762, "timer/dataset_train_count": 1997.0, "timer/dataset_train_total": 0.21869301795959473, "timer/dataset_train_frac": 0.00021860740418293395, "timer/dataset_train_avg": 0.00010951077514251113, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.0010821819305419922, "timer/agent.train_count": 1997.0, "timer/agent.train_total": 893.7830119132996, "timer/agent.train_frac": 0.8934331144182671, "timer/agent.train_avg": 0.44756285023199777, "timer/agent.train_min": 0.43347668647766113, "timer/agent.train_max": 0.9680590629577637, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4812581539154053, "timer/agent.report_frac": 0.0004810697513386339, "timer/agent.report_avg": 0.24062907695770264, "timer/agent.report_min": 0.23363852500915527, "timer/agent.report_max": 0.24761962890625, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.193558258574474e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 31.938981757162743}
{"step": 96688, "time": 3234.1442925930023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96744, "time": 3235.645049095154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97064, "time": 3245.5569128990173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97200, "time": 3249.966612815857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97208, "time": 3249.996303319931, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97520, "time": 3259.753967523575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97624, "time": 3262.732120037079, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97992, "time": 3274.2337069511414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99000, "time": 3305.7815351486206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99056, "time": 3307.71728682518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99376, "time": 3317.506132364273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99512, "time": 3321.4674785137177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99520, "time": 3321.9462461471558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99776, "time": 3329.7740490436554, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 99832, "time": 3331.4134063720703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99936, "time": 3334.8101046085358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 3343.7804601192474, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3343.7884554862976, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3343.795230150223, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3343.801596403122, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3343.8078207969666, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3343.814046859741, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3343.820259332657, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3343.8264989852905, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100256, "time": 3350.171850204468, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 100304, "time": 3351.6619987487793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101368, "time": 3384.1672217845917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101688, "time": 3394.1250953674316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101824, "time": 3398.5265312194824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101832, "time": 3398.556215763092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102088, "time": 3406.410040140152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102144, "time": 3408.3519282341003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102568, "time": 3421.188822031021, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102616, "time": 3422.6655836105347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103680, "time": 3455.6527695655823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104000, "time": 3465.487470626831, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104056, "time": 3466.988980293274, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 104144, "time": 3469.90749502182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104400, "time": 3477.7065913677216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104456, "time": 3479.2035558223724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104880, "time": 3492.429469347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104928, "time": 3493.9097871780396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105992, "time": 3526.196666955948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106312, "time": 3535.9588928222656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106368, "time": 3537.9325926303864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106456, "time": 3540.533905982971, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106712, "time": 3549.0301139354706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106768, "time": 3550.9646627902985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107192, "time": 3563.7267673015594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107240, "time": 3565.2061791419983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108304, "time": 3598.028135061264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108624, "time": 3607.9246895313263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108680, "time": 3609.4031805992126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108768, "time": 3612.341852903366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109024, "time": 3620.1307334899902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109080, "time": 3621.635082960129, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109504, "time": 3634.8990137577057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109552, "time": 3636.381566762924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 3654.0735754966736, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 110032, "time": 3656.490685224533, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3656.498319387436, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3656.5049226284027, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3656.51127409935, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3656.5175309181213, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3656.5238587856293, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3656.530116558075, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110616, "time": 3674.3253178596497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110936, "time": 3684.114197254181, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110992, "time": 3686.0556881427765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111080, "time": 3688.5143637657166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111336, "time": 3696.4367883205414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111392, "time": 3698.3684780597687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111816, "time": 3711.0858256816864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111864, "time": 3712.5569314956665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112928, "time": 3745.4253368377686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113248, "time": 3755.3436467647552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113304, "time": 3756.838684797287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113392, "time": 3759.765156507492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113648, "time": 3767.57581114769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113704, "time": 3769.070787668228, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114128, "time": 3782.3602797985077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114176, "time": 3783.836347103119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115240, "time": 3816.6872022151947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115560, "time": 3826.4287350177765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115616, "time": 3828.3627161979675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115704, "time": 3830.8427135944366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115960, "time": 3838.6996722221375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116016, "time": 3840.722661972046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116440, "time": 3853.504863023758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116488, "time": 3854.970833301544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117552, "time": 3887.9503161907196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117872, "time": 3897.703108549118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117928, "time": 3899.1902322769165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118016, "time": 3902.1509630680084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118272, "time": 3909.9598245620728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118328, "time": 3911.445666074753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118752, "time": 3924.621068954468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118800, "time": 3926.080342054367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119864, "time": 3958.5583555698395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 3968.894404411316, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3968.9018182754517, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3968.9079864025116, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3968.914209842682, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3968.9203050136566, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3968.926396369934, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3968.9322547912598, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3968.9381697177887, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120184, "time": 3973.8385093212128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120240, "time": 3975.7621881961823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120328, "time": 3978.2637329101562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120584, "time": 3986.074917078018, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120640, "time": 3988.0328850746155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121064, "time": 4000.882398366928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121112, "time": 4002.3624539375305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122176, "time": 4035.2966895103455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122496, "time": 4045.08216047287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122552, "time": 4046.598675966263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122640, "time": 4049.532470226288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122896, "time": 4058.018547773361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122952, "time": 4059.511878013611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123376, "time": 4072.7082891464233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123424, "time": 4074.178543329239, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124488, "time": 4106.653001785278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124808, "time": 4116.539631843567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124864, "time": 4118.48935842514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124952, "time": 4120.97935795784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125208, "time": 4128.811656713486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125264, "time": 4130.763218164444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125688, "time": 4143.644618988037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125736, "time": 4145.164923191071, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126800, "time": 4178.106075763702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126968, "time": 4183.026622056961, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 127120, "time": 4187.901323080063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127176, "time": 4189.415298700333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127264, "time": 4192.323848962784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127520, "time": 4200.176859855652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127568, "time": 4201.770936727524, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 128048, "time": 4216.543980360031, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128441, "time": 4229.409108877182, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0017715454101563, "train/action_min": 0.0, "train/action_std": 1.9997771400213242, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 6.016116484943268e-05, "train/actor_opt_grad_steps": 6935.0, "train/actor_opt_loss": -4.427541918063071, "train/adv_mag": 0.00024369739927351474, "train/adv_max": 0.00019923463463783264, "train/adv_mean": 6.634721408431688e-05, "train/adv_min": -9.219011291861535e-05, "train/adv_std": 5.7421046440140346e-05, "train/cont_avg": 0.9963671875, "train/cont_loss_mean": 0.02404332091799006, "train/cont_loss_std": 0.3283607864379883, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.652338931308919, "train/cont_pos_acc": 0.9999999809265137, "train/cont_pos_loss": 0.0035531892930157484, "train/cont_pred": 0.9964532363414764, "train/cont_rate": 0.9963671875, "train/dyn_loss_mean": 1.0000000417232513, "train/dyn_loss_std": 3.600908166845329e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.014578502814983949, "train/extr_critic_critic_opt_grad_steps": 6935.0, "train/extr_critic_critic_opt_loss": 8682.336586914062, "train/extr_critic_mag": 0.026093059182167054, "train/extr_critic_max": 0.026093059182167054, "train/extr_critic_mean": 0.02602379396557808, "train/extr_critic_min": 0.025983495712280272, "train/extr_critic_std": 1.5079126783268392e-05, "train/extr_return_normed_mag": 0.00034993909299373626, "train/extr_return_normed_max": 0.00030519107356667517, "train/extr_return_normed_mean": 0.00020744414933318467, "train/extr_return_normed_min": 9.444601833820343e-05, "train/extr_return_normed_std": 5.2757237178298055e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.026187889389693738, "train/extr_return_raw_max": 0.026187889389693738, "train/extr_return_raw_mean": 0.02609014361165464, "train/extr_return_raw_min": 0.025977144334465265, "train/extr_return_raw_std": 5.275723697835133e-05, "train/extr_reward_mag": 8.872389793395996e-05, "train/extr_reward_max": 8.872389793395996e-05, "train/extr_reward_mean": 8.867621329045506e-05, "train/extr_reward_min": 8.863687515258789e-05, "train/extr_reward_std": 1.4375398613708513e-08, "train/image_loss_mean": 0.25603854201734066, "train/image_loss_std": 0.08405149895697832, "train/model_loss_mean": 0.8819839280843734, "train/model_loss_std": 0.3781880404427648, "train/model_opt_grad_norm": 56.32420038223267, "train/model_opt_grad_steps": 6925.0, "train/model_opt_loss": 793.7704476928711, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 900.0, "train/policy_entropy_mag": 1.9458968448638916, "train/policy_entropy_max": 1.9458968448638916, "train/policy_entropy_mean": 1.9453198009729384, "train/policy_entropy_min": 1.934982408285141, "train/policy_entropy_std": 0.00042433104681549594, "train/policy_logprob_mag": 2.1262123656272887, "train/policy_logprob_max": -1.75788370013237, "train/policy_logprob_mean": -1.9453154659271241, "train/policy_logprob_min": -2.1262123656272887, "train/policy_logprob_std": 0.03374741787090898, "train/policy_randomness_mag": 0.9999932223558425, "train/policy_randomness_max": 0.9999932223558425, "train/policy_randomness_mean": 0.9996966794133186, "train/policy_randomness_min": 0.9943843111395836, "train/policy_randomness_std": 0.00021806303586345167, "train/post_ent_mag": 43.99338542938232, "train/post_ent_max": 43.99338542938232, "train/post_ent_mean": 43.9537128829956, "train/post_ent_min": 43.66612823486328, "train/post_ent_std": 0.0669712212914601, "train/prior_ent_mag": 49.313593273162844, "train/prior_ent_max": 49.313593273162844, "train/prior_ent_mean": 49.2538955116272, "train/prior_ent_min": 48.73816833496094, "train/prior_ent_std": 0.09418963194824755, "train/rep_loss_mean": 1.0000000417232513, "train/rep_loss_std": 3.600908166845329e-07, "train/reward_avg": 0.00011061096261983039, "train/reward_loss_mean": 0.0019020168809220194, "train/reward_loss_std": 0.05284644707123723, "train/reward_max_data": 0.10723437536507845, "train/reward_max_pred": 8.870601654052734e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0001930461519805249, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.710363780750948, "train/reward_pred": 8.865079493261874e-05, "train/reward_rate": 0.00017578125, "train_stats/mean_log_entropy": 1.9381274204505117, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02556166611611843, "report/cont_loss_std": 0.34356531500816345, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.51185941696167, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004046767950057983, "report/cont_pred": 0.9959612488746643, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.26567786931991577, "report/image_loss_std": 0.06938379257917404, "report/model_loss_mean": 0.8989198207855225, "report/model_loss_std": 0.5224903225898743, "report/post_ent_mag": 47.86539077758789, "report/post_ent_max": 47.86539077758789, "report/post_ent_mean": 47.853981018066406, "report/post_ent_min": 47.79396057128906, "report/post_ent_std": 0.011506142094731331, "report/prior_ent_mag": 44.0606689453125, "report/prior_ent_max": 44.0606689453125, "report/prior_ent_mean": 44.04243469238281, "report/prior_ent_min": 43.944786071777344, "report/prior_ent_std": 0.019029946997761726, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00011291504051769152, "report/reward_loss_mean": 0.007680283859372139, "report/reward_loss_std": 0.2407076060771942, "report/reward_max_data": 0.11562500149011612, "report/reward_max_pred": 7.390975952148438e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0001544952392578125, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 7.706562042236328, "report/reward_pred": 7.390975952148438e-05, "report/reward_rate": 0.0009765625, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.004046768415719271, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004046768415719271, "eval/cont_pred": 0.9959612488746643, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2664160132408142, "eval/image_loss_std": 0.07085689157247543, "eval/model_loss_mean": 0.8706173896789551, "eval/model_loss_std": 0.07085688412189484, "eval/post_ent_mag": 47.865928649902344, "eval/post_ent_max": 47.865928649902344, "eval/post_ent_mean": 47.85485076904297, "eval/post_ent_min": 47.79241180419922, "eval/post_ent_std": 0.010517723858356476, "eval/prior_ent_mag": 44.0612907409668, "eval/prior_ent_max": 44.0612907409668, "eval/prior_ent_mean": 44.04282760620117, "eval/prior_ent_min": 43.944786071777344, "eval/prior_ent_std": 0.017129838466644287, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001544952392578125, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 7.390975952148438e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001544952392578125, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.390975952148438e-05, "eval/reward_rate": 0.0, "replay/size": 127937.0, "replay/inserts": 31920.0, "replay/samples": 31920.0, "replay/insert_wait_avg": 1.3482600525208285e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.287585170047923e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31112.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1866274176996884e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.33220744133, "timer/env.step_count": 3990.0, "timer/env.step_total": 38.862077951431274, "timer/env.step_frac": 0.03884917196741419, "timer/env.step_avg": 0.009739869160759718, "timer/env.step_min": 0.007714271545410156, "timer/env.step_max": 0.05087566375732422, "timer/replay._sample_count": 31920.0, "timer/replay._sample_total": 17.220036268234253, "timer/replay._sample_frac": 0.017214317543848768, "timer/replay._sample_avg": 0.0005394748204334039, "timer/replay._sample_min": 0.00034618377685546875, "timer/replay._sample_max": 0.011812210083007812, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4857.0, "timer/agent.policy_total": 51.562435150146484, "timer/agent.policy_frac": 0.05154531141412904, "timer/agent.policy_avg": 0.010616107710551057, "timer/agent.policy_min": 0.009016275405883789, "timer/agent.policy_max": 0.07996535301208496, "timer/dataset_train_count": 1995.0, "timer/dataset_train_total": 0.2167513370513916, "timer/dataset_train_frac": 0.00021667935455742506, "timer/dataset_train_avg": 0.00010864728674255218, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.0005555152893066406, "timer/agent.train_count": 1995.0, "timer/agent.train_total": 895.9346890449524, "timer/agent.train_frac": 0.89563715171842, "timer/agent.train_avg": 0.449090069696718, "timer/agent.train_min": 0.4391019344329834, "timer/agent.train_max": 0.7653722763061523, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4805271625518799, "timer/agent.report_frac": 0.0004803675808669422, "timer/agent.report_avg": 0.24026358127593994, "timer/agent.report_min": 0.23301219940185547, "timer/agent.report_max": 0.24751496315002441, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.2175819132164346e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 31.908490709744207}
{"step": 129112, "time": 4250.007245540619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129280, "time": 4255.37114405632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129432, "time": 4259.787485599518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129488, "time": 4261.813567399979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129576, "time": 4264.327394723892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129832, "time": 4272.189594507217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129880, "time": 4273.675930976868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 4281.183348655701, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 130000, "time": 4283.834852218628, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4283.843247890472, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4283.850472688675, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4283.8579018116, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4283.864970207214, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4283.8726716041565, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4283.879798412323, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130360, "time": 4294.904187679291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131424, "time": 4328.463245391846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131592, "time": 4333.360737323761, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131744, "time": 4338.230694293976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131800, "time": 4339.732366323471, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131848, "time": 4341.1988530159, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 131888, "time": 4342.65527677536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132192, "time": 4352.083163261414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132672, "time": 4366.742591619492, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 133736, "time": 4399.122567415237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133904, "time": 4404.488942861557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134056, "time": 4408.917981386185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134112, "time": 4410.951851129532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134160, "time": 4412.432327032089, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134200, "time": 4413.4589948654175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134504, "time": 4422.774410247803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134984, "time": 4437.4574110507965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136048, "time": 4470.86612033844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136216, "time": 4475.786904335022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136368, "time": 4480.665966033936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136424, "time": 4482.180473327637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136472, "time": 4483.673635721207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136512, "time": 4485.117932319641, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136816, "time": 4494.4200212955475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137296, "time": 4509.202516794205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138360, "time": 4541.608513593674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138528, "time": 4547.006316900253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138680, "time": 4551.450290679932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138736, "time": 4553.3828139305115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138784, "time": 4556.165645599365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138824, "time": 4560.258754968643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139128, "time": 4569.606256246567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139608, "time": 4584.773577213287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 4601.729462862015, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 140088, "time": 4605.023299217224, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4605.031126737595, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4605.038066864014, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4605.045454502106, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4605.053422212601, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4605.060661315918, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4605.067856788635, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140672, "time": 4623.307423353195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140840, "time": 4628.935604095459, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140992, "time": 4633.84029841423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141048, "time": 4635.340611934662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141096, "time": 4636.820809364319, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141136, "time": 4638.262546539307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141440, "time": 4647.577662944794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141920, "time": 4662.469401597977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142984, "time": 4695.113534450531, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143152, "time": 4700.541132450104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143304, "time": 4705.002984285355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143360, "time": 4706.965269804001, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143408, "time": 4708.442787647247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143448, "time": 4709.474980354309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143752, "time": 4718.93327331543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144232, "time": 4733.685354709625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145296, "time": 4766.842538356781, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145464, "time": 4771.86284160614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145560, "time": 4774.837458372116, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 145616, "time": 4776.782287836075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145720, "time": 4779.796818494797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145760, "time": 4781.26610994339, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146064, "time": 4790.563766241074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146544, "time": 4805.344705820084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147608, "time": 4838.389621734619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147776, "time": 4843.784340620041, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147872, "time": 4846.747257232666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147928, "time": 4848.252105474472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148032, "time": 4851.692435503006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148072, "time": 4852.70991396904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148376, "time": 4862.176723241806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148856, "time": 4876.847844839096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149920, "time": 4910.664270401001, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 4920.93096113205, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4920.93852686882, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4920.946001291275, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4920.952852725983, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4920.95988035202, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4920.966751098633, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4920.9745535850525, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4920.981826305389, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150088, "time": 4921.475492477417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150184, "time": 4924.406802892685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150240, "time": 4926.360595941544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150344, "time": 4929.326935768127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150384, "time": 4930.78536939621, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150688, "time": 4940.041381120682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151168, "time": 4954.934561491013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152232, "time": 4987.242269039154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152400, "time": 4992.587340593338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152496, "time": 4995.520040035248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152552, "time": 4997.013426780701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152656, "time": 5000.411190986633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152696, "time": 5001.413289785385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152840, "time": 5005.814857959747, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 153000, "time": 5010.818516492844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153480, "time": 5025.495850086212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154712, "time": 5063.145309209824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154808, "time": 5066.105770349503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154864, "time": 5068.058495998383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154968, "time": 5071.141552209854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155008, "time": 5072.607147932053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155152, "time": 5077.0258412361145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155312, "time": 5081.896638631821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155792, "time": 5097.040933847427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157024, "time": 5134.789938926697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157120, "time": 5137.727214813232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157176, "time": 5139.215703964233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157280, "time": 5142.645519733429, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157320, "time": 5143.651685476303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157464, "time": 5148.045325517654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157624, "time": 5152.957413434982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158104, "time": 5167.721811294556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159336, "time": 5205.34628033638, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159432, "time": 5208.2636024951935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159488, "time": 5210.209699630737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159592, "time": 5213.144216775894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159632, "time": 5214.616585731506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159776, "time": 5218.980261325836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159936, "time": 5223.9725131988525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 5232.786488056183, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5232.794023990631, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5232.800698518753, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5232.807285070419, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5232.813807725906, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5232.820318937302, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5232.8268756866455, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5232.833663702011, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160057, "time": 5233.834049940109, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0000997630472717, "train/action_min": 0.0, "train/action_std": 2.0004370200452466, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 4.581776607286662e-05, "train/actor_opt_grad_steps": 8920.0, "train/actor_opt_loss": -5.832516048614144, "train/adv_mag": 0.00023937845593176519, "train/adv_max": 0.00014093679938522087, "train/adv_mean": -7.281090711677017e-06, "train/adv_min": -0.00016881412055891782, "train/adv_std": 5.2986230275102925e-05, "train/cont_avg": 0.996425880393401, "train/cont_loss_mean": 0.023756607232360064, "train/cont_loss_std": 0.32482943733619896, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.639663387456706, "train/cont_pos_acc": 0.9999999857796025, "train/cont_pos_loss": 0.0035990303734478157, "train/cont_pred": 0.9964075799520851, "train/cont_rate": 0.996425880393401, "train/dyn_loss_mean": 1.0000000157332056, "train/dyn_loss_std": 3.3706887942049796e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.014429062789277679, "train/extr_critic_critic_opt_grad_steps": 8920.0, "train/extr_critic_critic_opt_loss": 8995.743674651016, "train/extr_critic_mag": 0.02773707953806456, "train/extr_critic_max": 0.02773707953806456, "train/extr_critic_mean": 0.027649274199898474, "train/extr_critic_min": 0.027594137917920418, "train/extr_critic_std": 2.121725566381927e-05, "train/extr_return_normed_mag": 0.0002827615699338429, "train/extr_return_normed_max": 0.00015143081924031833, "train/extr_return_normed_mean": 5.0413917272518656e-05, "train/extr_return_normed_min": -5.113513109647683e-05, "train/extr_return_normed_std": 4.616943775016609e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.02774301193994919, "train/extr_return_raw_max": 0.02774301193994919, "train/extr_return_raw_mean": 0.027641996646744344, "train/extr_return_raw_min": 0.027540445989612396, "train/extr_return_raw_std": 4.616943771207811e-05, "train/extr_reward_mag": 8.206198058152562e-05, "train/extr_reward_max": 8.206198058152562e-05, "train/extr_reward_mean": 8.200801731539928e-05, "train/extr_reward_min": 8.196818647045774e-05, "train/extr_reward_std": 2.1312756299221286e-08, "train/image_loss_mean": 0.2525050506979076, "train/image_loss_std": 0.08463304244019658, "train/model_loss_mean": 0.8782426394181808, "train/model_loss_std": 0.37749033114934333, "train/model_opt_grad_norm": 49.62217511985508, "train/model_opt_grad_steps": 8909.573604060914, "train/model_opt_loss": 2206.3531711016813, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2512.6903553299494, "train/policy_entropy_mag": 1.9458922450312504, "train/policy_entropy_max": 1.9458922450312504, "train/policy_entropy_mean": 1.9450250773260436, "train/policy_entropy_min": 1.931793972320363, "train/policy_entropy_std": 0.0006182901847866472, "train/policy_logprob_mag": 2.161027613025026, "train/policy_logprob_max": -1.717859996151803, "train/policy_logprob_mean": -1.9450105089826633, "train/policy_logprob_min": -2.161027613025026, "train/policy_logprob_std": 0.04203113486167743, "train/policy_randomness_mag": 0.9999908587049107, "train/policy_randomness_max": 0.9999908587049107, "train/policy_randomness_mean": 0.9995452192834187, "train/policy_randomness_min": 0.9927457773745968, "train/policy_randomness_std": 0.00031773832527362756, "train/post_ent_mag": 48.75008766058133, "train/post_ent_max": 48.75008766058133, "train/post_ent_mean": 48.739182254384616, "train/post_ent_min": 48.68242075963674, "train/post_ent_std": 0.01057354700727965, "train/prior_ent_mag": 44.22707696130433, "train/prior_ent_max": 44.22707696130433, "train/prior_ent_mean": 44.20656341707646, "train/prior_ent_min": 44.134511337667554, "train/prior_ent_std": 0.014763502945395442, "train/rep_loss_mean": 1.0000000157332056, "train/rep_loss_std": 3.3706887942049796e-07, "train/reward_avg": 0.00011001819330161239, "train/reward_loss_mean": 0.0019809533250967257, "train/reward_loss_std": 0.05319118317056886, "train/reward_max_data": 0.10249048236965529, "train/reward_max_pred": 8.205774471844513e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00024408510737511125, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.714400351047516, "train/reward_pred": 8.200731974681319e-05, "train/reward_rate": 0.00017845812182741116, "train_stats/mean_log_entropy": 1.93802524464471, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9892578125, "report/cont_loss_mean": 0.06383077055215836, "report/cont_loss_std": 0.5770418643951416, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.601356029510498, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003699689405038953, "report/cont_pred": 0.9963071942329407, "report/cont_rate": 0.9892578125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2584443986415863, "report/image_loss_std": 0.08044662326574326, "report/model_loss_mean": 0.9224345684051514, "report/model_loss_std": 0.5837226510047913, "report/post_ent_mag": 50.40522003173828, "report/post_ent_max": 50.40522003173828, "report/post_ent_mean": 50.390480041503906, "report/post_ent_min": 50.33890914916992, "report/post_ent_std": 0.009839183650910854, "report/prior_ent_mag": 44.63640594482422, "report/prior_ent_max": 44.63640594482422, "report/prior_ent_mean": 44.612953186035156, "report/prior_ent_min": 44.58180618286133, "report/prior_ent_std": 0.008576884865760803, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00015938002616167068, "report/reward_loss_std": 3.122015073131479e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 6.890296936035156e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00015938002616167068, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 6.890296936035156e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003699689172208309, "eval/cont_loss_std": 9.313225746154785e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003699689172208309, "eval/cont_pred": 0.9963071942329407, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2544921934604645, "eval/image_loss_std": 0.08243308216333389, "eval/model_loss_mean": 0.8583512306213379, "eval/model_loss_std": 0.0824330672621727, "eval/post_ent_mag": 50.405975341796875, "eval/post_ent_max": 50.405975341796875, "eval/post_ent_mean": 50.391845703125, "eval/post_ent_min": 50.341773986816406, "eval/post_ent_std": 0.00800395105034113, "eval/prior_ent_mag": 44.638240814208984, "eval/prior_ent_max": 44.638240814208984, "eval/prior_ent_mean": 44.61229705810547, "eval/prior_ent_min": 44.580936431884766, "eval/prior_ent_std": 0.008029666729271412, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00015936978161334991, "eval/reward_loss_std": 2.999668424763513e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 6.890296936035156e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00015936978161334991, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 6.890296936035156e-05, "eval/reward_rate": 0.0, "replay/size": 159553.0, "replay/inserts": 31616.0, "replay/samples": 31616.0, "replay/insert_wait_avg": 1.3511944637607466e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.375644080552012e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 40360.0, "eval_replay/inserts": 9248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 3.997197819416086e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1004.4087572097778, "timer/env.step_count": 3952.0, "timer/env.step_total": 38.65165567398071, "timer/env.step_frac": 0.03848199788834382, "timer/env.step_avg": 0.009780277245440464, "timer/env.step_min": 0.007781028747558594, "timer/env.step_max": 0.038060903549194336, "timer/replay._sample_count": 31616.0, "timer/replay._sample_total": 17.442509174346924, "timer/replay._sample_frac": 0.01736594693061197, "timer/replay._sample_avg": 0.0005516987972655277, "timer/replay._sample_min": 0.0003693103790283203, "timer/replay._sample_max": 0.012160778045654297, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5108.0, "timer/agent.policy_total": 55.22176265716553, "timer/agent.policy_frac": 0.05497937195467131, "timer/agent.policy_avg": 0.010810838421528099, "timer/agent.policy_min": 0.008810997009277344, "timer/agent.policy_max": 0.08263492584228516, "timer/dataset_train_count": 1976.0, "timer/dataset_train_total": 0.22037220001220703, "timer/dataset_train_frac": 0.00021940489709029962, "timer/dataset_train_avg": 0.00011152439271872825, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0004200935363769531, "timer/agent.train_count": 1976.0, "timer/agent.train_total": 889.2119951248169, "timer/agent.train_frac": 0.8853088832031148, "timer/agent.train_avg": 0.450006070407296, "timer/agent.train_min": 0.43946194648742676, "timer/agent.train_max": 1.1062591075897217, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4736790657043457, "timer/agent.report_frac": 0.000471599896261572, "timer/agent.report_avg": 0.23683953285217285, "timer/agent.report_min": 0.22913908958435059, "timer/agent.report_max": 0.24453997611999512, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.299471679954262e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 31.476724762651646}
{"step": 160416, "time": 5244.744819879532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161648, "time": 5282.445667505264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161736, "time": 5284.932040452957, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 161744, "time": 5285.405058383942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161800, "time": 5286.891925811768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161904, "time": 5290.308321237564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162088, "time": 5295.711863279343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162248, "time": 5300.588846445084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162728, "time": 5315.296968221664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163960, "time": 5353.443242311478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164048, "time": 5356.341718912125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164056, "time": 5356.372201681137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164112, "time": 5358.314948320389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164216, "time": 5361.257218122482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164400, "time": 5367.074974298477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164560, "time": 5372.09493637085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165040, "time": 5386.649543762207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166272, "time": 5424.227833509445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166360, "time": 5426.704468727112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166368, "time": 5427.175331354141, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166424, "time": 5428.6606612205505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166528, "time": 5432.121400356293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166712, "time": 5437.57825088501, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166872, "time": 5442.478566646576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167352, "time": 5457.225467205048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168584, "time": 5495.003338575363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168672, "time": 5497.958136320114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168680, "time": 5497.989367008209, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168736, "time": 5499.938198566437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168840, "time": 5502.9067735672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169024, "time": 5508.781841039658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169184, "time": 5513.671674251556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169664, "time": 5528.4283282756805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 5545.641423463821, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5545.648736476898, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5545.656504869461, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5545.664662361145, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5545.671937227249, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5545.678487300873, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5545.6849193573, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5545.691707134247, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170896, "time": 5572.0928020477295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170984, "time": 5574.563754320145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170992, "time": 5575.059791326523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171048, "time": 5576.552228689194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171152, "time": 5579.964545249939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171336, "time": 5585.46995639801, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171496, "time": 5590.362754821777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171976, "time": 5605.019048213959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173208, "time": 5643.568821191788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173296, "time": 5646.477085351944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173304, "time": 5646.507858991623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173360, "time": 5648.4423723220825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173464, "time": 5651.402065515518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173648, "time": 5657.240154027939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173808, "time": 5662.1480259895325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174288, "time": 5676.938705444336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175520, "time": 5714.66061425209, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175608, "time": 5717.111100196838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175616, "time": 5717.579891443253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175672, "time": 5719.072565793991, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175776, "time": 5722.466189622879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175960, "time": 5727.879568099976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176120, "time": 5732.881066322327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176600, "time": 5747.542022943497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177832, "time": 5785.056421279907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177920, "time": 5787.984571695328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177928, "time": 5788.014657497406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177976, "time": 5789.487245798111, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 177984, "time": 5789.966598033905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178272, "time": 5798.88874912262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178432, "time": 5803.754199266434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178912, "time": 5818.3760459423065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 5857.490704536438, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5857.49884557724, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5857.505559682846, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5857.512316226959, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5857.518907546997, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5857.525494337082, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5857.532176017761, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5857.539076805115, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180144, "time": 5861.430274009705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180232, "time": 5864.1251673698425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180240, "time": 5864.890661001205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180288, "time": 5866.364742279053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180296, "time": 5866.394431114197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180584, "time": 5875.158814430237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180744, "time": 5880.029223918915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181224, "time": 5894.8073053359985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182456, "time": 5932.438091754913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182544, "time": 5935.334114789963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182552, "time": 5935.3638162612915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182600, "time": 5936.832311868668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182608, "time": 5937.306093454361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182896, "time": 5946.202496767044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183056, "time": 5951.11031126976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183536, "time": 5965.80001783371, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184768, "time": 6003.534614086151, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184856, "time": 6005.988130092621, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184864, "time": 6006.456411600113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184912, "time": 6007.9360139369965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184920, "time": 6007.965075016022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185208, "time": 6016.74188375473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185368, "time": 6021.6291761398315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185848, "time": 6036.294930458069, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187080, "time": 6073.999667882919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187168, "time": 6076.925468206406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187176, "time": 6076.960160017014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187224, "time": 6078.43163394928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187232, "time": 6078.90647149086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187520, "time": 6087.686848640442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187680, "time": 6092.6415293216705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188160, "time": 6107.211632013321, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189392, "time": 6145.198972940445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189480, "time": 6147.660567522049, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189488, "time": 6148.137456178665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189536, "time": 6149.597999572754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189544, "time": 6149.628173351288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189832, "time": 6158.491153717041, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189992, "time": 6163.371811628342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 6169.138549089432, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6169.146000146866, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6169.152535676956, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6169.15961098671, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6169.165751695633, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6169.172954320908, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6169.181389570236, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6169.189727067947, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190472, "time": 6183.329882860184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191664, "time": 6219.940903425217, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 191704, "time": 6220.945972204208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191792, "time": 6223.871804475784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191800, "time": 6223.900753974915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191848, "time": 6225.3665063381195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191856, "time": 6225.841413259506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192105, "time": 6234.206749916077, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9926202119286383, "train/action_min": 0.0, "train/action_std": 2.0034592127918605, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0001465833141702744, "train/actor_opt_grad_steps": 10910.0, "train/actor_opt_loss": -7.027399718645608, "train/adv_mag": 0.00043191757998359737, "train/adv_max": 0.00025230373686818935, "train/adv_mean": -7.084800485879007e-05, "train/adv_min": -0.00037029152041050925, "train/adv_std": 9.294303475402177e-05, "train/cont_avg": 0.9964532804726368, "train/cont_loss_mean": 0.023570975688383428, "train/cont_loss_std": 0.32284620316208, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.669084231058757, "train/cont_pos_acc": 0.9999999839868119, "train/cont_pos_loss": 0.003492610858039773, "train/cont_pred": 0.9965135775395294, "train/cont_rate": 0.9964532804726368, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.008449527450642591, "train/extr_critic_critic_opt_grad_steps": 10910.0, "train/extr_critic_critic_opt_loss": 8528.43206817475, "train/extr_critic_mag": 0.02543788822136115, "train/extr_critic_max": 0.02543788822136115, "train/extr_critic_mean": 0.02526726004718548, "train/extr_critic_min": 0.0251029302824789, "train/extr_critic_std": 4.877745443333078e-05, "train/extr_return_normed_mag": 0.00042564208753666477, "train/extr_return_normed_max": 0.00020486257266049361, "train/extr_return_normed_mean": -2.1878092022361037e-05, "train/extr_return_normed_min": -0.0002187460716535796, "train/extr_return_normed_std": 7.87568740416822e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.025423172675999837, "train/extr_return_raw_max": 0.025423172675999837, "train/extr_return_raw_mean": 0.025196433484331884, "train/extr_return_raw_min": 0.024999564031685764, "train/extr_return_raw_std": 7.875687422267617e-05, "train/extr_reward_mag": 6.476563600758414e-05, "train/extr_reward_max": 6.476563600758414e-05, "train/extr_reward_mean": 6.470031242392522e-05, "train/extr_reward_min": 6.46238896384168e-05, "train/extr_reward_std": 2.7528084647608705e-08, "train/image_loss_mean": 0.236961284680153, "train/image_loss_std": 0.08467829342356961, "train/model_loss_mean": 0.8622183959875533, "train/model_loss_std": 0.3718879407837023, "train/model_opt_grad_norm": 44.75708419799805, "train/model_opt_grad_steps": 10897.731343283582, "train/model_opt_loss": 2273.8755490127487, "train/model_opt_model_opt_grad_overflow": 0.004975124378109453, "train/model_opt_model_opt_grad_scale": 2624.378109452736, "train/policy_entropy_mag": 1.9457979119239162, "train/policy_entropy_max": 1.9457979119239162, "train/policy_entropy_mean": 1.938999473752074, "train/policy_entropy_min": 1.8649398734913536, "train/policy_entropy_std": 0.005554944943157094, "train/policy_logprob_mag": 2.4643396678848646, "train/policy_logprob_max": -1.456843919421903, "train/policy_logprob_mean": -1.9389622857914635, "train/policy_logprob_min": -2.4643396678848646, "train/policy_logprob_std": 0.10135403648018837, "train/policy_randomness_mag": 0.999942380990555, "train/policy_randomness_max": 0.999942380990555, "train/policy_randomness_mean": 0.996448674901801, "train/policy_randomness_min": 0.9583895648296793, "train/policy_randomness_std": 0.002854677163202325, "train/post_ent_mag": 51.58561040394342, "train/post_ent_max": 51.58561040394342, "train/post_ent_mean": 51.477951334483585, "train/post_ent_min": 51.39493551301719, "train/post_ent_std": 0.03547553589280268, "train/prior_ent_mag": 47.00692470038115, "train/prior_ent_max": 47.00692470038115, "train/prior_ent_mean": 46.13780688765037, "train/prior_ent_min": 45.86072591525405, "train/prior_ent_std": 0.1737918460333896, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 8.998889857885747e-05, "train/reward_loss_mean": 0.0016861121953275072, "train/reward_loss_std": 0.04652830295140912, "train/reward_max_data": 0.08690920416543733, "train/reward_max_pred": 6.478639384407309e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00014488010470922201, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.89091866591881, "train/reward_pred": 6.470429382069193e-05, "train/reward_rate": 0.0001554726368159204, "train_stats/mean_log_entropy": 1.9318328569601249, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025557884946465492, "report/cont_loss_std": 0.3452709913253784, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.539093971252441, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003936176188290119, "report/cont_pred": 0.9960715770721436, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.20293141901493073, "report/image_loss_std": 0.08144654333591461, "report/model_loss_mean": 0.8286504745483398, "report/model_loss_std": 0.3526821434497833, "report/post_ent_mag": 51.35626983642578, "report/post_ent_max": 51.35626983642578, "report/post_ent_mean": 51.13485336303711, "report/post_ent_min": 50.93647003173828, "report/post_ent_std": 0.09681957215070724, "report/prior_ent_mag": 53.38652038574219, "report/prior_ent_max": 53.38652038574219, "report/prior_ent_mean": 52.24938201904297, "report/prior_ent_min": 50.754981994628906, "report/prior_ent_std": 0.39791566133499146, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00016117095947265625, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 7.164478302001953e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00016117095947265625, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.164478302001953e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014750651083886623, "eval/cont_loss_std": 0.2444685995578766, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.54103946685791, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0039359997026622295, "eval/cont_pred": 0.9960716962814331, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21641868352890015, "eval/image_loss_std": 0.09685352444648743, "eval/model_loss_mean": 0.8522545695304871, "eval/model_loss_std": 0.741656482219696, "eval/post_ent_mag": 51.340606689453125, "eval/post_ent_max": 51.340606689453125, "eval/post_ent_mean": 51.1224365234375, "eval/post_ent_min": 50.93165588378906, "eval/post_ent_std": 0.0940316766500473, "eval/prior_ent_mag": 53.78359603881836, "eval/prior_ent_max": 53.78359603881836, "eval/prior_ent_mean": 52.22482681274414, "eval/prior_ent_min": 50.80924987792969, "eval/prior_ent_std": 0.47494399547576904, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008422851678915322, "eval/reward_loss_mean": 0.021085230633616447, "eval/reward_loss_std": 0.47299477458000183, "eval/reward_max_data": 0.4312500059604645, "eval/reward_max_pred": 7.164478302001953e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00016117095947265625, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.713279724121094, "eval/reward_pred": 7.164478302001953e-05, "eval/reward_rate": 0.001953125, "replay/size": 191601.0, "replay/inserts": 32048.0, "replay/samples": 32048.0, "replay/insert_wait_avg": 1.306072271768891e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.255079634119378e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 47296.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2101392844969013e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3516528606415, "timer/env.step_count": 4006.0, "timer/env.step_total": 38.28203010559082, "timer/env.step_frac": 0.03826857285247458, "timer/env.step_avg": 0.009556173266497959, "timer/env.step_min": 0.007758617401123047, "timer/env.step_max": 0.045500993728637695, "timer/replay._sample_count": 32048.0, "timer/replay._sample_total": 17.240755796432495, "timer/replay._sample_frac": 0.017234695166574884, "timer/replay._sample_avg": 0.0005379666686355621, "timer/replay._sample_min": 0.000392913818359375, "timer/replay._sample_max": 0.011068582534790039, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4873.0, "timer/agent.policy_total": 51.41486835479736, "timer/agent.policy_frac": 0.05139679452497485, "timer/agent.policy_avg": 0.010550968264887618, "timer/agent.policy_min": 0.008862495422363281, "timer/agent.policy_max": 0.08916759490966797, "timer/dataset_train_count": 2003.0, "timer/dataset_train_total": 0.22169232368469238, "timer/dataset_train_frac": 0.0002216143923496633, "timer/dataset_train_avg": 0.00011068014162990133, "timer/dataset_train_min": 9.72747802734375e-05, "timer/dataset_train_max": 0.0004558563232421875, "timer/agent.train_count": 2003.0, "timer/agent.train_total": 896.843421459198, "timer/agent.train_frac": 0.8965281547689279, "timer/agent.train_avg": 0.4477500856011972, "timer/agent.train_min": 0.43553805351257324, "timer/agent.train_max": 0.6812787055969238, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47606778144836426, "timer/agent.report_frac": 0.00047590042970087945, "timer/agent.report_avg": 0.23803389072418213, "timer/agent.report_min": 0.22997641563415527, "timer/agent.report_max": 0.24609136581420898, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.098351983981871e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 32.03619448684036}
{"step": 192144, "time": 6235.3813326358795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192304, "time": 6240.365338087082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193976, "time": 6291.437033414841, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194016, "time": 6292.888890504837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194104, "time": 6295.372091054916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194112, "time": 6295.843309879303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194160, "time": 6297.306346893311, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194168, "time": 6297.337429046631, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194456, "time": 6306.220191717148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194616, "time": 6311.105259418488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196288, "time": 6362.356023073196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196328, "time": 6363.346248149872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196416, "time": 6366.233061075211, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196424, "time": 6366.262822628021, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196472, "time": 6367.743662595749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196480, "time": 6368.2132823467255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196768, "time": 6377.730778694153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196928, "time": 6382.684592723846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198600, "time": 6433.6504282951355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198640, "time": 6435.096558332443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198728, "time": 6437.576855659485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198736, "time": 6438.047786235809, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198784, "time": 6439.506694793701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198792, "time": 6439.5373277664185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199080, "time": 6448.318667173386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199240, "time": 6453.29291176796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 6485.613214731216, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6485.62091588974, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6485.627587556839, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6485.634016990662, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6485.640341520309, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6485.6466743946075, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6485.653025150299, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6485.659216165543, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200912, "time": 6510.6238489151, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200952, "time": 6511.627064704895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201040, "time": 6514.529469013214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201048, "time": 6514.559626579285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201096, "time": 6516.048928976059, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201104, "time": 6516.520644664764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201392, "time": 6525.3023772239685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201552, "time": 6530.163376092911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203224, "time": 6581.910381317139, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203264, "time": 6583.357925653458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203352, "time": 6585.82381439209, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203360, "time": 6586.298227787018, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203408, "time": 6587.751566886902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203416, "time": 6587.780236005783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203704, "time": 6596.582947015762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203864, "time": 6601.606933832169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205536, "time": 6653.280944108963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205576, "time": 6654.31808423996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205664, "time": 6657.275303840637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205672, "time": 6657.307579755783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205720, "time": 6658.815606594086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205728, "time": 6659.296165466309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206016, "time": 6668.16704583168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206176, "time": 6673.046833992004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207848, "time": 6723.780006885529, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207888, "time": 6725.215948581696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207976, "time": 6727.679918050766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207984, "time": 6728.147843360901, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208032, "time": 6729.599997520447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208040, "time": 6729.630411863327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208328, "time": 6738.373061656952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208488, "time": 6743.2366597652435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209176, "time": 6764.2995262146, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 209584, "time": 6776.933634757996, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 209912, "time": 6786.779700756073, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 6797.341048717499, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6797.3487637043, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6797.357272863388, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6797.362001419067, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6797.368767976761, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6797.374744653702, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6797.380975246429, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6797.387283086777, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210200, "time": 6800.804318189621, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210288, "time": 6803.703553199768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210296, "time": 6803.733590602875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210344, "time": 6805.1889407634735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210544, "time": 6811.591488599777, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 211488, "time": 6840.475097417831, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211896, "time": 6852.626863718033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212224, "time": 6862.80131983757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212512, "time": 6871.675234794617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212600, "time": 6874.174651384354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212608, "time": 6874.647075176239, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212656, "time": 6876.115596294403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212856, "time": 6881.981170654297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213800, "time": 6911.3935561180115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214208, "time": 6923.9498500823975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214536, "time": 6933.781955718994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214824, "time": 6942.511305332184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214912, "time": 6945.444101333618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214920, "time": 6945.47475528717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214968, "time": 6946.927904129028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215168, "time": 6953.205613851547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215792, "time": 6972.197225809097, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 215864, "time": 6974.156868219376, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 216520, "time": 6994.2683873176575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216848, "time": 7004.489364862442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217136, "time": 7013.240291595459, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217224, "time": 7015.690972328186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217280, "time": 7017.640477657318, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217480, "time": 7023.579707860947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218104, "time": 7042.497833967209, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218176, "time": 7044.926249027252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218832, "time": 7065.056911468506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219160, "time": 7074.81619644165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219448, "time": 7083.6167867183685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219536, "time": 7086.529168128967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219592, "time": 7087.99751663208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219792, "time": 7094.31186580658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 7108.020023584366, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7108.027775526047, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7108.03430724144, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7108.040268659592, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7108.0471823215485, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7108.053416967392, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7108.0596969127655, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7108.065778970718, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220416, "time": 7118.8416912555695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220488, "time": 7120.825675487518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220752, "time": 7129.07341504097, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 221472, "time": 7151.44698548317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221760, "time": 7160.196911096573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221848, "time": 7162.632662057877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221904, "time": 7164.585547685623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222104, "time": 7170.52561879158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222728, "time": 7189.490313529968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222736, "time": 7189.969464302063, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 222800, "time": 7191.9416291713715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223064, "time": 7199.76309633255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223784, "time": 7221.676281452179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224072, "time": 7230.487582683563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224169, "time": 7234.398526668549, "train_stats/mean_log_entropy": 1.897211795406682, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0918850708007812, "train/action_min": 0.0, "train/action_std": 1.9409936106204986, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0002839451809268212, "train/actor_opt_grad_steps": 12915.0, "train/actor_opt_loss": -3.434797599466401, "train/adv_mag": 0.001189666511490941, "train/adv_max": 0.0010896114632487296, "train/adv_mean": 0.00013355743375782935, "train/adv_min": -0.0006790967006236315, "train/adv_std": 0.00022991902245848904, "train/cont_avg": 0.996416015625, "train/cont_loss_mean": 0.02374864447279833, "train/cont_loss_std": 0.32340248481918255, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.636159614640839, "train/cont_pos_acc": 0.9999999853968621, "train/cont_pos_loss": 0.0035832307394593954, "train/cont_pred": 0.9964231821894646, "train/cont_rate": 0.996416015625, "train/dyn_loss_mean": 1.0000021547079085, "train/dyn_loss_std": 5.6779316064421434e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0070454792740929405, "train/extr_critic_critic_opt_grad_steps": 12915.0, "train/extr_critic_critic_opt_loss": 8359.652998046875, "train/extr_critic_mag": 0.025041851997375488, "train/extr_critic_max": 0.025041851997375488, "train/extr_critic_mean": 0.024467394016683103, "train/extr_critic_min": 0.02402583062648773, "train/extr_critic_std": 0.00013306125110830181, "train/extr_return_normed_mag": 0.001508540352806449, "train/extr_return_normed_max": 0.0014848592877388, "train/extr_return_normed_mean": 0.0005694427694945859, "train/extr_return_normed_min": -3.3253896981477736e-05, "train/extr_return_normed_std": 0.00023577487972943346, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.025516389338299632, "train/extr_return_raw_max": 0.025516389338299632, "train/extr_return_raw_mean": 0.024600974107161163, "train/extr_return_raw_min": 0.023998276153579353, "train/extr_return_raw_std": 0.00023577488092996646, "train/extr_reward_mag": 0.0001521468162536621, "train/extr_reward_max": 0.0001521468162536621, "train/extr_reward_mean": 8.688399149832549e-05, "train/extr_reward_min": 5.4696202278137206e-05, "train/extr_reward_std": 2.6501357515650303e-05, "train/image_loss_mean": 0.20146133482456208, "train/image_loss_std": 0.09819570757448673, "train/model_loss_mean": 0.8270033729076386, "train/model_loss_std": 0.37628161668777466, "train/model_opt_grad_norm": 41.22233738899231, "train/model_opt_grad_steps": 12900.985, "train/model_opt_loss": 2509.2389666748045, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3037.5, "train/policy_entropy_mag": 1.9430609083175658, "train/policy_entropy_max": 1.9430609083175658, "train/policy_entropy_mean": 1.8993283212184906, "train/policy_entropy_min": 1.6722448748350143, "train/policy_entropy_std": 0.022952682436443866, "train/policy_logprob_mag": 3.15973771572113, "train/policy_logprob_max": -0.9692943561822176, "train/policy_logprob_mean": -1.899372591972351, "train/policy_logprob_min": -3.15973771572113, "train/policy_logprob_std": 0.2480917151272297, "train/policy_randomness_mag": 0.9985358375310898, "train/policy_randomness_max": 0.9985358375310898, "train/policy_randomness_mean": 0.9760617360472679, "train/policy_randomness_min": 0.8593639190495014, "train/policy_randomness_std": 0.011795346154831349, "train/post_ent_mag": 53.896843605041504, "train/post_ent_max": 53.896843605041504, "train/post_ent_mean": 53.45167135238648, "train/post_ent_min": 53.10305408477783, "train/post_ent_std": 0.167052031904459, "train/prior_ent_mag": 55.003776149749754, "train/prior_ent_max": 55.003776149749754, "train/prior_ent_mean": 51.943882122039795, "train/prior_ent_min": 49.4487721824646, "train/prior_ent_std": 0.8944173699617386, "train/rep_loss_mean": 1.0000021547079085, "train/rep_loss_std": 5.6779316064421434e-05, "train/reward_avg": 8.503723220201209e-05, "train/reward_loss_mean": 0.0017920819320715964, "train/reward_loss_std": 0.049834369479121586, "train/reward_max_data": 0.08395312577486039, "train/reward_max_pred": 0.0001410561800003052, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00018700412856560434, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.380155712366104, "train/reward_pred": 6.695282412692905e-05, "train/reward_rate": 0.0001708984375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.0037545806262642145, "report/cont_loss_std": 0.0005207944777794182, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0037545806262642145, "report/cont_pred": 0.9962525963783264, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.17682772874832153, "report/image_loss_std": 0.09672769904136658, "report/model_loss_mean": 0.7807812094688416, "report/model_loss_std": 0.09635676443576813, "report/post_ent_mag": 54.11554718017578, "report/post_ent_max": 54.11554718017578, "report/post_ent_mean": 53.51757049560547, "report/post_ent_min": 53.142921447753906, "report/post_ent_std": 0.19180935621261597, "report/prior_ent_mag": 54.19462966918945, "report/prior_ent_max": 54.19462966918945, "report/prior_ent_mean": 52.30592727661133, "report/prior_ent_min": 50.028289794921875, "report/prior_ent_std": 0.8135372996330261, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0001988699659705162, "report/reward_loss_std": 0.00037915550637990236, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0008890628814697266, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0001988699659705162, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 8.6221843957901e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014475527219474316, "eval/cont_loss_std": 0.24403375387191772, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.527497291564941, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003686834592372179, "eval/cont_pred": 0.9963193535804749, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.184726744890213, "eval/image_loss_std": 0.09779005497694016, "eval/model_loss_mean": 0.7993600368499756, "eval/model_loss_std": 0.26264211535453796, "eval/post_ent_mag": 54.04988098144531, "eval/post_ent_max": 54.04988098144531, "eval/post_ent_mean": 53.50312423706055, "eval/post_ent_min": 53.08587646484375, "eval/post_ent_std": 0.1899477243423462, "eval/prior_ent_mag": 53.88557434082031, "eval/prior_ent_max": 53.88557434082031, "eval/prior_ent_mean": 52.3651123046875, "eval/prior_ent_min": 50.1881217956543, "eval/prior_ent_std": 0.7531129121780396, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001577264629304409, "eval/reward_loss_std": 0.0003537754819262773, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.000978708267211914, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001577264629304409, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 6.829912308603525e-05, "eval/reward_rate": 0.0, "replay/size": 223665.0, "replay/inserts": 32064.0, "replay/samples": 32064.0, "replay/insert_wait_avg": 1.3060525743785257e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.131245415129823e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 54232.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.18831174733867e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1786406040192, "timer/env.step_count": 4008.0, "timer/env.step_total": 38.20354437828064, "timer/env.step_frac": 0.03819672089298876, "timer/env.step_avg": 0.009531822449670819, "timer/env.step_min": 0.007638454437255859, "timer/env.step_max": 0.041321754455566406, "timer/replay._sample_count": 32064.0, "timer/replay._sample_total": 16.760485887527466, "timer/replay._sample_frac": 0.016757492318977756, "timer/replay._sample_avg": 0.0005227197444962409, "timer/replay._sample_min": 0.0003707408905029297, "timer/replay._sample_max": 0.009900569915771484, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4875.0, "timer/agent.policy_total": 51.222360134124756, "timer/agent.policy_frac": 0.051213211375110944, "timer/agent.policy_avg": 0.010507150796743539, "timer/agent.policy_min": 0.008800983428955078, "timer/agent.policy_max": 0.08561038970947266, "timer/dataset_train_count": 2004.0, "timer/dataset_train_total": 0.22098922729492188, "timer/dataset_train_frac": 0.00022094975669692765, "timer/dataset_train_avg": 0.00011027406551642808, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.0006320476531982422, "timer/agent.train_count": 2004.0, "timer/agent.train_total": 897.0469861030579, "timer/agent.train_frac": 0.8968867657094948, "timer/agent.train_avg": 0.4476282365783722, "timer/agent.train_min": 0.43578362464904785, "timer/agent.train_max": 1.2688968181610107, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4660377502441406, "timer/agent.report_frac": 0.0004659545118486985, "timer/agent.report_avg": 0.2330188751220703, "timer/agent.report_min": 0.22304677963256836, "timer/agent.report_max": 0.24299097061157227, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 3.361101536123448e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 32.05775113297932}
{"step": 224216, "time": 7235.583798646927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224416, "time": 7241.8771896362305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225040, "time": 7260.882776737213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225048, "time": 7260.912032842636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225112, "time": 7262.867901563644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225376, "time": 7271.088823318481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226096, "time": 7293.050355195999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226384, "time": 7301.807105064392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226528, "time": 7306.1933805942535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226728, "time": 7312.034557104111, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227352, "time": 7331.069828987122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227360, "time": 7331.546240329742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227424, "time": 7333.48966550827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227688, "time": 7341.2864027023315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228408, "time": 7363.38903594017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228560, "time": 7368.262745141983, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 228696, "time": 7372.195786952972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228840, "time": 7376.590734243393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229664, "time": 7402.447489738464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229672, "time": 7402.479378938675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229736, "time": 7404.441328763962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230000, "time": 7412.802934408188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 7419.6492574214935, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7419.65704369545, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7419.66374707222, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7419.6705112457275, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7419.676859378815, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7419.683381080627, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7419.689910888672, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7419.6967895030975, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230720, "time": 7440.07963347435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230872, "time": 7444.54908823967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231008, "time": 7448.91584444046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231152, "time": 7453.2969307899475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231976, "time": 7478.214021444321, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231984, "time": 7478.682457923889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232048, "time": 7480.629603147507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232312, "time": 7488.442049741745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233032, "time": 7510.339201450348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233056, "time": 7511.291627883911, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 233184, "time": 7515.191201448441, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233320, "time": 7519.191876173019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233464, "time": 7523.660624027252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234288, "time": 7549.038551330566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234296, "time": 7549.067972660065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234624, "time": 7559.262197256088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235344, "time": 7581.301107883453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235368, "time": 7581.813296079636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235496, "time": 7585.687310695648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235632, "time": 7590.065940141678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235776, "time": 7594.609963655472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236600, "time": 7619.545944213867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236608, "time": 7620.016145467758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236936, "time": 7629.859220504761, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237656, "time": 7652.281410694122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237680, "time": 7653.246352434158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237808, "time": 7657.142032384872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237944, "time": 7661.079266548157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238088, "time": 7665.460001945496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238912, "time": 7690.82400894165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238920, "time": 7690.853482961655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239248, "time": 7701.089250087738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239968, "time": 7723.083651542664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239992, "time": 7723.601013422012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 7730.912612199783, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7730.920252561569, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7730.927054405212, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7730.93380188942, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7730.940482378006, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7730.946825742722, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7730.955296993256, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7730.96349811554, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240120, "time": 7733.431044101715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240256, "time": 7737.754502773285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240400, "time": 7742.236501932144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241224, "time": 7767.204656362534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241232, "time": 7767.696321487427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241560, "time": 7777.543262720108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242280, "time": 7799.401382684708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242304, "time": 7800.425110578537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242432, "time": 7804.322351932526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242568, "time": 7808.224081993103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242712, "time": 7812.599272727966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243536, "time": 7837.898996114731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243544, "time": 7837.9300084114075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243872, "time": 7848.111411809921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244592, "time": 7870.07581281662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244616, "time": 7870.587199211121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244744, "time": 7874.467399835587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244880, "time": 7878.826561927795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244912, "time": 7879.811268568039, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 245024, "time": 7883.190811157227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245856, "time": 7909.08821439743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245920, "time": 7911.061949491501, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 246184, "time": 7918.878005504608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246720, "time": 7935.443572998047, "episode/length": 265.0, "episode/score": 0.171875, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.0}
{"step": 246928, "time": 7941.7535672187805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247000, "time": 7943.735859632492, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 247056, "time": 7945.662260293961, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247224, "time": 7950.6499128341675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247336, "time": 7954.0685267448425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247712, "time": 7965.74315905571, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 247816, "time": 7968.690925836563, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 248496, "time": 7989.638696670532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249032, "time": 8005.748487472534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249240, "time": 8012.126884937286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249312, "time": 8014.541375398636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249536, "time": 8021.355651378632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249648, "time": 8024.779146194458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 8037.311810255051, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 250016, "time": 8037.906800270081, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 250016, "time": 8041.48458814621, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8041.491951942444, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8041.498553991318, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8041.505047798157, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8041.511239767075, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8041.517609596252, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250024, "time": 8041.545081138611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250128, "time": 8044.92980837822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250440, "time": 8054.144736766815, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 250808, "time": 8065.2727110385895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251344, "time": 8081.855996131897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251624, "time": 8090.224091053009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251848, "time": 8097.042371749878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251960, "time": 8100.524668216705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252336, "time": 8112.080614805222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252440, "time": 8115.011340379715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252512, "time": 8117.426168203354, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 252752, "time": 8124.744871139526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253120, "time": 8136.052085399628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253504, "time": 8147.653478384018, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 253936, "time": 8160.809471845627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254160, "time": 8168.024920701981, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254648, "time": 8182.559863328934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254752, "time": 8185.97575378418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254824, "time": 8187.945093154907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255064, "time": 8195.335978507996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255432, "time": 8206.50105047226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255576, "time": 8210.882071495056, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 255816, "time": 8218.176928281784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256248, "time": 8231.355138778687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256329, "time": 8234.778192996979, "train_stats/mean_log_entropy": 1.2434688949177408, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.1823742615049753, "train/action_min": 0.0, "train/action_std": 1.7539162973859417, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0020267630017082212, "train/actor_opt_grad_steps": 14920.0, "train/actor_opt_loss": 15.366288188821752, "train/adv_mag": 0.009744646741234842, "train/adv_max": 0.00938449275508449, "train/adv_mean": 0.002112478950853549, "train/adv_min": -0.0030384943148686516, "train/adv_std": 0.0016855922708894817, "train/cont_avg": 0.9965796019900498, "train/cont_loss_mean": 0.02276193098146561, "train/cont_loss_std": 0.31650413768609237, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.6300435212193705, "train/cont_pos_acc": 0.999999985172974, "train/cont_pos_loss": 0.0035158211842587044, "train/cont_pred": 0.99648999782344, "train/cont_rate": 0.9965796019900498, "train/dyn_loss_mean": 1.0000040133794148, "train/dyn_loss_std": 0.00010646376183977008, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10741132569519006, "train/extr_critic_critic_opt_grad_steps": 14920.0, "train/extr_critic_critic_opt_loss": 12285.098754275497, "train/extr_critic_mag": 0.07119282679771309, "train/extr_critic_max": 0.07119282679771309, "train/extr_critic_mean": 0.06822290720038153, "train/extr_critic_min": 0.06491279186894051, "train/extr_critic_std": 0.0009795533399333926, "train/extr_return_normed_mag": 0.015847796398164027, "train/extr_return_normed_max": 0.015555440879134989, "train/extr_return_normed_mean": 0.007189248027673816, "train/extr_return_normed_min": 0.0017504025232139512, "train/extr_return_normed_std": 0.001996171832448381, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.07870158564243744, "train/extr_return_raw_max": 0.07870158564243744, "train/extr_return_raw_mean": 0.07033539609751892, "train/extr_return_raw_min": 0.06489654732358396, "train/extr_return_raw_std": 0.0019961718327379716, "train/extr_reward_mag": 0.0025595396905396116, "train/extr_reward_max": 0.0025595396905396116, "train/extr_reward_mean": 0.00047852377565731107, "train/extr_reward_min": 8.159015902239292e-06, "train/extr_reward_std": 0.0006472003891876151, "train/image_loss_mean": 0.18358246670730077, "train/image_loss_std": 0.10255385382999828, "train/model_loss_mean": 0.8076067317777605, "train/model_loss_std": 0.35834535407782786, "train/model_opt_grad_norm": 37.48203034187431, "train/model_opt_grad_steps": 14904.427860696518, "train/model_opt_loss": 2336.53588199141, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2898.009950248756, "train/policy_entropy_mag": 1.819220265345787, "train/policy_entropy_max": 1.819220265345787, "train/policy_entropy_mean": 1.2307128319099767, "train/policy_entropy_min": 0.295182287322348, "train/policy_entropy_std": 0.2833300377450772, "train/policy_logprob_mag": 5.863457677376211, "train/policy_logprob_max": -0.06039511968858948, "train/policy_logprob_mean": -1.231299527842014, "train/policy_logprob_min": -5.863457677376211, "train/policy_logprob_std": 0.9126172009392164, "train/policy_randomness_mag": 0.9348943319486741, "train/policy_randomness_max": 0.9348943319486741, "train/policy_randomness_mean": 0.6324613198119017, "train/policy_randomness_min": 0.15169369701796503, "train/policy_randomness_std": 0.1456028462308853, "train/post_ent_mag": 53.42760323291987, "train/post_ent_max": 53.42760323291987, "train/post_ent_mean": 52.68298165240691, "train/post_ent_min": 52.16645074720999, "train/post_ent_std": 0.2336881200027703, "train/prior_ent_mag": 54.5064534239508, "train/prior_ent_max": 54.5064534239508, "train/prior_ent_mean": 51.67609849616663, "train/prior_ent_min": 49.000721793862716, "train/prior_ent_std": 1.0700413300030267, "train/rep_loss_mean": 1.0000040133794148, "train/rep_loss_std": 0.00010646376183977008, "train/reward_avg": 7.435053819211302e-05, "train/reward_loss_mean": 0.0012599025663006958, "train/reward_loss_std": 0.03304784556581327, "train/reward_max_data": 0.07070895555007517, "train/reward_max_pred": 0.0018556734815758852, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00017568096259695164, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.38547952969869, "train/reward_pred": 7.43990757071705e-05, "train/reward_rate": 0.00013118003731343284, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025545403361320496, "report/cont_loss_std": 0.3391076326370239, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.43896484375, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00431630527600646, "report/cont_pred": 0.9956932067871094, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1827450543642044, "report/image_loss_std": 0.10082410275936127, "report/model_loss_mean": 0.8084603548049927, "report/model_loss_std": 0.3512214422225952, "report/post_ent_mag": 49.6669807434082, "report/post_ent_max": 49.6669807434082, "report/post_ent_mean": 49.03154754638672, "report/post_ent_min": 48.487449645996094, "report/post_ent_std": 0.2009200006723404, "report/prior_ent_mag": 51.8292121887207, "report/prior_ent_max": 51.8292121887207, "report/prior_ent_mean": 49.091575622558594, "report/prior_ent_min": 46.65489196777344, "report/prior_ent_std": 1.0320162773132324, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00016985228285193443, "report/reward_loss_std": 0.0007242282154038548, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0049926042556762695, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00016985228285193443, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.45637807995081e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02072381228208542, "eval/cont_loss_std": 0.3016681969165802, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.58579158782959, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004371996968984604, "eval/cont_pred": 0.9956398010253906, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16558213531970978, "eval/image_loss_std": 0.10647624731063843, "eval/model_loss_mean": 0.7864751815795898, "eval/model_loss_std": 0.3227636516094208, "eval/post_ent_mag": 49.648963928222656, "eval/post_ent_max": 49.648963928222656, "eval/post_ent_mean": 49.03255081176758, "eval/post_ent_min": 48.50624465942383, "eval/post_ent_std": 0.19199766218662262, "eval/prior_ent_mag": 52.93303680419922, "eval/prior_ent_max": 52.93303680419922, "eval/prior_ent_mean": 48.95357894897461, "eval/prior_ent_min": 46.284515380859375, "eval/prior_ent_std": 1.0023075342178345, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00016922596842050552, "eval/reward_loss_std": 0.0006838645203970373, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.003589153289794922, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00016922596842050552, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.433141581714153e-05, "eval/reward_rate": 0.0, "replay/size": 255825.0, "replay/inserts": 32160.0, "replay/samples": 32160.0, "replay/insert_wait_avg": 1.3036143720446534e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.026017478449427e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 61168.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2201077660337314e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3632888793945, "timer/env.step_count": 4020.0, "timer/env.step_total": 38.03051972389221, "timer/env.step_frac": 0.03801670867639889, "timer/env.step_avg": 0.009460328289525427, "timer/env.step_min": 0.007666587829589844, "timer/env.step_max": 0.0418698787689209, "timer/replay._sample_count": 32160.0, "timer/replay._sample_total": 16.46710228919983, "timer/replay._sample_frac": 0.01646112214658162, "timer/replay._sample_avg": 0.0005120367627238753, "timer/replay._sample_min": 0.00039839744567871094, "timer/replay._sample_max": 0.02768087387084961, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4887.0, "timer/agent.policy_total": 51.18006730079651, "timer/agent.policy_frac": 0.05116148090373083, "timer/agent.policy_avg": 0.010472696398771538, "timer/agent.policy_min": 0.008898735046386719, "timer/agent.policy_max": 0.0893242359161377, "timer/dataset_train_count": 2010.0, "timer/dataset_train_total": 0.22030067443847656, "timer/dataset_train_frac": 0.000220220670717792, "timer/dataset_train_avg": 0.00010960232559128187, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0005550384521484375, "timer/agent.train_count": 2010.0, "timer/agent.train_total": 897.5532748699188, "timer/agent.train_frac": 0.8972273221614886, "timer/agent.train_avg": 0.4465439178457308, "timer/agent.train_min": 0.43561220169067383, "timer/agent.train_max": 0.6899456977844238, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47722721099853516, "timer/agent.report_frac": 0.00047705390262084126, "timer/agent.report_avg": 0.23861360549926758, "timer/agent.report_min": 0.23053979873657227, "timer/agent.report_max": 0.2466874122619629, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.169815543314163e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 32.147735707625145}
{"step": 256640, "time": 8244.195487260818, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 256704, "time": 8246.134416103363, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 256960, "time": 8254.022276639938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257064, "time": 8256.951469898224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257136, "time": 8259.369935274124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257320, "time": 8264.733028888702, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 257376, "time": 8266.651183843613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257744, "time": 8277.856095552444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257776, "time": 8278.83607006073, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 257808, "time": 8279.804889917374, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 258128, "time": 8289.604796886444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258584, "time": 8303.283905506134, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 258952, "time": 8314.570833683014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259376, "time": 8327.651928901672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259432, "time": 8329.126507997513, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 259688, "time": 8336.897343635559, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 8352.089236974716, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8352.098211288452, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8352.105100870132, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8352.111991167068, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8352.118862628937, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8352.131430625916, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8352.158365488052, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8352.188345193863, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260056, "time": 8353.677497386932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260088, "time": 8354.658546447754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260120, "time": 8355.653708934784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260392, "time": 8363.861764431, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 260896, "time": 8379.566882371902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261264, "time": 8390.753831386566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261688, "time": 8403.589934110641, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261744, "time": 8405.527565002441, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261776, "time": 8406.502313137054, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 262000, "time": 8413.293060064316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262368, "time": 8424.971009254456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262432, "time": 8426.918004989624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263000, "time": 8444.106194257736, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 263200, "time": 8450.391726493835, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 263208, "time": 8450.421338796616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263384, "time": 8455.764070987701, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 263944, "time": 8472.791945934296, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 264056, "time": 8476.190049886703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264312, "time": 8483.982038021088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264544, "time": 8491.347620487213, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 264640, "time": 8494.263778448105, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 264744, "time": 8497.205055475235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264992, "time": 8505.021177053452, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 265352, "time": 8515.828207015991, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 265520, "time": 8521.29277396202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265696, "time": 8526.737169027328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266176, "time": 8541.32195687294, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 266256, "time": 8543.75350189209, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266368, "time": 8547.162692308426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266952, "time": 8564.699246883392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267000, "time": 8566.187678098679, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 267304, "time": 8575.3832321167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267664, "time": 8586.630073308945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268008, "time": 8596.860260248184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268248, "time": 8604.14641571045, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 268488, "time": 8611.602294683456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268568, "time": 8614.021743774414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268680, "time": 8617.446549415588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268792, "time": 8620.859894990921, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 269208, "time": 8633.46670126915, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 269264, "time": 8635.405378580093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269616, "time": 8646.18560385704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 8660.816581010818, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 270088, "time": 8661.90970826149, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 270088, "time": 8663.219485521317, "eval_episode/length": 155.0, "eval_episode/score": 0.515625, "eval_episode/reward_rate": 0.00641025641025641}
{"step": 270088, "time": 8666.413738012314, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8666.421336650848, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8666.428042411804, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8666.434685468674, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8666.441581010818, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270320, "time": 8673.845457792282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270800, "time": 8688.872667312622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270880, "time": 8691.345387935638, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270992, "time": 8694.741121053696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271072, "time": 8697.163470983505, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 271104, "time": 8698.131500720978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271520, "time": 8711.741641283035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271576, "time": 8713.227368354797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272632, "time": 8745.351955413818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273112, "time": 8759.911533355713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273192, "time": 8762.43610048294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273304, "time": 8765.840156078339, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273384, "time": 8768.261374235153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273416, "time": 8769.248750448227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273832, "time": 8781.870572566986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273888, "time": 8783.820903778076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274800, "time": 8811.60147857666, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 274944, "time": 8816.026782751083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275504, "time": 8833.285327196121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275576, "time": 8835.27407336235, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 275616, "time": 8836.740239858627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275696, "time": 8839.231494426727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275728, "time": 8840.227174520493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275856, "time": 8844.123085021973, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 276144, "time": 8853.018963336945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276200, "time": 8854.497269392014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276280, "time": 8856.933086156845, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 277488, "time": 8893.820168733597, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 277544, "time": 8895.2987844944, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 277832, "time": 8904.083944320679, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 277928, "time": 8907.010748147964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278040, "time": 8910.468994617462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278168, "time": 8914.350862979889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278392, "time": 8921.163056373596, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 278512, "time": 8925.030041217804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278592, "time": 8927.902391195297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278728, "time": 8931.829356431961, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 279352, "time": 8950.897727251053, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 279408, "time": 8952.831494569778, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 279448, "time": 8953.82221031189, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 279800, "time": 8964.518843889236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 8973.443166732788, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 280072, "time": 8978.146019935608, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8978.153321504593, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8978.161759614944, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8978.16705417633, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8978.173600673676, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8978.180406332016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8978.186715364456, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280240, "time": 8983.478604793549, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280352, "time": 8986.874878406525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280536, "time": 8992.248760223389, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 280824, "time": 9001.104015111923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281040, "time": 9007.881440401077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281104, "time": 9009.834234714508, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 281472, "time": 9021.044825077057, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 281480, "time": 9021.072678089142, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 281720, "time": 9028.343729257584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281760, "time": 9029.778039932251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281832, "time": 9031.870042324066, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 281984, "time": 9036.820985078812, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 282104, "time": 9040.308130979538, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 282112, "time": 9040.779539823532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282552, "time": 9053.927864551544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282648, "time": 9056.84112405777, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 282816, "time": 9062.256163358688, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 282832, "time": 9062.769181728363, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 282960, "time": 9066.644813299179, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 283744, "time": 9090.51889181137, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 283784, "time": 9091.509925365448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284032, "time": 9099.259366989136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284144, "time": 9102.661732196808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284416, "time": 9110.906953573227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284424, "time": 9110.9362180233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284808, "time": 9122.684867620468, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 285128, "time": 9132.403622627258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285208, "time": 9134.830865621567, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 285272, "time": 9136.789539813995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285336, "time": 9138.721268177032, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 285496, "time": 9143.548166036606, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 285664, "time": 9148.87813282013, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 285728, "time": 9150.904786348343, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 286072, "time": 9161.115112304688, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 286128, "time": 9163.041161298752, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 286320, "time": 9168.873800039291, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 286456, "time": 9172.771690130234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286728, "time": 9181.338072776794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286736, "time": 9182.082633256912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286856, "time": 9185.508657932281, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 287120, "time": 9193.74265551567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287416, "time": 9202.475395202637, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 287592, "time": 9207.795544147491, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 287648, "time": 9209.740189313889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288304, "time": 9229.690789937973, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 288320, "time": 9230.18090248108, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 288384, "time": 9232.125165939331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288457, "time": 9235.097616672516, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6577400473219837, "train/action_min": 0.0, "train/action_std": 1.5089876639902295, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0026110176069995585, "train/actor_opt_grad_steps": 16930.0, "train/actor_opt_loss": 11.627640729417923, "train/adv_mag": 0.019714523644293127, "train/adv_max": 0.019382373573471657, "train/adv_mean": 0.003803244931874016, "train/adv_min": -0.005694296563146126, "train/adv_std": 0.003468887468647045, "train/cont_avg": 0.9964046952736318, "train/cont_loss_mean": 0.023473932565333536, "train/cont_loss_std": 0.32337176547714724, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.524063698687956, "train/cont_pos_acc": 0.9999999848764334, "train/cont_pos_loss": 0.00360753743177215, "train/cont_pred": 0.9963967702282008, "train/cont_rate": 0.9964046952736318, "train/dyn_loss_mean": 1.0000020194409498, "train/dyn_loss_std": 6.092093888275205e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.5791749401916912, "train/extr_critic_critic_opt_grad_steps": 16930.0, "train/extr_critic_critic_opt_loss": 5293.184521727301, "train/extr_critic_mag": 0.1763472586721923, "train/extr_critic_max": 0.1763472586721923, "train/extr_critic_mean": 0.17344996099596593, "train/extr_critic_min": 0.16759037319107437, "train/extr_critic_std": 0.0016611199115057805, "train/extr_return_normed_mag": 0.028047350212116146, "train/extr_return_normed_max": 0.027926807898787123, "train/extr_return_normed_mean": 0.010773552073074844, "train/extr_return_normed_min": 0.0009061388337790077, "train/extr_return_normed_std": 0.0040306831624321825, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.1944064542428771, "train/extr_return_raw_max": 0.1944064542428771, "train/extr_return_raw_mean": 0.17725320712695666, "train/extr_return_raw_min": 0.16738578515933522, "train/extr_return_raw_std": 0.004030683155482014, "train/extr_reward_mag": 0.012288863979168792, "train/extr_reward_max": 0.012288863979168792, "train/extr_reward_mean": 0.001013467133879796, "train/extr_reward_min": 8.000663263880792e-07, "train/extr_reward_std": 0.0023524197253146075, "train/image_loss_mean": 0.1693054382406657, "train/image_loss_std": 0.10590515241249283, "train/model_loss_mean": 0.7951658302871742, "train/model_loss_std": 0.38523269870981053, "train/model_opt_grad_norm": 35.63966488245115, "train/model_opt_grad_steps": 16912.98009950249, "train/model_opt_loss": 2475.7558369043454, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3109.452736318408, "train/policy_entropy_mag": 1.65001136390724, "train/policy_entropy_max": 1.65001136390724, "train/policy_entropy_mean": 0.5904944074984214, "train/policy_entropy_min": 0.06768162600436614, "train/policy_entropy_std": 0.3738831576719806, "train/policy_logprob_mag": 6.540453749509593, "train/policy_logprob_max": -0.009081090429788502, "train/policy_logprob_mean": -0.5905665535831925, "train/policy_logprob_min": -6.540453749509593, "train/policy_logprob_std": 0.9431296530647657, "train/policy_randomness_mag": 0.8479381541707622, "train/policy_randomness_max": 0.8479381541707622, "train/policy_randomness_mean": 0.30345411376277015, "train/policy_randomness_min": 0.03478147745577257, "train/policy_randomness_std": 0.19213794653688498, "train/post_ent_mag": 47.430673836475584, "train/post_ent_max": 47.430673836475584, "train/post_ent_mean": 46.83808287815075, "train/post_ent_min": 46.4300954448643, "train/post_ent_std": 0.16886453716019492, "train/prior_ent_mag": 48.65491819618946, "train/prior_ent_max": 48.65491819618946, "train/prior_ent_mean": 46.039570215329604, "train/prior_ent_min": 44.31361751651289, "train/prior_ent_std": 0.7378136374760623, "train/rep_loss_mean": 1.0000020194409498, "train/rep_loss_std": 6.092093888275205e-05, "train/reward_avg": 0.00018343949330355556, "train/reward_loss_mean": 0.0023852257910578407, "train/reward_loss_std": 0.06432523655602929, "train/reward_max_data": 0.1723880608802411, "train/reward_max_pred": 0.007513730087090487, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0002755705989429273, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 6.70009340088943, "train/reward_pred": 0.00011843019014511683, "train/reward_rate": 0.00031580379353233833, "train_stats/mean_log_entropy": 0.6097130379448198, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.038325581699609756, "report/cont_loss_std": 0.4573834240436554, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.962836742401123, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0034070529509335756, "report/cont_pred": 0.9966017007827759, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.15378329157829285, "report/image_loss_std": 0.10330347716808319, "report/model_loss_mean": 0.7921758890151978, "report/model_loss_std": 0.4727570116519928, "report/post_ent_mag": 43.79224395751953, "report/post_ent_max": 43.79224395751953, "report/post_ent_mean": 43.36521530151367, "report/post_ent_min": 43.066062927246094, "report/post_ent_std": 0.12319423258304596, "report/prior_ent_mag": 45.50728988647461, "report/prior_ent_max": 45.50728988647461, "report/prior_ent_mean": 43.13636779785156, "report/prior_ent_min": 41.62409973144531, "report/prior_ent_std": 0.632027804851532, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 6.695371121168137e-05, "report/reward_loss_std": 0.0003701763926073909, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.003082871437072754, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 6.695371121168137e-05, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 2.765841782093048e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.019334325566887856, "eval/cont_loss_std": 0.29641127586364746, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.468268394470215, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003323749639093876, "eval/cont_pred": 0.9966793656349182, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18581688404083252, "eval/image_loss_std": 0.10435932129621506, "eval/model_loss_mean": 0.805212140083313, "eval/model_loss_std": 0.3184258043766022, "eval/post_ent_mag": 43.782012939453125, "eval/post_ent_max": 43.782012939453125, "eval/post_ent_mean": 43.39786148071289, "eval/post_ent_min": 43.085060119628906, "eval/post_ent_std": 0.122781902551651, "eval/prior_ent_mag": 45.931854248046875, "eval/prior_ent_max": 45.931854248046875, "eval/prior_ent_mean": 43.116539001464844, "eval/prior_ent_min": 41.43464660644531, "eval/prior_ent_std": 0.6427315473556519, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 6.0860998928546906e-05, "eval/reward_loss_std": 0.00038513343315571547, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0028814077377319336, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 6.0860998928546906e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 2.522009890526533e-05, "eval/reward_rate": 0.0, "replay/size": 287953.0, "replay/inserts": 32128.0, "replay/samples": 32128.0, "replay/insert_wait_avg": 1.3109162984141316e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.134267838352705e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 68104.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1664842101804388e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3001477718353, "timer/env.step_count": 4016.0, "timer/env.step_total": 38.16594386100769, "timer/env.step_frac": 0.038154491875285815, "timer/env.step_avg": 0.009503472076944146, "timer/env.step_min": 0.007653474807739258, "timer/env.step_max": 0.053569793701171875, "timer/replay._sample_count": 32128.0, "timer/replay._sample_total": 16.34746813774109, "timer/replay._sample_frac": 0.016342562953884403, "timer/replay._sample_avg": 0.0005088230869565827, "timer/replay._sample_min": 0.0003883838653564453, "timer/replay._sample_max": 0.010066509246826172, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4883.0, "timer/agent.policy_total": 51.21670746803284, "timer/agent.policy_frac": 0.05120133950006691, "timer/agent.policy_avg": 0.010488778920342584, "timer/agent.policy_min": 0.00885009765625, "timer/agent.policy_max": 0.0902853012084961, "timer/dataset_train_count": 2008.0, "timer/dataset_train_total": 0.21850347518920898, "timer/dataset_train_frac": 0.00021843791153677687, "timer/dataset_train_avg": 0.0001088164717077734, "timer/dataset_train_min": 9.703636169433594e-05, "timer/dataset_train_max": 0.0003399848937988281, "timer/agent.train_count": 2008.0, "timer/agent.train_total": 897.1367919445038, "timer/agent.train_frac": 0.8968675991329927, "timer/agent.train_avg": 0.4467812708886971, "timer/agent.train_min": 0.4346311092376709, "timer/agent.train_max": 1.3451051712036133, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47365665435791016, "timer/agent.report_frac": 0.000473514530026791, "timer/agent.report_avg": 0.23682832717895508, "timer/agent.report_min": 0.22589612007141113, "timer/agent.report_max": 0.24776053428649902, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.528594970703125e-05, "timer/dataset_eval_frac": 3.5275361885760553e-08, "timer/dataset_eval_avg": 3.528594970703125e-05, "timer/dataset_eval_min": 3.528594970703125e-05, "timer/dataset_eval_max": 3.528594970703125e-05, "fps": 32.117807592749486}
{"step": 288768, "time": 9244.621815443039, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289048, "time": 9252.893117904663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289136, "time": 9255.787600755692, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 289168, "time": 9256.760859012604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289240, "time": 9258.731666326523, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 289432, "time": 9264.541341543198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289632, "time": 9270.933573961258, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 289904, "time": 9279.265801429749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289912, "time": 9279.295771598816, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 290008, "time": 9282.27059173584, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 9284.41109251976, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 290056, "time": 9284.886093378067, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 290056, "time": 9285.335540056229, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 290056, "time": 9285.67223906517, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 290056, "time": 9286.470311880112, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 290056, "time": 9287.131504774094, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 290056, "time": 9287.67704796791, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 290056, "time": 9288.073338270187, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 290432, "time": 9299.709420681, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 290632, "time": 9305.666929006577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290696, "time": 9307.641680717468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290912, "time": 9314.468560934067, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 291360, "time": 9328.143826007843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291448, "time": 9330.689270019531, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 291552, "time": 9334.104080915451, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291944, "time": 9345.926039457321, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292224, "time": 9354.702581167221, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292280, "time": 9356.203989744186, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 292320, "time": 9357.635056972504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292504, "time": 9363.127231121063, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 292784, "time": 9371.857253789902, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 292944, "time": 9376.731584310532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293008, "time": 9378.679721355438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293224, "time": 9385.076099157333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293760, "time": 9401.717576503754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294256, "time": 9416.888788700104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294592, "time": 9427.259073495865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294816, "time": 9434.107134342194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295096, "time": 9442.965424537659, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295256, "time": 9447.893290042877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295320, "time": 9449.853163480759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295536, "time": 9456.719993829727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295992, "time": 9470.327518224716, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 296072, "time": 9472.739609241486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296208, "time": 9477.10050535202, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 296568, "time": 9487.920503616333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296648, "time": 9490.371733903885, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 296664, "time": 9490.864374160767, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 296904, "time": 9498.140499591827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296928, "time": 9499.116165399551, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 296992, "time": 9501.052139759064, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 297120, "time": 9504.939198732376, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 297512, "time": 9516.677515506744, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 297568, "time": 9518.621459245682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297632, "time": 9520.564505577087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298520, "time": 9547.427758455276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298544, "time": 9548.38566327095, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 298888, "time": 9558.616526603699, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 298960, "time": 9561.02458357811, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298976, "time": 9561.514535427094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299432, "time": 9575.253258228302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299824, "time": 9587.569387674332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299880, "time": 9589.084356307983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299944, "time": 9591.078598022461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 9596.351904153824, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 300040, "time": 9597.087270498276, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 300040, "time": 9597.771553993225, "eval_episode/length": 188.0, "eval_episode/score": 0.4124999940395355, "eval_episode/reward_rate": 0.005291005291005291}
{"step": 300040, "time": 9598.25175690651, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 300040, "time": 9598.389209032059, "eval_episode/length": 220.0, "eval_episode/score": 0.3125, "eval_episode/reward_rate": 0.004524886877828055}
{"step": 300040, "time": 9599.644716262817, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9599.65382695198, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9599.660942554474, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9599.667864322662, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300264, "time": 9606.569011926651, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 300856, "time": 9624.666163682938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301032, "time": 9630.037833690643, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 301200, "time": 9635.582322120667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301272, "time": 9637.606246232986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301288, "time": 9638.108998537064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301520, "time": 9645.380910158157, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 301744, "time": 9652.230884552002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302192, "time": 9666.025298833847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302560, "time": 9677.222701787949, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 302576, "time": 9677.72043800354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303344, "time": 9701.694727659225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303584, "time": 9708.98348236084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303600, "time": 9709.47595834732, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 303600, "time": 9709.487183094025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303832, "time": 9716.351292133331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304056, "time": 9723.296050071716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304504, "time": 9737.099496364594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304800, "time": 9746.398205518723, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 304872, "time": 9748.390800237656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305440, "time": 9765.98132967949, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 305528, "time": 9768.448642730713, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 305656, "time": 9772.343258857727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305912, "time": 9780.144636392593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305912, "time": 9780.152953147888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306144, "time": 9787.505063056946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306192, "time": 9788.983175754547, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 306368, "time": 9794.315915346146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306536, "time": 9799.210464715958, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 306816, "time": 9807.928086519241, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307416, "time": 9826.001588821411, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 307520, "time": 9829.414984941483, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 307840, "time": 9839.141996860504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308224, "time": 9850.878356456757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308456, "time": 9857.749254703522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308680, "time": 9864.533259153366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308848, "time": 9869.873974084854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309128, "time": 9878.220280885696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309728, "time": 9896.75594496727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309832, "time": 9899.722432136536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 9909.099483251572, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 310024, "time": 9909.581571340561, "eval_episode/length": 175.0, "eval_episode/score": 0.453125, "eval_episode/reward_rate": 0.005681818181818182}
{"step": 310024, "time": 9910.450823783875, "eval_episode/length": 220.0, "eval_episode/score": 0.3125, "eval_episode/reward_rate": 0.004524886877828055}
{"step": 310024, "time": 9910.898352622986, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 310024, "time": 9911.794349193573, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 9911.80192399025, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 9911.8087079525, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 9911.815370798111, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 9911.822235822678, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310152, "time": 9915.72039270401, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310536, "time": 9927.415996789932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310616, "time": 9929.850938796997, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 310768, "time": 9934.785680770874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311088, "time": 9944.505488395691, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.0}
{"step": 311440, "time": 9955.689731359482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311776, "time": 9966.08356809616, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 312040, "time": 9973.887541294098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312144, "time": 9977.286526679993, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312464, "time": 9987.026083230972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312584, "time": 9990.591138124466, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 312680, "time": 9993.528997421265, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 312928, "time": 10001.33170580864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313080, "time": 10005.818133831024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313136, "time": 10007.784080028534, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 313752, "time": 10026.407024860382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314088, "time": 10036.60626244545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314256, "time": 10041.949608325958, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 314352, "time": 10044.888411998749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314696, "time": 10055.22028374672, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 314776, "time": 10057.641118526459, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314992, "time": 10064.432477474213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315048, "time": 10065.905622959137, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 315240, "time": 10071.76373553276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315448, "time": 10078.084891557693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315976, "time": 10094.248707532883, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 316024, "time": 10095.711957216263, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 316064, "time": 10097.161870241165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316136, "time": 10099.137530088425, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 316280, "time": 10103.524070978165, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 316640, "time": 10114.854939460754, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 316840, "time": 10120.71921634674, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 317040, "time": 10127.01786851883, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 317224, "time": 10132.416071414948, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 317464, "time": 10139.75723361969, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 317640, "time": 10145.195110797882, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 318176, "time": 10161.778277873993, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 318248, "time": 10163.766900777817, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 318288, "time": 10165.20605635643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318336, "time": 10166.687475919724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318592, "time": 10174.60194182396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319352, "time": 10197.524715900421, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319536, "time": 10203.892470121384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319776, "time": 10211.192260742188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 10219.687650203705, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 320008, "time": 10220.340875148773, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 320008, "time": 10220.678535938263, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 320008, "time": 10222.003337621689, "eval_episode/length": 212.0, "eval_episode/score": 0.3375000059604645, "eval_episode/reward_rate": 0.004694835680751174}
{"step": 320008, "time": 10223.392867803574, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10223.400840759277, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10223.408593177795, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10223.415817022324, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320361, "time": 10235.194475889206, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6184146440208855, "train/action_min": 0.0, "train/action_std": 1.5715883583878751, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005859809944607392, "train/actor_opt_grad_steps": 18930.0, "train/actor_opt_loss": 18.030770304701736, "train/adv_mag": 0.10767456252670768, "train/adv_max": 0.06259254122798766, "train/adv_mean": 0.007334610167382567, "train/adv_min": -0.07565845811187323, "train/adv_std": 0.010238343585942446, "train/cont_avg": 0.9963440248115578, "train/cont_loss_mean": 0.022248581416867485, "train/cont_loss_std": 0.30458564104292374, "train/cont_neg_acc": 0.01351611361359105, "train/cont_neg_loss": 5.101168390476342, "train/cont_pos_acc": 0.9999802558865379, "train/cont_pos_loss": 0.0036374071914814974, "train/cont_pred": 0.9963280870087782, "train/cont_rate": 0.9963440248115578, "train/dyn_loss_mean": 1.000011093652428, "train/dyn_loss_std": 0.00023646066978444513, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7411753333000531, "train/extr_critic_critic_opt_grad_steps": 18930.0, "train/extr_critic_critic_opt_loss": 10868.431218592965, "train/extr_critic_mag": 0.3473742499423386, "train/extr_critic_max": 0.3473742499423386, "train/extr_critic_mean": 0.336987229447868, "train/extr_critic_min": 0.3195699189775553, "train/extr_critic_std": 0.005391348697404242, "train/extr_return_normed_mag": 0.12266274687632843, "train/extr_return_normed_max": 0.0878125670267709, "train/extr_return_normed_mean": 0.026987543616832314, "train/extr_return_normed_min": -0.055241436814542993, "train/extr_return_normed_std": 0.0120353114618054, "train/extr_return_rate": 0.013956829253050333, "train/extr_return_raw_mag": 0.40514684539643964, "train/extr_return_raw_max": 0.40514684539643964, "train/extr_return_raw_mean": 0.34432183880003253, "train/extr_return_raw_min": 0.26209284155512574, "train/extr_return_raw_std": 0.012035311532005592, "train/extr_reward_mag": 0.048808242208394574, "train/extr_reward_max": 0.048808242208394574, "train/extr_reward_mean": 0.0019804895490591634, "train/extr_reward_min": 3.402556606273555e-07, "train/extr_reward_std": 0.0064139038782997345, "train/image_loss_mean": 0.14915736648605096, "train/image_loss_std": 0.10768078866615967, "train/model_loss_mean": 0.7748264460707429, "train/model_loss_std": 0.37997284572777434, "train/model_opt_grad_norm": 33.919621342989664, "train/model_opt_grad_steps": 18911.21608040201, "train/model_opt_loss": 2208.6563935399654, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2851.758793969849, "train/policy_entropy_mag": 1.5708447251487616, "train/policy_entropy_max": 1.5708447251487616, "train/policy_entropy_mean": 0.36263584499083573, "train/policy_entropy_min": 0.06496784199572089, "train/policy_entropy_std": 0.31806572650245685, "train/policy_logprob_mag": 6.550496810644716, "train/policy_logprob_max": -0.008651883580052673, "train/policy_logprob_mean": -0.36276590943935527, "train/policy_logprob_min": -6.550496810644716, "train/policy_logprob_std": 0.8399158422671371, "train/policy_randomness_mag": 0.8072545468507699, "train/policy_randomness_max": 0.8072545468507699, "train/policy_randomness_mean": 0.18635797249761657, "train/policy_randomness_min": 0.033386868429393625, "train/policy_randomness_std": 0.16345345981456527, "train/post_ent_mag": 42.43423908559521, "train/post_ent_max": 42.43423908559521, "train/post_ent_mean": 42.08901143673077, "train/post_ent_min": 41.86122731347779, "train/post_ent_std": 0.10059553908942333, "train/prior_ent_mag": 43.351460710841806, "train/prior_ent_max": 43.351460710841806, "train/prior_ent_mean": 41.18384049765429, "train/prior_ent_min": 40.0405612159614, "train/prior_ent_std": 0.4845400364255186, "train/rep_loss_mean": 1.000011093652428, "train/rep_loss_std": 0.00023646066978444513, "train/reward_avg": 0.0002870952681844221, "train/reward_loss_mean": 0.0034138229090589375, "train/reward_loss_std": 0.08316209870340868, "train/reward_max_data": 0.2346576634962954, "train/reward_max_pred": 0.020300312257891324, "train/reward_neg_acc": 0.9999950926507538, "train/reward_neg_loss": 0.0004462942607328179, "train/reward_pos_acc": 0.037037037037037035, "train/reward_pos_loss": 5.7237893210517035, "train/reward_pred": 0.00019482029227530537, "train/reward_rate": 0.0005201790201005025, "train_stats/mean_log_entropy": 0.3541248409875802, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.014745195396244526, "report/cont_loss_std": 0.2383406013250351, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.003011226654053, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0030264914967119694, "report/cont_pred": 0.9968225955963135, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.13503193855285645, "report/image_loss_std": 0.09735186398029327, "report/model_loss_mean": 0.7498773336410522, "report/model_loss_std": 0.25738605856895447, "report/post_ent_mag": 40.77532958984375, "report/post_ent_max": 40.77532958984375, "report/post_ent_mean": 40.44739532470703, "report/post_ent_min": 40.26964569091797, "report/post_ent_std": 0.09065856784582138, "report/prior_ent_mag": 41.66546630859375, "report/prior_ent_max": 41.66546630859375, "report/prior_ent_mean": 39.2333984375, "report/prior_ent_min": 37.50591278076172, "report/prior_ent_std": 0.6254480481147766, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00010012136772274971, "report/reward_loss_std": 0.0009793508797883987, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.009355545043945312, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00010012136772274971, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.2051891796290874e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.04217758774757385, "eval/cont_loss_std": 0.5238457322120667, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.795918941497803, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0023716476280242205, "eval/cont_pred": 0.997638463973999, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1920246183872223, "eval/image_loss_std": 0.12271320819854736, "eval/model_loss_mean": 0.8342670202255249, "eval/model_loss_std": 0.5355321764945984, "eval/post_ent_mag": 40.77544021606445, "eval/post_ent_max": 40.77544021606445, "eval/post_ent_mean": 40.44914627075195, "eval/post_ent_min": 40.23716735839844, "eval/post_ent_std": 0.08921705931425095, "eval/prior_ent_mag": 41.1644287109375, "eval/prior_ent_max": 41.1644287109375, "eval/prior_ent_mean": 39.133705139160156, "eval/prior_ent_min": 37.41143035888672, "eval/prior_ent_std": 0.5171366333961487, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 6.485404446721077e-05, "eval/reward_loss_std": 0.0006444116588681936, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.006509184837341309, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 6.485404446721077e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 2.704549115151167e-05, "eval/reward_rate": 0.0, "replay/size": 319857.0, "replay/inserts": 31904.0, "replay/samples": 31904.0, "replay/insert_wait_avg": 1.3072518192777184e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.165373008253581e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 76832.0, "eval_replay/inserts": 8728.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1885963810571938e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0820066928864, "timer/env.step_count": 3988.0, "timer/env.step_total": 38.295825481414795, "timer/env.step_frac": 0.03829268522493776, "timer/env.step_avg": 0.009602764664346739, "timer/env.step_min": 0.007748842239379883, "timer/env.step_max": 0.035314083099365234, "timer/replay._sample_count": 31904.0, "timer/replay._sample_total": 16.412303686141968, "timer/replay._sample_frac": 0.016410957877759317, "timer/replay._sample_avg": 0.0005144277735124739, "timer/replay._sample_min": 0.00039005279541015625, "timer/replay._sample_max": 0.03090667724609375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5079.0, "timer/agent.policy_total": 53.66229796409607, "timer/agent.policy_frac": 0.05365789765736195, "timer/agent.policy_avg": 0.010565524308741104, "timer/agent.policy_min": 0.008349180221557617, "timer/agent.policy_max": 0.08377337455749512, "timer/dataset_train_count": 1994.0, "timer/dataset_train_total": 0.22277450561523438, "timer/dataset_train_frac": 0.00022275623811282693, "timer/dataset_train_avg": 0.00011172242006782066, "timer/dataset_train_min": 9.775161743164062e-05, "timer/dataset_train_max": 0.0010733604431152344, "timer/agent.train_count": 1994.0, "timer/agent.train_total": 892.1187918186188, "timer/agent.train_frac": 0.892045638105934, "timer/agent.train_avg": 0.4474016007114437, "timer/agent.train_min": 0.43725109100341797, "timer/agent.train_max": 0.6920092105865479, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4822726249694824, "timer/agent.report_frac": 0.0004822330786295036, "timer/agent.report_avg": 0.2411363124847412, "timer/agent.report_min": 0.23404645919799805, "timer/agent.report_max": 0.24822616577148438, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 6.413459777832031e-05, "timer/dataset_eval_frac": 6.412933874333298e-08, "timer/dataset_eval_avg": 6.413459777832031e-05, "timer/dataset_eval_min": 6.413459777832031e-05, "timer/dataset_eval_max": 6.413459777832031e-05, "fps": 31.900849422392525}
{"step": 320488, "time": 10238.84272646904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320560, "time": 10241.255431175232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320600, "time": 10242.268488645554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320648, "time": 10243.723155260086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320904, "time": 10251.496301412582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321664, "time": 10274.952157258987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321848, "time": 10280.33250784874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322088, "time": 10287.647119760513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322392, "time": 10296.965801000595, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 322448, "time": 10298.884528160095, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 322640, "time": 10304.704180240631, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 322728, "time": 10307.16728568077, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.0}
{"step": 322872, "time": 10311.530935764313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322960, "time": 10314.417122364044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 323760, "time": 10338.724497556686, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 323824, "time": 10340.688699245453, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 323960, "time": 10344.590907812119, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 323976, "time": 10345.080129861832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324248, "time": 10353.544333457947, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 324400, "time": 10358.362208366394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324952, "time": 10374.88682961464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325184, "time": 10382.264201164246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326072, "time": 10408.960475683212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326136, "time": 10410.990164756775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326272, "time": 10415.402772188187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326288, "time": 10415.907013893127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326296, "time": 10415.937782049179, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 326320, "time": 10416.909381866455, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 326416, "time": 10419.892810106277, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 326560, "time": 10424.348186254501, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326888, "time": 10434.191747426987, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 327296, "time": 10446.901010036469, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 327680, "time": 10458.733801841736, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 327768, "time": 10461.560109376907, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 327904, "time": 10465.925013303757, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 327976, "time": 10467.916749954224, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 328136, "time": 10472.882583379745, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 328200, "time": 10474.83469080925, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 328384, "time": 10480.642259597778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 328576, "time": 10486.486339569092, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 328584, "time": 10486.515899181366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 328600, "time": 10487.024858474731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 328632, "time": 10488.00031208992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 328744, "time": 10491.411377429962, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 329112, "time": 10502.666056394577, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 329392, "time": 10511.435716152191, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 329992, "time": 10529.351218223572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 10533.24898314476, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 330096, "time": 10533.893139839172, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 330096, "time": 10534.030805587769, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 330096, "time": 10534.271734952927, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 330096, "time": 10534.871346235275, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 330096, "time": 10536.427225351334, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 330096, "time": 10537.995985031128, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10538.003138303757, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10538.009651184082, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330512, "time": 10550.534450769424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330528, "time": 10551.019902706146, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 330696, "time": 10555.893363237381, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330848, "time": 10560.803173065186, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 330888, "time": 10561.785501480103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330896, "time": 10562.249926567078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330912, "time": 10562.740461826324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330944, "time": 10563.71624326706, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 331424, "time": 10578.211821556091, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331544, "time": 10581.61111831665, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 331704, "time": 10586.446781873703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331720, "time": 10586.937475442886, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 331832, "time": 10590.4088037014, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 331976, "time": 10594.785818099976, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 331992, "time": 10595.273008108139, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 332008, "time": 10595.760793209076, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 332344, "time": 10605.908370494843, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 332352, "time": 10606.380290985107, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 332496, "time": 10610.747420310974, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 332824, "time": 10620.6368663311, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 333208, "time": 10632.252487421036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334032, "time": 10657.571041822433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334288, "time": 10665.354419708252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334304, "time": 10665.859413385391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334656, "time": 10676.56521987915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334664, "time": 10676.593999147415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334808, "time": 10681.056045293808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335136, "time": 10691.212258577347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335520, "time": 10702.870235443115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336344, "time": 10728.105840921402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336600, "time": 10735.839606046677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336616, "time": 10736.326714515686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336968, "time": 10746.991064548492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336976, "time": 10747.456356525421, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337120, "time": 10751.773644447327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337448, "time": 10761.570555210114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337832, "time": 10773.243432998657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338656, "time": 10798.431201696396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338912, "time": 10806.28708910942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338928, "time": 10806.779140472412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339280, "time": 10817.426521778107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339288, "time": 10817.456074237823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339432, "time": 10821.82126569748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339752, "time": 10831.605406045914, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 339760, "time": 10832.077618598938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339832, "time": 10834.052989721298, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 10842.826112985611, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 340080, "time": 10842.902426242828, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 340080, "time": 10843.086111307144, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 340080, "time": 10843.494144916534, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 340080, "time": 10844.75087594986, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 340080, "time": 10845.860984325409, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 340080, "time": 10847.525765895844, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10847.534013032913, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10847.583901643753, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10847.619163751602, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10847.649594068527, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340144, "time": 10849.642891645432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340384, "time": 10856.907175779343, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 340624, "time": 10864.27662396431, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 341136, "time": 10879.78339099884, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 341224, "time": 10882.22595667839, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341376, "time": 10887.061307430267, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 341600, "time": 10894.020408391953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341744, "time": 10898.387104511261, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342064, "time": 10908.089070558548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342456, "time": 10919.73729801178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342696, "time": 10927.136185646057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343448, "time": 10949.953161239624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343528, "time": 10952.481684207916, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 343536, "time": 10952.953382492065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343576, "time": 10953.950375080109, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 343584, "time": 10954.420020341873, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 343688, "time": 10957.365571975708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343696, "time": 10957.838162899017, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 343904, "time": 10964.16240143776, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 345624, "time": 11016.696108579636, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 345760, "time": 11021.039609193802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345840, "time": 11023.468691587448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345848, "time": 11023.497010707855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345888, "time": 11024.949024915695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345896, "time": 11024.978294610977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346000, "time": 11028.342468500137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346216, "time": 11034.693960428238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346744, "time": 11050.823748588562, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 346752, "time": 11051.294737815857, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 346952, "time": 11057.139880657196, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 347936, "time": 11087.383992433548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348072, "time": 11091.311666965485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348200, "time": 11095.217485427856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348312, "time": 11098.630826473236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348528, "time": 11105.477335453033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 349056, "time": 11121.683554410934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 349064, "time": 11121.713454246521, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 349264, "time": 11128.022378444672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 11153.816899299622, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 350064, "time": 11154.190492153168, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 350064, "time": 11154.846930265427, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 350064, "time": 11154.970733880997, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 350064, "time": 11156.623270988464, "eval_episode/length": 225.0, "eval_episode/score": 0.296875, "eval_episode/reward_rate": 0.004424778761061947}
{"step": 350064, "time": 11157.102744817734, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 350064, "time": 11157.792984485626, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11157.802315473557, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11157.80908370018, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350200, "time": 11162.854569673538, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 350248, "time": 11164.313915014267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350376, "time": 11168.210327625275, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 350384, "time": 11168.677315473557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350504, "time": 11172.076357364655, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 350512, "time": 11172.563123464584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350624, "time": 11175.933498620987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350896, "time": 11184.170884609222, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 351344, "time": 11197.810081005096, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 351368, "time": 11198.320234060287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 351536, "time": 11203.623943567276, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 351680, "time": 11207.985204696655, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 351824, "time": 11212.413509607315, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 352096, "time": 11220.797171592712, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 352104, "time": 11220.826298713684, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 352232, "time": 11224.712309837341, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 352537, "time": 11235.383197069168, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6437982208100124, "train/action_min": 0.0, "train/action_std": 1.5846630198445486, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013819497056648283, "train/actor_opt_grad_steps": 20930.0, "train/actor_opt_loss": 1.3222779931491286, "train/adv_mag": 0.43636800385826263, "train/adv_max": 0.26994246125814336, "train/adv_mean": 0.007529913545751235, "train/adv_min": -0.37202191278709107, "train/adv_std": 0.036489014374787236, "train/cont_avg": 0.9963463930348259, "train/cont_loss_mean": 0.01865328701481742, "train/cont_loss_std": 0.2687310516157776, "train/cont_neg_acc": 0.11775397017598152, "train/cont_neg_loss": 4.146517083495855, "train/cont_pos_acc": 0.9999073263424546, "train/cont_pos_loss": 0.0034051379779659547, "train/cont_pred": 0.9962321051317661, "train/cont_rate": 0.9963463930348259, "train/dyn_loss_mean": 1.0000073020137958, "train/dyn_loss_std": 0.00014001724106202883, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1173176948555665, "train/extr_critic_critic_opt_grad_steps": 20930.0, "train/extr_critic_critic_opt_loss": 12031.113057758084, "train/extr_critic_mag": 0.5205861851943666, "train/extr_critic_max": 0.5205861851943666, "train/extr_critic_mean": 0.5103764347176054, "train/extr_critic_min": 0.49312527677906093, "train/extr_critic_std": 0.005604440937124526, "train/extr_return_normed_mag": 0.43778108453276143, "train/extr_return_normed_max": 0.3002575192581955, "train/extr_return_normed_mean": 0.03317678236722279, "train/extr_return_normed_min": -0.3427048138718107, "train/extr_return_normed_std": 0.03713537587909334, "train/extr_return_rate": 0.3871395149280807, "train/extr_return_raw_mag": 0.7849870751153177, "train/extr_return_raw_max": 0.7849870751153177, "train/extr_return_raw_mean": 0.5179063631824, "train/extr_return_raw_min": 0.14202474168877102, "train/extr_return_raw_std": 0.03713537584665922, "train/extr_reward_mag": 0.28334241245516495, "train/extr_reward_max": 0.28334241245516495, "train/extr_reward_mean": 0.002711559928399372, "train/extr_reward_min": 1.5894571940104166e-07, "train/extr_reward_std": 0.014947137097186357, "train/image_loss_mean": 0.1265013136377382, "train/image_loss_std": 0.1046270977205305, "train/model_loss_mean": 0.7479143889982309, "train/model_loss_std": 0.33342133899826315, "train/model_opt_grad_norm": 31.27990645318482, "train/model_opt_grad_steps": 20909.3631840796, "train/model_opt_loss": 1973.4143376136894, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2636.81592039801, "train/policy_entropy_mag": 1.4624332237006419, "train/policy_entropy_max": 1.4624332237006419, "train/policy_entropy_mean": 0.23007030195709485, "train/policy_entropy_min": 0.06469486883623683, "train/policy_entropy_std": 0.251105739850903, "train/policy_logprob_mag": 6.551070146892794, "train/policy_logprob_max": -0.008609617110434457, "train/policy_logprob_mean": -0.22931383817053552, "train/policy_logprob_min": -6.551070146892794, "train/policy_logprob_std": 0.7468486493499717, "train/policy_randomness_mag": 0.7515420540055232, "train/policy_randomness_max": 0.7515420540055232, "train/policy_randomness_mean": 0.11823275403596868, "train/policy_randomness_min": 0.0332465877024392, "train/policy_randomness_std": 0.1290428303367463, "train/post_ent_mag": 39.8519286919589, "train/post_ent_max": 39.8519286919589, "train/post_ent_mean": 39.54711678727942, "train/post_ent_min": 39.355484597125454, "train/post_ent_std": 0.08668725982085983, "train/prior_ent_mag": 40.25995609416297, "train/prior_ent_max": 40.25995609416297, "train/prior_ent_mean": 38.419176661553074, "train/prior_ent_min": 37.27519863754956, "train/prior_ent_std": 0.40101740920721596, "train/rep_loss_mean": 1.0000073020137958, "train/rep_loss_std": 0.00014001724106202883, "train/reward_avg": 0.0002979335513916353, "train/reward_loss_mean": 0.002755384497224024, "train/reward_loss_std": 0.06446378075286621, "train/reward_max_data": 0.24430970243405348, "train/reward_max_pred": 0.06415091640320583, "train/reward_neg_acc": 0.9999222257244054, "train/reward_neg_loss": 0.0005089608678450595, "train/reward_pos_acc": 0.1400000003973643, "train/reward_pos_loss": 4.643926204045614, "train/reward_pred": 0.00025855869388402396, "train/reward_rate": 0.0004809934701492537, "train_stats/mean_log_entropy": 0.2113618571944788, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.016859041526913643, "report/cont_loss_std": 0.24891898036003113, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 3.0890233516693115, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0017846351256594062, "report/cont_pred": 0.9972650408744812, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.12180187553167343, "report/image_loss_std": 0.10575663298368454, "report/model_loss_mean": 0.7411791086196899, "report/model_loss_std": 0.29029056429862976, "report/post_ent_mag": 38.872093200683594, "report/post_ent_max": 38.872093200683594, "report/post_ent_mean": 38.58541488647461, "report/post_ent_min": 38.41743469238281, "report/post_ent_std": 0.08801344037055969, "report/prior_ent_mag": 39.386322021484375, "report/prior_ent_max": 39.386322021484375, "report/prior_ent_mean": 37.597801208496094, "report/prior_ent_min": 36.383949279785156, "report/prior_ent_std": 0.47022736072540283, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0009124755742959678, "report/reward_loss_mean": 0.002518207300454378, "report/reward_loss_std": 0.06673641502857208, "report/reward_max_data": 0.934374988079071, "report/reward_max_pred": 0.43113505840301514, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0004328059440013021, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 2.1358838081359863, "report/reward_pred": 0.0006129123503342271, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.007641871925443411, "eval/cont_loss_std": 0.18740379810333252, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.994682788848877, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001789437374100089, "eval/cont_pred": 0.998249888420105, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21200940012931824, "eval/image_loss_std": 0.13093653321266174, "eval/model_loss_mean": 0.8197194337844849, "eval/model_loss_std": 0.2312304675579071, "eval/post_ent_mag": 38.86695098876953, "eval/post_ent_max": 38.86695098876953, "eval/post_ent_mean": 38.54931640625, "eval/post_ent_min": 38.33417510986328, "eval/post_ent_std": 0.08126972615718842, "eval/prior_ent_mag": 39.14744186401367, "eval/prior_ent_max": 39.14744186401367, "eval/prior_ent_mean": 37.5235595703125, "eval/prior_ent_min": 36.223114013671875, "eval/prior_ent_std": 0.4627697467803955, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 6.819330155849457e-05, "eval/reward_loss_std": 0.0006364686996676028, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.006492018699645996, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 6.819330155849457e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.007019404321909e-05, "eval/reward_rate": 0.0, "replay/size": 352033.0, "replay/inserts": 32176.0, "replay/samples": 32176.0, "replay/insert_wait_avg": 1.3046629804689928e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.67532063621244e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 83768.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1351694285250865e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1715087890625, "timer/env.step_count": 4022.0, "timer/env.step_total": 38.41071891784668, "timer/env.step_frac": 0.03840413227162578, "timer/env.step_avg": 0.009550153883104595, "timer/env.step_min": 0.007588863372802734, "timer/env.step_max": 0.035390377044677734, "timer/replay._sample_count": 32176.0, "timer/replay._sample_total": 15.877233266830444, "timer/replay._sample_frac": 0.01587451064873212, "timer/replay._sample_avg": 0.0004934495669701158, "timer/replay._sample_min": 0.0003800392150878906, "timer/replay._sample_max": 0.011246681213378906, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4889.0, "timer/agent.policy_total": 51.20518636703491, "timer/agent.policy_frac": 0.05119640573348321, "timer/agent.policy_avg": 0.010473550085300657, "timer/agent.policy_min": 0.008849620819091797, "timer/agent.policy_max": 0.09686851501464844, "timer/dataset_train_count": 2011.0, "timer/dataset_train_total": 0.2180933952331543, "timer/dataset_train_frac": 0.0002180559967132102, "timer/dataset_train_avg": 0.0001084502213988833, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.00019741058349609375, "timer/agent.train_count": 2011.0, "timer/agent.train_total": 896.9544973373413, "timer/agent.train_frac": 0.8968006881372884, "timer/agent.train_avg": 0.4460241160305029, "timer/agent.train_min": 0.43283987045288086, "timer/agent.train_max": 1.5037178993225098, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.474628210067749, "timer/agent.report_frac": 0.0004745468211171058, "timer/agent.report_avg": 0.2373141050338745, "timer/agent.report_min": 0.23240351676940918, "timer/agent.report_max": 0.24222469329833984, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.075072268489108e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 32.16998882054847}
{"step": 352688, "time": 11239.941329240799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352696, "time": 11239.970351457596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352704, "time": 11240.440672397614, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 352776, "time": 11242.432369470596, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 352824, "time": 11243.891408920288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352872, "time": 11245.3508644104, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 353064, "time": 11251.314509153366, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 353224, "time": 11256.192550420761, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 353248, "time": 11257.171627998352, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 353584, "time": 11267.35585141182, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 353736, "time": 11271.749629020691, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 354056, "time": 11281.594876289368, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 354136, "time": 11284.014830827713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 354184, "time": 11285.482848644257, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 354416, "time": 11292.752608060837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 354808, "time": 11304.417607307434, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 354896, "time": 11307.316192150116, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 355000, "time": 11310.296425104141, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355088, "time": 11313.223517417908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355320, "time": 11320.038951158524, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 355480, "time": 11324.891694545746, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 355832, "time": 11335.576528549194, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 356040, "time": 11341.91198015213, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 356048, "time": 11342.379646539688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 356264, "time": 11348.702906608582, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 356368, "time": 11352.076894044876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 356448, "time": 11354.501792430878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 356568, "time": 11357.916858196259, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 356784, "time": 11364.722792863846, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 357128, "time": 11375.003381252289, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 357208, "time": 11377.428102254868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357768, "time": 11394.427418231964, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 357792, "time": 11395.386903047562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357992, "time": 11401.298904657364, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 358144, "time": 11406.118684530258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358192, "time": 11407.586579799652, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 358352, "time": 11412.44625878334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358640, "time": 11421.169808626175, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 358680, "time": 11422.184618234634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358832, "time": 11427.022403717041, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 358880, "time": 11428.468985080719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359096, "time": 11434.90818619728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359208, "time": 11438.35522389412, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 11465.200355291367, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 360048, "time": 11466.177711486816, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 360048, "time": 11466.704329252243, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 360048, "time": 11467.151778459549, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 360048, "time": 11467.288263559341, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 360048, "time": 11468.119802236557, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 360048, "time": 11469.482840061188, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11469.491539001465, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11469.498250246048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11469.505918741226, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11469.512456178665, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360232, "time": 11474.89453792572, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 360304, "time": 11477.319170713425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 360456, "time": 11481.956548690796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 360952, "time": 11497.336407899857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361024, "time": 11499.742398023605, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 361144, "time": 11503.18291425705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361192, "time": 11504.643592596054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361408, "time": 11511.429402589798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361520, "time": 11514.823635339737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361640, "time": 11518.253145694733, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 361848, "time": 11524.653017044067, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 361936, "time": 11527.561159133911, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 362424, "time": 11542.167496919632, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 362616, "time": 11548.019888877869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362768, "time": 11552.950438261032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362848, "time": 11555.40049982071, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 363336, "time": 11569.934660196304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363384, "time": 11571.396371364594, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 363456, "time": 11573.788021326065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363720, "time": 11581.647970676422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363792, "time": 11584.115513086319, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 363824, "time": 11585.100717544556, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 363832, "time": 11585.131039142609, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363960, "time": 11589.027188062668, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 364008, "time": 11590.48892235756, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 364232, "time": 11597.25281882286, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 364336, "time": 11600.620183706284, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 364616, "time": 11608.866794347763, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 364736, "time": 11612.791298389435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 364816, "time": 11615.247922420502, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 364944, "time": 11619.147198200226, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 365080, "time": 11623.059251785278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365304, "time": 11629.858431339264, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 365344, "time": 11631.310215950012, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 365448, "time": 11634.263239145279, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 365824, "time": 11645.964873075485, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 365824, "time": 11645.972116947174, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 366032, "time": 11652.314398288727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 366512, "time": 11666.968629837036, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 366544, "time": 11667.955562829971, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 366792, "time": 11675.395977020264, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 367048, "time": 11683.155618429184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367392, "time": 11693.793708562851, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367656, "time": 11701.644627094269, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367760, "time": 11705.016243696213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368184, "time": 11717.68767619133, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 368288, "time": 11721.080179929733, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 368344, "time": 11722.561860084534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368824, "time": 11737.637506961823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368856, "time": 11738.600999116898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369016, "time": 11743.463617563248, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 369104, "time": 11746.376606702805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369360, "time": 11754.147241353989, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369456, "time": 11757.066994905472, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 369704, "time": 11764.460289001465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 11776.516834974289, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 370032, "time": 11776.64973950386, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 370032, "time": 11778.48336148262, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 370032, "time": 11779.773987531662, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11779.781150102615, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11779.787795066833, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11779.793756961823, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11779.801211595535, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11779.807980060577, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370496, "time": 11793.860273361206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370504, "time": 11793.888665676117, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 370600, "time": 11796.794836997986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371168, "time": 11814.20572566986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371328, "time": 11819.042464017868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371416, "time": 11821.580525398254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371576, "time": 11826.413786411285, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 371704, "time": 11830.29315161705, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 371832, "time": 11834.161166191101, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 371928, "time": 11837.048595666885, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 372016, "time": 11839.93798327446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 372808, "time": 11863.730195045471, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 372912, "time": 11867.110208272934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373480, "time": 11884.086236715317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373888, "time": 11896.607637166977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374016, "time": 11900.469431877136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374040, "time": 11900.996321439743, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 374144, "time": 11904.335991382599, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374240, "time": 11907.233302354813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374272, "time": 11908.196080207825, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 374328, "time": 11909.657216310501, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374544, "time": 11916.468637228012, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 374920, "time": 11927.557633161545, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 374944, "time": 11928.50415110588, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 375120, "time": 11933.81065583229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375224, "time": 11936.717586040497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375344, "time": 11940.618535041809, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 375904, "time": 11957.491582632065, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 376328, "time": 11970.138762235641, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376456, "time": 11974.08910560608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376584, "time": 11977.935449361801, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376856, "time": 11986.6164290905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377232, "time": 11998.19616150856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377256, "time": 11998.707573652267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377592, "time": 12009.007551908493, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 377656, "time": 12010.948498010635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378216, "time": 12027.892715930939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378400, "time": 12033.768821001053, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 378640, "time": 12041.050230264664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378896, "time": 12048.890924692154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379144, "time": 12056.288258314133, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 379568, "time": 12069.47294640541, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379904, "time": 12079.639077186584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379968, "time": 12081.59170794487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 12083.729932308197, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 380016, "time": 12083.73508143425, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 380016, "time": 12084.316547632217, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 380016, "time": 12084.580147266388, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 380016, "time": 12084.980527162552, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 380016, "time": 12088.213912963867, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 380016, "time": 12088.807673931122, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12088.832178115845, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12088.853784322739, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380264, "time": 12096.164044618607, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 380288, "time": 12097.125163555145, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 380336, "time": 12098.570466518402, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 380432, "time": 12101.473267316818, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 380440, "time": 12102.44115614891, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 380712, "time": 12110.678126573563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380760, "time": 12112.153349399567, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 380952, "time": 12117.956001281738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 381184, "time": 12125.26860165596, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 381344, "time": 12130.10566687584, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 381824, "time": 12144.582025527954, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 381872, "time": 12146.06114411354, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 382280, "time": 12158.306395292282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382648, "time": 12169.408243179321, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382744, "time": 12172.387772798538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382752, "time": 12172.86658358574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383072, "time": 12182.680731534958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383264, "time": 12188.485547065735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383296, "time": 12189.456796884537, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 383568, "time": 12197.665855884552, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 383688, "time": 12201.07286810875, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 383864, "time": 12206.405594110489, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 384032, "time": 12211.79875087738, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 384136, "time": 12214.73554968834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 384184, "time": 12216.19737958908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 384392, "time": 12222.509817361832, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 384464, "time": 12224.924493074417, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 384592, "time": 12228.822778701782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 384793, "time": 12235.628387928009, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.3159693349706063, "train/action_min": 0.0, "train/action_std": 2.028586143904393, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010446390114023839, "train/actor_opt_grad_steps": 22945.0, "train/actor_opt_loss": -4.962041196182812, "train/adv_mag": 0.581571875232281, "train/adv_max": 0.23824960672029175, "train/adv_mean": 0.003820442553304848, "train/adv_min": -0.5602705744233462, "train/adv_std": 0.03830721124656277, "train/cont_avg": 0.9959052057549505, "train/cont_loss_mean": 0.015365583337451525, "train/cont_loss_std": 0.23134368268938937, "train/cont_neg_acc": 0.31740249311504654, "train/cont_neg_loss": 3.046238066539655, "train/cont_pos_acc": 0.9998204038284793, "train/cont_pos_loss": 0.002880572064463879, "train/cont_pred": 0.9960651713432652, "train/cont_rate": 0.9959052057549505, "train/dyn_loss_mean": 1.0000627436260185, "train/dyn_loss_std": 0.001168760427246147, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.22724052171896, "train/extr_critic_critic_opt_grad_steps": 22945.0, "train/extr_critic_critic_opt_loss": 10771.639423634746, "train/extr_critic_mag": 0.6822803227028044, "train/extr_critic_max": 0.6822803227028044, "train/extr_critic_mean": 0.6599557284671481, "train/extr_critic_min": 0.6339403479406149, "train/extr_critic_std": 0.00999074662104249, "train/extr_return_normed_mag": 0.5595012313068504, "train/extr_return_normed_max": 0.28944443387560326, "train/extr_return_normed_mean": 0.04135808093435279, "train/extr_return_normed_min": -0.5196047127246857, "train/extr_return_normed_std": 0.04027843511764809, "train/extr_return_rate": 0.9892108030248397, "train/extr_return_raw_mag": 0.9118625188227927, "train/extr_return_raw_max": 0.9118625188227927, "train/extr_return_raw_mean": 0.6637761935149089, "train/extr_return_raw_min": 0.10281337222250381, "train/extr_return_raw_std": 0.04027843499316437, "train/extr_reward_mag": 0.2766147232291722, "train/extr_reward_max": 0.2766147232291722, "train/extr_reward_mean": 0.002777292606564029, "train/extr_reward_min": 1.5638842441067838e-07, "train/extr_reward_std": 0.013028791321540657, "train/image_loss_mean": 0.11182852063586216, "train/image_loss_std": 0.10312594373775001, "train/model_loss_mean": 0.7310271735238557, "train/model_loss_std": 0.31881847251022216, "train/model_opt_grad_norm": 30.403201608374566, "train/model_opt_grad_steps": 22922.60891089109, "train/model_opt_loss": 2153.5710962880958, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2945.5445544554455, "train/policy_entropy_mag": 1.3398596249004402, "train/policy_entropy_max": 1.3398596249004402, "train/policy_entropy_mean": 0.12944230274988874, "train/policy_entropy_min": 0.06468707817320776, "train/policy_entropy_std": 0.16439708115735857, "train/policy_logprob_mag": 6.551080030970054, "train/policy_logprob_max": -0.0086083042407685, "train/policy_logprob_mean": -0.12944347890886929, "train/policy_logprob_min": -6.551080030970054, "train/policy_logprob_std": 0.665936301840414, "train/policy_randomness_mag": 0.6885516811715494, "train/policy_randomness_max": 0.6885516811715494, "train/policy_randomness_mean": 0.06652018890743798, "train/policy_randomness_min": 0.03324258417850084, "train/policy_randomness_std": 0.08448339240754595, "train/post_ent_mag": 40.89735157655017, "train/post_ent_max": 40.89735157655017, "train/post_ent_mean": 40.62722536596922, "train/post_ent_min": 40.46006840998584, "train/post_ent_std": 0.07647310090389582, "train/prior_ent_mag": 42.7594250971728, "train/prior_ent_max": 42.7594250971728, "train/prior_ent_mean": 40.77816241802555, "train/prior_ent_min": 39.988503522211964, "train/prior_ent_std": 0.3559270608838242, "train/rep_loss_mean": 1.0000627436260185, "train/rep_loss_std": 0.001168760427246147, "train/reward_avg": 0.00044678036539324347, "train/reward_loss_mean": 0.0037953991899359048, "train/reward_loss_std": 0.08728139130784761, "train/reward_max_data": 0.3467821776129232, "train/reward_max_pred": 0.11123912523288539, "train/reward_neg_acc": 0.9998741515792242, "train/reward_neg_loss": 0.0006609971993510603, "train/reward_pos_acc": 0.255709877030717, "train/reward_pos_loss": 4.304539451996486, "train/reward_pred": 0.00036828068204888023, "train/reward_rate": 0.0007203357054455445, "train_stats/mean_log_entropy": 0.11844040058991488, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.008886094205081463, "report/cont_loss_std": 0.16405360400676727, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 1.1748936176300049, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002013750374317169, "report/cont_pred": 0.9945395588874817, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09122298657894135, "report/image_loss_std": 0.09103062748908997, "report/model_loss_mean": 0.7037147283554077, "report/model_loss_std": 0.23266495764255524, "report/post_ent_mag": 40.86642074584961, "report/post_ent_max": 40.86642074584961, "report/post_ent_mean": 40.609947204589844, "report/post_ent_min": 40.45396423339844, "report/post_ent_std": 0.07100807130336761, "report/prior_ent_mag": 42.37236404418945, "report/prior_ent_max": 42.37236404418945, "report/prior_ent_mean": 41.07587432861328, "report/prior_ent_min": 40.308807373046875, "report/prior_ent_std": 0.3450401723384857, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004943847889080644, "report/reward_loss_mean": 0.0036056768149137497, "report/reward_loss_std": 0.10450969636440277, "report/reward_max_data": 0.5062500238418579, "report/reward_max_pred": 0.057853102684020996, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00034011818934231997, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.3442721366882324, "report/reward_pred": 0.00021514797117561102, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.020659761503338814, "eval/cont_loss_std": 0.4367810785770416, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.886772155761719, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0013523008674383163, "eval/cont_pred": 0.9986944198608398, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19911320507526398, "eval/image_loss_std": 0.12444975227117538, "eval/model_loss_mean": 0.8198403120040894, "eval/model_loss_std": 0.45678383111953735, "eval/post_ent_mag": 40.86941909790039, "eval/post_ent_max": 40.86941909790039, "eval/post_ent_mean": 40.595314025878906, "eval/post_ent_min": 40.465362548828125, "eval/post_ent_std": 0.06319446861743927, "eval/prior_ent_mag": 42.82632064819336, "eval/prior_ent_max": 42.82632064819336, "eval/prior_ent_mean": 41.06803512573242, "eval/prior_ent_min": 40.269866943359375, "eval/prior_ent_std": 0.3658623695373535, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 6.735417991876602e-05, "eval/reward_loss_std": 0.0005761486245319247, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.005387306213378906, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 6.735417991876602e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.174704033881426e-05, "eval/reward_rate": 0.0, "replay/size": 384289.0, "replay/inserts": 32256.0, "replay/samples": 32256.0, "replay/insert_wait_avg": 1.2780850132306416e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.07782982360749e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 90704.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.143831695239849e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2338991165161, "timer/env.step_count": 4032.0, "timer/env.step_total": 38.40113067626953, "timer/env.step_frac": 0.0383921507861195, "timer/env.step_avg": 0.00952408994947161, "timer/env.step_min": 0.007674455642700195, "timer/env.step_max": 0.043283939361572266, "timer/replay._sample_count": 32256.0, "timer/replay._sample_total": 15.577194690704346, "timer/replay._sample_frac": 0.015573552050638683, "timer/replay._sample_avg": 0.00048292394254415753, "timer/replay._sample_min": 0.0003795623779296875, "timer/replay._sample_max": 0.044646501541137695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4899.0, "timer/agent.policy_total": 50.50374102592468, "timer/agent.policy_frac": 0.05049193100787075, "timer/agent.policy_avg": 0.010308989799127309, "timer/agent.policy_min": 0.008781671524047852, "timer/agent.policy_max": 0.09829282760620117, "timer/dataset_train_count": 2016.0, "timer/dataset_train_total": 0.20866918563842773, "timer/dataset_train_frac": 0.00020862038951363325, "timer/dataset_train_avg": 0.00010350654049525185, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.0009353160858154297, "timer/agent.train_count": 2016.0, "timer/agent.train_total": 897.0010523796082, "timer/agent.train_frac": 0.8967912936883151, "timer/agent.train_avg": 0.4449409982041707, "timer/agent.train_min": 0.43286824226379395, "timer/agent.train_max": 0.6541144847869873, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4757068157196045, "timer/agent.report_frac": 0.00047559557433494857, "timer/agent.report_avg": 0.23785340785980225, "timer/agent.report_min": 0.22910213470458984, "timer/agent.report_max": 0.24660468101501465, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.6696636539674417e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 32.24796344274238}
{"step": 385320, "time": 12251.912374019623, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 385576, "time": 12259.69020652771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 385792, "time": 12266.439538002014, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 385880, "time": 12268.885391712189, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386176, "time": 12278.122798204422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386288, "time": 12281.504413604736, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 386344, "time": 12282.973354101181, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386496, "time": 12287.77832531929, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386704, "time": 12294.073924303055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386792, "time": 12296.501523733139, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 386904, "time": 12299.908684492111, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387888, "time": 12329.948605298996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388192, "time": 12339.265050649643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388600, "time": 12351.402134418488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388656, "time": 12353.318893194199, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388808, "time": 12357.701250076294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388832, "time": 12359.460943698883, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 389016, "time": 12364.926306962967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389104, "time": 12367.830320119858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389216, "time": 12371.219346284866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389360, "time": 12375.588648080826, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 389488, "time": 12379.48094367981, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 389584, "time": 12382.414747953415, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 389928, "time": 12392.786818027496, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 12396.891887903214, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 390000, "time": 12397.011901855469, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 390000, "time": 12397.72381234169, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 390000, "time": 12398.544270277023, "eval_episode/length": 176.0, "eval_episode/score": 0.44999998807907104, "eval_episode/reward_rate": 0.005649717514124294}
{"step": 390000, "time": 12399.087370157242, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 390000, "time": 12399.600875616074, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 390000, "time": 12400.741209506989, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12400.749986171722, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12400.75651216507, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12400.763507843018, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390200, "time": 12406.618045330048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390280, "time": 12409.037654399872, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 390520, "time": 12416.31176495552, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 390912, "time": 12428.553095340729, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391120, "time": 12434.87296962738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391144, "time": 12435.388177394867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391184, "time": 12436.835973262787, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 391448, "time": 12444.661271572113, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 391672, "time": 12451.600274085999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391800, "time": 12455.504333734512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392096, "time": 12464.697634458542, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 392512, "time": 12477.314202070236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392592, "time": 12479.744701385498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392616, "time": 12480.279648303986, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 393224, "time": 12498.888877630234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393432, "time": 12505.470074176788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393456, "time": 12506.424062013626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393760, "time": 12515.702078580856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393984, "time": 12522.48035287857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394240, "time": 12530.204118728638, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 394248, "time": 12530.231887340546, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 394352, "time": 12533.5979013443, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 394456, "time": 12536.528661727905, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 394904, "time": 12550.067106246948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394928, "time": 12551.012879371643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 395536, "time": 12569.399990320206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 395568, "time": 12570.435044050217, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 395576, "time": 12570.463549613953, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 396008, "time": 12583.557091712952, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 396552, "time": 12600.088359832764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396664, "time": 12603.615092754364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396768, "time": 12607.000138521194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397240, "time": 12621.042515039444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397360, "time": 12624.870943546295, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 397528, "time": 12629.727018117905, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 397840, "time": 12639.432461738586, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 397880, "time": 12640.438866853714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397888, "time": 12640.906314611435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 398032, "time": 12645.256174325943, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 398320, "time": 12653.930136680603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 398864, "time": 12670.470522165298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399080, "time": 12676.789098978043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399296, "time": 12683.53190946579, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 399488, "time": 12689.323956012726, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 399552, "time": 12691.33290553093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399672, "time": 12694.745007514954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399736, "time": 12696.679783344269, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 12707.814093828201, "eval_episode/length": 21.0, "eval_episode/score": 0.934374988079071, "eval_episode/reward_rate": 0.045454545454545456}
{"step": 400088, "time": 12708.601563692093, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 400088, "time": 12712.973275661469, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12712.982166051865, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12712.988875627518, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12712.99559378624, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12713.002188682556, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12713.008841753006, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12713.015471935272, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400168, "time": 12715.455425024033, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 400192, "time": 12716.403094768524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400200, "time": 12716.432435750961, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400632, "time": 12729.63096690178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400808, "time": 12735.020900964737, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 401176, "time": 12746.061481237411, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 401272, "time": 12748.967448949814, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 401328, "time": 12750.964824438095, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 401864, "time": 12767.376575946808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402056, "time": 12773.191059827805, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 402112, "time": 12775.10500049591, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 402480, "time": 12786.505868196487, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 402504, "time": 12787.024144649506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402568, "time": 12788.999416589737, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 402944, "time": 12800.735150575638, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403024, "time": 12803.159063339233, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 403488, "time": 12817.258348941803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403584, "time": 12820.156868696213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403640, "time": 12821.641559123993, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 404160, "time": 12837.6892182827, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 404248, "time": 12840.16193151474, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 404368, "time": 12844.1002471447, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 404424, "time": 12845.572155475616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404792, "time": 12856.739795207977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404816, "time": 12857.690938711166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404952, "time": 12861.609000444412, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 405160, "time": 12867.947390794754, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 405256, "time": 12870.961130142212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405440, "time": 12876.789437055588, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 405536, "time": 12879.699917554855, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 405800, "time": 12887.51234126091, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405832, "time": 12888.485367298126, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 406088, "time": 12896.249220848083, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 406352, "time": 12904.5206387043, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 406560, "time": 12910.798415660858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 406640, "time": 12913.215147256851, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 406736, "time": 12916.114978790283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 406984, "time": 12923.380878925323, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 407064, "time": 12925.79873752594, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 407104, "time": 12927.23281621933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407472, "time": 12938.412474870682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407568, "time": 12941.307975292206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408144, "time": 12958.69880604744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408704, "time": 12975.658769130707, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 408952, "time": 12982.97060918808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409048, "time": 12985.880305051804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409296, "time": 12993.71302819252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409376, "time": 12996.144717216492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409416, "time": 12997.147749185562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409464, "time": 12998.60416173935, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 409752, "time": 13007.767830371857, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 409784, "time": 13008.740045070648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409880, "time": 13011.652423620224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 13018.097682237625, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 410072, "time": 13018.26175904274, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 410072, "time": 13018.71555352211, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 410072, "time": 13019.17543387413, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 410072, "time": 13020.619942426682, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 410072, "time": 13021.008273124695, "eval_episode/length": 186.0, "eval_episode/score": 0.41874998807907104, "eval_episode/reward_rate": 0.0053475935828877}
{"step": 410072, "time": 13021.874767303467, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 410072, "time": 13022.299046278, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 410224, "time": 13027.153450727463, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 410352, "time": 13031.04204583168, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 410408, "time": 13032.502940416336, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 411016, "time": 13050.931775569916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 411264, "time": 13058.633315086365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 411600, "time": 13068.80068230629, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 411688, "time": 13071.26245546341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 411728, "time": 13072.688043832779, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412032, "time": 13082.021136045456, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 412104, "time": 13083.98076415062, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 412192, "time": 13086.874550104141, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412496, "time": 13096.09056520462, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 412536, "time": 13097.075814962387, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412584, "time": 13098.516474723816, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 412664, "time": 13100.93743109703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412720, "time": 13102.844362258911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412808, "time": 13105.294068813324, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 413048, "time": 13112.598997116089, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 413344, "time": 13121.77864909172, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 413416, "time": 13123.74254822731, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 413864, "time": 13137.315820932388, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 414016, "time": 13142.232175588608, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 414504, "time": 13156.710963010788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414896, "time": 13168.81953239441, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 415032, "time": 13172.86654138565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 415120, "time": 13175.77981042862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 415360, "time": 13183.062490701675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 415648, "time": 13191.819769144058, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 415728, "time": 13194.266421079636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 416024, "time": 13203.197360277176, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 416176, "time": 13208.056366682053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 416648, "time": 13222.127747297287, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 416712, "time": 13224.072619438171, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 416824, "time": 13227.466980457306, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 417065, "time": 13235.785522699356, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5836867530747214, "train/action_min": 0.0, "train/action_std": 1.5273277558902703, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00945183618390693, "train/actor_opt_grad_steps": 24965.0, "train/actor_opt_loss": -5.429853886439659, "train/adv_mag": 0.6124098138643963, "train/adv_max": 0.2774227866441897, "train/adv_mean": 0.0015838044210066092, "train/adv_min": -0.5995974871191648, "train/adv_std": 0.03528565284104483, "train/cont_avg": 0.9960357363861386, "train/cont_loss_mean": 0.013322256267471884, "train/cont_loss_std": 0.21533906322645743, "train/cont_neg_acc": 0.37826191060245035, "train/cont_neg_loss": 2.767092449674383, "train/cont_pos_acc": 0.9998203495351394, "train/cont_pos_loss": 0.0025132990679657546, "train/cont_pred": 0.9961727798575222, "train/cont_rate": 0.9960357363861386, "train/dyn_loss_mean": 1.000015943947405, "train/dyn_loss_std": 0.0003362457781903605, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.6541780166807446, "train/extr_critic_critic_opt_grad_steps": 24965.0, "train/extr_critic_critic_opt_loss": 11731.55333384901, "train/extr_critic_mag": 0.7060877609961104, "train/extr_critic_max": 0.7060877609961104, "train/extr_critic_mean": 0.6747758689493236, "train/extr_critic_min": 0.6499803904259559, "train/extr_critic_std": 0.00838797176049303, "train/extr_return_normed_mag": 0.5927141066825036, "train/extr_return_normed_max": 0.32194968999022305, "train/extr_return_normed_mean": 0.027788228055304908, "train/extr_return_normed_min": -0.5725570684022242, "train/extr_return_normed_std": 0.036853055637975286, "train/extr_return_rate": 0.9942937629057629, "train/extr_return_raw_mag": 0.9705211546751532, "train/extr_return_raw_max": 0.9705211546751532, "train/extr_return_raw_mean": 0.6763597284213151, "train/extr_return_raw_min": 0.07601439628270593, "train/extr_return_raw_std": 0.03685305568869087, "train/extr_reward_mag": 0.35052755917653, "train/extr_reward_max": 0.35052755917653, "train/extr_reward_mean": 0.0021692934063652827, "train/extr_reward_min": 1.8530552930170947e-07, "train/extr_reward_std": 0.013348687855678951, "train/image_loss_mean": 0.10139149342580597, "train/image_loss_std": 0.10047701355254296, "train/model_loss_mean": 0.7192337586738096, "train/model_loss_std": 0.317125359273488, "train/model_opt_grad_norm": 28.695194461558124, "train/model_opt_grad_steps": 24941.4900990099, "train/model_opt_loss": 2519.587734713413, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3502.4752475247524, "train/policy_entropy_mag": 1.3550270606975745, "train/policy_entropy_max": 1.3550270606975745, "train/policy_entropy_mean": 0.12738831684288413, "train/policy_entropy_min": 0.0646866393266338, "train/policy_entropy_std": 0.16276842772518055, "train/policy_logprob_mag": 6.551080158441374, "train/policy_logprob_max": -0.008608234562164191, "train/policy_logprob_mean": -0.1271971578497698, "train/policy_logprob_min": -6.551080158441374, "train/policy_logprob_std": 0.6619324778566266, "train/policy_randomness_mag": 0.6963462018140472, "train/policy_randomness_max": 0.6963462018140472, "train/policy_randomness_mean": 0.06546464809539294, "train/policy_randomness_min": 0.033242358927531995, "train/policy_randomness_std": 0.0836464307169513, "train/post_ent_mag": 40.51729262701355, "train/post_ent_max": 40.51729262701355, "train/post_ent_mean": 40.24935305000532, "train/post_ent_min": 40.081523838609755, "train/post_ent_std": 0.07679955967434562, "train/prior_ent_mag": 42.39363753441537, "train/prior_ent_max": 42.39363753441537, "train/prior_ent_mean": 40.69628738176705, "train/prior_ent_min": 39.607256332246386, "train/prior_ent_std": 0.4175771159110683, "train/rep_loss_mean": 1.000015943947405, "train/rep_loss_std": 0.0003362457781903605, "train/reward_avg": 0.0005797282234684329, "train/reward_loss_mean": 0.004510418139628623, "train/reward_loss_std": 0.1010485740086308, "train/reward_max_data": 0.4107673256335282, "train/reward_max_pred": 0.12906360449177204, "train/reward_neg_acc": 0.9998645543461979, "train/reward_neg_loss": 0.0006728259031300659, "train/reward_pos_acc": 0.27591036447957784, "train/reward_pos_loss": 4.285034878915098, "train/reward_pred": 0.0004284466901508225, "train/reward_rate": 0.000894376547029703, "train_stats/mean_log_entropy": 0.11207193537037584, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.020544229075312614, "report/cont_loss_std": 0.2884655296802521, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 3.5372872352600098, "report/cont_pos_acc": 0.999018669128418, "report/cont_pos_loss": 0.003288373351097107, "report/cont_pred": 0.9962443113327026, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09494246542453766, "report/image_loss_std": 0.09808224439620972, "report/model_loss_mean": 0.7262735366821289, "report/model_loss_std": 0.475309282541275, "report/post_ent_mag": 40.03129959106445, "report/post_ent_max": 40.03129959106445, "report/post_ent_mean": 39.773704528808594, "report/post_ent_min": 39.60725784301758, "report/post_ent_std": 0.0777101144194603, "report/prior_ent_mag": 42.06428527832031, "report/prior_ent_max": 42.06428527832031, "report/prior_ent_mean": 40.34107971191406, "report/prior_ent_min": 39.10594940185547, "report/prior_ent_std": 0.47951775789260864, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0018493651878088713, "report/reward_loss_mean": 0.010786810889840126, "report/reward_loss_std": 0.21222825348377228, "report/reward_max_data": 0.796875, "report/reward_max_pred": 0.46936941146850586, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00041402914212085307, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.5409903526306152, "report/reward_pred": 0.000701547134667635, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0214649997651577, "eval/cont_loss_std": 0.4654708802700043, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.54299545288086, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0008749213302507997, "eval/cont_pred": 0.9991355538368225, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21906927227973938, "eval/image_loss_std": 0.1369291990995407, "eval/model_loss_mean": 0.8406704664230347, "eval/model_loss_std": 0.48726263642311096, "eval/post_ent_mag": 40.02778625488281, "eval/post_ent_max": 40.02778625488281, "eval/post_ent_mean": 39.75299835205078, "eval/post_ent_min": 39.570743560791016, "eval/post_ent_std": 0.0708053708076477, "eval/prior_ent_mag": 42.06428527832031, "eval/prior_ent_max": 42.06428527832031, "eval/prior_ent_mean": 40.25714874267578, "eval/prior_ent_min": 39.015052795410156, "eval/prior_ent_std": 0.47963494062423706, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001361379399895668, "eval/reward_loss_std": 0.0010168139124289155, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0074509382247924805, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001361379399895668, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.092161104083061e-05, "eval/reward_rate": 0.0, "replay/size": 416561.0, "replay/inserts": 32272.0, "replay/samples": 32272.0, "replay/insert_wait_avg": 1.2717036605176798e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.220007844886155e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 97360.0, "eval_replay/inserts": 6656.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1735380842135503e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1383702754974, "timer/env.step_count": 4034.0, "timer/env.step_total": 38.36033535003662, "timer/env.step_frac": 0.03835502815422421, "timer/env.step_avg": 0.009509255168576257, "timer/env.step_min": 0.007523298263549805, "timer/env.step_max": 0.04692649841308594, "timer/replay._sample_count": 32272.0, "timer/replay._sample_total": 15.776110172271729, "timer/replay._sample_frac": 0.015773927529573784, "timer/replay._sample_avg": 0.0004888482329038091, "timer/replay._sample_min": 0.0003628730773925781, "timer/replay._sample_max": 0.03379225730895996, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4866.0, "timer/agent.policy_total": 49.9663290977478, "timer/agent.policy_frac": 0.04995941619956458, "timer/agent.policy_avg": 0.010268460562627991, "timer/agent.policy_min": 0.008537530899047852, "timer/agent.policy_max": 0.07263302803039551, "timer/dataset_train_count": 2017.0, "timer/dataset_train_total": 0.2098705768585205, "timer/dataset_train_frac": 0.00020984154102667783, "timer/dataset_train_avg": 0.00010405085615196852, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.0005750656127929688, "timer/agent.train_count": 2017.0, "timer/agent.train_total": 897.4874031543732, "timer/agent.train_frac": 0.8973632347563587, "timer/agent.train_avg": 0.4449615285842207, "timer/agent.train_min": 0.4332606792449951, "timer/agent.train_max": 0.6569328308105469, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4744720458984375, "timer/agent.report_frac": 0.0004744064021538737, "timer/agent.report_avg": 0.23723602294921875, "timer/agent.report_min": 0.2312479019165039, "timer/agent.report_max": 0.2432241439819336, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.7414343266449328e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 32.26699815462609}
{"step": 417208, "time": 13239.855262994766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417344, "time": 13244.220149040222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417432, "time": 13246.685222148895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417960, "time": 13263.407724142075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418040, "time": 13265.86471939087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418960, "time": 13294.304270982742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419024, "time": 13296.307303905487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419136, "time": 13299.762349843979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419520, "time": 13311.503506660461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419656, "time": 13315.464213132858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419744, "time": 13318.388983249664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 13329.530924320221, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 420056, "time": 13330.626843214035, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 420056, "time": 13332.233933925629, "eval_episode/length": 214.0, "eval_episode/score": 0.33125001192092896, "eval_episode/reward_rate": 0.004651162790697674}
{"step": 420056, "time": 13333.581109046936, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13333.588621377945, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13333.594947814941, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13333.60215473175, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13333.608657360077, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13333.617132902145, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420272, "time": 13340.418277978897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 420352, "time": 13342.848996400833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 420472, "time": 13346.301303863525, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 420768, "time": 13355.602452278137, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 421448, "time": 13375.941939115524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421832, "time": 13387.644524812698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421968, "time": 13391.98269200325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422056, "time": 13394.4448158741, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422584, "time": 13410.54538989067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422664, "time": 13412.965708255768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422784, "time": 13416.830399990082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 423080, "time": 13425.68953704834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 423096, "time": 13426.186497926712, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 423416, "time": 13435.948568582535, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 423552, "time": 13440.319625616074, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 423904, "time": 13451.065470933914, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 424144, "time": 13458.357061624527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424368, "time": 13465.159350156784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424432, "time": 13467.11677122116, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 424432, "time": 13467.124329328537, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 424480, "time": 13468.577663898468, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 424824, "time": 13478.903890132904, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 424896, "time": 13481.313864469528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 425088, "time": 13487.156894922256, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 425176, "time": 13489.607549905777, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 425408, "time": 13496.869414806366, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 425672, "time": 13504.685305833817, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 425728, "time": 13506.622226953506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 426048, "time": 13516.770837783813, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 426136, "time": 13519.21139383316, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 426160, "time": 13520.163293600082, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 426832, "time": 13540.596291542053, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 427136, "time": 13549.783865213394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427208, "time": 13551.763167381287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427432, "time": 13558.62409734726, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 427720, "time": 13567.391391992569, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427984, "time": 13575.600069761276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 428040, "time": 13577.070253133774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 428360, "time": 13586.73568701744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 428472, "time": 13590.151938199997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 428560, "time": 13593.09499835968, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 428760, "time": 13598.95976138115, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 429144, "time": 13610.597359895706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429192, "time": 13612.054588317871, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 429552, "time": 13623.30998468399, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 429984, "time": 13636.38226222992, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 430032, "time": 13637.849296092987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 13639.3148727417, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 430040, "time": 13639.430975198746, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 430040, "time": 13641.010786533356, "eval_episode/length": 174.0, "eval_episode/score": 0.45625001192092896, "eval_episode/reward_rate": 0.005714285714285714}
{"step": 430040, "time": 13641.804336547852, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 430040, "time": 13642.745186805725, "eval_episode/length": 191.0, "eval_episode/score": 0.40312498807907104, "eval_episode/reward_rate": 0.005208333333333333}
{"step": 430040, "time": 13643.042432785034, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13643.049455881119, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13643.055820465088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13643.06194281578, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13643.06799030304, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430048, "time": 13643.541068077087, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 430200, "time": 13647.945375204086, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 430296, "time": 13650.903747558594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430576, "time": 13659.654134273529, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 430696, "time": 13663.109531641006, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 430792, "time": 13666.010055541992, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 430928, "time": 13670.35320854187, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 431024, "time": 13673.272535085678, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 431072, "time": 13674.723021745682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 431512, "time": 13687.951974868774, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 431816, "time": 13697.178910255432, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 431864, "time": 13698.628013134003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 432344, "time": 13713.254471540451, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 432416, "time": 13715.655773639679, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 432728, "time": 13724.884882450104, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 432888, "time": 13729.714255094528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 433104, "time": 13736.50474357605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 433240, "time": 13740.497639417648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 433384, "time": 13744.834594249725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 433632, "time": 13752.57227730751, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 434120, "time": 13767.117738723755, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 434128, "time": 13767.590861320496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 434456, "time": 13777.900192975998, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 434656, "time": 13784.190645456314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 434904, "time": 13791.491624355316, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 435008, "time": 13794.871572494507, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 435040, "time": 13795.849748373032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435056, "time": 13796.340558052063, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 435096, "time": 13797.339487791061, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 435200, "time": 13800.819595098495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435336, "time": 13804.721722126007, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 435552, "time": 13811.470719099045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435568, "time": 13811.962552785873, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 435584, "time": 13812.449221372604, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 435712, "time": 13816.334297657013, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 435808, "time": 13819.255511045456, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 435984, "time": 13824.579606056213, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 436200, "time": 13830.988236665726, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 436336, "time": 13835.435114622116, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 436896, "time": 13852.676199913025, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 436904, "time": 13852.704962968826, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 437296, "time": 13864.932925701141, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 437408, "time": 13868.329011917114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437656, "time": 13875.614095211029, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 437864, "time": 13881.9145257473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437896, "time": 13882.901358366013, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 437896, "time": 13882.909123659134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 438088, "time": 13888.709397554398, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 438184, "time": 13891.679563045502, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 438296, "time": 13895.082037448883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 438464, "time": 13900.38715171814, "episode/length": 265.0, "episode/score": 0.171875, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.0}
{"step": 438800, "time": 13910.538124322891, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 438864, "time": 13912.499902963638, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 439120, "time": 13920.315182685852, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 439128, "time": 13920.381925344467, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 439264, "time": 13924.741322040558, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 439368, "time": 13927.670373439789, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 439576, "time": 13933.973462820053, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 439832, "time": 13941.762327432632, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 13949.644162893295, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 440024, "time": 13950.63184762001, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 440024, "time": 13952.460453510284, "eval_episode/length": 262.0, "eval_episode/score": 0.18125000596046448, "eval_episode/reward_rate": 0.0038022813688212928}
{"step": 440024, "time": 13952.95806980133, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 13952.96518278122, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 13952.973551511765, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 13952.98186826706, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 13952.989493370056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440176, "time": 13957.842458724976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440208, "time": 13960.056498765945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440336, "time": 13963.94797372818, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 440496, "time": 13968.820902824402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441432, "time": 13997.077680110931, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441440, "time": 13997.550382137299, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441680, "time": 14004.819256067276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441824, "time": 14009.197683095932, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 441848, "time": 14009.708903312683, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 442144, "time": 14019.030900001526, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 442184, "time": 14020.030816316605, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 442488, "time": 14029.68393778801, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 442808, "time": 14039.38335442543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443056, "time": 14047.173127651215, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 443240, "time": 14052.647712230682, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 443528, "time": 14061.563589572906, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 443744, "time": 14068.461683988571, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443752, "time": 14068.490737438202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443768, "time": 14068.981825351715, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 444160, "time": 14081.234239816666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444456, "time": 14089.995243787766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444720, "time": 14098.215438127518, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 444800, "time": 14100.75408911705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444896, "time": 14103.65580034256, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 444984, "time": 14106.104208946228, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 445120, "time": 14110.460822820663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446056, "time": 14138.606219530106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446064, "time": 14139.082980394363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446080, "time": 14139.573614120483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446376, "time": 14148.375705957413, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 446656, "time": 14157.079149723053, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 447112, "time": 14170.782358407974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 447208, "time": 14173.712192773819, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 447224, "time": 14174.19987154007, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 447432, "time": 14180.499759435654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 447840, "time": 14193.187713623047, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 447872, "time": 14194.160972118378, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 448392, "time": 14209.73796248436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448496, "time": 14213.11583852768, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 448688, "time": 14218.905695199966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448792, "time": 14221.898307085037, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 448968, "time": 14227.227986812592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449225, "time": 14235.964612722397, "train_stats/mean_log_entropy": 0.12305097788010004, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.741944877662469, "train/action_min": 0.0, "train/action_std": 1.7499194299403709, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011184537217405564, "train/actor_opt_grad_steps": 26980.0, "train/actor_opt_loss": -4.358892941300697, "train/adv_mag": 0.6852527987304612, "train/adv_max": 0.2529697006021566, "train/adv_mean": 0.004767958429882092, "train/adv_min": -0.6731822665651046, "train/adv_std": 0.03554250639098794, "train/cont_avg": 0.9958313899253731, "train/cont_loss_mean": 0.01311685851936122, "train/cont_loss_std": 0.20989234561902187, "train/cont_neg_acc": 0.4522400851920247, "train/cont_neg_loss": 2.5454631955870717, "train/cont_pos_acc": 0.9998048282974396, "train/cont_pos_loss": 0.002432576924231163, "train/cont_pred": 0.9959608690062566, "train/cont_rate": 0.9958313899253731, "train/dyn_loss_mean": 1.0000027163111749, "train/dyn_loss_std": 8.687512880765754e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.4315895718981081, "train/extr_critic_critic_opt_grad_steps": 26980.0, "train/extr_critic_critic_opt_loss": 9620.02100824005, "train/extr_critic_mag": 0.8555045738742126, "train/extr_critic_max": 0.8555045738742126, "train/extr_critic_mean": 0.7957756525248437, "train/extr_critic_min": 0.7519609578213289, "train/extr_critic_std": 0.01592644224341829, "train/extr_return_normed_mag": 0.6669216399169087, "train/extr_return_normed_max": 0.32089338344127977, "train/extr_return_normed_mean": 0.04282117818322366, "train/extr_return_normed_min": -0.6368168862304877, "train/extr_return_normed_std": 0.04003163929148322, "train/extr_return_rate": 0.9968481627269764, "train/extr_return_raw_mag": 1.0786157579564337, "train/extr_return_raw_max": 1.0786157579564337, "train/extr_return_raw_mean": 0.8005435893784708, "train/extr_return_raw_min": 0.12090548828466614, "train/extr_return_raw_std": 0.0400316392590491, "train/extr_reward_mag": 0.34982856648478344, "train/extr_reward_max": 0.34982856648478344, "train/extr_reward_mean": 0.002490350035128105, "train/extr_reward_min": 1.4945642272038247e-07, "train/extr_reward_std": 0.014300934314746317, "train/image_loss_mean": 0.09693124315780194, "train/image_loss_std": 0.0998229151637993, "train/model_loss_mean": 0.7150019173005328, "train/model_loss_std": 0.31846694841017176, "train/model_opt_grad_norm": 27.713144482664802, "train/model_opt_grad_steps": 26955.114427860695, "train/model_opt_loss": 2570.3888237037468, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3594.5273631840796, "train/policy_entropy_mag": 1.3552470337692184, "train/policy_entropy_max": 1.3552470337692184, "train/policy_entropy_mean": 0.12572368560590555, "train/policy_entropy_min": 0.06468660777332771, "train/policy_entropy_std": 0.16354907719205267, "train/policy_logprob_mag": 6.551080224525869, "train/policy_logprob_max": -0.008608157950365425, "train/policy_logprob_mean": -0.12569129163056464, "train/policy_logprob_min": -6.551080224525869, "train/policy_logprob_std": 0.6625250951567693, "train/policy_randomness_mag": 0.6964592432501304, "train/policy_randomness_max": 0.6964592432501304, "train/policy_randomness_mean": 0.06460919750122289, "train/policy_randomness_min": 0.03324234316968799, "train/policy_randomness_std": 0.08404760463024254, "train/post_ent_mag": 39.98876137045485, "train/post_ent_max": 39.98876137045485, "train/post_ent_mean": 39.715116149750514, "train/post_ent_min": 39.53247094984671, "train/post_ent_std": 0.081165617711805, "train/prior_ent_mag": 41.880292655223634, "train/prior_ent_max": 41.880292655223634, "train/prior_ent_mean": 39.93345044264153, "train/prior_ent_min": 38.302161999602816, "train/prior_ent_std": 0.571960633518684, "train/rep_loss_mean": 1.0000027163111749, "train/rep_loss_std": 8.687512880765754e-05, "train/reward_avg": 0.0006373315317346599, "train/reward_loss_mean": 0.0049521630735308, "train/reward_loss_std": 0.10561295178347031, "train/reward_max_data": 0.4363028605037661, "train/reward_max_pred": 0.1592532669133808, "train/reward_neg_acc": 0.9997518860285555, "train/reward_neg_loss": 0.0007878724104172865, "train/reward_pos_acc": 0.3208333339181639, "train/reward_pos_loss": 4.167647956840454, "train/reward_pred": 0.0004999859343092907, "train/reward_rate": 0.0009717039800995025, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.012783029116690159, "report/cont_loss_std": 0.24512940645217896, "report/cont_neg_acc": 0.6000000238418579, "report/cont_neg_loss": 2.2417008876800537, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0018462390871718526, "report/cont_pred": 0.995354175567627, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08796201646327972, "report/image_loss_std": 0.08910628408193588, "report/model_loss_mean": 0.7045704126358032, "report/model_loss_std": 0.27640411257743835, "report/post_ent_mag": 39.550086975097656, "report/post_ent_max": 39.550086975097656, "report/post_ent_mean": 39.28288269042969, "report/post_ent_min": 39.09160614013672, "report/post_ent_std": 0.0849224105477333, "report/prior_ent_mag": 41.66509246826172, "report/prior_ent_max": 41.66509246826172, "report/prior_ent_mean": 39.4244499206543, "report/prior_ent_min": 37.2422981262207, "report/prior_ent_std": 0.6353219747543335, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0012084960471838713, "report/reward_loss_mean": 0.0038253688253462315, "report/reward_loss_std": 0.07005411386489868, "report/reward_max_data": 0.71875, "report/reward_max_pred": 0.4751899242401123, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0007939903298392892, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 1.5528597831726074, "report/reward_pred": 0.0011244859779253602, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.04785625636577606, "eval/cont_loss_std": 0.7557100057601929, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.085946083068848, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0006480634910985827, "eval/cont_pred": 0.9993584156036377, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.263899028301239, "eval/image_loss_std": 0.18912528455257416, "eval/model_loss_mean": 0.9118430614471436, "eval/model_loss_std": 0.7689445614814758, "eval/post_ent_mag": 39.55034637451172, "eval/post_ent_max": 39.55034637451172, "eval/post_ent_mean": 39.252159118652344, "eval/post_ent_min": 39.083717346191406, "eval/post_ent_std": 0.07809681445360184, "eval/prior_ent_mag": 41.66509246826172, "eval/prior_ent_max": 41.66509246826172, "eval/prior_ent_mean": 39.314247131347656, "eval/prior_ent_min": 37.85771942138672, "eval/prior_ent_std": 0.6223136782646179, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 8.7713822722435e-05, "eval/reward_loss_std": 0.0012502807658165693, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.01912868022918701, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 8.7713822722435e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.337064456194639e-05, "eval/reward_rate": 0.0, "replay/size": 448721.0, "replay/inserts": 32160.0, "replay/samples": 32160.0, "replay/insert_wait_avg": 1.27747432509465e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.228620016752784e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1345850692625826e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1616332530975, "timer/env.step_count": 4020.0, "timer/env.step_total": 38.15570545196533, "timer/env.step_frac": 0.03814953921783738, "timer/env.step_avg": 0.009491469017901823, "timer/env.step_min": 0.007706403732299805, "timer/env.step_max": 0.038999080657958984, "timer/replay._sample_count": 32160.0, "timer/replay._sample_total": 15.709749698638916, "timer/replay._sample_frac": 0.015707210891045507, "timer/replay._sample_avg": 0.0004884872418731007, "timer/replay._sample_min": 0.0003676414489746094, "timer/replay._sample_max": 0.010361433029174805, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4887.0, "timer/agent.policy_total": 50.52059555053711, "timer/agent.policy_frac": 0.05051243106198269, "timer/agent.policy_avg": 0.010337752312366914, "timer/agent.policy_min": 0.008209705352783203, "timer/agent.policy_max": 0.09400057792663574, "timer/dataset_train_count": 2010.0, "timer/dataset_train_total": 0.20694255828857422, "timer/dataset_train_frac": 0.00020690911489523817, "timer/dataset_train_avg": 0.00010295649666098219, "timer/dataset_train_min": 9.1552734375e-05, "timer/dataset_train_max": 0.00027823448181152344, "timer/agent.train_count": 2010.0, "timer/agent.train_total": 898.0371215343475, "timer/agent.train_frac": 0.8978919923306969, "timer/agent.train_avg": 0.4467846375792774, "timer/agent.train_min": 0.43547511100769043, "timer/agent.train_max": 1.678976058959961, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47522687911987305, "timer/agent.report_frac": 0.00047515007906688393, "timer/agent.report_avg": 0.23761343955993652, "timer/agent.report_min": 0.23060202598571777, "timer/agent.report_max": 0.24462485313415527, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.650520324707031e-05, "timer/dataset_eval_frac": 5.649607160322985e-08, "timer/dataset_eval_avg": 5.650520324707031e-05, "timer/dataset_eval_min": 5.650520324707031e-05, "timer/dataset_eval_max": 5.650520324707031e-05, "fps": 32.15429198423934}
{"step": 449424, "time": 14241.93776845932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449520, "time": 14244.84219956398, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449536, "time": 14245.326840639114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449624, "time": 14247.785515546799, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 14260.02169251442, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 450008, "time": 14260.227521657944, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 450008, "time": 14260.733254432678, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 450008, "time": 14260.793932199478, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 450008, "time": 14260.8193795681, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 450008, "time": 14260.967588663101, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 450008, "time": 14260.992997407913, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 450008, "time": 14261.200225353241, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 450048, "time": 14262.65991640091, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 450144, "time": 14265.569776773453, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 450152, "time": 14265.599990606308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450440, "time": 14274.362003803253, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 450704, "time": 14283.21384215355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450784, "time": 14285.630954504013, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 451000, "time": 14291.977592468262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451104, "time": 14295.35659480095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451144, "time": 14296.353558778763, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 451736, "time": 14314.518841028214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451936, "time": 14320.850462436676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452456, "time": 14336.41000199318, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452464, "time": 14336.886951684952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452744, "time": 14345.307004928589, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 453056, "time": 14354.957981348038, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 453312, "time": 14362.718121051788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 453416, "time": 14365.669560909271, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 453456, "time": 14367.104996681213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 453856, "time": 14379.313616514206, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 454048, "time": 14385.137034416199, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454144, "time": 14388.045406103134, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 454688, "time": 14404.642952680588, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 454768, "time": 14407.074422597885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454776, "time": 14407.103835344315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454800, "time": 14408.06336426735, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 454904, "time": 14410.997648954391, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 454968, "time": 14412.94190955162, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 455192, "time": 14419.742923021317, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 455392, "time": 14426.013270139694, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 455808, "time": 14438.717599153519, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 456168, "time": 14449.39841246605, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 456360, "time": 14455.224010705948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 456480, "time": 14459.086221456528, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 457000, "time": 14474.707571268082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457024, "time": 14475.65722990036, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 457088, "time": 14477.616950273514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457280, "time": 14483.448723554611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457504, "time": 14490.285716056824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457760, "time": 14498.123421907425, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 457864, "time": 14501.045418262482, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 458104, "time": 14508.335949659348, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 458248, "time": 14512.72529745102, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 458408, "time": 14517.593623161316, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 458480, "time": 14520.003742456436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 458672, "time": 14525.969672679901, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 458928, "time": 14534.23483657837, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 459056, "time": 14538.120016813278, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 459112, "time": 14539.594647884369, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 459312, "time": 14545.89056801796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459576, "time": 14553.773134708405, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 459760, "time": 14559.64921283722, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 459776, "time": 14560.24283862114, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 459816, "time": 14561.42025566101, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459904, "time": 14564.290829896927, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 459928, "time": 14564.799215078354, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 460032, "time": 14568.164264202118, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 460056, "time": 14568.675378799438, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 14571.39132475853, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 460096, "time": 14574.333539247513, "eval_episode/length": 199.0, "eval_episode/score": 0.37812501192092896, "eval_episode/reward_rate": 0.005}
{"step": 460096, "time": 14576.012433052063, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14576.019411325455, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14576.025802612305, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14576.031970977783, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14576.0378844738, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14576.043757915497, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460328, "time": 14582.969387292862, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 460360, "time": 14583.950736761093, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 460384, "time": 14584.910686254501, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 460760, "time": 14596.14335155487, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 461128, "time": 14607.261584043503, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 461248, "time": 14611.204218149185, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 461336, "time": 14613.64376950264, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 461744, "time": 14626.248736858368, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 461864, "time": 14629.661083459854, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 461976, "time": 14633.078411102295, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 462216, "time": 14640.502116203308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 462440, "time": 14647.291239738464, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 462616, "time": 14652.651894330978, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 462696, "time": 14655.084714889526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 462808, "time": 14658.486253023148, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 463120, "time": 14668.21636891365, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 463160, "time": 14669.226537704468, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 463168, "time": 14669.694754600525, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 463192, "time": 14670.25955080986, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 463280, "time": 14673.21313047409, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 463488, "time": 14679.546781778336, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 463616, "time": 14683.42411661148, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 463928, "time": 14692.660761356354, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 464040, "time": 14696.065493822098, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 464176, "time": 14700.516941785812, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 464296, "time": 14703.94079208374, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 464408, "time": 14707.329946279526, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 464600, "time": 14713.180300235748, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 464640, "time": 14714.615659236908, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 464928, "time": 14723.406866550446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 465096, "time": 14728.302463531494, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 465120, "time": 14729.267809391022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 465128, "time": 14729.2954018116, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 465152, "time": 14730.271759271622, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 465240, "time": 14732.801032304764, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 465288, "time": 14734.247594118118, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 465552, "time": 14742.480121612549, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 465560, "time": 14742.50689792633, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 465720, "time": 14747.360278606415, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 465720, "time": 14747.36693572998, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 465808, "time": 14750.248651981354, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 465856, "time": 14751.699486494064, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 465856, "time": 14751.706516742706, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 466664, "time": 14776.166177749634, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 466768, "time": 14779.608785152435, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 466776, "time": 14779.638887166977, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 467232, "time": 14794.542028188705, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 467448, "time": 14800.854987621307, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 467464, "time": 14801.343816041946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 467472, "time": 14801.836575984955, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 467600, "time": 14805.716069221497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 467992, "time": 14817.450993776321, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 468008, "time": 14817.94484782219, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 468168, "time": 14822.887005329132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468408, "time": 14830.139919519424, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 468992, "time": 14848.050990581512, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 469072, "time": 14850.615891933441, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 469088, "time": 14851.104294776917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469264, "time": 14856.454339504242, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 469392, "time": 14860.340026855469, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 469456, "time": 14862.280548810959, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 469544, "time": 14864.729683160782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469928, "time": 14876.363302230835, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 470048, "time": 14880.2516913414, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 14881.929926395416, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 470080, "time": 14882.162290096283, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 470080, "time": 14882.458758354187, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 470080, "time": 14882.639857530594, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 470080, "time": 14883.024323940277, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 470080, "time": 14883.324000358582, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 470080, "time": 14884.00533413887, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 470080, "time": 14884.51150894165, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 470112, "time": 14885.481937885284, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 470304, "time": 14891.278793811798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470328, "time": 14891.786375761032, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 470480, "time": 14896.617062807083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470488, "time": 14896.645188331604, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 470752, "time": 14904.896191596985, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 471096, "time": 14915.206404209137, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 471392, "time": 14924.434648990631, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 471400, "time": 14924.463096380234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471576, "time": 14929.794721364975, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 471704, "time": 14933.688115358353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471856, "time": 14938.539928913116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472048, "time": 14944.466481208801, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 472616, "time": 14961.441405534744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472792, "time": 14966.783561944962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472880, "time": 14969.674389600754, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 473064, "time": 14975.12390422821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473408, "time": 14985.777502059937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473568, "time": 14990.712008476257, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 473704, "time": 14994.672845602036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473888, "time": 15000.619014501572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 474240, "time": 15011.291982650757, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 474360, "time": 15014.718315839767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 474368, "time": 15015.185414791107, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 474560, "time": 15021.019989490509, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 474560, "time": 15021.026352405548, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 474760, "time": 15026.846610546112, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 474928, "time": 15032.289036750793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475104, "time": 15037.626804590225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475160, "time": 15039.629034757614, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 475312, "time": 15044.474565505981, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 475520, "time": 15050.778524160385, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 475832, "time": 15059.996478796005, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 475880, "time": 15061.582871675491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476112, "time": 15068.825045585632, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 476216, "time": 15071.747988700867, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 476296, "time": 15074.193253040314, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 476344, "time": 15075.646091938019, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 476424, "time": 15078.072651147842, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 476456, "time": 15079.060004234314, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 476880, "time": 15092.314891338348, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 477152, "time": 15100.625988483429, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 477272, "time": 15104.06916308403, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 477296, "time": 15105.028471708298, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 477456, "time": 15109.918800592422, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 477472, "time": 15110.414015054703, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 477488, "time": 15110.90717959404, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 477992, "time": 15126.0694835186, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 478256, "time": 15134.328575611115, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 478296, "time": 15135.320330619812, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 478464, "time": 15140.648768901825, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 478472, "time": 15140.677733182907, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 478576, "time": 15144.068641424179, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 479016, "time": 15157.252557992935, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 479176, "time": 15162.10933303833, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 479320, "time": 15166.471994876862, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 479376, "time": 15168.387401103973, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 479520, "time": 15172.775964260101, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 479584, "time": 15174.764632225037, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 479880, "time": 15183.639700651169, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 479904, "time": 15184.597491979599, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 15190.573536396027, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 480064, "time": 15190.960612773895, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 480064, "time": 15191.166960716248, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 480064, "time": 15192.237587928772, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 480064, "time": 15192.263973474503, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 480064, "time": 15192.536062002182, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 480064, "time": 15192.635689735413, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 480064, "time": 15193.175543785095, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 480072, "time": 15193.202341794968, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 480336, "time": 15201.432631969452, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 480792, "time": 15215.084877967834, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 480880, "time": 15217.967422246933, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 480904, "time": 15218.478013277054, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 480984, "time": 15220.93024778366, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 481160, "time": 15226.2568192482, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 481448, "time": 15234.967663049698, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 481449, "time": 15235.969290971756, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7872153514653295, "train/action_min": 0.0, "train/action_std": 1.7515022511505962, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009399818118073194, "train/actor_opt_grad_steps": 28990.0, "train/actor_opt_loss": -4.831878932964391, "train/adv_mag": 0.7104863948489896, "train/adv_max": 0.3182005725096707, "train/adv_mean": 0.0016824240235078082, "train/adv_min": -0.6753433234062954, "train/adv_std": 0.02770722962091144, "train/cont_avg": 0.9958896921641791, "train/cont_loss_mean": 0.012621513433494972, "train/cont_loss_std": 0.20555782290546232, "train/cont_neg_acc": 0.4432302837941184, "train/cont_neg_loss": 2.44976972180838, "train/cont_pos_acc": 0.9998536029858376, "train/cont_pos_loss": 0.0024167302974490495, "train/cont_pred": 0.9959658153021513, "train/cont_rate": 0.9958896921641791, "train/dyn_loss_mean": 1.0000036035604145, "train/dyn_loss_std": 0.00011439261169158922, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.39865425145670547, "train/extr_critic_critic_opt_grad_steps": 28990.0, "train/extr_critic_critic_opt_loss": 5090.736985239817, "train/extr_critic_mag": 0.8964487480286935, "train/extr_critic_max": 0.8964487480286935, "train/extr_critic_mean": 0.8613915997951185, "train/extr_critic_min": 0.7878957458989537, "train/extr_critic_std": 0.01127909112777283, "train/extr_return_normed_mag": 0.6969612377199961, "train/extr_return_normed_max": 0.32894382340398, "train/extr_return_normed_mean": 0.02462145406984497, "train/extr_return_normed_min": -0.6603817764799393, "train/extr_return_normed_std": 0.03066571379330621, "train/extr_return_rate": 0.9982807766738816, "train/extr_return_raw_mag": 1.1673963366456293, "train/extr_return_raw_max": 1.1673963366456293, "train/extr_return_raw_mean": 0.863074011470548, "train/extr_return_raw_min": 0.17807073676170995, "train/extr_return_raw_std": 0.03066571404814572, "train/extr_reward_mag": 0.36715144719650494, "train/extr_reward_max": 0.36715144719650494, "train/extr_reward_mean": 0.0020233215370322045, "train/extr_reward_min": 1.7436582650711287e-07, "train/extr_reward_std": 0.010701053502473665, "train/image_loss_mean": 0.09156706061825823, "train/image_loss_std": 0.0985871321007387, "train/model_loss_mean": 0.7096145099668361, "train/model_loss_std": 0.320567130486467, "train/model_opt_grad_norm": 26.453431119966268, "train/model_opt_grad_steps": 28963.94527363184, "train/model_opt_loss": 2834.2054734870567, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3992.5373134328356, "train/policy_entropy_mag": 1.3507233531913947, "train/policy_entropy_max": 1.3507233531913947, "train/policy_entropy_mean": 0.12002427661003758, "train/policy_entropy_min": 0.06468656314397926, "train/policy_entropy_std": 0.1562460890012001, "train/policy_logprob_mag": 6.551080226898193, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11897987264454069, "train/policy_logprob_min": -6.551080226898193, "train/policy_logprob_std": 0.6514551515009865, "train/policy_randomness_mag": 0.6941345328122229, "train/policy_randomness_max": 0.6941345328122229, "train/policy_randomness_mean": 0.06168027998722015, "train/policy_randomness_min": 0.03324232078087864, "train/policy_randomness_std": 0.08029461016331739, "train/post_ent_mag": 39.68557160410715, "train/post_ent_max": 39.68557160410715, "train/post_ent_mean": 39.41407048998781, "train/post_ent_min": 39.227159566547144, "train/post_ent_std": 0.0851491144788799, "train/prior_ent_mag": 41.5795086533276, "train/prior_ent_max": 41.5795086533276, "train/prior_ent_mean": 39.267058301327836, "train/prior_ent_min": 37.473395921697666, "train/prior_ent_std": 0.6689074255933809, "train/rep_loss_mean": 1.0000036035604145, "train/rep_loss_std": 0.00011439261169158922, "train/reward_avg": 0.0006849450242111404, "train/reward_loss_mean": 0.005423752637348365, "train/reward_loss_std": 0.11455618369448652, "train/reward_max_data": 0.47540422940432137, "train/reward_max_pred": 0.15599011722488784, "train/reward_neg_acc": 0.9998054053652939, "train/reward_neg_loss": 0.0009596976063162696, "train/reward_pos_acc": 0.2937956210905618, "train/reward_pos_loss": 4.090797551356963, "train/reward_pred": 0.0005875504425082782, "train/reward_rate": 0.0010883084577114428, "train_stats/mean_log_entropy": 0.10431792748343084, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.006224098615348339, "report/cont_loss_std": 0.10098005086183548, "report/cont_neg_acc": 0.75, "report/cont_neg_loss": 0.9283758401870728, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0026078172959387302, "report/cont_pred": 0.9949967861175537, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08497156202793121, "report/image_loss_std": 0.08988555520772934, "report/model_loss_mean": 0.6972293853759766, "report/model_loss_std": 0.2963908314704895, "report/post_ent_mag": 39.806602478027344, "report/post_ent_max": 39.806602478027344, "report/post_ent_mean": 39.5572624206543, "report/post_ent_min": 39.36661148071289, "report/post_ent_std": 0.0848655104637146, "report/prior_ent_mag": 41.365272521972656, "report/prior_ent_max": 41.365272521972656, "report/prior_ent_mean": 38.99232482910156, "report/prior_ent_min": 36.845115661621094, "report/prior_ent_std": 0.7041381001472473, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004364013730082661, "report/reward_loss_mean": 0.006033660378307104, "report/reward_loss_std": 0.1698305904865265, "report/reward_max_data": 0.4468750059604645, "report/reward_max_pred": 0.017775535583496094, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0007250819471664727, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.436709403991699, "report/reward_pred": 0.0003731194883584976, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.04057183116674423, "eval/cont_loss_std": 0.6455923914909363, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.971435546875, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0016272685024887323, "eval/cont_pred": 0.9985671043395996, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2218785583972931, "eval/image_loss_std": 0.15770794451236725, "eval/model_loss_mean": 0.8626203536987305, "eval/model_loss_std": 0.6650810241699219, "eval/post_ent_mag": 39.78733825683594, "eval/post_ent_max": 39.78733825683594, "eval/post_ent_mean": 39.51464080810547, "eval/post_ent_min": 39.325050354003906, "eval/post_ent_std": 0.08258921653032303, "eval/prior_ent_mag": 41.365272521972656, "eval/prior_ent_max": 41.365272521972656, "eval/prior_ent_mean": 38.834564208984375, "eval/prior_ent_min": 37.0665283203125, "eval/prior_ent_std": 0.7077699303627014, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00016987882554531097, "eval/reward_loss_std": 0.0011938867392018437, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.010087370872497559, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00016987882554531097, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 8.532404899597168e-05, "eval/reward_rate": 0.0, "replay/size": 480945.0, "replay/inserts": 32224.0, "replay/samples": 32224.0, "replay/insert_wait_avg": 1.2817662190775411e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.301494997094618e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5976.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1039626007897149e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.987676858902, "timer/env.step_count": 4028.0, "timer/env.step_total": 38.31908178329468, "timer/env.step_frac": 0.03831955400056544, "timer/env.step_avg": 0.009513178198434627, "timer/env.step_min": 0.007635831832885742, "timer/env.step_max": 0.035158634185791016, "timer/replay._sample_count": 32224.0, "timer/replay._sample_total": 15.817515134811401, "timer/replay._sample_frac": 0.015817710058684303, "timer/replay._sample_avg": 0.0004908613187317341, "timer/replay._sample_min": 0.00036406517028808594, "timer/replay._sample_max": 0.009503841400146484, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4775.0, "timer/agent.policy_total": 49.40808820724487, "timer/agent.policy_frac": 0.04940869707759043, "timer/agent.policy_avg": 0.010347243603611491, "timer/agent.policy_min": 0.008744001388549805, "timer/agent.policy_max": 0.08638215065002441, "timer/dataset_train_count": 2014.0, "timer/dataset_train_total": 0.24555659294128418, "timer/dataset_train_frac": 0.00024555961900711717, "timer/dataset_train_avg": 0.00012192482271166047, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.03465104103088379, "timer/agent.train_count": 2014.0, "timer/agent.train_total": 899.224582195282, "timer/agent.train_frac": 0.8992356636032449, "timer/agent.train_avg": 0.44648688291722044, "timer/agent.train_min": 0.43541932106018066, "timer/agent.train_max": 0.7101051807403564, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.473773717880249, "timer/agent.report_frac": 0.00047377955633257107, "timer/agent.report_avg": 0.2368868589401245, "timer/agent.report_min": 0.23194551467895508, "timer/agent.report_max": 0.24182820320129395, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8133739030020057e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 32.22383289996014}
{"step": 481464, "time": 15236.024143695831, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 481568, "time": 15239.777170658112, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 481688, "time": 15243.274171352386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 481976, "time": 15251.958831071854, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 482024, "time": 15253.410802841187, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 482048, "time": 15254.377358436584, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 482352, "time": 15263.585863828659, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 482360, "time": 15263.613839387894, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 482376, "time": 15264.104912281036, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 482648, "time": 15272.402307987213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482768, "time": 15276.285171508789, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 482840, "time": 15278.272694826126, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 483064, "time": 15285.057164669037, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 483184, "time": 15288.929206848145, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 483416, "time": 15296.223997831345, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 483640, "time": 15303.112658262253, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 483776, "time": 15307.45043683052, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 483848, "time": 15309.4370906353, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 483904, "time": 15311.36046552658, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 484144, "time": 15318.61983180046, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 484208, "time": 15320.546857357025, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 484232, "time": 15321.056957244873, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 484488, "time": 15328.839842557907, "episode/length": 265.0, "episode/score": 0.171875, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.0}
{"step": 484784, "time": 15338.131098508835, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 484992, "time": 15344.438547372818, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 485496, "time": 15359.526342391968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485760, "time": 15367.931543827057, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 485776, "time": 15368.422917366028, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 485872, "time": 15371.340218544006, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 486216, "time": 15381.508786678314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 486360, "time": 15385.87799525261, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 486544, "time": 15391.783268928528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 486552, "time": 15391.812232732773, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 486896, "time": 15402.447213888168, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 487056, "time": 15407.275427818298, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 487096, "time": 15408.27435040474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487264, "time": 15413.636967897415, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 487384, "time": 15417.046827316284, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 487720, "time": 15427.324218988419, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 487744, "time": 15428.271299600601, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 487784, "time": 15429.252690076828, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 488000, "time": 15436.012323617935, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 488072, "time": 15437.960506916046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 488400, "time": 15448.078786611557, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 488520, "time": 15451.610435962677, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 488544, "time": 15452.565418720245, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 488888, "time": 15462.735171794891, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 489528, "time": 15482.22703576088, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 489624, "time": 15485.158296108246, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 489696, "time": 15487.549997091293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489816, "time": 15490.95976805687, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 489840, "time": 15491.908794879913, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 490032, "time": 15497.766255378723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 15499.717982292175, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 490048, "time": 15500.265164136887, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 490048, "time": 15500.34863948822, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 490048, "time": 15500.831144571304, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 490048, "time": 15500.993487358093, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 490048, "time": 15501.250079631805, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 490048, "time": 15502.162507772446, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 490048, "time": 15502.78597354889, "eval_episode/length": 250.0, "eval_episode/score": 0.21875, "eval_episode/reward_rate": 0.00398406374501992}
{"step": 490056, "time": 15502.814365386963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490184, "time": 15506.677559375763, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 490344, "time": 15511.596560239792, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 490384, "time": 15513.046236038208, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 490416, "time": 15514.013044118881, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 490824, "time": 15526.18927192688, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 490904, "time": 15528.648026704788, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 490976, "time": 15531.066702365875, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 491384, "time": 15543.233690023422, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 491464, "time": 15545.650407075882, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 491624, "time": 15550.9412753582, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 491728, "time": 15554.322379350662, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 491752, "time": 15554.834563732147, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 491880, "time": 15558.712518692017, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 491904, "time": 15559.666734933853, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 491984, "time": 15562.095965147018, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 492288, "time": 15571.374535799026, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 492376, "time": 15573.822912931442, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 492424, "time": 15575.276635169983, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 492440, "time": 15575.791886091232, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 492480, "time": 15577.249433517456, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 492536, "time": 15578.721701860428, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 492584, "time": 15580.171000480652, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 492800, "time": 15586.941550254822, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 493440, "time": 15606.407205343246, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 493560, "time": 15609.830384731293, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 493656, "time": 15612.7437748909, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 494216, "time": 15629.774618148804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494600, "time": 15641.564531326294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494736, "time": 15645.934282064438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494792, "time": 15647.412221193314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494848, "time": 15649.354237794876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495312, "time": 15663.505937814713, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 495568, "time": 15671.23972606659, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 495752, "time": 15676.571083784103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495872, "time": 15680.417132854462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495968, "time": 15683.365185260773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 496528, "time": 15700.478279590607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 496544, "time": 15700.967246294022, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 496872, "time": 15710.671148777008, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 496912, "time": 15712.134794712067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497048, "time": 15716.044855833054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497880, "time": 15741.379412651062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498064, "time": 15747.276235103607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498184, "time": 15750.786597967148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498840, "time": 15770.674271583557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498856, "time": 15771.159638404846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 499184, "time": 15781.53927397728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 499224, "time": 15782.541464328766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 499360, "time": 15786.882402420044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 15810.749257564545, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 500032, "time": 15813.759368658066, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15813.780972957611, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15813.796355724335, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15813.804493188858, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15813.810984611511, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15813.81718492508, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15813.823274374008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500128, "time": 15816.737062215805, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 500192, "time": 15818.66522526741, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 500496, "time": 15827.867997646332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 500552, "time": 15829.351567983627, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 501024, "time": 15844.004987478256, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 501152, "time": 15847.89078950882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501168, "time": 15848.37945818901, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501496, "time": 15858.093111753464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501536, "time": 15859.531587600708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501672, "time": 15863.438251256943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501824, "time": 15868.293523311615, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 502048, "time": 15875.207161664963, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 502120, "time": 15877.17047572136, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 502352, "time": 15884.42261004448, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 502760, "time": 15896.516380310059, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 502800, "time": 15897.952840089798, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 502864, "time": 15899.89819765091, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502992, "time": 15903.83620762825, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 503048, "time": 15905.323136091232, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 503368, "time": 15915.027326107025, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 503448, "time": 15917.450673103333, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 503456, "time": 15917.924699544907, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 503672, "time": 15924.267393827438, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 503688, "time": 15924.750646591187, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 504112, "time": 15937.885887622833, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 504136, "time": 15938.394337415695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 504152, "time": 15938.881424427032, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 504592, "time": 15952.392237186432, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 504712, "time": 15955.804338693619, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 504792, "time": 15958.263768434525, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 504888, "time": 15961.32481622696, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 505176, "time": 15970.19284248352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505304, "time": 15974.142067670822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505520, "time": 15980.964555501938, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 505832, "time": 15990.272234916687, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 505920, "time": 15993.232642173767, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 505928, "time": 15993.260493278503, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 506160, "time": 16000.508533000946, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 506216, "time": 16001.991949558258, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 506424, "time": 16008.28693652153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506488, "time": 16010.221690893173, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 506568, "time": 16012.662980556488, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 506656, "time": 16015.553035736084, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 506864, "time": 16021.985817193985, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 507072, "time": 16028.287941455841, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 507136, "time": 16030.216204404831, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 507288, "time": 16034.605759859085, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 507336, "time": 16036.09346461296, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 507592, "time": 16043.919703006744, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 507608, "time": 16044.41590499878, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 507712, "time": 16047.826145410538, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 508048, "time": 16058.546805620193, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 508136, "time": 16060.996080875397, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 508312, "time": 16066.334043264389, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 508344, "time": 16067.312742710114, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 508432, "time": 16070.203682422638, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 508472, "time": 16071.20506119728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 508688, "time": 16077.958490371704, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 508752, "time": 16079.912404298782, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 508936, "time": 16085.323746681213, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 509296, "time": 16096.445636510849, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 509496, "time": 16102.267071962357, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 509632, "time": 16106.614565610886, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 509832, "time": 16112.557487726212, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 509976, "time": 16116.924658536911, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 16119.040482759476, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 510016, "time": 16119.607622861862, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 510016, "time": 16120.45386171341, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 510016, "time": 16120.588724136353, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 510016, "time": 16120.934437990189, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 510016, "time": 16120.940787553787, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 510016, "time": 16121.828515052795, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 510016, "time": 16122.81718325615, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 510088, "time": 16124.797886371613, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 510168, "time": 16127.265911579132, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 510336, "time": 16132.662785768509, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 510400, "time": 16134.654208660126, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 510576, "time": 16140.045203208923, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 510784, "time": 16146.45911693573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510920, "time": 16150.359198093414, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 511072, "time": 16155.172857761383, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 511192, "time": 16158.587101697922, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 511288, "time": 16161.484380960464, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 511304, "time": 16161.973092556, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 511336, "time": 16162.9644613266, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 511600, "time": 16171.284974098206, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 511720, "time": 16174.706872701645, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 511792, "time": 16177.11646604538, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 511904, "time": 16180.492413520813, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 512232, "time": 16190.21025466919, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 512328, "time": 16193.128596544266, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 512520, "time": 16198.944982528687, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 512752, "time": 16206.261205911636, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 512960, "time": 16212.54866862297, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 512992, "time": 16213.51856470108, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 513184, "time": 16219.307747602463, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 513232, "time": 16220.772173404694, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 513400, "time": 16225.62918138504, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 513624, "time": 16232.489191532135, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 513721, "time": 16236.395654439926, "train_stats/mean_log_entropy": 0.09979764372110367, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.809224648050743, "train/action_min": 0.0, "train/action_std": 1.7497988644212779, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009020486526135909, "train/actor_opt_grad_steps": 31005.0, "train/actor_opt_loss": -5.808511738822159, "train/adv_mag": 0.74186872772061, "train/adv_max": 0.31412698284234153, "train/adv_mean": 0.002909328324068777, "train/adv_min": -0.7238406549290856, "train/adv_std": 0.03183266923228039, "train/cont_avg": 0.9958133508663366, "train/cont_loss_mean": 0.012778739379211744, "train/cont_loss_std": 0.2034511803649366, "train/cont_neg_acc": 0.4127619118988514, "train/cont_neg_loss": 2.4505696447729135, "train/cont_pos_acc": 0.9998786177965674, "train/cont_pos_loss": 0.002480015277373835, "train/cont_pred": 0.9959149646877062, "train/cont_rate": 0.9958133508663366, "train/dyn_loss_mean": 1.0000073225191324, "train/dyn_loss_std": 0.00018209821723532945, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.5035481335650577, "train/extr_critic_critic_opt_grad_steps": 31005.0, "train/extr_critic_critic_opt_loss": 6009.699363784035, "train/extr_critic_mag": 0.9664817688488724, "train/extr_critic_max": 0.9664817688488724, "train/extr_critic_mean": 0.9031772923351514, "train/extr_critic_min": 0.7763965430826244, "train/extr_critic_std": 0.013540060040402677, "train/extr_return_normed_mag": 0.727034727830698, "train/extr_return_normed_max": 0.30645793086231343, "train/extr_return_normed_mean": 0.03139385520734151, "train/extr_return_normed_min": -0.7023218020354167, "train/extr_return_normed_std": 0.03576015719756632, "train/extr_return_rate": 0.9979959991898867, "train/extr_return_raw_mag": 1.1811506757051637, "train/extr_return_raw_max": 1.1811506757051637, "train/extr_return_raw_mean": 0.9060866449138906, "train/extr_return_raw_min": 0.17237094280743362, "train/extr_return_raw_std": 0.035760157243671396, "train/extr_reward_mag": 0.36464816213834406, "train/extr_reward_max": 0.36464816213834406, "train/extr_reward_mean": 0.002302718608718513, "train/extr_reward_min": 1.4281508946182704e-07, "train/extr_reward_std": 0.012410996663891295, "train/image_loss_mean": 0.08902464215044338, "train/image_loss_std": 0.09781639949224963, "train/model_loss_mean": 0.7087462196255675, "train/model_loss_std": 0.3417085324699926, "train/model_opt_grad_norm": 25.154340531566355, "train/model_opt_grad_steps": 30977.37623762376, "train/model_opt_loss": 3543.731088770498, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.3454079751921173, "train/policy_entropy_max": 1.3454079751921173, "train/policy_entropy_mean": 0.1144614039671303, "train/policy_entropy_min": 0.06468658654554056, "train/policy_entropy_std": 0.14693169686758872, "train/policy_logprob_mag": 6.551080224537613, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11395779300001588, "train/policy_logprob_min": -6.551080224537613, "train/policy_logprob_std": 0.648793634801808, "train/policy_randomness_mag": 0.6914029684987398, "train/policy_randomness_max": 0.6914029684987398, "train/policy_randomness_mean": 0.05882152891026275, "train/policy_randomness_min": 0.03324233248165929, "train/policy_randomness_std": 0.07550795997797262, "train/post_ent_mag": 39.63115399426753, "train/post_ent_max": 39.63115399426753, "train/post_ent_mean": 39.3747128212806, "train/post_ent_min": 39.177822547383826, "train/post_ent_std": 0.08962877087368823, "train/prior_ent_mag": 41.57720663996026, "train/prior_ent_max": 41.57720663996026, "train/prior_ent_mean": 39.04074230760631, "train/prior_ent_min": 37.47738841972729, "train/prior_ent_std": 0.624634728868409, "train/rep_loss_mean": 1.0000073225191324, "train/rep_loss_std": 0.00018209821723532945, "train/reward_avg": 0.0008470894032809768, "train/reward_loss_mean": 0.006938422533296196, "train/reward_loss_std": 0.13822992655303384, "train/reward_max_data": 0.5268873766728557, "train/reward_max_pred": 0.1572125518676078, "train/reward_neg_acc": 0.9998305782233134, "train/reward_neg_loss": 0.001151629221063144, "train/reward_pos_acc": 0.23411111225684483, "train/reward_pos_loss": 4.284881792068481, "train/reward_pred": 0.000667169759289758, "train/reward_rate": 0.0013488165222772276, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.007588209118694067, "report/cont_loss_std": 0.13453087210655212, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.2494702339172363, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0027180833276361227, "report/cont_pred": 0.9949095249176025, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06951478123664856, "report/image_loss_std": 0.0784008726477623, "report/model_loss_mean": 0.6777588725090027, "report/model_loss_std": 0.1544499397277832, "report/post_ent_mag": 39.58589172363281, "report/post_ent_max": 39.58589172363281, "report/post_ent_mean": 39.328922271728516, "report/post_ent_min": 39.13567352294922, "report/post_ent_std": 0.08769358694553375, "report/prior_ent_mag": 41.51632308959961, "report/prior_ent_max": 41.51632308959961, "report/prior_ent_mean": 38.99477767944336, "report/prior_ent_min": 37.053993225097656, "report/prior_ent_std": 0.6449142098426819, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0006558680906891823, "report/reward_loss_std": 0.003236905438825488, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.015924930572509766, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0006558680906891823, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0003213543677702546, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.06405829638242722, "eval/cont_loss_std": 0.8288779854774475, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.73251724243164, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0011793646262958646, "eval/cont_pred": 0.9988358616828918, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22396329045295715, "eval/image_loss_std": 0.16667582094669342, "eval/model_loss_mean": 0.8988507986068726, "eval/model_loss_std": 1.0462735891342163, "eval/post_ent_mag": 39.58384704589844, "eval/post_ent_max": 39.58384704589844, "eval/post_ent_mean": 39.296974182128906, "eval/post_ent_min": 39.13275146484375, "eval/post_ent_std": 0.09389054775238037, "eval/prior_ent_mag": 41.51632308959961, "eval/prior_ent_max": 41.51632308959961, "eval/prior_ent_mean": 38.862266540527344, "eval/prior_ent_min": 37.59736633300781, "eval/prior_ent_std": 0.6786743998527527, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007598876836709678, "eval/reward_loss_mean": 0.010829165577888489, "eval/reward_loss_std": 0.34013158082962036, "eval/reward_max_data": 0.778124988079071, "eval/reward_max_pred": 0.04082083702087402, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001952137827174738, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.889362335205078, "eval/reward_pred": 9.434204548597336e-05, "eval/reward_rate": 0.0009765625, "replay/size": 513217.0, "replay/inserts": 32272.0, "replay/samples": 32272.0, "replay/insert_wait_avg": 1.2847578756042087e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.346191202938172e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1138665691380617e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4064249992371, "timer/env.step_count": 4034.0, "timer/env.step_total": 38.615302324295044, "timer/env.step_frac": 0.03859961447601108, "timer/env.step_avg": 0.00957245967384607, "timer/env.step_min": 0.007668018341064453, "timer/env.step_max": 0.03536081314086914, "timer/replay._sample_count": 32272.0, "timer/replay._sample_total": 15.999222040176392, "timer/replay._sample_frac": 0.015992722198069242, "timer/replay._sample_avg": 0.0004957617141849403, "timer/replay._sample_min": 0.0003902912139892578, "timer/replay._sample_max": 0.010666370391845703, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4815.0, "timer/agent.policy_total": 49.84832739830017, "timer/agent.policy_frac": 0.049828076022540725, "timer/agent.policy_avg": 0.010352715970571167, "timer/agent.policy_min": 0.008672475814819336, "timer/agent.policy_max": 0.08718609809875488, "timer/dataset_train_count": 2017.0, "timer/dataset_train_total": 0.2095944881439209, "timer/dataset_train_frac": 0.0002095093383112576, "timer/dataset_train_avg": 0.00010391397528206292, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.00029087066650390625, "timer/agent.train_count": 2017.0, "timer/agent.train_total": 898.6154413223267, "timer/agent.train_frac": 0.8982503699164187, "timer/agent.train_avg": 0.44552079391290367, "timer/agent.train_min": 0.4343302249908447, "timer/agent.train_max": 0.6602842807769775, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47892069816589355, "timer/agent.report_frac": 0.0004787261318981021, "timer/agent.report_avg": 0.23946034908294678, "timer/agent.report_min": 0.2315845489501953, "timer/agent.report_max": 0.24733614921569824, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.458427429199219e-05, "timer/dataset_eval_frac": 4.456616148984268e-08, "timer/dataset_eval_avg": 4.458427429199219e-05, "timer/dataset_eval_min": 4.458427429199219e-05, "timer/dataset_eval_max": 4.458427429199219e-05, "fps": 32.258310308498174}
{"step": 513944, "time": 16242.95465707779, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 513944, "time": 16242.968825101852, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 514096, "time": 16247.827848911285, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 514360, "time": 16255.600111484528, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 514512, "time": 16260.51866889, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 514600, "time": 16262.962463378906, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 514648, "time": 16264.419273376465, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 514688, "time": 16265.87083029747, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 515464, "time": 16289.171911478043, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 515624, "time": 16294.142198085785, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 515752, "time": 16298.03939318657, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 515784, "time": 16299.032439470291, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 516256, "time": 16314.324655056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516384, "time": 16318.293087005615, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 516488, "time": 16321.400512218475, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 516496, "time": 16321.882600069046, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 516672, "time": 16327.26539850235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516960, "time": 16335.9640147686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517048, "time": 16338.390539646149, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 517360, "time": 16348.05662560463, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 517376, "time": 16348.542750597, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 517384, "time": 16348.571335315704, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 517616, "time": 16355.930124759674, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 517840, "time": 16362.769184350967, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 517840, "time": 16362.777426719666, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 517872, "time": 16363.781351327896, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 518216, "time": 16374.092376708984, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 518344, "time": 16377.95106458664, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 518568, "time": 16384.804112434387, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518608, "time": 16386.23363184929, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 518912, "time": 16395.454817295074, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 519128, "time": 16401.78678035736, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 519176, "time": 16403.256024837494, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 519400, "time": 16410.095157146454, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 519536, "time": 16414.53664278984, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 519688, "time": 16418.91286420822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 519768, "time": 16421.336011886597, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 519816, "time": 16422.803522348404, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 519832, "time": 16423.29359292984, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 519984, "time": 16428.11428809166, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 16429.563539505005, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 520000, "time": 16430.0555768013, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 520000, "time": 16430.255121469498, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 520000, "time": 16430.435564517975, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 520000, "time": 16431.312359809875, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 520000, "time": 16431.683977365494, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 520000, "time": 16431.82863855362, "eval_episode/length": 171.0, "eval_episode/score": 0.46562498807907104, "eval_episode/reward_rate": 0.005813953488372093}
{"step": 520000, "time": 16431.90609407425, "eval_episode/length": 175.0, "eval_episode/score": 0.453125, "eval_episode/reward_rate": 0.005681818181818182}
{"step": 520008, "time": 16431.93167448044, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 520088, "time": 16434.338026046753, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 520152, "time": 16436.294498682022, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 520552, "time": 16448.474503040314, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 520568, "time": 16448.96456003189, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 520648, "time": 16451.413205623627, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 520912, "time": 16459.62595462799, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 521008, "time": 16462.518251419067, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 521032, "time": 16463.03011918068, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 521128, "time": 16465.94879937172, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 521336, "time": 16472.33804011345, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 521344, "time": 16472.808391332626, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 521368, "time": 16473.322143793106, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 521496, "time": 16477.289883613586, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 521728, "time": 16484.60609316826, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 521760, "time": 16485.58231973648, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 521784, "time": 16486.093336820602, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 521952, "time": 16491.421723604202, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 521976, "time": 16491.928812503815, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 522176, "time": 16498.216794013977, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 522520, "time": 16508.579584121704, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 522584, "time": 16510.509112119675, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 522584, "time": 16510.526158809662, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 522672, "time": 16513.422750234604, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 522968, "time": 16522.15891599655, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 523144, "time": 16527.495551109314, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 523280, "time": 16531.918051719666, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 523360, "time": 16534.36319231987, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 523528, "time": 16539.223516702652, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 523584, "time": 16541.142753362656, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 524000, "time": 16553.74937391281, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 524256, "time": 16561.68616580963, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 524264, "time": 16561.71867275238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 524288, "time": 16562.85849547386, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 524320, "time": 16564.22454714775, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 524384, "time": 16566.204943418503, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 524560, "time": 16571.543907403946, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 524992, "time": 16584.618800878525, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 525072, "time": 16587.058613061905, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 525272, "time": 16593.04238796234, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 525376, "time": 16596.42548775673, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 525456, "time": 16598.872537374496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525544, "time": 16601.31799674034, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 525728, "time": 16607.145516633987, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 525728, "time": 16607.1522898674, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 525840, "time": 16610.539666891098, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 526104, "time": 16618.333748102188, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 526424, "time": 16628.08905315399, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 526720, "time": 16637.249809503555, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 526832, "time": 16640.668780565262, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 527152, "time": 16650.418218374252, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 527152, "time": 16650.430592536926, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 527160, "time": 16650.470382213593, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 527224, "time": 16652.409159898758, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 527304, "time": 16654.82518029213, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 527632, "time": 16665.010003566742, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 528096, "time": 16678.957824468613, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 528104, "time": 16678.98655104637, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 528104, "time": 16678.993593215942, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 528248, "time": 16683.50738787651, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 528520, "time": 16691.73607158661, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 528616, "time": 16694.651366710663, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 529312, "time": 16716.068851470947, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 529384, "time": 16718.022584199905, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 529480, "time": 16720.933349847794, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 529552, "time": 16723.342059135437, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 529600, "time": 16724.784919261932, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 529688, "time": 16727.217059850693, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 529744, "time": 16729.1409304142, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 529744, "time": 16729.14878129959, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 529800, "time": 16730.625123023987, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 16742.21201634407, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 530088, "time": 16742.292908906937, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 530088, "time": 16742.503422498703, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 530088, "time": 16742.71161389351, "eval_episode/length": 169.0, "eval_episode/score": 0.47187501192092896, "eval_episode/reward_rate": 0.0058823529411764705}
{"step": 530088, "time": 16742.796962976456, "eval_episode/length": 173.0, "eval_episode/score": 0.4593749940395355, "eval_episode/reward_rate": 0.005747126436781609}
{"step": 530088, "time": 16743.17125582695, "eval_episode/length": 193.0, "eval_episode/score": 0.3968749940395355, "eval_episode/reward_rate": 0.005154639175257732}
{"step": 530088, "time": 16743.274252414703, "eval_episode/length": 198.0, "eval_episode/score": 0.3812499940395355, "eval_episode/reward_rate": 0.005025125628140704}
{"step": 530088, "time": 16743.541627645493, "eval_episode/length": 212.0, "eval_episode/score": 0.3375000059604645, "eval_episode/reward_rate": 0.004694835680751174}
{"step": 530480, "time": 16755.724143266678, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 530576, "time": 16758.699494361877, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 530880, "time": 16767.942932128906, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 530888, "time": 16767.97100830078, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 530952, "time": 16769.905766248703, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 531088, "time": 16774.34582233429, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 531248, "time": 16779.207494735718, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 531312, "time": 16781.163952350616, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 531416, "time": 16784.09310913086, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 531440, "time": 16785.042465686798, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 531672, "time": 16791.86860346794, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 531680, "time": 16792.342298030853, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 531688, "time": 16792.369897842407, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 531744, "time": 16794.30262517929, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 531904, "time": 16799.157137155533, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 532608, "time": 16821.11198592186, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 532672, "time": 16823.06147670746, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 532688, "time": 16823.55290389061, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 532792, "time": 16826.500671863556, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 532808, "time": 16826.990077018738, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 533144, "time": 16837.239944934845, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 533312, "time": 16842.549355983734, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 533728, "time": 16855.276465654373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 533816, "time": 16857.717005729675, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 533848, "time": 16858.68994283676, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 534000, "time": 16863.57528781891, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534304, "time": 16872.768658638, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 534392, "time": 16875.223440408707, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 534544, "time": 16880.040817022324, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 534552, "time": 16880.069032669067, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 534568, "time": 16880.55618429184, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 534752, "time": 16886.37286758423, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 534776, "time": 16887.45249915123, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 534984, "time": 16893.827889680862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 535208, "time": 16900.610411405563, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 535448, "time": 16907.870730161667, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 535456, "time": 16908.34053826332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 535536, "time": 16910.77424955368, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 535584, "time": 16912.220986366272, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 535656, "time": 16914.19662284851, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 535848, "time": 16920.00233912468, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 536160, "time": 16929.82443213463, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 536176, "time": 16930.31492948532, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 536184, "time": 16930.34413766861, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 536248, "time": 16932.27690219879, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 536504, "time": 16940.10626554489, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 536584, "time": 16942.56233239174, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 536808, "time": 16949.388158798218, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 536928, "time": 16953.315113306046, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 537120, "time": 16959.1416721344, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 537224, "time": 16962.128249645233, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 537344, "time": 16966.01401901245, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 537480, "time": 16969.923236608505, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 537552, "time": 16972.33555316925, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 537568, "time": 16972.824407815933, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 537832, "time": 16980.678292274475, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 537976, "time": 16985.053972005844, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 538208, "time": 16992.314798116684, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 538592, "time": 17003.962374448776, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 538696, "time": 17006.929814577103, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 538704, "time": 17007.400364637375, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 538768, "time": 17009.35527229309, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 538776, "time": 17009.383625984192, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 538816, "time": 17010.901213169098, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 538984, "time": 17015.800572872162, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 539184, "time": 17022.187527656555, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 539560, "time": 17033.39382839203, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 539656, "time": 17036.320301532745, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 539760, "time": 17039.67107605934, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 539768, "time": 17039.69968676567, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 539928, "time": 17044.637593984604, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 539952, "time": 17045.612439870834, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 540016, "time": 17047.550351381302, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 17050.140322446823, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 540072, "time": 17050.975562095642, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 540072, "time": 17051.170582056046, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 540072, "time": 17051.179830789566, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 540072, "time": 17051.291816473007, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 540072, "time": 17051.50562953949, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 540072, "time": 17051.53203845024, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 540072, "time": 17051.806138515472, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 540224, "time": 17056.615355968475, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 540392, "time": 17061.49622154236, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 540688, "time": 17071.348793506622, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 540792, "time": 17074.301431417465, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 540840, "time": 17075.762468099594, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 541000, "time": 17080.614056825638, "episode/length": 286.0, "episode/score": 0.10625000298023224, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.0}
{"step": 541136, "time": 17084.961872816086, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 541248, "time": 17088.37382531166, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 541464, "time": 17094.7018764019, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 541672, "time": 17101.120185613632, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 541928, "time": 17108.850747823715, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 542040, "time": 17112.241880893707, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 542040, "time": 17112.25282549858, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 542192, "time": 17117.08584499359, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 542192, "time": 17117.092469215393, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 542224, "time": 17118.0582344532, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 542328, "time": 17120.989758968353, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 542592, "time": 17129.213578224182, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 542712, "time": 17132.72357082367, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 542896, "time": 17138.527344465256, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 543264, "time": 17149.665967941284, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 543336, "time": 17151.63689017296, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 543352, "time": 17152.122483968735, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 543416, "time": 17154.046392202377, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 543448, "time": 17155.01807284355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 543512, "time": 17156.966437101364, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 543976, "time": 17171.104192733765, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 544152, "time": 17176.427810668945, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 544320, "time": 17181.741898298264, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 544344, "time": 17182.252454042435, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 544456, "time": 17185.668021202087, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 544544, "time": 17188.554791927338, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 544816, "time": 17196.928924798965, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 544824, "time": 17196.957068920135, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 544952, "time": 17200.84348797798, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 545160, "time": 17207.128002643585, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 545264, "time": 17210.495679616928, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 545784, "time": 17226.132147789, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 546032, "time": 17235.287228822708, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 546057, "time": 17236.793748617172, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8569937224435336, "train/action_min": 0.0, "train/action_std": 1.7468252913786633, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008100363157348394, "train/actor_opt_grad_steps": 33025.0, "train/actor_opt_loss": -4.964283949418897, "train/adv_mag": 0.816009797082089, "train/adv_max": 0.3215447510823165, "train/adv_mean": 0.00345617493167083, "train/adv_min": -0.7827589157784339, "train/adv_std": 0.02652242424031074, "train/cont_avg": 0.9954410968440595, "train/cont_loss_mean": 0.013954567464787772, "train/cont_loss_std": 0.21172427799262217, "train/cont_neg_acc": 0.3804338755299203, "train/cont_neg_loss": 2.5148659741236083, "train/cont_pos_acc": 0.9998299877832432, "train/cont_pos_loss": 0.0027088155001194427, "train/cont_pred": 0.9956993773432061, "train/cont_rate": 0.9954410968440595, "train/dyn_loss_mean": 1.0000313195851769, "train/dyn_loss_std": 0.0009973996979043829, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.28616974382928695, "train/extr_critic_critic_opt_grad_steps": 33025.0, "train/extr_critic_critic_opt_loss": 12599.960086633664, "train/extr_critic_mag": 1.0764708471770335, "train/extr_critic_max": 1.0764708471770335, "train/extr_critic_mean": 1.0046441059301394, "train/extr_critic_min": 0.768366302003955, "train/extr_critic_std": 0.01833153581984415, "train/extr_return_normed_mag": 0.8058147828767795, "train/extr_return_normed_max": 0.26738669583112884, "train/extr_return_normed_mean": 0.0361830847347063, "train/extr_return_normed_min": -0.773475432159877, "train/extr_return_normed_std": 0.03273750586195452, "train/extr_return_rate": 0.9987952942305273, "train/extr_return_raw_mag": 1.2393038231547515, "train/extr_return_raw_max": 1.2393038231547515, "train/extr_return_raw_mean": 1.0081002644383081, "train/extr_return_raw_min": 0.19844169516374568, "train/extr_return_raw_std": 0.032737505755912846, "train/extr_reward_mag": 0.3308880647810379, "train/extr_reward_max": 0.3308880647810379, "train/extr_reward_mean": 0.001735609343176302, "train/extr_reward_min": 1.5107711943069307e-07, "train/extr_reward_std": 0.008977052793690548, "train/image_loss_mean": 0.09160460288276767, "train/image_loss_std": 0.10112406715455621, "train/model_loss_mean": 0.714562989107453, "train/model_loss_std": 0.3782652477447939, "train/model_opt_grad_norm": 24.50916880428201, "train/model_opt_grad_steps": 32995.37128712871, "train/model_opt_loss": 3590.3830711440287, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5049.504950495049, "train/policy_entropy_mag": 1.300790269776146, "train/policy_entropy_max": 1.300790269776146, "train/policy_entropy_mean": 0.11403698614328214, "train/policy_entropy_min": 0.06468655128437693, "train/policy_entropy_std": 0.14670483985602265, "train/policy_logprob_mag": 6.551080231619354, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11310491792046197, "train/policy_logprob_min": -6.551080231619354, "train/policy_logprob_std": 0.6455244073773375, "train/policy_randomness_mag": 0.6684740020497011, "train/policy_randomness_max": 0.6684740020497011, "train/policy_randomness_mean": 0.058603421406875744, "train/policy_randomness_min": 0.03324231453756295, "train/policy_randomness_std": 0.07539137838279257, "train/post_ent_mag": 39.56422142935271, "train/post_ent_max": 39.56422142935271, "train/post_ent_mean": 39.3138113682813, "train/post_ent_min": 39.11285449490689, "train/post_ent_std": 0.09468010174903539, "train/prior_ent_mag": 41.15998462639233, "train/prior_ent_max": 41.15998462639233, "train/prior_ent_mean": 38.62953943309218, "train/prior_ent_min": 37.06140648492492, "train/prior_ent_std": 0.6443981076821242, "train/rep_loss_mean": 1.0000313195851769, "train/rep_loss_std": 0.0009973996979043829, "train/reward_avg": 0.0011312654699728534, "train/reward_loss_mean": 0.008985004354369743, "train/reward_loss_std": 0.16609479044967487, "train/reward_max_data": 0.5798267332265282, "train/reward_max_pred": 0.19834054342590937, "train/reward_neg_acc": 0.9997771597734773, "train/reward_neg_loss": 0.0013651890329867348, "train/reward_pos_acc": 0.2170351491797538, "train/reward_pos_loss": 4.2278666127295725, "train/reward_pred": 0.0008252288622892286, "train/reward_rate": 0.0018370977722772276, "train_stats/mean_log_entropy": 0.09171171633384688, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.011083144694566727, "report/cont_loss_std": 0.150849387049675, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.8447980880737305, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0038921062368899584, "report/cont_pred": 0.994745135307312, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09437763690948486, "report/image_loss_std": 0.10849373042583466, "report/model_loss_mean": 0.7155064344406128, "report/model_loss_std": 0.3679434359073639, "report/post_ent_mag": 39.416568756103516, "report/post_ent_max": 39.416568756103516, "report/post_ent_mean": 39.172447204589844, "report/post_ent_min": 38.97596740722656, "report/post_ent_std": 0.099990613758564, "report/prior_ent_mag": 40.776344299316406, "report/prior_ent_max": 40.776344299316406, "report/prior_ent_mean": 38.7084846496582, "report/prior_ent_min": 37.066162109375, "report/prior_ent_std": 0.5716120004653931, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.001251220703125, "report/reward_loss_mean": 0.010045669972896576, "report/reward_loss_std": 0.19029748439788818, "report/reward_max_data": 0.6875, "report/reward_max_pred": 0.09985494613647461, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0017290838295593858, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.259820938110352, "report/reward_pred": 0.0008735144510865211, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0379532054066658, "eval/cont_loss_std": 0.646776556968689, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.638139724731445, "eval/cont_pos_acc": 0.9980410933494568, "eval/cont_pos_loss": 0.0038684294559061527, "eval/cont_pred": 0.9969173669815063, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16283899545669556, "eval/image_loss_std": 0.13530871272087097, "eval/model_loss_mean": 0.8142446279525757, "eval/model_loss_std": 0.9587989449501038, "eval/post_ent_mag": 39.41628646850586, "eval/post_ent_max": 39.41628646850586, "eval/post_ent_mean": 39.12919998168945, "eval/post_ent_min": 38.92005920410156, "eval/post_ent_std": 0.0965728685259819, "eval/prior_ent_mag": 40.776344299316406, "eval/prior_ent_max": 40.776344299316406, "eval/prior_ent_mean": 38.50518035888672, "eval/prior_ent_min": 36.89738464355469, "eval/prior_ent_std": 0.6096363663673401, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007598876836709678, "eval/reward_loss_mean": 0.013452435843646526, "eval/reward_loss_std": 0.39035531878471375, "eval/reward_max_data": 0.778124988079071, "eval/reward_max_pred": 0.26707231998443604, "eval/reward_neg_acc": 0.9990224838256836, "eval/reward_neg_loss": 0.001265171798877418, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 12.481022834777832, "eval/reward_pred": 0.0005669208476319909, "eval/reward_rate": 0.0009765625, "replay/size": 545553.0, "replay/inserts": 32336.0, "replay/samples": 32336.0, "replay/insert_wait_avg": 1.2864914936101537e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.325974152502243e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4320.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0748704274495444e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3837928771973, "timer/env.step_count": 4042.0, "timer/env.step_total": 38.757288694381714, "timer/env.step_frac": 0.03874241962968245, "timer/env.step_avg": 0.00958864143849127, "timer/env.step_min": 0.007743358612060547, "timer/env.step_max": 0.0447080135345459, "timer/replay._sample_count": 32336.0, "timer/replay._sample_total": 16.0891592502594, "timer/replay._sample_frac": 0.01608298671451431, "timer/replay._sample_avg": 0.0004975618273830838, "timer/replay._sample_min": 0.0004048347473144531, "timer/replay._sample_max": 0.03224015235900879, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4582.0, "timer/agent.policy_total": 47.339829444885254, "timer/agent.policy_frac": 0.04732166772587497, "timer/agent.policy_avg": 0.010331695644889841, "timer/agent.policy_min": 0.008562564849853516, "timer/agent.policy_max": 0.07758307456970215, "timer/dataset_train_count": 2021.0, "timer/dataset_train_total": 0.21110200881958008, "timer/dataset_train_frac": 0.00021102102045499055, "timer/dataset_train_avg": 0.0001044542349428897, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.0005860328674316406, "timer/agent.train_count": 2021.0, "timer/agent.train_total": 902.7089776992798, "timer/agent.train_frac": 0.9023626573387443, "timer/agent.train_avg": 0.44666451147910924, "timer/agent.train_min": 0.43379974365234375, "timer/agent.train_max": 1.8758368492126465, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4746091365814209, "timer/agent.report_frac": 0.0004744270548570171, "timer/agent.report_avg": 0.23730456829071045, "timer/agent.report_min": 0.23142266273498535, "timer/agent.report_max": 0.24318647384643555, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9790888856746717e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 32.32303733615214}
{"step": 546104, "time": 17237.991461753845, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 546112, "time": 17238.465895414352, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 546464, "time": 17249.128401517868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 546504, "time": 17250.128679037094, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 546840, "time": 17260.56553888321, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 546856, "time": 17261.059895277023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547576, "time": 17283.051969766617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547664, "time": 17285.94221830368, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 547664, "time": 17285.94941020012, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 547688, "time": 17286.46838259697, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 548096, "time": 17299.03689932823, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 548144, "time": 17300.51560330391, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 548264, "time": 17303.914539575577, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 548344, "time": 17306.358313798904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 548712, "time": 17317.599719524384, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 548752, "time": 17319.05463194847, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 548832, "time": 17321.488008737564, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 549048, "time": 17328.351987361908, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 549456, "time": 17341.11135315895, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 549824, "time": 17352.32004761696, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 549864, "time": 17353.332199811935, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 550000, "time": 17357.76291656494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 550056, "time": 17360.172943353653, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 550056, "time": 17366.59234571457, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 550056, "time": 17366.706055879593, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 550056, "time": 17367.172233104706, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 550056, "time": 17368.46651172638, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 550056, "time": 17369.338052272797, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 550056, "time": 17370.64428138733, "eval_episode/length": 213.0, "eval_episode/score": 0.3343749940395355, "eval_episode/reward_rate": 0.004672897196261682}
{"step": 550056, "time": 17370.73437833786, "eval_episode/length": 217.0, "eval_episode/score": 0.3218750059604645, "eval_episode/reward_rate": 0.0045871559633027525}
{"step": 550192, "time": 17375.097576856613, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 550232, "time": 17376.08954691887, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 550256, "time": 17377.04088115692, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 550520, "time": 17384.832484960556, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 550600, "time": 17387.26724433899, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 550816, "time": 17394.037467241287, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 550848, "time": 17395.032635211945, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 550952, "time": 17397.95026421547, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 551064, "time": 17401.424864053726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551352, "time": 17410.179627656937, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 551800, "time": 17423.7681722641, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 551824, "time": 17424.714068174362, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 551848, "time": 17425.22292113304, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 552144, "time": 17434.499991178513, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 552184, "time": 17435.498916387558, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 552272, "time": 17438.38417696953, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 552464, "time": 17444.18129992485, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 552600, "time": 17448.0903673172, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 552600, "time": 17448.09961915016, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 552608, "time": 17448.569001436234, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 553088, "time": 17463.365555763245, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 553288, "time": 17469.325752735138, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 553320, "time": 17470.32402253151, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 553328, "time": 17470.801913261414, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 553400, "time": 17472.795942783356, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 553544, "time": 17477.140142202377, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 553712, "time": 17482.450135469437, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 553744, "time": 17483.412105321884, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 553864, "time": 17486.855393648148, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 554056, "time": 17492.8025598526, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 554136, "time": 17495.213938951492, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 554192, "time": 17497.143699884415, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 554728, "time": 17513.135224342346, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 554824, "time": 17516.030185699463, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 554880, "time": 17517.95125889778, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 554920, "time": 17518.941843271255, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 554984, "time": 17520.95095682144, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 555096, "time": 17524.349125146866, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 555336, "time": 17531.61535859108, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 555608, "time": 17539.85105228424, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 555696, "time": 17542.745646953583, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 555784, "time": 17545.167301654816, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 556048, "time": 17553.534918785095, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 556088, "time": 17554.53050327301, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 556448, "time": 17565.662860631943, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 556456, "time": 17565.69209575653, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 556544, "time": 17568.56633424759, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 556544, "time": 17568.573278188705, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 556808, "time": 17576.323400497437, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 556936, "time": 17580.21892976761, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 557248, "time": 17590.437967300415, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 557376, "time": 17594.29762339592, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 557720, "time": 17604.511135339737, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 557776, "time": 17606.42101240158, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 557896, "time": 17609.838745117188, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 558032, "time": 17614.259258270264, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 558056, "time": 17614.76517176628, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 558232, "time": 17620.101672410965, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 558344, "time": 17623.476056814194, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 558672, "time": 17633.67575764656, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 558696, "time": 17634.18577337265, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 558696, "time": 17634.193389892578, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 558848, "time": 17639.06820178032, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 558872, "time": 17639.580016374588, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 558944, "time": 17642.09179353714, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 559048, "time": 17645.052351236343, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 559456, "time": 17657.64152097702, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 559560, "time": 17660.59849715233, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 559720, "time": 17665.459985256195, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 559768, "time": 17666.920683145523, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 559912, "time": 17671.366635084152, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 17675.259989976883, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 17676.171258211136, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 560040, "time": 17676.638355731964, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 560040, "time": 17676.805119514465, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 560040, "time": 17677.014535665512, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 560040, "time": 17677.127269029617, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 560040, "time": 17677.2219581604, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 560040, "time": 17677.387330293655, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 560040, "time": 17677.536096334457, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 560056, "time": 17678.023475408554, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 560224, "time": 17683.33201122284, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 560240, "time": 17683.824424266815, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 560672, "time": 17696.930142879486, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 560688, "time": 17697.42087650299, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 561008, "time": 17707.1870572567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 561192, "time": 17712.525094509125, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 561280, "time": 17715.423393964767, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 561320, "time": 17716.421791791916, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 561376, "time": 17718.338353157043, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 561392, "time": 17718.849073648453, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 561656, "time": 17726.590367794037, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 561744, "time": 17729.502269268036, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 561872, "time": 17733.506566524506, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 562144, "time": 17741.882608652115, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 562360, "time": 17748.24033856392, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 562576, "time": 17755.008864879608, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 562584, "time": 17755.037806034088, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 562992, "time": 17767.671461105347, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 563176, "time": 17772.99254822731, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 563192, "time": 17773.490236997604, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 563248, "time": 17775.440280675888, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 563288, "time": 17776.442875385284, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 563496, "time": 17782.759141921997, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 563560, "time": 17784.69547533989, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 563768, "time": 17791.12521958351, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 563856, "time": 17794.01317334175, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 563968, "time": 17797.411438941956, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 563976, "time": 17797.43958592415, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 564144, "time": 17802.75813436508, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 564352, "time": 17809.046109437943, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 564464, "time": 17812.43310046196, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 564568, "time": 17815.346012830734, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 564592, "time": 17816.31177663803, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 564688, "time": 17819.212944984436, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 564928, "time": 17826.594211816788, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 565312, "time": 17838.666506528854, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 565312, "time": 17838.67355132103, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 565456, "time": 17843.03833246231, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 565504, "time": 17844.48795938492, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 565552, "time": 17846.53091287613, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 565616, "time": 17848.512358427048, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 565808, "time": 17854.49375963211, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 565936, "time": 17858.391340970993, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 565984, "time": 17859.84369635582, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 566000, "time": 17860.332672834396, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 566072, "time": 17862.32321691513, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 566168, "time": 17865.225415706635, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 566472, "time": 17874.438469409943, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 566784, "time": 17884.207188129425, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 567088, "time": 17893.39995455742, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 567184, "time": 17896.29233598709, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 567320, "time": 17900.181367874146, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 567360, "time": 17901.599566459656, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 567368, "time": 17901.627705812454, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 567384, "time": 17902.11245250702, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 567624, "time": 17909.350086450577, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 567768, "time": 17913.793842077255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 567904, "time": 17918.14518404007, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 567920, "time": 17918.636377811432, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 567936, "time": 17919.125277996063, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 568128, "time": 17924.967043876648, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 568224, "time": 17927.891182422638, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 568504, "time": 17936.119378328323, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 568760, "time": 17944.002908706665, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 568840, "time": 17946.415939331055, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 568888, "time": 17947.87363243103, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 568912, "time": 17948.843521118164, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 568952, "time": 17949.829381227493, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 569696, "time": 17972.719833612442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 569728, "time": 17973.72160100937, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 569760, "time": 17974.715330839157, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 569784, "time": 17975.23535490036, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 17984.739642858505, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 570024, "time": 17985.09286379814, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 570024, "time": 17985.267463445663, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 570024, "time": 17985.312127113342, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 570024, "time": 17985.873106241226, "eval_episode/length": 180.0, "eval_episode/score": 0.4375, "eval_episode/reward_rate": 0.0055248618784530384}
{"step": 570024, "time": 17985.900589227676, "eval_episode/length": 180.0, "eval_episode/score": 0.4375, "eval_episode/reward_rate": 0.0055248618784530384}
{"step": 570024, "time": 17986.332506418228, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 570024, "time": 17986.623660564423, "eval_episode/length": 219.0, "eval_episode/score": 0.31562501192092896, "eval_episode/reward_rate": 0.004545454545454545}
{"step": 570200, "time": 17991.97028708458, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 570328, "time": 17995.822621822357, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 570496, "time": 18001.19885635376, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 570632, "time": 18005.10089635849, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 570792, "time": 18009.945028066635, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 570840, "time": 18011.41170358658, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 571080, "time": 18018.6797413826, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 571136, "time": 18020.59134221077, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 571544, "time": 18032.805180311203, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 571568, "time": 18033.75198817253, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 571696, "time": 18037.616862535477, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 571800, "time": 18040.542610645294, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 572032, "time": 18047.85970878601, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 572224, "time": 18053.748386621475, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 572328, "time": 18056.68515062332, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 572440, "time": 18060.071052789688, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 572480, "time": 18061.59206843376, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 572592, "time": 18064.9823513031, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 572752, "time": 18069.816161870956, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 572808, "time": 18071.28397154808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 572976, "time": 18076.595611810684, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 573184, "time": 18082.878650665283, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 573200, "time": 18083.36989402771, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 573208, "time": 18083.39794754982, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 573272, "time": 18085.354147195816, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 573368, "time": 18088.255345106125, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 573440, "time": 18090.977650403976, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 573448, "time": 18091.098525762558, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 573880, "time": 18104.48463869095, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 574064, "time": 18110.28566813469, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 574080, "time": 18110.775656938553, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 574240, "time": 18115.619328975677, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 574240, "time": 18115.643394708633, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 574320, "time": 18118.057005643845, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 574352, "time": 18119.042202711105, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 574528, "time": 18124.472920656204, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 574688, "time": 18129.3101375103, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 574736, "time": 18130.767520666122, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 575392, "time": 18150.617923021317, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 575536, "time": 18154.965816020966, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 575568, "time": 18155.933141231537, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 575624, "time": 18157.40596461296, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 575752, "time": 18161.30415725708, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 575920, "time": 18166.625641345978, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 576160, "time": 18173.883286476135, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 576248, "time": 18176.32616329193, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 576296, "time": 18177.790067195892, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 576328, "time": 18178.76207280159, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 576432, "time": 18182.21056008339, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 576616, "time": 18187.52702975273, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 576648, "time": 18188.77177119255, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 576672, "time": 18192.87048959732, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 576832, "time": 18197.771965503693, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 576856, "time": 18198.282142162323, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 577080, "time": 18205.04754638672, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 577144, "time": 18206.971640586853, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 577152, "time": 18207.43519306183, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 577360, "time": 18213.76639175415, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 577744, "time": 18225.395275354385, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 577840, "time": 18228.298003911972, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 578105, "time": 18237.085181951523, "train_stats/mean_log_entropy": 0.08471463085665051, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8772073364257813, "train/action_min": 0.0, "train/action_std": 1.7631683778762817, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007731257687555626, "train/actor_opt_grad_steps": 35035.0, "train/actor_opt_loss": -7.535693438951857, "train/adv_mag": 0.9283581778407097, "train/adv_max": 0.37528959155082703, "train/adv_mean": 0.0033946227896194613, "train/adv_min": -0.8836128023266793, "train/adv_std": 0.0259849723149091, "train/cont_avg": 0.995478515625, "train/cont_loss_mean": 0.013111593045759946, "train/cont_loss_std": 0.19916304802056403, "train/cont_neg_acc": 0.42420437224209306, "train/cont_neg_loss": 2.2603220791794594, "train/cont_pos_acc": 0.9998626494407654, "train/cont_pos_loss": 0.0028333214030135424, "train/cont_pred": 0.9954087346792221, "train/cont_rate": 0.995478515625, "train/dyn_loss_mean": 1.0000027531385423, "train/dyn_loss_std": 8.806724741589278e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.20697250585071741, "train/extr_critic_critic_opt_grad_steps": 35035.0, "train/extr_critic_critic_opt_loss": 8327.422182617187, "train/extr_critic_mag": 1.1946701729297637, "train/extr_critic_max": 1.1946701729297637, "train/extr_critic_mean": 1.1380699902772904, "train/extr_critic_min": 0.7938490170240402, "train/extr_critic_std": 0.02128188137896359, "train/extr_return_normed_mag": 0.9206618455052376, "train/extr_return_normed_max": 0.24946657299995423, "train/extr_return_normed_mean": 0.04160676590166986, "train/extr_return_normed_min": -0.8947365203499794, "train/extr_return_normed_std": 0.034133900152519346, "train/extr_return_rate": 0.999168013036251, "train/extr_return_raw_mag": 1.3493243861198425, "train/extr_return_raw_max": 1.3493243861198425, "train/extr_return_raw_mean": 1.1414646339416503, "train/extr_return_raw_min": 0.2051212927699089, "train/extr_return_raw_std": 0.03413390004076064, "train/extr_reward_mag": 0.3276258558034897, "train/extr_reward_max": 0.3276258558034897, "train/extr_reward_mean": 0.001876756909332471, "train/extr_reward_min": 2.1278858184814452e-07, "train/extr_reward_std": 0.008791721214074642, "train/image_loss_mean": 0.0895574476569891, "train/image_loss_std": 0.10165871664881707, "train/model_loss_mean": 0.712118829190731, "train/model_loss_std": 0.37178691890090704, "train/model_opt_grad_norm": 23.305169777870177, "train/model_opt_grad_steps": 35003.405, "train/model_opt_loss": 3613.4028759765624, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5100.0, "train/policy_entropy_mag": 1.3064143013954164, "train/policy_entropy_max": 1.3064143013954164, "train/policy_entropy_mean": 0.10675830017775297, "train/policy_entropy_min": 0.06468652106821537, "train/policy_entropy_std": 0.13716305885463953, "train/policy_logprob_mag": 6.551080226898193, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10650360692292452, "train/policy_logprob_min": -6.551080226898193, "train/policy_logprob_std": 0.6422700324654579, "train/policy_randomness_mag": 0.6713641828298569, "train/policy_randomness_max": 0.6713641828298569, "train/policy_randomness_mean": 0.054862916879355905, "train/policy_randomness_min": 0.03324229756370187, "train/policy_randomness_std": 0.0704878730326891, "train/post_ent_mag": 39.528637161254885, "train/post_ent_max": 39.528637161254885, "train/post_ent_mean": 39.278293418884275, "train/post_ent_min": 39.062804546356205, "train/post_ent_std": 0.0998657513409853, "train/prior_ent_mag": 41.06282819747925, "train/prior_ent_max": 41.06282819747925, "train/prior_ent_mean": 38.83577903747559, "train/prior_ent_min": 37.468876419067385, "train/prior_ent_std": 0.5470574307441711, "train/rep_loss_mean": 1.0000027531385423, "train/rep_loss_std": 8.806724741589278e-05, "train/reward_avg": 0.0011550140362305682, "train/reward_loss_mean": 0.009448107251082548, "train/reward_loss_std": 0.1693782219302375, "train/reward_max_data": 0.6017187504842877, "train/reward_max_pred": 0.1913576328754425, "train/reward_neg_acc": 0.9998336344957351, "train/reward_neg_loss": 0.0016536215202359018, "train/reward_pos_acc": 0.17639691860689594, "train/reward_pos_loss": 4.149704327473062, "train/reward_pred": 0.0009396894893143326, "train/reward_rate": 0.00189453125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.010091780684888363, "report/cont_loss_std": 0.15051761269569397, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.252241373062134, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0035036816261708736, "report/cont_pred": 0.9955242872238159, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08454297482967377, "report/image_loss_std": 0.09777974337339401, "report/model_loss_mean": 0.705791175365448, "report/model_loss_std": 0.37428194284439087, "report/post_ent_mag": 39.84022521972656, "report/post_ent_max": 39.84022521972656, "report/post_ent_mean": 39.605751037597656, "report/post_ent_min": 39.386497497558594, "report/post_ent_std": 0.10612303763628006, "report/prior_ent_mag": 40.894622802734375, "report/prior_ent_max": 40.894622802734375, "report/prior_ent_mean": 38.689693450927734, "report/prior_ent_min": 37.544761657714844, "report/prior_ent_std": 0.5291060209274292, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0014221190940588713, "report/reward_loss_mean": 0.011156397871673107, "report/reward_loss_std": 0.19360996782779694, "report/reward_max_data": 0.731249988079071, "report/reward_max_pred": 0.06216263771057129, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002646331675350666, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.359799861907959, "report/reward_pred": 0.0012435558019205928, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.027306843549013138, "eval/cont_loss_std": 0.5766431093215942, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 13.058595657348633, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0018052980303764343, "eval/cont_pred": 0.9982350468635559, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17644935846328735, "eval/image_loss_std": 0.1580570936203003, "eval/model_loss_mean": 0.8043040037155151, "eval/model_loss_std": 0.5953623652458191, "eval/post_ent_mag": 39.82615661621094, "eval/post_ent_max": 39.82615661621094, "eval/post_ent_mean": 39.55727005004883, "eval/post_ent_min": 39.36691665649414, "eval/post_ent_std": 0.10091455280780792, "eval/prior_ent_mag": 40.894622802734375, "eval/prior_ent_max": 40.894622802734375, "eval/prior_ent_mean": 38.588932037353516, "eval/prior_ent_min": 37.091644287109375, "eval/prior_ent_std": 0.528748095035553, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0005478071980178356, "eval/reward_loss_std": 0.003458678023889661, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.02165377140045166, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0005478071980178356, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00025570590514689684, "eval/reward_rate": 0.0, "replay/size": 577601.0, "replay/inserts": 32048.0, "replay/samples": 32048.0, "replay/insert_wait_avg": 1.2909925644598897e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.264892637164249e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4456.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1516965698296976e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2753598690033, "timer/env.step_count": 4006.0, "timer/env.step_total": 38.31668448448181, "timer/env.step_frac": 0.03830613651174991, "timer/env.step_avg": 0.009564823885292515, "timer/env.step_min": 0.007654428482055664, "timer/env.step_max": 0.038252830505371094, "timer/replay._sample_count": 32048.0, "timer/replay._sample_total": 16.005034923553467, "timer/replay._sample_frac": 0.016000628992450135, "timer/replay._sample_avg": 0.0004994082290175196, "timer/replay._sample_min": 0.0003936290740966797, "timer/replay._sample_max": 0.010867834091186523, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4563.0, "timer/agent.policy_total": 47.62670397758484, "timer/agent.policy_frac": 0.04761359310482472, "timer/agent.policy_avg": 0.010437585793904195, "timer/agent.policy_min": 0.007490634918212891, "timer/agent.policy_max": 0.09010457992553711, "timer/dataset_train_count": 2003.0, "timer/dataset_train_total": 0.2247602939605713, "timer/dataset_train_frac": 0.00022469842103279046, "timer/dataset_train_avg": 0.000112211829236431, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.014535188674926758, "timer/agent.train_count": 2003.0, "timer/agent.train_total": 892.4960236549377, "timer/agent.train_frac": 0.8922503337199265, "timer/agent.train_avg": 0.445579642363923, "timer/agent.train_min": 0.43355584144592285, "timer/agent.train_max": 0.6988091468811035, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4790210723876953, "timer/agent.report_frac": 0.00047888920551879656, "timer/agent.report_avg": 0.23951053619384766, "timer/agent.report_min": 0.2341756820678711, "timer/agent.report_max": 0.24484539031982422, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.0032471229453286e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 32.03864279724052}
{"step": 578168, "time": 18238.754872322083, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 578184, "time": 18239.242010831833, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 578216, "time": 18240.272968292236, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 578360, "time": 18244.783284187317, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 578536, "time": 18250.112539052963, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 578664, "time": 18253.995794534683, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 578776, "time": 18257.42790031433, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 578816, "time": 18258.861149549484, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 579032, "time": 18265.233612298965, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 579112, "time": 18267.708825349808, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 579224, "time": 18271.228066921234, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 579224, "time": 18271.246948719025, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 579592, "time": 18282.459398269653, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 579688, "time": 18285.403827428818, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 579848, "time": 18290.28853869438, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 18295.166165828705, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 18296.002334594727, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 580008, "time": 18296.5971698761, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 580008, "time": 18296.749955892563, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 580008, "time": 18297.052151441574, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 580008, "time": 18297.494532823563, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 580008, "time": 18297.944407463074, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 580008, "time": 18298.360483646393, "eval_episode/length": 173.0, "eval_episode/score": 0.4593749940395355, "eval_episode/reward_rate": 0.005747126436781609}
{"step": 580008, "time": 18298.47239804268, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 580016, "time": 18298.951149225235, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 580064, "time": 18300.49554181099, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 580264, "time": 18306.345703125, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 580312, "time": 18307.809688091278, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 580496, "time": 18313.60578608513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 580504, "time": 18313.63368344307, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 580608, "time": 18317.015342712402, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 580640, "time": 18317.99071121216, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 580720, "time": 18320.42136335373, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 580896, "time": 18325.840306282043, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 581000, "time": 18328.833440303802, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 581392, "time": 18341.116783857346, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 581448, "time": 18342.59665131569, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 581664, "time": 18349.89539718628, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 581752, "time": 18352.358407258987, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 581936, "time": 18358.165913581848, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 581984, "time": 18359.62934780121, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 582016, "time": 18360.710096120834, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 582168, "time": 18365.114718437195, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 582184, "time": 18365.621715545654, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 582256, "time": 18368.039527654648, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 582336, "time": 18370.45725440979, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 582584, "time": 18377.794188261032, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 582856, "time": 18386.083047628403, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 583232, "time": 18397.870137929916, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 583320, "time": 18400.334802389145, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 583424, "time": 18403.720911026, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 583472, "time": 18405.207454919815, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 583568, "time": 18408.163687944412, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 584136, "time": 18425.584481954575, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 584256, "time": 18429.50496506691, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 584360, "time": 18432.52304625511, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 584456, "time": 18435.496062517166, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 584464, "time": 18435.967977285385, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 584816, "time": 18446.71861410141, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 585104, "time": 18455.581332683563, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 585360, "time": 18463.369779586792, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 585448, "time": 18465.834647655487, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 585552, "time": 18469.230347394943, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 585720, "time": 18474.114836215973, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 585936, "time": 18480.96857047081, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 585952, "time": 18481.461007595062, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 586040, "time": 18483.925010681152, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 586040, "time": 18483.93421936035, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 586240, "time": 18490.216942548752, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 586440, "time": 18496.08178138733, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 586576, "time": 18500.485867977142, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 586640, "time": 18502.457424640656, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 586792, "time": 18506.86637210846, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 587000, "time": 18513.316395044327, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 587088, "time": 18516.204530000687, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 587112, "time": 18516.71928358078, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 587144, "time": 18517.70139503479, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 587296, "time": 18522.628195524216, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 587400, "time": 18525.64262366295, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 587480, "time": 18528.099385499954, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 587672, "time": 18533.941155433655, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 588072, "time": 18546.232095003128, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 588264, "time": 18552.102319717407, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 588448, "time": 18557.97142148018, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 588576, "time": 18561.882152080536, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 588736, "time": 18566.779252290726, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 588752, "time": 18567.290770053864, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 588784, "time": 18568.267533540726, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 588864, "time": 18570.79027581215, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 588904, "time": 18571.80039000511, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 589112, "time": 18578.173356056213, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 589464, "time": 18588.917275428772, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 589512, "time": 18590.390566825867, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 589808, "time": 18599.67408657074, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 589880, "time": 18602.267795562744, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 589920, "time": 18603.70740890503, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 589968, "time": 18605.172351121902, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 18609.813511371613, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 590096, "time": 18610.581956863403, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 590096, "time": 18610.749363660812, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 590096, "time": 18611.119022607803, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 590096, "time": 18611.31776380539, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 590096, "time": 18611.854155302048, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 590096, "time": 18612.048077583313, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 590096, "time": 18612.685895442963, "eval_episode/length": 190.0, "eval_episode/score": 0.40625, "eval_episode/reward_rate": 0.005235602094240838}
{"step": 590472, "time": 18623.973084688187, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 590552, "time": 18626.464342355728, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 590576, "time": 18627.43479537964, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 590744, "time": 18632.43486237526, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 590768, "time": 18633.399414539337, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 590904, "time": 18637.34551000595, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 591144, "time": 18644.652719020844, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 591368, "time": 18651.475745677948, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 591448, "time": 18653.897871017456, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 592104, "time": 18673.971774578094, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 592232, "time": 18677.887517929077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 592784, "time": 18695.098174333572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 592864, "time": 18697.57138323784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593056, "time": 18703.494171380997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593080, "time": 18704.02791786194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593192, "time": 18707.43004655838, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 593456, "time": 18715.711968898773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593776, "time": 18725.760313749313, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 594056, "time": 18734.115421056747, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 594072, "time": 18734.606315135956, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 594072, "time": 18734.61496281624, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 594360, "time": 18743.388855695724, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 594456, "time": 18746.30251479149, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 594536, "time": 18748.77577471733, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 594712, "time": 18754.23592376709, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 594776, "time": 18756.19309091568, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 594920, "time": 18760.59125971794, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 594920, "time": 18760.60195660591, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 595288, "time": 18771.826937437057, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 595352, "time": 18773.789595365524, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 595416, "time": 18775.728148937225, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 595544, "time": 18779.619579076767, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 595600, "time": 18781.635360717773, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 595728, "time": 18785.532962799072, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 595928, "time": 18791.422572135925, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 596272, "time": 18802.124209165573, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 596336, "time": 18804.068974494934, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 596456, "time": 18807.515546798706, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 596576, "time": 18811.510595321655, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 596608, "time": 18812.502571105957, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 596664, "time": 18813.985255241394, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 597048, "time": 18825.6658475399, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 597048, "time": 18825.679881572723, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 597080, "time": 18826.684964179993, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 597128, "time": 18828.151987314224, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 597168, "time": 18829.603954553604, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 597272, "time": 18832.595479249954, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 597440, "time": 18837.941082000732, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 597528, "time": 18840.467817544937, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 597592, "time": 18842.432612657547, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 597592, "time": 18842.44009590149, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 597744, "time": 18847.297595739365, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 597864, "time": 18850.721347332, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 597920, "time": 18852.668576717377, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 598016, "time": 18855.749680280685, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 598168, "time": 18860.502706050873, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 598232, "time": 18862.46916270256, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 598264, "time": 18863.452273607254, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 598264, "time": 18863.45952606201, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 598352, "time": 18866.375762224197, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 598800, "time": 18880.162038564682, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 598936, "time": 18884.09345126152, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 599104, "time": 18889.44845676422, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 599240, "time": 18893.37563753128, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 599256, "time": 18893.869123220444, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 599296, "time": 18895.313345193863, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 599392, "time": 18898.249563217163, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 599640, "time": 18905.779427289963, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 599688, "time": 18907.27138710022, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 18920.731141090393, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 600080, "time": 18921.14310145378, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 600080, "time": 18921.519287586212, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 600080, "time": 18921.526485919952, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 600080, "time": 18921.93057012558, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 600080, "time": 18922.43689417839, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 600080, "time": 18923.200137615204, "eval_episode/length": 185.0, "eval_episode/score": 0.421875, "eval_episode/reward_rate": 0.005376344086021506}
{"step": 600080, "time": 18923.323949337006, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 600344, "time": 18931.35447192192, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 600528, "time": 18937.18355369568, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 600736, "time": 18943.504432439804, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 600744, "time": 18943.532098531723, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 600768, "time": 18944.507254123688, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 600768, "time": 18944.514585733414, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 601064, "time": 18953.287284612656, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 601064, "time": 18953.293986082077, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 601112, "time": 18954.779113292694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 601400, "time": 18963.639904022217, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 601472, "time": 18966.038395643234, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 601904, "time": 18979.194251537323, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 602208, "time": 18988.457057237625, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 602248, "time": 18989.45986366272, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 602720, "time": 19004.1715965271, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 602744, "time": 19004.684112548828, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 602840, "time": 19007.636459589005, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 602912, "time": 19010.066879034042, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 602968, "time": 19011.556437253952, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 603000, "time": 19012.560926675797, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 603072, "time": 19014.99248290062, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 603328, "time": 19022.89052915573, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 603520, "time": 19028.72986149788, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 603664, "time": 19033.128663301468, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 603696, "time": 19034.10307240486, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 603904, "time": 19040.448460817337, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 603968, "time": 19042.415789604187, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 604448, "time": 19057.17642211914, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 604552, "time": 19060.1103515625, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 604568, "time": 19060.60466837883, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 604728, "time": 19065.47248697281, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 604728, "time": 19065.479741096497, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 604808, "time": 19067.934901237488, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 604856, "time": 19069.39581155777, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 605040, "time": 19075.307932138443, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 605280, "time": 19082.73327922821, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 605304, "time": 19083.243114233017, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 605712, "time": 19095.918781518936, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 605776, "time": 19097.868039131165, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 605944, "time": 19102.763080596924, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 605976, "time": 19103.736159324646, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 606016, "time": 19105.183019399643, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 606088, "time": 19107.18419623375, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 606272, "time": 19113.648020744324, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 606320, "time": 19115.119910240173, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 606392, "time": 19117.113824367523, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 606832, "time": 19130.809270858765, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 607080, "time": 19138.213459014893, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 607280, "time": 19144.611610889435, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 607560, "time": 19152.926085948944, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 607624, "time": 19154.877386808395, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 607832, "time": 19161.221682548523, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 607888, "time": 19163.155968904495, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 608024, "time": 19167.099970579147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608264, "time": 19174.57432961464, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 608344, "time": 19177.034813404083, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 608632, "time": 19185.85204935074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608760, "time": 19189.768233299255, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 608768, "time": 19190.241332292557, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 608864, "time": 19193.184858083725, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 609160, "time": 19202.10291647911, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 609320, "time": 19206.977224111557, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 609456, "time": 19211.371980905533, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 609496, "time": 19212.36900663376, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 609568, "time": 19214.80203986168, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 609912, "time": 19225.052050590515, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 19231.17122888565, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 610064, "time": 19231.42055773735, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 610064, "time": 19231.543123483658, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 610064, "time": 19232.807433366776, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 610064, "time": 19232.87276864052, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 610064, "time": 19232.898199796677, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 610064, "time": 19235.76243853569, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 610064, "time": 19236.0222928524, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 610089, "time": 19237.52498626709, "train_stats/mean_log_entropy": 0.07909723993257753, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7828195190429685, "train/action_min": 0.0, "train/action_std": 1.6942039489746095, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008784785981988534, "train/actor_opt_grad_steps": 37035.0, "train/actor_opt_loss": -10.279854926764965, "train/adv_mag": 0.9479687702655792, "train/adv_max": 0.408493190407753, "train/adv_mean": 0.0016403153624150945, "train/adv_min": -0.910943104326725, "train/adv_std": 0.028917809191625565, "train/cont_avg": 0.9956005859375, "train/cont_loss_mean": 0.013510362725937738, "train/cont_loss_std": 0.19619184895651415, "train/cont_neg_acc": 0.36594480920077566, "train/cont_neg_loss": 2.3529813239109894, "train/cont_pos_acc": 0.9999116823077202, "train/cont_pos_loss": 0.003049283740692772, "train/cont_pred": 0.9954573494195939, "train/cont_rate": 0.9956005859375, "train/dyn_loss_mean": 1.0000012665987015, "train/dyn_loss_std": 3.630863182479516e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2666089718788862, "train/extr_critic_critic_opt_grad_steps": 37035.0, "train/extr_critic_critic_opt_loss": 4070.4123852539065, "train/extr_critic_mag": 1.2745998632907867, "train/extr_critic_max": 1.2745998632907867, "train/extr_critic_mean": 1.1984873497486115, "train/extr_critic_min": 0.88930714905262, "train/extr_critic_std": 0.021498431749641896, "train/extr_return_normed_mag": 0.9428785344958306, "train/extr_return_normed_max": 0.31576195240020755, "train/extr_return_normed_mean": 0.03920979642309248, "train/extr_return_normed_min": -0.9189748278260231, "train/extr_return_normed_std": 0.03727013600990176, "train/extr_return_rate": 0.9993382599949837, "train/extr_return_raw_mag": 1.4766797828674316, "train/extr_return_raw_max": 1.4766797828674316, "train/extr_return_raw_mean": 1.200127682685852, "train/extr_return_raw_min": 0.24194300264120103, "train/extr_return_raw_std": 0.03727013614960015, "train/extr_reward_mag": 0.367904366850853, "train/extr_reward_max": 0.367904366850853, "train/extr_reward_mean": 0.0020143135197577067, "train/extr_reward_min": 1.7046928405761718e-07, "train/extr_reward_std": 0.010384879534831271, "train/image_loss_mean": 0.08929852809756994, "train/image_loss_std": 0.10116771746426821, "train/model_loss_mean": 0.7129301074147224, "train/model_loss_std": 0.3705121516436338, "train/model_opt_grad_norm": 23.227476243972777, "train/model_opt_grad_steps": 37001.035, "train/model_opt_loss": 2841.7050274658204, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3987.5, "train/policy_entropy_mag": 1.308358069062233, "train/policy_entropy_max": 1.308358069062233, "train/policy_entropy_mean": 0.09725111424922943, "train/policy_entropy_min": 0.0646865103393793, "train/policy_entropy_std": 0.12127796586602926, "train/policy_logprob_mag": 6.551080234050751, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09664638139307499, "train/policy_logprob_min": -6.551080234050751, "train/policy_logprob_std": 0.6321769461035729, "train/policy_randomness_mag": 0.6723630821704865, "train/policy_randomness_max": 0.6723630821704865, "train/policy_randomness_mean": 0.049977188762277365, "train/policy_randomness_min": 0.03324229134246707, "train/policy_randomness_std": 0.06232454909011722, "train/post_ent_mag": 39.13689800262451, "train/post_ent_max": 39.13689800262451, "train/post_ent_mean": 38.86523727416992, "train/post_ent_min": 38.62985809326172, "train/post_ent_std": 0.1115286622196436, "train/prior_ent_mag": 40.36398405075073, "train/prior_ent_max": 40.36398405075073, "train/prior_ent_mean": 38.42128448486328, "train/prior_ent_min": 36.99478584289551, "train/prior_ent_std": 0.5180068863928318, "train/rep_loss_mean": 1.0000012665987015, "train/rep_loss_std": 3.630863182479516e-05, "train/reward_avg": 0.001188186643703375, "train/reward_loss_mean": 0.010120435333810747, "train/reward_loss_std": 0.16992948553757742, "train/reward_max_data": 0.598984375745058, "train/reward_max_pred": 0.17999574780464173, "train/reward_neg_acc": 0.9998532050848007, "train/reward_neg_loss": 0.00193353465940163, "train/reward_pos_acc": 0.17553366249662705, "train/reward_pos_loss": 3.9737799671189538, "train/reward_pred": 0.0010578590800287202, "train/reward_rate": 0.00205078125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.005308845080435276, "report/cont_loss_std": 0.053007762879133224, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.02955014631152153, "report/cont_pos_acc": 0.9980430603027344, "report/cont_pos_loss": 0.005261406302452087, "report/cont_pred": 0.99383944272995, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0605948343873024, "report/image_loss_std": 0.0716899186372757, "report/model_loss_mean": 0.6683787703514099, "report/model_loss_std": 0.09813503921031952, "report/post_ent_mag": 39.46293258666992, "report/post_ent_max": 39.46293258666992, "report/post_ent_mean": 39.180240631103516, "report/post_ent_min": 38.94948196411133, "report/post_ent_std": 0.11322424560785294, "report/prior_ent_mag": 40.22274398803711, "report/prior_ent_max": 40.22274398803711, "report/prior_ent_mean": 38.62665557861328, "report/prior_ent_min": 37.40038299560547, "report/prior_ent_std": 0.411019891500473, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007812500116415322, "report/reward_loss_mean": 0.0024750707671046257, "report/reward_loss_std": 0.03217947110533714, "report/reward_max_data": 0.800000011920929, "report/reward_max_pred": 0.5681025981903076, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0015136232832446694, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.986035943031311, "report/reward_pred": 0.0012197870528325438, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.07642538845539093, "eval/cont_loss_std": 0.9014137387275696, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.77241039276123, "eval/cont_pos_acc": 0.9990166425704956, "eval/cont_pos_loss": 0.0028050385881215334, "eval/cont_pred": 0.9980396032333374, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18247289955615997, "eval/image_loss_std": 0.15163828432559967, "eval/model_loss_mean": 0.8592190742492676, "eval/model_loss_std": 0.9170953035354614, "eval/post_ent_mag": 39.486297607421875, "eval/post_ent_max": 39.486297607421875, "eval/post_ent_mean": 39.15795135498047, "eval/post_ent_min": 38.95819091796875, "eval/post_ent_std": 0.11108409613370895, "eval/prior_ent_mag": 40.25774383544922, "eval/prior_ent_max": 40.25774383544922, "eval/prior_ent_mean": 38.61882781982422, "eval/prior_ent_min": 37.5361213684082, "eval/prior_ent_std": 0.4335840940475464, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00032075331546366215, "eval/reward_loss_std": 0.0032330637332051992, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.03885984420776367, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00032075331546366215, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00014681031461805105, "eval/reward_rate": 0.0, "replay/size": 609585.0, "replay/inserts": 31984.0, "replay/samples": 31984.0, "replay/insert_wait_avg": 1.3085291825752963e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.3766338640359e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5680.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.132740101344149e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4220240116119, "timer/env.step_count": 3998.0, "timer/env.step_total": 38.370208501815796, "timer/env.step_frac": 0.03835402218351246, "timer/env.step_avg": 0.009597350800854377, "timer/env.step_min": 0.007726907730102539, "timer/env.step_max": 0.03578901290893555, "timer/replay._sample_count": 31984.0, "timer/replay._sample_total": 16.111159324645996, "timer/replay._sample_frac": 0.01610436289681183, "timer/replay._sample_avg": 0.0005037255916910329, "timer/replay._sample_min": 0.0003745555877685547, "timer/replay._sample_max": 0.029379844665527344, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4708.0, "timer/agent.policy_total": 49.26592493057251, "timer/agent.policy_frac": 0.04924514229806748, "timer/agent.policy_avg": 0.010464300112695946, "timer/agent.policy_min": 0.0088348388671875, "timer/agent.policy_max": 0.08588790893554688, "timer/dataset_train_count": 1999.0, "timer/dataset_train_total": 0.21010923385620117, "timer/dataset_train_frac": 0.00021002060012001737, "timer/dataset_train_avg": 0.00010510717051335727, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.000701904296875, "timer/agent.train_count": 1999.0, "timer/agent.train_total": 897.4332959651947, "timer/agent.train_frac": 0.8970547173347497, "timer/agent.train_avg": 0.4489411185418683, "timer/agent.train_min": 0.4356236457824707, "timer/agent.train_max": 0.6989915370941162, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47428011894226074, "timer/agent.report_frac": 0.0004740800457795157, "timer/agent.report_avg": 0.23714005947113037, "timer/agent.report_min": 0.23119020462036133, "timer/agent.report_max": 0.24308991432189941, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8836478385000265e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 31.96999076538865}
{"step": 610224, "time": 19241.610294818878, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 610376, "time": 19246.047785282135, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 610408, "time": 19247.035054206848, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 610472, "time": 19248.99063229561, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 610552, "time": 19251.465987682343, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 610576, "time": 19252.432164669037, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 610696, "time": 19255.89207649231, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 611048, "time": 19266.80553293228, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 611168, "time": 19270.759555101395, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 611280, "time": 19274.168913841248, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 611680, "time": 19286.390383005142, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 611776, "time": 19289.31541275978, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 611904, "time": 19293.324238538742, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 612064, "time": 19298.273263931274, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 612120, "time": 19299.777899980545, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 612168, "time": 19301.235340833664, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 612184, "time": 19301.72911310196, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 612376, "time": 19307.594682455063, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 612408, "time": 19308.576556682587, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 612552, "time": 19312.98226261139, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 612656, "time": 19316.3920109272, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 612776, "time": 19319.847106695175, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 612808, "time": 19320.907467126846, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 612976, "time": 19326.252024173737, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 613304, "time": 19336.017003774643, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 613376, "time": 19338.420483350754, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 613392, "time": 19338.92761349678, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 613440, "time": 19340.391175985336, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 613560, "time": 19343.82150053978, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 613712, "time": 19348.680049419403, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 613832, "time": 19352.19111275673, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 613848, "time": 19352.68528366089, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 614056, "time": 19359.045849084854, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 614104, "time": 19360.506935834885, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 614344, "time": 19367.827206611633, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 614624, "time": 19377.051555156708, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 614752, "time": 19381.097084760666, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 615144, "time": 19392.831502199173, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 615288, "time": 19397.223498106003, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 615288, "time": 19397.230402946472, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 615384, "time": 19400.163729429245, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 615496, "time": 19403.586723804474, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 615664, "time": 19408.92947411537, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 615784, "time": 19412.43065428734, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 615872, "time": 19415.346655368805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 615896, "time": 19415.85825061798, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 616048, "time": 19420.755361795425, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 616160, "time": 19424.223284482956, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 616248, "time": 19426.725553512573, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 616528, "time": 19435.502856969833, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 616640, "time": 19438.938126325607, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 616648, "time": 19438.96576309204, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 616696, "time": 19440.514561653137, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 616792, "time": 19443.440942764282, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 616960, "time": 19448.79354405403, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 617208, "time": 19456.12359881401, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 617336, "time": 19460.048154592514, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 617432, "time": 19462.983481407166, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 617640, "time": 19469.354467630386, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 617728, "time": 19472.394473075867, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 618200, "time": 19486.619258403778, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 618312, "time": 19490.03172326088, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 618528, "time": 19496.861126184464, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 618680, "time": 19501.36252474785, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 618688, "time": 19501.83346056938, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 618840, "time": 19506.234431028366, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 618848, "time": 19506.705756425858, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 619136, "time": 19515.47540998459, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 619200, "time": 19517.43866944313, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 619272, "time": 19519.405150175095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 619392, "time": 19523.27811574936, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 619424, "time": 19524.256559848785, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 619464, "time": 19525.249395370483, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 619936, "time": 19539.937490701675, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 619960, "time": 19540.46786379814, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 620024, "time": 19542.411963939667, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 19544.435571432114, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 620048, "time": 19545.313080072403, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 620048, "time": 19546.078468322754, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 620048, "time": 19546.96966600418, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 620048, "time": 19547.087091445923, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 620048, "time": 19547.206721544266, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 620048, "time": 19547.8497569561, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 620048, "time": 19548.156669855118, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 620216, "time": 19553.081013202667, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 620256, "time": 19554.560662269592, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 620288, "time": 19555.580466985703, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 620328, "time": 19556.60315799713, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 620552, "time": 19563.659343481064, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 620800, "time": 19571.471657514572, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 621048, "time": 19578.7735080719, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 621176, "time": 19582.675521850586, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 621280, "time": 19586.056502103806, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 621448, "time": 19591.05748486519, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 621616, "time": 19596.391130447388, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 621672, "time": 19597.861970186234, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 621680, "time": 19598.331470251083, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 621688, "time": 19598.358046531677, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 621920, "time": 19605.683611869812, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 621984, "time": 19607.642956495285, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 622072, "time": 19610.123678445816, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 622696, "time": 19629.7807598114, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 622840, "time": 19634.168498277664, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 622896, "time": 19636.121141672134, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 622936, "time": 19637.132273435593, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 623040, "time": 19640.546556949615, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 623144, "time": 19643.498408555984, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 623336, "time": 19649.379160881042, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 623336, "time": 19649.386276483536, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 623512, "time": 19654.864520549774, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 623704, "time": 19660.828358888626, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 623736, "time": 19661.828058719635, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 623832, "time": 19664.814209222794, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 624048, "time": 19671.666073322296, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 624296, "time": 19679.00778579712, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 624376, "time": 19681.574333906174, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 624496, "time": 19685.492147922516, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 624624, "time": 19689.42191362381, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 624688, "time": 19691.382864952087, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 625000, "time": 19700.67062354088, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 625088, "time": 19703.593504428864, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 625152, "time": 19705.546296596527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 625296, "time": 19709.926305770874, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 625448, "time": 19714.439299345016, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 626008, "time": 19731.489093780518, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 626016, "time": 19731.960176467896, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 626144, "time": 19735.858655691147, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 626256, "time": 19739.284358024597, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 626368, "time": 19742.79458975792, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 626448, "time": 19745.209361314774, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 626664, "time": 19751.564585208893, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 626672, "time": 19752.072223186493, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 626720, "time": 19753.531987667084, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 626736, "time": 19754.02384352684, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 626880, "time": 19758.444787979126, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 627072, "time": 19764.3885781765, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 627216, "time": 19768.796130418777, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 627224, "time": 19768.82391524315, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 627448, "time": 19775.749851703644, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 627504, "time": 19777.697403907776, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 627656, "time": 19782.117894649506, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 627896, "time": 19789.43382501602, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 627904, "time": 19789.90922999382, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 627992, "time": 19792.425783634186, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 628248, "time": 19800.40371489525, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 628344, "time": 19803.380678892136, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 628432, "time": 19806.298426151276, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 628504, "time": 19808.26686477661, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 628664, "time": 19813.137578725815, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 628696, "time": 19814.11620283127, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 629016, "time": 19823.86151432991, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 629032, "time": 19824.352652311325, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 629160, "time": 19828.26490712166, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 629432, "time": 19836.667714834213, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 629480, "time": 19838.132870912552, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 629528, "time": 19839.58765554428, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 629632, "time": 19843.005907535553, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 629792, "time": 19847.945303678513, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 629800, "time": 19847.975615024567, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 629824, "time": 19848.936643123627, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 19856.23406767845, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 630032, "time": 19856.726083040237, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 630032, "time": 19856.875896692276, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 630032, "time": 19857.159464597702, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 630032, "time": 19858.045776844025, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 630032, "time": 19858.552290916443, "eval_episode/length": 169.0, "eval_episode/score": 0.47187501192092896, "eval_episode/reward_rate": 0.0058823529411764705}
{"step": 630032, "time": 19858.8897023201, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 630032, "time": 19859.27051448822, "eval_episode/length": 207.0, "eval_episode/score": 0.3531250059604645, "eval_episode/reward_rate": 0.004807692307692308}
{"step": 630112, "time": 19861.812964439392, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 630144, "time": 19862.795226573944, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 630168, "time": 19863.30913233757, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 630608, "time": 19877.0047955513, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 630624, "time": 19877.510511875153, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 630712, "time": 19880.027595758438, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 630800, "time": 19883.412878513336, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 630928, "time": 19887.34751391411, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 630976, "time": 19888.822013616562, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 631016, "time": 19889.842044830322, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 631376, "time": 19901.13893723488, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 631464, "time": 19903.583963155746, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 631544, "time": 19906.055572509766, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 631688, "time": 19910.45508670807, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 631768, "time": 19912.891837358475, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 632096, "time": 19923.211046934128, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 632192, "time": 19926.17225074768, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 632224, "time": 19927.149502038956, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 632320, "time": 19930.07869696617, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 632608, "time": 19938.86450099945, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 632680, "time": 19940.842266321182, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 632936, "time": 19948.63657975197, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 633032, "time": 19951.639193296432, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 633272, "time": 19958.99363732338, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 633304, "time": 19959.96738409996, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 633488, "time": 19965.798186063766, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 633488, "time": 19965.80527997017, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 633648, "time": 19970.698394060135, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 633720, "time": 19972.69047164917, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 634064, "time": 19983.55335187912, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 634216, "time": 19987.97610759735, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 634360, "time": 19992.378336429596, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 634408, "time": 19993.84672999382, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 634576, "time": 19999.230676651, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 634944, "time": 20010.650934934616, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 634984, "time": 20011.65251350403, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 635160, "time": 20017.04460644722, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 635176, "time": 20020.923078775406, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 635784, "time": 20039.430201292038, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 635928, "time": 20043.92794775963, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 635960, "time": 20044.9216029644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636032, "time": 20047.330810070038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636232, "time": 20053.205003976822, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 636352, "time": 20057.07357287407, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 636680, "time": 20066.861387491226, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 636864, "time": 20072.8372130394, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 636960, "time": 20075.792513132095, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 637112, "time": 20080.22116804123, "episode/length": 265.0, "episode/score": 0.171875, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.0}
{"step": 637480, "time": 20091.456260442734, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 637488, "time": 20091.926557064056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 637632, "time": 20096.333403110504, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 637680, "time": 20097.791877985, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 637704, "time": 20098.301797389984, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 637768, "time": 20100.326754570007, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 637872, "time": 20103.779147148132, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 638144, "time": 20112.07043862343, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 638416, "time": 20120.357189893723, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 638656, "time": 20127.665688753128, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 638688, "time": 20128.665521621704, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 638768, "time": 20131.159981012344, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 638840, "time": 20133.152228355408, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 639032, "time": 20139.46587371826, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 639144, "time": 20142.891941070557, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 639296, "time": 20147.752066135406, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 639304, "time": 20147.779715061188, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 639304, "time": 20147.785947799683, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 639424, "time": 20151.67342877388, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 639640, "time": 20158.06906938553, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 639752, "time": 20161.614968776703, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 639904, "time": 20166.46411728859, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 20170.328570604324, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 640016, "time": 20170.341203212738, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 640016, "time": 20170.735833644867, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 640016, "time": 20171.296753168106, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 640016, "time": 20171.30214858055, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 640016, "time": 20172.14404821396, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 640016, "time": 20172.34978222847, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 640016, "time": 20172.780329942703, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 640080, "time": 20174.72806406021, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 640096, "time": 20175.221237421036, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 640632, "time": 20191.473646640778, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 640992, "time": 20202.712012529373, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 641048, "time": 20204.193907022476, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 641400, "time": 20214.943700551987, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 641432, "time": 20215.92397260666, "episode/length": 265.0, "episode/score": 0.171875, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.0}
{"step": 641512, "time": 20218.36238217354, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 641568, "time": 20220.325315237045, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 641600, "time": 20221.369787454605, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 641616, "time": 20221.862024068832, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 641760, "time": 20226.271592140198, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 642105, "time": 20237.539752483368, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8860064697265626, "train/action_min": 0.0, "train/action_std": 1.7573332262039185, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010476175928488374, "train/actor_opt_grad_steps": 39035.0, "train/actor_opt_loss": -11.327706972956657, "train/adv_mag": 0.9850146406888962, "train/adv_max": 0.4116025412082672, "train/adv_mean": 0.002308926964606144, "train/adv_min": -0.9413261407613754, "train/adv_std": 0.030087915710173548, "train/cont_avg": 0.9952783203125, "train/cont_loss_mean": 0.014708871532930061, "train/cont_loss_std": 0.20991990860085935, "train/cont_neg_acc": 0.3399058850716107, "train/cont_neg_loss": 2.4672025157765827, "train/cont_pos_acc": 0.9998920506238937, "train/cont_pos_loss": 0.0032342599739786236, "train/cont_pred": 0.9952467033267021, "train/cont_rate": 0.9952783203125, "train/dyn_loss_mean": 1.000005580186844, "train/dyn_loss_std": 0.00015133806271478534, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2679298902209848, "train/extr_critic_critic_opt_grad_steps": 39035.0, "train/extr_critic_critic_opt_loss": 5831.02216796875, "train/extr_critic_mag": 1.3023196589946746, "train/extr_critic_max": 1.3023196589946746, "train/extr_critic_mean": 1.2255086839199065, "train/extr_critic_min": 0.8706847929954529, "train/extr_critic_std": 0.024095036606304347, "train/extr_return_normed_mag": 0.9792410516738892, "train/extr_return_normed_max": 0.31372446835041046, "train/extr_return_normed_mean": 0.04595383402891457, "train/extr_return_normed_min": -0.9404028958082199, "train/extr_return_normed_std": 0.03976055154111236, "train/extr_return_rate": 0.9992236766219139, "train/extr_return_raw_mag": 1.4955882036685944, "train/extr_return_raw_max": 1.4955882036685944, "train/extr_return_raw_mean": 1.227817628979683, "train/extr_return_raw_min": 0.241460839509964, "train/extr_return_raw_std": 0.039760551429353655, "train/extr_reward_mag": 0.3664888572692871, "train/extr_reward_max": 0.3664888572692871, "train/extr_reward_mean": 0.0019930294423829765, "train/extr_reward_min": 2.682209014892578e-07, "train/extr_reward_std": 0.009679998726351186, "train/image_loss_mean": 0.09022428398951889, "train/image_loss_std": 0.10243877559900284, "train/model_loss_mean": 0.716495124399662, "train/model_loss_std": 0.40419188238680365, "train/model_opt_grad_norm": 22.70249542713165, "train/model_opt_grad_steps": 38999.51, "train/model_opt_loss": 2578.769552612305, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3612.5, "train/policy_entropy_mag": 1.3336016649007798, "train/policy_entropy_max": 1.3336016649007798, "train/policy_entropy_mean": 0.10252209100872278, "train/policy_entropy_min": 0.06468653034418821, "train/policy_entropy_std": 0.13130242004990578, "train/policy_logprob_mag": 6.5510802388191225, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10260679773986339, "train/policy_logprob_min": -6.5510802388191225, "train/policy_logprob_std": 0.6408586457371712, "train/policy_randomness_mag": 0.6853357252478599, "train/policy_randomness_max": 0.6853357252478599, "train/policy_randomness_mean": 0.05268593486398458, "train/policy_randomness_min": 0.03324230326339603, "train/policy_randomness_std": 0.06747609999030829, "train/post_ent_mag": 39.16658983230591, "train/post_ent_max": 39.16658983230591, "train/post_ent_mean": 38.885551834106444, "train/post_ent_min": 38.63047245025635, "train/post_ent_std": 0.12069940950721503, "train/prior_ent_mag": 40.28465497970581, "train/prior_ent_max": 40.28465497970581, "train/prior_ent_mean": 38.49308624267578, "train/prior_ent_min": 37.31055522918701, "train/prior_ent_std": 0.4554126384854317, "train/rep_loss_mean": 1.000005580186844, "train/rep_loss_std": 0.00015133806271478534, "train/reward_avg": 0.0014090728785959073, "train/reward_loss_mean": 0.01155859934631735, "train/reward_loss_std": 0.19198185933055356, "train/reward_max_data": 0.6700781235098838, "train/reward_max_pred": 0.19594767689704895, "train/reward_neg_acc": 0.9997308000922203, "train/reward_neg_loss": 0.002144617374287918, "train/reward_pos_acc": 0.1483957234391554, "train/reward_pos_loss": 4.086062827212288, "train/reward_pred": 0.0011506397649645806, "train/reward_rate": 0.0023291015625, "train_stats/mean_log_entropy": 0.08362875458521721, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.015511693432927132, "report/cont_loss_std": 0.1947426050901413, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 2.4618208408355713, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003508214373141527, "report/cont_pred": 0.9954304099082947, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09588122367858887, "report/image_loss_std": 0.1175658106803894, "report/model_loss_mean": 0.7311391830444336, "report/model_loss_std": 0.5018342137336731, "report/post_ent_mag": 39.032081604003906, "report/post_ent_max": 39.032081604003906, "report/post_ent_mean": 38.74955368041992, "report/post_ent_min": 38.48893356323242, "report/post_ent_std": 0.12774233520030975, "report/prior_ent_mag": 40.569766998291016, "report/prior_ent_max": 40.569766998291016, "report/prior_ent_mean": 38.824859619140625, "report/prior_ent_min": 37.60105895996094, "report/prior_ent_std": 0.45364364981651306, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0017913818592205644, "report/reward_loss_mean": 0.019746208563447, "report/reward_loss_std": 0.27303171157836914, "report/reward_max_data": 0.609375, "report/reward_max_pred": 0.057745933532714844, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.002797150518745184, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.3417558670043945, "report/reward_pred": 0.0012836791574954987, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.07292382419109344, "eval/cont_loss_std": 0.8403531312942505, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.08999252319336, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0019232858903706074, "eval/cont_pred": 0.9980992674827576, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19717279076576233, "eval/image_loss_std": 0.14879213273525238, "eval/model_loss_mean": 0.8783524632453918, "eval/model_loss_std": 0.937619149684906, "eval/post_ent_mag": 39.030967712402344, "eval/post_ent_max": 39.030967712402344, "eval/post_ent_mean": 38.718788146972656, "eval/post_ent_min": 38.472076416015625, "eval/post_ent_std": 0.12696343660354614, "eval/prior_ent_mag": 40.569766998291016, "eval/prior_ent_max": 40.569766998291016, "eval/prior_ent_mean": 38.78156280517578, "eval/prior_ent_min": 37.683349609375, "eval/prior_ent_std": 0.48274263739585876, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0006774902576580644, "eval/reward_loss_mean": 0.00825582817196846, "eval/reward_loss_std": 0.24701839685440063, "eval/reward_max_data": 0.6937500238418579, "eval/reward_max_pred": 0.01684415340423584, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0005332507425919175, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.908452987670898, "eval/reward_pred": 0.0002458940725773573, "eval/reward_rate": 0.0009765625, "replay/size": 641601.0, "replay/inserts": 32016.0, "replay/samples": 32016.0, "replay/insert_wait_avg": 1.3129628342071335e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.345654379421922e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4656.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.103863683353175e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0007462501526, "timer/env.step_count": 4002.0, "timer/env.step_total": 38.459468603134155, "timer/env.step_frac": 0.03845943990277126, "timer/env.step_avg": 0.009610062119723676, "timer/env.step_min": 0.0076901912689208984, "timer/env.step_max": 0.03987693786621094, "timer/replay._sample_count": 32016.0, "timer/replay._sample_total": 16.067092657089233, "timer/replay._sample_frac": 0.016067080667027833, "timer/replay._sample_avg": 0.0005018457226727022, "timer/replay._sample_min": 0.00038051605224609375, "timer/replay._sample_max": 0.011160850524902344, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4584.0, "timer/agent.policy_total": 47.33283591270447, "timer/agent.policy_frac": 0.047332800590594803, "timer/agent.policy_avg": 0.010325662284621394, "timer/agent.policy_min": 0.008815288543701172, "timer/agent.policy_max": 0.0758066177368164, "timer/dataset_train_count": 2001.0, "timer/dataset_train_total": 0.21074318885803223, "timer/dataset_train_frac": 0.00021074303159101274, "timer/dataset_train_avg": 0.00010531893496153534, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0009713172912597656, "timer/agent.train_count": 2001.0, "timer/agent.train_total": 898.8580131530762, "timer/agent.train_frac": 0.8988573423806473, "timer/agent.train_avg": 0.4492044043743509, "timer/agent.train_min": 0.4366586208343506, "timer/agent.train_max": 0.6717822551727295, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47020912170410156, "timer/agent.report_frac": 0.0004702087708107346, "timer/agent.report_avg": 0.23510456085205078, "timer/agent.report_min": 0.228118896484375, "timer/agent.report_max": 0.24209022521972656, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.0279136950087866e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 32.01546180673097}
{"step": 642168, "time": 20239.19112420082, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 642200, "time": 20240.183800697327, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 642248, "time": 20241.64801955223, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 642296, "time": 20243.09353494644, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 642368, "time": 20245.510718345642, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 642536, "time": 20250.414020061493, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 642648, "time": 20253.821643829346, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 642664, "time": 20254.31188106537, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 642768, "time": 20257.697341442108, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 643064, "time": 20266.406725645065, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 643216, "time": 20271.255347251892, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 643384, "time": 20276.122874498367, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 643576, "time": 20282.098298311234, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 643584, "time": 20282.56898164749, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 643976, "time": 20294.27840447426, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 644032, "time": 20296.191273212433, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 644136, "time": 20299.13360309601, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 644528, "time": 20311.28193616867, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 644632, "time": 20314.20810198784, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 644768, "time": 20318.52365088463, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 644888, "time": 20321.911674022675, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 644944, "time": 20323.840475559235, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 644968, "time": 20324.34601211548, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 644968, "time": 20324.353710889816, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 645168, "time": 20330.61797595024, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 645336, "time": 20335.469621658325, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 645480, "time": 20339.829206943512, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 645776, "time": 20349.075581789017, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 645904, "time": 20352.950248241425, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 645944, "time": 20353.951109409332, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 645968, "time": 20354.899906396866, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 646040, "time": 20356.87548661232, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 646112, "time": 20359.273755311966, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 646280, "time": 20364.14828801155, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 646304, "time": 20365.100872516632, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 646832, "time": 20381.246816635132, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 646952, "time": 20384.639424324036, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 647080, "time": 20388.53861451149, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 647088, "time": 20389.00959253311, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 647216, "time": 20393.769181251526, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 647352, "time": 20397.686168432236, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 647384, "time": 20398.65615940094, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 647680, "time": 20407.975294828415, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 647904, "time": 20414.78533434868, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 647960, "time": 20416.27389216423, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 648248, "time": 20425.00790166855, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 648360, "time": 20428.41272997856, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 648440, "time": 20430.920962810516, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 648576, "time": 20435.23637700081, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 648576, "time": 20435.24330806732, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 648904, "time": 20444.963050365448, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 648944, "time": 20446.427354574203, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 648968, "time": 20446.938517570496, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 648968, "time": 20446.94557261467, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 649016, "time": 20448.402804613113, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 649160, "time": 20452.751754283905, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 649376, "time": 20459.476229190826, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 649424, "time": 20461.06183719635, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 649520, "time": 20463.9480779171, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 649592, "time": 20465.91476416588, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 649712, "time": 20469.77253484726, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 649760, "time": 20471.218282222748, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 649880, "time": 20474.628049612045, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 650000, "time": 20480.49517083168, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 650000, "time": 20481.10722875595, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 650000, "time": 20481.210822105408, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 650000, "time": 20481.528974056244, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 650000, "time": 20481.55577492714, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 650000, "time": 20481.60314631462, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 650000, "time": 20482.11776280403, "eval_episode/length": 185.0, "eval_episode/score": 0.421875, "eval_episode/reward_rate": 0.005376344086021506}
{"step": 650000, "time": 20483.04305911064, "eval_episode/length": 232.0, "eval_episode/score": 0.2750000059604645, "eval_episode/reward_rate": 0.004291845493562232}
{"step": 650240, "time": 20490.340205430984, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 650344, "time": 20493.320429086685, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 650344, "time": 20493.32736182213, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 650504, "time": 20498.16605567932, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 650568, "time": 20500.117656230927, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 650640, "time": 20502.511987686157, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 650728, "time": 20504.957758188248, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 650936, "time": 20511.236874818802, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 650952, "time": 20511.725550174713, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 651056, "time": 20515.080747127533, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 651368, "time": 20524.344777822495, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 651640, "time": 20532.564992666245, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 651640, "time": 20532.597398757935, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 651672, "time": 20533.584792375565, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 651936, "time": 20541.782373428345, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 652072, "time": 20545.72363305092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 652440, "time": 20556.98123192787, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 652464, "time": 20557.925965070724, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 652504, "time": 20558.91993355751, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 652648, "time": 20563.285967826843, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 652776, "time": 20567.172219753265, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 652904, "time": 20571.035430431366, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 652920, "time": 20571.54555416107, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 653224, "time": 20580.862905979156, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 653808, "time": 20598.645193338394, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 653856, "time": 20600.099498033524, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 653856, "time": 20600.106830120087, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 653928, "time": 20602.08422589302, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 654048, "time": 20605.93798804283, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 654056, "time": 20605.96717453003, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 654496, "time": 20619.560950517654, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 654504, "time": 20619.588763475418, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 654552, "time": 20621.055485248566, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 654648, "time": 20623.96489405632, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 654752, "time": 20627.354643821716, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 654872, "time": 20630.777458190918, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 655040, "time": 20636.062571763992, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 655288, "time": 20643.38032436371, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 655472, "time": 20649.613758802414, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 655472, "time": 20649.620305776596, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 655600, "time": 20653.483948230743, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 655672, "time": 20655.47891497612, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 655752, "time": 20657.90056371689, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 655944, "time": 20663.704557418823, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 655992, "time": 20665.182991743088, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 656160, "time": 20670.61258006096, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 656440, "time": 20678.927716493607, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 656552, "time": 20682.33009648323, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 656624, "time": 20684.748213768005, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 656656, "time": 20685.72656226158, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 656944, "time": 20694.49209022522, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 657376, "time": 20707.61504983902, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 657496, "time": 20711.04430437088, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 657616, "time": 20714.90784883499, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 657872, "time": 20722.691678762436, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 658016, "time": 20727.038587331772, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 658152, "time": 20731.10117506981, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 658256, "time": 20734.48827290535, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 658432, "time": 20739.83385825157, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 658632, "time": 20745.663905858994, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 658736, "time": 20749.032635211945, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 658832, "time": 20751.94994521141, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 658832, "time": 20751.958426237106, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 658904, "time": 20753.913417339325, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 658936, "time": 20754.879700899124, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 659024, "time": 20757.779129743576, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 659112, "time": 20760.264521598816, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 659464, "time": 20770.986192703247, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 659592, "time": 20774.87002635002, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 659624, "time": 20775.845081329346, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 659784, "time": 20780.675222873688, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 659968, "time": 20786.459114074707, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 20791.016090869904, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 660088, "time": 20791.471329689026, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 660088, "time": 20791.818432807922, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 660088, "time": 20791.82444834709, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 660088, "time": 20792.04180407524, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 660088, "time": 20792.546650886536, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 660088, "time": 20792.7172498703, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 660088, "time": 20793.734320878983, "eval_episode/length": 166.0, "eval_episode/score": 0.48124998807907104, "eval_episode/reward_rate": 0.005988023952095809}
{"step": 660120, "time": 20794.7214782238, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 660136, "time": 20795.204480409622, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 660160, "time": 20796.151079654694, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 660344, "time": 20801.469716072083, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 660928, "time": 20819.355179071426, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 660944, "time": 20819.84426689148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 661016, "time": 20821.870551109314, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 661144, "time": 20825.771802425385, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 661280, "time": 20830.117790222168, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 661440, "time": 20834.983957529068, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 661448, "time": 20835.011395454407, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 661480, "time": 20835.984604358673, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 661728, "time": 20843.747940301895, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 661832, "time": 20846.689487457275, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 662096, "time": 20855.029015779495, "episode/length": 265.0, "episode/score": 0.171875, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.0}
{"step": 662240, "time": 20861.072392463684, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 662416, "time": 20866.4215760231, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 662808, "time": 20878.09654021263, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 662864, "time": 20880.030290842056, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 662976, "time": 20883.52382349968, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 662992, "time": 20884.03613424301, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 663208, "time": 20890.3597741127, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 663272, "time": 20892.29991388321, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 663456, "time": 20898.09827518463, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 663760, "time": 20907.77695965767, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 663808, "time": 20909.26096558571, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 663912, "time": 20912.2385931015, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 663920, "time": 20912.705460071564, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 663984, "time": 20914.662071704865, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 663984, "time": 20914.668570756912, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 664032, "time": 20916.142095565796, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 664104, "time": 20918.133713960648, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 664384, "time": 20926.878279685974, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 664688, "time": 20936.09983944893, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 664800, "time": 20939.50715303421, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 664872, "time": 20941.598613023758, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 664952, "time": 20944.030729532242, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 665224, "time": 20952.251146793365, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 665264, "time": 20953.705732107162, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 665400, "time": 20957.60623574257, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 665424, "time": 20958.555963516235, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 665528, "time": 20961.47666811943, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 665800, "time": 20969.714312314987, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 666048, "time": 20977.614478588104, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 666128, "time": 20980.026702165604, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 666256, "time": 20983.898011446, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 666376, "time": 20987.31900691986, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 666544, "time": 20992.631370067596, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 666664, "time": 20996.039930582047, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 666752, "time": 20998.937168598175, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 666856, "time": 21001.946764230728, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 666928, "time": 21004.365162849426, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 667048, "time": 21007.777086019516, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 667128, "time": 21010.184590816498, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 667280, "time": 21015.006330013275, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 667312, "time": 21016.007038116455, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 667608, "time": 21024.738960266113, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 667616, "time": 21025.205786943436, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 667736, "time": 21028.81525993347, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 667776, "time": 21030.285192251205, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 668048, "time": 21038.603664636612, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 668168, "time": 21042.023569583893, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 668520, "time": 21052.757003307343, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 668520, "time": 21052.765125513077, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 668664, "time": 21057.136410713196, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 668752, "time": 21060.041153907776, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 669000, "time": 21067.462291240692, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 669064, "time": 21069.388450860977, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 669112, "time": 21070.855952978134, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 669128, "time": 21071.34581375122, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 669304, "time": 21076.665919303894, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 669472, "time": 21081.967883825302, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 669784, "time": 21091.273057222366, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 21099.99371600151, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 21100.77804708481, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 670072, "time": 21100.854840040207, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 670072, "time": 21101.235050439835, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 670072, "time": 21102.210434675217, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 670072, "time": 21102.2344892025, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 670072, "time": 21102.494396924973, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 670072, "time": 21102.63349723816, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 670072, "time": 21103.077234506607, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 670080, "time": 21103.55429649353, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 670432, "time": 21114.28883743286, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 670440, "time": 21114.317046642303, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 670448, "time": 21114.791553497314, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 670496, "time": 21116.259135484695, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 670512, "time": 21116.768971920013, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 670712, "time": 21122.714440584183, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 670960, "time": 21130.46029639244, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 671168, "time": 21136.76973247528, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 671280, "time": 21140.165535211563, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 671464, "time": 21145.51882815361, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 671552, "time": 21148.41285967827, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 671560, "time": 21148.442158699036, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 671744, "time": 21154.48423409462, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 671992, "time": 21162.10550069809, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 672024, "time": 21163.075295448303, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 672136, "time": 21166.467842817307, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 672384, "time": 21174.150006055832, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 672464, "time": 21176.625468730927, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 672608, "time": 21181.17078256607, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 672680, "time": 21183.162050247192, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 672704, "time": 21184.125784158707, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 672744, "time": 21185.138180732727, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 672928, "time": 21190.9768846035, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 673144, "time": 21197.25906276703, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 673200, "time": 21199.162605285645, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 673392, "time": 21204.973810195923, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 673512, "time": 21208.37988638878, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 673592, "time": 21210.888078927994, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 674048, "time": 21225.00743842125, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 674056, "time": 21225.03594851494, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 674272, "time": 21231.785764694214, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 674424, "time": 21236.154078245163, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 674441, "time": 21237.630784749985, "train_stats/mean_log_entropy": 0.07372644660640354, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.766453204768719, "train/action_min": 0.0, "train/action_std": 1.7123425620617252, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010260339730677408, "train/actor_opt_grad_steps": 41045.0, "train/actor_opt_loss": -12.636468903263017, "train/adv_mag": 0.9982017089824865, "train/adv_max": 0.4501660861591301, "train/adv_mean": 0.0020276055159832475, "train/adv_min": -0.9333905757653831, "train/adv_std": 0.03130709765349875, "train/cont_avg": 0.995049504950495, "train/cont_loss_mean": 0.015510979563800046, "train/cont_loss_std": 0.2102649382449281, "train/cont_neg_acc": 0.3193441223149276, "train/cont_neg_loss": 2.436348921701708, "train/cont_pos_acc": 0.9998639090226429, "train/cont_pos_loss": 0.0033333376292047083, "train/cont_pred": 0.9951879470655234, "train/cont_rate": 0.995049504950495, "train/dyn_loss_mean": 1.0000015178529342, "train/dyn_loss_std": 4.855542445709781e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1598739456293164, "train/extr_critic_critic_opt_grad_steps": 41045.0, "train/extr_critic_critic_opt_loss": 11419.060063428218, "train/extr_critic_mag": 1.3869301033492136, "train/extr_critic_max": 1.3869301033492136, "train/extr_critic_mean": 1.2991500957177418, "train/extr_critic_min": 0.9096469430640193, "train/extr_critic_std": 0.028297941882790317, "train/extr_return_normed_mag": 0.9824982483198147, "train/extr_return_normed_max": 0.304589048470601, "train/extr_return_normed_mean": 0.04996241018692456, "train/extr_return_normed_min": -0.9454845302175767, "train/extr_return_normed_std": 0.04258594495050683, "train/extr_return_rate": 0.9992790599860767, "train/extr_return_raw_mag": 1.5558043222616214, "train/extr_return_raw_max": 1.5558043222616214, "train/extr_return_raw_mean": 1.3011777454083508, "train/extr_return_raw_min": 0.3057307435734437, "train/extr_return_raw_std": 0.04258594496894886, "train/extr_reward_mag": 0.36430571515961446, "train/extr_reward_max": 0.36430571515961446, "train/extr_reward_mean": 0.0019982047456819194, "train/extr_reward_min": 2.11862054201636e-07, "train/extr_reward_std": 0.00915567963476302, "train/image_loss_mean": 0.0906495666592428, "train/image_loss_std": 0.10329842080574224, "train/model_loss_mean": 0.7195066384749838, "train/model_loss_std": 0.42451565609414976, "train/model_opt_grad_norm": 21.558791698795734, "train/model_opt_grad_steps": 41008.50495049505, "train/model_opt_loss": 3579.6263705716274, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4975.247524752475, "train/policy_entropy_mag": 1.3235382974737941, "train/policy_entropy_max": 1.3235382974737941, "train/policy_entropy_mean": 0.09151626378297806, "train/policy_entropy_min": 0.06468650333509587, "train/policy_entropy_std": 0.11276909052440436, "train/policy_logprob_mag": 6.5510802292587735, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09182733979703177, "train/policy_logprob_min": -6.5510802292587735, "train/policy_logprob_std": 0.6319412403177507, "train/policy_randomness_mag": 0.6801641757535463, "train/policy_randomness_max": 0.6801641757535463, "train/policy_randomness_mean": 0.047030058864614754, "train/policy_randomness_min": 0.033242287354008984, "train/policy_randomness_std": 0.057951852181317785, "train/post_ent_mag": 39.32191952620403, "train/post_ent_max": 39.32191952620403, "train/post_ent_mean": 39.024360883353964, "train/post_ent_min": 38.75148886501199, "train/post_ent_std": 0.13120479708408364, "train/prior_ent_mag": 40.30637956373762, "train/prior_ent_max": 40.30637956373762, "train/prior_ent_mean": 38.390321202797466, "train/prior_ent_min": 37.07852250278586, "train/prior_ent_std": 0.501911503991278, "train/rep_loss_mean": 1.0000015178529342, "train/rep_loss_std": 4.855542445709781e-05, "train/reward_avg": 0.0016641295699421131, "train/reward_loss_mean": 0.013345157600233866, "train/reward_loss_std": 0.20951470169515377, "train/reward_max_data": 0.7061417061503571, "train/reward_max_pred": 0.21899996653641804, "train/reward_neg_acc": 0.9997624150007078, "train/reward_neg_loss": 0.002334125128477849, "train/reward_pos_acc": 0.16236467418762354, "train/reward_pos_loss": 4.00921798608242, "train/reward_pred": 0.001297355390333635, "train/reward_rate": 0.0027266398514851483, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.016159048303961754, "report/cont_loss_std": 0.2067635953426361, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.1893773078918457, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0033502979204058647, "report/cont_pred": 0.9947495460510254, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0816841796040535, "report/image_loss_std": 0.09548389911651611, "report/model_loss_mean": 0.7145462036132812, "report/model_loss_std": 0.4759972095489502, "report/post_ent_mag": 39.17689514160156, "report/post_ent_max": 39.17689514160156, "report/post_ent_mean": 38.903564453125, "report/post_ent_min": 38.61750030517578, "report/post_ent_std": 0.1260754019021988, "report/prior_ent_mag": 40.294700622558594, "report/prior_ent_max": 40.294700622558594, "report/prior_ent_mean": 38.385528564453125, "report/prior_ent_min": 37.15837097167969, "report/prior_ent_std": 0.5031938552856445, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002038574079051614, "report/reward_loss_mean": 0.016702940687537193, "report/reward_loss_std": 0.24746325612068176, "report/reward_max_data": 0.6656249761581421, "report/reward_max_pred": 0.4993699789047241, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0025212427135556936, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.633035898208618, "report/reward_pred": 0.0016758700367063284, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.046958744525909424, "eval/cont_loss_std": 0.6647329330444336, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.211638450622559, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001989763928577304, "eval/cont_pred": 0.9980640411376953, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.14983463287353516, "eval/image_loss_std": 0.15879152715206146, "eval/model_loss_mean": 0.8205739259719849, "eval/model_loss_std": 1.0640467405319214, "eval/post_ent_mag": 39.16620635986328, "eval/post_ent_max": 39.16620635986328, "eval/post_ent_mean": 38.847190856933594, "eval/post_ent_min": 38.607093811035156, "eval/post_ent_std": 0.12149281799793243, "eval/prior_ent_mag": 40.294700622558594, "eval/prior_ent_max": 40.294700622558594, "eval/prior_ent_mean": 38.326602935791016, "eval/prior_ent_min": 37.2673225402832, "eval/prior_ent_std": 0.5082798004150391, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0012634277809411287, "eval/reward_loss_mean": 0.023780563846230507, "eval/reward_loss_std": 0.5321403741836548, "eval/reward_max_data": 0.6625000238418579, "eval/reward_max_pred": 0.09041380882263184, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0010577382054179907, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 11.635144233703613, "eval/reward_pred": 0.0004991830792278051, "eval/reward_rate": 0.001953125, "replay/size": 673937.0, "replay/inserts": 32336.0, "replay/samples": 32336.0, "replay/insert_wait_avg": 1.2849799953198326e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.325826689254406e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4536.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.189149456259645e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0752606391907, "timer/env.step_count": 4042.0, "timer/env.step_total": 38.899157762527466, "timer/env.step_frac": 0.0388962304073649, "timer/env.step_avg": 0.00962374016885885, "timer/env.step_min": 0.007616758346557617, "timer/env.step_max": 0.03916668891906738, "timer/replay._sample_count": 32336.0, "timer/replay._sample_total": 16.15057921409607, "timer/replay._sample_frac": 0.01614936380265376, "timer/replay._sample_avg": 0.0004994612572394875, "timer/replay._sample_min": 0.0003867149353027344, "timer/replay._sample_max": 0.010639190673828125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4609.0, "timer/agent.policy_total": 47.995214223861694, "timer/agent.policy_frac": 0.04799160234519341, "timer/agent.policy_avg": 0.010413368241237078, "timer/agent.policy_min": 0.00854945182800293, "timer/agent.policy_max": 0.08795046806335449, "timer/dataset_train_count": 2021.0, "timer/dataset_train_total": 0.2115793228149414, "timer/dataset_train_frac": 0.00021156340041819657, "timer/dataset_train_avg": 0.00010469041208062416, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.0004222393035888672, "timer/agent.train_count": 2021.0, "timer/agent.train_total": 901.0118057727814, "timer/agent.train_frac": 0.9009440001514549, "timer/agent.train_avg": 0.4458247430840086, "timer/agent.train_min": 0.4339427947998047, "timer/agent.train_max": 2.1082348823547363, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4786694049835205, "timer/agent.report_frac": 0.00047863338272919833, "timer/agent.report_avg": 0.23933470249176025, "timer/agent.report_min": 0.23223114013671875, "timer/agent.report_max": 0.24643826484680176, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.790855407714844e-05, "timer/dataset_eval_frac": 3.7905701269841896e-08, "timer/dataset_eval_avg": 3.790855407714844e-05, "timer/dataset_eval_min": 3.790855407714844e-05, "timer/dataset_eval_max": 3.790855407714844e-05, "fps": 32.333045171210195}
{"step": 674552, "time": 21240.847732543945, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 674616, "time": 21242.777386665344, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 674792, "time": 21248.098369836807, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 674856, "time": 21250.05154299736, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 675080, "time": 21256.92729997635, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 675128, "time": 21258.387015342712, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 675152, "time": 21259.36072397232, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 675248, "time": 21262.263844251633, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 675584, "time": 21272.61019062996, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 675672, "time": 21275.077046632767, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 675920, "time": 21282.82588148117, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 675976, "time": 21284.312059879303, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 676280, "time": 21293.51695585251, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 676312, "time": 21294.496129989624, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 676328, "time": 21294.990355968475, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 676344, "time": 21295.487317323685, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 676632, "time": 21304.305191516876, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 676664, "time": 21305.280388832092, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 676736, "time": 21307.67266702652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 677128, "time": 21319.507236003876, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 677248, "time": 21323.369071006775, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 677496, "time": 21330.821578025818, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 677512, "time": 21331.316710710526, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 677808, "time": 21340.554957151413, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 677872, "time": 21342.508993148804, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 677920, "time": 21343.972977876663, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 677936, "time": 21344.46331858635, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 678040, "time": 21347.400674581528, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 678072, "time": 21348.380968809128, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 678200, "time": 21352.288829803467, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 678208, "time": 21352.75807785988, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 678456, "time": 21360.077272176743, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 678456, "time": 21360.0843167305, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 678704, "time": 21367.94933629036, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 678768, "time": 21369.88880419731, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 678904, "time": 21373.80404496193, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 678920, "time": 21374.299292564392, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 679008, "time": 21377.21404480934, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 679064, "time": 21378.687044620514, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 679208, "time": 21383.05349755287, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 679456, "time": 21390.865495443344, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 679456, "time": 21390.87263727188, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 679504, "time": 21392.343128204346, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 679512, "time": 21392.372411727905, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 679728, "time": 21399.171196460724, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 679936, "time": 21405.642546892166, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 679952, "time": 21406.485653162003, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 680008, "time": 21407.95877313614, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 21409.90770959854, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 680056, "time": 21410.52998971939, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 680056, "time": 21411.078923225403, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 680056, "time": 21412.96433186531, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 680056, "time": 21413.309391498566, "eval_episode/length": 195.0, "eval_episode/score": 0.390625, "eval_episode/reward_rate": 0.00510204081632653}
{"step": 680056, "time": 21413.57135939598, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 680056, "time": 21413.598139047623, "eval_episode/length": 209.0, "eval_episode/score": 0.34687501192092896, "eval_episode/reward_rate": 0.004761904761904762}
{"step": 680056, "time": 21413.893777370453, "eval_episode/length": 224.0, "eval_episode/score": 0.30000001192092896, "eval_episode/reward_rate": 0.0044444444444444444}
{"step": 680080, "time": 21414.85139465332, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 680256, "time": 21420.20799779892, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 680352, "time": 21423.236283302307, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 680408, "time": 21424.743710756302, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 680536, "time": 21428.70016527176, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 680744, "time": 21434.998524427414, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 681024, "time": 21443.73760533333, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 681112, "time": 21446.204089164734, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 681320, "time": 21452.60640192032, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 681584, "time": 21460.83908367157, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 681592, "time": 21460.867676496506, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 681616, "time": 21461.819135189056, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 681768, "time": 21466.19103884697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 681888, "time": 21470.050900936127, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 682056, "time": 21474.91919016838, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 682072, "time": 21475.409688949585, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 682208, "time": 21479.758898735046, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 682216, "time": 21479.787327528, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 682424, "time": 21486.186464309692, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 682672, "time": 21493.881840229034, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 682728, "time": 21495.360525369644, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 682896, "time": 21500.686285734177, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 682936, "time": 21501.678731918335, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 683200, "time": 21509.96240091324, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 683304, "time": 21512.997818231583, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 683384, "time": 21515.41655564308, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 683600, "time": 21522.158910512924, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 684056, "time": 21535.76233649254, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 684080, "time": 21536.71250319481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684352, "time": 21544.99263215065, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 684360, "time": 21545.020283937454, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 684488, "time": 21548.880356311798, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 684536, "time": 21550.334815502167, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 684664, "time": 21554.210823059082, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 684768, "time": 21557.585935115814, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 684816, "time": 21559.0426363945, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 685080, "time": 21567.019344091415, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 685104, "time": 21567.99495124817, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 685208, "time": 21571.04154777527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 685272, "time": 21573.005319595337, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 685352, "time": 21575.417292118073, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 685512, "time": 21580.28040909767, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 685664, "time": 21585.077701091766, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 685736, "time": 21587.035321712494, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 685952, "time": 21593.776265382767, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 686168, "time": 21600.091417312622, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 686240, "time": 21602.594310760498, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 686456, "time": 21608.89568567276, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 686776, "time": 21618.557589054108, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 686832, "time": 21620.49205303192, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 686840, "time": 21620.519154548645, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 686952, "time": 21623.93185067177, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 686968, "time": 21624.42108106613, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 687304, "time": 21634.73535823822, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 687328, "time": 21635.697047948837, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 687408, "time": 21638.127303123474, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 687672, "time": 21645.89401435852, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 687944, "time": 21654.110467910767, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 688048, "time": 21657.511041641235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 688184, "time": 21662.078526496887, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 688376, "time": 21667.880370140076, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 688456, "time": 21670.310611486435, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 688784, "time": 21680.422159671783, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 688792, "time": 21680.448932886124, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 688912, "time": 21684.296683311462, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 689040, "time": 21688.166860818863, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 689216, "time": 21693.615563631058, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 689600, "time": 21705.40261745453, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 689624, "time": 21705.91135406494, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 689648, "time": 21706.859740018845, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 689712, "time": 21708.818635463715, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 689720, "time": 21708.847094774246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 21718.518794059753, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 21719.846589565277, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 690040, "time": 21720.68909931183, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 690040, "time": 21720.71484732628, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 690040, "time": 21721.40825009346, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 690040, "time": 21721.50926733017, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 690040, "time": 21721.65690922737, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 690040, "time": 21722.78267645836, "eval_episode/length": 220.0, "eval_episode/score": 0.3125, "eval_episode/reward_rate": 0.004524886877828055}
{"step": 690040, "time": 21722.917774438858, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 690080, "time": 21724.339366674423, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 690128, "time": 21725.79167032242, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 690288, "time": 21730.6428732872, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 690464, "time": 21735.972482204437, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 690480, "time": 21736.46249103546, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 690672, "time": 21742.286972522736, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 690776, "time": 21745.201174497604, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 691136, "time": 21756.463484287262, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 691192, "time": 21757.96804380417, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 691192, "time": 21757.975214481354, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 691648, "time": 21772.048608779907, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 691768, "time": 21775.446094036102, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 691792, "time": 21776.416888237, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 691840, "time": 21777.85981655121, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 691872, "time": 21778.82748222351, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 692024, "time": 21783.30605173111, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 692032, "time": 21783.77266216278, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 692064, "time": 21784.74647116661, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 692176, "time": 21788.220024108887, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 692264, "time": 21790.657997131348, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 692464, "time": 21796.93209505081, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 692584, "time": 21800.325211048126, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 692816, "time": 21807.5937769413, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 692992, "time": 21813.04356098175, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 693064, "time": 21814.9968585968, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 693088, "time": 21815.972590446472, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 693392, "time": 21825.128558397293, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 693408, "time": 21825.61610341072, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 693416, "time": 21825.64397907257, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 693616, "time": 21831.88034915924, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 693984, "time": 21843.055077791214, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 694136, "time": 21847.427264213562, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 694328, "time": 21853.222190618515, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 694392, "time": 21855.17557168007, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 694672, "time": 21863.896254062653, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 694776, "time": 21866.876715660095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 694784, "time": 21867.34920167923, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 694944, "time": 21872.272176504135, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 695136, "time": 21878.061032533646, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 695184, "time": 21879.543897867203, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 695232, "time": 21881.000786304474, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 695328, "time": 21883.924772262573, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 695328, "time": 21883.931559324265, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 695816, "time": 21898.429030179977, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 695928, "time": 21901.878855228424, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 695944, "time": 21902.367537021637, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 696000, "time": 21904.29717850685, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 696304, "time": 21913.53091096878, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 696680, "time": 21925.175936460495, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 696816, "time": 21929.57287144661, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 696888, "time": 21931.667195558548, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 696904, "time": 21932.161662101746, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 696920, "time": 21932.678327560425, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 696944, "time": 21933.642512083054, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 696992, "time": 21935.09884405136, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 697168, "time": 21940.441695451736, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 697328, "time": 21945.285666942596, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 697336, "time": 21945.905094861984, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 697384, "time": 21947.368283510208, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 698112, "time": 21969.75676059723, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 698128, "time": 21970.24598145485, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 698144, "time": 21970.73227572441, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 698264, "time": 21974.153943777084, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 698368, "time": 21977.555198669434, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 698632, "time": 21985.300238609314, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 698688, "time": 21987.23292541504, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 698912, "time": 21994.07625770569, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 699112, "time": 21999.90008354187, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 699136, "time": 22000.8489382267, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 699392, "time": 22008.632524967194, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 699480, "time": 22011.13157558441, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 699648, "time": 22016.47532916069, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 699688, "time": 22017.46871614456, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 699736, "time": 22018.923788785934, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 699864, "time": 22022.888227701187, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 699896, "time": 22023.866196870804, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 700024, "time": 22028.879369974136, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 700024, "time": 22029.442719221115, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 700024, "time": 22030.144634246826, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 700024, "time": 22030.466370105743, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 700024, "time": 22030.993202209473, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 700024, "time": 22031.388415813446, "eval_episode/length": 191.0, "eval_episode/score": 0.40312498807907104, "eval_episode/reward_rate": 0.005208333333333333}
{"step": 700024, "time": 22031.529011011124, "eval_episode/length": 198.0, "eval_episode/score": 0.3812499940395355, "eval_episode/reward_rate": 0.005025125628140704}
{"step": 700024, "time": 22031.616290807724, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 700192, "time": 22036.92987346649, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 700392, "time": 22042.772726774216, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 700440, "time": 22044.2522854805, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 700552, "time": 22047.662570238113, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 700720, "time": 22053.07834506035, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 700904, "time": 22058.43609404564, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 700936, "time": 22059.425926923752, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 700952, "time": 22059.918244838715, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 701304, "time": 22070.57780599594, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 701368, "time": 22072.512045621872, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 701368, "time": 22072.52014183998, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 701696, "time": 22082.761630296707, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 702056, "time": 22093.442538499832, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 702128, "time": 22095.835129499435, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 702208, "time": 22098.28017282486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 702264, "time": 22099.756307840347, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 702312, "time": 22101.201553106308, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 702360, "time": 22102.67837691307, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 702600, "time": 22109.93468761444, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 702616, "time": 22110.508544683456, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 702744, "time": 22114.406665802002, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 702880, "time": 22118.74972295761, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 703064, "time": 22124.110775470734, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 703320, "time": 22131.868187904358, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 703328, "time": 22132.335690259933, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 703368, "time": 22133.33173418045, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 703552, "time": 22139.11622095108, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 703864, "time": 22148.440591335297, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 703936, "time": 22150.836932182312, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 703976, "time": 22151.844611406326, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 704096, "time": 22155.68890452385, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 704128, "time": 22156.672108888626, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 704272, "time": 22161.0240111351, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 704272, "time": 22161.030201673508, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 704648, "time": 22172.788768053055, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 704720, "time": 22175.188779115677, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 704944, "time": 22182.006803750992, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 704984, "time": 22183.000827550888, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 705336, "time": 22193.655190229416, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 705744, "time": 22206.2775285244, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 705816, "time": 22208.232733011246, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 705864, "time": 22209.6993932724, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 705944, "time": 22212.130565166473, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 706040, "time": 22215.064646482468, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 706096, "time": 22216.981910943985, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 706288, "time": 22222.772364854813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 706320, "time": 22223.740429878235, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 706336, "time": 22224.2315158844, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 706656, "time": 22234.02788424492, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 706761, "time": 22237.97219991684, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.777699687693379, "train/action_min": 0.0, "train/action_std": 1.723659082804576, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010219093959658674, "train/actor_opt_grad_steps": 43065.0, "train/actor_opt_loss": -14.98879064191686, "train/adv_mag": 0.9665284882677664, "train/adv_max": 0.43499718208124144, "train/adv_mean": 0.0018628535791875866, "train/adv_min": -0.9036973036161744, "train/adv_std": 0.02938645718490133, "train/cont_avg": 0.9950978496287128, "train/cont_loss_mean": 0.015579447553073526, "train/cont_loss_std": 0.20911743891619072, "train/cont_neg_acc": 0.32694680789614666, "train/cont_neg_loss": 2.450634456826328, "train/cont_pos_acc": 0.999897960093942, "train/cont_pos_loss": 0.003466253843744018, "train/cont_pred": 0.9950633869312777, "train/cont_rate": 0.9950978496287128, "train/dyn_loss_mean": 1.0000019787561776, "train/dyn_loss_std": 6.328547104851961e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12413322333578426, "train/extr_critic_critic_opt_grad_steps": 43065.0, "train/extr_critic_critic_opt_loss": 12936.700427366955, "train/extr_critic_mag": 1.4320701986256212, "train/extr_critic_max": 1.4320701986256212, "train/extr_critic_mean": 1.346035865273806, "train/extr_critic_min": 0.973172908372218, "train/extr_critic_std": 0.03008309435468204, "train/extr_return_normed_mag": 0.9662416884214571, "train/extr_return_normed_max": 0.30014916221694193, "train/extr_return_normed_mean": 0.05511665647609694, "train/extr_return_normed_min": -0.9195289594112056, "train/extr_return_normed_std": 0.042530990021284854, "train/extr_return_rate": 0.9994737266904057, "train/extr_return_raw_mag": 1.5929311525703658, "train/extr_return_raw_max": 1.5929311525703658, "train/extr_return_raw_mean": 1.3478987163836413, "train/extr_return_raw_min": 0.3732530309422181, "train/extr_return_raw_std": 0.042530990076610944, "train/extr_reward_mag": 0.33465070299582905, "train/extr_reward_max": 0.33465070299582905, "train/extr_reward_mean": 0.0020582042268528097, "train/extr_reward_min": 1.2038957954633354e-07, "train/extr_reward_std": 0.008885282661194111, "train/image_loss_mean": 0.09204357036269538, "train/image_loss_std": 0.10400872356673278, "train/model_loss_mean": 0.7219572217747716, "train/model_loss_std": 0.43200880008758885, "train/model_opt_grad_norm": 21.30845877675727, "train/model_opt_grad_steps": 43026.4900990099, "train/model_opt_loss": 3620.913581470452, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5037.1287128712875, "train/policy_entropy_mag": 1.3464291331791642, "train/policy_entropy_max": 1.3464291331791642, "train/policy_entropy_mean": 0.093411239325115, "train/policy_entropy_min": 0.06468650130647244, "train/policy_entropy_std": 0.11703122510473327, "train/policy_logprob_mag": 6.5510802292587735, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09355410546211913, "train/policy_logprob_min": -6.5510802292587735, "train/policy_logprob_std": 0.6327468864988572, "train/policy_randomness_mag": 0.6919277390040973, "train/policy_randomness_max": 0.6919277390040973, "train/policy_randomness_mean": 0.04800388417990491, "train/policy_randomness_min": 0.03324228626592915, "train/policy_randomness_std": 0.060142156566576205, "train/post_ent_mag": 39.32749510283517, "train/post_ent_max": 39.32749510283517, "train/post_ent_mean": 39.00456481404824, "train/post_ent_min": 38.71588104550201, "train/post_ent_std": 0.13857473517851074, "train/prior_ent_mag": 40.43736459713171, "train/prior_ent_max": 40.43736459713171, "train/prior_ent_mean": 38.502297845217264, "train/prior_ent_min": 37.13324184228878, "train/prior_ent_std": 0.509063543217017, "train/rep_loss_mean": 1.0000019787561776, "train/rep_loss_std": 6.328547104851961e-05, "train/reward_avg": 0.0017007506663719708, "train/reward_loss_mean": 0.014332997419013836, "train/reward_loss_std": 0.21422160105401705, "train/reward_max_data": 0.6923112611074259, "train/reward_max_pred": 0.22930522012238455, "train/reward_neg_acc": 0.9997526551827346, "train/reward_neg_loss": 0.002594837546579097, "train/reward_pos_acc": 0.14547745221190983, "train/reward_pos_loss": 4.060247075305414, "train/reward_pred": 0.0013979477341065534, "train/reward_rate": 0.0028668394183168316, "train_stats/mean_log_entropy": 0.075493329091043, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 0.018869290128350258, "report/cont_loss_std": 0.26197806000709534, "report/cont_neg_acc": 0.5555555820465088, "report/cont_neg_loss": 1.784658670425415, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003212044248357415, "report/cont_pred": 0.9919588565826416, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08406530320644379, "report/image_loss_std": 0.09670860320329666, "report/model_loss_mean": 0.7198027968406677, "report/model_loss_std": 0.5072125792503357, "report/post_ent_mag": 39.30895233154297, "report/post_ent_max": 39.30895233154297, "report/post_ent_mean": 39.02784729003906, "report/post_ent_min": 38.74485778808594, "report/post_ent_std": 0.14685948193073273, "report/prior_ent_mag": 39.972076416015625, "report/prior_ent_max": 39.972076416015625, "report/prior_ent_mean": 38.359100341796875, "report/prior_ent_min": 37.17557144165039, "report/prior_ent_std": 0.456369012594223, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0026214600075036287, "report/reward_loss_mean": 0.016868185251951218, "report/reward_loss_std": 0.25720447301864624, "report/reward_max_data": 0.887499988079071, "report/reward_max_pred": 0.6858479976654053, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.002426403108984232, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.6995229721069336, "report/reward_pred": 0.001836175681091845, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.018552133813500404, "eval/cont_loss_std": 0.4317023456096649, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.541741371154785, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0018727019196376204, "eval/cont_pred": 0.998131275177002, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12972262501716614, "eval/image_loss_std": 0.1385761797428131, "eval/model_loss_mean": 0.7544729709625244, "eval/model_loss_std": 0.5205903053283691, "eval/post_ent_mag": 39.359161376953125, "eval/post_ent_max": 39.359161376953125, "eval/post_ent_mean": 38.99536895751953, "eval/post_ent_min": 38.67158126831055, "eval/post_ent_std": 0.14377613365650177, "eval/prior_ent_mag": 39.972076416015625, "eval/prior_ent_max": 39.972076416015625, "eval/prior_ent_mean": 38.35968017578125, "eval/prior_ent_min": 37.2905158996582, "eval/prior_ent_std": 0.40972036123275757, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007720947032794356, "eval/reward_loss_mean": 0.006198198534548283, "eval/reward_loss_std": 0.15973815321922302, "eval/reward_max_data": 0.7906249761581421, "eval/reward_max_pred": 0.01866436004638672, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0012060158187523484, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.113201141357422, "eval/reward_pred": 0.0005988819757476449, "eval/reward_rate": 0.0009765625, "replay/size": 706257.0, "replay/inserts": 32320.0, "replay/samples": 32320.0, "replay/insert_wait_avg": 1.2928380234406726e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.239972600842466e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.119949468752233e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3245458602905, "timer/env.step_count": 4040.0, "timer/env.step_total": 38.78646802902222, "timer/env.step_frac": 0.03877388412544192, "timer/env.step_avg": 0.009600610898272827, "timer/env.step_min": 0.007662296295166016, "timer/env.step_max": 0.035726070404052734, "timer/replay._sample_count": 32320.0, "timer/replay._sample_total": 16.17118525505066, "timer/replay._sample_frac": 0.01616593866657871, "timer/replay._sample_avg": 0.0005003460784359734, "timer/replay._sample_min": 0.00041031837463378906, "timer/replay._sample_max": 0.025679588317871094, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4696.0, "timer/agent.policy_total": 48.60420513153076, "timer/agent.policy_frac": 0.04858843595578332, "timer/agent.policy_avg": 0.01035012886105851, "timer/agent.policy_min": 0.008907556533813477, "timer/agent.policy_max": 0.1499795913696289, "timer/dataset_train_count": 2020.0, "timer/dataset_train_total": 0.21108245849609375, "timer/dataset_train_frac": 0.00021101397478411413, "timer/dataset_train_avg": 0.00010449626658222464, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.001077413558959961, "timer/agent.train_count": 2020.0, "timer/agent.train_total": 899.8704299926758, "timer/agent.train_frac": 0.8995784755224385, "timer/agent.train_avg": 0.44548041088746326, "timer/agent.train_min": 0.43427395820617676, "timer/agent.train_max": 0.6727886199951172, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4721510410308838, "timer/agent.report_frac": 0.00047199785608062684, "timer/agent.report_avg": 0.2360755205154419, "timer/agent.report_min": 0.23007750511169434, "timer/agent.report_max": 0.24207353591918945, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9077629626068423e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 32.30899365366097}
{"step": 706800, "time": 22239.128222465515, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 706824, "time": 22239.638424873352, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 706856, "time": 22240.629539966583, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 707032, "time": 22245.989279270172, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 707136, "time": 22249.362807750702, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 707144, "time": 22249.39085507393, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 707552, "time": 22262.100798606873, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 707568, "time": 22262.591255903244, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 707584, "time": 22263.08090186119, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 707688, "time": 22266.03649711609, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 707944, "time": 22273.799093961716, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 708136, "time": 22279.657561302185, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 708160, "time": 22280.612856388092, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 708216, "time": 22282.094032764435, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 708272, "time": 22284.03791975975, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 708352, "time": 22286.481324911118, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 708472, "time": 22289.90914583206, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 709040, "time": 22307.457383155823, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 709264, "time": 22314.284584999084, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 709296, "time": 22315.261312246323, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 709368, "time": 22317.22230052948, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 709368, "time": 22317.229470968246, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 709432, "time": 22319.18346595764, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 709704, "time": 22327.564684152603, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 709808, "time": 22330.973628520966, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 22336.88262939453, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 22337.81832385063, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 710008, "time": 22338.508420467377, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 710008, "time": 22338.783226251602, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 710008, "time": 22338.96987938881, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 710008, "time": 22339.095854759216, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 710008, "time": 22339.386858463287, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 710008, "time": 22339.451408863068, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 710008, "time": 22339.9196228981, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 710040, "time": 22340.923357725143, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 710040, "time": 22340.93039417267, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 710120, "time": 22343.35978293419, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 710272, "time": 22348.224800348282, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 710360, "time": 22350.775010585785, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 710608, "time": 22358.55048084259, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 710696, "time": 22361.028600215912, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 710744, "time": 22362.496707201004, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 710808, "time": 22364.44317650795, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 711120, "time": 22374.22146463394, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 711176, "time": 22375.735310316086, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 711216, "time": 22377.184393644333, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 711240, "time": 22377.700620412827, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 711240, "time": 22377.708750247955, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 711592, "time": 22388.597257375717, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 711616, "time": 22389.5576608181, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 711640, "time": 22390.087157726288, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 712032, "time": 22402.253338575363, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 712072, "time": 22403.255150318146, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 712080, "time": 22403.726112127304, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 712120, "time": 22404.740028381348, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 712264, "time": 22409.114179849625, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 712336, "time": 22411.631281614304, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 712344, "time": 22411.65838074684, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 712344, "time": 22411.668533325195, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 712704, "time": 22422.99256849289, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 712976, "time": 22431.67086458206, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 713104, "time": 22435.605884552002, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 713288, "time": 22441.123202323914, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 713416, "time": 22445.036908864975, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 713560, "time": 22449.434670209885, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 713608, "time": 22450.89185976982, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 713752, "time": 22455.307272195816, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 713848, "time": 22458.22512292862, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 714104, "time": 22466.042729616165, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 714376, "time": 22474.427118062973, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 714656, "time": 22483.193806886673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 714696, "time": 22484.197892427444, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 714736, "time": 22485.63282752037, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 714744, "time": 22485.66018819809, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 714920, "time": 22491.034620285034, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 714976, "time": 22492.975469589233, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 715192, "time": 22499.378873109818, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 715544, "time": 22510.19288086891, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 715608, "time": 22512.152621030807, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 715624, "time": 22512.644101381302, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 715712, "time": 22515.54854631424, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 715792, "time": 22517.98542690277, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 715904, "time": 22521.39085650444, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 715968, "time": 22523.356027126312, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 716064, "time": 22526.2988550663, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 716320, "time": 22534.177214860916, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 716560, "time": 22541.48124718666, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 716624, "time": 22543.45086169243, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 716688, "time": 22545.40250301361, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 717072, "time": 22557.147869348526, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 717168, "time": 22560.080886125565, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 717168, "time": 22560.088119268417, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 717264, "time": 22563.11760187149, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 717648, "time": 22574.778772115707, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 717672, "time": 22575.288489341736, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 717960, "time": 22584.03594660759, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 718000, "time": 22585.480489253998, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 718016, "time": 22585.972542524338, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 718024, "time": 22586.001536130905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 718048, "time": 22586.98019528389, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 718624, "time": 22604.675857543945, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 718712, "time": 22607.15998148918, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 718912, "time": 22613.501288414, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 718936, "time": 22614.021435260773, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 718976, "time": 22615.463911771774, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 719016, "time": 22616.478320121765, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 719040, "time": 22617.433715343475, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 719184, "time": 22621.900153636932, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 719528, "time": 22632.185093402863, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 719528, "time": 22632.19251728058, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 719696, "time": 22637.55073952675, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 719792, "time": 22640.476639270782, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 719984, "time": 22646.330350399017, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 720096, "time": 22651.959743499756, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 720096, "time": 22652.08208346367, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 720096, "time": 22652.23489665985, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 720096, "time": 22652.669964313507, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 720096, "time": 22652.694777965546, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 720096, "time": 22653.1374399662, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 720096, "time": 22653.55317258835, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 720096, "time": 22653.577298164368, "eval_episode/length": 155.0, "eval_episode/score": 0.515625, "eval_episode/reward_rate": 0.00641025641025641}
{"step": 720136, "time": 22654.58549284935, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 720352, "time": 22661.373924970627, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 720752, "time": 22673.595032930374, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 720768, "time": 22674.090052604675, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 720792, "time": 22674.60675430298, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 720944, "time": 22679.96818804741, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 720968, "time": 22680.60816001892, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 721008, "time": 22682.07003879547, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 721280, "time": 22690.363644838333, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 721440, "time": 22695.236942768097, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 721496, "time": 22696.715219259262, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 721504, "time": 22697.18595123291, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 721872, "time": 22708.404170513153, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 722144, "time": 22716.766664266586, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 722184, "time": 22717.767951488495, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 722504, "time": 22727.51164340973, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 722520, "time": 22728.022039413452, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 722696, "time": 22733.35976076126, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 723016, "time": 22743.165158510208, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 723056, "time": 22744.606681585312, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 723208, "time": 22749.028608322144, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 723248, "time": 22750.460694551468, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 723472, "time": 22757.291551828384, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 723512, "time": 22758.280428409576, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 723568, "time": 22760.203274726868, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 723720, "time": 22764.617817878723, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 723736, "time": 22765.116103887558, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 724184, "time": 22778.92280459404, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 724288, "time": 22782.30254817009, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 724472, "time": 22787.66335749626, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 724480, "time": 22788.137233495712, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 724528, "time": 22789.59354519844, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 724576, "time": 22791.04150390625, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 724656, "time": 22793.49958729744, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 724960, "time": 22802.846564292908, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 724976, "time": 22803.337357521057, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 725104, "time": 22807.249680757523, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 725152, "time": 22808.721424102783, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 725264, "time": 22812.14274072647, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 725360, "time": 22815.076946496964, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 725520, "time": 22819.920989751816, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 725608, "time": 22822.40268754959, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 725776, "time": 22827.74350142479, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 725824, "time": 22829.190099954605, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 726168, "time": 22839.504506349564, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 726240, "time": 22841.94276690483, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 726408, "time": 22846.864372253418, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 726448, "time": 22848.299165725708, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 726600, "time": 22852.682490348816, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 726664, "time": 22854.63795042038, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 726760, "time": 22857.595985651016, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 726880, "time": 22861.60476756096, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 727448, "time": 22878.714400053024, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 727504, "time": 22880.662643909454, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 727728, "time": 22887.504182100296, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 727728, "time": 22887.511666297913, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 727808, "time": 22889.98250722885, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 728096, "time": 22898.935220479965, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 728136, "time": 22899.965742111206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 728392, "time": 22907.788767576218, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 728400, "time": 22908.263184785843, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 728584, "time": 22913.672101020813, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 728584, "time": 22913.67896604538, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 728592, "time": 22914.16911959648, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 728608, "time": 22914.661979675293, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 729104, "time": 22930.373653888702, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 729136, "time": 22931.36929011345, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 729256, "time": 22934.821649312973, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 729464, "time": 22941.157603502274, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 729656, "time": 22947.043177604675, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 730016, "time": 22958.287039756775, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 730048, "time": 22959.288096666336, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 22961.832561016083, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 730080, "time": 22962.187945604324, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 730080, "time": 22962.72082591057, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 730080, "time": 22962.897754907608, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 730080, "time": 22963.204133749008, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 730080, "time": 22964.015337705612, "eval_episode/length": 205.0, "eval_episode/score": 0.359375, "eval_episode/reward_rate": 0.0048543689320388345}
{"step": 730080, "time": 22964.679127931595, "eval_episode/length": 228.0, "eval_episode/score": 0.2874999940395355, "eval_episode/reward_rate": 0.004366812227074236}
{"step": 730080, "time": 22964.927921295166, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 730240, "time": 22969.80272102356, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 730464, "time": 22976.590281248093, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 730688, "time": 22983.52898812294, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 730696, "time": 22983.556351661682, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 730784, "time": 22986.42758512497, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 730848, "time": 22988.37638115883, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 730944, "time": 22991.291233062744, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 731152, "time": 22997.639452695847, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 731480, "time": 23007.362854480743, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 731544, "time": 23009.306676626205, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 731792, "time": 23017.238533735275, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 731824, "time": 23018.21879220009, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 731864, "time": 23019.228095769882, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 732032, "time": 23024.565189361572, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 732456, "time": 23037.236495018005, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 732472, "time": 23037.723647117615, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 732520, "time": 23039.169963359833, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 732752, "time": 23046.482973098755, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 732848, "time": 23049.38610601425, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 732960, "time": 23052.7868475914, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 733104, "time": 23057.179079294205, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 733256, "time": 23061.593307971954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 733280, "time": 23062.557099342346, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 733376, "time": 23065.47179031372, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 733496, "time": 23068.919352293015, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 733656, "time": 23073.865877628326, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 733904, "time": 23081.582958698273, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 733952, "time": 23083.03149986267, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 734064, "time": 23086.488773345947, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 734368, "time": 23095.771038770676, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 734680, "time": 23105.102308750153, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 734736, "time": 23107.061418056488, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 734752, "time": 23107.564589738846, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 734792, "time": 23108.588747739792, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 734816, "time": 23109.56595802307, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 734984, "time": 23114.530308008194, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 735112, "time": 23118.497554063797, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 735160, "time": 23119.997864484787, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 735416, "time": 23127.78971529007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 735456, "time": 23129.24391722679, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 735512, "time": 23130.84676527977, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 735544, "time": 23131.829399108887, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 735920, "time": 23143.48557806015, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 736080, "time": 23148.417939424515, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 736384, "time": 23157.72959113121, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 736472, "time": 23160.25630402565, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 736632, "time": 23165.229207277298, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 736768, "time": 23169.660863637924, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 736784, "time": 23170.162518024445, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 737016, "time": 23176.97725534439, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 737384, "time": 23188.644045114517, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 737440, "time": 23190.651942014694, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 737488, "time": 23192.142200231552, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 737648, "time": 23197.05441570282, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 737672, "time": 23197.563814163208, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 737744, "time": 23199.984187602997, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 737824, "time": 23202.417719125748, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 737840, "time": 23202.907171726227, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 738016, "time": 23208.236270427704, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 738216, "time": 23214.081731557846, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 738360, "time": 23218.433566093445, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 738464, "time": 23221.827478647232, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 738672, "time": 23228.129244565964, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 738776, "time": 23231.078978300095, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 738888, "time": 23234.454547166824, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 738985, "time": 23238.379856586456, "train_stats/mean_log_entropy": 0.0782389963769223, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7337329222424196, "train/action_min": 0.0, "train/action_std": 1.6943156949364313, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010225180394735446, "train/actor_opt_grad_steps": 45085.0, "train/actor_opt_loss": -17.387579719618994, "train/adv_mag": 0.9990363348238539, "train/adv_max": 0.3268273142304751, "train/adv_mean": 0.0015475770625908078, "train/adv_min": -0.9474837862619079, "train/adv_std": 0.028539516409803733, "train/cont_avg": 0.9947110922029703, "train/cont_loss_mean": 0.015944068917156298, "train/cont_loss_std": 0.2073431811687343, "train/cont_neg_acc": 0.35159980918806377, "train/cont_neg_loss": 2.259240017906477, "train/cont_pos_acc": 0.9998882241768412, "train/cont_pos_loss": 0.0035518277361574076, "train/cont_pred": 0.9948633516779041, "train/cont_rate": 0.9947110922029703, "train/dyn_loss_mean": 1.000000843907347, "train/dyn_loss_std": 2.697351809918401e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11432103721406495, "train/extr_critic_critic_opt_grad_steps": 45085.0, "train/extr_critic_critic_opt_loss": 12851.20709893255, "train/extr_critic_mag": 1.498288610193989, "train/extr_critic_max": 1.498288610193989, "train/extr_critic_mean": 1.4087108308726017, "train/extr_critic_min": 1.1174766580657203, "train/extr_critic_std": 0.034518040965615525, "train/extr_return_normed_mag": 1.0101171737850303, "train/extr_return_normed_max": 0.3013638966154344, "train/extr_return_normed_mean": 0.063066996929079, "train/extr_return_normed_min": -0.9473766112091517, "train/extr_return_normed_std": 0.04555292064231811, "train/extr_return_rate": 0.9995907211657797, "train/extr_return_raw_mag": 1.6485551825844416, "train/extr_return_raw_max": 1.6485551825844416, "train/extr_return_raw_mean": 1.4102583444944703, "train/extr_return_raw_min": 0.3998146747598554, "train/extr_return_raw_std": 0.04555292073452827, "train/extr_reward_mag": 0.3012927741107374, "train/extr_reward_max": 0.3012927741107374, "train/extr_reward_mean": 0.001929565546930408, "train/extr_reward_min": 9.914435962639232e-08, "train/extr_reward_std": 0.00825251530427117, "train/image_loss_mean": 0.09297580401053523, "train/image_loss_std": 0.10498150703635546, "train/model_loss_mean": 0.7244047944498534, "train/model_loss_std": 0.44089681662545344, "train/model_opt_grad_norm": 20.98631146402642, "train/model_opt_grad_steps": 45044.9801980198, "train/model_opt_loss": 2876.757039589457, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3972.772277227723, "train/policy_entropy_mag": 1.3568063484560144, "train/policy_entropy_max": 1.3568063484560144, "train/policy_entropy_mean": 0.09821235639329004, "train/policy_entropy_min": 0.06468649260183372, "train/policy_entropy_std": 0.12526662216180623, "train/policy_logprob_mag": 6.5510802292587735, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09881327710676902, "train/policy_logprob_min": -6.5510802292587735, "train/policy_logprob_std": 0.6395727106840303, "train/policy_randomness_mag": 0.697260575719399, "train/policy_randomness_max": 0.697260575719399, "train/policy_randomness_mean": 0.05047116944990536, "train/policy_randomness_min": 0.03324228178451557, "train/policy_randomness_std": 0.06437431331170668, "train/post_ent_mag": 39.39393394772369, "train/post_ent_max": 39.39393394772369, "train/post_ent_mean": 39.051367391454114, "train/post_ent_min": 38.729550729883776, "train/post_ent_std": 0.15407150032201616, "train/prior_ent_mag": 40.11892365937186, "train/prior_ent_max": 40.11892365937186, "train/prior_ent_mean": 38.596194635523425, "train/prior_ent_min": 37.428107006715074, "train/prior_ent_std": 0.41848456269443624, "train/rep_loss_mean": 1.000000843907347, "train/rep_loss_std": 2.697351809918401e-05, "train/reward_avg": 0.0018938876580277522, "train/reward_loss_mean": 0.015484395096917628, "train/reward_loss_std": 0.2237226658300174, "train/reward_max_data": 0.7117728952429082, "train/reward_max_pred": 0.2792641620824833, "train/reward_neg_acc": 0.9997333733752223, "train/reward_neg_loss": 0.0027189213848248643, "train/reward_pos_acc": 0.19225882283300932, "train/reward_pos_loss": 3.899563026860588, "train/reward_pred": 0.0015108442622107814, "train/reward_rate": 0.0032149211014851483, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.0069426908157765865, "report/cont_loss_std": 0.16946108639240265, "report/cont_neg_acc": 0.75, "report/cont_neg_loss": 1.3826756477355957, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0015476599801331758, "report/cont_pred": 0.9956461191177368, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07432714849710464, "report/image_loss_std": 0.09834426641464233, "report/model_loss_mean": 0.6834389567375183, "report/model_loss_std": 0.19825394451618195, "report/post_ent_mag": 39.45844268798828, "report/post_ent_max": 39.45844268798828, "report/post_ent_mean": 39.03575134277344, "report/post_ent_min": 38.7454833984375, "report/post_ent_std": 0.15680044889450073, "report/prior_ent_mag": 40.38800048828125, "report/prior_ent_max": 40.38800048828125, "report/prior_ent_mean": 39.07399368286133, "report/prior_ent_min": 38.154945373535156, "report/prior_ent_std": 0.3386344313621521, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004150390741415322, "report/reward_loss_mean": 0.0021690938156098127, "report/reward_loss_std": 0.029158353805541992, "report/reward_max_data": 0.42500001192092896, "report/reward_max_pred": 0.3571842908859253, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0012825167505070567, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.909137487411499, "report/reward_pred": 0.0009759078966453671, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.027800824493169785, "eval/cont_loss_std": 0.42424318194389343, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.458805084228516, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0025812003295868635, "eval/cont_pred": 0.9975185990333557, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09879077970981598, "eval/image_loss_std": 0.11249560117721558, "eval/model_loss_mean": 0.740929126739502, "eval/model_loss_std": 0.6416829228401184, "eval/post_ent_mag": 39.47402572631836, "eval/post_ent_max": 39.47402572631836, "eval/post_ent_mean": 39.052459716796875, "eval/post_ent_min": 38.721702575683594, "eval/post_ent_std": 0.17032231390476227, "eval/prior_ent_mag": 40.38800048828125, "eval/prior_ent_max": 40.38800048828125, "eval/prior_ent_mean": 39.047645568847656, "eval/prior_ent_min": 38.12895965576172, "eval/prior_ent_std": 0.35525035858154297, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0013946532271802425, "eval/reward_loss_mean": 0.014337470754981041, "eval/reward_loss_std": 0.2748354375362396, "eval/reward_max_data": 0.887499988079071, "eval/reward_max_pred": 0.18128931522369385, "eval/reward_neg_acc": 0.9960861206054688, "eval/reward_neg_loss": 0.0026610074564814568, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.9810099601745605, "eval/reward_pred": 0.0012178426841273904, "eval/reward_rate": 0.001953125, "replay/size": 738481.0, "replay/inserts": 32224.0, "replay/samples": 32224.0, "replay/insert_wait_avg": 1.3025124236393827e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.2482977036568e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1252008215354307e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3876838684082, "timer/env.step_count": 4028.0, "timer/env.step_total": 38.98483419418335, "timer/env.step_frac": 0.03896972625995608, "timer/env.step_avg": 0.009678459333213344, "timer/env.step_min": 0.0077228546142578125, "timer/env.step_max": 0.04214167594909668, "timer/replay._sample_count": 32224.0, "timer/replay._sample_total": 16.214525938034058, "timer/replay._sample_frac": 0.016208242263973063, "timer/replay._sample_avg": 0.0005031816639161512, "timer/replay._sample_min": 0.00036215782165527344, "timer/replay._sample_max": 0.025995254516601562, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4576.0, "timer/agent.policy_total": 48.1703143119812, "timer/agent.policy_frac": 0.048151646695320134, "timer/agent.policy_avg": 0.010526729526219669, "timer/agent.policy_min": 0.008870363235473633, "timer/agent.policy_max": 0.10105061531066895, "timer/dataset_train_count": 2014.0, "timer/dataset_train_total": 0.21332049369812012, "timer/dataset_train_frac": 0.0002132378248332978, "timer/dataset_train_avg": 0.00010591881514305865, "timer/dataset_train_min": 9.1552734375e-05, "timer/dataset_train_max": 0.0005660057067871094, "timer/agent.train_count": 2014.0, "timer/agent.train_total": 901.6181616783142, "timer/agent.train_frac": 0.9012687543211635, "timer/agent.train_avg": 0.44767535336559794, "timer/agent.train_min": 0.43550872802734375, "timer/agent.train_max": 0.6986649036407471, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47942638397216797, "timer/agent.report_frac": 0.0004792405901262896, "timer/agent.report_avg": 0.23971319198608398, "timer/agent.report_min": 0.23171448707580566, "timer/agent.report_max": 0.2477118968963623, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.16973824566586e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 32.210942335534114}
{"step": 739304, "time": 23247.804557800293, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 739400, "time": 23250.82924771309, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 739440, "time": 23252.26285147667, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 739584, "time": 23256.638890504837, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 739840, "time": 23264.407422304153, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 739856, "time": 23264.896677970886, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 740040, "time": 23270.26083636284, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 740064, "time": 23271.738595485687, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 740064, "time": 23271.78502869606, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 740064, "time": 23272.263954162598, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 740064, "time": 23273.144787311554, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 740064, "time": 23273.22389626503, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 740064, "time": 23274.35386967659, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 740064, "time": 23274.847830057144, "eval_episode/length": 195.0, "eval_episode/score": 0.390625, "eval_episode/reward_rate": 0.00510204081632653}
{"step": 740064, "time": 23274.910915613174, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 740144, "time": 23277.35918855667, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 740480, "time": 23287.62014555931, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 740760, "time": 23295.895118951797, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 740808, "time": 23297.349025011063, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 740904, "time": 23300.254209041595, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 740936, "time": 23301.242269039154, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 741024, "time": 23304.126889944077, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 741320, "time": 23312.979116916656, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 741704, "time": 23324.57725095749, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 741712, "time": 23325.066744089127, "episode/length": 265.0, "episode/score": 0.171875, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.0}
{"step": 741976, "time": 23332.848398685455, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 742352, "time": 23344.538276433945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742464, "time": 23347.916153669357, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 742616, "time": 23352.325984477997, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 742664, "time": 23353.809599637985, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 742840, "time": 23359.175791740417, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 742952, "time": 23362.56955075264, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 743184, "time": 23369.8485994339, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 743280, "time": 23372.846976041794, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 743360, "time": 23375.2759912014, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 743456, "time": 23378.17184662819, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 743504, "time": 23379.63772392273, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 743960, "time": 23393.357386112213, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 743992, "time": 23394.34855556488, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 744016, "time": 23395.312766075134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 744024, "time": 23395.341959953308, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 744176, "time": 23400.25233578682, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 744248, "time": 23402.276343107224, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 744640, "time": 23414.39412379265, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 744856, "time": 23420.72619175911, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 745080, "time": 23427.52401471138, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 745176, "time": 23430.499856710434, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 745216, "time": 23431.93195414543, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 745384, "time": 23436.80247950554, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 745448, "time": 23438.752501487732, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 745504, "time": 23441.121032714844, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 745576, "time": 23443.086660146713, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 745880, "time": 23452.306175231934, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 746072, "time": 23458.129044294357, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 746272, "time": 23464.498700857162, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 746360, "time": 23466.979691267014, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 746440, "time": 23469.403481721878, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 746480, "time": 23470.83227777481, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 746576, "time": 23473.75694847107, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 747040, "time": 23487.78320169449, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 747144, "time": 23490.80216526985, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 747152, "time": 23491.287860631943, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 747216, "time": 23493.21972966194, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 747248, "time": 23494.19389772415, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 747336, "time": 23496.657572746277, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 747480, "time": 23501.0126888752, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 747512, "time": 23501.98134994507, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 747656, "time": 23506.354091882706, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 747752, "time": 23509.25852751732, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 747752, "time": 23509.265245437622, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 747808, "time": 23511.211990594864, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 748088, "time": 23519.547554254532, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 748184, "time": 23522.576520442963, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 748264, "time": 23524.992433071136, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 748472, "time": 23531.28010225296, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 748536, "time": 23533.21266055107, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 748592, "time": 23535.17341518402, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 748760, "time": 23540.06711125374, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 748912, "time": 23544.890912294388, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 748984, "time": 23546.84317445755, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 749072, "time": 23549.744119405746, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 749192, "time": 23553.221311330795, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 749288, "time": 23556.148752212524, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 749480, "time": 23561.969608783722, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 749584, "time": 23565.359258890152, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 749720, "time": 23569.280252695084, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 749744, "time": 23570.234893798828, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 749960, "time": 23576.578840494156, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 750040, "time": 23579.022025346756, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 23580.55006957054, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 750048, "time": 23580.86242580414, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 750048, "time": 23582.050451755524, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 750048, "time": 23582.325454235077, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 750048, "time": 23582.841143131256, "eval_episode/length": 177.0, "eval_episode/score": 0.4468750059604645, "eval_episode/reward_rate": 0.0056179775280898875}
{"step": 750048, "time": 23582.973001480103, "eval_episode/length": 184.0, "eval_episode/score": 0.42500001192092896, "eval_episode/reward_rate": 0.005405405405405406}
{"step": 750048, "time": 23583.04903101921, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 750048, "time": 23583.745366334915, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 750152, "time": 23586.662150621414, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 750296, "time": 23591.092950582504, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 750336, "time": 23592.52645754814, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 750624, "time": 23601.266456127167, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 750784, "time": 23606.12792110443, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 750880, "time": 23609.070247888565, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 751120, "time": 23616.454435110092, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 751256, "time": 23620.359808921814, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 751408, "time": 23625.187008857727, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 751464, "time": 23626.687494516373, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 751584, "time": 23630.628120422363, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 751664, "time": 23633.080139160156, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 751784, "time": 23636.48362803459, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 752016, "time": 23643.812915086746, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 752488, "time": 23657.877233028412, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 752544, "time": 23659.79713821411, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 752672, "time": 23663.673924922943, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 752704, "time": 23664.645402908325, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 752752, "time": 23666.126801729202, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 753032, "time": 23674.521164417267, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 753040, "time": 23674.988904476166, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 753248, "time": 23681.291207551956, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 753248, "time": 23681.30178785324, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 753320, "time": 23683.26592850685, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 753552, "time": 23690.54376578331, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 753784, "time": 23697.852746725082, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 753824, "time": 23699.29004597664, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 753896, "time": 23701.343992471695, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 753976, "time": 23703.7621884346, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 753976, "time": 23703.76829624176, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 754224, "time": 23711.524468421936, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 754328, "time": 23714.434972524643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 754384, "time": 23716.36046385765, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 754712, "time": 23726.065457582474, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 754760, "time": 23727.533990621567, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 754952, "time": 23733.445254802704, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 755040, "time": 23736.335361003876, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 755088, "time": 23737.789944171906, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 755368, "time": 23746.02495789528, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 755400, "time": 23746.998520374298, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 755456, "time": 23748.9097468853, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 755576, "time": 23752.34291100502, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 755648, "time": 23754.7613863945, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 756056, "time": 23766.97372984886, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 756136, "time": 23769.444680690765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 756144, "time": 23769.91609120369, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 756480, "time": 23780.18968439102, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 756648, "time": 23785.081376075745, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 757072, "time": 23798.358461856842, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 757120, "time": 23799.80765271187, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 757264, "time": 23804.173637151718, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 757288, "time": 23804.6869161129, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 757440, "time": 23809.598546266556, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 757576, "time": 23813.599262714386, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 757712, "time": 23818.022738218307, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 757920, "time": 23824.487062215805, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 757960, "time": 23825.48983645439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 758120, "time": 23830.36920928955, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 758160, "time": 23831.802350759506, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 758168, "time": 23831.83157157898, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 758496, "time": 23842.015072107315, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 758760, "time": 23849.840458631516, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 759048, "time": 23858.65751004219, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 759152, "time": 23862.05028438568, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 759216, "time": 23863.993813991547, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 759288, "time": 23865.958402872086, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 759320, "time": 23866.959805250168, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 759344, "time": 23867.922662973404, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 759352, "time": 23867.95052266121, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 759752, "time": 23880.08524298668, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 759840, "time": 23883.095237731934, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 760032, "time": 23890.092298030853, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 760032, "time": 23890.49262857437, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 760032, "time": 23890.8388838768, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 760032, "time": 23890.916360616684, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 760032, "time": 23891.79599571228, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 760032, "time": 23892.381079673767, "eval_episode/length": 186.0, "eval_episode/score": 0.41874998807907104, "eval_episode/reward_rate": 0.0053475935828877}
{"step": 760032, "time": 23892.702264785767, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 760032, "time": 23892.819422006607, "eval_episode/length": 209.0, "eval_episode/score": 0.34687501192092896, "eval_episode/reward_rate": 0.004761904761904762}
{"step": 760136, "time": 23895.769238471985, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 760376, "time": 23903.05438184738, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 760416, "time": 23904.485776662827, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 760664, "time": 23911.903492689133, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 760720, "time": 23913.812135457993, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 760792, "time": 23915.780022621155, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 760800, "time": 23916.251754045486, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 760840, "time": 23917.247111558914, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 761024, "time": 23923.025334358215, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 761048, "time": 23923.531522274017, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 761096, "time": 23925.012494325638, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 761328, "time": 23932.268966913223, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 761432, "time": 23935.228761911392, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 761664, "time": 23942.59451699257, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 761744, "time": 23945.036859035492, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 761808, "time": 23946.9813477993, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 761912, "time": 23950.42043709755, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 761936, "time": 23951.37407374382, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 762064, "time": 23955.25869822502, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 762160, "time": 23958.154932260513, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 762288, "time": 23962.030218839645, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 762464, "time": 23967.368716955185, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 762472, "time": 23967.39647436142, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 762672, "time": 23973.780490875244, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 762688, "time": 23974.272004127502, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 762856, "time": 23979.171622514725, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 763032, "time": 23984.53207373619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 763192, "time": 23989.403882026672, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 763312, "time": 23993.28669643402, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 763432, "time": 23996.70124578476, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 763784, "time": 24007.436426877975, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 764072, "time": 24016.175324201584, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 764256, "time": 24021.996477127075, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 764352, "time": 24024.925391197205, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 764424, "time": 24026.89274096489, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 764472, "time": 24028.36942267418, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 764480, "time": 24028.843825817108, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 764512, "time": 24029.82294154167, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 764520, "time": 24029.851304769516, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 764608, "time": 24032.822737693787, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 764720, "time": 24036.206346273422, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 765096, "time": 24047.39457345009, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 765248, "time": 24052.227774620056, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 765368, "time": 24055.6372756958, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 765400, "time": 24056.638345956802, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 765624, "time": 24063.59665799141, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 765712, "time": 24066.523650169373, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 765864, "time": 24070.91917037964, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 765928, "time": 24072.880352020264, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 766216, "time": 24081.619248390198, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 766416, "time": 24087.913479804993, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 766440, "time": 24088.425563812256, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 766480, "time": 24089.850189208984, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 766568, "time": 24092.378197669983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 766808, "time": 24099.63843512535, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 766816, "time": 24100.106222867966, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 766992, "time": 24105.430113315582, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 767024, "time": 24106.409188508987, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 767240, "time": 24112.717688322067, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 767272, "time": 24113.684433937073, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 767280, "time": 24114.337210655212, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 767416, "time": 24118.281061172485, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 767704, "time": 24127.12586402893, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 767736, "time": 24128.099951982498, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 768048, "time": 24137.75549864769, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 768056, "time": 24137.783540964127, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 768184, "time": 24141.657341480255, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 768344, "time": 24146.481458425522, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 768352, "time": 24146.94978785515, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 768416, "time": 24148.87854361534, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 768416, "time": 24148.886016130447, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 768472, "time": 24150.412100076675, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 768800, "time": 24160.550470352173, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 768816, "time": 24161.042069911957, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 769056, "time": 24168.33201122284, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 769200, "time": 24172.698048114777, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 769208, "time": 24172.726016759872, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 769272, "time": 24174.676555633545, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 769688, "time": 24187.410718917847, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 769704, "time": 24187.909047842026, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 769824, "time": 24191.776068925858, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 769952, "time": 24195.67342352867, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 770000, "time": 24197.14843583107, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 770016, "time": 24199.161539316177, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 770016, "time": 24199.74645280838, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 770016, "time": 24200.125007152557, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 770016, "time": 24200.8145775795, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 770016, "time": 24201.22071003914, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 770016, "time": 24201.283341646194, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 770016, "time": 24201.46061348915, "eval_episode/length": 169.0, "eval_episode/score": 0.47187501192092896, "eval_episode/reward_rate": 0.0058823529411764705}
{"step": 770016, "time": 24201.5429186821, "eval_episode/length": 173.0, "eval_episode/score": 0.4593749940395355, "eval_episode/reward_rate": 0.005747126436781609}
{"step": 770360, "time": 24212.338136434555, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 770392, "time": 24213.306510686874, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 770600, "time": 24219.622403860092, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 770632, "time": 24220.584919452667, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 770672, "time": 24222.034574747086, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 770800, "time": 24225.879823684692, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 770872, "time": 24227.843064069748, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 771193, "time": 24238.45995426178, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.71461084470227, "train/action_min": 0.0, "train/action_std": 1.6904094764842323, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010161336400170825, "train/actor_opt_grad_steps": 47100.0, "train/actor_opt_loss": -18.142024799365903, "train/adv_mag": 0.8977226742464511, "train/adv_max": 0.308104115932142, "train/adv_mean": 0.0006244802139641722, "train/adv_min": -0.8411191482449052, "train/adv_std": 0.025357694740393268, "train/cont_avg": 0.9947625155472637, "train/cont_loss_mean": 0.01674855638188843, "train/cont_loss_std": 0.21457341596928994, "train/cont_neg_acc": 0.29132853581834195, "train/cont_neg_loss": 2.4663843812921376, "train/cont_pos_acc": 0.9998974948380124, "train/cont_pos_loss": 0.0037993626977173398, "train/cont_pred": 0.9947654379541008, "train/cont_rate": 0.9947625155472637, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09131246329799517, "train/extr_critic_critic_opt_grad_steps": 47100.0, "train/extr_critic_critic_opt_loss": 11651.72070798352, "train/extr_critic_mag": 1.5350443273041379, "train/extr_critic_max": 1.5350443273041379, "train/extr_critic_mean": 1.452592763734694, "train/extr_critic_min": 1.1271523100819754, "train/extr_critic_std": 0.032346484404224066, "train/extr_return_normed_mag": 0.9066545856532766, "train/extr_return_normed_max": 0.2723666014362924, "train/extr_return_normed_mean": 0.05913589292423642, "train/extr_return_normed_min": -0.8308516562874637, "train/extr_return_normed_std": 0.04173585691892389, "train/extr_return_rate": 0.999681637061769, "train/extr_return_raw_mag": 1.6664480475050893, "train/extr_return_raw_max": 1.6664480475050893, "train/extr_return_raw_mean": 1.4532174079572384, "train/extr_return_raw_min": 0.5632297897813332, "train/extr_return_raw_std": 0.041735856900390104, "train/extr_reward_mag": 0.2638509178636086, "train/extr_reward_max": 0.2638509178636086, "train/extr_reward_mean": 0.0020632334962830097, "train/extr_reward_min": 9.726529097675683e-08, "train/extr_reward_std": 0.008084321355178434, "train/image_loss_mean": 0.09317425705158888, "train/image_loss_std": 0.10510631917572733, "train/model_loss_mean": 0.7259997425980829, "train/model_loss_std": 0.4527209789598759, "train/model_opt_grad_norm": 20.696718552812413, "train/model_opt_grad_steps": 47057.92039800995, "train/model_opt_loss": 2475.1361229739973, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3420.3980099502487, "train/policy_entropy_mag": 1.3165059143037938, "train/policy_entropy_max": 1.3165059143037938, "train/policy_entropy_mean": 0.09707512565661426, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12362300048568356, "train/policy_logprob_mag": 6.551080231642842, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09688297970526254, "train/policy_logprob_min": -6.551080231642842, "train/policy_logprob_std": 0.6341854488078634, "train/policy_randomness_mag": 0.6765502477759746, "train/policy_randomness_max": 0.6765502477759746, "train/policy_randomness_mean": 0.04988674813909317, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06352965906262398, "train/post_ent_mag": 39.66708694761665, "train/post_ent_max": 39.66708694761665, "train/post_ent_mean": 39.27684328449306, "train/post_ent_min": 38.88560212548099, "train/post_ent_std": 0.1824884327193398, "train/prior_ent_mag": 40.22578483315843, "train/prior_ent_max": 40.22578483315843, "train/prior_ent_mean": 38.86111076317023, "train/prior_ent_min": 37.713315308983645, "train/prior_ent_std": 0.3811917777974807, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0019301836714362818, "train/reward_loss_mean": 0.0160769080773311, "train/reward_loss_std": 0.2299220625714246, "train/reward_max_data": 0.7225279848818755, "train/reward_max_pred": 0.22718484959199062, "train/reward_neg_acc": 0.999693046458325, "train/reward_neg_loss": 0.003024352902363504, "train/reward_pos_acc": 0.12724397906343343, "train/reward_pos_loss": 4.019628067912184, "train/reward_pred": 0.0015920733654204366, "train/reward_rate": 0.0032454912935323383, "train_stats/mean_log_entropy": 0.07659409119755275, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.010249113664031029, "report/cont_loss_std": 0.1432989239692688, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.5853404998779297, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004072285257279873, "report/cont_pred": 0.9939941167831421, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09219084680080414, "report/image_loss_std": 0.10356999188661575, "report/model_loss_mean": 0.7139973640441895, "report/model_loss_std": 0.3491547405719757, "report/post_ent_mag": 39.427162170410156, "report/post_ent_max": 39.427162170410156, "report/post_ent_mean": 39.05739974975586, "report/post_ent_min": 38.5523681640625, "report/post_ent_std": 0.1899169236421585, "report/prior_ent_mag": 40.22265625, "report/prior_ent_max": 40.22265625, "report/prior_ent_mean": 38.89680480957031, "report/prior_ent_min": 37.68821716308594, "report/prior_ent_std": 0.3751375675201416, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0011871338356286287, "report/reward_loss_mean": 0.011557377874851227, "report/reward_loss_std": 0.17870494723320007, "report/reward_max_data": 0.659375011920929, "report/reward_max_pred": 0.03850400447845459, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0037659823428839445, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.9929609298706055, "report/reward_pred": 0.001717942301183939, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0447968915104866, "eval/cont_loss_std": 0.600929319858551, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.247576713562012, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.004547725897282362, "eval/cont_pred": 0.9971482753753662, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17510810494422913, "eval/image_loss_std": 0.1611470878124237, "eval/model_loss_mean": 0.8316295742988586, "eval/model_loss_std": 0.7733830213546753, "eval/post_ent_mag": 39.39030075073242, "eval/post_ent_max": 39.39030075073242, "eval/post_ent_mean": 38.947723388671875, "eval/post_ent_min": 38.59021759033203, "eval/post_ent_std": 0.1724216490983963, "eval/prior_ent_mag": 40.22265625, "eval/prior_ent_max": 40.22265625, "eval/prior_ent_mean": 38.85710144042969, "eval/prior_ent_min": 37.72203826904297, "eval/prior_ent_std": 0.37700527906417847, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.00030517578125, "eval/reward_loss_mean": 0.011724593117833138, "eval/reward_loss_std": 0.2679041028022766, "eval/reward_max_data": 0.3125, "eval/reward_max_pred": 0.7575031518936157, "eval/reward_neg_acc": 0.9990224838256836, "eval/reward_neg_loss": 0.0039422535337507725, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.973058700561523, "eval/reward_pred": 0.0011180969886481762, "eval/reward_rate": 0.0009765625, "replay/size": 770689.0, "replay/inserts": 32208.0, "replay/samples": 32208.0, "replay/insert_wait_avg": 1.285430571361377e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.287948450163355e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6496.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0976944063684624e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0664625167847, "timer/env.step_count": 4026.0, "timer/env.step_total": 38.581098318099976, "timer/env.step_frac": 0.03857853429161709, "timer/env.step_avg": 0.009582985175881763, "timer/env.step_min": 0.00757908821105957, "timer/env.step_max": 0.03812241554260254, "timer/replay._sample_count": 32208.0, "timer/replay._sample_total": 16.110287189483643, "timer/replay._sample_frac": 0.0161092165304096, "timer/replay._sample_avg": 0.0005001952058334465, "timer/replay._sample_min": 0.0004000663757324219, "timer/replay._sample_max": 0.011437177658081055, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4838.0, "timer/agent.policy_total": 49.95611047744751, "timer/agent.policy_frac": 0.049952790489271176, "timer/agent.policy_avg": 0.010325777279340122, "timer/agent.policy_min": 0.008769035339355469, "timer/agent.policy_max": 0.08770346641540527, "timer/dataset_train_count": 2013.0, "timer/dataset_train_total": 0.21132111549377441, "timer/dataset_train_frac": 0.00021130707149398853, "timer/dataset_train_avg": 0.00010497819945045922, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.0010683536529541016, "timer/agent.train_count": 2013.0, "timer/agent.train_total": 897.9656271934509, "timer/agent.train_frac": 0.8979059501041711, "timer/agent.train_avg": 0.44608327232660255, "timer/agent.train_min": 0.43139052391052246, "timer/agent.train_max": 0.714261531829834, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47539377212524414, "timer/agent.report_frac": 0.0004753621783584862, "timer/agent.report_avg": 0.23769688606262207, "timer/agent.report_min": 0.23186635971069336, "timer/agent.report_max": 0.24352741241455078, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9561939047723604e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 32.20533536673951}
{"step": 771224, "time": 24239.14407300949, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 771232, "time": 24239.702831745148, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 771272, "time": 24240.8495323658, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 771336, "time": 24242.8191986084, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 771400, "time": 24244.75569653511, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 771720, "time": 24254.420744419098, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 771752, "time": 24255.38303256035, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 771864, "time": 24258.777950525284, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 771920, "time": 24260.68402314186, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 772056, "time": 24264.571526288986, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 772296, "time": 24271.92037820816, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 772392, "time": 24274.810876369476, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 772800, "time": 24287.46081352234, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 772840, "time": 24288.452970027924, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 773016, "time": 24293.817303180695, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 773064, "time": 24295.27639889717, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 773128, "time": 24297.26026725769, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 773536, "time": 24310.03917980194, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 773600, "time": 24312.00130724907, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 773728, "time": 24315.904542684555, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 773768, "time": 24316.90908718109, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 773920, "time": 24321.73250889778, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 774096, "time": 24327.049862861633, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 774336, "time": 24334.417342185974, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 774560, "time": 24341.18950152397, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 774624, "time": 24343.13094830513, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 774632, "time": 24343.161503314972, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 774672, "time": 24344.62570786476, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 774840, "time": 24349.582659244537, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 774864, "time": 24350.544107437134, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 774880, "time": 24351.04086613655, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 774968, "time": 24353.463242292404, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 775216, "time": 24361.254484653473, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 775224, "time": 24361.28165626526, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 775416, "time": 24367.045670986176, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 775520, "time": 24370.404048919678, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 775656, "time": 24374.29673266411, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 775784, "time": 24378.147686481476, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 775840, "time": 24380.073506832123, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 775912, "time": 24382.019901752472, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 776056, "time": 24386.361077308655, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 776096, "time": 24387.781242132187, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 776136, "time": 24388.786940336227, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 776424, "time": 24397.563732385635, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 776464, "time": 24399.011737823486, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 776504, "time": 24399.996584177017, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 776984, "time": 24414.434425354004, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 777008, "time": 24415.38351893425, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 777112, "time": 24418.30001974106, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 777144, "time": 24419.267402410507, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 777504, "time": 24430.543121099472, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 777736, "time": 24437.38228559494, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 777888, "time": 24442.191945314407, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 777920, "time": 24443.155554056168, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 778016, "time": 24446.04678297043, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 778160, "time": 24450.483630657196, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 778464, "time": 24460.1103785038, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 778928, "time": 24474.12179207802, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 778968, "time": 24475.11419725418, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 779032, "time": 24477.06434726715, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 779048, "time": 24477.55049109459, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 779200, "time": 24482.48330283165, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 779360, "time": 24487.315717458725, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 779384, "time": 24487.820422172546, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 779472, "time": 24490.698543787003, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 779728, "time": 24498.401735067368, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 779824, "time": 24501.311464071274, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 780000, "time": 24508.134687900543, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 780000, "time": 24508.3682448864, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 780000, "time": 24508.498863220215, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 780000, "time": 24509.440318346024, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 780000, "time": 24509.46817755699, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 780000, "time": 24509.595059871674, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 780000, "time": 24509.840945243835, "eval_episode/length": 162.0, "eval_episode/score": 0.4937500059604645, "eval_episode/reward_rate": 0.006134969325153374}
{"step": 780000, "time": 24510.508902788162, "eval_episode/length": 188.0, "eval_episode/score": 0.4124999940395355, "eval_episode/reward_rate": 0.005291005291005291}
{"step": 780048, "time": 24511.965505599976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 780272, "time": 24518.74319577217, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 780456, "time": 24524.055547237396, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 780464, "time": 24524.5241522789, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 780616, "time": 24528.89151287079, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 780880, "time": 24537.052896022797, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 780912, "time": 24538.044145584106, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 780936, "time": 24538.5640707016, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 781208, "time": 24546.89354300499, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 781576, "time": 24558.02410030365, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 781592, "time": 24558.50957274437, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 781632, "time": 24559.937124490738, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 781952, "time": 24569.59876894951, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 781952, "time": 24569.60682296753, "episode/length": 265.0, "episode/score": 0.171875, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.0}
{"step": 782040, "time": 24572.148369789124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 782104, "time": 24574.078977823257, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 782624, "time": 24590.0037047863, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 782624, "time": 24590.011318445206, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 782632, "time": 24590.038771629333, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 782664, "time": 24591.004701137543, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 782688, "time": 24591.9810192585, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 782816, "time": 24595.836116552353, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 783000, "time": 24601.322471380234, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 783104, "time": 24604.67328429222, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 783176, "time": 24606.642885923386, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 783184, "time": 24607.110459804535, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 783248, "time": 24609.0408680439, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 783672, "time": 24621.5958006382, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 784048, "time": 24633.25579404831, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 784104, "time": 24634.74284529686, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 784112, "time": 24635.231269598007, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 784112, "time": 24635.238847732544, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 784224, "time": 24638.61866736412, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 784328, "time": 24641.54173731804, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 784464, "time": 24645.879667520523, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 784792, "time": 24655.555347681046, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 784920, "time": 24659.416236639023, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 784936, "time": 24659.90016269684, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 785040, "time": 24663.31848835945, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 785072, "time": 24664.309865951538, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 785160, "time": 24666.752475500107, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 785160, "time": 24666.76060771942, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 785504, "time": 24677.367326259613, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 785824, "time": 24687.066252231598, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 785824, "time": 24687.493285894394, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 785872, "time": 24688.956162929535, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 786232, "time": 24699.67114663124, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 786392, "time": 24704.494189977646, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 786504, "time": 24708.30660367012, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 786512, "time": 24708.793919324875, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 786520, "time": 24708.821584701538, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 786624, "time": 24712.176060914993, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 786712, "time": 24714.62846803665, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 787144, "time": 24727.742078065872, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 787336, "time": 24733.550888299942, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 787376, "time": 24734.975506544113, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 787392, "time": 24735.458063602448, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 787616, "time": 24742.186086654663, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 787800, "time": 24747.538780927658, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 787824, "time": 24748.4853246212, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 787856, "time": 24749.448085308075, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 787936, "time": 24751.91909313202, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 788048, "time": 24755.290150880814, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 788128, "time": 24757.708876371384, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 788320, "time": 24763.484526634216, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 788560, "time": 24770.77274107933, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 788800, "time": 24778.02109003067, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 788816, "time": 24778.504757404327, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 788840, "time": 24779.011686086655, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 789048, "time": 24785.38492012024, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 789248, "time": 24791.663998126984, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 789368, "time": 24795.066473722458, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 789456, "time": 24797.975620508194, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 789800, "time": 24808.18151831627, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 789808, "time": 24808.64763855934, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 789848, "time": 24809.64165878296, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 789952, "time": 24813.114530563354, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 790088, "time": 24817.793605804443, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 790088, "time": 24819.022974014282, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 790088, "time": 24819.15255379677, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 790088, "time": 24819.36971116066, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 790088, "time": 24819.775084257126, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 790088, "time": 24820.184194803238, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 790088, "time": 24820.31256222725, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 790088, "time": 24820.532571792603, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 790224, "time": 24824.88193821907, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 790296, "time": 24826.83753681183, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 790408, "time": 24830.24178147316, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 790440, "time": 24831.21453857422, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 790768, "time": 24841.54782152176, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 790952, "time": 24846.878526449203, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 791184, "time": 24854.234843492508, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 791256, "time": 24856.188227415085, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 791440, "time": 24861.969611167908, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 791552, "time": 24865.355215072632, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 791576, "time": 24865.871335983276, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 791640, "time": 24867.825226545334, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 791808, "time": 24873.261224508286, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 791968, "time": 24878.100737810135, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 792168, "time": 24883.894879341125, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 792224, "time": 24885.79591178894, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 792480, "time": 24893.499866485596, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 792656, "time": 24898.803236722946, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 792696, "time": 24899.796808958054, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 792704, "time": 24900.291821956635, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 792752, "time": 24901.838214874268, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 792792, "time": 24902.823587417603, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 792848, "time": 24904.73340034485, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 793088, "time": 24911.99028491974, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 793136, "time": 24913.441913366318, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 793200, "time": 24917.280138015747, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 793504, "time": 24926.44230055809, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 793608, "time": 24929.368911266327, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 793696, "time": 24932.326783895493, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 793760, "time": 24934.27155327797, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 793984, "time": 24941.079540252686, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 794032, "time": 24942.544706344604, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 794120, "time": 24944.974436998367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 794208, "time": 24947.857419013977, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 794448, "time": 24955.065647363663, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 794496, "time": 24956.509635925293, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 794536, "time": 24957.54994869232, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 794632, "time": 24960.792642593384, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 794792, "time": 24965.88894367218, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 794904, "time": 24969.283051252365, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 794912, "time": 24969.74723815918, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 795192, "time": 24977.961799621582, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 795216, "time": 24978.907307624817, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 795632, "time": 24991.602731227875, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 795936, "time": 25000.74230670929, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 795992, "time": 25002.22911143303, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 796000, "time": 25002.696313381195, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 796112, "time": 25006.103647470474, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 796384, "time": 25014.306963920593, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 796408, "time": 25014.81553006172, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 796416, "time": 25015.281433820724, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 796416, "time": 25015.289244174957, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 796504, "time": 25017.74301123619, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 796768, "time": 25026.00749349594, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 796792, "time": 25026.516028404236, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 797128, "time": 25036.658336639404, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 797336, "time": 25042.91062092781, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 797368, "time": 25043.882659196854, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 797384, "time": 25044.369193077087, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 797408, "time": 25045.32924056053, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 797408, "time": 25045.336269378662, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 797416, "time": 25045.363943576813, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 797936, "time": 25061.34941649437, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 798000, "time": 25063.274347305298, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 798016, "time": 25063.762983083725, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 798272, "time": 25071.501953125, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 798600, "time": 25081.273127555847, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 799008, "time": 25093.788508176804, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 799096, "time": 25096.220873832703, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 799104, "time": 25096.68912601471, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 799144, "time": 25097.684549331665, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 799184, "time": 25099.133120536804, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 799208, "time": 25099.640959739685, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 799304, "time": 25102.536757469177, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 799536, "time": 25109.74766111374, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 799744, "time": 25116.102060317993, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 799856, "time": 25119.485527276993, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 800072, "time": 25126.618762254715, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 800072, "time": 25127.040642499924, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 800072, "time": 25127.125549554825, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 800072, "time": 25127.757976055145, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 800072, "time": 25128.049322366714, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 800072, "time": 25128.13083434105, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 800072, "time": 25128.890085220337, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 800072, "time": 25129.208302497864, "eval_episode/length": 180.0, "eval_episode/score": 0.4375, "eval_episode/reward_rate": 0.0055248618784530384}
{"step": 800256, "time": 25134.968430042267, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 800264, "time": 25134.99565267563, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 800432, "time": 25140.346186876297, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 800464, "time": 25141.357949733734, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 800760, "time": 25150.065608739853, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 801112, "time": 25160.652015447617, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 801168, "time": 25162.557765483856, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 801248, "time": 25165.00125670433, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 801320, "time": 25166.972034215927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801376, "time": 25168.88800597191, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 801568, "time": 25174.778232574463, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 802000, "time": 25187.783590316772, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 802008, "time": 25187.811162233353, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 802112, "time": 25191.223674058914, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 802304, "time": 25197.125251054764, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 802624, "time": 25206.94895386696, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 802656, "time": 25207.92031931877, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 802696, "time": 25208.92163825035, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 802728, "time": 25209.884422540665, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 802728, "time": 25209.89405322075, "episode/length": 286.0, "episode/score": 0.10625000298023224, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.0}
{"step": 802984, "time": 25218.156051158905, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 803016, "time": 25219.140938043594, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 803200, "time": 25224.913028001785, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 803464, "time": 25232.75183749199, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 803480, "time": 25233.256704568863, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 803625, "time": 25238.61349129677, "train_stats/mean_log_entropy": 0.07869505976152615, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7777403281827278, "train/action_min": 0.0, "train/action_std": 1.7011899701480209, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0109161229246741, "train/actor_opt_grad_steps": 49120.0, "train/actor_opt_loss": -20.167635321029888, "train/adv_mag": 0.9667577796381682, "train/adv_max": 0.3598343351204407, "train/adv_mean": 0.0006609175662670796, "train/adv_min": -0.8997232502904432, "train/adv_std": 0.02748794094865839, "train/cont_avg": 0.994501423953202, "train/cont_loss_mean": 0.01680238400081292, "train/cont_loss_std": 0.21101492574080605, "train/cont_neg_acc": 0.3036069759888015, "train/cont_neg_loss": 2.3328672801570227, "train/cont_pos_acc": 0.999879099758975, "train/cont_pos_loss": 0.0038173385033283035, "train/cont_pred": 0.9945824066993638, "train/cont_rate": 0.994501423953202, "train/dyn_loss_mean": 1.0000002325462003, "train/dyn_loss_std": 7.431535509052535e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09674355922624689, "train/extr_critic_critic_opt_grad_steps": 49120.0, "train/extr_critic_critic_opt_loss": 10947.033366687192, "train/extr_critic_mag": 1.556274350640809, "train/extr_critic_max": 1.556274350640809, "train/extr_critic_mean": 1.4665506702338533, "train/extr_critic_min": 1.1041606059802578, "train/extr_critic_std": 0.03425282839997649, "train/extr_return_normed_mag": 0.9938800217482844, "train/extr_return_normed_max": 0.2976768827203459, "train/extr_return_normed_mean": 0.06299842031571666, "train/extr_return_normed_min": -0.9110922754691739, "train/extr_return_normed_std": 0.044717311739848165, "train/extr_return_rate": 0.9996523860052888, "train/extr_return_raw_mag": 1.7018899729686419, "train/extr_return_raw_max": 1.7018899729686419, "train/extr_return_raw_mean": 1.4672115876756866, "train/extr_return_raw_min": 0.4931208147791219, "train/extr_return_raw_std": 0.04471731196006237, "train/extr_reward_mag": 0.26084226281772105, "train/extr_reward_max": 0.26084226281772105, "train/extr_reward_mean": 0.002065411432797612, "train/extr_reward_min": 1.0863900771869227e-07, "train/extr_reward_std": 0.008313819337085696, "train/image_loss_mean": 0.09450518288489046, "train/image_loss_std": 0.10560751287954781, "train/model_loss_mean": 0.7283348731806712, "train/model_loss_std": 0.459085024306046, "train/model_opt_grad_norm": 20.001201568565932, "train/model_opt_grad_steps": 49076.86699507389, "train/model_opt_loss": 3041.1531314943813, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4174.87684729064, "train/policy_entropy_mag": 1.3211585952730602, "train/policy_entropy_max": 1.3211585952730602, "train/policy_entropy_mean": 0.09967378137880946, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12766890558115954, "train/policy_logprob_mag": 6.551080231596097, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10011743181591551, "train/policy_logprob_min": -6.551080231596097, "train/policy_logprob_std": 0.6398011968640859, "train/policy_randomness_mag": 0.6789412516091258, "train/policy_randomness_max": 0.6789412516091258, "train/policy_randomness_mean": 0.051222193013564704, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06560884269293893, "train/post_ent_mag": 39.84365895463915, "train/post_ent_max": 39.84365895463915, "train/post_ent_mean": 39.42697013892564, "train/post_ent_min": 39.004422042170184, "train/post_ent_std": 0.19738059575334557, "train/prior_ent_mag": 40.15663891120497, "train/prior_ent_max": 40.15663891120497, "train/prior_ent_mean": 38.853412665757055, "train/prior_ent_min": 37.758265208728204, "train/prior_ent_std": 0.35648929206608554, "train/rep_loss_mean": 1.0000002325462003, "train/rep_loss_std": 7.431535509052535e-06, "train/reward_avg": 0.002132021152217106, "train/reward_loss_mean": 0.017027144340954245, "train/reward_loss_std": 0.23567637306605949, "train/reward_max_data": 0.7334821423873525, "train/reward_max_pred": 0.27144257070982986, "train/reward_neg_acc": 0.9997827763040664, "train/reward_neg_loss": 0.0030119455284140823, "train/reward_pos_acc": 0.15139387630338047, "train/reward_pos_loss": 3.876698949528699, "train/reward_pred": 0.001668181487707779, "train/reward_rate": 0.0035935575738916255, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.020661944523453712, "report/cont_loss_std": 0.2872350513935089, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 3.2711589336395264, "report/cont_pos_acc": 0.999018669128418, "report/cont_pos_loss": 0.004712497815489769, "report/cont_pred": 0.994501531124115, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09144523739814758, "report/image_loss_std": 0.1112593486905098, "report/model_loss_mean": 0.7276116609573364, "report/model_loss_std": 0.4589831233024597, "report/post_ent_mag": 40.06657409667969, "report/post_ent_max": 40.06657409667969, "report/post_ent_mean": 39.63130569458008, "report/post_ent_min": 39.13677215576172, "report/post_ent_std": 0.21111734211444855, "report/prior_ent_mag": 40.24015808105469, "report/prior_ent_max": 40.24015808105469, "report/prior_ent_mean": 38.9797477722168, "report/prior_ent_min": 37.99232864379883, "report/prior_ent_std": 0.3487650752067566, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0016601562965661287, "report/reward_loss_mean": 0.015504512935876846, "report/reward_loss_std": 0.20022918283939362, "report/reward_max_data": 0.668749988079071, "report/reward_max_pred": 0.40316474437713623, "report/reward_neg_acc": 0.9990195631980896, "report/reward_neg_loss": 0.004450224805623293, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 2.834348201751709, "report/reward_pred": 0.0024953018873929977, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.027783609926700592, "eval/cont_loss_std": 0.454378217458725, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.29574728012085, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.003203359665349126, "eval/cont_pred": 0.9967734813690186, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11103592813014984, "eval/image_loss_std": 0.12171369791030884, "eval/model_loss_mean": 0.7479052543640137, "eval/model_loss_std": 0.5349711179733276, "eval/post_ent_mag": 40.05781173706055, "eval/post_ent_max": 40.05781173706055, "eval/post_ent_mean": 39.565956115722656, "eval/post_ent_min": 39.239105224609375, "eval/post_ent_std": 0.19512905180454254, "eval/prior_ent_mag": 40.216278076171875, "eval/prior_ent_max": 40.216278076171875, "eval/prior_ent_mean": 38.97734832763672, "eval/prior_ent_min": 38.09178924560547, "eval/prior_ent_std": 0.3369579315185547, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0011108398903161287, "eval/reward_loss_mean": 0.00908568687736988, "eval/reward_loss_std": 0.15500052273273468, "eval/reward_max_data": 0.5843750238418579, "eval/reward_max_pred": 0.10471320152282715, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.0024574515409767628, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 3.396113872528076, "eval/reward_pred": 0.0013495272723957896, "eval/reward_rate": 0.001953125, "replay/size": 803121.0, "replay/inserts": 32432.0, "replay/samples": 32432.0, "replay/insert_wait_avg": 1.2895275232647227e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.322299756848523e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.177938174670614e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1358256340027, "timer/env.step_count": 4054.0, "timer/env.step_total": 39.06090712547302, "timer/env.step_frac": 0.03905560237351928, "timer/env.step_avg": 0.00963515222631303, "timer/env.step_min": 0.007600307464599609, "timer/env.step_max": 0.053359031677246094, "timer/replay._sample_count": 32432.0, "timer/replay._sample_total": 16.326801538467407, "timer/replay._sample_frac": 0.01632458424146298, "timer/replay._sample_avg": 0.0005034164263217626, "timer/replay._sample_min": 0.0004048347473144531, "timer/replay._sample_max": 0.0310666561126709, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4593.0, "timer/agent.policy_total": 47.817134618759155, "timer/agent.policy_frac": 0.04781064070817289, "timer/agent.policy_avg": 0.010410871896093873, "timer/agent.policy_min": 0.008307695388793945, "timer/agent.policy_max": 0.0793755054473877, "timer/dataset_train_count": 2027.0, "timer/dataset_train_total": 0.2122514247894287, "timer/dataset_train_frac": 0.00021222259952029916, "timer/dataset_train_avg": 0.00010471209905743892, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.00039887428283691406, "timer/agent.train_count": 2027.0, "timer/agent.train_total": 901.4857478141785, "timer/agent.train_frac": 0.9013633195698312, "timer/agent.train_avg": 0.44473889877364503, "timer/agent.train_min": 0.4313688278198242, "timer/agent.train_max": 2.346723794937134, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4745163917541504, "timer/agent.report_frac": 0.0004744519490173713, "timer/agent.report_avg": 0.2372581958770752, "timer/agent.report_min": 0.23004388809204102, "timer/agent.report_max": 0.24447250366210938, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051343361853316e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 32.42705238784391}
{"step": 804072, "time": 25251.806513786316, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 804136, "time": 25253.752111673355, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 804208, "time": 25256.1321144104, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 804360, "time": 25260.643822431564, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 804368, "time": 25261.11192369461, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 804384, "time": 25261.602774620056, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 804424, "time": 25262.591502904892, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 804952, "time": 25278.520135879517, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 805040, "time": 25281.392181396484, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 805248, "time": 25287.67516565323, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 805512, "time": 25295.505344629288, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 805576, "time": 25297.44998240471, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 805648, "time": 25299.857569932938, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 805672, "time": 25300.373128175735, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 805864, "time": 25306.17795777321, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 805880, "time": 25306.68230199814, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 805960, "time": 25309.092828273773, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 806240, "time": 25317.790913820267, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 806304, "time": 25319.71668100357, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 806512, "time": 25326.153899908066, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 806552, "time": 25327.14004087448, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 806856, "time": 25336.35695695877, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 806920, "time": 25338.28690481186, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 807224, "time": 25347.449993610382, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 807256, "time": 25348.421587467194, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 807344, "time": 25351.363312482834, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 807464, "time": 25354.753727912903, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 807720, "time": 25362.474729061127, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 807736, "time": 25362.96345257759, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 807760, "time": 25363.90995812416, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 808008, "time": 25371.252025842667, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 808032, "time": 25372.21282362938, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 808120, "time": 25374.69172143936, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 808168, "time": 25376.134806632996, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 808344, "time": 25381.563507080078, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 808488, "time": 25385.907308340073, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 808704, "time": 25392.617145061493, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 808720, "time": 25393.103352308273, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 809224, "time": 25408.089154958725, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 809240, "time": 25408.59533405304, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 809280, "time": 25410.01093149185, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 809496, "time": 25416.40598988533, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 809616, "time": 25420.23858141899, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 809696, "time": 25422.649832963943, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 809712, "time": 25423.153938293457, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 809832, "time": 25426.536386728287, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 809832, "time": 25426.545429229736, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 809848, "time": 25427.03396630287, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 810048, "time": 25433.314919948578, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 810056, "time": 25434.258146047592, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 810056, "time": 25434.793540000916, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 810056, "time": 25434.890209197998, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 810056, "time": 25435.231792211533, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 810056, "time": 25435.65814590454, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 810056, "time": 25435.816009044647, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 810056, "time": 25436.290959358215, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 810056, "time": 25436.638247728348, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 810224, "time": 25442.08376955986, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 810352, "time": 25445.966930389404, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 810664, "time": 25455.150725841522, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 810688, "time": 25456.123577594757, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 810776, "time": 25458.552228927612, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 810840, "time": 25460.50934767723, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 810872, "time": 25461.477662563324, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 810920, "time": 25462.923104286194, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 811080, "time": 25468.33518075943, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 811248, "time": 25473.708436727524, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 811448, "time": 25479.547569990158, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 811504, "time": 25481.474966049194, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 811688, "time": 25486.81341767311, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 811912, "time": 25493.59552884102, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 811936, "time": 25494.545566082, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 812168, "time": 25501.42553114891, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 812296, "time": 25505.296021461487, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 812336, "time": 25506.726383447647, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 812544, "time": 25512.98211836815, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 812672, "time": 25516.849244832993, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 812736, "time": 25518.78273677826, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 812872, "time": 25522.67313694954, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 813112, "time": 25529.927347421646, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 813224, "time": 25533.372661828995, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 813288, "time": 25535.319587230682, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 813672, "time": 25546.86826968193, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 813952, "time": 25555.525881767273, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 813952, "time": 25555.532942056656, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 813968, "time": 25556.02135872841, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 813984, "time": 25556.511778831482, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 814048, "time": 25558.45095849037, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 814192, "time": 25562.878970384598, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 814296, "time": 25565.772183179855, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 814400, "time": 25569.133994817734, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 814424, "time": 25569.640070438385, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 814664, "time": 25576.86026239395, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 814984, "time": 25586.537050008774, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 814992, "time": 25587.024337291718, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 815008, "time": 25587.51030421257, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 815136, "time": 25591.44487309456, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 815296, "time": 25596.288608312607, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 815504, "time": 25602.56693172455, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 815512, "time": 25602.595128774643, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 815544, "time": 25603.551014900208, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 815664, "time": 25607.401906728745, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 815728, "time": 25609.322813510895, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 815960, "time": 25616.094303131104, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 816264, "time": 25625.349511623383, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 816312, "time": 25626.84951019287, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 816376, "time": 25628.78154683113, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 816480, "time": 25632.136856794357, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 816488, "time": 25632.164040327072, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 816616, "time": 25636.027896404266, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 817136, "time": 25652.02659034729, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 817160, "time": 25652.535346269608, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 817176, "time": 25653.02494239807, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 817520, "time": 25663.60487651825, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 817576, "time": 25665.10127544403, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 817584, "time": 25665.569593906403, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 817592, "time": 25665.597914218903, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 817608, "time": 25666.084914445877, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 817768, "time": 25670.90716958046, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 817768, "time": 25670.914612054825, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 817872, "time": 25674.304067373276, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 818096, "time": 25681.167812347412, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 818336, "time": 25688.38706445694, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 818592, "time": 25696.124950408936, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 818664, "time": 25698.078188419342, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 818760, "time": 25700.98061108589, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 819008, "time": 25708.700789928436, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 819056, "time": 25710.14519572258, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 819096, "time": 25711.227380037308, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 819192, "time": 25714.132656097412, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 819312, "time": 25718.453705072403, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 819736, "time": 25731.031845331192, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 819752, "time": 25731.517329454422, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 819888, "time": 25735.84838294983, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 820040, "time": 25741.01169347763, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 820040, "time": 25742.103968143463, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 820040, "time": 25742.202766418457, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 820040, "time": 25742.539479970932, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 820040, "time": 25743.122317552567, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 820040, "time": 25743.7755112648, "eval_episode/length": 166.0, "eval_episode/score": 0.48124998807907104, "eval_episode/reward_rate": 0.005988023952095809}
{"step": 820040, "time": 25744.361434936523, "eval_episode/length": 177.0, "eval_episode/score": 0.4468750059604645, "eval_episode/reward_rate": 0.0056179775280898875}
{"step": 820040, "time": 25744.52830338478, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 820416, "time": 25756.065835237503, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 820536, "time": 25759.46994781494, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 820728, "time": 25765.24346804619, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 820848, "time": 25769.081078767776, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 820848, "time": 25769.08912229538, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 820960, "time": 25772.565873384476, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 821176, "time": 25778.839802980423, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 821320, "time": 25783.193120479584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 821616, "time": 25792.364072799683, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 821624, "time": 25792.39504647255, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 821640, "time": 25792.88984155655, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 821768, "time": 25796.782611370087, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 822024, "time": 25804.599309444427, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 822120, "time": 25807.511926651, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 822136, "time": 25807.99898147583, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 822208, "time": 25810.418390989304, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 822280, "time": 25812.368997097015, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 822376, "time": 25815.287291526794, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 822464, "time": 25818.163821220398, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 822728, "time": 25825.930900335312, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 823016, "time": 25834.725498199463, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 823072, "time": 25836.635344982147, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 823096, "time": 25837.142953634262, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 823192, "time": 25840.055386781693, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 823200, "time": 25840.52561378479, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 823248, "time": 25841.97648692131, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 823384, "time": 25845.886974811554, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 823752, "time": 25856.971791505814, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 823784, "time": 25857.937096357346, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 823864, "time": 25860.44451236725, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 823896, "time": 25861.411069869995, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 823976, "time": 25863.837865829468, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 823992, "time": 25864.32439136505, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 824144, "time": 25869.13115811348, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 824256, "time": 25872.496693849564, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 824352, "time": 25875.404549360275, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 824408, "time": 25876.87847185135, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 824496, "time": 25879.76012825966, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 824904, "time": 25891.89690709114, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 825024, "time": 25895.74392580986, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 825160, "time": 25899.642212867737, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 825176, "time": 25900.131265878677, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 825200, "time": 25901.079159259796, "episode/length": 265.0, "episode/score": 0.171875, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.0}
{"step": 825432, "time": 25907.86066055298, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 825488, "time": 25909.779009103775, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 825552, "time": 25911.73367214203, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 825656, "time": 25914.64294576645, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 825992, "time": 25924.864221811295, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 826064, "time": 25927.26454925537, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 826176, "time": 25930.634048223495, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 826256, "time": 25933.05341076851, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 826384, "time": 25936.91843509674, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 826512, "time": 25940.778919696808, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 826672, "time": 25945.623659849167, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 826736, "time": 25947.564650774002, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 827256, "time": 25963.182074785233, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 827296, "time": 25964.60621881485, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 827376, "time": 25967.04506421089, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 827536, "time": 25972.365594387054, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 827552, "time": 25972.848125219345, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 827672, "time": 25976.258548259735, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 827944, "time": 25984.531029701233, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 828016, "time": 25986.950820207596, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 828152, "time": 25990.84152007103, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 828168, "time": 25991.33074069023, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 828240, "time": 25993.70983982086, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 828352, "time": 25997.088222265244, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 828584, "time": 26003.87352824211, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 828760, "time": 26009.21110510826, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 828904, "time": 26013.636693000793, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 828960, "time": 26015.589874744415, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 829040, "time": 26018.014515161514, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 829328, "time": 26026.72683429718, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 829528, "time": 26032.550107240677, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 829632, "time": 26035.911339521408, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 829688, "time": 26037.37264227867, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 829872, "time": 26043.246876955032, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 829888, "time": 26043.731673002243, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 829944, "time": 26045.209011554718, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 830024, "time": 26049.290468215942, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 830024, "time": 26049.74473309517, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 830024, "time": 26049.897834062576, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 830024, "time": 26050.340675115585, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 830024, "time": 26050.457176685333, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 830024, "time": 26051.063044071198, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 830024, "time": 26051.33754825592, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 830024, "time": 26051.50914001465, "eval_episode/length": 211.0, "eval_episode/score": 0.34062498807907104, "eval_episode/reward_rate": 0.0047169811320754715}
{"step": 830096, "time": 26053.910044193268, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 830168, "time": 26055.85961651802, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 830200, "time": 26056.846551179886, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 830560, "time": 26067.925149202347, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 830608, "time": 26069.374746322632, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 830672, "time": 26071.40741586685, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 830744, "time": 26073.359345912933, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 830936, "time": 26079.175256967545, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 830984, "time": 26080.620568990707, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 831056, "time": 26083.02635216713, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 831264, "time": 26089.29608631134, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 831576, "time": 26098.484778404236, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 831600, "time": 26099.43062067032, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 831672, "time": 26101.476426124573, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 831888, "time": 26108.22753572464, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 832056, "time": 26113.084335565567, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 832096, "time": 26114.51120042801, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 832120, "time": 26115.035534143448, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 832168, "time": 26116.477154254913, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 832176, "time": 26116.94388794899, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 832224, "time": 26118.38454246521, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 832232, "time": 26118.413079977036, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 832696, "time": 26132.591735601425, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 832720, "time": 26133.538267850876, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 832984, "time": 26141.28505396843, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 833008, "time": 26142.23094844818, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 833136, "time": 26146.086406469345, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 833192, "time": 26147.5553753376, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 833248, "time": 26149.47984790802, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 833320, "time": 26151.432666778564, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 833472, "time": 26156.23041653633, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 833536, "time": 26158.16432404518, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 833664, "time": 26162.088183164597, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 833744, "time": 26164.51385307312, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 833848, "time": 26167.420023202896, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 833944, "time": 26170.355906248093, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 834056, "time": 26173.752580165863, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 834144, "time": 26176.624484300613, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 834368, "time": 26183.45092201233, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 834400, "time": 26184.4216234684, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 834432, "time": 26185.38647389412, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 834520, "time": 26187.828665971756, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 834640, "time": 26191.7457818985, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 834744, "time": 26194.667164325714, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 835088, "time": 26205.300364255905, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 835256, "time": 26210.14641237259, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 835312, "time": 26212.081644296646, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 835376, "time": 26214.01319861412, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 835424, "time": 26215.457972049713, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 835544, "time": 26218.881143569946, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 835664, "time": 26223.2623360157, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 835712, "time": 26224.703627824783, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 835936, "time": 26231.45484852791, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 835952, "time": 26231.963482618332, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 836072, "time": 26235.349090337753, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 836144, "time": 26237.751378297806, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 836153, "time": 26238.790150642395, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7150292607951045, "train/action_min": 0.0, "train/action_std": 1.7053557610864123, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009920370017219647, "train/actor_opt_grad_steps": 51150.0, "train/actor_opt_loss": -19.462655250662067, "train/adv_mag": 0.9301323638173747, "train/adv_max": 0.3527301455953438, "train/adv_mean": 0.0009307195990546515, "train/adv_min": -0.8607242277690342, "train/adv_std": 0.024486434829462632, "train/cont_avg": 0.9944148322044335, "train/cont_loss_mean": 0.017688823290389455, "train/cont_loss_std": 0.21995419805658423, "train/cont_neg_acc": 0.2844131020049156, "train/cont_neg_loss": 2.4238109324916537, "train/cont_pos_acc": 0.9998887668689483, "train/cont_pos_loss": 0.004015613938544147, "train/cont_pred": 0.9945019580460535, "train/cont_rate": 0.9944148322044335, "train/dyn_loss_mean": 1.0000017435092645, "train/dyn_loss_std": 5.577563415992583e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09903750240142123, "train/extr_critic_critic_opt_grad_steps": 51150.0, "train/extr_critic_critic_opt_loss": 9533.282481527094, "train/extr_critic_mag": 1.5769673227676617, "train/extr_critic_max": 1.5769673227676617, "train/extr_critic_mean": 1.4890754798362995, "train/extr_critic_min": 1.0952392105985744, "train/extr_critic_std": 0.03549226141291593, "train/extr_return_normed_mag": 0.950559309550694, "train/extr_return_normed_max": 0.2855721982241851, "train/extr_return_normed_mean": 0.06568306335821528, "train/extr_return_normed_min": -0.875397655176999, "train/extr_return_normed_std": 0.04383167841935099, "train/extr_return_rate": 0.9997460328299423, "train/extr_return_raw_mag": 1.7098951979810968, "train/extr_return_raw_max": 1.7098951979810968, "train/extr_return_raw_mean": 1.4900061414746815, "train/extr_return_raw_min": 0.5489253445799127, "train/extr_return_raw_std": 0.0438316784101754, "train/extr_reward_mag": 0.24842303492165552, "train/extr_reward_max": 0.24842303492165552, "train/extr_reward_mean": 0.002082777508360155, "train/extr_reward_min": 2.936189397802494e-08, "train/extr_reward_std": 0.00810599605107836, "train/image_loss_mean": 0.09443625246215924, "train/image_loss_std": 0.10615369563766301, "train/model_loss_mean": 0.7293863411020176, "train/model_loss_std": 0.4651072273040053, "train/model_opt_grad_norm": 20.124558749457297, "train/model_opt_grad_steps": 51105.24137931035, "train/model_opt_loss": 3736.9833010217826, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5123.152709359606, "train/policy_entropy_mag": 1.3139226013803718, "train/policy_entropy_max": 1.3139226013803718, "train/policy_entropy_mean": 0.09610108043906723, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12145170228087844, "train/policy_logprob_mag": 6.5510802386429505, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09599491429005938, "train/policy_logprob_min": -6.5510802386429505, "train/policy_logprob_std": 0.6329935416212222, "train/policy_randomness_mag": 0.6752226863588605, "train/policy_randomness_max": 0.6752226863588605, "train/policy_randomness_mean": 0.049386186901424906, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06241383242049241, "train/post_ent_mag": 39.918626813465735, "train/post_ent_max": 39.918626813465735, "train/post_ent_mean": 39.46118947672726, "train/post_ent_min": 38.98812315616701, "train/post_ent_std": 0.2238997903657077, "train/prior_ent_mag": 40.07235625694538, "train/prior_ent_max": 40.07235625694538, "train/prior_ent_mean": 38.75943928986347, "train/prior_ent_min": 37.77333974603361, "train/prior_ent_std": 0.355300059899908, "train/rep_loss_mean": 1.0000017435092645, "train/rep_loss_std": 5.577563415992583e-05, "train/reward_avg": 0.0021446040110935554, "train/reward_loss_mean": 0.017260195004978572, "train/reward_loss_std": 0.23610585513226504, "train/reward_max_data": 0.7295104671875244, "train/reward_max_pred": 0.2388455004527651, "train/reward_neg_acc": 0.9997344956609416, "train/reward_neg_loss": 0.0031827965320037504, "train/reward_pos_acc": 0.14289944592466208, "train/reward_pos_loss": 3.92337369691902, "train/reward_pred": 0.0017183230848056195, "train/reward_rate": 0.0035935575738916255, "train_stats/mean_log_entropy": 0.07645300745792773, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.025032369419932365, "report/cont_loss_std": 0.3355727791786194, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.9627792835235596, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005710748489946127, "report/cont_pred": 0.9942213892936707, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09647335112094879, "report/image_loss_std": 0.10768101364374161, "report/model_loss_mean": 0.7408761382102966, "report/model_loss_std": 0.5260087251663208, "report/post_ent_mag": 40.02644348144531, "report/post_ent_max": 40.02644348144531, "report/post_ent_mean": 39.49413299560547, "report/post_ent_min": 38.88764190673828, "report/post_ent_std": 0.27990466356277466, "report/prior_ent_mag": 39.78160858154297, "report/prior_ent_max": 39.78160858154297, "report/prior_ent_mean": 38.5451545715332, "report/prior_ent_min": 37.384727478027344, "report/prior_ent_std": 0.3218492865562439, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002410888671875, "report/reward_loss_mean": 0.019370388239622116, "report/reward_loss_std": 0.23789800703525543, "report/reward_max_data": 0.7593749761581421, "report/reward_max_pred": 0.0732651948928833, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.004629273433238268, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.7783546447753906, "report/reward_pred": 0.0022133635357022285, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.051776222884655, "eval/cont_loss_std": 0.7837439775466919, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.480480194091797, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0030362061224877834, "eval/cont_pred": 0.9971548914909363, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12884770333766937, "eval/image_loss_std": 0.12597118318080902, "eval/model_loss_mean": 0.8035950064659119, "eval/model_loss_std": 1.1836283206939697, "eval/post_ent_mag": 39.960811614990234, "eval/post_ent_max": 39.960811614990234, "eval/post_ent_mean": 39.36857604980469, "eval/post_ent_min": 38.859947204589844, "eval/post_ent_std": 0.247887521982193, "eval/prior_ent_mag": 39.78160858154297, "eval/prior_ent_max": 39.78160858154297, "eval/prior_ent_mean": 38.447967529296875, "eval/prior_ent_min": 37.627315521240234, "eval/prior_ent_std": 0.3407227098941803, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0013275146484375, "eval/reward_loss_mean": 0.022971097379922867, "eval/reward_loss_std": 0.4779554605484009, "eval/reward_max_data": 0.7124999761581421, "eval/reward_max_pred": 0.18353044986724854, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.0023737852461636066, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.548197746276855, "eval/reward_pred": 0.0010563661344349384, "eval/reward_rate": 0.001953125, "replay/size": 835649.0, "replay/inserts": 32528.0, "replay/samples": 32528.0, "replay/insert_wait_avg": 1.2960198825061232e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.518672966570087e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4592.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1414185633642749e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1404795646667, "timer/env.step_count": 4066.0, "timer/env.step_total": 38.96000671386719, "timer/env.step_frac": 0.03895453439783318, "timer/env.step_avg": 0.009581900323135068, "timer/env.step_min": 0.007644176483154297, "timer/env.step_max": 0.04623675346374512, "timer/replay._sample_count": 32528.0, "timer/replay._sample_total": 16.441739559173584, "timer/replay._sample_frac": 0.016439430155182014, "timer/replay._sample_avg": 0.000505464201892941, "timer/replay._sample_min": 0.0003757476806640625, "timer/replay._sample_max": 0.011309623718261719, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4640.0, "timer/agent.policy_total": 48.11100959777832, "timer/agent.policy_frac": 0.048104251933408095, "timer/agent.policy_avg": 0.010368752068486708, "timer/agent.policy_min": 0.008828401565551758, "timer/agent.policy_max": 0.08250761032104492, "timer/dataset_train_count": 2033.0, "timer/dataset_train_total": 0.21405720710754395, "timer/dataset_train_frac": 0.00021402714066799604, "timer/dataset_train_avg": 0.00010529129715078403, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.0010707378387451172, "timer/agent.train_count": 2033.0, "timer/agent.train_total": 901.5149490833282, "timer/agent.train_frac": 0.9013883224441956, "timer/agent.train_avg": 0.44344070294310295, "timer/agent.train_min": 0.430769681930542, "timer/agent.train_max": 0.7118592262268066, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48006343841552734, "timer/agent.report_frac": 0.00047999600878517143, "timer/agent.report_avg": 0.24003171920776367, "timer/agent.report_min": 0.23308730125427246, "timer/agent.report_max": 0.24697613716125488, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.908298108586847e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 32.52288018101826}
{"step": 836368, "time": 26245.27215886116, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 836408, "time": 26246.271052360535, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 836432, "time": 26247.249944210052, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 836680, "time": 26254.692214488983, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 836928, "time": 26262.46946811676, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 837176, "time": 26269.754047870636, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 837336, "time": 26274.601705551147, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 837336, "time": 26274.608555793762, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 837344, "time": 26275.08089852333, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 837560, "time": 26281.55769276619, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 837568, "time": 26282.029509067535, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 837872, "time": 26291.285729408264, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 837960, "time": 26293.728627443314, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 838384, "time": 26306.84643959999, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 838584, "time": 26312.795228004456, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 838712, "time": 26316.6866042614, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 838760, "time": 26318.143912553787, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 838928, "time": 26323.45992088318, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 838976, "time": 26324.925459623337, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 839152, "time": 26330.311319112778, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 839216, "time": 26332.232594013214, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 839296, "time": 26334.65638065338, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 839600, "time": 26343.982526302338, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 839608, "time": 26344.010147571564, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 839632, "time": 26344.981561899185, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 839832, "time": 26350.80354452133, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 839840, "time": 26351.272348165512, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 840008, "time": 26357.378792762756, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 840008, "time": 26357.743326425552, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 840008, "time": 26357.91627049446, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 840008, "time": 26358.441060066223, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 840008, "time": 26358.797961235046, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 840008, "time": 26359.0189807415, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 840008, "time": 26359.044519662857, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 840008, "time": 26359.648090600967, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 840128, "time": 26363.507411003113, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 840144, "time": 26363.999462366104, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 840200, "time": 26365.479533433914, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 840440, "time": 26372.918009757996, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 840552, "time": 26376.357238531113, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 840592, "time": 26377.83711719513, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 840800, "time": 26384.188215970993, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 841008, "time": 26390.48418712616, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 841032, "time": 26390.99582529068, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 841200, "time": 26396.300214767456, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 841256, "time": 26397.79860019684, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 841504, "time": 26405.621809005737, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 841536, "time": 26406.593766450882, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 841792, "time": 26414.379435539246, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 841984, "time": 26420.19623684883, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 842104, "time": 26423.618665218353, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 842400, "time": 26432.949503660202, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 842464, "time": 26434.88333916664, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 842696, "time": 26441.721272945404, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 842752, "time": 26443.637930870056, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 842784, "time": 26444.61368370056, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 842984, "time": 26450.46071076393, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 843056, "time": 26452.88156890869, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 843072, "time": 26453.37414622307, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 843184, "time": 26456.77624320984, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 843432, "time": 26464.138868570328, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 843920, "time": 26479.629166841507, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 843936, "time": 26480.11885881424, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 844192, "time": 26487.866324424744, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 844240, "time": 26489.353870630264, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 844328, "time": 26491.907920360565, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 844360, "time": 26492.886194467545, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 844408, "time": 26494.339742422104, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 844472, "time": 26496.298231840134, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 844672, "time": 26502.57810163498, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 844728, "time": 26504.052097797394, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 844832, "time": 26507.449831962585, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 845216, "time": 26519.131075143814, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 845240, "time": 26519.660473823547, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 845424, "time": 26525.5168094635, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 845544, "time": 26528.905217409134, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 845624, "time": 26531.38032388687, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 845632, "time": 26531.858071804047, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 845840, "time": 26538.238971233368, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 845880, "time": 26539.251863718033, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 846056, "time": 26544.590128660202, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 846112, "time": 26546.503925800323, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 846184, "time": 26548.4704246521, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 846368, "time": 26554.40162754059, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 846592, "time": 26561.180640935898, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 846640, "time": 26562.632841348648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 846688, "time": 26564.09424304962, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 846848, "time": 26568.917320251465, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 846864, "time": 26569.404878377914, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 846888, "time": 26569.915175437927, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 847024, "time": 26574.260199069977, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 847200, "time": 26579.557693004608, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 847384, "time": 26584.983917474747, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 847400, "time": 26585.47225666046, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 847488, "time": 26588.358369588852, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 847824, "time": 26598.49011516571, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 848000, "time": 26603.81430888176, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 848096, "time": 26606.71523451805, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 848384, "time": 26615.674438476562, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 848696, "time": 26625.05599308014, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 848712, "time": 26625.54965186119, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 848744, "time": 26626.534907341003, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 849048, "time": 26635.822276592255, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 849048, "time": 26635.829731941223, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 849184, "time": 26640.197191476822, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 849240, "time": 26641.764986276627, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 849384, "time": 26646.113577127457, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 849896, "time": 26661.683929920197, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 849960, "time": 26663.64037322998, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 850096, "time": 26668.44060397148, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 850096, "time": 26669.179550886154, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 850096, "time": 26669.69352889061, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 850096, "time": 26669.880108594894, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 850096, "time": 26671.112313747406, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 850096, "time": 26671.693379878998, "eval_episode/length": 178.0, "eval_episode/score": 0.4437499940395355, "eval_episode/reward_rate": 0.00558659217877095}
{"step": 850096, "time": 26671.885922908783, "eval_episode/length": 187.0, "eval_episode/score": 0.4156250059604645, "eval_episode/reward_rate": 0.005319148936170213}
{"step": 850096, "time": 26672.09162592888, "eval_episode/length": 197.0, "eval_episode/score": 0.3843750059604645, "eval_episode/reward_rate": 0.005050505050505051}
{"step": 850096, "time": 26672.098385810852, "eval_episode/length": 197.0, "eval_episode/score": 0.3843750059604645, "eval_episode/reward_rate": 0.005050505050505051}
{"step": 850144, "time": 26673.569821357727, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 850152, "time": 26673.600284814835, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 850208, "time": 26675.557020664215, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 850544, "time": 26685.803730726242, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 850552, "time": 26685.83312034607, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 850648, "time": 26688.77357363701, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 850704, "time": 26690.747231960297, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 851048, "time": 26701.13156747818, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 851368, "time": 26710.889657735825, "episode/length": 265.0, "episode/score": 0.171875, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.0}
{"step": 851368, "time": 26710.89906001091, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 851512, "time": 26715.32381415367, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 851576, "time": 26717.29959011078, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 851728, "time": 26722.162341356277, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 851832, "time": 26725.101288557053, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 851912, "time": 26727.54114460945, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 852280, "time": 26739.295311689377, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 852312, "time": 26740.271951913834, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 852384, "time": 26742.68061518669, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 852512, "time": 26746.570838928223, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 852536, "time": 26747.084567070007, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 853008, "time": 26761.74946641922, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 853128, "time": 26765.191266059875, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 853464, "time": 26775.40073442459, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 853560, "time": 26778.315119981766, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 853632, "time": 26780.705497264862, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 853640, "time": 26780.73261332512, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 853704, "time": 26782.675097465515, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 854016, "time": 26792.406034708023, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 854072, "time": 26793.902193546295, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 854144, "time": 26796.293784856796, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 854320, "time": 26801.625492572784, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 854392, "time": 26803.595822811127, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 854728, "time": 26813.796851158142, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 854848, "time": 26817.67448949814, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 855104, "time": 26825.491975307465, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 855576, "time": 26839.71253657341, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 855632, "time": 26841.641912698746, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 855680, "time": 26843.10334467888, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 855712, "time": 26844.07865214348, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 855856, "time": 26848.48398542404, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 855896, "time": 26849.467943668365, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 856336, "time": 26863.099766254425, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 856368, "time": 26864.069348335266, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 856592, "time": 26870.818919420242, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 856744, "time": 26875.148557186127, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 856776, "time": 26876.13409948349, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 857008, "time": 26883.48725748062, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 857496, "time": 26898.07719564438, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 857584, "time": 26900.97867012024, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 857592, "time": 26901.00769495964, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 857648, "time": 26902.922730207443, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 857688, "time": 26903.91181063652, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 857704, "time": 26904.401635169983, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 857912, "time": 26910.851835012436, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 858000, "time": 26913.763105154037, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 858184, "time": 26919.12254667282, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 858288, "time": 26922.500843286514, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 858304, "time": 26922.990428686142, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 858440, "time": 26926.887144804, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 858728, "time": 26935.58157134056, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 858904, "time": 26940.994940280914, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 859000, "time": 26943.910293340683, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 859000, "time": 26943.917867660522, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 859048, "time": 26945.362185001373, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 859056, "time": 26945.826422214508, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 859192, "time": 26949.703080177307, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 859272, "time": 26952.13032412529, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 859496, "time": 26958.913308382034, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 859592, "time": 26961.796103715897, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 859800, "time": 26968.156182050705, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 859816, "time": 26968.64587044716, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 859872, "time": 26970.656455039978, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 859904, "time": 26971.634951114655, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 859944, "time": 26972.633692741394, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 859968, "time": 26973.61704301834, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 26978.206290006638, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 860080, "time": 26978.21253299713, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 860080, "time": 26978.218399763107, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 860080, "time": 26979.980659008026, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 860080, "time": 26980.0675907135, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 860080, "time": 26980.289800167084, "eval_episode/length": 164.0, "eval_episode/score": 0.48750001192092896, "eval_episode/reward_rate": 0.006060606060606061}
{"step": 860080, "time": 26980.35845708847, "eval_episode/length": 167.0, "eval_episode/score": 0.4781250059604645, "eval_episode/reward_rate": 0.005952380952380952}
{"step": 860080, "time": 26980.834413290024, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 860184, "time": 26984.243282794952, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 860752, "time": 27001.82165646553, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 861032, "time": 27010.13579773903, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 861112, "time": 27012.579617738724, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 861136, "time": 27013.537236452103, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 861152, "time": 27014.033305168152, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 861392, "time": 27021.30307507515, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 861456, "time": 27023.247659683228, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 861600, "time": 27027.625864744186, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 861792, "time": 27033.54864525795, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 861904, "time": 27036.95175933838, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 861968, "time": 27038.891409397125, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 862024, "time": 27040.37145924568, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 862448, "time": 27053.49273085594, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 862504, "time": 27054.975360631943, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 862648, "time": 27059.356911182404, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 862720, "time": 27061.874191761017, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 862880, "time": 27066.743706703186, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 862968, "time": 27069.230528831482, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 863016, "time": 27070.728714227676, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 863056, "time": 27072.184965848923, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 863208, "time": 27076.64473938942, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 863240, "time": 27077.61772751808, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 863272, "time": 27078.59050011635, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 863336, "time": 27080.55048418045, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 863520, "time": 27086.359937906265, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 863592, "time": 27088.327625989914, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 863728, "time": 27092.76394176483, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 863776, "time": 27094.221842050552, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 863800, "time": 27094.755975484848, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 863944, "time": 27099.132854938507, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 864224, "time": 27107.820709705353, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 864240, "time": 27108.313096284866, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 864296, "time": 27109.80983901024, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 864560, "time": 27118.025802850723, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 864608, "time": 27119.503347873688, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 864832, "time": 27126.438194990158, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 864912, "time": 27128.874189138412, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 865176, "time": 27136.635477542877, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 865248, "time": 27139.057115793228, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 865368, "time": 27142.465859651566, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 865376, "time": 27142.93478488922, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 865688, "time": 27152.274161815643, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 865688, "time": 27152.281332731247, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 865840, "time": 27157.105212450027, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 865864, "time": 27157.61745595932, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 865888, "time": 27158.58770799637, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 865960, "time": 27160.546877145767, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 865992, "time": 27161.50966858864, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 866128, "time": 27165.837420463562, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 866144, "time": 27166.32374382019, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 866336, "time": 27172.132109880447, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 866688, "time": 27182.905499458313, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 866736, "time": 27184.364047527313, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 866784, "time": 27185.823338747025, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 866792, "time": 27185.85065484047, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 866896, "time": 27189.245921611786, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 867176, "time": 27197.48058128357, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 867392, "time": 27204.22690677643, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 867456, "time": 27206.16263651848, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 867624, "time": 27211.154348134995, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 867808, "time": 27216.955633163452, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 867880, "time": 27218.90492630005, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 868080, "time": 27225.166558265686, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 868104, "time": 27225.678419589996, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 868505, "time": 27239.205984592438, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.745875896793781, "train/action_min": 0.0, "train/action_std": 1.7094261298085203, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010708058987154007, "train/actor_opt_grad_steps": 53175.0, "train/actor_opt_loss": -20.53994292551928, "train/adv_mag": 0.9151640265884966, "train/adv_max": 0.35675187453184976, "train/adv_mean": 0.0004885861496454213, "train/adv_min": -0.8398365151173998, "train/adv_std": 0.026444024955023928, "train/cont_avg": 0.9945467202970297, "train/cont_loss_mean": 0.01768001832418365, "train/cont_loss_std": 0.2178445727988561, "train/cont_neg_acc": 0.26240227960828527, "train/cont_neg_loss": 2.51872165527065, "train/cont_pos_acc": 0.9999318872347916, "train/cont_pos_loss": 0.003986049823850246, "train/cont_pred": 0.994624390460477, "train/cont_rate": 0.9945467202970297, "train/dyn_loss_mean": 1.0000001882562544, "train/dyn_loss_std": 6.042862158138444e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11165937321205245, "train/extr_critic_critic_opt_grad_steps": 53175.0, "train/extr_critic_critic_opt_loss": 7396.4661563080135, "train/extr_critic_mag": 1.6119279011641399, "train/extr_critic_max": 1.6119279011641399, "train/extr_critic_mean": 1.5166097513519892, "train/extr_critic_min": 1.1174993703861047, "train/extr_critic_std": 0.03815025579885091, "train/extr_return_normed_mag": 0.9190510298946116, "train/extr_return_normed_max": 0.2967931038082236, "train/extr_return_normed_mean": 0.0695428893449578, "train/extr_return_normed_min": -0.8288150648079297, "train/extr_return_normed_std": 0.04714514302218904, "train/extr_return_rate": 0.9997341358425593, "train/extr_return_raw_mag": 1.7443484711174917, "train/extr_return_raw_max": 1.7443484711174917, "train/extr_return_raw_mean": 1.517098325313908, "train/extr_return_raw_min": 0.6187403025013385, "train/extr_return_raw_std": 0.04714514301296803, "train/extr_reward_mag": 0.24779400317975792, "train/extr_reward_max": 0.24779400317975792, "train/extr_reward_mean": 0.002180069556464395, "train/extr_reward_min": 3.068753988435953e-08, "train/extr_reward_std": 0.008324614430934485, "train/image_loss_mean": 0.09478911458708272, "train/image_loss_std": 0.10716887817967057, "train/model_loss_mean": 0.7303857862359227, "train/model_loss_std": 0.4768063259301799, "train/model_opt_grad_norm": 19.04452691691937, "train/model_opt_grad_steps": 53128.09405940594, "train/model_opt_loss": 2746.788470277692, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3762.3762376237623, "train/policy_entropy_mag": 1.3346094742859944, "train/policy_entropy_max": 1.3346094742859944, "train/policy_entropy_mean": 0.09422778290244613, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11878258425115358, "train/policy_logprob_mag": 6.551080243422254, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09441336336554867, "train/policy_logprob_min": -6.551080243422254, "train/policy_logprob_std": 0.6332801397484128, "train/policy_randomness_mag": 0.6858536362057865, "train/policy_randomness_max": 0.6858536362057865, "train/policy_randomness_mean": 0.048423503258145685, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06104217689152401, "train/post_ent_mag": 40.089867960108386, "train/post_ent_max": 40.089867960108386, "train/post_ent_mean": 39.454567805375206, "train/post_ent_min": 38.82464216251184, "train/post_ent_std": 0.31054803522506563, "train/prior_ent_mag": 39.96384784962871, "train/prior_ent_max": 39.96384784962871, "train/prior_ent_mean": 38.738288086239656, "train/prior_ent_min": 37.83738081526048, "train/prior_ent_std": 0.3247520808536227, "train/rep_loss_mean": 1.0000001882562544, "train/rep_loss_std": 6.042862158138444e-06, "train/reward_avg": 0.0022270882399254223, "train/reward_loss_mean": 0.01791651631327401, "train/reward_loss_std": 0.24469685347492595, "train/reward_max_data": 0.7487314341608251, "train/reward_max_pred": 0.2243600599836595, "train/reward_neg_acc": 0.9997574217838816, "train/reward_neg_loss": 0.003208105570502985, "train/reward_pos_acc": 0.12380549655801754, "train/reward_pos_loss": 4.029371893950525, "train/reward_pred": 0.0017131767293327663, "train/reward_rate": 0.0036403542698019804, "train_stats/mean_log_entropy": 0.07558461439436402, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.022339653223752975, "report/cont_loss_std": 0.2383357733488083, "report/cont_neg_acc": 0.375, "report/cont_neg_loss": 2.1246414184570312, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005786097142845392, "report/cont_pred": 0.9916221499443054, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09687495231628418, "report/image_loss_std": 0.10531866550445557, "report/model_loss_mean": 0.7404820919036865, "report/model_loss_std": 0.5057357549667358, "report/post_ent_mag": 40.334190368652344, "report/post_ent_max": 40.334190368652344, "report/post_ent_mean": 39.69506072998047, "report/post_ent_min": 38.99726104736328, "report/post_ent_std": 0.32030633091926575, "report/prior_ent_mag": 40.357704162597656, "report/prior_ent_max": 40.357704162597656, "report/prior_ent_mean": 39.215126037597656, "report/prior_ent_min": 38.38509750366211, "report/prior_ent_std": 0.3323751986026764, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0027587891090661287, "report/reward_loss_mean": 0.021267449483275414, "report/reward_loss_std": 0.25912079215049744, "report/reward_max_data": 0.815625011920929, "report/reward_max_pred": 0.33025646209716797, "report/reward_neg_acc": 0.9980372786521912, "report/reward_neg_loss": 0.00455372454598546, "report/reward_pos_acc": 0.20000000298023224, "report/reward_pos_loss": 3.4275245666503906, "report/reward_pred": 0.0025265533477067947, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.03198624029755592, "eval/cont_loss_std": 0.43476492166519165, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.643857479095459, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.00605733273550868, "eval/cont_pred": 0.9945537447929382, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11094092577695847, "eval/image_loss_std": 0.12787111103534698, "eval/model_loss_mean": 0.7728943228721619, "eval/model_loss_std": 0.9218043088912964, "eval/post_ent_mag": 40.335426330566406, "eval/post_ent_max": 40.335426330566406, "eval/post_ent_mean": 39.59744644165039, "eval/post_ent_min": 39.0399284362793, "eval/post_ent_std": 0.30920493602752686, "eval/prior_ent_mag": 40.357704162597656, "eval/prior_ent_max": 40.357704162597656, "eval/prior_ent_mean": 39.1484260559082, "eval/prior_ent_min": 38.407752990722656, "eval/prior_ent_std": 0.30700796842575073, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0017791747814044356, "eval/reward_loss_mean": 0.02996714599430561, "eval/reward_loss_std": 0.47449806332588196, "eval/reward_max_data": 0.8062499761581421, "eval/reward_max_pred": 0.6142594814300537, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.004547109827399254, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.681253433227539, "eval/reward_pred": 0.0018464647000655532, "eval/reward_rate": 0.0029296875, "replay/size": 868001.0, "replay/inserts": 32352.0, "replay/samples": 32352.0, "replay/insert_wait_avg": 1.3018176180672575e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.451612329152878e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4648.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1369509048593228e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.417537689209, "timer/env.step_count": 4044.0, "timer/env.step_total": 38.96717858314514, "timer/env.step_frac": 0.03895091510805835, "timer/env.step_avg": 0.009635800836583863, "timer/env.step_min": 0.007660388946533203, "timer/env.step_max": 0.03569436073303223, "timer/replay._sample_count": 32352.0, "timer/replay._sample_total": 16.48246479034424, "timer/replay._sample_frac": 0.01647558561239927, "timer/replay._sample_avg": 0.0005094728236382369, "timer/replay._sample_min": 0.0004062652587890625, "timer/replay._sample_max": 0.027992963790893555, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4625.0, "timer/agent.policy_total": 47.959349632263184, "timer/agent.policy_frac": 0.04793933315387589, "timer/agent.policy_avg": 0.010369589109678527, "timer/agent.policy_min": 0.00841975212097168, "timer/agent.policy_max": 0.08115720748901367, "timer/dataset_train_count": 2022.0, "timer/dataset_train_total": 0.21102619171142578, "timer/dataset_train_frac": 0.00021093811709744682, "timer/dataset_train_avg": 0.00010436507997597714, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.00039649009704589844, "timer/agent.train_count": 2022.0, "timer/agent.train_total": 901.9541227817535, "timer/agent.train_frac": 0.9015776801205536, "timer/agent.train_avg": 0.4460702882204518, "timer/agent.train_min": 0.4333915710449219, "timer/agent.train_max": 0.7945246696472168, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47426581382751465, "timer/agent.report_frac": 0.00047406787262345125, "timer/agent.report_avg": 0.23713290691375732, "timer/agent.report_min": 0.22900032997131348, "timer/agent.report_max": 0.24526548385620117, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.0981479347907926e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 32.33797074031631}
{"step": 868704, "time": 27245.32841348648, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 868728, "time": 27245.846690177917, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 868856, "time": 27249.762865304947, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 868904, "time": 27251.224650621414, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 869040, "time": 27255.602625846863, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 869160, "time": 27259.04421520233, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 869384, "time": 27265.8679792881, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 869400, "time": 27266.390323877335, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 869576, "time": 27271.90734887123, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 869656, "time": 27274.349759101868, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 869984, "time": 27284.55654358864, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 870064, "time": 27288.093082904816, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 870064, "time": 27288.410615682602, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 870064, "time": 27288.492718935013, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 870064, "time": 27289.28023123741, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 870064, "time": 27289.967302560806, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 870064, "time": 27290.14689898491, "eval_episode/length": 167.0, "eval_episode/score": 0.4781250059604645, "eval_episode/reward_rate": 0.005952380952380952}
{"step": 870064, "time": 27290.28935623169, "eval_episode/length": 174.0, "eval_episode/score": 0.45625001192092896, "eval_episode/reward_rate": 0.005714285714285714}
{"step": 870064, "time": 27290.446706533432, "eval_episode/length": 182.0, "eval_episode/score": 0.4312500059604645, "eval_episode/reward_rate": 0.00546448087431694}
{"step": 870208, "time": 27294.827151060104, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 870232, "time": 27295.33771109581, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 870272, "time": 27296.77565574646, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 870416, "time": 27301.268849611282, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 870520, "time": 27304.21755552292, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 870560, "time": 27305.66290664673, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 870824, "time": 27313.460275411606, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 871040, "time": 27320.276944875717, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 871064, "time": 27320.78699684143, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 871112, "time": 27322.236488103867, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 871288, "time": 27327.60575389862, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 871320, "time": 27328.621632814407, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 871680, "time": 27339.8909637928, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 871752, "time": 27341.866869449615, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 871848, "time": 27344.794922828674, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 871984, "time": 27349.17818593979, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 872288, "time": 27358.452630758286, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 872400, "time": 27361.931913137436, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 872560, "time": 27366.79401254654, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 872664, "time": 27369.74418902397, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 872832, "time": 27375.063420534134, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 873056, "time": 27381.85592317581, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 873216, "time": 27386.699727535248, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 873504, "time": 27395.54839372635, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 873592, "time": 27398.011822223663, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 873736, "time": 27402.403038978577, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 873784, "time": 27403.869611740112, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 873864, "time": 27406.302611112595, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 873944, "time": 27408.748366832733, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 873992, "time": 27410.2149310112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 874104, "time": 27413.614588022232, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 874168, "time": 27415.55441570282, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 874456, "time": 27424.40974020958, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 874768, "time": 27434.095083236694, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 874808, "time": 27435.08590888977, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 875024, "time": 27441.890643835068, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 875080, "time": 27443.381971359253, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 875160, "time": 27445.832408428192, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 875328, "time": 27451.287682533264, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 875344, "time": 27451.777856111526, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 875392, "time": 27453.23387145996, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 875536, "time": 27457.61595249176, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 875576, "time": 27458.611454486847, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 875784, "time": 27464.93633556366, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 875848, "time": 27466.900859355927, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 876008, "time": 27471.76512861252, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 876080, "time": 27474.181855916977, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 876184, "time": 27477.144263744354, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 876368, "time": 27483.107248544693, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 876520, "time": 27487.51131772995, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 876640, "time": 27491.86104106903, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 876800, "time": 27496.721935510635, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 876864, "time": 27498.66723227501, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 877160, "time": 27507.423769950867, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 877208, "time": 27508.876215934753, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 877360, "time": 27513.785227537155, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 877568, "time": 27520.079629182816, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 877712, "time": 27524.435498714447, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 877808, "time": 27527.32870364189, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 877984, "time": 27532.647954940796, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 878016, "time": 27533.62731194496, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 878224, "time": 27539.957004785538, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 878272, "time": 27541.52663397789, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 878352, "time": 27543.954946517944, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 878480, "time": 27547.811521291733, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 878584, "time": 27550.7634036541, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 879328, "time": 27573.602725982666, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 879440, "time": 27576.985725402832, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 879768, "time": 27586.662960767746, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 879784, "time": 27587.154505968094, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 879816, "time": 27588.147587537766, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 879984, "time": 27593.47265148163, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 27595.40140557289, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 27597.260642290115, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 880048, "time": 27597.26636481285, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 880048, "time": 27597.52462863922, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 880048, "time": 27597.728276729584, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 880048, "time": 27597.871371030807, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 880048, "time": 27598.355452299118, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 880048, "time": 27598.902101039886, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 880048, "time": 27599.165811538696, "eval_episode/length": 162.0, "eval_episode/score": 0.4937500059604645, "eval_episode/reward_rate": 0.006134969325153374}
{"step": 880248, "time": 27605.069097042084, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 880312, "time": 27607.006613969803, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 880848, "time": 27623.55651450157, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 880904, "time": 27625.06433582306, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 881176, "time": 27633.45274734497, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 881200, "time": 27634.406209230423, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 881256, "time": 27635.900963306427, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 881560, "time": 27645.119176387787, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 881592, "time": 27646.083367824554, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 881600, "time": 27646.55119729042, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 881600, "time": 27646.558491706848, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 881848, "time": 27653.823128461838, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 881944, "time": 27656.742732524872, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 882176, "time": 27664.07759666443, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 882296, "time": 27667.503169298172, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 882344, "time": 27668.95112681389, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 882424, "time": 27671.395456552505, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 882496, "time": 27673.793724298477, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 882608, "time": 27677.215220689774, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 882672, "time": 27679.187352895737, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 882912, "time": 27686.516388893127, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 883088, "time": 27691.922708034515, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 883104, "time": 27692.417371749878, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 883152, "time": 27693.902791261673, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 883352, "time": 27699.76939868927, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 883496, "time": 27704.13372683525, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 883496, "time": 27704.140281677246, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 883784, "time": 27712.86911702156, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 884048, "time": 27721.295914411545, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 884168, "time": 27724.751195669174, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 884320, "time": 27729.61898136139, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 884400, "time": 27732.061367034912, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 884496, "time": 27734.99128818512, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 884544, "time": 27736.440203666687, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 884968, "time": 27749.529910087585, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 884976, "time": 27749.998755455017, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 885032, "time": 27751.608637332916, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 885080, "time": 27753.083573818207, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 885112, "time": 27754.065316915512, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 885224, "time": 27757.467900276184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 885240, "time": 27757.98279762268, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 885272, "time": 27758.960992097855, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 885616, "time": 27769.70501089096, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 885984, "time": 27781.122052669525, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 886016, "time": 27782.102712392807, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 886064, "time": 27783.566281557083, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 886096, "time": 27784.533058404922, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 886216, "time": 27787.958218812943, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 886360, "time": 27792.331074476242, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 886512, "time": 27797.167660951614, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 886704, "time": 27803.00084233284, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 886712, "time": 27803.02895617485, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 886728, "time": 27803.518137693405, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 886792, "time": 27805.474603176117, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 887240, "time": 27819.167799949646, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 887240, "time": 27819.175078868866, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 887576, "time": 27829.377373218536, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 887656, "time": 27831.82914018631, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 887736, "time": 27834.250987052917, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 887968, "time": 27841.620075941086, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 888016, "time": 27843.08478951454, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 888240, "time": 27849.887204885483, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 888504, "time": 27857.69939804077, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 888704, "time": 27864.06884121895, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 888704, "time": 27864.076536655426, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 888808, "time": 27867.085655927658, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 888808, "time": 27867.09428358078, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 889104, "time": 27876.426493167877, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 889288, "time": 27881.76937508583, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 889320, "time": 27882.763068199158, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 889392, "time": 27885.201627969742, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 889416, "time": 27885.711304426193, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 889816, "time": 27897.83763885498, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 889840, "time": 27898.789870738983, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 889848, "time": 27898.817571878433, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 889856, "time": 27899.28523659706, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 890032, "time": 27906.106955051422, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 890032, "time": 27906.620463371277, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 890032, "time": 27907.07716679573, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 890032, "time": 27907.20665550232, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 890032, "time": 27907.332840442657, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 890032, "time": 27907.53219151497, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 890032, "time": 27907.558183431625, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 890032, "time": 27907.78557753563, "eval_episode/length": 166.0, "eval_episode/score": 0.48124998807907104, "eval_episode/reward_rate": 0.005988023952095809}
{"step": 890064, "time": 27908.754335403442, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 890192, "time": 27912.63860654831, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 890224, "time": 27913.616021871567, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 890360, "time": 27917.53933930397, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 890488, "time": 27921.401663541794, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 890592, "time": 27924.78100848198, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 890632, "time": 27925.76810979843, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 890688, "time": 27927.704704523087, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 890768, "time": 27930.121034383774, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 890952, "time": 27935.56400680542, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 891032, "time": 27938.01625227928, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 891176, "time": 27942.373343229294, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 891176, "time": 27942.382264375687, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 891384, "time": 27948.681698083878, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 891632, "time": 27956.418481111526, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 891688, "time": 27957.88636469841, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 891800, "time": 27961.377465963364, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 891800, "time": 27961.38423895836, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 892120, "time": 27971.040489196777, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 892168, "time": 27972.48683309555, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 892376, "time": 27978.7708902359, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 892576, "time": 27985.03924536705, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 892616, "time": 27986.04438018799, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 892744, "time": 27989.920726060867, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 892864, "time": 27993.88508939743, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 892936, "time": 27996.067187309265, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 892992, "time": 27998.265219449997, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 893024, "time": 27999.23920559883, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 893176, "time": 28003.642194747925, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 893280, "time": 28007.053579330444, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 893352, "time": 28009.01366209984, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 893584, "time": 28016.294882297516, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 893592, "time": 28016.321960926056, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 893792, "time": 28022.669191122055, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 893872, "time": 28025.096640110016, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 893896, "time": 28025.607828378677, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 894240, "time": 28036.22523832321, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 894456, "time": 28042.550253152847, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 894568, "time": 28045.960659742355, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 894648, "time": 28048.39195919037, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 894680, "time": 28049.38773584366, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 894800, "time": 28053.308794498444, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 895048, "time": 28060.615072965622, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 895160, "time": 28064.00284934044, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 895480, "time": 28073.623598575592, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 895480, "time": 28073.630668640137, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 895576, "time": 28076.52292227745, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 895624, "time": 28077.983275175095, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 895816, "time": 28083.982684135437, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 895936, "time": 28087.846894979477, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 896032, "time": 28090.787213087082, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 896088, "time": 28092.25639820099, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 896264, "time": 28097.60504436493, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 896392, "time": 28101.504114627838, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 896432, "time": 28102.97003698349, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 896576, "time": 28107.317263364792, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 896872, "time": 28116.179205179214, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 896888, "time": 28116.671131134033, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 897000, "time": 28120.09591627121, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 897168, "time": 28125.429347991943, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 897376, "time": 28131.777814388275, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 897736, "time": 28142.588982343674, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 897968, "time": 28149.818141937256, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 897992, "time": 28150.337431192398, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 898008, "time": 28150.838607788086, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 898072, "time": 28152.81039261818, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 898096, "time": 28153.75817155838, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 898272, "time": 28159.105353355408, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 898320, "time": 28160.582536935806, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 898376, "time": 28162.104074001312, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 898584, "time": 28168.50669145584, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 898592, "time": 28168.987687587738, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 898608, "time": 28169.491493701935, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 898648, "time": 28170.66136264801, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 898784, "time": 28175.0561504364, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 898840, "time": 28176.554901361465, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 898920, "time": 28178.973437070847, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 898984, "time": 28180.91911506653, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 899088, "time": 28184.313967466354, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 899096, "time": 28184.34072327614, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 899464, "time": 28195.49073457718, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 899480, "time": 28195.99662041664, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 899544, "time": 28197.933272361755, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 899744, "time": 28204.286811113358, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 899872, "time": 28208.159652233124, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 899880, "time": 28208.188005924225, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 899976, "time": 28211.100626707077, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 900016, "time": 28212.867025136948, "eval_episode/length": 16.0, "eval_episode/score": 0.949999988079071, "eval_episode/reward_rate": 0.058823529411764705}
{"step": 900016, "time": 28213.72374510765, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 900016, "time": 28213.749905109406, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 900016, "time": 28213.983588933945, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 900016, "time": 28214.297186613083, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 900016, "time": 28214.864463567734, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 900016, "time": 28215.08193039894, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 900016, "time": 28215.50032567978, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 900176, "time": 28220.355615854263, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 900496, "time": 28230.029744386673, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 900656, "time": 28235.037001609802, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 900664, "time": 28235.06688261032, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 900704, "time": 28236.503286123276, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 900777, "time": 28239.45845723152, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.732395889735458, "train/action_min": 0.0, "train/action_std": 1.716703445604532, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010678078716454825, "train/actor_opt_grad_steps": 55195.0, "train/actor_opt_loss": -21.052869423781292, "train/adv_mag": 0.9284703129588967, "train/adv_max": 0.361227020178691, "train/adv_mean": 0.0012519545173268168, "train/adv_min": -0.849123473804776, "train/adv_std": 0.027374686760883227, "train/cont_avg": 0.9939134050123762, "train/cont_loss_mean": 0.018757326883439084, "train/cont_loss_std": 0.22422647402428164, "train/cont_neg_acc": 0.28189337511758994, "train/cont_neg_loss": 2.382024677378116, "train/cont_pos_acc": 0.9998541282545222, "train/cont_pos_loss": 0.004210649420147632, "train/cont_pred": 0.9941915731028755, "train/cont_rate": 0.9939134050123762, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12366680355539711, "train/extr_critic_critic_opt_grad_steps": 55195.0, "train/extr_critic_critic_opt_loss": 6008.7069200572405, "train/extr_critic_mag": 1.637554424824101, "train/extr_critic_max": 1.637554424824101, "train/extr_critic_mean": 1.5410810661788035, "train/extr_critic_min": 1.1522285460245492, "train/extr_critic_std": 0.03855893388390541, "train/extr_return_normed_mag": 0.9491308667872211, "train/extr_return_normed_max": 0.3070221773468622, "train/extr_return_normed_mean": 0.07275850014152503, "train/extr_return_normed_min": -0.8404490835595839, "train/extr_return_normed_std": 0.048689288695776226, "train/extr_return_rate": 0.9997051272651937, "train/extr_return_raw_mag": 1.7765965768606355, "train/extr_return_raw_max": 1.7765965768606355, "train/extr_return_raw_mean": 1.5423329803023007, "train/extr_return_raw_min": 0.6291253159541895, "train/extr_return_raw_std": 0.04868928868655521, "train/extr_reward_mag": 0.2663983366276958, "train/extr_reward_max": 0.2663983366276958, "train/extr_reward_mean": 0.0022806373072124207, "train/extr_reward_min": 5.8424354779838334e-08, "train/extr_reward_std": 0.0088073890748443, "train/image_loss_mean": 0.0961338016803902, "train/image_loss_std": 0.1074813844838945, "train/model_loss_mean": 0.7347716916315626, "train/model_loss_std": 0.498267107597082, "train/model_opt_grad_norm": 19.109691988123526, "train/model_opt_grad_steps": 55146.72772277228, "train/model_opt_loss": 3875.6439801206684, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5297.029702970297, "train/policy_entropy_mag": 1.326762601880744, "train/policy_entropy_max": 1.326762601880744, "train/policy_entropy_mean": 0.09093173478942106, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11155812453367922, "train/policy_logprob_mag": 6.551080250503993, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09088936794807415, "train/policy_logprob_min": -6.551080250503993, "train/policy_logprob_std": 0.6289541830520818, "train/policy_randomness_mag": 0.6818211423878623, "train/policy_randomness_max": 0.6818211423878623, "train/policy_randomness_mean": 0.04672966945436922, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.057329538932973795, "train/post_ent_mag": 40.16520383098338, "train/post_ent_max": 40.16520383098338, "train/post_ent_mean": 39.46414341312824, "train/post_ent_min": 38.74281826585826, "train/post_ent_std": 0.35226862973505907, "train/prior_ent_mag": 40.229642528118475, "train/prior_ent_max": 40.229642528118475, "train/prior_ent_mean": 38.970091810320866, "train/prior_ent_min": 37.76526131960425, "train/prior_ent_std": 0.3738941050106936, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0024847804896053994, "train/reward_loss_mean": 0.019880542556967327, "train/reward_loss_std": 0.26032253148698126, "train/reward_max_data": 0.7803527214149437, "train/reward_max_pred": 0.26399627888556754, "train/reward_neg_acc": 0.9996407147091214, "train/reward_neg_loss": 0.003484814742460183, "train/reward_pos_acc": 0.12030522180582161, "train/reward_pos_loss": 3.970833058380962, "train/reward_pred": 0.0018807749579762025, "train/reward_rate": 0.00412863551980198, "train_stats/mean_log_entropy": 0.07225096280435248, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.015021425671875477, "report/cont_loss_std": 0.18958356976509094, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 2.619746208190918, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004806817509233952, "report/cont_pred": 0.9943215847015381, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10095256567001343, "report/image_loss_std": 0.11331970244646072, "report/model_loss_mean": 0.7300769686698914, "report/model_loss_std": 0.419086217880249, "report/post_ent_mag": 40.067481994628906, "report/post_ent_max": 40.067481994628906, "report/post_ent_mean": 39.22954559326172, "report/post_ent_min": 38.14684295654297, "report/post_ent_std": 0.43097972869873047, "report/prior_ent_mag": 39.77046585083008, "report/prior_ent_max": 39.77046585083008, "report/prior_ent_mean": 38.80727767944336, "report/prior_ent_min": 36.98200988769531, "report/prior_ent_std": 0.4342433512210846, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0011749267578125, "report/reward_loss_mean": 0.014102970249950886, "report/reward_loss_std": 0.22061333060264587, "report/reward_max_data": 0.856249988079071, "report/reward_max_pred": 0.1844191551208496, "report/reward_neg_acc": 0.9990215301513672, "report/reward_neg_loss": 0.004394973628222942, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.974888801574707, "report/reward_pred": 0.001941914320923388, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.043618910014629364, "eval/cont_loss_std": 0.6143624186515808, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.04725980758667, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0023400846403092146, "eval/cont_pred": 0.9976122379302979, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16709116101264954, "eval/image_loss_std": 0.1438140720129013, "eval/model_loss_mean": 0.8377104997634888, "eval/model_loss_std": 1.010046362876892, "eval/post_ent_mag": 40.08403015136719, "eval/post_ent_max": 40.08403015136719, "eval/post_ent_mean": 39.09471130371094, "eval/post_ent_min": 38.39535140991211, "eval/post_ent_std": 0.39475956559181213, "eval/prior_ent_mag": 39.77046585083008, "eval/prior_ent_max": 39.77046585083008, "eval/prior_ent_mean": 38.74272155761719, "eval/prior_ent_min": 37.30388641357422, "eval/prior_ent_std": 0.4073641300201416, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0026031495071947575, "eval/reward_loss_mean": 0.027000438421964645, "eval/reward_loss_std": 0.4516165852546692, "eval/reward_max_data": 0.8656250238418579, "eval/reward_max_pred": 0.0897066593170166, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.0018826584564521909, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.432034015655518, "eval/reward_pred": 0.0008701782207936049, "eval/reward_rate": 0.00390625, "replay/size": 900273.0, "replay/inserts": 32272.0, "replay/samples": 32272.0, "replay/insert_wait_avg": 1.2929213773985577e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.410169416095694e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5360.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0982823016038583e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1920928955078125e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2376041412354, "timer/env.step_count": 4034.0, "timer/env.step_total": 38.85000681877136, "timer/env.step_frac": 0.0388407780890486, "timer/env.step_avg": 0.009630641254033555, "timer/env.step_min": 0.007677555084228516, "timer/env.step_max": 0.044825077056884766, "timer/replay._sample_count": 32272.0, "timer/replay._sample_total": 16.534682512283325, "timer/replay._sample_frac": 0.016530754736500185, "timer/replay._sample_avg": 0.0005123538210300981, "timer/replay._sample_min": 0.0003647804260253906, "timer/replay._sample_max": 0.04365372657775879, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4704.0, "timer/agent.policy_total": 48.735514879226685, "timer/agent.policy_frac": 0.04872393786981152, "timer/agent.policy_avg": 0.010360441088270979, "timer/agent.policy_min": 0.008834123611450195, "timer/agent.policy_max": 0.09201884269714355, "timer/dataset_train_count": 2017.0, "timer/dataset_train_total": 0.21195602416992188, "timer/dataset_train_frac": 0.00021190567450410843, "timer/dataset_train_avg": 0.00010508479135841441, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.0005180835723876953, "timer/agent.train_count": 2017.0, "timer/agent.train_total": 900.4989705085754, "timer/agent.train_frac": 0.9002850590502528, "timer/agent.train_avg": 0.4464546209759918, "timer/agent.train_min": 0.43334221839904785, "timer/agent.train_max": 0.6662535667419434, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47826147079467773, "timer/agent.report_frac": 0.00047814786088280916, "timer/agent.report_avg": 0.23913073539733887, "timer/agent.report_min": 0.2344985008239746, "timer/agent.report_max": 0.24376296997070312, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.390975952148438e-05, "timer/dataset_eval_frac": 7.389220242818244e-08, "timer/dataset_eval_avg": 7.390975952148438e-05, "timer/dataset_eval_min": 7.390975952148438e-05, "timer/dataset_eval_max": 7.390975952148438e-05, "fps": 32.26380427230107}
{"step": 900896, "time": 28243.020085811615, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 900928, "time": 28244.003190517426, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 901072, "time": 28248.375148296356, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 901440, "time": 28260.022833108902, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 901616, "time": 28265.51252055168, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 901680, "time": 28267.447357416153, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 901816, "time": 28271.356256484985, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 901832, "time": 28271.842062473297, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 901848, "time": 28272.330337047577, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 901872, "time": 28273.30318045616, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 902248, "time": 28284.396161794662, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 902392, "time": 28288.745538949966, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 902464, "time": 28291.24218058586, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 902528, "time": 28293.195086717606, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 902552, "time": 28293.703219652176, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 902800, "time": 28301.386688232422, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 903200, "time": 28313.47371339798, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 903304, "time": 28316.428648233414, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 903432, "time": 28320.3631439209, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 903432, "time": 28320.396266222, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 903448, "time": 28320.914588212967, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 903512, "time": 28322.864033937454, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 903688, "time": 28328.182689666748, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 903880, "time": 28333.97523546219, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 903920, "time": 28335.40280365944, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 903960, "time": 28336.414689302444, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 904112, "time": 28341.231526374817, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 904472, "time": 28352.072713136673, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 904496, "time": 28353.022568941116, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 904536, "time": 28354.007529973984, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 904808, "time": 28362.188671588898, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 904856, "time": 28363.63366627693, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 905320, "time": 28377.61797976494, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 905400, "time": 28380.065712213516, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 905440, "time": 28381.629797697067, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 905512, "time": 28383.580586910248, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 905792, "time": 28392.34983062744, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 905816, "time": 28392.868426322937, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 905824, "time": 28393.342200517654, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 905848, "time": 28393.860356092453, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 906000, "time": 28398.720083236694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 906464, "time": 28412.861669063568, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 906480, "time": 28413.3473007679, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 906936, "time": 28426.854778766632, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 907080, "time": 28431.200887680054, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 907104, "time": 28432.158331871033, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 907384, "time": 28440.507832050323, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 907584, "time": 28446.7926530838, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 907600, "time": 28447.287944555283, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 907696, "time": 28450.218316316605, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 907704, "time": 28450.24662208557, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 907944, "time": 28457.545268297195, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 907968, "time": 28458.51726412773, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 907984, "time": 28459.01343679428, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 908048, "time": 28460.95934033394, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 908512, "time": 28475.226215600967, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 908608, "time": 28478.145892620087, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 908976, "time": 28489.27130675316, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 909000, "time": 28489.78045487404, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 909080, "time": 28492.20160984993, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 909320, "time": 28499.659206151962, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 909336, "time": 28500.542242527008, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 909376, "time": 28501.98397755623, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 909512, "time": 28505.896463871002, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 909528, "time": 28506.38854765892, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 909736, "time": 28512.724493026733, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 909760, "time": 28513.67541527748, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 910000, "time": 28522.01197862625, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 910000, "time": 28522.217581510544, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 910000, "time": 28522.46258831024, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 910000, "time": 28522.56560111046, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 910000, "time": 28522.79316520691, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 910000, "time": 28523.31358385086, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 910000, "time": 28523.33800625801, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 910000, "time": 28523.36315560341, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 910016, "time": 28523.85115122795, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 910128, "time": 28527.271426200867, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 910192, "time": 28529.235206604004, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 910264, "time": 28531.301623106003, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 910616, "time": 28541.96166229248, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 910648, "time": 28542.935981035233, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 910808, "time": 28547.796705007553, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 910808, "time": 28547.808178901672, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 911096, "time": 28556.569867134094, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 911288, "time": 28562.498462677002, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 911616, "time": 28572.6664083004, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 911616, "time": 28572.674048662186, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 911808, "time": 28578.488651514053, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 911840, "time": 28579.464515686035, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 911936, "time": 28582.35773086548, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 912000, "time": 28584.346965551376, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 912176, "time": 28589.70605134964, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 912288, "time": 28593.21804857254, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 912568, "time": 28601.48113155365, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 912608, "time": 28602.927257299423, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 912656, "time": 28604.373594999313, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 912792, "time": 28608.284519910812, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 912984, "time": 28614.114218711853, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 913256, "time": 28622.411413908005, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 913504, "time": 28630.182708501816, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 913656, "time": 28634.551454782486, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 913680, "time": 28635.509835243225, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 913736, "time": 28636.997542142868, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 913896, "time": 28641.82511973381, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 914056, "time": 28646.65166091919, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 914304, "time": 28654.492339849472, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 914432, "time": 28658.383605718613, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 914608, "time": 28663.769994735718, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 914760, "time": 28668.254326343536, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 914832, "time": 28670.710861682892, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 914856, "time": 28671.227771282196, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 914856, "time": 28671.2349588871, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 914880, "time": 28672.201983213425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 915104, "time": 28679.05846095085, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 915208, "time": 28682.144139766693, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 915448, "time": 28689.418399095535, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 915776, "time": 28699.616857290268, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 915824, "time": 28701.09845161438, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 915904, "time": 28703.520563602448, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 916040, "time": 28707.426151037216, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 916048, "time": 28707.89866423607, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 916184, "time": 28711.921021461487, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 916312, "time": 28715.809463500977, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 916368, "time": 28717.73890709877, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 916456, "time": 28720.20794558525, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 916480, "time": 28721.1738781929, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 916992, "time": 28738.084699869156, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 917016, "time": 28738.596001148224, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 917256, "time": 28746.070118188858, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 917280, "time": 28747.029817819595, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 917424, "time": 28751.40156698227, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 917560, "time": 28755.75365447998, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 917592, "time": 28756.723251581192, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 917616, "time": 28757.671226501465, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 917720, "time": 28760.622970104218, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 917952, "time": 28767.885865688324, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 918000, "time": 28769.343093156815, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 918120, "time": 28772.873237848282, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 918136, "time": 28773.364559173584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 918656, "time": 28789.430859565735, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 918768, "time": 28792.84799027443, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 918896, "time": 28796.744127750397, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 919008, "time": 28800.17686533928, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 919080, "time": 28802.26961994171, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 919136, "time": 28804.20619893074, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 919176, "time": 28805.22354030609, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 919576, "time": 28817.399667024612, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 919592, "time": 28817.89095044136, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 919736, "time": 28822.26627969742, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 919904, "time": 28827.63582634926, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 920088, "time": 28834.099641561508, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 920088, "time": 28834.740037441254, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 920088, "time": 28834.941546201706, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 920088, "time": 28835.31306695938, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 920088, "time": 28836.010617733, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 920088, "time": 28836.238995552063, "eval_episode/length": 164.0, "eval_episode/score": 0.48750001192092896, "eval_episode/reward_rate": 0.006060606060606061}
{"step": 920088, "time": 28836.356840133667, "eval_episode/length": 170.0, "eval_episode/score": 0.46875, "eval_episode/reward_rate": 0.005847953216374269}
{"step": 920088, "time": 28836.457114696503, "eval_episode/length": 175.0, "eval_episode/score": 0.453125, "eval_episode/reward_rate": 0.005681818181818182}
{"step": 920104, "time": 28836.95570755005, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 920168, "time": 28838.91719508171, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 920184, "time": 28839.403688192368, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 920240, "time": 28841.326338768005, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 920336, "time": 28844.250813007355, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 920696, "time": 28854.9716258049, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 921104, "time": 28867.72539138794, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 921104, "time": 28867.732000112534, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 921160, "time": 28869.204936027527, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 921216, "time": 28871.125802993774, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 921344, "time": 28875.00349164009, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 921448, "time": 28877.9725253582, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 921488, "time": 28879.411895751953, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 921880, "time": 28891.21690940857, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 922136, "time": 28898.97390985489, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 922248, "time": 28902.40645980835, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 922288, "time": 28903.847990751266, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 922648, "time": 28914.5822558403, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 922680, "time": 28915.57704949379, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 922792, "time": 28918.997099399567, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 922968, "time": 28924.47455883026, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 923008, "time": 28925.92925643921, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 923152, "time": 28930.316408634186, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 923232, "time": 28932.74204802513, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 923384, "time": 28937.1380879879, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 923656, "time": 28945.3966255188, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 923672, "time": 28945.88581252098, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 923856, "time": 28951.80864596367, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 923888, "time": 28952.795818567276, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 923920, "time": 28953.767469644547, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 924328, "time": 28965.962874889374, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 924384, "time": 28967.880619049072, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 924712, "time": 28977.60876584053, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 924976, "time": 28986.002145767212, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 924976, "time": 28986.012633562088, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 925024, "time": 28987.48008465767, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 925096, "time": 28989.45357108116, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 925208, "time": 28992.839384317398, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.0}
{"step": 925296, "time": 28995.746685266495, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 925296, "time": 28995.752794981003, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 925328, "time": 28996.725211143494, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 925480, "time": 29001.129356861115, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 925688, "time": 29007.449473381042, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 925720, "time": 29008.918870449066, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 925976, "time": 29016.798316955566, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 926360, "time": 29028.509484529495, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 926456, "time": 29031.450734376907, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 926568, "time": 29034.87170481682, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 926696, "time": 29038.790167093277, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 926784, "time": 29041.81745839119, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 926968, "time": 29047.23138165474, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 927008, "time": 29048.685271263123, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 927016, "time": 29048.712770938873, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 927032, "time": 29049.203159332275, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 927072, "time": 29050.644242286682, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 927152, "time": 29053.109586954117, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 927704, "time": 29069.688195705414, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 927848, "time": 29074.217185735703, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 927864, "time": 29074.71298646927, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 927880, "time": 29075.208759069443, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 928000, "time": 29079.08617901802, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 928216, "time": 29085.45903944969, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 928232, "time": 29085.954196214676, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 928448, "time": 29092.869952201843, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 928760, "time": 29102.33895921707, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 928912, "time": 29107.165923833847, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 928952, "time": 29108.15785098076, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 929112, "time": 29113.086683750153, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 929216, "time": 29116.525829076767, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 929248, "time": 29117.53517460823, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 929464, "time": 29123.97985315323, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 929496, "time": 29124.98002433777, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 929576, "time": 29127.46276283264, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 929656, "time": 29129.897667884827, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 929744, "time": 29132.90760064125, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 930072, "time": 29144.04490828514, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 930072, "time": 29144.131393432617, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 930072, "time": 29144.365797758102, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 930072, "time": 29145.212265253067, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 930072, "time": 29145.220702409744, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 930072, "time": 29145.391739845276, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 930072, "time": 29145.566570281982, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 930072, "time": 29146.08893609047, "eval_episode/length": 180.0, "eval_episode/score": 0.4375, "eval_episode/reward_rate": 0.0055248618784530384}
{"step": 930096, "time": 29147.05004119873, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 930192, "time": 29149.982640504837, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 930208, "time": 29150.4728474617, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 930440, "time": 29157.282431602478, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 930520, "time": 29159.731925725937, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 930528, "time": 29160.240606307983, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 930584, "time": 29161.78413105011, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 930872, "time": 29170.503016471863, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 930872, "time": 29170.510749340057, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 931088, "time": 29177.266474723816, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 931216, "time": 29181.22964167595, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 931456, "time": 29188.50369143486, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 931480, "time": 29189.036566495895, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 931504, "time": 29189.99317908287, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 931688, "time": 29195.510547876358, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 931824, "time": 29199.874599695206, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 931888, "time": 29201.82228565216, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 932120, "time": 29208.69219636917, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 932232, "time": 29212.119559049606, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 932416, "time": 29217.955261468887, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 932432, "time": 29218.46751332283, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 932760, "time": 29228.333458185196, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 932824, "time": 29230.275290489197, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 933032, "time": 29236.61805486679, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 933048, "time": 29237.111102342606, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 933097, "time": 29239.580901145935, "train_stats/mean_log_entropy": 0.07298307097709376, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.742787880472618, "train/action_min": 0.0, "train/action_std": 1.7336811045608898, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011073711128803985, "train/actor_opt_grad_steps": 57215.0, "train/actor_opt_loss": -22.731976962325597, "train/adv_mag": 0.8901225712039683, "train/adv_max": 0.3263784711903865, "train/adv_mean": 0.001144814261270668, "train/adv_min": -0.8194472010773007, "train/adv_std": 0.028224771759371357, "train/cont_avg": 0.9942131420173267, "train/cont_loss_mean": 0.018867018408981143, "train/cont_loss_std": 0.22177900745542628, "train/cont_neg_acc": 0.2460508593680835, "train/cont_neg_loss": 2.491712834722925, "train/cont_pos_acc": 0.9998443831901739, "train/cont_pos_loss": 0.004517684702756861, "train/cont_pred": 0.9941591614543801, "train/cont_rate": 0.9942131420173267, "train/dyn_loss_mean": 1.0000003080556887, "train/dyn_loss_std": 9.845113520058665e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14831208073451083, "train/extr_critic_critic_opt_grad_steps": 57215.0, "train/extr_critic_critic_opt_loss": 5525.823305035582, "train/extr_critic_mag": 1.667440916051959, "train/extr_critic_max": 1.667440916051959, "train/extr_critic_mean": 1.5621206075838296, "train/extr_critic_min": 1.2011019198021087, "train/extr_critic_std": 0.03955651479450488, "train/extr_return_normed_mag": 0.911257783375164, "train/extr_return_normed_max": 0.3024401027377289, "train/extr_return_normed_mean": 0.07656842082886413, "train/extr_return_normed_min": -0.8013420937084915, "train/extr_return_normed_std": 0.04967495094579045, "train/extr_return_rate": 0.9997402577116938, "train/extr_return_raw_mag": 1.789137081934674, "train/extr_return_raw_max": 1.789137081934674, "train/extr_return_raw_mean": 1.5632654788470504, "train/extr_return_raw_min": 0.6853548854884535, "train/extr_return_raw_std": 0.04967495090890639, "train/extr_reward_mag": 0.24461758136749268, "train/extr_reward_max": 0.24461758136749268, "train/extr_reward_mean": 0.0023987875997185672, "train/extr_reward_min": 3.068753988435953e-08, "train/extr_reward_std": 0.009296454399326208, "train/image_loss_mean": 0.09763272169350397, "train/image_loss_std": 0.10905680672662092, "train/model_loss_mean": 0.7367469541507192, "train/model_loss_std": 0.4959409472965958, "train/model_opt_grad_norm": 19.207860016586757, "train/model_opt_grad_steps": 57164.88613861386, "train/model_opt_loss": 3977.8305301477412, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5396.039603960396, "train/policy_entropy_mag": 1.3400499496129479, "train/policy_entropy_max": 1.3400499496129479, "train/policy_entropy_mean": 0.09032152261179273, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10982763420532246, "train/policy_logprob_mag": 6.551080245782833, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0908541817697558, "train/policy_logprob_min": -6.551080245782833, "train/policy_logprob_std": 0.6310565279852046, "train/policy_randomness_mag": 0.6886494897379734, "train/policy_randomness_max": 0.6886494897379734, "train/policy_randomness_mean": 0.04641608344298778, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05644024244629511, "train/post_ent_mag": 40.472371167475636, "train/post_ent_max": 40.472371167475636, "train/post_ent_mean": 39.725195327607715, "train/post_ent_min": 38.9497280309696, "train/post_ent_std": 0.3771040002898415, "train/prior_ent_mag": 40.10904168610526, "train/prior_ent_max": 40.10904168610526, "train/prior_ent_mean": 38.97046379995818, "train/prior_ent_min": 38.01520247506623, "train/prior_ent_std": 0.33769574569593563, "train/rep_loss_mean": 1.0000003080556887, "train/rep_loss_std": 9.845113520058665e-06, "train/reward_avg": 0.002514134774371834, "train/reward_loss_mean": 0.020247007804890485, "train/reward_loss_std": 0.2590804256655571, "train/reward_max_data": 0.7698793300602695, "train/reward_max_pred": 0.261542280121605, "train/reward_neg_acc": 0.9996020407369821, "train/reward_neg_loss": 0.0038107042875150125, "train/reward_pos_acc": 0.13620623612581795, "train/reward_pos_loss": 3.942144668369151, "train/reward_pred": 0.002033556215603384, "train/reward_rate": 0.004186649133663367, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.015533825382590294, "report/cont_loss_std": 0.20214208960533142, "report/cont_neg_acc": 0.4285714626312256, "report/cont_neg_loss": 1.8393141031265259, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0029807656537741423, "report/cont_pred": 0.994107186794281, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07610456645488739, "report/image_loss_std": 0.09993873536586761, "report/model_loss_mean": 0.7127383947372437, "report/model_loss_std": 0.5217695236206055, "report/post_ent_mag": 40.496063232421875, "report/post_ent_max": 40.496063232421875, "report/post_ent_mean": 39.674522399902344, "report/post_ent_min": 38.96271514892578, "report/post_ent_std": 0.43492627143859863, "report/prior_ent_mag": 39.90964889526367, "report/prior_ent_max": 39.90964889526367, "report/prior_ent_mean": 38.80821990966797, "report/prior_ent_min": 38.01321029663086, "report/prior_ent_std": 0.32864293456077576, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0035156249068677425, "report/reward_loss_mean": 0.02109997719526291, "report/reward_loss_std": 0.287601113319397, "report/reward_max_data": 0.9156249761581421, "report/reward_max_pred": 0.6320874691009521, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0028084651567041874, "report/reward_pos_acc": 0.20000000298023224, "report/reward_pos_loss": 3.7489101886749268, "report/reward_pred": 0.0019524043891578913, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.03217195346951485, "eval/cont_loss_std": 0.41654348373413086, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.2023844718933105, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.006802902556955814, "eval/cont_pred": 0.9951207637786865, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11035702377557755, "eval/image_loss_std": 0.11719322949647903, "eval/model_loss_mean": 0.7603992819786072, "eval/model_loss_std": 0.6033276915550232, "eval/post_ent_mag": 40.52760314941406, "eval/post_ent_max": 40.52760314941406, "eval/post_ent_mean": 39.70182418823242, "eval/post_ent_min": 38.98377990722656, "eval/post_ent_std": 0.382442831993103, "eval/prior_ent_mag": 39.90964889526367, "eval/prior_ent_max": 39.90964889526367, "eval/prior_ent_mean": 38.79779815673828, "eval/prior_ent_min": 37.89814758300781, "eval/prior_ent_std": 0.34116995334625244, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.00201416015625, "eval/reward_loss_mean": 0.01787029206752777, "eval/reward_loss_std": 0.25439533591270447, "eval/reward_max_data": 0.903124988079071, "eval/reward_max_pred": 0.3027580976486206, "eval/reward_neg_acc": 0.9960822463035583, "eval/reward_neg_loss": 0.004269603174179792, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.646637916564941, "eval/reward_pred": 0.0018803583225235343, "eval/reward_rate": 0.0029296875, "replay/size": 932593.0, "replay/inserts": 32320.0, "replay/samples": 32320.0, "replay/insert_wait_avg": 1.3118775764314255e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.456555815026312e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3896.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.064132616015675e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.104095697403, "timer/env.step_count": 4040.0, "timer/env.step_total": 39.04786205291748, "timer/env.step_frac": 0.03904379776156023, "timer/env.step_avg": 0.00966531238933601, "timer/env.step_min": 0.0076940059661865234, "timer/env.step_max": 0.06317758560180664, "timer/replay._sample_count": 32320.0, "timer/replay._sample_total": 16.428683280944824, "timer/replay._sample_frac": 0.016426973303702557, "timer/replay._sample_avg": 0.0005083132203262631, "timer/replay._sample_min": 0.00039386749267578125, "timer/replay._sample_max": 0.010879993438720703, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4527.0, "timer/agent.policy_total": 46.87085723876953, "timer/agent.policy_frac": 0.046865978692033114, "timer/agent.policy_avg": 0.010353624307216596, "timer/agent.policy_min": 0.00867009162902832, "timer/agent.policy_max": 0.07654881477355957, "timer/dataset_train_count": 2020.0, "timer/dataset_train_total": 0.21260714530944824, "timer/dataset_train_frac": 0.00021258501612393742, "timer/dataset_train_avg": 0.00010525106203438032, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.00044608116149902344, "timer/agent.train_count": 2020.0, "timer/agent.train_total": 902.5722897052765, "timer/agent.train_frac": 0.902478345592501, "timer/agent.train_avg": 0.44681796520063194, "timer/agent.train_min": 0.4318246841430664, "timer/agent.train_max": 0.7577979564666748, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47501325607299805, "timer/agent.report_frac": 0.00047496381438349864, "timer/agent.report_avg": 0.23750662803649902, "timer/agent.report_min": 0.22992706298828125, "timer/agent.report_max": 0.2450861930847168, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.0276007943736957e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 32.316077926110275}
{"step": 933328, "time": 29246.625562906265, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 933392, "time": 29248.59200334549, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 933496, "time": 29251.65429854393, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 933520, "time": 29252.612993955612, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 933600, "time": 29255.065703630447, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 933776, "time": 29260.42698907852, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 933880, "time": 29263.374290704727, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 933960, "time": 29266.248518705368, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 933976, "time": 29266.739567756653, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 934424, "time": 29280.502728939056, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 934488, "time": 29282.45206427574, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 934568, "time": 29284.885843753815, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 934584, "time": 29285.378962278366, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 934720, "time": 29289.83509016037, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 934728, "time": 29289.866708755493, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 934896, "time": 29295.262552261353, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 934960, "time": 29297.19334745407, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 935336, "time": 29308.366476774216, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 935400, "time": 29310.3406791687, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 935408, "time": 29310.856738090515, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 935504, "time": 29313.77136540413, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 935696, "time": 29319.613185167313, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 935888, "time": 29325.455055952072, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 935928, "time": 29326.45689225197, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 936024, "time": 29329.39253640175, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 936120, "time": 29332.326389312744, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 936152, "time": 29333.29496192932, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 936296, "time": 29337.665867090225, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 936920, "time": 29356.84219479561, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 936976, "time": 29358.753037929535, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 936992, "time": 29359.241005420685, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 937176, "time": 29364.604500055313, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 937208, "time": 29365.58372426033, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 937416, "time": 29372.002913713455, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 937504, "time": 29374.886666297913, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 937568, "time": 29376.84687256813, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 937664, "time": 29379.75574183464, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 937904, "time": 29387.188002586365, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 938048, "time": 29391.627361536026, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 938152, "time": 29394.55137181282, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 938560, "time": 29407.31891965866, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 938624, "time": 29409.298127651215, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 938664, "time": 29410.292917966843, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 938776, "time": 29413.75405240059, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 939104, "time": 29424.11010146141, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 939232, "time": 29428.049108982086, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 939464, "time": 29435.028851509094, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 939568, "time": 29438.431433200836, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 939608, "time": 29439.430426359177, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 939904, "time": 29448.625904083252, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 939968, "time": 29450.584851026535, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 939992, "time": 29451.0936126709, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 940056, "time": 29453.720081806183, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 940056, "time": 29454.804001569748, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 940056, "time": 29455.35389971733, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 940056, "time": 29455.600897550583, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 940056, "time": 29455.681406974792, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 940056, "time": 29456.0432035923, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 940056, "time": 29456.220646381378, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 940056, "time": 29456.53597164154, "eval_episode/length": 16.0, "eval_episode/score": 0.949999988079071, "eval_episode/reward_rate": 0.058823529411764705}
{"step": 940328, "time": 29464.88388633728, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 940344, "time": 29465.371101617813, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 940368, "time": 29468.531725883484, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 940384, "time": 29469.026527404785, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 940416, "time": 29469.996385335922, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 940504, "time": 29472.45987677574, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 940552, "time": 29473.90812397003, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 940760, "time": 29480.267425060272, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 940792, "time": 29481.233221292496, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 941104, "time": 29491.038085460663, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 941200, "time": 29493.949015378952, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 941360, "time": 29498.802861452103, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 941616, "time": 29506.588317155838, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 941672, "time": 29508.06166768074, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 941680, "time": 29508.53066420555, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 941744, "time": 29510.490082979202, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 941768, "time": 29510.999423265457, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 942064, "time": 29520.22467970848, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 942184, "time": 29524.195883750916, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 942272, "time": 29527.091005802155, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 942656, "time": 29538.73500919342, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 942728, "time": 29540.70858860016, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 943008, "time": 29549.430218219757, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 943072, "time": 29551.490194797516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 943088, "time": 29551.98387145996, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 943320, "time": 29558.845097780228, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 943400, "time": 29561.254356861115, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 943576, "time": 29566.583595752716, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 943576, "time": 29566.595065116882, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 943600, "time": 29567.551842212677, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 943776, "time": 29572.878486394882, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 943832, "time": 29574.368916988373, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 944048, "time": 29581.23591041565, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 944064, "time": 29581.72817134857, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 944168, "time": 29584.667453050613, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 944200, "time": 29585.642293930054, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 944576, "time": 29597.269830942154, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 944648, "time": 29599.255544424057, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 944768, "time": 29603.130182266235, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 944816, "time": 29604.59362435341, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 945184, "time": 29615.8784096241, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 945224, "time": 29616.892939329147, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 945336, "time": 29620.32730460167, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 945416, "time": 29622.764796972275, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 945424, "time": 29623.23380303383, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 945464, "time": 29624.222990989685, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 946272, "time": 29649.05716228485, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 946328, "time": 29650.54558777809, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 946344, "time": 29651.033336400986, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 946456, "time": 29654.440284252167, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 946568, "time": 29657.857673883438, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 946592, "time": 29658.815610170364, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 946712, "time": 29662.242660999298, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 946728, "time": 29662.73947620392, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 946896, "time": 29668.08219218254, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 947304, "time": 29680.393489837646, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 947312, "time": 29680.88141655922, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 947472, "time": 29685.744867563248, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 947544, "time": 29687.700624465942, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 947608, "time": 29689.637514591217, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 947616, "time": 29690.111696958542, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 947832, "time": 29696.469249486923, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 947912, "time": 29698.90248155594, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 948112, "time": 29705.28235220909, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 948240, "time": 29709.14773583412, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 948392, "time": 29713.542062997818, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 948696, "time": 29722.790509700775, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 948744, "time": 29724.249657154083, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 948768, "time": 29725.21523118019, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 948848, "time": 29727.642547607422, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 949176, "time": 29737.445956468582, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 949224, "time": 29738.910141706467, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 949680, "time": 29752.936686992645, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 949784, "time": 29755.86917591095, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 950000, "time": 29762.744999170303, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 950040, "time": 29765.07886338234, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 950040, "time": 29765.259835243225, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 950040, "time": 29765.395206451416, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 950040, "time": 29765.45935177803, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 950040, "time": 29765.48428940773, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 950040, "time": 29765.60853767395, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 950040, "time": 29766.381187915802, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 950040, "time": 29766.750797510147, "eval_episode/length": 159.0, "eval_episode/score": 0.503125011920929, "eval_episode/reward_rate": 0.00625}
{"step": 950096, "time": 29768.66894364357, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 950192, "time": 29771.598479509354, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 950376, "time": 29777.429483413696, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 950488, "time": 29780.82743525505, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 950488, "time": 29780.840713262558, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 950568, "time": 29783.28023982048, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 950992, "time": 29796.500640392303, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 951024, "time": 29797.46741127968, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 951112, "time": 29799.912244319916, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 951168, "time": 29801.839916944504, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 951408, "time": 29809.098703622818, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 951520, "time": 29812.499963760376, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 951544, "time": 29813.007796049118, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 951704, "time": 29817.875602722168, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 951768, "time": 29819.815313577652, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 951840, "time": 29822.35501050949, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 951848, "time": 29822.38307929039, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 952256, "time": 29834.96545481682, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 952328, "time": 29836.9454703331, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 952408, "time": 29839.36732172966, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 952552, "time": 29843.733515501022, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 952640, "time": 29846.63546180725, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 952696, "time": 29848.108612298965, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 952712, "time": 29848.59809231758, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 952848, "time": 29853.08466720581, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 952968, "time": 29856.505692243576, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 953344, "time": 29868.116347312927, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 953400, "time": 29869.618007421494, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 953416, "time": 29870.105251789093, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 953576, "time": 29874.949697494507, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 953592, "time": 29875.44018483162, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 953664, "time": 29877.843104839325, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 953680, "time": 29878.33091688156, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 953960, "time": 29886.692651987076, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 954024, "time": 29888.629391908646, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 954216, "time": 29894.452761650085, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 954352, "time": 29898.80651330948, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 954720, "time": 29909.92267370224, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 954720, "time": 29909.930364131927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 954832, "time": 29913.430193901062, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 954976, "time": 29917.78843665123, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 955000, "time": 29918.3190741539, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 955064, "time": 29920.260991811752, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 955136, "time": 29922.658938884735, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 955408, "time": 29930.903293132782, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 955680, "time": 29939.1493165493, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 955712, "time": 29940.123912334442, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 956032, "time": 29949.907257318497, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 956072, "time": 29950.90067267418, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 956360, "time": 29959.634510040283, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 956480, "time": 29963.50150203705, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 956520, "time": 29964.496891498566, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 956552, "time": 29965.463628292084, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 956736, "time": 29971.366176366806, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 956776, "time": 29972.392292499542, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 956824, "time": 29973.852541208267, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 956856, "time": 29974.82741189003, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 957104, "time": 29982.57990694046, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 957152, "time": 29984.037885665894, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 957256, "time": 29986.97529411316, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 957696, "time": 30000.661294460297, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 957952, "time": 30008.463208675385, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 958032, "time": 30010.895113945007, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 958040, "time": 30010.922394514084, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 958048, "time": 30011.389387845993, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 958048, "time": 30011.39804840088, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 958352, "time": 30020.62213587761, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 958440, "time": 30023.05855679512, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 958536, "time": 30026.45659995079, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 958560, "time": 30027.410262346268, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 958680, "time": 30030.907403469086, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 958800, "time": 30034.767146110535, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 958896, "time": 30037.704622983932, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 959072, "time": 30043.055508613586, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 959440, "time": 30054.219316005707, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 959440, "time": 30054.22705101967, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 959568, "time": 30058.12078857422, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 959568, "time": 30058.129020929337, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 959696, "time": 30062.11478638649, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 959816, "time": 30065.53446149826, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 959816, "time": 30065.54226255417, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 959856, "time": 30066.97087287903, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 960024, "time": 30072.96653866768, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 960024, "time": 30073.123115062714, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 960024, "time": 30073.329268455505, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 960024, "time": 30073.481982946396, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 960024, "time": 30074.733491420746, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 960024, "time": 30075.580147504807, "eval_episode/length": 199.0, "eval_episode/score": 0.37812501192092896, "eval_episode/reward_rate": 0.005}
{"step": 960024, "time": 30075.625089883804, "eval_episode/length": 201.0, "eval_episode/score": 0.37187498807907104, "eval_episode/reward_rate": 0.0049504950495049506}
{"step": 960024, "time": 30075.711375951767, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 960048, "time": 30076.665328025818, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 960104, "time": 30078.163825035095, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 960536, "time": 30091.365253686905, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 960896, "time": 30102.482479572296, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 960976, "time": 30104.915600538254, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 961336, "time": 30115.586039543152, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 961344, "time": 30116.057980775833, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 961352, "time": 30116.086483240128, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 961448, "time": 30119.010489940643, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 961592, "time": 30123.489927768707, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 961616, "time": 30124.439764022827, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 961656, "time": 30125.432109832764, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 961688, "time": 30126.39451789856, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 961808, "time": 30130.271820783615, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 962248, "time": 30143.39457654953, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 962384, "time": 30147.76126050949, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 962584, "time": 30153.691084861755, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 962656, "time": 30156.080406665802, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 962728, "time": 30158.051527261734, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 962752, "time": 30158.995179891586, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 962896, "time": 30163.352065563202, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 963128, "time": 30170.145055294037, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 963136, "time": 30170.609790802002, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 963240, "time": 30173.549815893173, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 963248, "time": 30174.017843723297, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 963296, "time": 30175.46483898163, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 963736, "time": 30188.641437530518, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 963792, "time": 30190.580016851425, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 963920, "time": 30194.4307243824, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 963968, "time": 30195.89483642578, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 964224, "time": 30203.605360984802, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 964272, "time": 30205.084250450134, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 964384, "time": 30208.477510213852, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 964392, "time": 30208.50489282608, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 964416, "time": 30209.455463647842, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 964744, "time": 30219.351429462433, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 964816, "time": 30221.767914772034, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 964944, "time": 30225.6448431015, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 965032, "time": 30228.08098244667, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 965216, "time": 30233.875502347946, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 965272, "time": 30235.360187768936, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 965352, "time": 30237.792229413986, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 965385, "time": 30239.77864074707, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7815161978844367, "train/action_min": 0.0, "train/action_std": 1.7519870146666423, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011608359006251956, "train/actor_opt_grad_steps": 59235.0, "train/actor_opt_loss": -21.309282246202525, "train/adv_mag": 0.9441758975534156, "train/adv_max": 0.3311652670992483, "train/adv_mean": 0.0012443086751872134, "train/adv_min": -0.8897659657615247, "train/adv_std": 0.02823439197577905, "train/cont_avg": 0.9943146658415841, "train/cont_loss_mean": 0.01926780489762083, "train/cont_loss_std": 0.22662299030949132, "train/cont_neg_acc": 0.22508590587294927, "train/cont_neg_loss": 2.5885656382243085, "train/cont_pos_acc": 0.9998979028498772, "train/cont_pos_loss": 0.004523154497400184, "train/cont_pred": 0.9942461556137199, "train/cont_rate": 0.9943146658415841, "train/dyn_loss_mean": 1.0000138247367178, "train/dyn_loss_std": 0.00044218410212214633, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14887319354912137, "train/extr_critic_critic_opt_grad_steps": 59235.0, "train/extr_critic_critic_opt_loss": 6072.752564685179, "train/extr_critic_mag": 1.7052006532650184, "train/extr_critic_max": 1.7052006532650184, "train/extr_critic_mean": 1.5858440428677172, "train/extr_critic_min": 1.2379105793367517, "train/extr_critic_std": 0.041861719239761334, "train/extr_return_normed_mag": 0.9815990405507607, "train/extr_return_normed_max": 0.31902871332546273, "train/extr_return_normed_mean": 0.08167664413478705, "train/extr_return_normed_min": -0.883018402179869, "train/extr_return_normed_std": 0.05184498731747712, "train/extr_return_rate": 0.9997273686498699, "train/extr_return_raw_mag": 1.824440363610145, "train/extr_return_raw_max": 1.824440363610145, "train/extr_return_raw_mean": 1.587088373627993, "train/extr_return_raw_min": 0.6223932481048131, "train/extr_return_raw_std": 0.05184498740968728, "train/extr_reward_mag": 0.2542450616855432, "train/extr_reward_max": 0.2542450616855432, "train/extr_reward_mean": 0.0024837471451379803, "train/extr_reward_min": 1.1802899955522896e-09, "train/extr_reward_std": 0.00918549275957048, "train/image_loss_mean": 0.09651906390001277, "train/image_loss_std": 0.10756806177225443, "train/model_loss_mean": 0.7361113461527494, "train/model_loss_std": 0.5001700944313319, "train/model_opt_grad_norm": 18.15671426234859, "train/model_opt_grad_steps": 59182.91584158416, "train/model_opt_loss": 3717.12160982944, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5049.504950495049, "train/policy_entropy_mag": 1.3528312727956489, "train/policy_entropy_max": 1.3528312727956489, "train/policy_entropy_mean": 0.0936028255094396, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11645811597014417, "train/policy_logprob_mag": 6.5510802528645735, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09388083636318104, "train/policy_logprob_min": -6.5510802528645735, "train/policy_logprob_std": 0.6324200824935837, "train/policy_randomness_mag": 0.6952177899898869, "train/policy_randomness_max": 0.6952177899898869, "train/policy_randomness_mean": 0.048102339250173896, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05984763642496402, "train/post_ent_mag": 40.45614119803552, "train/post_ent_max": 40.45614119803552, "train/post_ent_mean": 39.71215161238567, "train/post_ent_min": 38.89824627413608, "train/post_ent_std": 0.39742853057266464, "train/prior_ent_mag": 40.00830057351896, "train/prior_ent_max": 40.00830057351896, "train/prior_ent_mean": 38.77756213197614, "train/prior_ent_min": 37.86837105703826, "train/prior_ent_std": 0.3452087968292803, "train/rep_loss_mean": 1.0000138247367178, "train/rep_loss_std": 0.00044218410212214633, "train/reward_avg": 0.0024979997281904913, "train/reward_loss_mean": 0.02031615800754453, "train/reward_loss_std": 0.2596713518908266, "train/reward_max_data": 0.7655476492525327, "train/reward_max_pred": 0.2357392181264292, "train/reward_neg_acc": 0.9996601939201355, "train/reward_neg_loss": 0.00384229322489683, "train/reward_pos_acc": 0.10461383713270302, "train/reward_pos_loss": 3.984092760441908, "train/reward_pred": 0.0020262834161870404, "train/reward_rate": 0.004138304455445545, "train_stats/mean_log_entropy": 0.07520547586370749, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.023118047043681145, "report/cont_loss_std": 0.30813074111938477, "report/cont_neg_acc": 0.2857142984867096, "report/cont_neg_loss": 2.8329038619995117, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003778323531150818, "report/cont_pred": 0.9944295883178711, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09320773929357529, "report/image_loss_std": 0.1131097599864006, "report/model_loss_mean": 0.7382310628890991, "report/model_loss_std": 0.5830524563789368, "report/post_ent_mag": 40.27436828613281, "report/post_ent_max": 40.27436828613281, "report/post_ent_mean": 39.58665466308594, "report/post_ent_min": 38.82270812988281, "report/post_ent_std": 0.3692907392978668, "report/prior_ent_mag": 39.82121276855469, "report/prior_ent_max": 39.82121276855469, "report/prior_ent_mean": 38.670265197753906, "report/prior_ent_min": 37.64940643310547, "report/prior_ent_std": 0.362087607383728, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0035491944290697575, "report/reward_loss_mean": 0.02190520614385605, "report/reward_loss_std": 0.2969391942024231, "report/reward_max_data": 0.909375011920929, "report/reward_max_pred": 0.324023962020874, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.003278726013377309, "report/reward_pos_acc": 0.20000000298023224, "report/reward_pos_loss": 3.8179821968078613, "report/reward_pred": 0.0018720132065936923, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.008046325296163559, "eval/cont_loss_std": 0.12348416447639465, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.931910276412964, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004210680723190308, "eval/cont_pred": 0.9958783984184265, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10525692999362946, "eval/image_loss_std": 0.116585373878479, "eval/model_loss_mean": 0.7226462364196777, "eval/model_loss_std": 0.34847694635391235, "eval/post_ent_mag": 40.29131317138672, "eval/post_ent_max": 40.29131317138672, "eval/post_ent_mean": 39.53511047363281, "eval/post_ent_min": 38.831565856933594, "eval/post_ent_std": 0.3712821900844574, "eval/prior_ent_mag": 39.82121276855469, "eval/prior_ent_max": 39.82121276855469, "eval/prior_ent_mean": 38.6996955871582, "eval/prior_ent_min": 37.815093994140625, "eval/prior_ent_std": 0.34863024950027466, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008972167852334678, "eval/reward_loss_mean": 0.009342948906123638, "eval/reward_loss_std": 0.19786973297595978, "eval/reward_max_data": 0.918749988079071, "eval/reward_max_pred": 0.11139225959777832, "eval/reward_neg_acc": 0.9990224838256836, "eval/reward_neg_loss": 0.0031707058660686016, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.323547840118408, "eval/reward_pred": 0.0014036103384569287, "eval/reward_rate": 0.0009765625, "replay/size": 964881.0, "replay/inserts": 32288.0, "replay/samples": 32288.0, "replay/insert_wait_avg": 1.292480054293917e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.44674085271134e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4176.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2001429481067877e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1801879405975, "timer/env.step_count": 4036.0, "timer/env.step_total": 38.879992961883545, "timer/env.step_frac": 0.03887298851813759, "timer/env.step_avg": 0.00963329855348948, "timer/env.step_min": 0.00763702392578125, "timer/env.step_max": 0.03557872772216797, "timer/replay._sample_count": 32288.0, "timer/replay._sample_total": 16.508339881896973, "timer/replay._sample_frac": 0.016505365814022135, "timer/replay._sample_avg": 0.0005112840647267398, "timer/replay._sample_min": 0.00041031837463378906, "timer/replay._sample_max": 0.028670549392700195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4558.0, "timer/agent.policy_total": 47.52668571472168, "timer/agent.policy_frac": 0.04751812352190321, "timer/agent.policy_avg": 0.010427092083089442, "timer/agent.policy_min": 0.008495330810546875, "timer/agent.policy_max": 0.08584022521972656, "timer/dataset_train_count": 2018.0, "timer/dataset_train_total": 0.21156787872314453, "timer/dataset_train_frac": 0.00021152976361066443, "timer/dataset_train_avg": 0.00010484037597777232, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.0005817413330078125, "timer/agent.train_count": 2018.0, "timer/agent.train_total": 902.8647515773773, "timer/agent.train_frac": 0.9027020955458078, "timer/agent.train_avg": 0.4474057242702564, "timer/agent.train_min": 0.4343416690826416, "timer/agent.train_max": 2.6536014080047607, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47581934928894043, "timer/agent.report_frac": 0.00047573362782626943, "timer/agent.report_avg": 0.23790967464447021, "timer/agent.report_min": 0.23040390014648438, "timer/agent.report_max": 0.24541544914245605, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.2895836482985525e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 32.281664686054064}
{"step": 965632, "time": 30247.36884212494, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 965696, "time": 30249.31402850151, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 965816, "time": 30252.732605695724, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 965928, "time": 30256.12762594223, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 966040, "time": 30259.53124475479, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 966056, "time": 30260.021599292755, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 966080, "time": 30260.969301462173, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 966608, "time": 30277.09420990944, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 966664, "time": 30278.811501264572, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 966672, "time": 30279.5448513031, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 966896, "time": 30286.316475391388, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 966976, "time": 30288.74078321457, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 967160, "time": 30294.10580587387, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 967472, "time": 30303.871041059494, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 967480, "time": 30303.89995265007, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 967760, "time": 30312.567509412766, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 967912, "time": 30316.953455924988, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 967928, "time": 30317.44376015663, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 968072, "time": 30321.808384418488, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 968328, "time": 30329.599251270294, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 968336, "time": 30330.067044496536, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 968392, "time": 30331.62380051613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 968480, "time": 30334.525803804398, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 968568, "time": 30336.957188367844, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 968712, "time": 30341.322999954224, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 968768, "time": 30343.253996133804, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 968984, "time": 30349.545395374298, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 969096, "time": 30352.947338819504, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 969096, "time": 30352.95414185524, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 969240, "time": 30357.324996948242, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 969488, "time": 30365.158894062042, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 969752, "time": 30372.91883611679, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 970000, "time": 30380.638497829437, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 970008, "time": 30381.00935435295, "eval_episode/length": 17.0, "eval_episode/score": 0.9468749761581421, "eval_episode/reward_rate": 0.05555555555555555}
{"step": 970008, "time": 30382.058391809464, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 970008, "time": 30382.08250808716, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 970008, "time": 30382.124357938766, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 970008, "time": 30382.187376499176, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 970008, "time": 30382.62423300743, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 970008, "time": 30382.830647706985, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 970008, "time": 30383.01842689514, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 970120, "time": 30386.443043231964, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 970128, "time": 30386.914687633514, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 970256, "time": 30390.915354967117, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 970304, "time": 30392.37284564972, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 970400, "time": 30395.296226978302, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 970536, "time": 30399.21782398224, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 970664, "time": 30403.084470510483, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 970688, "time": 30404.052228927612, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 970728, "time": 30405.03816986084, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 970848, "time": 30408.914962768555, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 971016, "time": 30413.788362026215, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 971168, "time": 30418.62021422386, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 971232, "time": 30420.668580770493, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 971248, "time": 30421.16065979004, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 971272, "time": 30421.674696922302, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 971456, "time": 30427.484661102295, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 971536, "time": 30429.919374227524, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 971568, "time": 30430.891754627228, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 971736, "time": 30435.747994422913, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 971776, "time": 30437.185691595078, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 971808, "time": 30438.168367147446, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 972072, "time": 30445.926600456238, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 972096, "time": 30446.87733721733, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 972104, "time": 30446.904522657394, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 972472, "time": 30458.173186302185, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 972568, "time": 30461.08936357498, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 972672, "time": 30464.46590924263, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 972848, "time": 30469.784023046494, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 973024, "time": 30475.1095328331, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 973040, "time": 30475.602263212204, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 973360, "time": 30485.433045864105, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 973400, "time": 30486.459274053574, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 973552, "time": 30491.287365674973, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 973600, "time": 30492.737323522568, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 973656, "time": 30494.211832523346, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 973744, "time": 30497.11283993721, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 973784, "time": 30498.102026224136, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 973832, "time": 30499.54525589943, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 974072, "time": 30506.812697649002, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 974368, "time": 30516.12405848503, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 974568, "time": 30521.96684527397, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 974656, "time": 30524.856496095657, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 974768, "time": 30528.25794529915, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 974800, "time": 30529.232719421387, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 975200, "time": 30541.9180932045, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 975208, "time": 30541.9458527565, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 975240, "time": 30542.92002105713, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 975400, "time": 30547.778977632523, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 975584, "time": 30553.562721014023, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 975640, "time": 30555.05653166771, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 975680, "time": 30556.48654770851, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 975800, "time": 30559.898607492447, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 975904, "time": 30563.253405570984, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 976080, "time": 30568.59621667862, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 976400, "time": 30578.395802736282, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 976424, "time": 30578.9080889225, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 976680, "time": 30586.667251586914, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 976824, "time": 30591.037518024445, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 976896, "time": 30593.443126916885, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 977064, "time": 30598.305590629578, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 977096, "time": 30599.293672323227, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 977272, "time": 30604.720324516296, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 977384, "time": 30608.100411891937, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 977408, "time": 30609.0639231205, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 977424, "time": 30609.54930305481, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 977648, "time": 30616.31772351265, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 977776, "time": 30620.20995616913, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 978032, "time": 30627.97075200081, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 978200, "time": 30632.928370952606, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 978304, "time": 30636.36773085594, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 978336, "time": 30637.362664222717, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 978456, "time": 30640.84519290924, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 978672, "time": 30647.76704788208, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 978736, "time": 30649.741221427917, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 979040, "time": 30659.070888757706, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 979096, "time": 30660.66564965248, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 979112, "time": 30661.154177188873, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 979112, "time": 30661.165781974792, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 979192, "time": 30663.60618329048, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 979304, "time": 30666.982619524002, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 979488, "time": 30672.776468515396, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 979560, "time": 30674.727984905243, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 979880, "time": 30684.370492458344, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 980008, "time": 30688.244869470596, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 980096, "time": 30692.955448389053, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 980096, "time": 30693.255531072617, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 980096, "time": 30693.670122385025, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 980096, "time": 30694.044761419296, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 980096, "time": 30694.052735328674, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 980096, "time": 30694.078532218933, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 980096, "time": 30694.1428565979, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 980096, "time": 30694.571321487427, "eval_episode/length": 170.0, "eval_episode/score": 0.46875, "eval_episode/reward_rate": 0.005847953216374269}
{"step": 980104, "time": 30694.597983837128, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 980112, "time": 30695.085007429123, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 980488, "time": 30706.336661815643, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 980504, "time": 30706.82567882538, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 980512, "time": 30707.295879125595, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 980736, "time": 30714.071978092194, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 980736, "time": 30714.078380823135, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 980992, "time": 30721.90048933029, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 981040, "time": 30723.355731010437, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 981288, "time": 30730.65901851654, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 981304, "time": 30731.146856307983, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 981496, "time": 30736.955580711365, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 981528, "time": 30737.923207759857, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 981808, "time": 30746.63711833954, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 981848, "time": 30747.635278224945, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 981880, "time": 30748.629878282547, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 981984, "time": 30752.111386060715, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 982184, "time": 30757.946162462234, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 982224, "time": 30759.398463010788, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 982392, "time": 30764.256245613098, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 982432, "time": 30765.68655347824, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 982512, "time": 30768.119705677032, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 982704, "time": 30773.91574859619, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 982768, "time": 30775.842669010162, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 982832, "time": 30777.80460214615, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 983072, "time": 30785.67306470871, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 983328, "time": 30793.39735364914, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 983408, "time": 30795.817716360092, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 983520, "time": 30799.20752286911, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 983680, "time": 30804.093284130096, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 983696, "time": 30804.585680007935, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 983792, "time": 30807.5144302845, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 983840, "time": 30808.975277900696, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 984104, "time": 30816.854313373566, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 984120, "time": 30817.362622737885, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 984136, "time": 30817.85309958458, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 984168, "time": 30818.820610046387, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 984672, "time": 30834.333933115005, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 984688, "time": 30834.821491241455, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 985072, "time": 30846.717020511627, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 985096, "time": 30847.226897478104, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 985256, "time": 30852.08171224594, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 985296, "time": 30853.51574921608, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 985416, "time": 30856.94708776474, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 985464, "time": 30858.398931741714, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 985504, "time": 30859.82472038269, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 985600, "time": 30862.747832536697, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 985800, "time": 30868.60736823082, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 986088, "time": 30877.501326560974, "episode/length": 286.0, "episode/score": 0.10625000298023224, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.0}
{"step": 986104, "time": 30877.996469020844, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 986280, "time": 30883.348120689392, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 986392, "time": 30886.7735517025, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 986416, "time": 30887.72819876671, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 986504, "time": 30890.17325735092, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 986784, "time": 30898.867005586624, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 986784, "time": 30898.874000549316, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 986816, "time": 30899.834921598434, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 986896, "time": 30902.35146856308, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 986984, "time": 30904.788724422455, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 987112, "time": 30908.655789375305, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 987496, "time": 30920.32297706604, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 987512, "time": 30920.813791036606, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 987520, "time": 30921.28391623497, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 987736, "time": 30927.66897201538, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 987896, "time": 30932.615267038345, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 987928, "time": 30933.586159944534, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 988008, "time": 30936.033223628998, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 988040, "time": 30937.004925966263, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 988232, "time": 30942.816116333008, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 988344, "time": 30946.220428943634, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 988376, "time": 30947.1934094429, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 988736, "time": 30958.32394003868, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 988800, "time": 30960.30730700493, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 988880, "time": 30962.797513484955, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 989080, "time": 30968.64157986641, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 989200, "time": 30972.474349975586, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 989216, "time": 30972.959625005722, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 989416, "time": 30978.78440761566, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 989432, "time": 30979.274260044098, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 989624, "time": 30985.080191612244, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 989640, "time": 30985.565614938736, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 989648, "time": 30986.03180718422, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 989760, "time": 30989.429196834564, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 989760, "time": 30989.436739206314, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 990016, "time": 30997.26495027542, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 990048, "time": 30998.253333330154, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 990080, "time": 31000.37517285347, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 990080, "time": 31000.876745462418, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 990080, "time": 31001.33036017418, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 990080, "time": 31001.59274840355, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 990080, "time": 31001.688072919846, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 990080, "time": 31001.7658059597, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 990080, "time": 31002.288943767548, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 990080, "time": 31002.33324599266, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 990080, "time": 31002.342285633087, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 990240, "time": 31007.193221330643, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 990568, "time": 31016.892127752304, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 990624, "time": 31018.800659418106, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 990856, "time": 31025.72981619835, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 991064, "time": 31032.031168222427, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 991112, "time": 31033.493248462677, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 991328, "time": 31040.760600566864, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 991400, "time": 31042.71450304985, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 991520, "time": 31046.58053612709, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 991688, "time": 31051.57858657837, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 991768, "time": 31053.99673485756, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 991896, "time": 31057.896557569504, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 992160, "time": 31066.12165093422, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 992176, "time": 31066.609206438065, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 992696, "time": 31082.247400283813, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 992744, "time": 31083.707225322723, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 992792, "time": 31085.17657327652, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 993056, "time": 31093.421363830566, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 993056, "time": 31093.42989730835, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 993112, "time": 31094.96322774887, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 993128, "time": 31095.466683626175, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 993576, "time": 31109.07207798958, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 993592, "time": 31109.560817956924, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 993608, "time": 31110.05292892456, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 993824, "time": 31116.94048500061, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 993976, "time": 31121.334774255753, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 994000, "time": 31122.291761398315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 994016, "time": 31122.779234409332, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 994200, "time": 31128.16104197502, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 994424, "time": 31134.957469701767, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 994592, "time": 31140.28312587738, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 994600, "time": 31140.363532304764, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 994712, "time": 31143.826518774033, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 994896, "time": 31149.599657535553, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 994896, "time": 31149.60924887657, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 994960, "time": 31151.560027122498, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 995136, "time": 31156.897230148315, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 995328, "time": 31162.743977308273, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 995416, "time": 31165.20443201065, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 995504, "time": 31168.12779521942, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 995664, "time": 31173.098314762115, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 995696, "time": 31174.07395887375, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 995712, "time": 31174.565438747406, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 996000, "time": 31183.353017807007, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 996120, "time": 31186.789506435394, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 996304, "time": 31192.595076560974, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 996512, "time": 31198.90039730072, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 996656, "time": 31203.330626010895, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 996704, "time": 31204.793146133423, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 996784, "time": 31207.222732305527, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 996872, "time": 31209.675894021988, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 996872, "time": 31209.68262410164, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 996976, "time": 31213.067094802856, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 997136, "time": 31217.92799091339, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 997192, "time": 31219.401401758194, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 997256, "time": 31221.3617272377, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 997536, "time": 31230.06368970871, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 997824, "time": 31238.90097308159, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 997833, "time": 31239.922259807587, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.736718508276609, "train/action_min": 0.0, "train/action_std": 1.739773406840787, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012431149315642247, "train/actor_opt_grad_steps": 61255.0, "train/actor_opt_loss": -20.362061762573695, "train/adv_mag": 0.9557152390480042, "train/adv_max": 0.35957201872721756, "train/adv_mean": 0.0009560601362440733, "train/adv_min": -0.8983023945647891, "train/adv_std": 0.028975126545618075, "train/cont_avg": 0.9944838722153465, "train/cont_loss_mean": 0.01835002996474689, "train/cont_loss_std": 0.2171161510741873, "train/cont_neg_acc": 0.2513851439303691, "train/cont_neg_loss": 2.4744424681066266, "train/cont_pos_acc": 0.9998347644168551, "train/cont_pos_loss": 0.004578579869582364, "train/cont_pred": 0.9941776967284703, "train/cont_rate": 0.9944838722153465, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12081261789702838, "train/extr_critic_critic_opt_grad_steps": 61255.0, "train/extr_critic_critic_opt_loss": 6787.233033435179, "train/extr_critic_mag": 1.7378860157315095, "train/extr_critic_max": 1.7378860157315095, "train/extr_critic_mean": 1.6125335640246325, "train/extr_critic_min": 1.255557407246958, "train/extr_critic_std": 0.0393827382641116, "train/extr_return_normed_mag": 1.0040289677015626, "train/extr_return_normed_max": 0.3307506607310607, "train/extr_return_normed_mean": 0.07495120077366287, "train/extr_return_normed_min": -0.9115029915724651, "train/extr_return_normed_std": 0.04997214211132562, "train/extr_return_rate": 0.9997322037078367, "train/extr_return_raw_mag": 1.8692890370246207, "train/extr_return_raw_max": 1.8692890370246207, "train/extr_return_raw_mean": 1.6134896514439347, "train/extr_return_raw_min": 0.627035384721095, "train/extr_return_raw_std": 0.049972142240419834, "train/extr_reward_mag": 0.2782504658887882, "train/extr_reward_max": 0.2782504658887882, "train/extr_reward_mean": 0.0024577451139079906, "train/extr_reward_min": 8.262029968866028e-09, "train/extr_reward_std": 0.009329806715895487, "train/image_loss_mean": 0.09742964889005859, "train/image_loss_std": 0.10897030961690563, "train/model_loss_mean": 0.735401060026471, "train/model_loss_std": 0.48307604405401955, "train/model_opt_grad_norm": 17.955129753244986, "train/model_opt_grad_steps": 61200.960396039605, "train/model_opt_loss": 3820.0151524307703, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5198.019801980198, "train/policy_entropy_mag": 1.3697382660195379, "train/policy_entropy_max": 1.3697382660195379, "train/policy_entropy_mean": 0.08916061998593926, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10824005519694621, "train/policy_logprob_mag": 6.551080250503993, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0895236743853824, "train/policy_logprob_min": -6.551080250503993, "train/policy_logprob_std": 0.6289563618674137, "train/policy_randomness_mag": 0.703906265225741, "train/policy_randomness_max": 0.703906265225741, "train/policy_randomness_mean": 0.045819496975676846, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.055624387900132945, "train/post_ent_mag": 40.39989907670729, "train/post_ent_max": 40.39989907670729, "train/post_ent_mean": 39.61162871181375, "train/post_ent_min": 38.72361587297799, "train/post_ent_std": 0.4302655827290941, "train/prior_ent_mag": 39.83729043337378, "train/prior_ent_max": 39.83729043337378, "train/prior_ent_mean": 38.81316581574997, "train/prior_ent_min": 37.79565712957099, "train/prior_ent_std": 0.34132141892862794, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.002349944161666133, "train/reward_loss_mean": 0.0196213560815126, "train/reward_loss_std": 0.2508576441012175, "train/reward_max_data": 0.754347152344071, "train/reward_max_pred": 0.2662168251405848, "train/reward_neg_acc": 0.9995388671903327, "train/reward_neg_loss": 0.0038926028006820764, "train/reward_pos_acc": 0.13102018200422652, "train/reward_pos_loss": 3.92084545091768, "train/reward_pred": 0.0020463643520655535, "train/reward_rate": 0.003993270420792079, "train_stats/mean_log_entropy": 0.0716752517554495, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.015930794179439545, "report/cont_loss_std": 0.18448768556118011, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 2.8075928688049316, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004983101040124893, "report/cont_pred": 0.9948495626449585, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09190332144498825, "report/image_loss_std": 0.09976482391357422, "report/model_loss_mean": 0.7261941432952881, "report/model_loss_std": 0.47337424755096436, "report/post_ent_mag": 40.764564514160156, "report/post_ent_max": 40.764564514160156, "report/post_ent_mean": 39.938560485839844, "report/post_ent_min": 38.97740936279297, "report/post_ent_std": 0.4371018409729004, "report/prior_ent_mag": 40.44319152832031, "report/prior_ent_max": 40.44319152832031, "report/prior_ent_mean": 39.58443069458008, "report/prior_ent_min": 38.432716369628906, "report/prior_ent_std": 0.35904839634895325, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0021636963356286287, "report/reward_loss_mean": 0.018359988927841187, "report/reward_loss_std": 0.25345468521118164, "report/reward_max_data": 0.668749988079071, "report/reward_max_pred": 0.09560012817382812, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0030233338475227356, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.9292073249816895, "report/reward_pred": 0.0015599813777953386, "report/reward_rate": 0.00390625, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.007409760262817144, "eval/cont_loss_std": 0.044332586228847504, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.998046875, "eval/cont_pos_loss": 0.007409760262817144, "eval/cont_pred": 0.9933813214302063, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1139373928308487, "eval/image_loss_std": 0.1282968819141388, "eval/model_loss_mean": 0.7273058891296387, "eval/model_loss_std": 0.15735690295696259, "eval/post_ent_mag": 40.84632110595703, "eval/post_ent_max": 40.84632110595703, "eval/post_ent_mean": 39.98419952392578, "eval/post_ent_min": 39.08786392211914, "eval/post_ent_std": 0.42766809463500977, "eval/prior_ent_mag": 40.47062683105469, "eval/prior_ent_max": 40.47062683105469, "eval/prior_ent_mean": 39.631011962890625, "eval/prior_ent_min": 38.6884651184082, "eval/prior_ent_std": 0.31417590379714966, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.005958726163953543, "eval/reward_loss_std": 0.04516918957233429, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.36021173000335693, "eval/reward_neg_acc": 0.998046875, "eval/reward_neg_loss": 0.005958726163953543, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0024039915297180414, "eval/reward_rate": 0.0, "replay/size": 997329.0, "replay/inserts": 32448.0, "replay/samples": 32448.0, "replay/insert_wait_avg": 1.2911988433296158e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.348447391502485e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3728.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1037091840490252e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1308336257935, "timer/env.step_count": 4056.0, "timer/env.step_total": 38.94342565536499, "timer/env.step_frac": 0.038938331212310134, "timer/env.step_avg": 0.00960143630556336, "timer/env.step_min": 0.007710456848144531, "timer/env.step_max": 0.050301551818847656, "timer/replay._sample_count": 32448.0, "timer/replay._sample_total": 16.46428871154785, "timer/replay._sample_frac": 0.016462134910749177, "timer/replay._sample_avg": 0.0005074053473726533, "timer/replay._sample_min": 0.0003871917724609375, "timer/replay._sample_max": 0.011055231094360352, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4522.0, "timer/agent.policy_total": 46.741538763046265, "timer/agent.policy_frac": 0.04673542419804544, "timer/agent.policy_avg": 0.01033647473751576, "timer/agent.policy_min": 0.008803129196166992, "timer/agent.policy_max": 0.07734251022338867, "timer/dataset_train_count": 2028.0, "timer/dataset_train_total": 0.21134448051452637, "timer/dataset_train_frac": 0.00021131683316705192, "timer/dataset_train_avg": 0.00010421325469158104, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0003361701965332031, "timer/agent.train_count": 2028.0, "timer/agent.train_total": 904.0612235069275, "timer/agent.train_frac": 0.903942957372304, "timer/agent.train_avg": 0.44578955794227193, "timer/agent.train_min": 0.43419981002807617, "timer/agent.train_max": 0.6689777374267578, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4776144027709961, "timer/agent.report_frac": 0.00047755192292141566, "timer/agent.report_avg": 0.23880720138549805, "timer/agent.report_min": 0.23236513137817383, "timer/agent.report_max": 0.24524927139282227, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9083261581827974e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 32.44325188669571}
{"step": 997880, "time": 31241.11576604843, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 997880, "time": 31241.126415252686, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 998040, "time": 31245.97414135933, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 998408, "time": 31257.08451461792, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 998416, "time": 31257.557680130005, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 998496, "time": 31259.974712610245, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 998496, "time": 31259.98098731041, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.0}
{"step": 998520, "time": 31260.652417898178, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 998656, "time": 31264.987117528915, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 998680, "time": 31265.5159573555, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 998688, "time": 31265.98423218727, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 999040, "time": 31276.674254655838, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 999072, "time": 31277.6536796093, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 999264, "time": 31283.474897384644, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 999384, "time": 31286.900770902634, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 999408, "time": 31287.855962514877, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 999592, "time": 31293.807016134262, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 999920, "time": 31304.004866600037, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1000008, "time": 31306.461355686188, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1000064, "time": 31311.17769265175, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 1000064, "time": 31311.533472299576, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1000064, "time": 31311.858405590057, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 1000064, "time": 31312.23730778694, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 1000064, "time": 31312.309310674667, "eval_episode/length": 168.0, "eval_episode/score": 0.4749999940395355, "eval_episode/reward_rate": 0.005917159763313609}
{"step": 1000064, "time": 31312.491840839386, "eval_episode/length": 177.0, "eval_episode/score": 0.4468750059604645, "eval_episode/reward_rate": 0.0056179775280898875}
{"step": 1000064, "time": 31312.743326425552, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1000064, "time": 31313.28459596634, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1000168, "time": 31316.297699451447, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1000200, "time": 31317.297777175903, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1000408, "time": 31323.71614766121, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1000528, "time": 31327.607192516327, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1000576, "time": 31329.067516565323, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1000736, "time": 31333.942715168, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1000736, "time": 31333.961056232452, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1000896, "time": 31338.84912109375, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1000912, "time": 31339.36207962036, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 1001040, "time": 31343.233854055405, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1001120, "time": 31345.69496011734, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1001368, "time": 31353.091255903244, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1001816, "time": 31366.740264177322, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1001976, "time": 31371.606449604034, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1002024, "time": 31373.065595149994, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1002064, "time": 31374.52515387535, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1002144, "time": 31376.93896174431, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1002256, "time": 31380.35978293419, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1002328, "time": 31382.369023799896, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1002792, "time": 31396.404305696487, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 1002824, "time": 31397.374551057816, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1002960, "time": 31401.711814641953, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1003136, "time": 31407.035163640976, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1003136, "time": 31407.043533325195, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1003176, "time": 31408.05189228058, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1003408, "time": 31415.432275533676, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1003408, "time": 31415.440802574158, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1003424, "time": 31415.93415427208, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1003944, "time": 31431.50984764099, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1003968, "time": 31432.48189806938, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1003992, "time": 31432.98886179924, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1004104, "time": 31436.370358228683, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1004160, "time": 31438.308289289474, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1004216, "time": 31439.78982448578, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1004216, "time": 31439.796384334564, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1004464, "time": 31447.64130949974, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1004536, "time": 31449.603247642517, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1004648, "time": 31453.005323171616, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1005272, "time": 31472.115268945694, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1005288, "time": 31472.60841536522, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1005416, "time": 31476.507897377014, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 1005464, "time": 31477.96832036972, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1005496, "time": 31478.942048072815, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1005520, "time": 31479.898509979248, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1005648, "time": 31483.79419374466, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1005992, "time": 31493.99261021614, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1006000, "time": 31494.46040058136, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1006064, "time": 31496.41500020027, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1006296, "time": 31503.32674765587, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1006344, "time": 31504.797966241837, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1006576, "time": 31512.072163820267, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1006808, "time": 31518.8826315403, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1006888, "time": 31521.315733909607, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1007016, "time": 31525.180935382843, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1007256, "time": 31532.55772471428, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1007376, "time": 31536.432173013687, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1007456, "time": 31538.862496376038, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 1007584, "time": 31542.76998281479, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1007600, "time": 31543.260507822037, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1008104, "time": 31558.776302337646, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1008120, "time": 31559.287103652954, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1008256, "time": 31563.701882839203, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1008312, "time": 31565.195344924927, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1008496, "time": 31571.006242513657, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1008608, "time": 31574.43464255333, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1008752, "time": 31578.82865190506, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1008856, "time": 31581.76253414154, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1008984, "time": 31585.64977478981, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1009176, "time": 31591.61627483368, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1009176, "time": 31591.62534737587, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1009392, "time": 31598.438223838806, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1009536, "time": 31602.822985887527, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1009888, "time": 31613.54578256607, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1010040, "time": 31617.933517932892, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1010048, "time": 31618.400770902634, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1010048, "time": 31619.607769727707, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1010048, "time": 31619.613212823868, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1010048, "time": 31620.08445930481, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1010048, "time": 31620.491947889328, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1010048, "time": 31620.95296883583, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1010048, "time": 31621.206852197647, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 1010048, "time": 31621.56530380249, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 1010048, "time": 31622.227005004883, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 1010360, "time": 31631.452684879303, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1010552, "time": 31637.27356505394, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1010560, "time": 31637.74579000473, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1010600, "time": 31638.740233182907, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 1010632, "time": 31639.713359832764, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1010704, "time": 31642.14267373085, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1011000, "time": 31650.975430727005, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1011368, "time": 31662.141078948975, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1011456, "time": 31665.019471168518, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1011504, "time": 31666.48642730713, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1011576, "time": 31668.449966192245, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1011704, "time": 31672.33071088791, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1011816, "time": 31675.737718582153, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1011928, "time": 31679.126999139786, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1012048, "time": 31683.072234392166, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1012112, "time": 31685.009103536606, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1012360, "time": 31692.285316944122, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1012536, "time": 31697.62078022957, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1012584, "time": 31699.084875822067, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1012840, "time": 31706.847284317017, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1013176, "time": 31717.100058317184, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1013312, "time": 31721.45796585083, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1013576, "time": 31729.274736166, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 1013600, "time": 31730.22703576088, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1013664, "time": 31732.169887304306, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1014024, "time": 31743.013996839523, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1014024, "time": 31743.020851373672, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1014032, "time": 31743.518652439117, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1014096, "time": 31745.49702167511, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1014136, "time": 31746.51106953621, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1014616, "time": 31761.14981842041, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1014624, "time": 31761.619484186172, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1014656, "time": 31762.601150274277, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1014880, "time": 31769.470786333084, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1014904, "time": 31769.988094329834, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1014904, "time": 31769.9947245121, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1014928, "time": 31771.099282741547, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1015200, "time": 31779.389407873154, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1015288, "time": 31781.825376033783, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1015352, "time": 31783.7813038826, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1015576, "time": 31790.567952394485, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1015592, "time": 31791.05438899994, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1015608, "time": 31791.541060447693, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1015704, "time": 31794.45251941681, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1015704, "time": 31794.461127758026, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 1015776, "time": 31796.84898853302, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1015920, "time": 31801.749661445618, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1016312, "time": 31813.357904434204, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1016432, "time": 31817.217997312546, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1016448, "time": 31817.7035343647, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 1016480, "time": 31818.66512441635, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1016792, "time": 31827.865524053574, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1016904, "time": 31831.32506275177, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1017040, "time": 31835.685756206512, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1017232, "time": 31841.50621366501, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1017352, "time": 31844.91943001747, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1017368, "time": 31845.41008400917, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1017448, "time": 31847.85092139244, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1017536, "time": 31850.731093406677, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1017640, "time": 31853.673053264618, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1017856, "time": 31860.57469034195, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1018016, "time": 31865.44002056122, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1018400, "time": 31877.090242385864, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1018600, "time": 31882.93778204918, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1018664, "time": 31884.863966941833, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1018824, "time": 31889.716333389282, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1018840, "time": 31890.294495821, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1018864, "time": 31891.31743836403, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1019296, "time": 31904.412596464157, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1019360, "time": 31906.363567352295, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 1019432, "time": 31908.32130074501, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1019488, "time": 31910.251184225082, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 1019600, "time": 31913.645656347275, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1019672, "time": 31915.62608742714, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1019696, "time": 31916.590624809265, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1020032, "time": 31926.933282613754, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1020032, "time": 31928.018487215042, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1020032, "time": 31928.08002471924, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1020032, "time": 31928.27878689766, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1020032, "time": 31928.43559384346, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1020032, "time": 31928.52988100052, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1020032, "time": 31929.392077684402, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 1020032, "time": 31930.04803109169, "eval_episode/length": 170.0, "eval_episode/score": 0.46875, "eval_episode/reward_rate": 0.005847953216374269}
{"step": 1020032, "time": 31930.35720849037, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 1020096, "time": 31932.287898540497, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1020424, "time": 31942.06712794304, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1020584, "time": 31946.93501186371, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1020640, "time": 31948.88661313057, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1020840, "time": 31954.801843881607, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1020968, "time": 31958.699542284012, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1021216, "time": 31966.465888738632, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1021240, "time": 31966.995841741562, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 1021760, "time": 31983.145818710327, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1021784, "time": 31983.65811920166, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1021912, "time": 31987.563346862793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1022112, "time": 31993.842634916306, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1022256, "time": 31998.20589709282, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1022320, "time": 32000.14646244049, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1022368, "time": 32001.628651857376, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1022448, "time": 32004.043888807297, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1022448, "time": 32004.053045511246, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1022568, "time": 32007.499008655548, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 1022744, "time": 32012.882798671722, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1022784, "time": 32014.302698612213, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1023248, "time": 32028.39186358452, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1023400, "time": 32032.78214406967, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1023408, "time": 32033.248707056046, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1023488, "time": 32035.681034088135, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1023824, "time": 32045.96227812767, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1023888, "time": 32047.90466451645, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1024208, "time": 32058.09318089485, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 1024648, "time": 32071.34226679802, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1024752, "time": 32074.768014431, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1024848, "time": 32077.67293691635, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 1024912, "time": 32079.639858722687, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1024944, "time": 32080.61271548271, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1025160, "time": 32086.950495004654, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1025176, "time": 32087.44629430771, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 1025384, "time": 32093.76448082924, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1025656, "time": 32102.138547182083, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1025696, "time": 32103.586277723312, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1025848, "time": 32107.99502491951, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 1025960, "time": 32111.411343336105, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1026344, "time": 32123.049693346024, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1026432, "time": 32125.946690559387, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1026552, "time": 32129.38538503647, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 1026784, "time": 32136.7109978199, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1026872, "time": 32139.16775918007, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1026992, "time": 32143.033871412277, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1027008, "time": 32143.525333881378, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1027208, "time": 32149.367359638214, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1027216, "time": 32149.837160110474, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1027584, "time": 32161.12432551384, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1027688, "time": 32164.071406841278, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1027744, "time": 32165.986767053604, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1027808, "time": 32167.953790426254, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 1028032, "time": 32174.72815322876, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1028224, "time": 32180.52271962166, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1028240, "time": 32181.012323141098, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1028336, "time": 32183.922871351242, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1028384, "time": 32185.374494075775, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1028688, "time": 32194.70407962799, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1028736, "time": 32196.175190925598, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1028976, "time": 32203.455584049225, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1029112, "time": 32207.46406030655, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1029328, "time": 32214.389070034027, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1029456, "time": 32218.323088407516, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1029480, "time": 32218.837094306946, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1029504, "time": 32219.789029598236, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1029768, "time": 32227.722507238388, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1029808, "time": 32229.16442990303, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1029824, "time": 32229.655400037766, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1030016, "time": 32236.20035457611, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 1030016, "time": 32236.20597720146, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 1030016, "time": 32236.592489242554, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 1030016, "time": 32237.585567474365, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1030016, "time": 32237.649179697037, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1030016, "time": 32237.71458053589, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1030016, "time": 32237.87487912178, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1030016, "time": 32238.549943447113, "eval_episode/length": 159.0, "eval_episode/score": 0.503125011920929, "eval_episode/reward_rate": 0.00625}
{"step": 1030041, "time": 32240.188011407852, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7008615625966894, "train/action_min": 0.0, "train/action_std": 1.7143368260695202, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012231386808383435, "train/actor_opt_grad_steps": 63275.0, "train/actor_opt_loss": -19.736520911207293, "train/adv_mag": 0.9577328031606013, "train/adv_max": 0.36285989001245783, "train/adv_mean": 0.0015650275061236945, "train/adv_min": -0.9012820378388509, "train/adv_std": 0.029941299381564455, "train/cont_avg": 0.9940632735148515, "train/cont_loss_mean": 0.01946179709849086, "train/cont_loss_std": 0.22755538240665257, "train/cont_neg_acc": 0.23882817325763184, "train/cont_neg_loss": 2.524212269794823, "train/cont_pos_acc": 0.9998589886887239, "train/cont_pos_loss": 0.004573050914055641, "train/cont_pred": 0.9940802056600552, "train/cont_rate": 0.9940632735148515, "train/dyn_loss_mean": 1.0000001345530596, "train/dyn_loss_std": 4.307760817856334e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12284503093837659, "train/extr_critic_critic_opt_grad_steps": 63275.0, "train/extr_critic_critic_opt_loss": 8552.043983988242, "train/extr_critic_mag": 1.7823444085546059, "train/extr_critic_max": 1.7823444085546059, "train/extr_critic_mean": 1.6438817794960323, "train/extr_critic_min": 1.2335177583269554, "train/extr_critic_std": 0.04046355817688278, "train/extr_return_normed_mag": 0.9995037877913748, "train/extr_return_normed_max": 0.3198496162301243, "train/extr_return_normed_mean": 0.07699861006792819, "train/extr_return_normed_min": -0.9025631139774134, "train/extr_return_normed_std": 0.051296343270799905, "train/extr_return_rate": 0.9996890157166094, "train/extr_return_raw_mag": 1.8882977124488, "train/extr_return_raw_max": 1.8882977124488, "train/extr_return_raw_mean": 1.6454467932776649, "train/extr_return_raw_min": 0.6658849822412624, "train/extr_return_raw_std": 0.051296343326125995, "train/extr_reward_mag": 0.2560979098376661, "train/extr_reward_max": 0.2560979098376661, "train/extr_reward_mean": 0.0025131342590251696, "train/extr_reward_min": 2.3605799911045792e-09, "train/extr_reward_std": 0.009399949828863587, "train/image_loss_mean": 0.09788561221396569, "train/image_loss_std": 0.1088060413182962, "train/model_loss_mean": 0.7383046147256794, "train/model_loss_std": 0.5062219931347536, "train/model_opt_grad_norm": 17.329384728233414, "train/model_opt_grad_steps": 63219.13861386139, "train/model_opt_loss": 4333.2415771484375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5866.336633663366, "train/policy_entropy_mag": 1.3818302272570016, "train/policy_entropy_max": 1.3818302272570016, "train/policy_entropy_mean": 0.08640218957668484, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10274765762214613, "train/policy_logprob_mag": 6.5510802528645735, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08634478609898302, "train/policy_logprob_min": -6.5510802528645735, "train/policy_logprob_std": 0.6246973789564454, "train/policy_randomness_mag": 0.710120306451722, "train/policy_randomness_max": 0.710120306451722, "train/policy_randomness_mean": 0.04440194480858817, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.052801854115459, "train/post_ent_mag": 40.59486028463534, "train/post_ent_max": 40.59486028463534, "train/post_ent_mean": 39.68123730574504, "train/post_ent_min": 38.672353914468594, "train/post_ent_std": 0.48674101271841785, "train/prior_ent_mag": 39.935716213566245, "train/prior_ent_max": 39.935716213566245, "train/prior_ent_mean": 38.890116549954556, "train/prior_ent_min": 37.81701497748347, "train/prior_ent_std": 0.3351881918635699, "train/rep_loss_mean": 1.0000001345530596, "train/rep_loss_std": 4.307760817856334e-06, "train/reward_avg": 0.0025672383821398795, "train/reward_loss_mean": 0.02095709946744218, "train/reward_loss_std": 0.26374816284100017, "train/reward_max_data": 0.779439973506597, "train/reward_max_pred": 0.25798752638373046, "train/reward_neg_acc": 0.9994706818372896, "train/reward_neg_loss": 0.003960509287737457, "train/reward_pos_acc": 0.1334558476020794, "train/reward_pos_loss": 3.948210103677051, "train/reward_pred": 0.0020817406366044414, "train/reward_rate": 0.004293007425742575, "train_stats/mean_log_entropy": 0.07259506027863807, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.01578616537153721, "report/cont_loss_std": 0.24999602138996124, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 3.2102768421173096, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003258748911321163, "report/cont_pred": 0.9957669377326965, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10485184192657471, "report/image_loss_std": 0.11330798268318176, "report/model_loss_mean": 0.7330026030540466, "report/model_loss_std": 0.4210715889930725, "report/post_ent_mag": 40.785675048828125, "report/post_ent_max": 40.785675048828125, "report/post_ent_mean": 39.67132568359375, "report/post_ent_min": 38.52406311035156, "report/post_ent_std": 0.5653260350227356, "report/prior_ent_mag": 39.63585662841797, "report/prior_ent_max": 39.63585662841797, "report/prior_ent_mean": 38.51796340942383, "report/prior_ent_min": 37.48627471923828, "report/prior_ent_std": 0.31452488899230957, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0021301270462572575, "report/reward_loss_mean": 0.012364568188786507, "report/reward_loss_std": 0.1926923394203186, "report/reward_max_data": 0.846875011920929, "report/reward_max_pred": 0.64914870262146, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.003233252791687846, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.1200551986694336, "report/reward_pred": 0.002135180402547121, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.008666973561048508, "eval/cont_loss_std": 0.15195715427398682, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.816720008850098, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00396701879799366, "eval/cont_pred": 0.9962535500526428, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.06552819162607193, "eval/image_loss_std": 0.0785803496837616, "eval/model_loss_mean": 0.6779080629348755, "eval/model_loss_std": 0.17451848089694977, "eval/post_ent_mag": 40.796661376953125, "eval/post_ent_max": 40.796661376953125, "eval/post_ent_mean": 39.65932083129883, "eval/post_ent_min": 38.470924377441406, "eval/post_ent_std": 0.46910494565963745, "eval/prior_ent_mag": 39.63585662841797, "eval/prior_ent_max": 39.63585662841797, "eval/prior_ent_mean": 38.52342987060547, "eval/prior_ent_min": 37.76828384399414, "eval/prior_ent_std": 0.3014959394931793, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.003712849225848913, "eval/reward_loss_std": 0.024872886016964912, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.27961254119873047, "eval/reward_neg_acc": 0.9990234375, "eval/reward_neg_loss": 0.003712849225848913, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0016274027293547988, "eval/reward_rate": 0.0, "replay/size": 1000000.0, "replay/inserts": 32208.0, "replay/samples": 32208.0, "replay/insert_wait_avg": 1.2348199210472504e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.27958366519115e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6136.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.111778162293515e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1423695087433, "timer/env.step_count": 4026.0, "timer/env.step_total": 39.00784945487976, "timer/env.step_frac": 0.039002296717056295, "timer/env.step_avg": 0.009688983967928406, "timer/env.step_min": 0.007700920104980469, "timer/env.step_max": 0.035341739654541016, "timer/replay._sample_count": 32208.0, "timer/replay._sample_total": 16.21916627883911, "timer/replay._sample_frac": 0.0162168574928045, "timer/replay._sample_avg": 0.0005035757041368329, "timer/replay._sample_min": 0.0004112720489501953, "timer/replay._sample_max": 0.010560750961303711, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4793.0, "timer/agent.policy_total": 49.82732653617859, "timer/agent.policy_frac": 0.04982023365398779, "timer/agent.policy_avg": 0.010395853648274273, "timer/agent.policy_min": 0.008932352066040039, "timer/agent.policy_max": 0.09622764587402344, "timer/dataset_train_count": 2013.0, "timer/dataset_train_total": 0.21654486656188965, "timer/dataset_train_frac": 0.00021651404156415612, "timer/dataset_train_avg": 0.00010757320743263271, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0004394054412841797, "timer/agent.train_count": 2013.0, "timer/agent.train_total": 897.9352355003357, "timer/agent.train_frac": 0.8978074150997019, "timer/agent.train_avg": 0.44606817461516923, "timer/agent.train_min": 0.4341719150543213, "timer/agent.train_max": 0.6884212493896484, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48171091079711914, "timer/agent.report_frac": 0.00048164233961383836, "timer/agent.report_avg": 0.24085545539855957, "timer/agent.report_min": 0.23408985137939453, "timer/agent.report_max": 0.2476210594177246, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8844541488087476e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 32.202876958115}
{"step": 1030056, "time": 32240.243116617203, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1030256, "time": 32246.925412416458, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1030320, "time": 32248.875401973724, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1030536, "time": 32255.351928710938, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1030872, "time": 32265.57065963745, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1031056, "time": 32271.365972995758, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1031080, "time": 32271.878771305084, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1031120, "time": 32273.317611694336, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1031168, "time": 32274.786633729935, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 1031336, "time": 32279.64013314247, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1031424, "time": 32282.599380016327, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1031488, "time": 32284.5676882267, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1031536, "time": 32286.021993875504, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1031888, "time": 32296.731425762177, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1032112, "time": 32303.56651544571, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1032304, "time": 32309.883986234665, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1032328, "time": 32310.478689670563, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1032480, "time": 32315.314594984055, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1032552, "time": 32317.28088903427, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1032624, "time": 32319.69807767868, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1032640, "time": 32320.189004421234, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1032720, "time": 32322.611488342285, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1032928, "time": 32328.94802379608, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1032976, "time": 32330.422867298126, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1032992, "time": 32330.917813777924, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1033152, "time": 32335.75438594818, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1033176, "time": 32336.2593896389, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1033296, "time": 32340.12119412422, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1033480, "time": 32345.549262285233, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1033568, "time": 32348.433230161667, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1033608, "time": 32349.423515558243, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1034008, "time": 32361.50851726532, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1034032, "time": 32362.475292921066, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1034072, "time": 32363.461173295975, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1034184, "time": 32366.832247018814, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1034304, "time": 32370.796340227127, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1034400, "time": 32373.734657287598, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1034568, "time": 32378.61318540573, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1034784, "time": 32385.362270116806, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1035080, "time": 32394.131190299988, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1035168, "time": 32397.023585557938, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1035216, "time": 32398.470614910126, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1035312, "time": 32401.46399116516, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1035432, "time": 32404.85469532013, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1035552, "time": 32408.717929124832, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1035768, "time": 32415.0147857666, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1035808, "time": 32416.46454834938, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1035880, "time": 32418.417094945908, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1035920, "time": 32419.84880566597, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1035992, "time": 32421.841140031815, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1036360, "time": 32433.070217847824, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1036440, "time": 32435.50674057007, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1036488, "time": 32436.96672487259, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1036800, "time": 32446.640089035034, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1037200, "time": 32458.754932165146, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1037424, "time": 32465.629531383514, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 1037504, "time": 32468.050165891647, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1037680, "time": 32473.380129814148, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 1037824, "time": 32477.754141569138, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1037968, "time": 32482.098401784897, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1037984, "time": 32482.583121061325, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 1038032, "time": 32484.05004119873, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1038240, "time": 32490.35826611519, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 1038408, "time": 32495.264322280884, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1038592, "time": 32501.060237646103, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1038696, "time": 32504.013825178146, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1038800, "time": 32507.382354021072, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1039032, "time": 32514.227575302124, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1039200, "time": 32519.550330877304, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1039288, "time": 32522.10449552536, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1039328, "time": 32523.544019699097, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1039480, "time": 32527.923588752747, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1039864, "time": 32539.598085165024, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1040000, "time": 32545.30596756935, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1040000, "time": 32545.79505300522, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1040000, "time": 32545.876106977463, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1040000, "time": 32546.021889448166, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1040000, "time": 32546.250636577606, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 1040000, "time": 32546.621432065964, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 1040000, "time": 32547.379361629486, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1040000, "time": 32547.72612762451, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1040008, "time": 32547.752955198288, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1040040, "time": 32548.730722427368, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1040360, "time": 32558.5794570446, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1040416, "time": 32560.97732257843, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1040472, "time": 32562.477600097656, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1040576, "time": 32565.876269817352, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1040816, "time": 32573.217987060547, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 1040920, "time": 32576.18008327484, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1040952, "time": 32577.155886888504, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1041088, "time": 32581.63613152504, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1041352, "time": 32589.415113925934, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1041440, "time": 32592.31538748741, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1041576, "time": 32596.23397874832, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1041640, "time": 32598.182340860367, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1041792, "time": 32603.02878499031, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1042168, "time": 32614.315589904785, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1042208, "time": 32615.766996383667, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1042224, "time": 32616.26366519928, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1042344, "time": 32619.673855543137, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1042408, "time": 32621.634814977646, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1042440, "time": 32622.615393161774, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1042552, "time": 32626.025242328644, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1042816, "time": 32634.264313936234, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1042864, "time": 32635.735605716705, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1042920, "time": 32637.209835767746, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1042928, "time": 32637.681965827942, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1042992, "time": 32639.66027855873, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1043176, "time": 32645.152512311935, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1043472, "time": 32654.42193555832, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1043656, "time": 32659.820238113403, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1043768, "time": 32663.217858314514, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1043816, "time": 32664.705040216446, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1043840, "time": 32665.667339086533, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1043856, "time": 32666.16037416458, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1043896, "time": 32667.164461374283, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1044104, "time": 32673.586160182953, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1044464, "time": 32684.841422080994, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 1044528, "time": 32686.80681014061, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1044712, "time": 32692.16979932785, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1044912, "time": 32698.480100870132, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1045056, "time": 32702.86939883232, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1045328, "time": 32711.09277701378, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1045584, "time": 32718.878735780716, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1045952, "time": 32730.054732322693, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 1045960, "time": 32730.08230113983, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1046104, "time": 32734.53628897667, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1046144, "time": 32735.984008550644, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 1046216, "time": 32737.94927597046, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1046312, "time": 32740.843652009964, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1046488, "time": 32746.186135292053, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1046608, "time": 32750.05394768715, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1046912, "time": 32759.297778844833, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1047024, "time": 32762.80040693283, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1047064, "time": 32763.814509391785, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1047064, "time": 32763.82225203514, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1047176, "time": 32767.23099207878, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1047320, "time": 32771.633477211, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1047360, "time": 32773.07075381279, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1047656, "time": 32781.849606990814, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1047864, "time": 32788.18765306473, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1047880, "time": 32788.67743206024, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1047896, "time": 32789.16927933693, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1047992, "time": 32792.192626953125, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1048264, "time": 32800.4525578022, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1048336, "time": 32802.875727176666, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1048656, "time": 32813.15042638779, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1048744, "time": 32815.616673231125, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1048840, "time": 32818.54066467285, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1049144, "time": 32827.96347260475, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1049192, "time": 32829.43405127525, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1049392, "time": 32835.71914792061, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1049408, "time": 32836.205516815186, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1049776, "time": 32847.30855464935, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1050024, "time": 32854.73385477066, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1050024, "time": 32854.741425037384, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1050040, "time": 32855.24984526634, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1050088, "time": 32857.152202129364, "eval_episode/length": 22.0, "eval_episode/score": 0.9312499761581421, "eval_episode/reward_rate": 0.043478260869565216}
{"step": 1050088, "time": 32858.18437743187, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1050088, "time": 32858.53910779953, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 1050088, "time": 32858.820967912674, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1050088, "time": 32859.55619597435, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1050088, "time": 32859.95227241516, "eval_episode/length": 170.0, "eval_episode/score": 0.46875, "eval_episode/reward_rate": 0.005847953216374269}
{"step": 1050088, "time": 32860.12359905243, "eval_episode/length": 179.0, "eval_episode/score": 0.44062501192092896, "eval_episode/reward_rate": 0.005555555555555556}
{"step": 1050088, "time": 32861.150894880295, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1050232, "time": 32865.52623438835, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1050256, "time": 32866.47623920441, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1050288, "time": 32867.44864630699, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1050304, "time": 32867.936697006226, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1050480, "time": 32873.264972925186, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1050512, "time": 32874.25714826584, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1050640, "time": 32878.12398600578, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1050696, "time": 32879.61770248413, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1050784, "time": 32882.654619932175, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1050952, "time": 32887.600125551224, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1050968, "time": 32888.09884786606, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1051056, "time": 32891.02105474472, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1051072, "time": 32891.50880861282, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1051208, "time": 32895.41600036621, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1051952, "time": 32918.26751232147, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1051968, "time": 32918.756450891495, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1052104, "time": 32922.664625644684, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1052184, "time": 32925.1161468029, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1052264, "time": 32927.54368329048, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1052656, "time": 32939.708236694336, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1052736, "time": 32942.25676035881, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1052768, "time": 32943.25062131882, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1052784, "time": 32943.74072957039, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1052872, "time": 32946.1884226799, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 1053048, "time": 32951.53740310669, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1053112, "time": 32953.502586603165, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1053128, "time": 32953.99123287201, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1053752, "time": 32972.98385262489, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1053840, "time": 32975.86983418465, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1053888, "time": 32977.34640073776, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1053952, "time": 32979.29051041603, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1054032, "time": 32981.76042819023, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1054256, "time": 32988.6244225502, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1054256, "time": 32988.63580060005, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1054336, "time": 32991.094556331635, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1054424, "time": 32993.550948381424, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1054824, "time": 33005.773973464966, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1055040, "time": 33012.569680929184, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1055160, "time": 33016.00985407829, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1055256, "time": 33018.92788028717, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1055344, "time": 33021.84094166756, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1055576, "time": 33028.691793203354, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1055648, "time": 33031.190042734146, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1055960, "time": 33040.444103717804, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1056120, "time": 33045.29872584343, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1056200, "time": 33047.72605609894, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1056240, "time": 33049.162245988846, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1056560, "time": 33058.87924361229, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1056688, "time": 33062.86086535454, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1056744, "time": 33064.33200240135, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1056920, "time": 33070.14147734642, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1057000, "time": 33072.564977407455, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 1057008, "time": 33073.03795671463, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1057304, "time": 33081.85309958458, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1057304, "time": 33081.86089229584, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1057528, "time": 33088.716391325, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1057656, "time": 33092.760419130325, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1057768, "time": 33096.20897626877, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1057872, "time": 33099.61204338074, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1057952, "time": 33102.055783987045, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1058064, "time": 33105.481588602066, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1058088, "time": 33105.996639728546, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1058440, "time": 33116.73611879349, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1058656, "time": 33123.622745752335, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1058696, "time": 33124.63852095604, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1058752, "time": 33126.55502009392, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1058872, "time": 33129.97653532028, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 1059288, "time": 33142.57582759857, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1059384, "time": 33145.50615930557, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1059504, "time": 33149.38841366768, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1059560, "time": 33150.94768548012, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1059720, "time": 33155.77508211136, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1059912, "time": 33161.559165000916, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 1059968, "time": 33163.50201010704, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1060072, "time": 33166.421077251434, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1060072, "time": 33167.3636610508, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 1060072, "time": 33167.83640027046, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1060072, "time": 33168.03030705452, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1060072, "time": 33168.055649995804, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1060072, "time": 33168.266746520996, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 1060072, "time": 33168.5143597126, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1060072, "time": 33168.75866270065, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 1060072, "time": 33168.98012828827, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 1060088, "time": 33169.47548675537, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1060280, "time": 33175.350147247314, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1060560, "time": 33184.201187849045, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 1060576, "time": 33184.69200754166, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1060600, "time": 33185.22227978706, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1060840, "time": 33192.48949289322, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1060848, "time": 33192.9616587162, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1060976, "time": 33196.842669487, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1061016, "time": 33197.83945441246, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1061160, "time": 33202.199254989624, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1061424, "time": 33210.53545308113, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1061488, "time": 33212.480239868164, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1061528, "time": 33213.48000741005, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1061656, "time": 33217.37329483032, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1061968, "time": 33227.05142688751, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1061992, "time": 33227.55892467499, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1062168, "time": 33232.88194346428, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1062336, "time": 33238.17897963524, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1062377, "time": 33240.27608180046, "train_stats/mean_log_entropy": 0.0742195565715309, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6912899206180385, "train/action_min": 0.0, "train/action_std": 1.733508825302124, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012665183135852366, "train/actor_opt_grad_steps": 65295.0, "train/actor_opt_loss": -22.464011872168815, "train/adv_mag": 0.9230692905954795, "train/adv_max": 0.35546891878146936, "train/adv_mean": 0.0008983959824666335, "train/adv_min": -0.8582141352171945, "train/adv_std": 0.028837068089385434, "train/cont_avg": 0.9940197633044554, "train/cont_loss_mean": 0.02022371641913484, "train/cont_loss_std": 0.22704882698483986, "train/cont_neg_acc": 0.20415095575522668, "train/cont_neg_loss": 2.594595648127027, "train/cont_pos_acc": 0.9998881704736464, "train/cont_pos_loss": 0.00491955499671916, "train/cont_pred": 0.9938898903898673, "train/cont_rate": 0.9940197633044554, "train/dyn_loss_mean": 1.0000003157275739, "train/dyn_loss_std": 1.0092708162299478e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09981030897043719, "train/extr_critic_critic_opt_grad_steps": 65295.0, "train/extr_critic_critic_opt_loss": 11577.86046275526, "train/extr_critic_mag": 1.8326848190609772, "train/extr_critic_max": 1.8326848190609772, "train/extr_critic_mean": 1.7009502543081152, "train/extr_critic_min": 1.3241436788351229, "train/extr_critic_std": 0.0414422898654743, "train/extr_return_normed_mag": 0.9661267370280653, "train/extr_return_normed_max": 0.32042359597612136, "train/extr_return_normed_mean": 0.08021933994818442, "train/extr_return_normed_min": -0.854265560017954, "train/extr_return_normed_std": 0.05114989831010894, "train/extr_return_rate": 0.9997641090119239, "train/extr_return_raw_mag": 1.9420527786311537, "train/extr_return_raw_max": 1.9420527786311537, "train/extr_return_raw_mean": 1.7018486125634449, "train/extr_return_raw_min": 0.7673636226370784, "train/extr_return_raw_std": 0.05114989832855097, "train/extr_reward_mag": 0.25194557350460844, "train/extr_reward_max": 0.25194557350460844, "train/extr_reward_mean": 0.002617319109319423, "train/extr_reward_min": 5.901449977761448e-09, "train/extr_reward_std": 0.009276242938243074, "train/image_loss_mean": 0.09989167034330934, "train/image_loss_std": 0.1089899918009149, "train/model_loss_mean": 0.7425467318827563, "train/model_loss_std": 0.5158358868395928, "train/model_opt_grad_norm": 17.441802036702928, "train/model_opt_grad_steps": 65237.36138613861, "train/model_opt_loss": 3955.204922213413, "train/model_opt_model_opt_grad_overflow": 0.0049504950495049506, "train/model_opt_model_opt_grad_scale": 5297.029702970297, "train/policy_entropy_mag": 1.4023803944634918, "train/policy_entropy_max": 1.4023803944634918, "train/policy_entropy_mean": 0.09544325852305582, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12575343579496487, "train/policy_logprob_mag": 6.5510802528645735, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09551153579118228, "train/policy_logprob_min": -6.5510802528645735, "train/policy_logprob_std": 0.6352204875190659, "train/policy_randomness_mag": 0.7206810022344684, "train/policy_randomness_max": 0.7206810022344684, "train/policy_randomness_mean": 0.04904813360017125, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06462448580872894, "train/post_ent_mag": 40.78850134292451, "train/post_ent_max": 40.78850134292451, "train/post_ent_mean": 39.81788316103491, "train/post_ent_min": 38.680203862709575, "train/post_ent_std": 0.5263448151031344, "train/prior_ent_mag": 40.0377573258806, "train/prior_ent_max": 40.0377573258806, "train/prior_ent_mean": 39.06612902348584, "train/prior_ent_min": 37.77832578904558, "train/prior_ent_std": 0.38982121159534644, "train/rep_loss_mean": 1.0000003157275739, "train/rep_loss_std": 1.0092708162299478e-05, "train/reward_avg": 0.0027671134107144515, "train/reward_loss_mean": 0.02243113273173792, "train/reward_loss_std": 0.2712905577171852, "train/reward_max_data": 0.7736386141859659, "train/reward_max_pred": 0.26198262861459565, "train/reward_neg_acc": 0.999596747136352, "train/reward_neg_loss": 0.004293298177619345, "train/reward_pos_acc": 0.12444798297958799, "train/reward_pos_loss": 3.9248657919982874, "train/reward_pred": 0.002281627589537034, "train/reward_rate": 0.004626585705445545, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.014509458094835281, "report/cont_loss_std": 0.1813260316848755, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 2.890437126159668, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0032313093543052673, "report/cont_pred": 0.996627688407898, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08075593411922455, "report/image_loss_std": 0.09574207663536072, "report/model_loss_mean": 0.7093645334243774, "report/model_loss_std": 0.415158212184906, "report/post_ent_mag": 41.074684143066406, "report/post_ent_max": 41.074684143066406, "report/post_ent_mean": 39.865264892578125, "report/post_ent_min": 38.727439880371094, "report/post_ent_std": 0.6296902894973755, "report/prior_ent_mag": 40.15296936035156, "report/prior_ent_max": 40.15296936035156, "report/prior_ent_mean": 39.000648498535156, "report/prior_ent_min": 37.5543098449707, "report/prior_ent_std": 0.5371233820915222, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0014678954612463713, "report/reward_loss_mean": 0.014099137857556343, "report/reward_loss_std": 0.21703733503818512, "report/reward_max_data": 0.5625, "report/reward_max_pred": 0.05467855930328369, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002407070016488433, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.993300199508667, "report/reward_pred": 0.001201842213049531, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.03181086853146553, "eval/cont_loss_std": 0.3171215057373047, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.792454481124878, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.005926400888711214, "eval/cont_pred": 0.9941487312316895, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11981255561113358, "eval/image_loss_std": 0.11453897505998611, "eval/model_loss_mean": 0.7847156524658203, "eval/model_loss_std": 0.6925103068351746, "eval/post_ent_mag": 41.1249885559082, "eval/post_ent_max": 41.1249885559082, "eval/post_ent_mean": 40.219871520996094, "eval/post_ent_min": 38.84992218017578, "eval/post_ent_std": 0.5384289026260376, "eval/prior_ent_mag": 40.12464904785156, "eval/prior_ent_max": 40.12464904785156, "eval/prior_ent_mean": 39.303287506103516, "eval/prior_ent_min": 37.963768005371094, "eval/prior_ent_std": 0.3732346296310425, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0038421633653342724, "eval/reward_loss_mean": 0.033092185854911804, "eval/reward_loss_std": 0.36668628454208374, "eval/reward_max_data": 0.9281250238418579, "eval/reward_max_pred": 0.12667155265808105, "eval/reward_neg_acc": 0.9980353713035583, "eval/reward_neg_loss": 0.005040748976171017, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.792486190795898, "eval/reward_pred": 0.0024010748602449894, "eval/reward_rate": 0.005859375, "replay/size": 1000000.0, "replay/inserts": 32336.0, "replay/samples": 32336.0, "replay/insert_wait_avg": 1.219646403366006e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.291467752508572e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4200.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.117274874732608e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0830719470978, "timer/env.step_count": 4042.0, "timer/env.step_total": 39.26420259475708, "timer/env.step_frac": 0.03926094111193402, "timer/env.step_avg": 0.00971405309123134, "timer/env.step_min": 0.007687807083129883, "timer/env.step_max": 0.03556013107299805, "timer/replay._sample_count": 32336.0, "timer/replay._sample_total": 16.289711952209473, "timer/replay._sample_frac": 0.016288358846525065, "timer/replay._sample_avg": 0.000503763976750664, "timer/replay._sample_min": 0.0003917217254638672, "timer/replay._sample_max": 0.029675006866455078, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4567.0, "timer/agent.policy_total": 47.5942120552063, "timer/agent.policy_frac": 0.04759025863975821, "timer/agent.policy_avg": 0.010421329550078016, "timer/agent.policy_min": 0.008605718612670898, "timer/agent.policy_max": 0.09067463874816895, "timer/dataset_train_count": 2021.0, "timer/dataset_train_total": 0.20972275733947754, "timer/dataset_train_frac": 0.00020970533670884033, "timer/dataset_train_avg": 0.00010377177503190377, "timer/dataset_train_min": 8.821487426757812e-05, "timer/dataset_train_max": 0.0010640621185302734, "timer/agent.train_count": 2021.0, "timer/agent.train_total": 901.5395662784576, "timer/agent.train_frac": 0.9014646798522624, "timer/agent.train_avg": 0.4460858813846896, "timer/agent.train_min": 0.4349985122680664, "timer/agent.train_max": 0.6727006435394287, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4844090938568115, "timer/agent.report_frac": 0.00048436885639279744, "timer/agent.report_avg": 0.24220454692840576, "timer/agent.report_min": 0.23663592338562012, "timer/agent.report_max": 0.2477731704711914, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.075344195579833e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 32.332761022520344}
{"step": 1062408, "time": 33241.03810572624, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1062720, "time": 33250.79208564758, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1062800, "time": 33253.21126747131, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1063016, "time": 33259.55030298233, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1063160, "time": 33263.93851161003, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1063224, "time": 33265.897701740265, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1063408, "time": 33271.824951171875, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1063544, "time": 33275.73351311684, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1063640, "time": 33278.64667582512, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 1063672, "time": 33279.61781167984, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1063768, "time": 33282.537606716156, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1064056, "time": 33291.26124763489, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1064288, "time": 33298.51361203194, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1064520, "time": 33305.43086862564, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1064616, "time": 33308.3342461586, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1064656, "time": 33309.759557724, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1064696, "time": 33310.74422335625, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 1064840, "time": 33315.108669281006, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1065152, "time": 33325.239439964294, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1065368, "time": 33331.63667297363, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1065664, "time": 33340.81812977791, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 1065680, "time": 33341.30707001686, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1065736, "time": 33342.80423283577, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1065992, "time": 33350.57476902008, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1066080, "time": 33353.470104932785, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1066224, "time": 33357.846903562546, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1066232, "time": 33357.87628078461, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 1066472, "time": 33365.23256897926, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1066544, "time": 33367.66092348099, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1066640, "time": 33370.55015325546, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1066664, "time": 33371.06363892555, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1066848, "time": 33376.855810403824, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1066968, "time": 33380.24880671501, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1067568, "time": 33398.64965510368, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1067568, "time": 33398.65706253052, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1067672, "time": 33401.59872055054, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1067880, "time": 33407.88440775871, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1067936, "time": 33409.80554533005, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1068096, "time": 33414.63379096985, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1068240, "time": 33418.975761175156, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1068312, "time": 33421.0714738369, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1068408, "time": 33423.96675467491, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 1068432, "time": 33424.942276239395, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1068608, "time": 33430.24879193306, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1068696, "time": 33432.678487062454, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1068920, "time": 33439.45351815224, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1068968, "time": 33440.900503873825, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1069008, "time": 33442.32060241699, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1069192, "time": 33447.68805336952, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1069280, "time": 33450.70348119736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1069376, "time": 33453.63093209267, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1069376, "time": 33453.646431446075, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1069472, "time": 33456.56207585335, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1069736, "time": 33464.36230349541, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1069880, "time": 33468.73666858673, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1070008, "time": 33472.603628873825, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1070048, "time": 33474.05476021767, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1070056, "time": 33474.083188056946, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1070056, "time": 33474.76512050629, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 1070056, "time": 33474.85529208183, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 1070056, "time": 33475.38728046417, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1070056, "time": 33475.43340468407, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1070056, "time": 33476.14140200615, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1070056, "time": 33476.88493156433, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1070056, "time": 33476.9984960556, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 1070056, "time": 33477.36440896988, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1070120, "time": 33479.3016064167, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 1070312, "time": 33485.21400141716, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1070448, "time": 33489.581867694855, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1070896, "time": 33503.130289554596, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1070992, "time": 33506.05597162247, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1071104, "time": 33509.44052577019, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1071104, "time": 33509.44734573364, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1071184, "time": 33511.97046279907, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 1071200, "time": 33512.46309423447, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1071256, "time": 33513.936819791794, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1071272, "time": 33514.42967104912, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1071776, "time": 33529.885999917984, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1071856, "time": 33532.33205962181, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 1072056, "time": 33538.15049982071, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1072080, "time": 33539.09667181969, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1072096, "time": 33539.58468914032, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1072176, "time": 33542.09777569771, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1072400, "time": 33548.84785461426, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1072432, "time": 33549.84183835983, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1072712, "time": 33558.04887676239, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 1072728, "time": 33558.53593420982, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1072768, "time": 33559.97883296013, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1073088, "time": 33569.67627930641, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1073288, "time": 33576.08010339737, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1073296, "time": 33576.55061459541, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1073392, "time": 33579.475372076035, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1073416, "time": 33579.9871776104, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1073520, "time": 33583.34767770767, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1073672, "time": 33587.729949235916, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1073808, "time": 33592.07209587097, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1073960, "time": 33596.468326091766, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1074104, "time": 33600.93302869797, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1074176, "time": 33603.33675789833, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1074296, "time": 33606.75398206711, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1074352, "time": 33608.690928936005, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1074376, "time": 33609.20226812363, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1074728, "time": 33619.83835864067, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1074760, "time": 33620.80215859413, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1075184, "time": 33633.93402004242, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1075200, "time": 33634.42336845398, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1075208, "time": 33634.457839250565, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1075320, "time": 33637.85517525673, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1075384, "time": 33639.78125953674, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1075392, "time": 33640.2481379509, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 1075800, "time": 33652.38309431076, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1075816, "time": 33652.87062001228, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1075968, "time": 33657.69647908211, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1076200, "time": 33664.551234960556, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1076232, "time": 33665.518448352814, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1076240, "time": 33665.98145198822, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1076400, "time": 33670.808514118195, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1076400, "time": 33670.81584525108, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1076528, "time": 33674.68306350708, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1076616, "time": 33677.14247250557, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1076680, "time": 33679.084070920944, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1076752, "time": 33681.509058475494, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1076792, "time": 33682.49930715561, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1077168, "time": 33694.17222046852, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1077248, "time": 33696.598954916, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1077384, "time": 33700.47380256653, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1077416, "time": 33701.472430467606, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1077448, "time": 33702.442898988724, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1077512, "time": 33704.370151758194, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1077728, "time": 33711.14729857445, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1077800, "time": 33713.101529598236, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1077968, "time": 33718.40046596527, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1078176, "time": 33724.73903632164, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1078344, "time": 33729.58581972122, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1078352, "time": 33730.07057571411, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1078432, "time": 33732.48472428322, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1078592, "time": 33737.319276332855, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1078624, "time": 33738.28803420067, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1078672, "time": 33739.75257205963, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1078912, "time": 33747.0052485466, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1079080, "time": 33751.95581793785, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1079528, "time": 33765.49047446251, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1079560, "time": 33766.46109461784, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1079600, "time": 33767.898802280426, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1079632, "time": 33768.90131020546, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1079728, "time": 33771.79858970642, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1079872, "time": 33776.1751666069, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1079984, "time": 33779.59643959999, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1080040, "time": 33782.487963438034, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1080040, "time": 33782.853743076324, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1080040, "time": 33783.64146542549, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1080040, "time": 33783.66816020012, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 1080040, "time": 33784.07420063019, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1080040, "time": 33784.17822647095, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 1080040, "time": 33784.47518157959, "eval_episode/length": 173.0, "eval_episode/score": 0.4593749940395355, "eval_episode/reward_rate": 0.005747126436781609}
{"step": 1080040, "time": 33785.143473386765, "eval_episode/length": 209.0, "eval_episode/score": 0.34687501192092896, "eval_episode/reward_rate": 0.004761904761904762}
{"step": 1080224, "time": 33790.937222480774, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1080248, "time": 33791.44498229027, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1080352, "time": 33794.829071998596, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1080392, "time": 33795.819685697556, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1080592, "time": 33802.07856655121, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1080800, "time": 33808.34067630768, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 1080912, "time": 33811.8292195797, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1080984, "time": 33813.78794384003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1081064, "time": 33816.21685004234, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1081304, "time": 33823.497460603714, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1081472, "time": 33829.253890275955, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1081536, "time": 33831.1913318634, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1081760, "time": 33837.95799064636, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1081816, "time": 33839.42564320564, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1081880, "time": 33841.43229866028, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 1082440, "time": 33858.376001119614, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1082528, "time": 33861.27079629898, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1082600, "time": 33863.22777342796, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1082752, "time": 33868.06693172455, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1082824, "time": 33870.028077840805, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1082896, "time": 33872.592222929, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1082944, "time": 33874.05676531792, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1083016, "time": 33876.03061747551, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1083344, "time": 33886.15240073204, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1083592, "time": 33893.440073251724, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1083640, "time": 33894.92876815796, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1083848, "time": 33901.297859191895, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1084144, "time": 33910.46698260307, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 1084296, "time": 33914.85102391243, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1084360, "time": 33916.796377658844, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1084656, "time": 33925.973242521286, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 1084664, "time": 33926.001569509506, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1084872, "time": 33932.37786817551, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1084904, "time": 33933.35517716408, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1084976, "time": 33935.76714038849, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1085016, "time": 33936.769072532654, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1085024, "time": 33937.23731255531, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1085296, "time": 33945.47504115105, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1085440, "time": 33949.841307640076, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1085464, "time": 33950.357820510864, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1085672, "time": 33956.64987921715, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1085688, "time": 33957.13694477081, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1085888, "time": 33963.54358148575, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1086008, "time": 33966.945618629456, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1086128, "time": 33970.81123518944, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1086176, "time": 33972.267684459686, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1086200, "time": 33972.79505777359, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1086344, "time": 33977.14064979553, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1086528, "time": 33982.944313287735, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1086848, "time": 33992.70224547386, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1086904, "time": 33994.17678356171, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1087008, "time": 33997.55380630493, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1087088, "time": 33999.9598133564, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1087128, "time": 34000.94941115379, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1087424, "time": 34010.12180233002, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1087448, "time": 34010.633090257645, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1087456, "time": 34011.10078430176, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1087744, "time": 34019.8101041317, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 1088136, "time": 34031.49148631096, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1088224, "time": 34034.36916923523, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1088264, "time": 34035.36663556099, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1088264, "time": 34035.37490558624, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1088336, "time": 34037.79374432564, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1088456, "time": 34041.209070682526, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1088656, "time": 34047.484001636505, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1088936, "time": 34055.86629033089, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1089192, "time": 34063.61362361908, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1089280, "time": 34066.51215457916, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1089288, "time": 34066.54004049301, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1089472, "time": 34072.320267915726, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1089520, "time": 34073.77069354057, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1089616, "time": 34077.24704217911, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1089744, "time": 34081.27029442787, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1089912, "time": 34086.16267204285, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1089992, "time": 34088.57003688812, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1090024, "time": 34090.89018917084, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1090024, "time": 34091.32752394676, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1090024, "time": 34091.6517636776, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1090024, "time": 34091.754756212234, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 1090024, "time": 34092.416853666306, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 1090024, "time": 34092.54892897606, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 1090024, "time": 34092.72074460983, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 1090024, "time": 34092.873567819595, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1090072, "time": 34094.344124794006, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1090344, "time": 34102.55129265785, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1090384, "time": 34104.00447511673, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1090432, "time": 34105.45133113861, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1090480, "time": 34106.9030790329, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1090528, "time": 34108.38281726837, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1090760, "time": 34115.29694366455, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1091072, "time": 34125.02229976654, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1091160, "time": 34127.47781562805, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1091224, "time": 34129.40618085861, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1091520, "time": 34138.57054710388, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1091592, "time": 34140.64014387131, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1091632, "time": 34142.08671283722, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1091640, "time": 34142.11440253258, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1091744, "time": 34145.46518993378, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1091752, "time": 34145.49183702469, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1092224, "time": 34159.934510707855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1092280, "time": 34161.41724705696, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1092344, "time": 34163.357166051865, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1092472, "time": 34167.24278473854, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1092792, "time": 34177.03720545769, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1092792, "time": 34177.04512691498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1092920, "time": 34180.92824316025, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1093000, "time": 34183.3426194191, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1093272, "time": 34191.54989385605, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1093304, "time": 34192.526312589645, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1093392, "time": 34195.41306066513, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 1093800, "time": 34207.69083714485, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1093816, "time": 34208.176649808884, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1093888, "time": 34210.593786001205, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1093976, "time": 34213.030294418335, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1094016, "time": 34214.46376776695, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1094176, "time": 34219.273515462875, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1094392, "time": 34225.56325030327, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 1094552, "time": 34230.481939315796, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1094752, "time": 34236.74448776245, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 1094841, "time": 34240.34786057472, "train_stats/mean_log_entropy": 0.07395659627548727, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5658274683459052, "train/action_min": 0.0, "train/action_std": 1.7481645210623153, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010181980106630935, "train/actor_opt_grad_steps": 67320.0, "train/actor_opt_loss": -22.60023143843477, "train/adv_mag": 0.8385798578779099, "train/adv_max": 0.30755472241951326, "train/adv_mean": 0.0006175503658842842, "train/adv_min": -0.773677857051342, "train/adv_std": 0.027298243097006687, "train/cont_avg": 0.9937750153940886, "train/cont_loss_mean": 0.02131857444747842, "train/cont_loss_std": 0.23262567061178496, "train/cont_neg_acc": 0.18713383416970963, "train/cont_neg_loss": 2.5990302114577717, "train/cont_pos_acc": 0.9998450942814644, "train/cont_pos_loss": 0.005055359586513615, "train/cont_pred": 0.9938468909615954, "train/cont_rate": 0.9937750153940886, "train/dyn_loss_mean": 1.0000001133369107, "train/dyn_loss_std": 3.6271008561947957e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08956163538060165, "train/extr_critic_critic_opt_grad_steps": 67320.0, "train/extr_critic_critic_opt_loss": 11916.678157712438, "train/extr_critic_mag": 1.8432787439506042, "train/extr_critic_max": 1.8432787439506042, "train/extr_critic_mean": 1.7079474491438842, "train/extr_critic_min": 1.3833068380214897, "train/extr_critic_std": 0.037449747718540316, "train/extr_return_normed_mag": 0.8883329383258162, "train/extr_return_normed_max": 0.2975333347696389, "train/extr_return_normed_mean": 0.07249451344236364, "train/extr_return_normed_min": -0.7679131900148438, "train/extr_return_normed_std": 0.04726688404168401, "train/extr_return_rate": 0.9997992621266784, "train/extr_return_raw_mag": 1.9336038123210664, "train/extr_return_raw_max": 1.9336038123210664, "train/extr_return_raw_mean": 1.7085650642517165, "train/extr_return_raw_min": 0.8681572875365835, "train/extr_return_raw_std": 0.04726688380311862, "train/extr_reward_mag": 0.23622128294019276, "train/extr_reward_max": 0.23622128294019276, "train/extr_reward_mean": 0.002601975175377734, "train/extr_reward_min": 3.875770005099292e-08, "train/extr_reward_std": 0.009069682112688502, "train/image_loss_mean": 0.10103544871795353, "train/image_loss_std": 0.11059938308787463, "train/model_loss_mean": 0.7462438239252626, "train/model_loss_std": 0.5333933455897082, "train/model_opt_grad_norm": 16.820908257526717, "train/model_opt_grad_steps": 67260.43349753694, "train/model_opt_loss": 3861.708712573122, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5172.413793103448, "train/policy_entropy_mag": 1.3260351959707701, "train/policy_entropy_max": 1.3260351959707701, "train/policy_entropy_mean": 0.09648708397238126, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12380015890439743, "train/policy_logprob_mag": 6.55108026917932, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09611728101087909, "train/policy_logprob_min": -6.55108026917932, "train/policy_logprob_std": 0.6334954165472773, "train/policy_randomness_mag": 0.681447329192326, "train/policy_randomness_max": 0.681447329192326, "train/policy_randomness_mean": 0.04958455416883154, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06362070034950824, "train/post_ent_mag": 40.75438960784762, "train/post_ent_max": 40.75438960784762, "train/post_ent_mean": 39.71370866145994, "train/post_ent_min": 38.5200459898399, "train/post_ent_std": 0.5535098011857771, "train/prior_ent_mag": 40.1965512994475, "train/prior_ent_max": 40.1965512994475, "train/prior_ent_mean": 39.05715720641789, "train/prior_ent_min": 37.59619018479521, "train/prior_ent_std": 0.4919523106419981, "train/rep_loss_mean": 1.0000001133369107, "train/rep_loss_std": 3.6271008561947957e-06, "train/reward_avg": 0.0029772828879887745, "train/reward_loss_mean": 0.02388970964023926, "train/reward_loss_std": 0.282002959409591, "train/reward_max_data": 0.791009849368645, "train/reward_max_pred": 0.25033036769904526, "train/reward_neg_acc": 0.9996034679154457, "train/reward_neg_loss": 0.004403511457961842, "train/reward_pos_acc": 0.11350642389325953, "train/reward_pos_loss": 3.9521154645663588, "train/reward_pred": 0.0023163013112056873, "train/reward_rate": 0.004940540332512316, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.011394821107387543, "report/cont_loss_std": 0.12806755304336548, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 2.8711636066436768, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00579840550199151, "report/cont_pred": 0.994297444820404, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09039275348186493, "report/image_loss_std": 0.09860584884881973, "report/model_loss_mean": 0.7149575352668762, "report/model_loss_std": 0.34395676851272583, "report/post_ent_mag": 40.81520080566406, "report/post_ent_max": 40.81520080566406, "report/post_ent_mean": 39.77153015136719, "report/post_ent_min": 38.537689208984375, "report/post_ent_std": 0.5698569416999817, "report/prior_ent_mag": 39.998294830322266, "report/prior_ent_max": 39.998294830322266, "report/prior_ent_mean": 38.80528259277344, "report/prior_ent_min": 37.44695281982422, "report/prior_ent_std": 0.4588545560836792, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0015838623512536287, "report/reward_loss_mean": 0.013169948942959309, "report/reward_loss_std": 0.18707707524299622, "report/reward_max_data": 0.8374999761581421, "report/reward_max_pred": 0.06495261192321777, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00492754066362977, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.225041389465332, "report/reward_pred": 0.002217419445514679, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.03268267214298248, "eval/cont_loss_std": 0.4147617518901825, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.158813953399658, "eval/cont_pos_acc": 0.9970587491989136, "eval/cont_pos_loss": 0.012580196373164654, "eval/cont_pred": 0.9917758703231812, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11628728359937668, "eval/image_loss_std": 0.12006960064172745, "eval/model_loss_mean": 0.7685314416885376, "eval/model_loss_std": 0.5984542369842529, "eval/post_ent_mag": 40.80060577392578, "eval/post_ent_max": 40.80060577392578, "eval/post_ent_mean": 39.90275573730469, "eval/post_ent_min": 38.665977478027344, "eval/post_ent_std": 0.43669721484184265, "eval/prior_ent_mag": 39.998294830322266, "eval/prior_ent_max": 39.998294830322266, "eval/prior_ent_mean": 38.94424819946289, "eval/prior_ent_min": 38.058860778808594, "eval/prior_ent_std": 0.361555814743042, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.001940918038599193, "eval/reward_loss_mean": 0.01956140249967575, "eval/reward_loss_std": 0.2598239779472351, "eval/reward_max_data": 0.8687499761581421, "eval/reward_max_pred": 0.167455792427063, "eval/reward_neg_acc": 0.9970616698265076, "eval/reward_neg_loss": 0.005620588082820177, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.76408576965332, "eval/reward_pred": 0.0024028355255723, "eval/reward_rate": 0.0029296875, "replay/size": 1000000.0, "replay/inserts": 32464.0, "replay/samples": 32464.0, "replay/insert_wait_avg": 1.2200151305295023e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.326392013489642e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4344.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.123322527272486e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.979594707489, "timer/env.step_count": 4058.0, "timer/env.step_total": 39.414477586746216, "timer/env.step_frac": 0.039415281867102116, "timer/env.step_avg": 0.009712784028276545, "timer/env.step_min": 0.00772547721862793, "timer/env.step_max": 0.054167985916137695, "timer/replay._sample_count": 32464.0, "timer/replay._sample_total": 16.294000148773193, "timer/replay._sample_frac": 0.01629433263939697, "timer/replay._sample_avg": 0.0005019098123698002, "timer/replay._sample_min": 0.0003657341003417969, "timer/replay._sample_max": 0.016808748245239258, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4601.0, "timer/agent.policy_total": 47.954089641571045, "timer/agent.policy_frac": 0.04795506817876462, "timer/agent.policy_avg": 0.010422536327226917, "timer/agent.policy_min": 0.008501529693603516, "timer/agent.policy_max": 0.08015084266662598, "timer/dataset_train_count": 2029.0, "timer/dataset_train_total": 0.20531630516052246, "timer/dataset_train_frac": 0.00020532049478527706, "timer/dataset_train_avg": 0.00010119088475136642, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.0010597705841064453, "timer/agent.train_count": 2029.0, "timer/agent.train_total": 901.146066904068, "timer/agent.train_frac": 0.9011644554283815, "timer/agent.train_avg": 0.44413310345198026, "timer/agent.train_min": 0.43258142471313477, "timer/agent.train_max": 0.7276194095611572, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4760780334472656, "timer/agent.report_frac": 0.0004760877481570277, "timer/agent.report_avg": 0.2380390167236328, "timer/agent.report_min": 0.2321455478668213, "timer/agent.report_max": 0.24393248558044434, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.6703425750588486e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 32.46409954471213}
{"step": 1094944, "time": 34243.43122076988, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1094992, "time": 34244.890432834625, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1095024, "time": 34245.86196732521, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1095088, "time": 34247.80225658417, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1095272, "time": 34253.11904883385, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1095320, "time": 34254.58550643921, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1095568, "time": 34262.376030921936, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1095688, "time": 34265.80147075653, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1095808, "time": 34269.66278529167, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1095848, "time": 34270.65622711182, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1095960, "time": 34274.04476213455, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 1096248, "time": 34282.740884780884, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1096368, "time": 34286.6276948452, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1096464, "time": 34289.52897787094, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1096472, "time": 34289.55605697632, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1096488, "time": 34290.04689002037, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1096544, "time": 34292.063515901566, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1096560, "time": 34292.55415344238, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1096712, "time": 34296.94462394714, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1096816, "time": 34300.31583118439, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1097144, "time": 34310.004455804825, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1097144, "time": 34310.01104259491, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1097192, "time": 34311.455819129944, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1097264, "time": 34313.89003419876, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1097304, "time": 34314.90130996704, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1097504, "time": 34321.355424165726, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1097584, "time": 34323.786652326584, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1097608, "time": 34324.295781850815, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1097712, "time": 34327.66928625107, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1097776, "time": 34330.08765745163, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1097960, "time": 34335.41688299179, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1097968, "time": 34335.88796067238, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1098048, "time": 34338.32901096344, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1098336, "time": 34347.0348110199, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1098448, "time": 34350.560732364655, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1098464, "time": 34351.05204772949, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1098600, "time": 34354.947436094284, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1098608, "time": 34355.41860795021, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1098632, "time": 34355.93337535858, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1098720, "time": 34358.8255314827, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1099008, "time": 34367.51178431511, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1099160, "time": 34371.90729498863, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1099416, "time": 34379.69033789635, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1099416, "time": 34379.69781780243, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1099608, "time": 34385.591322660446, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1099608, "time": 34385.59896874428, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 1099680, "time": 34388.00338411331, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1100008, "time": 34398.47912764549, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 1100008, "time": 34399.30700325966, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1100008, "time": 34399.67658615112, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1100008, "time": 34399.970448970795, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 1100008, "time": 34400.270659685135, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 1100008, "time": 34400.70708274841, "eval_episode/length": 169.0, "eval_episode/score": 0.47187501192092896, "eval_episode/reward_rate": 0.0058823529411764705}
{"step": 1100008, "time": 34400.93064403534, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1100008, "time": 34400.99386096001, "eval_episode/length": 184.0, "eval_episode/score": 0.42500001192092896, "eval_episode/reward_rate": 0.005405405405405406}
{"step": 1100080, "time": 34403.37636256218, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1100168, "time": 34405.82164978981, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1100336, "time": 34411.16863512993, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1100408, "time": 34413.11791181564, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1100480, "time": 34415.51130604744, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 1100560, "time": 34417.94239497185, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1100568, "time": 34417.97163963318, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1101056, "time": 34432.96353507042, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1101192, "time": 34436.86937832832, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 1101240, "time": 34438.35100364685, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1101384, "time": 34442.796879053116, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1101584, "time": 34449.07933831215, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1101592, "time": 34449.10714197159, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1101600, "time": 34449.57350873947, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1101728, "time": 34453.4499399662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1101792, "time": 34455.389655828476, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1101816, "time": 34455.895414590836, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1101992, "time": 34461.208537817, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1102000, "time": 34461.67541694641, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1102184, "time": 34467.0287528038, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1102256, "time": 34469.45509934425, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1102624, "time": 34480.68836355209, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1102680, "time": 34482.18254947662, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1103160, "time": 34496.69924759865, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1103168, "time": 34497.16713786125, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1103360, "time": 34503.05463767052, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1103368, "time": 34503.08320903778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1103416, "time": 34504.53655290604, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1103472, "time": 34506.46548962593, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 1103496, "time": 34506.973095178604, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1103584, "time": 34509.84111523628, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1103896, "time": 34519.0213971138, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1104200, "time": 34528.20766019821, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1104312, "time": 34531.67378973961, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1104312, "time": 34531.68161153793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1104368, "time": 34533.59662771225, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1104656, "time": 34542.298233509064, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1104736, "time": 34544.710530757904, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1104800, "time": 34546.6669216156, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1105032, "time": 34553.44778227806, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1105152, "time": 34557.305207014084, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 1105336, "time": 34562.735721349716, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1105360, "time": 34563.685631513596, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1105408, "time": 34565.17077541351, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1105440, "time": 34566.13727593422, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1106016, "time": 34583.99633216858, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1106104, "time": 34586.457236766815, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1106512, "time": 34599.119725465775, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 1106528, "time": 34599.60976243019, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1106600, "time": 34601.57434773445, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1106656, "time": 34603.4843583107, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1106720, "time": 34605.44666147232, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1106920, "time": 34611.27733159065, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1107008, "time": 34614.17259454727, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1107056, "time": 34615.63799953461, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 1107080, "time": 34616.14852356911, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1107136, "time": 34618.05656147003, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1107640, "time": 34633.206832408905, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1107928, "time": 34641.89028286934, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1107968, "time": 34643.33670067787, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1108080, "time": 34646.71837902069, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1108144, "time": 34648.65915608406, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1108304, "time": 34653.56943106651, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1108552, "time": 34660.80903458595, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1108664, "time": 34664.204147577286, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1108672, "time": 34664.67155146599, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1108816, "time": 34669.024297475815, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1108864, "time": 34670.47018933296, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 1109072, "time": 34676.77268028259, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1109232, "time": 34681.69958281517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1109384, "time": 34686.06271934509, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1109432, "time": 34687.53588795662, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1109488, "time": 34689.448667526245, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1109656, "time": 34694.29677820206, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1109880, "time": 34701.076655864716, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1109880, "time": 34701.08413696289, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1110096, "time": 34708.6003010273, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 1110096, "time": 34709.20425391197, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1110096, "time": 34709.73477959633, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1110096, "time": 34709.82978391647, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1110096, "time": 34710.21686720848, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1110096, "time": 34710.36853432655, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 1110096, "time": 34710.568469285965, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 1110096, "time": 34710.57477355003, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1110144, "time": 34712.0280418396, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1110160, "time": 34712.522141218185, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1110392, "time": 34719.33409285545, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1110448, "time": 34721.24417257309, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1110448, "time": 34721.25161552429, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1110472, "time": 34721.757855176926, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1110672, "time": 34728.00002741814, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1110784, "time": 34731.36081671715, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1111000, "time": 34737.66999530792, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1111048, "time": 34739.12078499794, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1111096, "time": 34740.65935707092, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1111264, "time": 34745.97959923744, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1111352, "time": 34748.45339488983, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1111408, "time": 34750.35752892494, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1111408, "time": 34750.36418890953, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1111488, "time": 34752.815338134766, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1111832, "time": 34762.99993801117, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1111840, "time": 34763.46751356125, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1112160, "time": 34773.27494478226, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1112176, "time": 34773.76488280296, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1112232, "time": 34775.23372554779, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1112336, "time": 34778.618267297745, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1112488, "time": 34782.98813915253, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1112584, "time": 34785.87799334526, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1112888, "time": 34795.06446528435, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1113040, "time": 34799.88624048233, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1113328, "time": 34808.634752988815, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1113488, "time": 34813.47424244881, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1113840, "time": 34824.082706451416, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1113872, "time": 34825.06948971748, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1113984, "time": 34828.454468011856, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1113984, "time": 34828.46272158623, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 1114240, "time": 34836.79952764511, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1114288, "time": 34838.243218421936, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 1114352, "time": 34840.190078020096, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1114416, "time": 34842.11787867546, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 1114888, "time": 34856.16320538521, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1115264, "time": 34867.89897251129, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1115320, "time": 34869.38932847977, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1115336, "time": 34869.87886071205, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1115408, "time": 34872.267904520035, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1115416, "time": 34872.298372507095, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1115504, "time": 34875.1977930069, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1115792, "time": 34883.90546250343, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1116144, "time": 34894.63110566139, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 1116232, "time": 34897.07283473015, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1116496, "time": 34905.27860689163, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1116512, "time": 34905.764375925064, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1116784, "time": 34914.00758433342, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 1116800, "time": 34914.49743247032, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1116912, "time": 34917.88928079605, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1116976, "time": 34919.821546792984, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1117000, "time": 34920.367283821106, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1117168, "time": 34925.73554420471, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1117280, "time": 34929.17509388924, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1117384, "time": 34932.082021951675, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1117456, "time": 34934.487471818924, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1117544, "time": 34936.92044901848, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1117616, "time": 34939.324159383774, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1117792, "time": 34944.62227201462, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1117872, "time": 34947.04454493523, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1118088, "time": 34953.42767190933, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1118360, "time": 34961.66791701317, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1118368, "time": 34962.14124059677, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1118520, "time": 34966.52001976967, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1118664, "time": 34970.862248659134, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1118912, "time": 34978.597512960434, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1119088, "time": 34984.01270198822, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1119096, "time": 34984.04031300545, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1119424, "time": 34994.14973163605, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1119424, "time": 34994.15681052208, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1119472, "time": 34995.62060594559, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1119552, "time": 34998.04024243355, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1119552, "time": 34998.0478682518, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1119688, "time": 35001.94550490379, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1119832, "time": 35006.30688023567, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1119848, "time": 35006.79789471626, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1119872, "time": 35007.75192403793, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1119880, "time": 35007.78055071831, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1120080, "time": 35015.18015789986, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 1120080, "time": 35015.56081914902, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 1120080, "time": 35015.7992606163, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1120080, "time": 35016.5718562603, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1120080, "time": 35016.616440057755, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1120080, "time": 35016.6416888237, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 1120080, "time": 35017.157416820526, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 1120080, "time": 35017.50635147095, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 1120248, "time": 35022.35463500023, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1120264, "time": 35022.840364694595, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1120384, "time": 35026.681174993515, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1120664, "time": 35034.92616438866, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1120856, "time": 35040.81552195549, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1120920, "time": 35042.75884079933, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1121144, "time": 35049.518018722534, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1121216, "time": 35051.90138506889, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1121352, "time": 35055.780980825424, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1121368, "time": 35056.27018618584, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1121416, "time": 35057.732236623764, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1121600, "time": 35063.49962925911, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1121768, "time": 35068.404723882675, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1122328, "time": 35085.878736019135, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1122336, "time": 35086.34630727768, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1122352, "time": 35086.85809278488, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 1122608, "time": 35094.59627079964, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1122728, "time": 35098.02678847313, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1122784, "time": 35099.93937778473, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1122832, "time": 35101.53552865982, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 1122840, "time": 35101.56361889839, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1123112, "time": 35109.76469182968, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1123416, "time": 35118.958532094955, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 1123536, "time": 35122.81737327576, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1123768, "time": 35129.611644506454, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1123896, "time": 35133.57965230942, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1124008, "time": 35136.984380960464, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1124192, "time": 35142.77849340439, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1124200, "time": 35142.80760240555, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1124448, "time": 35150.53500247002, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1124472, "time": 35151.049630880356, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 1124736, "time": 35159.21307396889, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1124752, "time": 35159.720134973526, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1125040, "time": 35168.509179115295, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1125040, "time": 35168.51762890816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1125208, "time": 35173.38375258446, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1125376, "time": 35178.68560886383, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1125448, "time": 35180.64466524124, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1125664, "time": 35187.36679697037, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1125768, "time": 35190.37763738632, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1125920, "time": 35195.224939107895, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 1126448, "time": 35211.15082001686, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1126568, "time": 35214.559408426285, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1126592, "time": 35215.50987100601, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1126704, "time": 35218.898560762405, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 1126856, "time": 35223.358201503754, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1126968, "time": 35226.738958358765, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1127040, "time": 35229.15480685234, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 1127056, "time": 35229.64626932144, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1127336, "time": 35237.882509708405, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1127384, "time": 35239.328171253204, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1127385, "time": 35240.37661719322, "train_stats/mean_log_entropy": 0.07733310380648718, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6303816170528016, "train/action_min": 0.0, "train/action_std": 1.7709415135125222, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010949070914074998, "train/actor_opt_grad_steps": 69350.0, "train/actor_opt_loss": -30.907011905914455, "train/adv_mag": 0.832631094115121, "train/adv_max": 0.31258325212694743, "train/adv_mean": 0.003151349588698023, "train/adv_min": -0.7623843776768652, "train/adv_std": 0.031117815781256247, "train/cont_avg": 0.9936451277709359, "train/cont_loss_mean": 0.022166284310443353, "train/cont_loss_std": 0.23979094822712133, "train/cont_neg_acc": 0.18051646279143582, "train/cont_neg_loss": 2.662817116441398, "train/cont_pos_acc": 0.9998886626342247, "train/cont_pos_loss": 0.005213136480790861, "train/cont_pred": 0.9936678808898174, "train/cont_rate": 0.9936451277709359, "train/dyn_loss_mean": 1.000001375898352, "train/dyn_loss_std": 4.4004257029757417e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10045798478895808, "train/extr_critic_critic_opt_grad_steps": 69350.0, "train/extr_critic_critic_opt_loss": 12687.564467556958, "train/extr_critic_mag": 1.933514957944748, "train/extr_critic_max": 1.933514957944748, "train/extr_critic_mean": 1.8045446913817833, "train/extr_critic_min": 1.479122490131209, "train/extr_critic_std": 0.04710455145228085, "train/extr_return_normed_mag": 0.8675799874836588, "train/extr_return_normed_max": 0.33391550667767456, "train/extr_return_normed_mean": 0.09781128208478683, "train/extr_return_normed_min": -0.7129230270244805, "train/extr_return_normed_std": 0.057492028481414166, "train/extr_return_rate": 0.9998364615910159, "train/extr_return_raw_mag": 2.0438001091257103, "train/extr_return_raw_max": 2.0438001091257103, "train/extr_return_raw_mean": 1.8076959748573491, "train/extr_return_raw_min": 0.9969615754235555, "train/extr_return_raw_std": 0.05749202849976535, "train/extr_reward_mag": 0.26587418147495817, "train/extr_reward_max": 0.26587418147495817, "train/extr_reward_mean": 0.0029407199644231295, "train/extr_reward_min": 2.290227730285945e-08, "train/extr_reward_std": 0.010487876231483931, "train/image_loss_mean": 0.1026550157023181, "train/image_loss_std": 0.11124964898883416, "train/model_loss_mean": 0.7499214924615005, "train/model_loss_std": 0.5491094338923252, "train/model_opt_grad_norm": 16.832664924302126, "train/model_opt_grad_steps": 69288.52216748768, "train/model_opt_loss": 3951.8451078067274, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5270.935960591133, "train/policy_entropy_mag": 1.3714393488879275, "train/policy_entropy_max": 1.3714393488879275, "train/policy_entropy_mean": 0.09331757663359196, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11840870124953133, "train/policy_logprob_mag": 6.551080243340854, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09424760489921852, "train/policy_logprob_min": -6.551080243340854, "train/policy_logprob_std": 0.6369763228106381, "train/policy_randomness_mag": 0.7047804505954235, "train/policy_randomness_max": 0.7047804505954235, "train/policy_randomness_mean": 0.04795574991427032, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06085003910613765, "train/post_ent_mag": 40.559966063851796, "train/post_ent_max": 40.559966063851796, "train/post_ent_mean": 39.669751660577184, "train/post_ent_min": 38.57525802010973, "train/post_ent_std": 0.48400316449808956, "train/prior_ent_mag": 40.08995492117746, "train/prior_ent_max": 40.08995492117746, "train/prior_ent_mean": 38.77224272929976, "train/prior_ent_min": 37.452013043934485, "train/prior_ent_std": 0.4506519055131621, "train/rep_loss_mean": 1.000001375898352, "train/rep_loss_std": 4.4004257029757417e-05, "train/reward_avg": 0.0031425288030785953, "train/reward_loss_mean": 0.02509933868836006, "train/reward_loss_std": 0.291359193329447, "train/reward_max_data": 0.7901939658695841, "train/reward_max_pred": 0.2827300860964019, "train/reward_neg_acc": 0.9995841897767166, "train/reward_neg_loss": 0.004665189647469027, "train/reward_pos_acc": 0.11830746173271404, "train/reward_pos_loss": 3.9545889182631018, "train/reward_pred": 0.0024978781791101094, "train/reward_rate": 0.005195504926108374, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.019918326288461685, "report/cont_loss_std": 0.20819565653800964, "report/cont_neg_acc": 0.1428571492433548, "report/cont_neg_loss": 2.354156017303467, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003851794870570302, "report/cont_pred": 0.9952241778373718, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08619052171707153, "report/image_loss_std": 0.10245261341333389, "report/model_loss_mean": 0.7284116744995117, "report/model_loss_std": 0.5024877786636353, "report/post_ent_mag": 40.423065185546875, "report/post_ent_max": 40.423065185546875, "report/post_ent_mean": 39.524391174316406, "report/post_ent_min": 38.42969512939453, "report/post_ent_std": 0.44404321908950806, "report/prior_ent_mag": 40.360877990722656, "report/prior_ent_max": 40.360877990722656, "report/prior_ent_mean": 38.87419891357422, "report/prior_ent_min": 37.58469009399414, "report/prior_ent_std": 0.4681199789047241, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0026092529296875, "report/reward_loss_mean": 0.02230280265212059, "report/reward_loss_std": 0.2706460654735565, "report/reward_max_data": 0.715624988079071, "report/reward_max_pred": 0.05048513412475586, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0035284573677927256, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.8485145568847656, "report/reward_pred": 0.0017500240355730057, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.027682747691869736, "eval/cont_loss_std": 0.36191362142562866, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.497597694396973, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.006232099607586861, "eval/cont_pred": 0.9939374327659607, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12904933094978333, "eval/image_loss_std": 0.12914828956127167, "eval/model_loss_mean": 0.7804548144340515, "eval/model_loss_std": 0.7025368809700012, "eval/post_ent_mag": 40.45597839355469, "eval/post_ent_max": 40.45597839355469, "eval/post_ent_mean": 39.69171142578125, "eval/post_ent_min": 38.61426544189453, "eval/post_ent_std": 0.41135862469673157, "eval/prior_ent_mag": 40.360877990722656, "eval/prior_ent_max": 40.360877990722656, "eval/prior_ent_mean": 39.00624465942383, "eval/prior_ent_min": 37.60319137573242, "eval/prior_ent_std": 0.4197951853275299, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.001922607421875, "eval/reward_loss_mean": 0.023722726851701736, "eval/reward_loss_std": 0.3441636264324188, "eval/reward_max_data": 0.7406250238418579, "eval/reward_max_pred": 0.2476818561553955, "eval/reward_neg_acc": 0.9980410933494568, "eval/reward_neg_loss": 0.006053251679986715, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.037233352661133, "eval/reward_pred": 0.0028079559560865164, "eval/reward_rate": 0.0029296875, "replay/size": 1000000.0, "replay/inserts": 32544.0, "replay/samples": 32544.0, "replay/insert_wait_avg": 1.2414996954543753e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.302448109539561e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3720.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1402432636548113e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1304805278778, "timer/env.step_count": 4068.0, "timer/env.step_total": 39.43815064430237, "timer/env.step_frac": 0.039433005404941324, "timer/env.step_avg": 0.009694727297026147, "timer/env.step_min": 0.007562875747680664, "timer/env.step_max": 0.044732093811035156, "timer/replay._sample_count": 32544.0, "timer/replay._sample_total": 16.264493942260742, "timer/replay._sample_frac": 0.01626237201937511, "timer/replay._sample_avg": 0.0004997693566328891, "timer/replay._sample_min": 0.0003783702850341797, "timer/replay._sample_max": 0.025650978088378906, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4533.0, "timer/agent.policy_total": 47.21817111968994, "timer/agent.policy_frac": 0.047212010871589244, "timer/agent.policy_avg": 0.010416538963090655, "timer/agent.policy_min": 0.008255958557128906, "timer/agent.policy_max": 0.08698749542236328, "timer/dataset_train_count": 2034.0, "timer/dataset_train_total": 0.20737600326538086, "timer/dataset_train_frac": 0.0002073489482651563, "timer/dataset_train_avg": 0.0001019547705336189, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.0010647773742675781, "timer/agent.train_count": 2034.0, "timer/agent.train_total": 902.7635655403137, "timer/agent.train_frac": 0.9026457878414295, "timer/agent.train_avg": 0.44383656122925946, "timer/agent.train_min": 0.4344508647918701, "timer/agent.train_max": 0.689049482345581, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47745704650878906, "timer/agent.report_frac": 0.00047739475578904763, "timer/agent.report_avg": 0.23872852325439453, "timer/agent.report_min": 0.23195433616638184, "timer/agent.report_max": 0.24550271034240723, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.9321659323905353e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 32.53919740275188}
{"step": 1127544, "time": 35244.960941791534, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1127624, "time": 35247.38282442093, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1128072, "time": 35261.15101838112, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1128112, "time": 35262.630315065384, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1128184, "time": 35264.62213873863, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1128224, "time": 35266.08040857315, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1128224, "time": 35266.08784365654, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1128376, "time": 35270.57896852493, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1128824, "time": 35284.56954050064, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1129008, "time": 35290.48168635368, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1129096, "time": 35292.99199342728, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1129128, "time": 35293.97114443779, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 1129168, "time": 35295.41148495674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1129352, "time": 35300.76081418991, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1129512, "time": 35305.62962722778, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1129528, "time": 35306.129658937454, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1129720, "time": 35312.1178689003, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1129912, "time": 35317.939373254776, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1129944, "time": 35318.917605400085, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1130024, "time": 35321.348816394806, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1130064, "time": 35323.746995687485, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 1130064, "time": 35324.20092320442, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1130064, "time": 35324.73697924614, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1130064, "time": 35324.849633693695, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1130064, "time": 35325.61496925354, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 1130064, "time": 35325.639436006546, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1130064, "time": 35326.176533937454, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 1130064, "time": 35326.349351644516, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 1130208, "time": 35330.75345945358, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1130376, "time": 35335.644357442856, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1130400, "time": 35336.59705376625, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1130408, "time": 35336.62484240532, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1130464, "time": 35338.54795217514, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1130552, "time": 35341.636358976364, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1130984, "time": 35354.740859270096, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1131040, "time": 35356.70985651016, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1131072, "time": 35357.6911611557, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1131112, "time": 35358.691212415695, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 1131144, "time": 35359.66372990608, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1131352, "time": 35366.00287437439, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1131432, "time": 35368.456785440445, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1131472, "time": 35369.90667438507, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1131504, "time": 35370.94036817551, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1131512, "time": 35370.96777677536, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1131864, "time": 35381.672741651535, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1131992, "time": 35385.558497428894, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1132152, "time": 35390.41202187538, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1132288, "time": 35394.764749765396, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1132360, "time": 35396.72260570526, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1132416, "time": 35398.64761161804, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1132536, "time": 35402.15712952614, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1132608, "time": 35404.58165025711, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1132808, "time": 35410.445353507996, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1132896, "time": 35413.32169389725, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1133032, "time": 35417.24212408066, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1133144, "time": 35420.64895272255, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1133288, "time": 35425.01614880562, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1133368, "time": 35427.44306874275, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1133424, "time": 35429.38931822777, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1133432, "time": 35429.4168920517, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1133504, "time": 35431.898591041565, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1133648, "time": 35436.285927295685, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1133936, "time": 35445.03327059746, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1134184, "time": 35452.32374382019, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1134520, "time": 35462.644615888596, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1134584, "time": 35464.600197553635, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1134680, "time": 35467.52411532402, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1134696, "time": 35468.01455569267, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1134928, "time": 35475.29090189934, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1134976, "time": 35476.744144678116, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1135344, "time": 35487.99907255173, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1135408, "time": 35489.97367811203, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1135432, "time": 35490.63645172119, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1135736, "time": 35499.87484693527, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1135800, "time": 35501.842851638794, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1136040, "time": 35509.131655693054, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1136040, "time": 35509.13895487785, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1136112, "time": 35511.55563998222, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1136168, "time": 35513.03708362579, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1136168, "time": 35513.04434251785, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1136192, "time": 35513.99975538254, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1136312, "time": 35517.43282985687, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 1136624, "time": 35527.22280502319, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1136928, "time": 35536.44895911217, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1137000, "time": 35538.409709215164, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1137008, "time": 35538.88137578964, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1137152, "time": 35543.354469537735, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1137192, "time": 35544.36183786392, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1137232, "time": 35545.84092879295, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1137424, "time": 35551.82668995857, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1137528, "time": 35554.749321222305, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1137856, "time": 35564.94822096825, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1138192, "time": 35575.16282582283, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1138240, "time": 35576.62216973305, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1138320, "time": 35579.05150914192, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1138512, "time": 35585.00232863426, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1138720, "time": 35591.774609327316, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 1138728, "time": 35591.80239415169, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1138880, "time": 35596.648762226105, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 1138928, "time": 35598.11387634277, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1138952, "time": 35598.624715805054, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1139168, "time": 35605.43081665039, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1139376, "time": 35611.82439136505, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1139424, "time": 35613.29232597351, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1139616, "time": 35619.18564867973, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1139920, "time": 35628.449573755264, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1140024, "time": 35631.396161556244, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1140040, "time": 35631.88840341568, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1140048, "time": 35633.97790694237, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1140048, "time": 35634.04325842857, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1140048, "time": 35634.294362068176, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 1140048, "time": 35634.8182990551, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 1140048, "time": 35634.95364308357, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 1140048, "time": 35634.959944963455, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 1140048, "time": 35635.04169178009, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1140048, "time": 35635.39342355728, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 1140104, "time": 35636.86027312279, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1140136, "time": 35637.85223913193, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1140192, "time": 35639.771339178085, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1140312, "time": 35643.266728401184, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1140544, "time": 35650.53516125679, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1140560, "time": 35651.02018284798, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1140592, "time": 35652.017048835754, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1140720, "time": 35655.950957775116, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1140728, "time": 35655.97890996933, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 1141200, "time": 35670.66177487373, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1141208, "time": 35670.69013381004, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1141408, "time": 35677.04966330528, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1141536, "time": 35680.935477018356, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1141624, "time": 35683.41864705086, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1141920, "time": 35692.68327879906, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1142184, "time": 35700.65063548088, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1142240, "time": 35702.59833884239, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1142256, "time": 35703.090193748474, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1142368, "time": 35706.50616145134, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1142400, "time": 35707.476697444916, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1142448, "time": 35708.92189121246, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1142528, "time": 35711.35988402367, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1143216, "time": 35732.33454799652, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1143216, "time": 35732.34159016609, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1143240, "time": 35732.85062932968, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1143264, "time": 35733.81998038292, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1143496, "time": 35740.69923329353, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1143616, "time": 35744.559972047806, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 1143744, "time": 35748.47015666962, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1143776, "time": 35749.44161272049, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1143952, "time": 35754.796132564545, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1144040, "time": 35757.248797893524, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1144232, "time": 35763.20494937897, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1144256, "time": 35764.16338276863, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1144280, "time": 35764.692524671555, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1144624, "time": 35775.535645484924, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1144688, "time": 35777.4886341095, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1144728, "time": 35778.484462976456, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1144768, "time": 35779.93692827225, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1144792, "time": 35780.44938802719, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1144824, "time": 35781.42456650734, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1145520, "time": 35802.95212674141, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1145576, "time": 35804.45091533661, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1145632, "time": 35806.371030807495, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1145640, "time": 35806.398965120316, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1145824, "time": 35812.19845986366, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 1145824, "time": 35812.205323934555, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1145904, "time": 35814.648136138916, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1145912, "time": 35814.676500082016, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1146216, "time": 35824.03547477722, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1146520, "time": 35833.288711071014, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1146576, "time": 35835.208238601685, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1146616, "time": 35836.20255446434, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1146832, "time": 35843.00681781769, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1147040, "time": 35849.844069719315, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1147064, "time": 35850.42250752449, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1147128, "time": 35852.39790511131, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1147240, "time": 35855.890553474426, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1147312, "time": 35858.34265875816, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1147792, "time": 35872.93893313408, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1147800, "time": 35872.96792602539, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1147880, "time": 35875.39855337143, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 1148032, "time": 35880.266251564026, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1148088, "time": 35881.83056998253, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1148248, "time": 35886.711248636246, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1148464, "time": 35893.49628138542, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1148568, "time": 35896.42101621628, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1148672, "time": 35899.81699824333, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1148712, "time": 35900.80749154091, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1148784, "time": 35903.2249443531, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1148832, "time": 35904.668598890305, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1148856, "time": 35905.17411351204, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1148976, "time": 35909.036450624466, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1149072, "time": 35912.07881236076, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1149472, "time": 35924.243601322174, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1149656, "time": 35929.62979054451, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1149816, "time": 35934.478640556335, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1149872, "time": 35936.44058227539, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1149936, "time": 35938.39423441887, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1149936, "time": 35938.40189123154, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1150032, "time": 35942.938908576965, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1150032, "time": 35943.26372551918, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1150032, "time": 35943.61179995537, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 1150032, "time": 35943.78932380676, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 1150032, "time": 35943.8350315094, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 1150032, "time": 35944.419379234314, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 1150032, "time": 35944.515749931335, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 1150032, "time": 35944.89218735695, "eval_episode/length": 185.0, "eval_episode/score": 0.421875, "eval_episode/reward_rate": 0.005376344086021506}
{"step": 1150216, "time": 35950.27341413498, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1150256, "time": 35951.709700107574, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1150256, "time": 35951.717144966125, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1150680, "time": 35964.42837691307, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1150768, "time": 35967.34322762489, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1150872, "time": 35970.331013441086, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1151024, "time": 35975.22451424599, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 1151048, "time": 35975.732640981674, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1151064, "time": 35976.22252678871, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1151144, "time": 35978.655722141266, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1151456, "time": 35988.38698244095, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1151552, "time": 35991.30510878563, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1151792, "time": 35998.634846925735, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1151816, "time": 35999.14510130882, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1151944, "time": 36003.09808969498, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1152288, "time": 36013.777137994766, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1152312, "time": 36014.29150414467, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1152328, "time": 36014.79426288605, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1152472, "time": 36019.251514196396, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1152672, "time": 36025.65190124512, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1152848, "time": 36031.12893033028, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1152848, "time": 36031.13723731041, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1152920, "time": 36033.12708711624, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1153008, "time": 36036.02366232872, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1153464, "time": 36049.674397706985, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1153576, "time": 36053.091547489166, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1153648, "time": 36055.48331284523, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1153656, "time": 36055.5113902092, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1153752, "time": 36058.43826055527, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1153856, "time": 36061.870037555695, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 1153944, "time": 36064.333471775055, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1153952, "time": 36064.80303311348, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1154144, "time": 36070.62096500397, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1154152, "time": 36070.64789557457, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1154192, "time": 36072.10239958763, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1154352, "time": 36076.94977879524, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1154616, "time": 36084.74999713898, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1154632, "time": 36085.24568963051, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1154680, "time": 36086.72625994682, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1154776, "time": 36089.62802863121, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1154928, "time": 36094.53274464607, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1155136, "time": 36101.29362607002, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1155336, "time": 36107.13541054726, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1155432, "time": 36110.06892776489, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1155512, "time": 36112.54615068436, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1155544, "time": 36113.52280378342, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1155656, "time": 36116.93939948082, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1155664, "time": 36117.40858793259, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1155672, "time": 36117.437116622925, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1155808, "time": 36121.88514375687, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1156000, "time": 36127.746547460556, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1156136, "time": 36131.68793344498, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1156224, "time": 36134.58665537834, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1156264, "time": 36135.584820985794, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1156280, "time": 36136.09322285652, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1156912, "time": 36155.68765902519, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1157056, "time": 36160.04818749428, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1157104, "time": 36161.526196718216, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1157128, "time": 36162.03680586815, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1157208, "time": 36164.47199392319, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1157344, "time": 36168.845781326294, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1157360, "time": 36169.338190317154, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1157712, "time": 36180.04886317253, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1157992, "time": 36188.4403963089, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1158312, "time": 36198.116879701614, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 1158504, "time": 36203.94457054138, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1158528, "time": 36204.91191649437, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1158568, "time": 36205.90803647041, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1158864, "time": 36215.25552010536, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1159184, "time": 36224.97665023804, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1159224, "time": 36225.9737944603, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 1159296, "time": 36228.38414263725, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1159320, "time": 36228.91227269173, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1159400, "time": 36231.335664749146, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 1159496, "time": 36234.244203329086, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1159592, "time": 36237.147290706635, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1159673, "time": 36240.79362607002, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.570294975054146, "train/action_min": 0.0, "train/action_std": 1.7352208837424175, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0112723352982303, "train/actor_opt_grad_steps": 71375.0, "train/actor_opt_loss": -29.391127874355504, "train/adv_mag": 0.8111785608943146, "train/adv_max": 0.2810850432603666, "train/adv_mean": 0.0013891404751480913, "train/adv_min": -0.75109860802641, "train/adv_std": 0.031127478701459006, "train/cont_avg": 0.9934251237623762, "train/cont_loss_mean": 0.023234656440223208, "train/cont_loss_std": 0.24383671091187117, "train/cont_neg_acc": 0.15263044520622432, "train/cont_neg_loss": 2.7220853035992914, "train/cont_pos_acc": 0.9998928473727537, "train/cont_pos_loss": 0.005419600537129779, "train/cont_pred": 0.9935729482976516, "train/cont_rate": 0.9934251237623762, "train/dyn_loss_mean": 1.000000017114205, "train/dyn_loss_std": 5.481059554650789e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09854365173856368, "train/extr_critic_critic_opt_grad_steps": 71375.0, "train/extr_critic_critic_opt_loss": 11529.382739982982, "train/extr_critic_mag": 1.9914332510221122, "train/extr_critic_max": 1.9914332510221122, "train/extr_critic_mean": 1.8710194035331802, "train/extr_critic_min": 1.576347809026737, "train/extr_critic_std": 0.041231227383976526, "train/extr_return_normed_mag": 0.8550957234779207, "train/extr_return_normed_max": 0.31890616204478955, "train/extr_return_normed_mean": 0.0858210024820401, "train/extr_return_normed_min": -0.7046395321883777, "train/extr_return_normed_std": 0.05265241765444822, "train/extr_return_rate": 0.999826302917877, "train/extr_return_raw_mag": 2.105493713723551, "train/extr_return_raw_max": 2.105493713723551, "train/extr_return_raw_mean": 1.8724086261031652, "train/extr_return_raw_min": 1.0819480194903837, "train/extr_return_raw_std": 0.052652417737437354, "train/extr_reward_mag": 0.2533552091900665, "train/extr_reward_max": 0.2533552091900665, "train/extr_reward_mean": 0.003051934890001828, "train/extr_reward_min": 2.950724988880724e-09, "train/extr_reward_std": 0.010934046232187659, "train/image_loss_mean": 0.10486461543063126, "train/image_loss_std": 0.11198431452607165, "train/model_loss_mean": 0.7550906258644444, "train/model_loss_std": 0.5668080884336245, "train/model_opt_grad_norm": 16.715810585970903, "train/model_opt_grad_steps": 71311.61881188118, "train/model_opt_loss": 4055.0754442875927, "train/model_opt_model_opt_grad_overflow": 0.0049504950495049506, "train/model_opt_model_opt_grad_scale": 5371.287128712871, "train/policy_entropy_mag": 1.3527727829347742, "train/policy_entropy_max": 1.3527727829347742, "train/policy_entropy_mean": 0.08966224216441117, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1106024294501484, "train/policy_logprob_mag": 6.551080248143413, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09024733434071636, "train/policy_logprob_min": -6.551080248143413, "train/policy_logprob_std": 0.631242979576092, "train/policy_randomness_mag": 0.6951877321347152, "train/policy_randomness_max": 0.6951877321347152, "train/policy_randomness_mean": 0.04607727977972809, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05683840838915641, "train/post_ent_mag": 40.87112762904403, "train/post_ent_max": 40.87112762904403, "train/post_ent_mean": 39.949325523754155, "train/post_ent_min": 38.782312865304476, "train/post_ent_std": 0.4942544143978912, "train/prior_ent_mag": 40.363484429840994, "train/prior_ent_max": 40.363484429840994, "train/prior_ent_mean": 39.049296407416314, "train/prior_ent_min": 37.67298199870799, "train/prior_ent_std": 0.46020777892358233, "train/rep_loss_mean": 1.000000017114205, "train/rep_loss_std": 5.481059554650789e-07, "train/reward_avg": 0.0033961381010554435, "train/reward_loss_mean": 0.026991323365064542, "train/reward_loss_std": 0.30220719651863126, "train/reward_max_data": 0.8048112631434261, "train/reward_max_pred": 0.27985524895167585, "train/reward_neg_acc": 0.999513837370542, "train/reward_neg_loss": 0.004918003693398199, "train/reward_pos_acc": 0.11488636719560859, "train/reward_pos_loss": 3.9603060118042595, "train/reward_pred": 0.0026013164753370946, "train/reward_rate": 0.005598313737623762, "train_stats/mean_log_entropy": 0.07599604912684299, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.025068961083889008, "report/cont_loss_std": 0.25850042700767517, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.3760008811950684, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00531887449324131, "report/cont_pred": 0.9946231842041016, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10697321593761444, "report/image_loss_std": 0.11807689815759659, "report/model_loss_mean": 0.765300989151001, "report/model_loss_std": 0.6676719188690186, "report/post_ent_mag": 40.83341979980469, "report/post_ent_max": 40.83341979980469, "report/post_ent_mean": 39.95756530761719, "report/post_ent_min": 38.743621826171875, "report/post_ent_std": 0.5165683627128601, "report/prior_ent_mag": 40.18918991088867, "report/prior_ent_max": 40.18918991088867, "report/prior_ent_mean": 38.98091506958008, "report/prior_ent_min": 37.526981353759766, "report/prior_ent_std": 0.45718780159950256, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.003216552548110485, "report/reward_loss_mean": 0.033258743584156036, "report/reward_loss_std": 0.3747447729110718, "report/reward_max_data": 0.840624988079071, "report/reward_max_pred": 0.03851330280303955, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.004944379907101393, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.8372626304626465, "report/reward_pred": 0.0024030283093452454, "report/reward_rate": 0.005859375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.02683330327272415, "eval/cont_loss_std": 0.27548646926879883, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.769808053970337, "eval/cont_pos_acc": 0.9980391263961792, "eval/cont_pos_loss": 0.012154973112046719, "eval/cont_pred": 0.9921307563781738, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13539043068885803, "eval/image_loss_std": 0.1273825615644455, "eval/model_loss_mean": 0.7881790995597839, "eval/model_loss_std": 0.6025505661964417, "eval/post_ent_mag": 40.835243225097656, "eval/post_ent_max": 40.835243225097656, "eval/post_ent_mean": 39.961788177490234, "eval/post_ent_min": 38.556236267089844, "eval/post_ent_std": 0.4934450387954712, "eval/prior_ent_mag": 40.18918991088867, "eval/prior_ent_max": 40.18918991088867, "eval/prior_ent_mean": 39.00254821777344, "eval/prior_ent_min": 37.594146728515625, "eval/prior_ent_std": 0.4232162833213806, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.002600097795948386, "eval/reward_loss_mean": 0.025955332443118095, "eval/reward_loss_std": 0.30786189436912537, "eval/reward_max_data": 0.765625, "eval/reward_max_pred": 0.33812034130096436, "eval/reward_neg_acc": 0.9990195631980896, "eval/reward_neg_loss": 0.007142859511077404, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.823136329650879, "eval/reward_pred": 0.0028634746558964252, "eval/reward_rate": 0.00390625, "replay/size": 1000000.0, "replay/inserts": 32288.0, "replay/samples": 32288.0, "replay/insert_wait_avg": 1.2242212167934572e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.346169090838096e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4304.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1122138083645846e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2872107028961, "timer/env.step_count": 4036.0, "timer/env.step_total": 39.50712966918945, "timer/env.step_frac": 0.03949578605671467, "timer/env.step_avg": 0.009788684258966663, "timer/env.step_min": 0.00766444206237793, "timer/env.step_max": 0.036956071853637695, "timer/replay._sample_count": 32288.0, "timer/replay._sample_total": 16.1691415309906, "timer/replay._sample_frac": 0.016164498913895577, "timer/replay._sample_avg": 0.0005007786648597188, "timer/replay._sample_min": 0.00040602684020996094, "timer/replay._sample_max": 0.010205507278442383, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4574.0, "timer/agent.policy_total": 47.54029154777527, "timer/agent.policy_frac": 0.047526641387696016, "timer/agent.policy_avg": 0.010393592380361886, "timer/agent.policy_min": 0.008957147598266602, "timer/agent.policy_max": 0.07715106010437012, "timer/dataset_train_count": 2018.0, "timer/dataset_train_total": 0.20886468887329102, "timer/dataset_train_frac": 0.0002088047179234882, "timer/dataset_train_avg": 0.00010350083690450496, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.00032806396484375, "timer/agent.train_count": 2018.0, "timer/agent.train_total": 902.1656136512756, "timer/agent.train_frac": 0.9019065764295127, "timer/agent.train_avg": 0.4470592733653497, "timer/agent.train_min": 0.43717241287231445, "timer/agent.train_max": 0.8243870735168457, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5181145668029785, "timer/agent.report_frac": 0.000517965801481059, "timer/agent.report_avg": 0.25905728340148926, "timer/agent.report_min": 0.2431192398071289, "timer/agent.report_max": 0.2749953269958496, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.146221615618936e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 32.27814540533684}
{"step": 1159944, "time": 36248.82477760315, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1159976, "time": 36249.81462144852, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1160016, "time": 36251.83138370514, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 1160016, "time": 36252.3699221611, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1160016, "time": 36252.72558236122, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1160016, "time": 36253.09019494057, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1160016, "time": 36253.37250375748, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 1160016, "time": 36253.43785190582, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1160016, "time": 36254.5226457119, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1160016, "time": 36254.6087911129, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1160024, "time": 36254.63508415222, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1160200, "time": 36259.9556555748, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1160576, "time": 36271.64151120186, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1160728, "time": 36276.00953769684, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1160952, "time": 36282.816964387894, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 1161208, "time": 36290.56871557236, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1161232, "time": 36291.53578400612, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1161232, "time": 36291.54272866249, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1161312, "time": 36293.958822488785, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 1161424, "time": 36297.35798406601, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1161496, "time": 36299.32203793526, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1161888, "time": 36311.50873374939, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1161912, "time": 36312.020213127136, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1161976, "time": 36313.96842455864, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1162080, "time": 36317.36728191376, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1162256, "time": 36322.72277879715, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1162272, "time": 36323.20890879631, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1162416, "time": 36327.56704258919, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1162480, "time": 36329.49756193161, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1162496, "time": 36329.9867773056, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1162600, "time": 36333.06032395363, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1162784, "time": 36338.8567173481, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1162800, "time": 36339.344620227814, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1163064, "time": 36347.17584180832, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1163464, "time": 36359.81534361839, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1163480, "time": 36360.42462182045, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1163552, "time": 36362.8291144371, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1163856, "time": 36372.04381322861, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1164104, "time": 36379.35486865044, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1164240, "time": 36383.70883727074, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1164272, "time": 36384.7064974308, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 1164288, "time": 36385.19687438011, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1164480, "time": 36391.12833619118, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1164512, "time": 36392.10614538193, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1164600, "time": 36394.57566714287, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1165016, "time": 36407.20649790764, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1165112, "time": 36410.12948560715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1165224, "time": 36413.52010059357, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1165248, "time": 36414.49485874176, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1165320, "time": 36416.46759843826, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1165688, "time": 36427.7140955925, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1165816, "time": 36431.60957503319, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1165888, "time": 36434.02178525925, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1165896, "time": 36434.050564050674, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 1166200, "time": 36443.240248680115, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1166288, "time": 36446.11792945862, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1166344, "time": 36447.59905076027, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 1166440, "time": 36450.65940666199, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1166448, "time": 36451.12751913071, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1166600, "time": 36455.52172923088, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1166904, "time": 36464.762330532074, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1167056, "time": 36469.60297846794, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1167088, "time": 36470.579704999924, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1167416, "time": 36480.329590797424, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1167464, "time": 36481.849356889725, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 1167520, "time": 36483.78685760498, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1167632, "time": 36487.18925976753, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1167768, "time": 36491.09288048744, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1167840, "time": 36493.51705598831, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1168048, "time": 36499.85579633713, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1168072, "time": 36500.37537288666, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1168264, "time": 36506.24241185188, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1168400, "time": 36510.71253490448, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1168496, "time": 36513.64625787735, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1168496, "time": 36513.65326213837, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1168520, "time": 36514.16270494461, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1168752, "time": 36521.41906285286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1169128, "time": 36532.603191137314, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1169280, "time": 36537.44505858421, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1169280, "time": 36537.45262813568, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1169424, "time": 36541.88921427727, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1169528, "time": 36544.816989421844, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1170000, "time": 36559.40352368355, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 1170000, "time": 36560.36013221741, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 1170000, "time": 36560.727861881256, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1170000, "time": 36560.88358283043, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1170000, "time": 36560.94793343544, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1170000, "time": 36560.97407722473, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1170000, "time": 36561.84138393402, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 1170000, "time": 36562.267939567566, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 1170000, "time": 36562.31069159508, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1170176, "time": 36567.68179345131, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1170248, "time": 36569.661870241165, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1170312, "time": 36571.69212937355, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1170592, "time": 36580.510464429855, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1170680, "time": 36582.99116683006, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1170744, "time": 36584.944591999054, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1170952, "time": 36591.298936367035, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1170968, "time": 36591.7910118103, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1171008, "time": 36593.25016140938, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1171392, "time": 36605.05902290344, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1171632, "time": 36612.87451887131, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1171728, "time": 36615.79810190201, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1171872, "time": 36620.21331119537, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1172296, "time": 36633.1223154068, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1172296, "time": 36633.13034367561, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 1172312, "time": 36633.62169241905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1172472, "time": 36638.52366614342, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1172480, "time": 36638.99591302872, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1172816, "time": 36649.28404688835, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1172872, "time": 36650.76287460327, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1173080, "time": 36657.131068229675, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1173168, "time": 36660.02693295479, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 1173696, "time": 36676.185359716415, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1173784, "time": 36678.680529356, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1173944, "time": 36683.50646710396, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1173952, "time": 36683.974548101425, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1173968, "time": 36684.45731306076, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1174048, "time": 36686.8916823864, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1174416, "time": 36698.15169739723, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1174584, "time": 36703.05560064316, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1174608, "time": 36704.01613306999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1174720, "time": 36707.43161416054, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1174992, "time": 36715.67870092392, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1175104, "time": 36719.064789772034, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 1175288, "time": 36724.52479505539, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1175392, "time": 36727.938472270966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1175432, "time": 36728.92959690094, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1175568, "time": 36733.33097219467, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1175704, "time": 36737.279093027115, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1175720, "time": 36737.77950811386, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1175760, "time": 36739.22660160065, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 1175984, "time": 36746.0507068634, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 1176352, "time": 36757.39313292503, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1176400, "time": 36758.8559691906, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1176448, "time": 36760.3343064785, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1176504, "time": 36761.82420182228, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1176656, "time": 36766.69363498688, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1176720, "time": 36768.660340070724, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1176792, "time": 36770.64869046211, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1176840, "time": 36772.1160402298, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1176896, "time": 36774.05219745636, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1177192, "time": 36782.98061990738, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1177400, "time": 36789.34183597565, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1177408, "time": 36789.823878765106, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1177528, "time": 36793.30681824684, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1177848, "time": 36803.15145564079, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1177944, "time": 36806.07020330429, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1177952, "time": 36806.539513111115, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1177976, "time": 36807.04854464531, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1178000, "time": 36808.00070333481, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1178040, "time": 36809.00235724449, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1178288, "time": 36816.8069422245, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 1178752, "time": 36830.839144945145, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1178832, "time": 36833.2851498127, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1178936, "time": 36836.2348716259, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 1178976, "time": 36837.67361688614, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1178984, "time": 36837.70168232918, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1179328, "time": 36848.46972942352, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1179536, "time": 36854.788781404495, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1179632, "time": 36857.71862101555, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1179680, "time": 36859.665591955185, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 1179712, "time": 36860.63513350487, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1179848, "time": 36864.55847835541, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 1179920, "time": 36866.96992945671, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 1180072, "time": 36871.47291183472, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1180088, "time": 36873.540335416794, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 1180088, "time": 36873.84288191795, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1180088, "time": 36874.71116065979, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1180088, "time": 36874.77372121811, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1180088, "time": 36875.16182017326, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 1180088, "time": 36875.48989915848, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 1180088, "time": 36875.73136854172, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 1180088, "time": 36875.826281785965, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 1180320, "time": 36883.16182947159, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1180416, "time": 36886.11895155907, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1180496, "time": 36888.6185939312, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1180808, "time": 36897.98183822632, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 1181144, "time": 36908.37145972252, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1181224, "time": 36910.775757312775, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1181336, "time": 36914.18509697914, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1181384, "time": 36915.6339673996, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1181480, "time": 36918.55509376526, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
