{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.83642578125, "train/action_min": 0.0, "train/action_std": 1.8644825220108032, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0009146436350420117, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.884621024131775, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.6033958196640015, "train/cont_loss_std": 0.24649624526500702, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.67578125, "train/cont_pos_loss": 0.6033958196640015, "train/cont_pred": 0.5628450512886047, "train/cont_rate": 1.0, "train/dyn_loss_mean": 10.973783493041992, "train/dyn_loss_std": 0.37787574529647827, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 10.5669527053833, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 41892.3359375, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 5008.091796875, "train/image_loss_std": 40.57868576049805, "train/model_loss_mean": 5020.81982421875, "train/model_loss_std": 40.572025299072266, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 50208200.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9393550157546997, "train/policy_entropy_max": 1.9393550157546997, "train/policy_entropy_mean": 1.652704119682312, "train/policy_entropy_min": 0.6354860067367554, "train/policy_entropy_std": 0.13706007599830627, "train/policy_logprob_mag": 4.530908107757568, "train/policy_logprob_max": -0.16210880875587463, "train/policy_logprob_mean": -1.6650712490081787, "train/policy_logprob_min": -4.530908107757568, "train/policy_logprob_std": 0.7124660015106201, "train/policy_randomness_mag": 0.996631383895874, "train/policy_randomness_max": 0.996631383895874, "train/policy_randomness_mean": 0.8493219017982483, "train/policy_randomness_min": 0.32657521963119507, "train/policy_randomness_std": 0.07043495029211044, "train/post_ent_mag": 105.61442565917969, "train/post_ent_max": 105.61442565917969, "train/post_ent_mean": 105.30036926269531, "train/post_ent_min": 104.96145629882812, "train/post_ent_std": 0.10937153548002243, "train/prior_ent_mag": 106.32479858398438, "train/prior_ent_max": 106.32479858398438, "train/prior_ent_mean": 105.59966278076172, "train/prior_ent_min": 104.76225280761719, "train/prior_ent_std": 0.2573077380657196, "train/rep_loss_mean": 10.973783493041992, "train/rep_loss_std": 0.37787574529647827, "train/reward_avg": 0.000667642685584724, "train/reward_loss_mean": 5.541263580322266, "train/reward_loss_std": 2.640492482441914e-07, "train/reward_max_data": 0.0024999999441206455, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541263580322266, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.6279375553131104, "report/cont_loss_std": 0.26831483840942383, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.642578125, "report/cont_pos_loss": 0.6279375553131104, "report/cont_pred": 0.5520286560058594, "report/cont_rate": 1.0, "report/dyn_loss_mean": 10.996671676635742, "report/dyn_loss_std": 0.36802634596824646, "report/image_loss_mean": 5008.15625, "report/image_loss_std": 39.09331512451172, "report/model_loss_mean": 5020.923828125, "report/model_loss_std": 39.10744857788086, "report/post_ent_mag": 105.64204406738281, "report/post_ent_max": 105.64204406738281, "report/post_ent_mean": 105.31204986572266, "report/post_ent_min": 104.97114562988281, "report/post_ent_std": 0.10667525231838226, "report/prior_ent_mag": 106.3803482055664, "report/prior_ent_max": 106.3803482055664, "report/prior_ent_mean": 105.56251525878906, "report/prior_ent_min": 104.60763549804688, "report/prior_ent_std": 0.2805408835411072, "report/rep_loss_mean": 10.996671676635742, "report/rep_loss_std": 0.36802634596824646, "report/reward_avg": 0.000667642685584724, "report/reward_loss_mean": 5.541263580322266, "report/reward_loss_std": 2.640492482441914e-07, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541263580322266, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.6553231477737427, "eval/cont_loss_std": 0.27506139874458313, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.6103515625, "eval/cont_pos_loss": 0.6553231477737427, "eval/cont_pred": 0.5378931164741516, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 11.00624942779541, "eval/dyn_loss_std": 0.3700134754180908, "eval/image_loss_mean": 5001.55908203125, "eval/image_loss_std": 39.54688262939453, "eval/model_loss_mean": 5014.359375, "eval/model_loss_std": 39.547489166259766, "eval/post_ent_mag": 105.58879089355469, "eval/post_ent_max": 105.58879089355469, "eval/post_ent_mean": 105.28998565673828, "eval/post_ent_min": 104.92285919189453, "eval/post_ent_std": 0.10932701826095581, "eval/prior_ent_mag": 106.32600402832031, "eval/prior_ent_max": 106.32600402832031, "eval/prior_ent_mean": 105.5760498046875, "eval/prior_ent_min": 104.73684692382812, "eval/prior_ent_std": 0.2759045362472534, "eval/rep_loss_mean": 11.00624942779541, "eval/rep_loss_std": 0.3700134754180908, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 9.378850065319744e-07, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.706535611833845e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.0844930617090075e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.365937641688756e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 71.20756316184998, "timer/env.step_count": 196.0, "timer/env.step_total": 0.1963651180267334, "timer/env.step_frac": 0.0027576441224425666, "timer/env.step_avg": 0.0010018628470751705, "timer/env.step_min": 0.0008282661437988281, "timer/env.step_max": 0.008297443389892578, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 67.09615421295166, "timer/replay._sample_frac": 0.9422616255024293, "timer/replay._sample_avg": 0.5990728054727826, "timer/replay._sample_min": 0.09004616737365723, "timer/replay._sample_max": 5.276286840438843, "timer/agent.save_count": 1.0, "timer/agent.save_total": 1.3827307224273682, "timer/agent.save_frac": 0.019418312620592206, "timer/agent.save_avg": 1.3827307224273682, "timer/agent.save_min": 1.3827307224273682, "timer/agent.save_max": 1.3827307224273682, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 12.609456777572632, "timer/agent.policy_frac": 0.17708030183412105, "timer/agent.policy_avg": 0.04348088543990563, "timer/agent.policy_min": 0.005228757858276367, "timer/agent.policy_max": 9.729081869125366, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.910064697265625e-05, "timer/dataset_train_frac": 5.49108061510027e-07, "timer/dataset_train_avg": 3.910064697265625e-05, "timer/dataset_train_min": 3.910064697265625e-05, "timer/dataset_train_max": 3.910064697265625e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 47.452083349227905, "timer/agent.train_frac": 0.6663910579466472, "timer/agent.train_avg": 47.452083349227905, "timer/agent.train_min": 47.452083349227905, "timer/agent.train_max": 47.452083349227905, "timer/agent.report_count": 2.0, "timer/agent.report_total": 9.3517427444458, "timer/agent.report_frac": 0.13133075096517377, "timer/agent.report_avg": 4.6758713722229, "timer/agent.report_min": 0.20840883255004883, "timer/agent.report_max": 9.143333911895752, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.743171691894531e-05, "timer/dataset_eval_frac": 5.256705222992331e-07, "timer/dataset_eval_avg": 3.743171691894531e-05, "timer/dataset_eval_min": 3.743171691894531e-05, "timer/dataset_eval_max": 3.743171691894531e-05}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.17357294823568736, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.15319417895852894, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.17715592246349843, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.18074852050813206, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.14135275518310664, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.12985304473613724, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.1622286250126308, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.19106102770092548, "episode/reward_rate": 0.0}
{"step": 3360, "episode/length": 130.0, "episode/score": 0.6716829276367662, "episode/reward_rate": 0.007633587786259542}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.14489235503788223, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.11591674033934396, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.10554055989473454, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.16039230140040672, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.08836887622419454, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.1168724095757625, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.13014800036467022, "episode/reward_rate": 0.0}
{"step": 5672, "episode/length": 288.0, "episode/score": 0.17357858506454704, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.15494076819197744, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.11867249923193413, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.07568723087638318, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.11854406640554771, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.11428560724368708, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.12956203587066284, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.12452502268820353, "episode/reward_rate": 0.0}
{"step": 7984, "episode/length": 288.0, "episode/score": 0.17341790009788838, "episode/reward_rate": 0.0}
{"step": 8688, "episode/length": 218.0, "episode/score": 0.4184398799478686, "episode/reward_rate": 0.0045662100456621}
{"step": 9224, "episode/length": 285.0, "episode/score": 0.27302367049139775, "episode/reward_rate": 0.0034965034965034965}
{"step": 9248, "episode/length": 288.0, "episode/score": 0.11626573436876697, "episode/reward_rate": 0.0}
{"step": 9248, "episode/length": 288.0, "episode/score": 0.12559043024646144, "episode/reward_rate": 0.0}
{"step": 9248, "episode/length": 288.0, "episode/score": 0.10669562064686033, "episode/reward_rate": 0.0}
{"step": 9248, "episode/length": 288.0, "episode/score": 0.12993885478385891, "episode/reward_rate": 0.0}
{"step": 9248, "episode/length": 288.0, "episode/score": 0.15010823334228007, "episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10296, "episode/length": 288.0, "episode/score": 0.15147772953537242, "episode/reward_rate": 0.0}
{"step": 11000, "episode/length": 288.0, "episode/score": 0.11404148615235954, "episode/reward_rate": 0.0}
{"step": 11536, "episode/length": 288.0, "episode/score": 0.11633121920033318, "episode/reward_rate": 0.0}
{"step": 11560, "episode/length": 288.0, "episode/score": 0.16672243259006336, "episode/reward_rate": 0.0}
{"step": 11560, "episode/length": 288.0, "episode/score": 0.15962276853156254, "episode/reward_rate": 0.0}
{"step": 11560, "episode/length": 288.0, "episode/score": 0.10766456893588838, "episode/reward_rate": 0.0}
{"step": 11560, "episode/length": 288.0, "episode/score": 0.09756951779809242, "episode/reward_rate": 0.0}
{"step": 11560, "episode/length": 288.0, "episode/score": 0.10999412902492622, "episode/reward_rate": 0.0}
{"step": 12608, "episode/length": 288.0, "episode/score": 0.06703911587544553, "episode/reward_rate": 0.0}
{"step": 13312, "episode/length": 288.0, "episode/score": 0.13797520773539418, "episode/reward_rate": 0.0}
{"step": 13848, "episode/length": 288.0, "episode/score": 0.11064729705287846, "episode/reward_rate": 0.0}
{"step": 13872, "episode/length": 288.0, "episode/score": 0.11165120609382484, "episode/reward_rate": 0.0}
{"step": 13872, "episode/length": 288.0, "episode/score": 0.09690145890101576, "episode/reward_rate": 0.0}
{"step": 13872, "episode/length": 288.0, "episode/score": 0.08758556138195672, "episode/reward_rate": 0.0}
{"step": 13872, "episode/length": 288.0, "episode/score": 0.13605409231001886, "episode/reward_rate": 0.0}
{"step": 13872, "episode/length": 288.0, "episode/score": 0.1123102199924233, "episode/reward_rate": 0.0}
{"step": 14776, "episode/length": 112.0, "episode/score": 0.6960715002743427, "episode/reward_rate": 0.008849557522123894}
{"step": 14920, "episode/length": 288.0, "episode/score": 0.10054184942413258, "episode/reward_rate": 0.0}
{"step": 15624, "episode/length": 288.0, "episode/score": 0.0962784316607781, "episode/reward_rate": 0.0}
{"step": 16160, "episode/length": 288.0, "episode/score": 0.1553321914842627, "episode/reward_rate": 0.0}
{"step": 16184, "episode/length": 288.0, "episode/score": 0.09944591729879448, "episode/reward_rate": 0.0}
{"step": 16184, "episode/length": 288.0, "episode/score": 0.09966901528463268, "episode/reward_rate": 0.0}
{"step": 16184, "episode/length": 288.0, "episode/score": 0.06416552901555406, "episode/reward_rate": 0.0}
{"step": 16184, "episode/length": 288.0, "episode/score": 0.10093914133574344, "episode/reward_rate": 0.0}
{"step": 17088, "episode/length": 288.0, "episode/score": 0.14389277925687338, "episode/reward_rate": 0.0}
{"step": 17232, "episode/length": 288.0, "episode/score": 0.13455687298346675, "episode/reward_rate": 0.0}
{"step": 17936, "episode/length": 288.0, "episode/score": 0.11631688346426472, "episode/reward_rate": 0.0}
{"step": 18472, "episode/length": 288.0, "episode/score": 0.15755895392669572, "episode/reward_rate": 0.0}
{"step": 18496, "episode/length": 288.0, "episode/score": 0.14679682292296548, "episode/reward_rate": 0.0}
{"step": 18496, "episode/length": 288.0, "episode/score": 0.1291671841814832, "episode/reward_rate": 0.0}
{"step": 18496, "episode/length": 288.0, "episode/score": 0.14584177659247644, "episode/reward_rate": 0.0}
{"step": 18496, "episode/length": 288.0, "episode/score": 0.1621557627293555, "episode/reward_rate": 0.0}
{"step": 18952, "episode/length": 56.0, "episode/score": 0.8617890228608758, "episode/reward_rate": 0.017543859649122806}
{"step": 19400, "episode/length": 288.0, "episode/score": 0.13128038566605937, "episode/reward_rate": 0.0}
{"step": 19544, "episode/length": 288.0, "episode/score": 0.08244236118298431, "episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20248, "episode/length": 288.0, "episode/score": 0.11000361298897587, "episode/reward_rate": 0.0}
{"step": 20473, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0101871813757946, "train/action_min": 0.0, "train/action_std": 1.9987295461913286, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0013671088174490606, "train/actor_opt_grad_steps": 595.0, "train/actor_opt_loss": 42.94327880669449, "train/adv_mag": 0.004312830287529061, "train/adv_max": 0.004312830287529061, "train/adv_mean": 0.0025533494040752857, "train/adv_min": 0.00036140838608365373, "train/adv_std": 0.0011859702523408426, "train/cont_avg": 0.9969958289194916, "train/cont_loss_mean": 0.025740576276231716, "train/cont_loss_std": 0.29586308902901715, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.79281435975241, "train/cont_pos_acc": 0.99693788461766, "train/cont_pos_loss": 0.008343538999107272, "train/cont_pred": 0.993194449756105, "train/cont_rate": 0.9969958289194916, "train/dyn_loss_mean": 1.1138412245249345, "train/dyn_loss_std": 0.007437645754149436, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.834999601467181, "train/extr_critic_critic_opt_grad_steps": 595.0, "train/extr_critic_critic_opt_loss": 16167.541181144068, "train/extr_critic_mag": 0.027530990414700265, "train/extr_critic_max": 0.02753098940445205, "train/extr_critic_mean": 0.027482439043435603, "train/extr_critic_min": 0.0274277925491333, "train/extr_critic_std": 1.09349592563035e-05, "train/extr_return_normed_mag": 0.008179489757322826, "train/extr_return_normed_max": 0.008179487956062667, "train/extr_return_normed_mean": 0.0064655152558621, "train/extr_return_normed_min": 0.0042911241557994, "train/extr_return_normed_std": 0.0011857574632990733, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0317497618191073, "train/extr_return_raw_max": 0.03174975985503914, "train/extr_return_raw_mean": 0.030035788728171912, "train/extr_return_raw_min": 0.027861396061805207, "train/extr_return_raw_std": 0.0011857574505969779, "train/extr_reward_mag": 0.00048639511657973467, "train/extr_reward_max": 0.00048639511657973467, "train/extr_reward_mean": 0.000486101377538358, "train/extr_reward_min": 0.0004856222766940877, "train/extr_reward_std": 1.3054629876919086e-07, "train/image_loss_mean": 44.23874598514225, "train/image_loss_std": 0.546046181787121, "train/model_loss_mean": 45.12883805875051, "train/model_loss_std": 0.8060151095486293, "train/model_opt_grad_norm": 107.89268846593352, "train/model_opt_grad_steps": 585.0, "train/model_opt_loss": 857.3473008931693, "train/model_opt_model_opt_grad_overflow": 0.00847457627118644, "train/model_opt_model_opt_grad_scale": 11.172537076271187, "train/policy_entropy_mag": 1.9454715716636788, "train/policy_entropy_max": 1.9454715716636788, "train/policy_entropy_mean": 1.936449231737751, "train/policy_entropy_min": 1.8546022449509572, "train/policy_entropy_std": 0.0049334901130474096, "train/policy_logprob_mag": 2.4930048049506492, "train/policy_logprob_max": -1.3966888459557194, "train/policy_logprob_mean": -1.9364933452363742, "train/policy_logprob_min": -2.4930048049506492, "train/policy_logprob_std": 0.12496183421147072, "train/policy_randomness_mag": 0.9997746767634053, "train/policy_randomness_max": 0.9997746767634053, "train/policy_randomness_mean": 0.9951381117610608, "train/policy_randomness_min": 0.9530770733194837, "train/policy_randomness_std": 0.0025353125425773846, "train/post_ent_mag": 82.52830880375232, "train/post_ent_max": 82.52830880375232, "train/post_ent_mean": 82.4938174102266, "train/post_ent_min": 82.25884777004435, "train/post_ent_std": 0.04668657186488479, "train/prior_ent_mag": 85.82751613552287, "train/prior_ent_max": 85.82751613552287, "train/prior_ent_mean": 85.70615542137017, "train/prior_ent_min": 85.31090662034892, "train/prior_ent_std": 0.07647906837321944, "train/rep_loss_mean": 1.1138412245249345, "train/rep_loss_std": 0.007437645754149436, "train/reward_avg": 0.0005442848647609195, "train/reward_loss_mean": 0.19604687083323122, "train/reward_loss_std": 0.06322190716986335, "train/reward_max_data": 0.06315854420269823, "train/reward_max_pred": 0.00048601021200923595, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.1947654820189385, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.693303283055624, "train/reward_pred": 0.00048564164011376135, "train/reward_rate": 0.00014896716101694916, "train_stats/mean_log_entropy": 1.9191360438571257, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025653807446360588, "report/cont_loss_std": 0.3598906397819519, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.772647380828857, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003116586012765765, "report/cont_pred": 0.9968881011009216, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2671845555305481, "report/image_loss_std": 0.08711934834718704, "report/model_loss_mean": 0.9240889549255371, "report/model_loss_std": 0.6229217052459717, "report/post_ent_mag": 71.26366424560547, "report/post_ent_max": 71.26366424560547, "report/post_ent_mean": 71.23806762695312, "report/post_ent_min": 71.10366821289062, "report/post_ent_std": 0.029497841373085976, "report/prior_ent_mag": 72.92387390136719, "report/prior_ent_max": 72.92387390136719, "report/prior_ent_mean": 72.8325424194336, "report/prior_ent_min": 72.62826538085938, "report/prior_ent_std": 0.03847848251461983, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.001253511174581945, "report/reward_loss_mean": 0.03125055879354477, "report/reward_loss_std": 0.3418307304382324, "report/reward_max_data": 0.8274999856948853, "report/reward_max_pred": 0.0004436969757080078, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.020608117803931236, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 10.918469429016113, "report/reward_pred": 0.0004435793962329626, "report/reward_rate": 0.0009765625, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0031165732070803642, "eval/cont_loss_std": 1.6003328937586048e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0031165732070803642, "eval/cont_pred": 0.9968881607055664, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2590175271034241, "eval/image_loss_std": 0.07879360765218735, "eval/model_loss_mean": 0.8658326864242554, "eval/model_loss_std": 0.07879351824522018, "eval/post_ent_mag": 71.2658462524414, "eval/post_ent_max": 71.2658462524414, "eval/post_ent_mean": 71.23979949951172, "eval/post_ent_min": 71.09785461425781, "eval/post_ent_std": 0.02740604244172573, "eval/prior_ent_mag": 72.93206024169922, "eval/prior_ent_max": 72.93206024169922, "eval/prior_ent_mean": 72.83381652832031, "eval/prior_ent_min": 72.62826538085938, "eval/prior_ent_std": 0.03468121588230133, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0036985292099416256, "eval/reward_loss_std": 2.514463233183051e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0004436969757080078, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0036985292099416256, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0004435792798176408, "eval/reward_rate": 0.0, "replay/size": 19969.0, "replay/inserts": 18912.0, "replay/samples": 18912.0, "replay/insert_wait_avg": 1.3327588486389057e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.890463344941889e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 7992.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1767792454227856e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 491.4600794315338, "timer/env.step_count": 2364.0, "timer/env.step_total": 5.2137463092803955, "timer/env.step_frac": 0.010608687312530196, "timer/env.step_avg": 0.002205476442165988, "timer/env.step_min": 0.001058816909790039, "timer/env.step_max": 0.009925127029418945, "timer/replay._sample_count": 18912.0, "timer/replay._sample_total": 1309.460586309433, "timer/replay._sample_frac": 2.664429200076781, "timer/replay._sample_avg": 0.0692396672117932, "timer/replay._sample_min": 0.00022101402282714844, "timer/replay._sample_max": 0.09515380859375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2942.0, "timer/agent.policy_total": 19.852535009384155, "timer/agent.policy_frac": 0.04039501037876231, "timer/agent.policy_avg": 0.0067479724708987615, "timer/agent.policy_min": 0.0050923824310302734, "timer/agent.policy_max": 0.013452529907226562, "timer/dataset_train_count": 1182.0, "timer/dataset_train_total": 0.10094237327575684, "timer/dataset_train_frac": 0.00020539282334491077, "timer/dataset_train_avg": 8.539963898118176e-05, "timer/dataset_train_min": 6.508827209472656e-05, "timer/dataset_train_max": 0.0002677440643310547, "timer/agent.train_count": 1182.0, "timer/agent.train_total": 458.27033042907715, "timer/agent.train_frac": 0.9324670499364935, "timer/agent.train_avg": 0.3877075553545492, "timer/agent.train_min": 0.35124874114990234, "timer/agent.train_max": 0.5458178520202637, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4175887107849121, "timer/agent.report_frac": 0.0008496899916427234, "timer/agent.report_avg": 0.20879435539245605, "timer/agent.report_min": 0.19957470893859863, "timer/agent.report_max": 0.21801400184631348, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.790855407714844e-05, "timer/dataset_eval_frac": 7.713455408422354e-08, "timer/dataset_eval_avg": 3.790855407714844e-05, "timer/dataset_eval_min": 3.790855407714844e-05, "timer/dataset_eval_max": 3.790855407714844e-05, "fps": 38.480837479585695}
{"step": 20784, "episode/length": 288.0, "episode/score": 0.12358252233116218, "episode/reward_rate": 0.0}
{"step": 20808, "episode/length": 288.0, "episode/score": 0.14048917468426225, "episode/reward_rate": 0.0}
{"step": 20808, "episode/length": 288.0, "episode/score": 0.1118163966107204, "episode/reward_rate": 0.0}
{"step": 20808, "episode/length": 288.0, "episode/score": 0.1336221268106783, "episode/reward_rate": 0.0}
{"step": 21264, "episode/length": 288.0, "episode/score": 0.14536910132471803, "episode/reward_rate": 0.0}
{"step": 21712, "episode/length": 288.0, "episode/score": 0.09779213027502465, "episode/reward_rate": 0.0}
{"step": 21856, "episode/length": 288.0, "episode/score": 0.07841086130031272, "episode/reward_rate": 0.0}
{"step": 22408, "episode/length": 199.0, "episode/score": 0.48609906520880486, "episode/reward_rate": 0.005}
{"step": 22560, "episode/length": 288.0, "episode/score": 0.14313915208299477, "episode/reward_rate": 0.0}
{"step": 23096, "episode/length": 288.0, "episode/score": 0.1296279341996751, "episode/reward_rate": 0.0}
{"step": 23120, "episode/length": 288.0, "episode/score": 0.11524388202576574, "episode/reward_rate": 0.0}
{"step": 23120, "episode/length": 288.0, "episode/score": 0.0830528308644034, "episode/reward_rate": 0.0}
{"step": 23576, "episode/length": 288.0, "episode/score": 0.12150067605284676, "episode/reward_rate": 0.0}
{"step": 24024, "episode/length": 288.0, "episode/score": 0.11556286178790742, "episode/reward_rate": 0.0}
{"step": 24168, "episode/length": 288.0, "episode/score": 0.11383278859329948, "episode/reward_rate": 0.0}
{"step": 24720, "episode/length": 288.0, "episode/score": 0.1754012678311483, "episode/reward_rate": 0.0}
{"step": 24872, "episode/length": 288.0, "episode/score": 0.09808982801422417, "episode/reward_rate": 0.0}
{"step": 25408, "episode/length": 288.0, "episode/score": 0.10779319417054012, "episode/reward_rate": 0.0}
{"step": 25432, "episode/length": 288.0, "episode/score": 0.12480471203468824, "episode/reward_rate": 0.0}
{"step": 25432, "episode/length": 288.0, "episode/score": 0.10924407734700026, "episode/reward_rate": 0.0}
{"step": 25888, "episode/length": 288.0, "episode/score": 0.14146992068123154, "episode/reward_rate": 0.0}
{"step": 26336, "episode/length": 288.0, "episode/score": 0.09051711002899765, "episode/reward_rate": 0.0}
{"step": 26480, "episode/length": 288.0, "episode/score": 0.11316161748942477, "episode/reward_rate": 0.0}
{"step": 27032, "episode/length": 288.0, "episode/score": 0.0878143400033764, "episode/reward_rate": 0.0}
{"step": 27184, "episode/length": 288.0, "episode/score": 0.10741670663441028, "episode/reward_rate": 0.0}
{"step": 27720, "episode/length": 288.0, "episode/score": 0.07905916990904416, "episode/reward_rate": 0.0}
{"step": 27744, "episode/length": 288.0, "episode/score": 0.10878340746063486, "episode/reward_rate": 0.0}
{"step": 27744, "episode/length": 288.0, "episode/score": 0.07649341710992985, "episode/reward_rate": 0.0}
{"step": 28200, "episode/length": 288.0, "episode/score": 0.11114924527998937, "episode/reward_rate": 0.0}
{"step": 28648, "episode/length": 288.0, "episode/score": 0.10801061718831306, "episode/reward_rate": 0.0}
{"step": 28792, "episode/length": 288.0, "episode/score": 0.10231693382763751, "episode/reward_rate": 0.0}
{"step": 29344, "episode/length": 288.0, "episode/score": 0.06626089544766955, "episode/reward_rate": 0.0}
{"step": 29496, "episode/length": 288.0, "episode/score": 0.07379788226802475, "episode/reward_rate": 0.0}
{"step": 30032, "episode/length": 288.0, "episode/score": 0.07100245159517726, "episode/reward_rate": 0.0}
{"step": 30056, "episode/length": 288.0, "episode/score": 0.11433878720930579, "episode/reward_rate": 0.0}
{"step": 30056, "episode/length": 288.0, "episode/score": 0.09567129953842368, "episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30512, "episode/length": 288.0, "episode/score": 0.09858102820879822, "episode/reward_rate": 0.0}
{"step": 30960, "episode/length": 288.0, "episode/score": 0.0714579703589493, "episode/reward_rate": 0.0}
{"step": 31104, "episode/length": 288.0, "episode/score": 0.1269179246434078, "episode/reward_rate": 0.0}
{"step": 31656, "episode/length": 288.0, "episode/score": 0.10132924987675551, "episode/reward_rate": 0.0}
{"step": 31808, "episode/length": 288.0, "episode/score": 0.10279153685860365, "episode/reward_rate": 0.0}
{"step": 32344, "episode/length": 288.0, "episode/score": 0.12521238358846176, "episode/reward_rate": 0.0}
{"step": 32368, "episode/length": 288.0, "episode/score": 0.0482840486160967, "episode/reward_rate": 0.0}
{"step": 32368, "episode/length": 288.0, "episode/score": 0.09383863973857842, "episode/reward_rate": 0.0}
{"step": 32824, "episode/length": 288.0, "episode/score": 0.08184089663637906, "episode/reward_rate": 0.0}
{"step": 33272, "episode/length": 288.0, "episode/score": 0.14478457690808, "episode/reward_rate": 0.0}
{"step": 33416, "episode/length": 288.0, "episode/score": 0.07205339610510464, "episode/reward_rate": 0.0}
{"step": 33960, "episode/length": 268.0, "episode/score": 0.26927456898869195, "episode/reward_rate": 0.0037174721189591076}
{"step": 33968, "episode/length": 288.0, "episode/score": 0.1173868060234895, "episode/reward_rate": 0.0}
{"step": 34656, "episode/length": 288.0, "episode/score": 0.0799635879872369, "episode/reward_rate": 0.0}
{"step": 34680, "episode/length": 288.0, "episode/score": 0.11475535545736193, "episode/reward_rate": 0.0}
{"step": 34680, "episode/length": 288.0, "episode/score": 0.12570726180652514, "episode/reward_rate": 0.0}
{"step": 35136, "episode/length": 288.0, "episode/score": 0.06690932969965502, "episode/reward_rate": 0.0}
{"step": 35584, "episode/length": 288.0, "episode/score": 0.13702871695471686, "episode/reward_rate": 0.0}
{"step": 35728, "episode/length": 288.0, "episode/score": 0.09834400431299173, "episode/reward_rate": 0.0}
{"step": 36168, "episode/length": 185.0, "episode/score": 0.4976787593812162, "episode/reward_rate": 0.005376344086021506}
{"step": 36272, "episode/length": 288.0, "episode/score": 0.11650667533254477, "episode/reward_rate": 0.0}
{"step": 36280, "episode/length": 288.0, "episode/score": 0.08825081669689894, "episode/reward_rate": 0.0}
{"step": 36968, "episode/length": 288.0, "episode/score": 0.08167116500985117, "episode/reward_rate": 0.0}
{"step": 36992, "episode/length": 288.0, "episode/score": 0.10039335951913131, "episode/reward_rate": 0.0}
{"step": 37448, "episode/length": 288.0, "episode/score": 0.09586188747317692, "episode/reward_rate": 0.0}
{"step": 37896, "episode/length": 288.0, "episode/score": 0.10333799945905753, "episode/reward_rate": 0.0}
{"step": 38040, "episode/length": 288.0, "episode/score": 0.11188890569945897, "episode/reward_rate": 0.0}
{"step": 38480, "episode/length": 288.0, "episode/score": 0.09845606005745822, "episode/reward_rate": 0.0}
{"step": 38584, "episode/length": 288.0, "episode/score": 0.06739941203784383, "episode/reward_rate": 0.0}
{"step": 38592, "episode/length": 288.0, "episode/score": 0.08304776723642249, "episode/reward_rate": 0.0}
{"step": 39280, "episode/length": 288.0, "episode/score": 0.11136991967427434, "episode/reward_rate": 0.0}
{"step": 39304, "episode/length": 288.0, "episode/score": 0.08532590571977039, "episode/reward_rate": 0.0}
{"step": 39760, "episode/length": 288.0, "episode/score": 0.06283785703004696, "episode/reward_rate": 0.0}
{"step": 39849, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0038381529248452, "train/action_min": 0.0, "train/action_std": 2.0013094647856784, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007265225576702505, "train/actor_opt_grad_steps": 1790.0, "train/actor_opt_loss": 26.308910527505166, "train/adv_mag": 0.00290138021973539, "train/adv_max": 0.00290138021973539, "train/adv_mean": 0.0016769870686583405, "train/adv_min": 0.00016545639796690509, "train/adv_std": 0.0007803090891323614, "train/cont_avg": 0.9966587035123967, "train/cont_loss_mean": 0.022530698144331205, "train/cont_loss_std": 0.3156857750463215, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.725763442152638, "train/cont_pos_acc": 0.9999999862071897, "train/cont_pos_loss": 0.003424991592803339, "train/cont_pred": 0.9965812972754486, "train/cont_rate": 0.9966587035123967, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.18305720302684247, "train/extr_critic_critic_opt_grad_steps": 1790.0, "train/extr_critic_critic_opt_loss": 13392.299982244318, "train/extr_critic_mag": 0.07761189661735346, "train/extr_critic_max": 0.07761189661735346, "train/extr_critic_mean": 0.07749859151268794, "train/extr_critic_min": 0.0774131648796649, "train/extr_critic_std": 2.7021266417469247e-05, "train/extr_return_normed_mag": 0.0059540792683924525, "train/extr_return_normed_max": 0.0059540792683924525, "train/extr_return_normed_mean": 0.004800712972617716, "train/extr_return_normed_min": 0.0033389075913212514, "train/extr_return_normed_std": 0.0007794755352237685, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08032894026765153, "train/extr_return_raw_max": 0.08032894026765153, "train/extr_return_raw_mean": 0.07917557773757572, "train/extr_return_raw_min": 0.07771376859058034, "train/extr_return_raw_std": 0.0007794755376290438, "train/extr_reward_mag": 0.0004982376886793404, "train/extr_reward_max": 0.0004982376886793404, "train/extr_reward_mean": 0.0004978298610326457, "train/extr_reward_min": 0.0004972278579207491, "train/extr_reward_std": 1.3383820259039716e-07, "train/image_loss_mean": 0.28602831250379895, "train/image_loss_std": 0.08287338001176345, "train/model_loss_mean": 0.9297971548127734, "train/model_loss_std": 0.3831891686586309, "train/model_opt_grad_norm": 92.82379106253632, "train/model_opt_grad_steps": 1780.0, "train/model_opt_loss": 23.85007572962233, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 25.665030991735538, "train/policy_entropy_mag": 1.9458179611805058, "train/policy_entropy_max": 1.9458179611805058, "train/policy_entropy_mean": 1.9435722946135465, "train/policy_entropy_min": 1.9210918205828706, "train/policy_entropy_std": 0.00123437198431208, "train/policy_logprob_mag": 2.2475148488667385, "train/policy_logprob_max": -1.6427467972779077, "train/policy_logprob_mean": -1.9435224996125402, "train/policy_logprob_min": -2.2475148488667385, "train/policy_logprob_std": 0.06684436307342584, "train/policy_randomness_mag": 0.999952682778855, "train/policy_randomness_max": 0.999952682778855, "train/policy_randomness_mean": 0.9987986348877268, "train/policy_randomness_min": 0.9872459621468851, "train/policy_randomness_std": 0.0006343417412270445, "train/post_ent_mag": 61.19207120532832, "train/post_ent_max": 61.19207120532832, "train/post_ent_mean": 61.165057158667196, "train/post_ent_min": 61.07755667316027, "train/post_ent_std": 0.018662876218618934, "train/prior_ent_mag": 66.14288358451907, "train/prior_ent_max": 66.14288358451907, "train/prior_ent_mean": 66.05984490765027, "train/prior_ent_min": 65.85962109526326, "train/prior_ent_std": 0.03659791076047854, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0005329825825438919, "train/reward_loss_mean": 0.021238122481760408, "train/reward_loss_std": 0.0912629399325483, "train/reward_max_data": 0.11900137599619214, "train/reward_max_pred": 0.0004982564074934022, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.019034022511529528, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.384575336210188, "train/reward_pred": 0.0004978781644916855, "train/reward_rate": 0.00026633522727272725, "train_stats/mean_log_entropy": 1.9366336473520251, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025620928034186363, "report/cont_loss_std": 0.33479344844818115, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.3718438148498535, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004655351396650076, "report/cont_pred": 0.995355486869812, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2620268166065216, "report/image_loss_std": 0.07347999513149261, "report/model_loss_mean": 0.9150662422180176, "report/model_loss_std": 0.5735753774642944, "report/post_ent_mag": 54.063594818115234, "report/post_ent_max": 54.063594818115234, "report/post_ent_mean": 54.0426025390625, "report/post_ent_min": 53.960853576660156, "report/post_ent_std": 0.01601220853626728, "report/prior_ent_mag": 57.11420440673828, "report/prior_ent_max": 57.11420440673828, "report/prior_ent_mean": 57.00501251220703, "report/prior_ent_min": 56.938812255859375, "report/prior_ent_std": 0.022126760333776474, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0009686662815511227, "report/reward_loss_mean": 0.027418475598096848, "report/reward_loss_std": 0.3170901834964752, "report/reward_max_data": 0.5962499976158142, "report/reward_max_pred": 0.0004680156707763672, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.017542431131005287, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 10.130610466003418, "report/reward_pred": 0.0004679833073168993, "report/reward_rate": 0.0009765625, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.004655638709664345, "eval/cont_loss_std": 3.5919740639656084e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004655638709664345, "eval/cont_pred": 0.9953551888465881, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2578630745410919, "eval/image_loss_std": 0.06582987308502197, "eval/model_loss_mean": 0.8655321598052979, "eval/model_loss_std": 0.06582952290773392, "eval/post_ent_mag": 54.06239318847656, "eval/post_ent_max": 54.06239318847656, "eval/post_ent_mean": 54.04424285888672, "eval/post_ent_min": 53.97239685058594, "eval/post_ent_std": 0.014535477384924889, "eval/prior_ent_mag": 57.08753204345703, "eval/prior_ent_max": 57.08753204345703, "eval/prior_ent_mean": 57.003211975097656, "eval/prior_ent_min": 56.963199615478516, "eval/prior_ent_std": 0.020954838022589684, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0030134739354252815, "eval/reward_loss_std": 4.208330892652157e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0004680156707763672, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0030134739354252815, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0004679880803450942, "eval/reward_rate": 0.0, "replay/size": 39345.0, "replay/inserts": 19376.0, "replay/samples": 19376.0, "replay/insert_wait_avg": 1.3386312346139494e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.002930519110304e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10304.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1941553399637084e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.1017997264862, "timer/env.step_count": 2422.0, "timer/env.step_total": 5.341477870941162, "timer/env.step_frac": 0.010680781140684763, "timer/env.step_avg": 0.002205399616408407, "timer/env.step_min": 0.0011336803436279297, "timer/env.step_max": 0.013211727142333984, "timer/replay._sample_count": 19376.0, "timer/replay._sample_total": 1348.1211564540863, "timer/replay._sample_frac": 2.695693471192057, "timer/replay._sample_avg": 0.06957685572120594, "timer/replay._sample_min": 0.0003407001495361328, "timer/replay._sample_max": 0.1046743392944336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2711.0, "timer/agent.policy_total": 18.334137439727783, "timer/agent.policy_frac": 0.036660810758439626, "timer/agent.policy_avg": 0.006762868845344073, "timer/agent.policy_min": 0.005052328109741211, "timer/agent.policy_max": 0.01076054573059082, "timer/dataset_train_count": 1211.0, "timer/dataset_train_total": 0.10605096817016602, "timer/dataset_train_frac": 0.00021205876129253487, "timer/dataset_train_avg": 8.7573053815166e-05, "timer/dataset_train_min": 6.532669067382812e-05, "timer/dataset_train_max": 0.00021791458129882812, "timer/agent.train_count": 1211.0, "timer/agent.train_total": 469.30817127227783, "timer/agent.train_frac": 0.9384252796709591, "timer/agent.train_avg": 0.3875377136847876, "timer/agent.train_min": 0.34853601455688477, "timer/agent.train_max": 0.7255785465240479, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.42994070053100586, "timer/agent.report_frac": 0.0008597063653163164, "timer/agent.report_avg": 0.21497035026550293, "timer/agent.report_min": 0.2140812873840332, "timer/agent.report_max": 0.21585941314697266, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 6.246566772460938e-05, "timer/dataset_eval_frac": 1.249059046753538e-07, "timer/dataset_eval_avg": 6.246566772460938e-05, "timer/dataset_eval_min": 6.246566772460938e-05, "timer/dataset_eval_max": 6.246566772460938e-05, "fps": 38.74368017141369}
{"step": 40040, "eval_episode/length": 273.0, "eval_episode/score": 0.14687499403953552, "eval_episode/reward_rate": 0.0036496350364963502}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40208, "episode/length": 288.0, "episode/score": 0.0646236414262944, "episode/reward_rate": 0.0}
{"step": 40352, "episode/length": 288.0, "episode/score": 0.07293392332891813, "episode/reward_rate": 0.0}
{"step": 40792, "episode/length": 288.0, "episode/score": 0.10816446228781729, "episode/reward_rate": 0.0}
{"step": 40896, "episode/length": 288.0, "episode/score": 0.11820339600825491, "episode/reward_rate": 0.0}
{"step": 40904, "episode/length": 288.0, "episode/score": 0.11149010752015442, "episode/reward_rate": 0.0}
{"step": 41592, "episode/length": 288.0, "episode/score": 0.10221674403291559, "episode/reward_rate": 0.0}
{"step": 41616, "episode/length": 288.0, "episode/score": 0.08789933668171557, "episode/reward_rate": 0.0}
{"step": 42072, "episode/length": 288.0, "episode/score": 0.12239654740483275, "episode/reward_rate": 0.0}
{"step": 42520, "episode/length": 288.0, "episode/score": 0.1500544909524706, "episode/reward_rate": 0.0}
{"step": 42664, "episode/length": 288.0, "episode/score": 0.14527713163653289, "episode/reward_rate": 0.0}
{"step": 43104, "episode/length": 288.0, "episode/score": 0.10411942321184142, "episode/reward_rate": 0.0}
{"step": 43208, "episode/length": 288.0, "episode/score": 0.10428739466783554, "episode/reward_rate": 0.0}
{"step": 43216, "episode/length": 288.0, "episode/score": 0.11061746118048177, "episode/reward_rate": 0.0}
{"step": 43904, "episode/length": 288.0, "episode/score": 0.14440501478429724, "episode/reward_rate": 0.0}
{"step": 43928, "episode/length": 288.0, "episode/score": 0.14023016907162855, "episode/reward_rate": 0.0}
{"step": 44384, "episode/length": 288.0, "episode/score": 0.14277840603358527, "episode/reward_rate": 0.0}
{"step": 44832, "episode/length": 288.0, "episode/score": 0.11411444505506552, "episode/reward_rate": 0.0}
{"step": 44976, "episode/length": 288.0, "episode/score": 0.1571092832659815, "episode/reward_rate": 0.0}
{"step": 45416, "episode/length": 288.0, "episode/score": 0.137955095619418, "episode/reward_rate": 0.0}
{"step": 45520, "episode/length": 288.0, "episode/score": 0.14150799520416513, "episode/reward_rate": 0.0}
{"step": 45528, "episode/length": 288.0, "episode/score": 0.10616533604388678, "episode/reward_rate": 0.0}
{"step": 46216, "episode/length": 288.0, "episode/score": 0.11663910796505661, "episode/reward_rate": 0.0}
{"step": 46240, "episode/length": 288.0, "episode/score": 0.16336293946960723, "episode/reward_rate": 0.0}
{"step": 46696, "episode/length": 288.0, "episode/score": 0.118024299835497, "episode/reward_rate": 0.0}
{"step": 47144, "episode/length": 288.0, "episode/score": 0.10478371357271499, "episode/reward_rate": 0.0}
{"step": 47288, "episode/length": 288.0, "episode/score": 0.15495530272505675, "episode/reward_rate": 0.0}
{"step": 47728, "episode/length": 288.0, "episode/score": 0.1225213643222105, "episode/reward_rate": 0.0}
{"step": 47832, "episode/length": 288.0, "episode/score": 0.11410101333603961, "episode/reward_rate": 0.0}
{"step": 47840, "episode/length": 288.0, "episode/score": 0.12945699406350286, "episode/reward_rate": 0.0}
{"step": 48528, "episode/length": 288.0, "episode/score": 0.13644184632789802, "episode/reward_rate": 0.0}
{"step": 48552, "episode/length": 288.0, "episode/score": 0.13301917049955136, "episode/reward_rate": 0.0}
{"step": 49008, "episode/length": 288.0, "episode/score": 0.07711303723874607, "episode/reward_rate": 0.0}
{"step": 49456, "episode/length": 288.0, "episode/score": 0.09825461950435965, "episode/reward_rate": 0.0}
{"step": 49600, "episode/length": 288.0, "episode/score": 0.0991540680477101, "episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50040, "episode/length": 288.0, "episode/score": 0.11376096815888559, "episode/reward_rate": 0.0}
{"step": 50144, "episode/length": 288.0, "episode/score": 0.15259232417565727, "episode/reward_rate": 0.0}
{"step": 50152, "episode/length": 288.0, "episode/score": 0.15401579178296743, "episode/reward_rate": 0.0}
{"step": 50792, "episode/length": 282.0, "episode/score": 0.18842776841643172, "episode/reward_rate": 0.0035335689045936395}
{"step": 50864, "episode/length": 288.0, "episode/score": 0.124999421452344, "episode/reward_rate": 0.0}
{"step": 51320, "episode/length": 288.0, "episode/score": 0.09784370501904505, "episode/reward_rate": 0.0}
{"step": 51768, "episode/length": 288.0, "episode/score": 0.1031430434013032, "episode/reward_rate": 0.0}
{"step": 51912, "episode/length": 288.0, "episode/score": 0.1017101910485394, "episode/reward_rate": 0.0}
{"step": 52352, "episode/length": 288.0, "episode/score": 0.04805355956398216, "episode/reward_rate": 0.0}
{"step": 52456, "episode/length": 288.0, "episode/score": 0.10456466499397266, "episode/reward_rate": 0.0}
{"step": 52464, "episode/length": 288.0, "episode/score": 0.10960871815291284, "episode/reward_rate": 0.0}
{"step": 53104, "episode/length": 288.0, "episode/score": 0.13914343557524944, "episode/reward_rate": 0.0}
{"step": 53176, "episode/length": 288.0, "episode/score": 0.037068187743045655, "episode/reward_rate": 0.0}
{"step": 53632, "episode/length": 288.0, "episode/score": 0.10474890536676185, "episode/reward_rate": 0.0}
{"step": 54080, "episode/length": 288.0, "episode/score": 0.106584687790928, "episode/reward_rate": 0.0}
{"step": 54224, "episode/length": 288.0, "episode/score": 0.1133436381102797, "episode/reward_rate": 0.0}
{"step": 54664, "episode/length": 288.0, "episode/score": 0.11187297830207399, "episode/reward_rate": 0.0}
{"step": 54768, "episode/length": 288.0, "episode/score": 0.17687598242514468, "episode/reward_rate": 0.0}
{"step": 54776, "episode/length": 288.0, "episode/score": 0.1085067615575781, "episode/reward_rate": 0.0}
{"step": 55416, "episode/length": 288.0, "episode/score": 0.13978509547007434, "episode/reward_rate": 0.0}
{"step": 55488, "episode/length": 288.0, "episode/score": 0.19079515074150777, "episode/reward_rate": 0.0}
{"step": 55944, "episode/length": 288.0, "episode/score": 0.14746241334944443, "episode/reward_rate": 0.0}
{"step": 56160, "episode/length": 186.0, "episode/score": 0.5180559561672453, "episode/reward_rate": 0.0053475935828877}
{"step": 56392, "episode/length": 288.0, "episode/score": 0.12193901835848919, "episode/reward_rate": 0.0}
{"step": 56536, "episode/length": 288.0, "episode/score": 0.10756059322557121, "episode/reward_rate": 0.0}
{"step": 57080, "episode/length": 288.0, "episode/score": 0.15251702063574157, "episode/reward_rate": 0.0}
{"step": 57088, "episode/length": 288.0, "episode/score": 0.12686086943995178, "episode/reward_rate": 0.0}
{"step": 57728, "episode/length": 288.0, "episode/score": 0.17670593561524583, "episode/reward_rate": 0.0}
{"step": 57800, "episode/length": 288.0, "episode/score": 0.14994611745169095, "episode/reward_rate": 0.0}
{"step": 58256, "episode/length": 288.0, "episode/score": 0.12755193823886657, "episode/reward_rate": 0.0}
{"step": 58472, "episode/length": 288.0, "episode/score": 0.13921343607262315, "episode/reward_rate": 0.0}
{"step": 58704, "episode/length": 288.0, "episode/score": 0.13823629175726637, "episode/reward_rate": 0.0}
{"step": 58848, "episode/length": 288.0, "episode/score": 0.13098863593359056, "episode/reward_rate": 0.0}
{"step": 59289, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0020166822701446, "train/action_min": 0.0, "train/action_std": 1.998618851023272, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00037533831231830996, "train/actor_opt_grad_steps": 3000.0, "train/actor_opt_loss": 10.022260159500375, "train/adv_mag": 0.0014815060190918033, "train/adv_max": 0.0014815060190918033, "train/adv_mean": 0.0008229530115288582, "train/adv_min": 3.7372912749771246e-05, "train/adv_std": 0.00038484342034024856, "train/cont_avg": 0.996771694214876, "train/cont_loss_mean": 0.021792816719779177, "train/cont_loss_std": 0.31086134291922274, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.691582952226911, "train/cont_pos_acc": 0.9999999876849908, "train/cont_pos_loss": 0.003441537877598639, "train/cont_pred": 0.9965646040341085, "train/cont_rate": 0.996771694214876, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.05879330105525403, "train/extr_critic_critic_opt_grad_steps": 3000.0, "train/extr_critic_critic_opt_loss": 12736.522646565083, "train/extr_critic_mag": 0.10607844935961006, "train/extr_critic_max": 0.10607844935961006, "train/extr_critic_mean": 0.10598290126678372, "train/extr_critic_min": 0.10589098437758517, "train/extr_critic_std": 2.4729679353633688e-05, "train/extr_return_normed_mag": 0.0029706609520045195, "train/extr_return_normed_max": 0.0029706609520045195, "train/extr_return_normed_mean": 0.002394300749841, "train/extr_return_normed_min": 0.0016475052626664973, "train/extr_return_normed_std": 0.0003834962729395421, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.10738220878622749, "train/extr_return_raw_max": 0.10738220878622749, "train/extr_return_raw_mean": 0.10680585459244153, "train/extr_return_raw_min": 0.10605905309688947, "train/extr_return_raw_std": 0.00038349627318006965, "train/extr_reward_mag": 0.0004487027806684005, "train/extr_reward_max": 0.0004487027806684005, "train/extr_reward_mean": 0.00044842987188546, "train/extr_reward_min": 0.00044794417609853195, "train/extr_reward_std": 1.3823031680266808e-07, "train/image_loss_mean": 0.2730017962041965, "train/image_loss_std": 0.0831916217715287, "train/model_loss_mean": 0.9136457034378997, "train/model_loss_std": 0.35204293301775436, "train/model_opt_grad_norm": 79.13865778268861, "train/model_opt_grad_steps": 2990.0, "train/model_opt_loss": 53.05007988165233, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 58.10950413223141, "train/policy_entropy_mag": 1.9458880454055534, "train/policy_entropy_max": 1.9458880454055534, "train/policy_entropy_mean": 1.9449439186695194, "train/policy_entropy_min": 1.9322474869814785, "train/policy_entropy_std": 0.0006043488089541697, "train/policy_logprob_mag": 2.1689976168072915, "train/policy_logprob_max": -1.7318743142214688, "train/policy_logprob_mean": -1.945066699311753, "train/policy_logprob_min": -2.1689976168072915, "train/policy_logprob_std": 0.04370003960226193, "train/policy_randomness_mag": 0.9999887022105131, "train/policy_randomness_max": 0.9999887022105131, "train/policy_randomness_mean": 0.9995035135056362, "train/policy_randomness_min": 0.9929788393422592, "train/policy_randomness_std": 0.0003105738596636648, "train/post_ent_mag": 47.96117864561475, "train/post_ent_max": 47.96117864561475, "train/post_ent_mean": 47.91013925725763, "train/post_ent_min": 47.85158690145193, "train/post_ent_std": 0.014109707622180792, "train/prior_ent_mag": 55.04685283692415, "train/prior_ent_max": 55.04685283692415, "train/prior_ent_mean": 54.97633056010096, "train/prior_ent_min": 54.875776338183194, "train/prior_ent_std": 0.022712979804385792, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0004520422217632405, "train/reward_loss_mean": 0.018851070795670027, "train/reward_loss_std": 0.05767810875780819, "train/reward_max_data": 0.057663566444438596, "train/reward_max_pred": 0.0004489687848682246, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.017838060286296302, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.799082040786743, "train/reward_pred": 0.0004484091946962944, "train/reward_rate": 0.00010491993801652893, "eval_stats/mean_log_entropy": 0.0, "train_stats/mean_log_entropy": 1.9381973102911194, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020027248188853264, "report/cont_loss_std": 0.30992719531059265, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.737603187561035, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0032273188699036837, "report/cont_pred": 0.9967778921127319, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.26944589614868164, "report/image_loss_std": 0.08821491152048111, "report/model_loss_mean": 0.9066747426986694, "report/model_loss_std": 0.3243361711502075, "report/post_ent_mag": 43.734397888183594, "report/post_ent_max": 43.734397888183594, "report/post_ent_mean": 43.67934036254883, "report/post_ent_min": 43.627113342285156, "report/post_ent_std": 0.013095472939312458, "report/prior_ent_mag": 50.87980651855469, "report/prior_ent_max": 50.87980651855469, "report/prior_ent_mean": 50.8369140625, "report/prior_ent_min": 50.71033477783203, "report/prior_ent_std": 0.0243869349360466, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00037940306356176734, "report/reward_loss_mean": 0.017201529815793037, "report/reward_loss_std": 0.027982957661151886, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.0005251169204711914, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.017201529815793037, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0005248216912150383, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0032272585667669773, "eval/cont_loss_std": 2.2825918222224573e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0032272585667669773, "eval/cont_pred": 0.9967778921127319, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2890833616256714, "eval/image_loss_std": 0.08464811742305756, "eval/model_loss_mean": 0.8955299854278564, "eval/model_loss_std": 0.08464804291725159, "eval/post_ent_mag": 43.734962463378906, "eval/post_ent_max": 43.734962463378906, "eval/post_ent_mean": 43.67991638183594, "eval/post_ent_min": 43.63115310668945, "eval/post_ent_std": 0.012318848632276058, "eval/prior_ent_mag": 50.880088806152344, "eval/prior_ent_max": 50.880088806152344, "eval/prior_ent_mean": 50.83573913574219, "eval/prior_ent_min": 50.688873291015625, "eval/prior_ent_std": 0.02443728782236576, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.003219270147383213, "eval/reward_loss_std": 1.4233968386179185e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0005251169204711914, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.003219270147383213, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0005248097004368901, "eval/reward_rate": 0.0, "replay/size": 58785.0, "replay/inserts": 19440.0, "replay/samples": 19440.0, "replay/insert_wait_avg": 1.3182560602823894e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.979630317217038e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 14928.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.216584423421576e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.3546071052551, "timer/env.step_count": 2430.0, "timer/env.step_total": 5.422369956970215, "timer/env.step_frac": 0.010837054121157636, "timer/env.step_avg": 0.0022314279658313643, "timer/env.step_min": 0.0011515617370605469, "timer/env.step_max": 0.009130239486694336, "timer/replay._sample_count": 19440.0, "timer/replay._sample_total": 1350.7236833572388, "timer/replay._sample_frac": 2.6995328196770236, "timer/replay._sample_avg": 0.06948167095459047, "timer/replay._sample_min": 0.00036907196044921875, "timer/replay._sample_max": 0.10056805610656738, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3008.0, "timer/agent.policy_total": 20.055370330810547, "timer/agent.policy_frac": 0.04008231371514418, "timer/agent.policy_avg": 0.006667343859976911, "timer/agent.policy_min": 0.005023002624511719, "timer/agent.policy_max": 0.011398077011108398, "timer/dataset_train_count": 1215.0, "timer/dataset_train_total": 0.10558295249938965, "timer/dataset_train_frac": 0.0002110162492761441, "timer/dataset_train_avg": 8.689954938221371e-05, "timer/dataset_train_min": 7.295608520507812e-05, "timer/dataset_train_max": 0.0002002716064453125, "timer/agent.train_count": 1215.0, "timer/agent.train_total": 466.7283809185028, "timer/agent.train_frac": 0.9327952102184228, "timer/agent.train_avg": 0.38413858511810933, "timer/agent.train_min": 0.35621190071105957, "timer/agent.train_max": 0.4607210159301758, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4372889995574951, "timer/agent.report_frac": 0.0008739581755574932, "timer/agent.report_avg": 0.21864449977874756, "timer/agent.report_min": 0.21336722373962402, "timer/agent.report_max": 0.2239217758178711, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4332275390625e-05, "timer/dataset_eval_frac": 6.86158874188258e-08, "timer/dataset_eval_avg": 3.4332275390625e-05, "timer/dataset_eval_min": 3.4332275390625e-05, "timer/dataset_eval_max": 3.4332275390625e-05, "fps": 38.851956959693176}
{"step": 59392, "episode/length": 288.0, "episode/score": 0.10310687926403261, "episode/reward_rate": 0.0}
{"step": 59400, "episode/length": 288.0, "episode/score": 0.09842003647850106, "episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60040, "episode/length": 288.0, "episode/score": 0.12996345376791396, "episode/reward_rate": 0.0}
{"step": 60112, "episode/length": 288.0, "episode/score": 0.13415820864770467, "episode/reward_rate": 0.0}
{"step": 60400, "episode/length": 193.0, "episode/score": 0.4627392599441009, "episode/reward_rate": 0.005154639175257732}
{"step": 60568, "episode/length": 288.0, "episode/score": 0.10079247002227021, "episode/reward_rate": 0.0}
{"step": 60768, "episode/length": 257.0, "episode/score": 0.3090966761646996, "episode/reward_rate": 0.003875968992248062}
{"step": 60784, "episode/length": 288.0, "episode/score": 0.10197894841621746, "episode/reward_rate": 0.0}
{"step": 61704, "episode/length": 288.0, "episode/score": 0.12025986942842337, "episode/reward_rate": 0.0}
{"step": 61712, "episode/length": 288.0, "episode/score": 0.13177583222386602, "episode/reward_rate": 0.0}
{"step": 62352, "episode/length": 288.0, "episode/score": 0.0977225741374923, "episode/reward_rate": 0.0}
{"step": 62424, "episode/length": 288.0, "episode/score": 0.13264909154020188, "episode/reward_rate": 0.0}
{"step": 62712, "episode/length": 288.0, "episode/score": 0.1054657469301219, "episode/reward_rate": 0.0}
{"step": 62880, "episode/length": 288.0, "episode/score": 0.16166487936084195, "episode/reward_rate": 0.0}
{"step": 63080, "episode/length": 288.0, "episode/score": 0.10351518504057822, "episode/reward_rate": 0.0}
{"step": 63096, "episode/length": 288.0, "episode/score": 0.09009288104493862, "episode/reward_rate": 0.0}
{"step": 64016, "episode/length": 288.0, "episode/score": 0.08478056859496519, "episode/reward_rate": 0.0}
{"step": 64024, "episode/length": 288.0, "episode/score": 0.09427541785782978, "episode/reward_rate": 0.0}
{"step": 64664, "episode/length": 288.0, "episode/score": 0.08858155263249046, "episode/reward_rate": 0.0}
{"step": 64736, "episode/length": 288.0, "episode/score": 0.14837204794628178, "episode/reward_rate": 0.0}
{"step": 65024, "episode/length": 288.0, "episode/score": 0.10654274480953063, "episode/reward_rate": 0.0}
{"step": 65192, "episode/length": 288.0, "episode/score": 0.09501202131184527, "episode/reward_rate": 0.0}
{"step": 65392, "episode/length": 288.0, "episode/score": 0.12093061667826532, "episode/reward_rate": 0.0}
{"step": 65408, "episode/length": 288.0, "episode/score": 0.07626667865309855, "episode/reward_rate": 0.0}
{"step": 66328, "episode/length": 288.0, "episode/score": 0.11399977900123304, "episode/reward_rate": 0.0}
{"step": 66336, "episode/length": 288.0, "episode/score": 0.11529535046184947, "episode/reward_rate": 0.0}
{"step": 66976, "episode/length": 288.0, "episode/score": 0.13465362524772218, "episode/reward_rate": 0.0}
{"step": 67048, "episode/length": 288.0, "episode/score": 0.18398756291219343, "episode/reward_rate": 0.0}
{"step": 67336, "episode/length": 288.0, "episode/score": 0.1247411266770655, "episode/reward_rate": 0.0}
{"step": 67504, "episode/length": 288.0, "episode/score": 0.15351558376141838, "episode/reward_rate": 0.0}
{"step": 67704, "episode/length": 288.0, "episode/score": 0.10323346807376765, "episode/reward_rate": 0.0}
{"step": 67720, "episode/length": 288.0, "episode/score": 0.1876542018127907, "episode/reward_rate": 0.0}
{"step": 68480, "episode/length": 268.0, "episode/score": 0.30216763923090184, "episode/reward_rate": 0.0037174721189591076}
{"step": 68648, "episode/length": 288.0, "episode/score": 0.07228496376569638, "episode/reward_rate": 0.0}
{"step": 69288, "episode/length": 288.0, "episode/score": 0.15236998265208967, "episode/reward_rate": 0.0}
{"step": 69360, "episode/length": 288.0, "episode/score": 0.15965417865777454, "episode/reward_rate": 0.0}
{"step": 69648, "episode/length": 288.0, "episode/score": 0.13538651804333313, "episode/reward_rate": 0.0}
{"step": 69816, "episode/length": 288.0, "episode/score": 0.12334773386601228, "episode/reward_rate": 0.0}
{"step": 70016, "episode/length": 288.0, "episode/score": 0.1765841164298081, "episode/reward_rate": 0.0}
{"step": 70032, "episode/length": 288.0, "episode/score": 0.09674113794494588, "episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70792, "episode/length": 288.0, "episode/score": 0.12077030423506585, "episode/reward_rate": 0.0}
{"step": 70960, "episode/length": 288.0, "episode/score": 0.15308271410560792, "episode/reward_rate": 0.0}
{"step": 71600, "episode/length": 288.0, "episode/score": 0.13495439513155816, "episode/reward_rate": 0.0}
{"step": 71672, "episode/length": 288.0, "episode/score": 0.14965364176521234, "episode/reward_rate": 0.0}
{"step": 71960, "episode/length": 288.0, "episode/score": 0.11041863342848046, "episode/reward_rate": 0.0}
{"step": 72128, "episode/length": 288.0, "episode/score": 0.10817141765107863, "episode/reward_rate": 0.0}
{"step": 72328, "episode/length": 288.0, "episode/score": 0.12363015516586984, "episode/reward_rate": 0.0}
{"step": 72344, "episode/length": 288.0, "episode/score": 0.11327896139835048, "episode/reward_rate": 0.0}
{"step": 73104, "episode/length": 288.0, "episode/score": 0.08404424785624087, "episode/reward_rate": 0.0}
{"step": 73272, "episode/length": 288.0, "episode/score": 0.10565744084499329, "episode/reward_rate": 0.0}
{"step": 73912, "episode/length": 288.0, "episode/score": 0.1156212026681942, "episode/reward_rate": 0.0}
{"step": 73984, "episode/length": 288.0, "episode/score": 0.10078359080273458, "episode/reward_rate": 0.0}
{"step": 74272, "episode/length": 288.0, "episode/score": 0.12755358897220503, "episode/reward_rate": 0.0}
{"step": 74440, "episode/length": 288.0, "episode/score": 0.07345985148072032, "episode/reward_rate": 0.0}
{"step": 74640, "episode/length": 288.0, "episode/score": 0.06573867255730192, "episode/reward_rate": 0.0}
{"step": 74656, "episode/length": 288.0, "episode/score": 0.10305935201046168, "episode/reward_rate": 0.0}
{"step": 75416, "episode/length": 288.0, "episode/score": 0.10903654025418064, "episode/reward_rate": 0.0}
{"step": 75584, "episode/length": 288.0, "episode/score": 0.08391710981129563, "episode/reward_rate": 0.0}
{"step": 75872, "episode/length": 244.0, "episode/score": 0.3270020774897944, "episode/reward_rate": 0.004081632653061225}
{"step": 76296, "episode/length": 288.0, "episode/score": 0.12142665316014245, "episode/reward_rate": 0.0}
{"step": 76584, "episode/length": 288.0, "episode/score": 0.11132167058428877, "episode/reward_rate": 0.0}
{"step": 76752, "episode/length": 288.0, "episode/score": 0.12410689979742529, "episode/reward_rate": 0.0}
{"step": 76952, "episode/length": 288.0, "episode/score": 0.09992527207162993, "episode/reward_rate": 0.0}
{"step": 76968, "episode/length": 288.0, "episode/score": 0.04516839811333284, "episode/reward_rate": 0.0}
{"step": 77728, "episode/length": 288.0, "episode/score": 0.12199149628821715, "episode/reward_rate": 0.0}
{"step": 77896, "episode/length": 288.0, "episode/score": 0.10715609345191979, "episode/reward_rate": 0.0}
{"step": 78184, "episode/length": 288.0, "episode/score": 0.06238308493414024, "episode/reward_rate": 0.0}
{"step": 78537, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0010623143724175, "train/action_min": 0.0, "train/action_std": 1.9989002657330726, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0002305190592019507, "train/actor_opt_grad_steps": 4210.0, "train/actor_opt_loss": 4.548696978033082, "train/adv_mag": 0.0009822028358120564, "train/adv_max": 0.0009822028358120564, "train/adv_mean": 0.0005364437772284362, "train/adv_min": -1.2362422036730554e-06, "train/adv_std": 0.00025247440375517554, "train/cont_avg": 0.9965941373966942, "train/cont_loss_mean": 0.02278956202289844, "train/cont_loss_std": 0.3122079908207628, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.660615046127983, "train/cont_pos_acc": 0.9999999837441877, "train/cont_pos_loss": 0.0035171439440166655, "train/cont_pred": 0.9964892140104751, "train/cont_rate": 0.9965941373966942, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.034875433237776775, "train/extr_critic_critic_opt_grad_steps": 4210.0, "train/extr_critic_critic_opt_loss": 11309.387307915806, "train/extr_critic_mag": 0.12248936467919468, "train/extr_critic_max": 0.12248936467919468, "train/extr_critic_mean": 0.12239298175189121, "train/extr_critic_min": 0.12233178182081743, "train/extr_critic_std": 2.2880371363269483e-05, "train/extr_return_normed_mag": 0.001956786744850726, "train/extr_return_normed_max": 0.001956786744850726, "train/extr_return_normed_mean": 0.0015687128299970395, "train/extr_return_normed_min": 0.0010759955472197415, "train/extr_return_normed_std": 0.0002508260355576823, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.1233174928948899, "train/extr_return_raw_max": 0.1233174928948899, "train/extr_return_raw_mean": 0.12292942478637064, "train/extr_return_raw_min": 0.12243670169725891, "train/extr_return_raw_std": 0.00025082603411451715, "train/extr_reward_mag": 0.0004528031861486514, "train/extr_reward_max": 0.0004528031861486514, "train/extr_reward_mean": 0.0004524541994718419, "train/extr_reward_min": 0.0004522031988979371, "train/extr_reward_std": 1.2359392395839774e-07, "train/image_loss_mean": 0.2665377054825302, "train/image_loss_std": 0.08216333943457643, "train/model_loss_mean": 0.9084062118175601, "train/model_loss_std": 0.3554551461634557, "train/model_opt_grad_norm": 70.13825537941672, "train/model_opt_grad_steps": 4200.0, "train/model_opt_loss": 117.83844252657299, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 129.77789256198346, "train/policy_entropy_mag": 1.9458959585378979, "train/policy_entropy_max": 1.9458959585378979, "train/policy_entropy_mean": 1.9452618045255172, "train/policy_entropy_min": 1.9360313238191211, "train/policy_entropy_std": 0.0004244467432606842, "train/policy_logprob_mag": 2.134604731867136, "train/policy_logprob_max": -1.770384252563981, "train/policy_logprob_mean": -1.9452664142797802, "train/policy_logprob_min": -2.134604731867136, "train/policy_logprob_std": 0.035754107169745385, "train/policy_randomness_mag": 0.9999927671487666, "train/policy_randomness_max": 0.9999927671487666, "train/policy_randomness_mean": 0.999666878507157, "train/policy_randomness_min": 0.9949233438357834, "train/policy_randomness_std": 0.0002181224959367532, "train/post_ent_mag": 41.0629468870557, "train/post_ent_max": 41.0629468870557, "train/post_ent_mean": 41.02806567357592, "train/post_ent_min": 40.94843043177581, "train/post_ent_std": 0.0188918545888352, "train/prior_ent_mag": 48.327002690843315, "train/prior_ent_max": 48.327002690843315, "train/prior_ent_mean": 48.282925471786626, "train/prior_ent_min": 48.170018188224354, "train/prior_ent_std": 0.021143655154145947, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0004490208901053156, "train/reward_loss_mean": 0.019078922773565144, "train/reward_loss_std": 0.06087578549857967, "train/reward_max_data": 0.04972107340158387, "train/reward_max_pred": 0.0004531371691995416, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.017903607138548015, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 7.2877975569831, "train/reward_pred": 0.0004528515571959255, "train/reward_rate": 0.00016141528925619835, "train_stats/mean_log_entropy": 1.9384859907093333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025559529662132263, "report/cont_loss_std": 0.34527090191841125, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.539093971252441, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003937828354537487, "report/cont_pred": 0.9960699081420898, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.26632267236709595, "report/image_loss_std": 0.07835670560598373, "report/model_loss_mean": 0.9104068279266357, "report/model_loss_std": 0.35867342352867126, "report/post_ent_mag": 39.04080581665039, "report/post_ent_max": 39.04080581665039, "report/post_ent_mean": 39.01997375488281, "report/post_ent_min": 38.915225982666016, "report/post_ent_std": 0.026288757100701332, "report/prior_ent_mag": 45.19218063354492, "report/prior_ent_max": 45.19218063354492, "report/prior_ent_mean": 45.155128479003906, "report/prior_ent_min": 45.082340240478516, "report/prior_ent_std": 0.012451042421162128, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00041890423744916916, "report/reward_loss_mean": 0.01852462626993656, "report/reward_loss_std": 0.030002536252141, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.00045096874237060547, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01852462813258171, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00045096874237060547, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003937828820198774, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003937828820198774, "eval/cont_pred": 0.9960699081420898, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2538074254989624, "eval/image_loss_std": 0.07340157777070999, "eval/model_loss_mean": 0.8605610132217407, "eval/model_loss_std": 0.07340157777070999, "eval/post_ent_mag": 39.04456329345703, "eval/post_ent_max": 39.04456329345703, "eval/post_ent_mean": 39.02229309082031, "eval/post_ent_min": 38.904052734375, "eval/post_ent_std": 0.02444925345480442, "eval/prior_ent_mag": 45.20208740234375, "eval/prior_ent_max": 45.20208740234375, "eval/prior_ent_mean": 45.15423583984375, "eval/prior_ent_min": 45.100929260253906, "eval/prior_ent_std": 0.011554290540516376, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.002815723419189453, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00045096874237060547, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002815723419189453, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00045096874237060547, "eval/reward_rate": 0.0, "replay/size": 78033.0, "replay/inserts": 19248.0, "replay/samples": 19248.0, "replay/insert_wait_avg": 1.324394892774219e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.97864855911369e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 19552.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2322590012863845e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.07940125465393, "timer/env.step_count": 2406.0, "timer/env.step_total": 5.395519495010376, "timer/env.step_frac": 0.010789325618038867, "timer/env.step_avg": 0.0022425268059062245, "timer/env.step_min": 0.0011434555053710938, "timer/env.step_max": 0.05948519706726074, "timer/replay._sample_count": 19248.0, "timer/replay._sample_total": 1334.193235874176, "timer/replay._sample_frac": 2.667962792562153, "timer/replay._sample_avg": 0.06931594118215793, "timer/replay._sample_min": 0.0003540515899658203, "timer/replay._sample_max": 0.10107231140136719, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2984.0, "timer/agent.policy_total": 20.0170578956604, "timer/agent.policy_frac": 0.04002775928270474, "timer/agent.policy_avg": 0.006708129321602011, "timer/agent.policy_min": 0.004971981048583984, "timer/agent.policy_max": 0.0133514404296875, "timer/dataset_train_count": 1203.0, "timer/dataset_train_total": 0.10550308227539062, "timer/dataset_train_frac": 0.00021097266156272973, "timer/dataset_train_avg": 8.769998526632637e-05, "timer/dataset_train_min": 7.343292236328125e-05, "timer/dataset_train_max": 0.00019979476928710938, "timer/agent.train_count": 1203.0, "timer/agent.train_total": 466.5955526828766, "timer/agent.train_frac": 0.9330429358062552, "timer/agent.train_avg": 0.3878599772924992, "timer/agent.train_min": 0.3477916717529297, "timer/agent.train_max": 0.4801790714263916, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4349656105041504, "timer/agent.report_frac": 0.0008697930956821278, "timer/agent.report_avg": 0.2174828052520752, "timer/agent.report_min": 0.21681666374206543, "timer/agent.report_max": 0.21814894676208496, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.838539123535156e-05, "timer/dataset_eval_frac": 7.675859301352164e-08, "timer/dataset_eval_avg": 3.838539123535156e-05, "timer/dataset_eval_min": 3.838539123535156e-05, "timer/dataset_eval_max": 3.838539123535156e-05, "fps": 38.48945589025521}
{"step": 78608, "episode/length": 288.0, "episode/score": 0.13621931677340626, "episode/reward_rate": 0.0}
{"step": 78896, "episode/length": 288.0, "episode/score": 0.10823928664024152, "episode/reward_rate": 0.0}
{"step": 79064, "episode/length": 288.0, "episode/score": 0.13168182590732158, "episode/reward_rate": 0.0}
{"step": 79264, "episode/length": 288.0, "episode/score": 0.08071147803377698, "episode/reward_rate": 0.0}
{"step": 79280, "episode/length": 288.0, "episode/score": 0.07179135660680913, "episode/reward_rate": 0.0}
{"step": 80040, "episode/length": 288.0, "episode/score": 0.10511666269178477, "episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 164.0, "eval_episode/score": 0.48750001192092896, "eval_episode/reward_rate": 0.006060606060606061}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80208, "episode/length": 288.0, "episode/score": 0.09147140593660197, "episode/reward_rate": 0.0}
{"step": 80496, "episode/length": 288.0, "episode/score": 0.06597600632903777, "episode/reward_rate": 0.0}
{"step": 80920, "episode/length": 288.0, "episode/score": 0.09672402723310825, "episode/reward_rate": 0.0}
{"step": 81208, "episode/length": 288.0, "episode/score": 0.09910556332130227, "episode/reward_rate": 0.0}
{"step": 81376, "episode/length": 288.0, "episode/score": 0.10849713656750737, "episode/reward_rate": 0.0}
{"step": 81576, "episode/length": 288.0, "episode/score": 0.08574879858394979, "episode/reward_rate": 0.0}
{"step": 81592, "episode/length": 288.0, "episode/score": 0.07999855858190585, "episode/reward_rate": 0.0}
{"step": 82352, "episode/length": 288.0, "episode/score": 0.07446930151826336, "episode/reward_rate": 0.0}
{"step": 82520, "episode/length": 288.0, "episode/score": 0.08098889747455473, "episode/reward_rate": 0.0}
{"step": 82808, "episode/length": 288.0, "episode/score": 0.10646398444819738, "episode/reward_rate": 0.0}
{"step": 83232, "episode/length": 288.0, "episode/score": 0.08845363127150563, "episode/reward_rate": 0.0}
{"step": 83520, "episode/length": 288.0, "episode/score": 0.06015058415076169, "episode/reward_rate": 0.0}
{"step": 83688, "episode/length": 288.0, "episode/score": 0.12135045330060734, "episode/reward_rate": 0.0}
{"step": 83848, "episode/length": 165.0, "episode/score": 0.5454137501436378, "episode/reward_rate": 0.006024096385542169}
{"step": 83888, "episode/length": 288.0, "episode/score": 0.054270317385430644, "episode/reward_rate": 0.0}
{"step": 83904, "episode/length": 288.0, "episode/score": 0.09307675274806115, "episode/reward_rate": 0.0}
{"step": 84664, "episode/length": 288.0, "episode/score": 0.09486206255590446, "episode/reward_rate": 0.0}
{"step": 85120, "episode/length": 288.0, "episode/score": 0.0999361028730732, "episode/reward_rate": 0.0}
{"step": 85544, "episode/length": 288.0, "episode/score": 0.09740062953861184, "episode/reward_rate": 0.0}
{"step": 85832, "episode/length": 288.0, "episode/score": 0.08189428113814756, "episode/reward_rate": 0.0}
{"step": 85896, "episode/length": 153.0, "episode/score": 0.5728148648759941, "episode/reward_rate": 0.006493506493506494}
{"step": 86000, "episode/length": 288.0, "episode/score": 0.1072800567470722, "episode/reward_rate": 0.0}
{"step": 86160, "episode/length": 288.0, "episode/score": 0.09709038122252878, "episode/reward_rate": 0.0}
{"step": 86200, "episode/length": 288.0, "episode/score": 0.0939141408623243, "episode/reward_rate": 0.0}
{"step": 86216, "episode/length": 288.0, "episode/score": 0.08406486496011212, "episode/reward_rate": 0.0}
{"step": 87432, "episode/length": 288.0, "episode/score": 0.09734086343058834, "episode/reward_rate": 0.0}
{"step": 87856, "episode/length": 288.0, "episode/score": 0.08790559654164554, "episode/reward_rate": 0.0}
{"step": 88144, "episode/length": 288.0, "episode/score": 0.06636415431646014, "episode/reward_rate": 0.0}
{"step": 88208, "episode/length": 288.0, "episode/score": 0.07430593660015461, "episode/reward_rate": 0.0}
{"step": 88312, "episode/length": 288.0, "episode/score": 0.07263204358397957, "episode/reward_rate": 0.0}
{"step": 88472, "episode/length": 288.0, "episode/score": 0.08605047960998036, "episode/reward_rate": 0.0}
{"step": 88512, "episode/length": 288.0, "episode/score": 0.10058148455883043, "episode/reward_rate": 0.0}
{"step": 88528, "episode/length": 288.0, "episode/score": 0.11308652108047568, "episode/reward_rate": 0.0}
{"step": 89744, "episode/length": 288.0, "episode/score": 0.07221208765244569, "episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90112, "episode/length": 204.0, "episode/score": 0.4341785631395396, "episode/reward_rate": 0.004878048780487805}
{"step": 90168, "episode/length": 288.0, "episode/score": 0.08890240021878526, "episode/reward_rate": 0.0}
{"step": 90456, "episode/length": 288.0, "episode/score": 0.08112996291239938, "episode/reward_rate": 0.0}
{"step": 90520, "episode/length": 288.0, "episode/score": 0.07439960900924802, "episode/reward_rate": 0.0}
{"step": 90624, "episode/length": 288.0, "episode/score": 0.09594850172342717, "episode/reward_rate": 0.0}
{"step": 90824, "episode/length": 288.0, "episode/score": 0.09189257759658176, "episode/reward_rate": 0.0}
{"step": 90840, "episode/length": 288.0, "episode/score": 0.07518524853173858, "episode/reward_rate": 0.0}
{"step": 92056, "episode/length": 288.0, "episode/score": 0.11039913556351166, "episode/reward_rate": 0.0}
{"step": 92424, "episode/length": 288.0, "episode/score": 0.07359304047713522, "episode/reward_rate": 0.0}
{"step": 92480, "episode/length": 288.0, "episode/score": 0.10553858119885717, "episode/reward_rate": 0.0}
{"step": 92768, "episode/length": 288.0, "episode/score": 0.0921506850469882, "episode/reward_rate": 0.0}
{"step": 92832, "episode/length": 288.0, "episode/score": 0.05726760905599804, "episode/reward_rate": 0.0}
{"step": 92936, "episode/length": 288.0, "episode/score": 0.10107584432373073, "episode/reward_rate": 0.0}
{"step": 93136, "episode/length": 288.0, "episode/score": 0.05661544645110439, "episode/reward_rate": 0.0}
{"step": 93152, "episode/length": 288.0, "episode/score": 0.06734668182249948, "episode/reward_rate": 0.0}
{"step": 94368, "episode/length": 288.0, "episode/score": 0.08272139306919257, "episode/reward_rate": 0.0}
{"step": 94736, "episode/length": 288.0, "episode/score": 0.0733241316203248, "episode/reward_rate": 0.0}
{"step": 94792, "episode/length": 288.0, "episode/score": 0.11001367467551404, "episode/reward_rate": 0.0}
{"step": 95080, "episode/length": 288.0, "episode/score": 0.09904440700182704, "episode/reward_rate": 0.0}
{"step": 95144, "episode/length": 288.0, "episode/score": 0.04381640541481602, "episode/reward_rate": 0.0}
{"step": 95248, "episode/length": 288.0, "episode/score": 0.0770972444141762, "episode/reward_rate": 0.0}
{"step": 95448, "episode/length": 288.0, "episode/score": 0.09653590272304768, "episode/reward_rate": 0.0}
{"step": 95464, "episode/length": 288.0, "episode/score": 0.07478416353640682, "episode/reward_rate": 0.0}
{"step": 96680, "episode/length": 288.0, "episode/score": 0.09814491250591573, "episode/reward_rate": 0.0}
{"step": 97048, "episode/length": 288.0, "episode/score": 0.09589275252426432, "episode/reward_rate": 0.0}
{"step": 97104, "episode/length": 288.0, "episode/score": 0.11900575300950322, "episode/reward_rate": 0.0}
{"step": 97392, "episode/length": 288.0, "episode/score": 0.12974663756628502, "episode/reward_rate": 0.0}
{"step": 97456, "episode/length": 288.0, "episode/score": 0.09505385305391201, "episode/reward_rate": 0.0}
{"step": 97560, "episode/length": 288.0, "episode/score": 0.13878986602676946, "episode/reward_rate": 0.0}
{"step": 97760, "episode/length": 288.0, "episode/score": 0.1303318703984644, "episode/reward_rate": 0.0}
{"step": 97776, "episode/length": 288.0, "episode/score": 0.1317518198355856, "episode/reward_rate": 0.0}
{"step": 97961, "train_stats/mean_log_entropy": 1.938569319080299, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9996988596009815, "train/action_min": 0.0, "train/action_std": 1.999911611730402, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0001474851723595605, "train/actor_opt_grad_steps": 5420.0, "train/actor_opt_loss": 0.23966099207928357, "train/adv_mag": 0.0005940366382441245, "train/adv_max": 0.0005863313832558876, "train/adv_mean": 0.0003107762295934482, "train/adv_min": -3.57829834804062e-05, "train/adv_std": 0.00015033230841833176, "train/cont_avg": 0.9966748450413223, "train/cont_loss_mean": 0.022379872398758847, "train/cont_loss_std": 0.31167384589183306, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.665306543899795, "train/cont_pos_acc": 0.9999999847293886, "train/cont_pos_loss": 0.0035297830227362225, "train/cont_pred": 0.9964765926037938, "train/cont_rate": 0.9966748450413223, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.02076515722019244, "train/extr_critic_critic_opt_grad_steps": 5420.0, "train/extr_critic_critic_opt_loss": 10072.623159865703, "train/extr_critic_mag": 0.13225395423321684, "train/extr_critic_max": 0.13225395423321684, "train/extr_critic_mean": 0.1321619138244755, "train/extr_critic_min": 0.13212001225179879, "train/extr_critic_std": 1.897931666612285e-05, "train/extr_return_normed_mag": 0.0011229218283960642, "train/extr_return_normed_max": 0.0011225565652216761, "train/extr_return_normed_mean": 0.0008816402525388349, "train/extr_return_normed_min": 0.0005857600899767285, "train/extr_return_normed_std": 0.00014835920519394415, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.13271359939220523, "train/extr_return_raw_max": 0.13271359939220523, "train/extr_return_raw_mean": 0.13247268997933254, "train/extr_return_raw_min": 0.1321768029169603, "train/extr_return_raw_std": 0.00014835920699038407, "train/extr_reward_mag": 0.00044634223969514705, "train/extr_reward_max": 0.00044634223969514705, "train/extr_reward_mean": 0.00044612958137338506, "train/extr_reward_min": 0.00044587229894212457, "train/extr_reward_std": 1.0356987490957853e-07, "train/image_loss_mean": 0.26117269103684704, "train/image_loss_std": 0.08349989748690739, "train/model_loss_mean": 0.9025318937853348, "train/model_loss_std": 0.3593348313954251, "train/model_opt_grad_norm": 61.60300087731732, "train/model_opt_grad_steps": 5410.0, "train/model_opt_loss": 260.91599582640595, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 289.25619834710744, "train/policy_entropy_mag": 1.9459005623809562, "train/policy_entropy_max": 1.9459005623809562, "train/policy_entropy_mean": 1.9454373278893715, "train/policy_entropy_min": 1.9381563200438319, "train/policy_entropy_std": 0.00032698194095133687, "train/policy_logprob_mag": 2.1136652792780852, "train/policy_logprob_max": -1.78669999355127, "train/policy_logprob_mean": -1.9454221400347622, "train/policy_logprob_min": -2.1136652792780852, "train/policy_logprob_std": 0.03068827620653574, "train/policy_randomness_mag": 0.999995133108344, "train/policy_randomness_max": 0.999995133108344, "train/policy_randomness_mean": 0.9997570815165181, "train/policy_randomness_min": 0.9960153802367281, "train/policy_randomness_std": 0.00016803547936253065, "train/post_ent_mag": 37.421310141066876, "train/post_ent_max": 37.421310141066876, "train/post_ent_mean": 37.395411089432145, "train/post_ent_min": 37.254731706351286, "train/post_ent_std": 0.034068968793577396, "train/prior_ent_mag": 45.245167755883585, "train/prior_ent_max": 45.245167755883585, "train/prior_ent_mean": 45.20733075102499, "train/prior_ent_min": 45.1304243418796, "train/prior_ent_std": 0.012659380974417383, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00045750877210939657, "train/reward_loss_mean": 0.01897930574010719, "train/reward_loss_std": 0.06761324023904879, "train/reward_max_data": 0.06573347007655654, "train/reward_max_pred": 0.0004461392883426887, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.017597643596943744, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.5740981980374, "train/reward_pred": 0.00044596953844759337, "train/reward_rate": 0.00016141528925619835, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.009743940085172653, "report/cont_loss_std": 0.16898483037948608, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.41461706161499, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00446058576926589, "report/cont_pred": 0.9955495595932007, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2646053433418274, "report/image_loss_std": 0.08948840200901031, "report/model_loss_mean": 0.8932420611381531, "report/model_loss_std": 0.19538135826587677, "report/post_ent_mag": 36.664573669433594, "report/post_ent_max": 36.664573669433594, "report/post_ent_mean": 36.63743209838867, "report/post_ent_min": 36.464576721191406, "report/post_ent_std": 0.04211590811610222, "report/prior_ent_mag": 45.29507827758789, "report/prior_ent_max": 45.29507827758789, "report/prior_ent_mean": 45.26780319213867, "report/prior_ent_min": 45.17803955078125, "report/prior_ent_std": 0.014023174531757832, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004270411154720932, "report/reward_loss_mean": 0.018892746418714523, "report/reward_loss_std": 0.030249567702412605, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.00041544437408447266, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.018892750144004822, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00041544437408447266, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.004460654221475124, "eval/cont_loss_std": 2.341699428143329e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004460654221475124, "eval/cont_pred": 0.9955494403839111, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2605222463607788, "eval/image_loss_std": 0.08066127449274063, "eval/model_loss_mean": 0.8674748539924622, "eval/model_loss_std": 0.08066131174564362, "eval/post_ent_mag": 36.66559982299805, "eval/post_ent_max": 36.66559982299805, "eval/post_ent_mean": 36.63839340209961, "eval/post_ent_min": 36.45465087890625, "eval/post_ent_std": 0.04133525863289833, "eval/prior_ent_mag": 45.29814147949219, "eval/prior_ent_max": 45.29814147949219, "eval/prior_ent_mean": 45.26824951171875, "eval/prior_ent_min": 45.18059158325195, "eval/prior_ent_std": 0.014563143253326416, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0024919509887695312, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00041544437408447266, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0024919509887695312, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00041544437408447266, "eval/reward_rate": 0.0, "replay/size": 97457.0, "replay/inserts": 19424.0, "replay/samples": 19424.0, "replay/insert_wait_avg": 1.3257000945152522e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.998267755084219e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24176.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.242725906900056e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.2828526496887, "timer/env.step_count": 2428.0, "timer/env.step_total": 5.338860034942627, "timer/env.step_frac": 0.010671683042234986, "timer/env.step_avg": 0.0021988715135678035, "timer/env.step_min": 0.001165151596069336, "timer/env.step_max": 0.009695768356323242, "timer/replay._sample_count": 19424.0, "timer/replay._sample_total": 1346.9518501758575, "timer/replay._sample_frac": 2.6923806063747477, "timer/replay._sample_avg": 0.06934472045798278, "timer/replay._sample_min": 0.00038051605224609375, "timer/replay._sample_max": 0.09616804122924805, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3006.0, "timer/agent.policy_total": 19.980100631713867, "timer/agent.policy_frac": 0.039937608346741524, "timer/agent.policy_avg": 0.006646740063777069, "timer/agent.policy_min": 0.0049517154693603516, "timer/agent.policy_max": 0.011107683181762695, "timer/dataset_train_count": 1214.0, "timer/dataset_train_total": 0.10718059539794922, "timer/dataset_train_frac": 0.0002142399940958998, "timer/dataset_train_avg": 8.828714612681154e-05, "timer/dataset_train_min": 7.414817810058594e-05, "timer/dataset_train_max": 0.00033402442932128906, "timer/agent.train_count": 1214.0, "timer/agent.train_total": 466.7684123516083, "timer/agent.train_frac": 0.9330090165581827, "timer/agent.train_avg": 0.3844879838151633, "timer/agent.train_min": 0.35567545890808105, "timer/agent.train_max": 0.8048529624938965, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4342787265777588, "timer/agent.report_frac": 0.0008680663834022155, "timer/agent.report_avg": 0.2171393632888794, "timer/agent.report_min": 0.2166893482208252, "timer/agent.report_max": 0.2175893783569336, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.743171691894531e-05, "timer/dataset_eval_frac": 7.482110714107564e-08, "timer/dataset_eval_avg": 3.743171691894531e-05, "timer/dataset_eval_min": 3.743171691894531e-05, "timer/dataset_eval_max": 3.743171691894531e-05, "fps": 38.82550226143426}
{"step": 98992, "episode/length": 288.0, "episode/score": 0.09864030670578927, "episode/reward_rate": 0.0}
{"step": 99360, "episode/length": 288.0, "episode/score": 0.17984800211229413, "episode/reward_rate": 0.0}
{"step": 99416, "episode/length": 288.0, "episode/score": 0.10927491960228508, "episode/reward_rate": 0.0}
{"step": 99704, "episode/length": 288.0, "episode/score": 0.1150048895638065, "episode/reward_rate": 0.0}
{"step": 99768, "episode/length": 288.0, "episode/score": 0.1600036796492077, "episode/reward_rate": 0.0}
{"step": 99872, "episode/length": 288.0, "episode/score": 0.1321464697537067, "episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 213.0, "eval_episode/score": 0.3343749940395355, "eval_episode/reward_rate": 0.004672897196261682}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100072, "episode/length": 288.0, "episode/score": 0.1385418647194001, "episode/reward_rate": 0.0}
{"step": 100088, "episode/length": 288.0, "episode/score": 0.1703068648057524, "episode/reward_rate": 0.0}
{"step": 101176, "episode/length": 219.0, "episode/score": 0.431872990185866, "episode/reward_rate": 0.004545454545454545}
{"step": 101304, "episode/length": 288.0, "episode/score": 0.08964867793986286, "episode/reward_rate": 0.0}
{"step": 101672, "episode/length": 288.0, "episode/score": 0.13006422017406294, "episode/reward_rate": 0.0}
{"step": 102016, "episode/length": 288.0, "episode/score": 0.12437694287655177, "episode/reward_rate": 0.0}
{"step": 102016, "episode/length": 42.0, "episode/score": 0.9123758074169928, "episode/reward_rate": 0.023255813953488372}
{"step": 102080, "episode/length": 288.0, "episode/score": 0.14021619544166697, "episode/reward_rate": 0.0}
{"step": 102184, "episode/length": 288.0, "episode/score": 0.10394709757747478, "episode/reward_rate": 0.0}
{"step": 102384, "episode/length": 288.0, "episode/score": 0.15320849247791557, "episode/reward_rate": 0.0}
{"step": 102400, "episode/length": 288.0, "episode/score": 0.10916671209190554, "episode/reward_rate": 0.0}
{"step": 103488, "episode/length": 288.0, "episode/score": 0.12155649283079129, "episode/reward_rate": 0.0}
{"step": 103616, "episode/length": 288.0, "episode/score": 0.08544285562766163, "episode/reward_rate": 0.0}
{"step": 104328, "episode/length": 288.0, "episode/score": 0.11366197355118857, "episode/reward_rate": 0.0}
{"step": 104328, "episode/length": 288.0, "episode/score": 0.06655273420483354, "episode/reward_rate": 0.0}
{"step": 104392, "episode/length": 288.0, "episode/score": 0.11076682457360221, "episode/reward_rate": 0.0}
{"step": 104496, "episode/length": 288.0, "episode/score": 0.10407079504091143, "episode/reward_rate": 0.0}
{"step": 104696, "episode/length": 288.0, "episode/score": 0.11818252941191076, "episode/reward_rate": 0.0}
{"step": 104712, "episode/length": 288.0, "episode/score": 0.14014844061557596, "episode/reward_rate": 0.0}
{"step": 105800, "episode/length": 288.0, "episode/score": 0.14463330776618477, "episode/reward_rate": 0.0}
{"step": 105848, "episode/length": 189.0, "episode/score": 0.5132336651020637, "episode/reward_rate": 0.005263157894736842}
{"step": 105928, "episode/length": 288.0, "episode/score": 0.09062439417544965, "episode/reward_rate": 0.0}
{"step": 106640, "episode/length": 288.0, "episode/score": 0.10871714849582759, "episode/reward_rate": 0.0}
{"step": 106704, "episode/length": 288.0, "episode/score": 0.11856644516024062, "episode/reward_rate": 0.0}
{"step": 106808, "episode/length": 288.0, "episode/score": 0.06954379539337197, "episode/reward_rate": 0.0}
{"step": 107008, "episode/length": 288.0, "episode/score": 0.1328330472512107, "episode/reward_rate": 0.0}
{"step": 107024, "episode/length": 288.0, "episode/score": 0.13901812772348876, "episode/reward_rate": 0.0}
{"step": 108112, "episode/length": 288.0, "episode/score": 0.08181807566040789, "episode/reward_rate": 0.0}
{"step": 108160, "episode/length": 288.0, "episode/score": 0.10199155689940653, "episode/reward_rate": 0.0}
{"step": 108240, "episode/length": 288.0, "episode/score": 0.11227365053667882, "episode/reward_rate": 0.0}
{"step": 108288, "episode/length": 157.0, "episode/score": 0.5860150840721303, "episode/reward_rate": 0.006329113924050633}
{"step": 108952, "episode/length": 288.0, "episode/score": 0.08255286402754791, "episode/reward_rate": 0.0}
{"step": 109016, "episode/length": 288.0, "episode/score": 0.07690338737830871, "episode/reward_rate": 0.0}
{"step": 109120, "episode/length": 288.0, "episode/score": 0.07783421567347659, "episode/reward_rate": 0.0}
{"step": 109320, "episode/length": 288.0, "episode/score": 0.08196779473098559, "episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110424, "episode/length": 288.0, "episode/score": 0.06630143549176637, "episode/reward_rate": 0.0}
{"step": 110472, "episode/length": 288.0, "episode/score": 0.11099251653701003, "episode/reward_rate": 0.0}
{"step": 110552, "episode/length": 288.0, "episode/score": 0.057221712241982914, "episode/reward_rate": 0.0}
{"step": 110600, "episode/length": 288.0, "episode/score": 0.0758753308574569, "episode/reward_rate": 0.0}
{"step": 111264, "episode/length": 288.0, "episode/score": 0.10561009474929506, "episode/reward_rate": 0.0}
{"step": 111328, "episode/length": 288.0, "episode/score": 0.09079940832390321, "episode/reward_rate": 0.0}
{"step": 111432, "episode/length": 288.0, "episode/score": 0.08093152182959784, "episode/reward_rate": 0.0}
{"step": 111632, "episode/length": 288.0, "episode/score": 0.05283439513863186, "episode/reward_rate": 0.0}
{"step": 112736, "episode/length": 288.0, "episode/score": 0.07539577192244451, "episode/reward_rate": 0.0}
{"step": 112784, "episode/length": 288.0, "episode/score": 0.08674025879940928, "episode/reward_rate": 0.0}
{"step": 112864, "episode/length": 288.0, "episode/score": 0.06398784340115071, "episode/reward_rate": 0.0}
{"step": 112912, "episode/length": 288.0, "episode/score": 0.10351302445786814, "episode/reward_rate": 0.0}
{"step": 113576, "episode/length": 288.0, "episode/score": 0.1142081495427476, "episode/reward_rate": 0.0}
{"step": 113640, "episode/length": 288.0, "episode/score": 0.1205558668038691, "episode/reward_rate": 0.0}
{"step": 113744, "episode/length": 288.0, "episode/score": 0.0720086433792062, "episode/reward_rate": 0.0}
{"step": 113944, "episode/length": 288.0, "episode/score": 0.06809283055247306, "episode/reward_rate": 0.0}
{"step": 115048, "episode/length": 288.0, "episode/score": 0.08192615799055147, "episode/reward_rate": 0.0}
{"step": 115096, "episode/length": 288.0, "episode/score": 0.1209249124344467, "episode/reward_rate": 0.0}
{"step": 115176, "episode/length": 288.0, "episode/score": 0.06580781206326947, "episode/reward_rate": 0.0}
{"step": 115224, "episode/length": 288.0, "episode/score": 0.07161867304174052, "episode/reward_rate": 0.0}
{"step": 115888, "episode/length": 288.0, "episode/score": 0.12067634192692367, "episode/reward_rate": 0.0}
{"step": 115952, "episode/length": 288.0, "episode/score": 0.08415758048712974, "episode/reward_rate": 0.0}
{"step": 116056, "episode/length": 288.0, "episode/score": 0.11065401875282532, "episode/reward_rate": 0.0}
{"step": 116256, "episode/length": 288.0, "episode/score": 0.06503379185571134, "episode/reward_rate": 0.0}
{"step": 117360, "episode/length": 288.0, "episode/score": 0.08297149837352435, "episode/reward_rate": 0.0}
{"step": 117385, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9995362328701334, "train/action_min": 0.0, "train/action_std": 2.0006971593763008, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00010859913373813052, "train/actor_opt_grad_steps": 6635.0, "train/actor_opt_loss": -1.8526716742198914, "train/adv_mag": 0.0004586733755518178, "train/adv_max": 0.0004382319137698314, "train/adv_mean": 0.00020119362274212497, "train/adv_min": -7.320305363076632e-05, "train/adv_std": 0.00010821601398167898, "train/cont_avg": 0.9964459528688525, "train/cont_loss_mean": 0.023641989812575526, "train/cont_loss_std": 0.3240923228230877, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.672437451466792, "train/cont_pos_acc": 0.9999999829003068, "train/cont_pos_loss": 0.003488380608881717, "train/cont_pred": 0.9965178155508198, "train/cont_rate": 0.9964459528688525, "train/dyn_loss_mean": 1.0004791431739681, "train/dyn_loss_std": 0.000541534935139486, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.01924965396660884, "train/extr_critic_critic_opt_grad_steps": 6635.0, "train/extr_critic_critic_opt_loss": 9190.800381019468, "train/extr_critic_mag": 0.1379667588921844, "train/extr_critic_max": 0.1379667588921844, "train/extr_critic_mean": 0.13787507094809268, "train/extr_critic_min": 0.13780233117400623, "train/extr_critic_std": 1.9177913453607384e-05, "train/extr_return_normed_mag": 0.0007749687208503973, "train/extr_return_normed_max": 0.0007561205840501629, "train/extr_return_normed_mean": 0.0005787519467878051, "train/extr_return_normed_min": 0.00035107416696235783, "train/extr_return_normed_std": 0.00010461451455046431, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.1382536259098131, "train/extr_return_raw_max": 0.1382536259098131, "train/extr_return_raw_mean": 0.13807626496084402, "train/extr_return_raw_min": 0.1378485794927253, "train/extr_return_raw_std": 0.00010461451485984161, "train/extr_reward_mag": 0.00044615737727431, "train/extr_reward_max": 0.00044615737727431, "train/extr_reward_mean": 0.00044592653952737446, "train/extr_reward_min": 0.00044574209901153064, "train/extr_reward_std": 1.0833178311785812e-07, "train/image_loss_mean": 0.25739214679256817, "train/image_loss_std": 0.08297878842739785, "train/model_loss_mean": 0.9004303798323772, "train/model_loss_std": 0.3788533415340009, "train/model_opt_grad_norm": 56.48842733414447, "train/model_opt_grad_steps": 6625.0, "train/model_opt_loss": 668.4972759309362, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 742.827868852459, "train/policy_entropy_mag": 1.9458975098172173, "train/policy_entropy_max": 1.9458975098172173, "train/policy_entropy_mean": 1.9452977414991035, "train/policy_entropy_min": 1.9345280625781074, "train/policy_entropy_std": 0.00043596399444170665, "train/policy_logprob_mag": 2.157471709564084, "train/policy_logprob_max": -1.7719731477440381, "train/policy_logprob_mean": -1.9452961556247024, "train/policy_logprob_min": -2.157471709564084, "train/policy_logprob_std": 0.03409642167389393, "train/policy_randomness_mag": 0.9999935631869269, "train/policy_randomness_max": 0.9999935631869269, "train/policy_randomness_mean": 0.9996853461031054, "train/policy_randomness_min": 0.9941508227684459, "train/policy_randomness_std": 0.00022404120658184632, "train/post_ent_mag": 39.25507276566302, "train/post_ent_max": 39.25507276566302, "train/post_ent_mean": 39.228455715492125, "train/post_ent_min": 39.0421028137207, "train/post_ent_std": 0.043624666561448915, "train/prior_ent_mag": 44.33763119431793, "train/prior_ent_max": 44.33763119431793, "train/prior_ent_mean": 44.30415644411181, "train/prior_ent_min": 44.219947689869365, "train/prior_ent_std": 0.015543770178633391, "train/rep_loss_mean": 1.0004791431739681, "train/rep_loss_std": 0.000541534935139486, "train/reward_avg": 0.00046863249497350735, "train/reward_loss_mean": 0.01910873387986031, "train/reward_loss_std": 0.07727927833673406, "train/reward_max_data": 0.07938831871314371, "train/reward_max_pred": 0.0004456160498447106, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.017276110562694368, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.162112375100454, "train/reward_pred": 0.00044546352955131014, "train/reward_rate": 0.00022412909836065574, "train_stats/mean_log_entropy": 1.9378975954922764, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.030947107821702957, "report/cont_loss_std": 0.38447389006614685, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.5196404457092285, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004015340469777584, "report/cont_pred": 0.9959926605224609, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2735326290130615, "report/image_loss_std": 0.07067007571458817, "report/model_loss_mean": 0.9226597547531128, "report/model_loss_std": 0.39476320147514343, "report/post_ent_mag": 43.683868408203125, "report/post_ent_max": 43.683868408203125, "report/post_ent_mean": 43.6748046875, "report/post_ent_min": 43.625125885009766, "report/post_ent_std": 0.010555209591984749, "report/prior_ent_mag": 40.78749084472656, "report/prior_ent_max": 40.78749084472656, "report/prior_ent_mean": 40.76408386230469, "report/prior_ent_min": 40.75106430053711, "report/prior_ent_std": 0.0071243904531002045, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00040841414011083543, "report/reward_loss_mean": 0.018180090934038162, "report/reward_loss_std": 0.028746727854013443, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.0005143880844116211, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.018180090934038162, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0005143880844116211, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.004015340469777584, "eval/cont_loss_std": 9.313225746154785e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004015340469777584, "eval/cont_pred": 0.9959926605224609, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2662668824195862, "eval/image_loss_std": 0.06606496870517731, "eval/model_loss_mean": 0.8733616471290588, "eval/model_loss_std": 0.06606496125459671, "eval/post_ent_mag": 43.683998107910156, "eval/post_ent_max": 43.683998107910156, "eval/post_ent_mean": 43.67499923706055, "eval/post_ent_min": 43.62575149536133, "eval/post_ent_std": 0.010319241322577, "eval/prior_ent_mag": 40.7879753112793, "eval/prior_ent_max": 40.7879753112793, "eval/prior_ent_mean": 40.764015197753906, "eval/prior_ent_min": 40.75213623046875, "eval/prior_ent_std": 0.007185406517237425, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0030794143676757812, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0005143880844116211, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0030794143676757812, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0005143880844116211, "eval/reward_rate": 0.0, "replay/size": 116881.0, "replay/inserts": 19424.0, "replay/samples": 19424.0, "replay/insert_wait_avg": 1.3440012735432808e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.087257391538416e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 28800.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2445821069103624e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.38490748405457, "timer/env.step_count": 2428.0, "timer/env.step_total": 5.479614734649658, "timer/env.step_frac": 0.010950799380023813, "timer/env.step_avg": 0.0022568429714372564, "timer/env.step_min": 0.0011801719665527344, "timer/env.step_max": 0.015724897384643555, "timer/replay._sample_count": 19424.0, "timer/replay._sample_total": 1352.7557425498962, "timer/replay._sample_frac": 2.703430343955775, "timer/replay._sample_avg": 0.06964352051842547, "timer/replay._sample_min": 0.00032830238342285156, "timer/replay._sample_max": 0.10031676292419434, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3006.0, "timer/agent.policy_total": 20.171525955200195, "timer/agent.policy_frac": 0.0403120191146912, "timer/agent.policy_avg": 0.006710421142781169, "timer/agent.policy_min": 0.004965543746948242, "timer/agent.policy_max": 0.011959075927734375, "timer/dataset_train_count": 1214.0, "timer/dataset_train_total": 0.10802102088928223, "timer/dataset_train_frac": 0.00021587585731235203, "timer/dataset_train_avg": 8.897942412626214e-05, "timer/dataset_train_min": 7.486343383789062e-05, "timer/dataset_train_max": 0.00022029876708984375, "timer/agent.train_count": 1214.0, "timer/agent.train_total": 466.4630126953125, "timer/agent.train_frac": 0.9322083974128995, "timer/agent.train_avg": 0.3842364190241454, "timer/agent.train_min": 0.3570823669433594, "timer/agent.train_max": 0.46078968048095703, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4557523727416992, "timer/agent.report_frac": 0.0009108035952427729, "timer/agent.report_avg": 0.2278761863708496, "timer/agent.report_min": 0.21846389770507812, "timer/agent.report_max": 0.2372884750366211, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.743171691894531e-05, "timer/dataset_eval_frac": 7.480584717703166e-08, "timer/dataset_eval_avg": 3.743171691894531e-05, "timer/dataset_eval_min": 3.743171691894531e-05, "timer/dataset_eval_max": 3.743171691894531e-05, "fps": 38.81768168238167}
{"step": 117408, "episode/length": 288.0, "episode/score": 0.053392597004517484, "episode/reward_rate": 0.0}
{"step": 117488, "episode/length": 288.0, "episode/score": 0.08233783813955142, "episode/reward_rate": 0.0}
{"step": 117536, "episode/length": 288.0, "episode/score": 0.05451107717908599, "episode/reward_rate": 0.0}
{"step": 118200, "episode/length": 288.0, "episode/score": 0.11665309872654461, "episode/reward_rate": 0.0}
{"step": 118264, "episode/length": 288.0, "episode/score": 0.07399134922604844, "episode/reward_rate": 0.0}
{"step": 118368, "episode/length": 288.0, "episode/score": 0.07889478422217167, "episode/reward_rate": 0.0}
{"step": 118568, "episode/length": 288.0, "episode/score": 0.10329160128605963, "episode/reward_rate": 0.0}
{"step": 119672, "episode/length": 288.0, "episode/score": 0.0959476059745441, "episode/reward_rate": 0.0}
{"step": 119720, "episode/length": 288.0, "episode/score": 0.05573422703548658, "episode/reward_rate": 0.0}
{"step": 119800, "episode/length": 288.0, "episode/score": 0.07711094840348665, "episode/reward_rate": 0.0}
{"step": 119848, "episode/length": 288.0, "episode/score": 0.06668837105550551, "episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 216.0, "eval_episode/score": 0.32499998807907104, "eval_episode/reward_rate": 0.004608294930875576}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120512, "episode/length": 288.0, "episode/score": 0.07160419351239966, "episode/reward_rate": 0.0}
{"step": 120576, "episode/length": 288.0, "episode/score": 0.0602583374464416, "episode/reward_rate": 0.0}
{"step": 120680, "episode/length": 288.0, "episode/score": 0.15686675556224827, "episode/reward_rate": 0.0}
{"step": 120880, "episode/length": 288.0, "episode/score": 0.09333342052633498, "episode/reward_rate": 0.0}
{"step": 121984, "episode/length": 288.0, "episode/score": 0.10053153922200408, "episode/reward_rate": 0.0}
{"step": 122032, "episode/length": 288.0, "episode/score": 0.16546197524760942, "episode/reward_rate": 0.0}
{"step": 122112, "episode/length": 288.0, "episode/score": 0.13298315943362127, "episode/reward_rate": 0.0}
{"step": 122160, "episode/length": 288.0, "episode/score": 0.11291830956625404, "episode/reward_rate": 0.0}
{"step": 122824, "episode/length": 288.0, "episode/score": 0.16421732707476622, "episode/reward_rate": 0.0}
{"step": 122888, "episode/length": 288.0, "episode/score": 0.11461640102015735, "episode/reward_rate": 0.0}
{"step": 122992, "episode/length": 288.0, "episode/score": 0.17362174190475343, "episode/reward_rate": 0.0}
{"step": 123192, "episode/length": 288.0, "episode/score": 0.174382341274395, "episode/reward_rate": 0.0}
{"step": 124296, "episode/length": 288.0, "episode/score": 0.1444295124204018, "episode/reward_rate": 0.0}
{"step": 124344, "episode/length": 288.0, "episode/score": 0.06198916448443015, "episode/reward_rate": 0.0}
{"step": 124424, "episode/length": 288.0, "episode/score": 0.06857548043967654, "episode/reward_rate": 0.0}
{"step": 124472, "episode/length": 288.0, "episode/score": 0.10099045089555148, "episode/reward_rate": 0.0}
{"step": 125136, "episode/length": 288.0, "episode/score": 0.11474103441537409, "episode/reward_rate": 0.0}
{"step": 125200, "episode/length": 288.0, "episode/score": 0.11148530752348051, "episode/reward_rate": 0.0}
{"step": 125304, "episode/length": 288.0, "episode/score": 0.17361557814740536, "episode/reward_rate": 0.0}
{"step": 125504, "episode/length": 288.0, "episode/score": 0.06486324363959284, "episode/reward_rate": 0.0}
{"step": 126048, "episode/length": 113.0, "episode/score": 0.7134879204670597, "episode/reward_rate": 0.008771929824561403}
{"step": 126088, "episode/length": 97.0, "episode/score": 0.7436768168377057, "episode/reward_rate": 0.01020408163265306}
{"step": 126608, "episode/length": 288.0, "episode/score": 0.1035950145011384, "episode/reward_rate": 0.0}
{"step": 126656, "episode/length": 288.0, "episode/score": 0.14722158905783544, "episode/reward_rate": 0.0}
{"step": 126736, "episode/length": 288.0, "episode/score": 0.13497905124347653, "episode/reward_rate": 0.0}
{"step": 126784, "episode/length": 288.0, "episode/score": 0.08502622029288887, "episode/reward_rate": 0.0}
{"step": 127512, "episode/length": 288.0, "episode/score": 0.12210456276795867, "episode/reward_rate": 0.0}
{"step": 127816, "episode/length": 288.0, "episode/score": 0.1161824396197062, "episode/reward_rate": 0.0}
{"step": 128176, "episode/length": 82.0, "episode/score": 0.7960822653577679, "episode/reward_rate": 0.012048192771084338}
{"step": 128360, "episode/length": 288.0, "episode/score": 0.09739988267062927, "episode/reward_rate": 0.0}
{"step": 128400, "episode/length": 288.0, "episode/score": 0.049705342786069195, "episode/reward_rate": 0.0}
{"step": 128920, "episode/length": 288.0, "episode/score": 0.08280558381625269, "episode/reward_rate": 0.0}
{"step": 128968, "episode/length": 288.0, "episode/score": 0.16055378257965458, "episode/reward_rate": 0.0}
{"step": 129048, "episode/length": 288.0, "episode/score": 0.09002771289766542, "episode/reward_rate": 0.0}
{"step": 129096, "episode/length": 288.0, "episode/score": 0.16827208274355598, "episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 201.0, "eval_episode/score": 0.37187498807907104, "eval_episode/reward_rate": 0.0049504950495049506}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130128, "episode/length": 288.0, "episode/score": 0.06209727440648294, "episode/reward_rate": 0.0}
{"step": 130488, "episode/length": 288.0, "episode/score": 0.09756520346206798, "episode/reward_rate": 0.0}
{"step": 130672, "episode/length": 288.0, "episode/score": 0.07438451050757067, "episode/reward_rate": 0.0}
{"step": 130712, "episode/length": 288.0, "episode/score": 0.10356613072099208, "episode/reward_rate": 0.0}
{"step": 131232, "episode/length": 288.0, "episode/score": 0.11060587555715529, "episode/reward_rate": 0.0}
{"step": 131280, "episode/length": 288.0, "episode/score": 0.14682259973119471, "episode/reward_rate": 0.0}
{"step": 131360, "episode/length": 288.0, "episode/score": 0.08347236190127205, "episode/reward_rate": 0.0}
{"step": 131408, "episode/length": 288.0, "episode/score": 0.13537149365970436, "episode/reward_rate": 0.0}
{"step": 131432, "episode/length": 18.0, "episode/score": 0.9590589825870666, "episode/reward_rate": 0.05263157894736842}
{"step": 132440, "episode/length": 288.0, "episode/score": 0.10502139072974614, "episode/reward_rate": 0.0}
{"step": 132800, "episode/length": 288.0, "episode/score": 0.08751455179998402, "episode/reward_rate": 0.0}
{"step": 132984, "episode/length": 288.0, "episode/score": 0.07119852081865474, "episode/reward_rate": 0.0}
{"step": 133024, "episode/length": 288.0, "episode/score": 0.1316173211909586, "episode/reward_rate": 0.0}
{"step": 133544, "episode/length": 288.0, "episode/score": 0.09462405600322654, "episode/reward_rate": 0.0}
{"step": 133672, "episode/length": 288.0, "episode/score": 0.17716458065251572, "episode/reward_rate": 0.0}
{"step": 133720, "episode/length": 288.0, "episode/score": 0.11578230092982267, "episode/reward_rate": 0.0}
{"step": 133744, "episode/length": 288.0, "episode/score": 0.13218394337076234, "episode/reward_rate": 0.0}
{"step": 134752, "episode/length": 288.0, "episode/score": 0.1261208370825102, "episode/reward_rate": 0.0}
{"step": 135112, "episode/length": 288.0, "episode/score": 0.11092123332991832, "episode/reward_rate": 0.0}
{"step": 135296, "episode/length": 288.0, "episode/score": 0.1415380801665833, "episode/reward_rate": 0.0}
{"step": 135336, "episode/length": 288.0, "episode/score": 0.12577326400332822, "episode/reward_rate": 0.0}
{"step": 135856, "episode/length": 288.0, "episode/score": 0.11186181173206933, "episode/reward_rate": 0.0}
{"step": 135984, "episode/length": 288.0, "episode/score": 0.1325343154737766, "episode/reward_rate": 0.0}
{"step": 136032, "episode/length": 288.0, "episode/score": 0.12959425875760644, "episode/reward_rate": 0.0}
{"step": 136056, "episode/length": 288.0, "episode/score": 0.12286087760412556, "episode/reward_rate": 0.0}
{"step": 136409, "train_stats/mean_log_entropy": 1.9364879500698036, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0010003558659957, "train/action_min": 0.0, "train/action_std": 1.9986964939004284, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 7.0056134711071e-05, "train/actor_opt_grad_steps": 7835.0, "train/actor_opt_loss": -3.899413843370848, "train/adv_mag": 0.0003737167029057519, "train/adv_max": 0.00030766692707094096, "train/adv_mean": 9.399069920915527e-05, "train/adv_min": -0.00013414820877172178, "train/adv_std": 8.408117370844732e-05, "train/cont_avg": 0.9963916843220338, "train/cont_loss_mean": 0.02393701527330835, "train/cont_loss_std": 0.32831279141904335, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.665044500910002, "train/cont_pos_acc": 0.9999999858565249, "train/cont_pos_loss": 0.0035176197130043626, "train/cont_pred": 0.9964887080556255, "train/cont_rate": 0.9963916843220338, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.021751925270309894, "train/extr_critic_critic_opt_grad_steps": 7835.0, "train/extr_critic_critic_opt_loss": 8662.245257878707, "train/extr_critic_mag": 0.14105519399804584, "train/extr_critic_max": 0.14105519399804584, "train/extr_critic_mean": 0.14095754441568406, "train/extr_critic_min": 0.14088263855142108, "train/extr_critic_std": 2.093153404584702e-05, "train/extr_return_normed_mag": 0.0005224739848557165, "train/extr_return_normed_max": 0.0004281863822775372, "train/extr_return_normed_mean": 0.0002793876544304929, "train/extr_return_normed_min": 0.00011505704309980748, "train/extr_return_normed_std": 7.844901549040484e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.1412003278984862, "train/extr_return_raw_max": 0.1412003278984862, "train/extr_return_raw_mean": 0.1410515365206589, "train/extr_return_raw_min": 0.14088719855930845, "train/extr_return_raw_std": 7.84490191900443e-05, "train/extr_reward_mag": 0.00043836185487650207, "train/extr_reward_max": 0.00043836185487650207, "train/extr_reward_mean": 0.0004382455863070406, "train/extr_reward_min": 0.0004380587804115425, "train/extr_reward_std": 6.289003474111958e-08, "train/image_loss_mean": 0.25345978696467514, "train/image_loss_std": 0.08432067173012232, "train/model_loss_mean": 0.896400823936624, "train/model_loss_std": 0.38312795467801014, "train/model_opt_grad_norm": 52.457327535596946, "train/model_opt_grad_steps": 7825.0, "train/model_opt_loss": 1509.9222039691472, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1684.322033898305, "train/policy_entropy_mag": 1.9458956395165394, "train/policy_entropy_max": 1.9458956395165394, "train/policy_entropy_mean": 1.9452048661345143, "train/policy_entropy_min": 1.93216779878584, "train/policy_entropy_std": 0.0005096015774435759, "train/policy_logprob_mag": 2.1934243218373446, "train/policy_logprob_max": -1.7574753973443629, "train/policy_logprob_mean": -1.9451593170731754, "train/policy_logprob_min": -2.1934243218373446, "train/policy_logprob_std": 0.0375621950222274, "train/policy_randomness_mag": 0.9999926039728068, "train/policy_randomness_max": 0.9999926039728068, "train/policy_randomness_mean": 0.99963762396473, "train/policy_randomness_min": 0.9929378866139105, "train/policy_randomness_std": 0.0002618834203192017, "train/post_ent_mag": 44.054787037736276, "train/post_ent_max": 44.054787037736276, "train/post_ent_mean": 44.04550293744621, "train/post_ent_min": 44.00356215137546, "train/post_ent_std": 0.00921674371870645, "train/prior_ent_mag": 40.80952673443293, "train/prior_ent_max": 40.80952673443293, "train/prior_ent_mean": 40.79499674651582, "train/prior_ent_min": 40.784559508501474, "train/prior_ent_std": 0.00444771524053067, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00046380917749849103, "train/reward_loss_mean": 0.019003995938889556, "train/reward_loss_std": 0.07643038784232685, "train/reward_max_data": 0.07806814864072632, "train/reward_max_pred": 0.0004382214303744041, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.017216638725061538, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.100141504536504, "train/reward_pred": 0.00043796985883707716, "train/reward_rate": 0.00022345074152542373, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.031810514628887177, "report/cont_loss_std": 0.419327050447464, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.018062114715576, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0024373498745262623, "report/cont_pred": 0.9975654482841492, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.244254469871521, "report/image_loss_std": 0.07692676037549973, "report/model_loss_mean": 0.8943158388137817, "report/model_loss_std": 0.43244341015815735, "report/post_ent_mag": 44.764766693115234, "report/post_ent_max": 44.764766693115234, "report/post_ent_mean": 44.754417419433594, "report/post_ent_min": 44.71131896972656, "report/post_ent_std": 0.009554366581141949, "report/prior_ent_mag": 40.821693420410156, "report/prior_ent_max": 40.821693420410156, "report/prior_ent_mean": 40.809776306152344, "report/prior_ent_min": 40.80012130737305, "report/prior_ent_std": 0.003629834856837988, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00041083950782194734, "report/reward_loss_mean": 0.018250778317451477, "report/reward_loss_std": 0.030410761013627052, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.000396728515625, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.018250776454806328, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.000396728515625, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014186611399054527, "eval/cont_loss_std": 0.26559576392173767, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.018062114715576, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0024373498745262623, "eval/cont_pred": 0.9975654482841492, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.25401097536087036, "eval/image_loss_std": 0.0801229253411293, "eval/model_loss_mean": 0.8705455660820007, "eval/model_loss_std": 0.27851247787475586, "eval/post_ent_mag": 44.76512145996094, "eval/post_ent_max": 44.76512145996094, "eval/post_ent_mean": 44.75486373901367, "eval/post_ent_min": 44.711265563964844, "eval/post_ent_std": 0.00893259048461914, "eval/prior_ent_mag": 40.821998596191406, "eval/prior_ent_max": 40.821998596191406, "eval/prior_ent_mean": 40.809505462646484, "eval/prior_ent_min": 40.79955291748047, "eval/prior_ent_std": 0.0035204330924898386, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0023479461669921875, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.000396728515625, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0023479461669921875, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.000396728515625, "eval/reward_rate": 0.0, "replay/size": 135905.0, "replay/inserts": 19024.0, "replay/samples": 19024.0, "replay/insert_wait_avg": 1.348749342036909e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.104808488144806e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 33424.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2899558849400715e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.1995987892151, "timer/env.step_count": 2378.0, "timer/env.step_total": 5.509579181671143, "timer/env.step_frac": 0.011014761297305414, "timer/env.step_avg": 0.002316896207599303, "timer/env.step_min": 0.0011608600616455078, "timer/env.step_max": 0.012388229370117188, "timer/replay._sample_count": 19024.0, "timer/replay._sample_total": 1326.671421289444, "timer/replay._sample_frac": 2.6522840572059425, "timer/replay._sample_avg": 0.06973672315440728, "timer/replay._sample_min": 0.02485036849975586, "timer/replay._sample_max": 0.11500859260559082, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2956.0, "timer/agent.policy_total": 19.99598741531372, "timer/agent.policy_frac": 0.0399760165016447, "timer/agent.policy_avg": 0.006764542427372707, "timer/agent.policy_min": 0.005001068115234375, "timer/agent.policy_max": 0.01283717155456543, "timer/dataset_train_count": 1189.0, "timer/dataset_train_total": 0.10704326629638672, "timer/dataset_train_frac": 0.000214001103870327, "timer/dataset_train_avg": 9.002797838215872e-05, "timer/dataset_train_min": 7.653236389160156e-05, "timer/dataset_train_max": 0.00031304359436035156, "timer/agent.train_count": 1189.0, "timer/agent.train_total": 465.4440538883209, "timer/agent.train_frac": 0.9305166477841574, "timer/agent.train_avg": 0.39145841369917656, "timer/agent.train_min": 0.3568251132965088, "timer/agent.train_max": 0.4947042465209961, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5576822757720947, "timer/agent.report_frac": 0.0011149194783882722, "timer/agent.report_avg": 0.27884113788604736, "timer/agent.report_min": 0.23000478744506836, "timer/agent.report_max": 0.32767748832702637, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.695487976074219e-05, "timer/dataset_eval_frac": 7.388026669792478e-08, "timer/dataset_eval_avg": 3.695487976074219e-05, "timer/dataset_eval_min": 3.695487976074219e-05, "timer/dataset_eval_max": 3.695487976074219e-05, "fps": 38.0322504577758}
{"step": 137064, "episode/length": 288.0, "episode/score": 0.13478282586993373, "episode/reward_rate": 0.0}
{"step": 137424, "episode/length": 288.0, "episode/score": 0.14175474389890041, "episode/reward_rate": 0.0}
{"step": 137608, "episode/length": 288.0, "episode/score": 0.11245333129159008, "episode/reward_rate": 0.0}
{"step": 137648, "episode/length": 288.0, "episode/score": 0.13901325598340009, "episode/reward_rate": 0.0}
{"step": 138168, "episode/length": 288.0, "episode/score": 0.09727614690473274, "episode/reward_rate": 0.0}
{"step": 138296, "episode/length": 288.0, "episode/score": 0.11732184820607472, "episode/reward_rate": 0.0}
{"step": 138344, "episode/length": 288.0, "episode/score": 0.126005368452752, "episode/reward_rate": 0.0}
{"step": 138368, "episode/length": 288.0, "episode/score": 0.109516061959539, "episode/reward_rate": 0.0}
{"step": 139376, "episode/length": 288.0, "episode/score": 0.16929904871517465, "episode/reward_rate": 0.0}
{"step": 139736, "episode/length": 288.0, "episode/score": 0.15924127719699754, "episode/reward_rate": 0.0}
{"step": 139920, "episode/length": 288.0, "episode/score": 0.06988009136091478, "episode/reward_rate": 0.0}
{"step": 139960, "episode/length": 288.0, "episode/score": 0.12996704171871443, "episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140480, "episode/length": 288.0, "episode/score": 0.10123203090256538, "episode/reward_rate": 0.0}
{"step": 140608, "episode/length": 288.0, "episode/score": 0.07718089906086334, "episode/reward_rate": 0.0}
{"step": 140656, "episode/length": 288.0, "episode/score": 0.1321036982391206, "episode/reward_rate": 0.0}
{"step": 140680, "episode/length": 288.0, "episode/score": 0.10832083629202316, "episode/reward_rate": 0.0}
{"step": 141688, "episode/length": 288.0, "episode/score": 0.1019926344255282, "episode/reward_rate": 0.0}
{"step": 142048, "episode/length": 288.0, "episode/score": 0.16376855780447386, "episode/reward_rate": 0.0}
{"step": 142232, "episode/length": 288.0, "episode/score": 0.11210543929200867, "episode/reward_rate": 0.0}
{"step": 142272, "episode/length": 288.0, "episode/score": 0.08953631961992414, "episode/reward_rate": 0.0}
{"step": 142792, "episode/length": 288.0, "episode/score": 0.1433787725432012, "episode/reward_rate": 0.0}
{"step": 142920, "episode/length": 288.0, "episode/score": 0.12848126043388675, "episode/reward_rate": 0.0}
{"step": 142968, "episode/length": 288.0, "episode/score": 0.07973277484825303, "episode/reward_rate": 0.0}
{"step": 142992, "episode/length": 288.0, "episode/score": 0.08774341143328002, "episode/reward_rate": 0.0}
{"step": 144000, "episode/length": 288.0, "episode/score": 0.11917165704386434, "episode/reward_rate": 0.0}
{"step": 144136, "episode/length": 260.0, "episode/score": 0.2901550798585504, "episode/reward_rate": 0.0038314176245210726}
{"step": 144544, "episode/length": 288.0, "episode/score": 0.09216968518808244, "episode/reward_rate": 0.0}
{"step": 144584, "episode/length": 288.0, "episode/score": 0.11390057493071026, "episode/reward_rate": 0.0}
{"step": 145104, "episode/length": 288.0, "episode/score": 0.0872638443159417, "episode/reward_rate": 0.0}
{"step": 145232, "episode/length": 288.0, "episode/score": 0.08294830167545797, "episode/reward_rate": 0.0}
{"step": 145280, "episode/length": 288.0, "episode/score": 0.06551205972681373, "episode/reward_rate": 0.0}
{"step": 145304, "episode/length": 288.0, "episode/score": 0.1217865532797191, "episode/reward_rate": 0.0}
{"step": 146312, "episode/length": 288.0, "episode/score": 0.14495011250824064, "episode/reward_rate": 0.0}
{"step": 146448, "episode/length": 288.0, "episode/score": 0.08153286124820625, "episode/reward_rate": 0.0}
{"step": 146856, "episode/length": 288.0, "episode/score": 0.11728928103906355, "episode/reward_rate": 0.0}
{"step": 146896, "episode/length": 288.0, "episode/score": 0.09276717606866214, "episode/reward_rate": 0.0}
{"step": 147416, "episode/length": 288.0, "episode/score": 0.09712637606219232, "episode/reward_rate": 0.0}
{"step": 147544, "episode/length": 288.0, "episode/score": 0.09004106782316512, "episode/reward_rate": 0.0}
{"step": 147592, "episode/length": 288.0, "episode/score": 0.09278712204218209, "episode/reward_rate": 0.0}
{"step": 147616, "episode/length": 288.0, "episode/score": 0.1307810817071413, "episode/reward_rate": 0.0}
{"step": 148624, "episode/length": 288.0, "episode/score": 0.1104256394403933, "episode/reward_rate": 0.0}
{"step": 148760, "episode/length": 288.0, "episode/score": 0.09950705854441821, "episode/reward_rate": 0.0}
{"step": 149168, "episode/length": 288.0, "episode/score": 0.12094709003287107, "episode/reward_rate": 0.0}
{"step": 149168, "episode/length": 202.0, "episode/score": 0.4715868095878477, "episode/reward_rate": 0.0049261083743842365}
{"step": 149208, "episode/length": 288.0, "episode/score": 0.07498258963403259, "episode/reward_rate": 0.0}
{"step": 149440, "episode/length": 33.0, "episode/score": 0.9055209524785255, "episode/reward_rate": 0.029411764705882353}
{"step": 149728, "episode/length": 288.0, "episode/score": 0.09563630949264734, "episode/reward_rate": 0.0}
{"step": 149904, "episode/length": 288.0, "episode/score": 0.10397656320270698, "episode/reward_rate": 0.0}
{"step": 149928, "episode/length": 288.0, "episode/score": 0.1229831544510489, "episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150936, "episode/length": 288.0, "episode/score": 0.10611419337612915, "episode/reward_rate": 0.0}
{"step": 151072, "episode/length": 288.0, "episode/score": 0.11273118804729165, "episode/reward_rate": 0.0}
{"step": 151480, "episode/length": 288.0, "episode/score": 0.07926181399065513, "episode/reward_rate": 0.0}
{"step": 151520, "episode/length": 288.0, "episode/score": 0.11604270080260903, "episode/reward_rate": 0.0}
{"step": 151752, "episode/length": 288.0, "episode/score": 0.12604542811442343, "episode/reward_rate": 0.0}
{"step": 152040, "episode/length": 288.0, "episode/score": 0.11492902965284202, "episode/reward_rate": 0.0}
{"step": 152216, "episode/length": 288.0, "episode/score": 0.049437325319786396, "episode/reward_rate": 0.0}
{"step": 152240, "episode/length": 288.0, "episode/score": 0.07520656346414967, "episode/reward_rate": 0.0}
{"step": 153248, "episode/length": 288.0, "episode/score": 0.0918925143539866, "episode/reward_rate": 0.0}
{"step": 153384, "episode/length": 288.0, "episode/score": 0.0826138698047032, "episode/reward_rate": 0.0}
{"step": 153792, "episode/length": 288.0, "episode/score": 0.12453026110509313, "episode/reward_rate": 0.0}
{"step": 153832, "episode/length": 288.0, "episode/score": 0.08871421336380081, "episode/reward_rate": 0.0}
{"step": 154064, "episode/length": 288.0, "episode/score": 0.07807260734833221, "episode/reward_rate": 0.0}
{"step": 154352, "episode/length": 288.0, "episode/score": 0.08428064080243303, "episode/reward_rate": 0.0}
{"step": 154528, "episode/length": 288.0, "episode/score": 0.10168835145182697, "episode/reward_rate": 0.0}
{"step": 154552, "episode/length": 288.0, "episode/score": 0.07334524908958429, "episode/reward_rate": 0.0}
{"step": 155560, "episode/length": 288.0, "episode/score": 0.09880642703467402, "episode/reward_rate": 0.0}
{"step": 155696, "episode/length": 288.0, "episode/score": 0.056141805981553716, "episode/reward_rate": 0.0}
{"step": 155833, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9987963066726433, "train/action_min": 0.0, "train/action_std": 1.9998679512836894, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 7.014462312699684e-05, "train/actor_opt_grad_steps": 9035.0, "train/actor_opt_loss": -4.123756492602044, "train/adv_mag": 0.0003497427115674879, "train/adv_max": 0.0002838257150571854, "train/adv_mean": 8.233030041258301e-05, "train/adv_min": -0.00012726458858271114, "train/adv_std": 7.891380281665481e-05, "train/cont_avg": 0.9968381787909836, "train/cont_loss_mean": 0.021394211491646213, "train/cont_loss_std": 0.302196172108302, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.671332224821433, "train/cont_pos_acc": 0.9999999902287467, "train/cont_pos_loss": 0.0034783297374875086, "train/cont_pred": 0.9965278525821498, "train/cont_rate": 0.9968381787909836, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.02002392325657191, "train/extr_critic_critic_opt_grad_steps": 9035.0, "train/extr_critic_critic_opt_loss": 8255.465752273309, "train/extr_critic_mag": 0.14329062328963985, "train/extr_critic_max": 0.14329062328963985, "train/extr_critic_mean": 0.14320995756348626, "train/extr_critic_min": 0.14313397837466882, "train/extr_critic_std": 2.0147441184652978e-05, "train/extr_return_normed_mag": 0.0005078655285913436, "train/extr_return_normed_max": 0.0004123823075998025, "train/extr_return_normed_mean": 0.0002754803518598692, "train/extr_return_normed_min": 0.00011788308620452881, "train/extr_return_normed_std": 7.327691127918607e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.14342918100415683, "train/extr_return_raw_max": 0.14342918100415683, "train/extr_return_raw_mean": 0.14329228647908226, "train/extr_return_raw_min": 0.14313468178276156, "train/extr_return_raw_std": 7.327691225857022e-05, "train/extr_reward_mag": 0.00044331198833027824, "train/extr_reward_max": 0.00044331198833027824, "train/extr_reward_mean": 0.0004431344053448468, "train/extr_reward_min": 0.0004428664191824491, "train/extr_reward_std": 7.362115411564469e-08, "train/image_loss_mean": 0.2510958985715616, "train/image_loss_std": 0.08429081118131271, "train/model_loss_mean": 0.8910073227569705, "train/model_loss_std": 0.3518441851998939, "train/model_opt_grad_norm": 49.567622825747634, "train/model_opt_grad_steps": 9024.524590163934, "train/model_opt_loss": 2317.802978515625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2602.4590163934427, "train/policy_entropy_mag": 1.9458942471957597, "train/policy_entropy_max": 1.9458942471957597, "train/policy_entropy_mean": 1.9451058018402976, "train/policy_entropy_min": 1.9326060394771765, "train/policy_entropy_std": 0.0005689783014173879, "train/policy_logprob_mag": 2.1761325754103114, "train/policy_logprob_max": -1.7445189112522563, "train/policy_logprob_mean": -1.9450872687042737, "train/policy_logprob_min": -2.1761325754103114, "train/policy_logprob_std": 0.03999309620407761, "train/policy_randomness_mag": 0.999991887416996, "train/policy_randomness_max": 0.999991887416996, "train/policy_randomness_mean": 0.9995867013931274, "train/policy_randomness_min": 0.9931630971001797, "train/policy_randomness_std": 0.0002923970364538006, "train/post_ent_mag": 46.39574100932137, "train/post_ent_max": 46.39574100932137, "train/post_ent_mean": 46.37815819411981, "train/post_ent_min": 46.339840247982835, "train/post_ent_std": 0.009280531964890782, "train/prior_ent_mag": 40.813962217237126, "train/prior_ent_max": 40.813962217237126, "train/prior_ent_mean": 40.7848723364658, "train/prior_ent_min": 40.76762490194352, "train/prior_ent_std": 0.007204410476900148, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0004482340603421793, "train/reward_loss_mean": 0.01851719178137232, "train/reward_loss_std": 0.0671124970845756, "train/reward_max_data": 0.06902322400223891, "train/reward_max_pred": 0.00044326899481601404, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.017184566599545908, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.779595676221346, "train/reward_pred": 0.00044300027008427947, "train/reward_rate": 0.0001520876024590164, "train_stats/mean_log_entropy": 1.9374820527745718, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.0367172509431839, "report/cont_loss_std": 0.4343793988227844, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.6947760581970215, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003369161393493414, "report/cont_pred": 0.9966364502906799, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2541162371635437, "report/image_loss_std": 0.08233655244112015, "report/model_loss_mean": 0.9211399555206299, "report/model_loss_std": 0.6639114022254944, "report/post_ent_mag": 47.560340881347656, "report/post_ent_max": 47.560340881347656, "report/post_ent_mean": 47.51814270019531, "report/post_ent_min": 47.47735595703125, "report/post_ent_std": 0.012877637520432472, "report/prior_ent_mag": 40.88828659057617, "report/prior_ent_max": 40.88828659057617, "report/prior_ent_mean": 40.85195541381836, "report/prior_ent_min": 40.828948974609375, "report/prior_ent_std": 0.008843490853905678, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.001178569276817143, "report/reward_loss_mean": 0.030306439846754074, "report/reward_loss_std": 0.3393414318561554, "report/reward_max_data": 0.7462499737739563, "report/reward_max_pred": 0.00045228004455566406, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.019739627838134766, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 10.840154647827148, "report/reward_pred": 0.00045228004455566406, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.008927175775170326, "eval/cont_loss_std": 0.17776957154273987, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.694775581359863, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003369161393493414, "eval/cont_pred": 0.9966364502906799, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2498261034488678, "eval/image_loss_std": 0.09283085912466049, "eval/model_loss_mean": 0.8614379167556763, "eval/model_loss_std": 0.19977976381778717, "eval/post_ent_mag": 47.55827331542969, "eval/post_ent_max": 47.55827331542969, "eval/post_ent_mean": 47.52081298828125, "eval/post_ent_min": 47.47748947143555, "eval/post_ent_std": 0.012963083572685719, "eval/prior_ent_mag": 40.898353576660156, "eval/prior_ent_max": 40.898353576660156, "eval/prior_ent_mean": 40.85236740112305, "eval/prior_ent_min": 40.8299446105957, "eval/prior_ent_std": 0.009462130255997181, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0026845932006835938, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00045228004455566406, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0026845932006835938, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00045228004455566406, "eval/reward_rate": 0.0, "replay/size": 155329.0, "replay/inserts": 19424.0, "replay/samples": 19424.0, "replay/insert_wait_avg": 1.3572208374689596e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.012751585569178e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38048.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.252728762511151e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 499.99147844314575, "timer/env.step_count": 2428.0, "timer/env.step_total": 5.434455633163452, "timer/env.step_frac": 0.010869096509574626, "timer/env.step_avg": 0.0022382436709898895, "timer/env.step_min": 0.001157999038696289, "timer/env.step_max": 0.016406774520874023, "timer/replay._sample_count": 19424.0, "timer/replay._sample_total": 1351.2988350391388, "timer/replay._sample_frac": 2.702643731542708, "timer/replay._sample_avg": 0.0695685149834812, "timer/replay._sample_min": 0.00044846534729003906, "timer/replay._sample_max": 0.1045541763305664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3006.0, "timer/agent.policy_total": 20.110631227493286, "timer/agent.policy_frac": 0.04022194796221927, "timer/agent.policy_avg": 0.006690163415666429, "timer/agent.policy_min": 0.0048923492431640625, "timer/agent.policy_max": 0.011220455169677734, "timer/dataset_train_count": 1214.0, "timer/dataset_train_total": 0.1073157787322998, "timer/dataset_train_frac": 0.0002146352155169835, "timer/dataset_train_avg": 8.839849977948913e-05, "timer/dataset_train_min": 6.222724914550781e-05, "timer/dataset_train_max": 0.00029015541076660156, "timer/agent.train_count": 1214.0, "timer/agent.train_total": 466.04515957832336, "timer/agent.train_frac": 0.9321062051486895, "timer/agent.train_avg": 0.38389222370537346, "timer/agent.train_min": 0.3482792377471924, "timer/agent.train_max": 0.9621317386627197, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.41446995735168457, "timer/agent.report_frac": 0.0008289540426613774, "timer/agent.report_avg": 0.20723497867584229, "timer/agent.report_min": 0.19904303550720215, "timer/agent.report_max": 0.21542692184448242, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.124641418457031e-05, "timer/dataset_eval_frac": 8.249423432775657e-08, "timer/dataset_eval_avg": 4.124641418457031e-05, "timer/dataset_eval_min": 4.124641418457031e-05, "timer/dataset_eval_max": 4.124641418457031e-05, "fps": 38.8482229396644}
{"step": 156104, "episode/length": 288.0, "episode/score": 0.08335423544821197, "episode/reward_rate": 0.0}
{"step": 156144, "episode/length": 288.0, "episode/score": 0.0924449765795714, "episode/reward_rate": 0.0}
{"step": 156376, "episode/length": 288.0, "episode/score": 0.10090122600621498, "episode/reward_rate": 0.0}
{"step": 156560, "episode/length": 51.0, "episode/score": 0.8778629317193918, "episode/reward_rate": 0.019230769230769232}
{"step": 156664, "episode/length": 288.0, "episode/score": 0.11187875861074303, "episode/reward_rate": 0.0}
{"step": 156840, "episode/length": 288.0, "episode/score": 0.13083948969398307, "episode/reward_rate": 0.0}
{"step": 156864, "episode/length": 288.0, "episode/score": 0.10506640636080533, "episode/reward_rate": 0.0}
{"step": 157872, "episode/length": 288.0, "episode/score": 0.12613621314821444, "episode/reward_rate": 0.0}
{"step": 158008, "episode/length": 288.0, "episode/score": 0.11258763665787797, "episode/reward_rate": 0.0}
{"step": 158416, "episode/length": 288.0, "episode/score": 0.12566798859916162, "episode/reward_rate": 0.0}
{"step": 158688, "episode/length": 288.0, "episode/score": 0.12957920866665518, "episode/reward_rate": 0.0}
{"step": 158872, "episode/length": 288.0, "episode/score": 0.12436644905960748, "episode/reward_rate": 0.0}
{"step": 158976, "episode/length": 288.0, "episode/score": 0.15829212945436666, "episode/reward_rate": 0.0}
{"step": 159152, "episode/length": 288.0, "episode/score": 0.12886672272429678, "episode/reward_rate": 0.0}
{"step": 159176, "episode/length": 288.0, "episode/score": 0.12506141788321656, "episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160184, "episode/length": 288.0, "episode/score": 0.07616439787057061, "episode/reward_rate": 0.0}
{"step": 160320, "episode/length": 288.0, "episode/score": 0.10951469612325582, "episode/reward_rate": 0.0}
{"step": 160728, "episode/length": 288.0, "episode/score": 0.09332198845891071, "episode/reward_rate": 0.0}
{"step": 161000, "episode/length": 288.0, "episode/score": 0.10441704229447168, "episode/reward_rate": 0.0}
{"step": 161184, "episode/length": 288.0, "episode/score": 0.12242848108462567, "episode/reward_rate": 0.0}
{"step": 161288, "episode/length": 288.0, "episode/score": 0.10256446987136769, "episode/reward_rate": 0.0}
{"step": 161464, "episode/length": 288.0, "episode/score": 0.13752977786839438, "episode/reward_rate": 0.0}
{"step": 161488, "episode/length": 288.0, "episode/score": 0.09518056187721413, "episode/reward_rate": 0.0}
{"step": 162496, "episode/length": 288.0, "episode/score": 0.16945433958323974, "episode/reward_rate": 0.0}
{"step": 162632, "episode/length": 288.0, "episode/score": 0.15221589201962615, "episode/reward_rate": 0.0}
{"step": 163040, "episode/length": 288.0, "episode/score": 0.14860804077636658, "episode/reward_rate": 0.0}
{"step": 163312, "episode/length": 288.0, "episode/score": 0.2218317388945934, "episode/reward_rate": 0.0}
{"step": 163496, "episode/length": 288.0, "episode/score": 0.17095030484085783, "episode/reward_rate": 0.0}
{"step": 163600, "episode/length": 288.0, "episode/score": 0.1696161529434903, "episode/reward_rate": 0.0}
{"step": 163776, "episode/length": 288.0, "episode/score": 0.1720345921307853, "episode/reward_rate": 0.0}
{"step": 163800, "episode/length": 288.0, "episode/score": 0.1717074614948615, "episode/reward_rate": 0.0}
{"step": 164808, "episode/length": 288.0, "episode/score": 0.10151705807629696, "episode/reward_rate": 0.0}
{"step": 164944, "episode/length": 288.0, "episode/score": 0.11140101504111044, "episode/reward_rate": 0.0}
{"step": 165352, "episode/length": 288.0, "episode/score": 0.11997630002792903, "episode/reward_rate": 0.0}
{"step": 165624, "episode/length": 288.0, "episode/score": 0.11915223771575256, "episode/reward_rate": 0.0}
{"step": 165808, "episode/length": 288.0, "episode/score": 0.13845947025151872, "episode/reward_rate": 0.0}
{"step": 165912, "episode/length": 288.0, "episode/score": 0.1294377471936059, "episode/reward_rate": 0.0}
{"step": 166088, "episode/length": 288.0, "episode/score": 0.15705161068785856, "episode/reward_rate": 0.0}
{"step": 166112, "episode/length": 288.0, "episode/score": 0.1702862166664545, "episode/reward_rate": 0.0}
{"step": 167120, "episode/length": 288.0, "episode/score": 0.06696356953909799, "episode/reward_rate": 0.0}
{"step": 167256, "episode/length": 288.0, "episode/score": 0.12443807717147592, "episode/reward_rate": 0.0}
{"step": 167664, "episode/length": 288.0, "episode/score": 0.13959632179489745, "episode/reward_rate": 0.0}
{"step": 167936, "episode/length": 288.0, "episode/score": 0.15563791418696837, "episode/reward_rate": 0.0}
{"step": 168120, "episode/length": 288.0, "episode/score": 0.11683989927780658, "episode/reward_rate": 0.0}
{"step": 168224, "episode/length": 288.0, "episode/score": 0.12499207726284567, "episode/reward_rate": 0.0}
{"step": 168400, "episode/length": 288.0, "episode/score": 0.1467092918948083, "episode/reward_rate": 0.0}
{"step": 168424, "episode/length": 288.0, "episode/score": 0.07356871229546869, "episode/reward_rate": 0.0}
{"step": 169432, "episode/length": 288.0, "episode/score": 0.15419540339928517, "episode/reward_rate": 0.0}
{"step": 169568, "episode/length": 288.0, "episode/score": 0.14076260502895366, "episode/reward_rate": 0.0}
{"step": 169976, "episode/length": 288.0, "episode/score": 0.1242008605125875, "episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170248, "episode/length": 288.0, "episode/score": 0.08217393408290263, "episode/reward_rate": 0.0}
{"step": 170432, "episode/length": 288.0, "episode/score": 0.13277092830321635, "episode/reward_rate": 0.0}
{"step": 170536, "episode/length": 288.0, "episode/score": 0.14286711450245093, "episode/reward_rate": 0.0}
{"step": 170712, "episode/length": 288.0, "episode/score": 0.09323337935029485, "episode/reward_rate": 0.0}
{"step": 170736, "episode/length": 288.0, "episode/score": 0.09884800849113162, "episode/reward_rate": 0.0}
{"step": 170880, "episode/length": 112.0, "episode/score": 0.7179406646919233, "episode/reward_rate": 0.008849557522123894}
{"step": 171744, "episode/length": 288.0, "episode/score": 0.12140157858539169, "episode/reward_rate": 0.0}
{"step": 171880, "episode/length": 288.0, "episode/score": 0.12012011443698611, "episode/reward_rate": 0.0}
{"step": 172560, "episode/length": 288.0, "episode/score": 0.09559617039394652, "episode/reward_rate": 0.0}
{"step": 172744, "episode/length": 288.0, "episode/score": 0.11542578611749832, "episode/reward_rate": 0.0}
{"step": 172848, "episode/length": 288.0, "episode/score": 0.12053382586771022, "episode/reward_rate": 0.0}
{"step": 173024, "episode/length": 288.0, "episode/score": 0.1460318999490937, "episode/reward_rate": 0.0}
{"step": 173048, "episode/length": 288.0, "episode/score": 0.1357788491076235, "episode/reward_rate": 0.0}
{"step": 173112, "episode/length": 45.0, "episode/score": 0.8989363768301928, "episode/reward_rate": 0.021739130434782608}
{"step": 173192, "episode/length": 288.0, "episode/score": 0.12623128270911366, "episode/reward_rate": 0.0}
{"step": 174056, "episode/length": 288.0, "episode/score": 0.09691346766874176, "episode/reward_rate": 0.0}
{"step": 174192, "episode/length": 288.0, "episode/score": 0.1492526467245625, "episode/reward_rate": 0.0}
{"step": 174872, "episode/length": 288.0, "episode/score": 0.09384506552623861, "episode/reward_rate": 0.0}
{"step": 175160, "episode/length": 288.0, "episode/score": 0.13391391356651638, "episode/reward_rate": 0.0}
{"step": 175241, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9907867179429237, "train/action_min": 0.0, "train/action_std": 2.0070620637294674, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00012807560233341064, "train/actor_opt_grad_steps": 10250.0, "train/actor_opt_loss": -4.490897779283691, "train/adv_mag": 0.000454208698154481, "train/adv_max": 0.0003832657475116824, "train/adv_mean": 6.282789793805166e-05, "train/adv_min": -0.0002521113915876909, "train/adv_std": 9.638896952776483e-05, "train/cont_avg": 0.9963842975206612, "train/cont_loss_mean": 0.024006688538246043, "train/cont_loss_std": 0.32987198025211384, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.664371903203115, "train/cont_pos_acc": 0.9999999842367882, "train/cont_pos_loss": 0.003500451957268163, "train/cont_pred": 0.9965057850869234, "train/cont_rate": 0.9963842975206612, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.013321273597457623, "train/extr_critic_critic_opt_grad_steps": 10250.0, "train/extr_critic_critic_opt_loss": 7962.1260693762915, "train/extr_critic_mag": 0.1448377331426321, "train/extr_critic_max": 0.1448377331426321, "train/extr_critic_mean": 0.14472412336463772, "train/extr_critic_min": 0.1445002506587131, "train/extr_critic_std": 4.8401744379780064e-05, "train/extr_return_normed_mag": 0.0005358750662527794, "train/extr_return_normed_max": 0.0004227383077637223, "train/extr_return_normed_mean": 0.00024151328968366952, "train/extr_return_normed_min": -3.31536058552009e-05, "train/extr_return_normed_std": 8.475088097012221e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.14496816805571563, "train/extr_return_raw_max": 0.14496816805571563, "train/extr_return_raw_mean": 0.1447869496158332, "train/extr_return_raw_min": 0.14451227614209672, "train/extr_return_raw_std": 8.475088196981473e-05, "train/extr_reward_mag": 0.00044473340688658156, "train/extr_reward_max": 0.00044473340688658156, "train/extr_reward_mean": 0.00044447787092567596, "train/extr_reward_min": 0.0004442930221557617, "train/extr_reward_std": 1.2061124386467e-07, "train/image_loss_mean": 0.24516625135890707, "train/image_loss_std": 0.08459134849388737, "train/model_loss_mean": 0.8872187305087885, "train/model_loss_std": 0.36334104466536815, "train/model_opt_grad_norm": 46.50903569371247, "train/model_opt_grad_steps": 10238.446280991735, "train/model_opt_loss": 2438.627957935176, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2747.9338842975208, "train/policy_entropy_mag": 1.945859705121064, "train/policy_entropy_max": 1.945859705121064, "train/policy_entropy_mean": 1.9432183267656438, "train/policy_entropy_min": 1.9203418631198979, "train/policy_entropy_std": 0.0019554134438099138, "train/policy_logprob_mag": 2.2808822797349664, "train/policy_logprob_max": -1.6384608055934433, "train/policy_logprob_mean": -1.943177501032175, "train/policy_logprob_min": -2.2808822797349664, "train/policy_logprob_std": 0.06810254742168198, "train/policy_randomness_mag": 0.9999741355249704, "train/policy_randomness_max": 0.9999741355249704, "train/policy_randomness_mean": 0.998616738260285, "train/policy_randomness_min": 0.9868605585137674, "train/policy_randomness_std": 0.0010048837888281608, "train/post_ent_mag": 46.1586381581204, "train/post_ent_max": 46.1586381581204, "train/post_ent_mean": 46.10451072503712, "train/post_ent_min": 46.05326515386913, "train/post_ent_std": 0.01913922231582817, "train/prior_ent_mag": 42.925721570479965, "train/prior_ent_max": 42.925721570479965, "train/prior_ent_mean": 42.41244352356461, "train/prior_ent_min": 42.277860562663435, "train/prior_ent_std": 0.10072176707215792, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00042450186110501876, "train/reward_loss_mean": 0.018045769257794234, "train/reward_loss_std": 0.052814104663562185, "train/reward_max_data": 0.043976927737990196, "train/reward_max_pred": 0.0004448723201909341, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.01721517125929683, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.37327766418457, "train/reward_pred": 0.0004445888892909096, "train/reward_rate": 8.87784090909091e-05, "train_stats/mean_log_entropy": 1.935776720876279, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014804217033088207, "report/cont_loss_std": 0.2431754320859909, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.51185941696167, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004046768415719271, "report/cont_pred": 0.9959612488746643, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2367052137851715, "report/image_loss_std": 0.0929311215877533, "report/model_loss_mean": 0.8797270059585571, "report/model_loss_std": 0.5422170162200928, "report/post_ent_mag": 46.32962417602539, "report/post_ent_max": 46.32962417602539, "report/post_ent_mean": 46.19877624511719, "report/post_ent_min": 46.05814743041992, "report/post_ent_std": 0.05740911141037941, "report/prior_ent_mag": 44.58554458618164, "report/prior_ent_max": 44.58554458618164, "report/prior_ent_mean": 43.530235290527344, "report/prior_ent_min": 43.118492126464844, "report/prior_ent_std": 0.2884570360183716, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.001244913088157773, "report/reward_loss_mean": 0.028217589482665062, "report/reward_loss_std": 0.3287859559059143, "report/reward_max_data": 0.8618749976158142, "report/reward_max_pred": 0.00043761730194091797, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01798061840236187, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 10.500636100769043, "report/reward_pred": 0.00043761730194091797, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.009425493888556957, "eval/cont_loss_std": 0.1720350682735443, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.51185941696167, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004046768415719271, "eval/cont_pred": 0.9959612488746643, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2371053844690323, "eval/image_loss_std": 0.08942829817533493, "eval/model_loss_mean": 0.8490724563598633, "eval/model_loss_std": 0.19302286207675934, "eval/post_ent_mag": 46.33002853393555, "eval/post_ent_max": 46.33002853393555, "eval/post_ent_mean": 46.1946907043457, "eval/post_ent_min": 46.05305862426758, "eval/post_ent_std": 0.05785957723855972, "eval/prior_ent_mag": 44.8073844909668, "eval/prior_ent_max": 44.8073844909668, "eval/prior_ent_mean": 43.593597412109375, "eval/prior_ent_min": 43.11640167236328, "eval/prior_ent_std": 0.3320848047733307, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0025415420532226562, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00043761730194091797, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0025415420532226562, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00043761730194091797, "eval/reward_rate": 0.0, "replay/size": 174737.0, "replay/inserts": 19408.0, "replay/samples": 19408.0, "replay/insert_wait_avg": 1.378768942912354e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.045558927870937e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 42672.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3682256520413197e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 2.562999725341797e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.2183358669281, "timer/env.step_count": 2426.0, "timer/env.step_total": 5.696815729141235, "timer/env.step_frac": 0.011388658353093129, "timer/env.step_avg": 0.002348234018607269, "timer/env.step_min": 0.001168966293334961, "timer/env.step_max": 0.017206907272338867, "timer/replay._sample_count": 19408.0, "timer/replay._sample_total": 1354.6450185775757, "timer/replay._sample_frac": 2.708107483165009, "timer/replay._sample_avg": 0.06979828001739363, "timer/replay._sample_min": 0.0003046989440917969, "timer/replay._sample_max": 0.1305832862854004, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3004.0, "timer/agent.policy_total": 20.33776617050171, "timer/agent.policy_frac": 0.04065777823848528, "timer/agent.policy_avg": 0.006770228418941981, "timer/agent.policy_min": 0.0049800872802734375, "timer/agent.policy_max": 0.015020132064819336, "timer/dataset_train_count": 1213.0, "timer/dataset_train_total": 0.11023378372192383, "timer/dataset_train_frac": 0.00022037133750980504, "timer/dataset_train_avg": 9.087698575591413e-05, "timer/dataset_train_min": 7.581710815429688e-05, "timer/dataset_train_max": 0.0003788471221923828, "timer/agent.train_count": 1213.0, "timer/agent.train_total": 465.55377292633057, "timer/agent.train_frac": 0.9307011349743499, "timer/agent.train_avg": 0.38380360505056105, "timer/agent.train_min": 0.3481144905090332, "timer/agent.train_max": 0.4667043685913086, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47513437271118164, "timer/agent.report_frac": 0.0009498539710419182, "timer/agent.report_avg": 0.23756718635559082, "timer/agent.report_min": 0.234297513961792, "timer/agent.report_max": 0.24083685874938965, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.581710815429688e-05, "timer/dataset_eval_frac": 1.515680308337724e-07, "timer/dataset_eval_avg": 7.581710815429688e-05, "timer/dataset_eval_min": 7.581710815429688e-05, "timer/dataset_eval_max": 7.581710815429688e-05, "fps": 38.79789457363617}
{"step": 175336, "episode/length": 288.0, "episode/score": 0.15989218410300055, "episode/reward_rate": 0.0}
{"step": 175360, "episode/length": 288.0, "episode/score": 0.14062478154619384, "episode/reward_rate": 0.0}
{"step": 175424, "episode/length": 288.0, "episode/score": 0.10079986169341737, "episode/reward_rate": 0.0}
{"step": 175504, "episode/length": 288.0, "episode/score": 0.1267146178023495, "episode/reward_rate": 0.0}
{"step": 176368, "episode/length": 288.0, "episode/score": 0.12687295408773025, "episode/reward_rate": 0.0}
{"step": 176504, "episode/length": 288.0, "episode/score": 0.1358349005877244, "episode/reward_rate": 0.0}
{"step": 177184, "episode/length": 288.0, "episode/score": 0.1854335745622393, "episode/reward_rate": 0.0}
{"step": 177472, "episode/length": 288.0, "episode/score": 0.14309164958353904, "episode/reward_rate": 0.0}
{"step": 177648, "episode/length": 288.0, "episode/score": 0.11434202527129855, "episode/reward_rate": 0.0}
{"step": 177672, "episode/length": 288.0, "episode/score": 0.18253035859765987, "episode/reward_rate": 0.0}
{"step": 177736, "episode/length": 288.0, "episode/score": 0.06823945008500232, "episode/reward_rate": 0.0}
{"step": 177816, "episode/length": 288.0, "episode/score": 0.09103919379253966, "episode/reward_rate": 0.0}
{"step": 178680, "episode/length": 288.0, "episode/score": 0.08810033061126887, "episode/reward_rate": 0.0}
{"step": 178816, "episode/length": 288.0, "episode/score": 0.13107644665103635, "episode/reward_rate": 0.0}
{"step": 179496, "episode/length": 288.0, "episode/score": 0.13169168357785566, "episode/reward_rate": 0.0}
{"step": 179784, "episode/length": 288.0, "episode/score": 0.06780398054468151, "episode/reward_rate": 0.0}
{"step": 179960, "episode/length": 288.0, "episode/score": 0.10912978335147727, "episode/reward_rate": 0.0}
{"step": 179984, "episode/length": 288.0, "episode/score": 0.11908108483669366, "episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180048, "episode/length": 288.0, "episode/score": 0.12722147295323794, "episode/reward_rate": 0.0}
{"step": 180128, "episode/length": 288.0, "episode/score": 0.08908099639825195, "episode/reward_rate": 0.0}
{"step": 180992, "episode/length": 288.0, "episode/score": 0.06213658066997141, "episode/reward_rate": 0.0}
{"step": 181128, "episode/length": 288.0, "episode/score": 0.0660354736331783, "episode/reward_rate": 0.0}
{"step": 181808, "episode/length": 288.0, "episode/score": 0.15535800243765152, "episode/reward_rate": 0.0}
{"step": 182096, "episode/length": 288.0, "episode/score": 0.13979018351631112, "episode/reward_rate": 0.0}
{"step": 182272, "episode/length": 288.0, "episode/score": 0.13944390988649502, "episode/reward_rate": 0.0}
{"step": 182296, "episode/length": 288.0, "episode/score": 0.09738419032760248, "episode/reward_rate": 0.0}
{"step": 182360, "episode/length": 288.0, "episode/score": 0.10362759740041838, "episode/reward_rate": 0.0}
{"step": 182440, "episode/length": 288.0, "episode/score": 0.13372552867508603, "episode/reward_rate": 0.0}
{"step": 183304, "episode/length": 288.0, "episode/score": 0.09735430112016275, "episode/reward_rate": 0.0}
{"step": 183440, "episode/length": 288.0, "episode/score": 0.07651970553979481, "episode/reward_rate": 0.0}
{"step": 184120, "episode/length": 288.0, "episode/score": 0.06953994364829441, "episode/reward_rate": 0.0}
{"step": 184408, "episode/length": 288.0, "episode/score": 0.10708073103950255, "episode/reward_rate": 0.0}
{"step": 184584, "episode/length": 288.0, "episode/score": 0.07871755925987145, "episode/reward_rate": 0.0}
{"step": 184608, "episode/length": 288.0, "episode/score": 0.13642496191357623, "episode/reward_rate": 0.0}
{"step": 184672, "episode/length": 288.0, "episode/score": 0.12548340188357088, "episode/reward_rate": 0.0}
{"step": 184752, "episode/length": 288.0, "episode/score": 0.12722779569241993, "episode/reward_rate": 0.0}
{"step": 185616, "episode/length": 288.0, "episode/score": 0.09546127274904848, "episode/reward_rate": 0.0}
{"step": 185752, "episode/length": 288.0, "episode/score": 0.1229654820949122, "episode/reward_rate": 0.0}
{"step": 186432, "episode/length": 288.0, "episode/score": 0.09323814431883193, "episode/reward_rate": 0.0}
{"step": 186720, "episode/length": 288.0, "episode/score": 0.11562861966200444, "episode/reward_rate": 0.0}
{"step": 186896, "episode/length": 288.0, "episode/score": 0.1259286575364058, "episode/reward_rate": 0.0}
{"step": 186920, "episode/length": 288.0, "episode/score": 0.15571600856139867, "episode/reward_rate": 0.0}
{"step": 186984, "episode/length": 288.0, "episode/score": 0.09592250573120964, "episode/reward_rate": 0.0}
{"step": 187064, "episode/length": 288.0, "episode/score": 0.0975364919353865, "episode/reward_rate": 0.0}
{"step": 187928, "episode/length": 288.0, "episode/score": 0.071294166516509, "episode/reward_rate": 0.0}
{"step": 188064, "episode/length": 288.0, "episode/score": 0.07694313930159069, "episode/reward_rate": 0.0}
{"step": 188664, "episode/length": 278.0, "episode/score": 0.23117930758695593, "episode/reward_rate": 0.0035842293906810036}
{"step": 189032, "episode/length": 288.0, "episode/score": 0.07801408524335329, "episode/reward_rate": 0.0}
{"step": 189208, "episode/length": 288.0, "episode/score": 0.1270267981171287, "episode/reward_rate": 0.0}
{"step": 189232, "episode/length": 288.0, "episode/score": 0.1418292260736962, "episode/reward_rate": 0.0}
{"step": 189296, "episode/length": 288.0, "episode/score": 0.16127218797453224, "episode/reward_rate": 0.0}
{"step": 189376, "episode/length": 288.0, "episode/score": 0.0583786786655196, "episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190240, "episode/length": 288.0, "episode/score": 0.11363706406211804, "episode/reward_rate": 0.0}
{"step": 190376, "episode/length": 288.0, "episode/score": 0.08964522816904719, "episode/reward_rate": 0.0}
{"step": 190976, "episode/length": 288.0, "episode/score": 0.1418737310974052, "episode/reward_rate": 0.0}
{"step": 191344, "episode/length": 288.0, "episode/score": 0.11767222569096703, "episode/reward_rate": 0.0}
{"step": 191520, "episode/length": 288.0, "episode/score": 0.16169174077239745, "episode/reward_rate": 0.0}
{"step": 191544, "episode/length": 288.0, "episode/score": 0.12828418433085176, "episode/reward_rate": 0.0}
{"step": 191608, "episode/length": 288.0, "episode/score": 0.15910176894146844, "episode/reward_rate": 0.0}
{"step": 191688, "episode/length": 288.0, "episode/score": 0.13488233017565676, "episode/reward_rate": 0.0}
{"step": 192552, "episode/length": 288.0, "episode/score": 0.15412757678052458, "episode/reward_rate": 0.0}
{"step": 192688, "episode/length": 288.0, "episode/score": 0.13193484619620222, "episode/reward_rate": 0.0}
{"step": 193288, "episode/length": 288.0, "episode/score": 0.09627584986174043, "episode/reward_rate": 0.0}
{"step": 193656, "episode/length": 288.0, "episode/score": 0.1671415314094702, "episode/reward_rate": 0.0}
{"step": 193832, "episode/length": 288.0, "episode/score": 0.10937782915766547, "episode/reward_rate": 0.0}
{"step": 193856, "episode/length": 288.0, "episode/score": 0.09092805233535728, "episode/reward_rate": 0.0}
{"step": 193920, "episode/length": 288.0, "episode/score": 0.09487388028128407, "episode/reward_rate": 0.0}
{"step": 194000, "episode/length": 288.0, "episode/score": 0.09443475908847176, "episode/reward_rate": 0.0}
{"step": 194489, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0212086995442706, "train/action_min": 0.0, "train/action_std": 2.0140117128690083, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00019123726106045068, "train/actor_opt_grad_steps": 11455.0, "train/actor_opt_loss": -4.791643012392645, "train/adv_mag": 0.001187344640493393, "train/adv_max": 0.0011479617406924567, "train/adv_mean": 4.62650517780124e-05, "train/adv_min": -0.0007308376332124074, "train/adv_std": 0.00016372720880705554, "train/cont_avg": 0.9963623046875, "train/cont_loss_mean": 0.024095815854767957, "train/cont_loss_std": 0.3312439420609735, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.668347875611121, "train/cont_pos_acc": 0.9999999831120173, "train/cont_pos_loss": 0.0034946696968593946, "train/cont_pred": 0.9965115338563919, "train/cont_rate": 0.9963623046875, "train/dyn_loss_mean": 1.0000004857778548, "train/dyn_loss_std": 1.2739851081278175e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.010909739635341491, "train/extr_critic_critic_opt_grad_steps": 11455.0, "train/extr_critic_critic_opt_loss": 7775.665478515625, "train/extr_critic_mag": 0.14599672555923462, "train/extr_critic_max": 0.14599672555923462, "train/extr_critic_mean": 0.14567602798342705, "train/extr_critic_min": 0.14443649252255758, "train/extr_critic_std": 0.00015464569654189593, "train/extr_return_normed_mag": 0.0009394250810146332, "train/extr_return_normed_max": 0.0007066026329994202, "train/extr_return_normed_mean": 0.00034286931800882786, "train/extr_return_normed_min": -0.0005652389178673426, "train/extr_return_normed_std": 0.0001601800267356642, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.14608601642151672, "train/extr_return_raw_max": 0.14608601642151672, "train/extr_return_raw_mean": 0.14572229099770387, "train/extr_return_raw_min": 0.14481417487065, "train/extr_return_raw_std": 0.00016018002722072803, "train/extr_reward_mag": 0.00044650137424468995, "train/extr_reward_max": 0.00044650137424468995, "train/extr_reward_mean": 0.0004457438350073062, "train/extr_reward_min": 0.00044527649879455566, "train/extr_reward_std": 2.7722469153242576e-07, "train/image_loss_mean": 0.21478548347949983, "train/image_loss_std": 0.09275561602165301, "train/model_loss_mean": 0.8568880225221316, "train/model_loss_std": 0.374324411402146, "train/model_opt_grad_norm": 43.3610599676768, "train/model_opt_grad_steps": 11442.341666666667, "train/model_opt_loss": 2285.3436279296875, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2666.6666666666665, "train/policy_entropy_mag": 1.9456190645694733, "train/policy_entropy_max": 1.9456190645694733, "train/policy_entropy_mean": 1.9291308065255484, "train/policy_entropy_min": 1.7727196345726648, "train/policy_entropy_std": 0.012669958694217106, "train/policy_logprob_mag": 2.8681009709835052, "train/policy_logprob_max": -1.1064740379651388, "train/policy_logprob_mean": -1.9291783144076666, "train/policy_logprob_min": -2.8681009709835052, "train/policy_logprob_std": 0.18146289077897867, "train/policy_randomness_mag": 0.9998504708210627, "train/policy_randomness_max": 0.9998504708210627, "train/policy_randomness_mean": 0.9913771758476894, "train/policy_randomness_min": 0.9109977349638939, "train/policy_randomness_std": 0.0065110711652475095, "train/post_ent_mag": 50.28830633163452, "train/post_ent_max": 50.28830633163452, "train/post_ent_mean": 49.866080888112386, "train/post_ent_min": 49.57172346115112, "train/post_ent_std": 0.149744681827724, "train/prior_ent_mag": 47.97530450820923, "train/prior_ent_max": 47.97530450820923, "train/prior_ent_mean": 44.996973260243735, "train/prior_ent_min": 43.76157290140788, "train/prior_ent_std": 0.7004279926419258, "train/rep_loss_mean": 1.0000004857778548, "train/rep_loss_std": 1.2739851081278175e-05, "train/reward_avg": 0.0004353886562360761, "train/reward_loss_mean": 0.018006405568060775, "train/reward_loss_std": 0.061708886207391817, "train/reward_max_data": 0.06462118001654744, "train/reward_max_pred": 0.0004465570052464803, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.01685216830422481, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.881585717201233, "train/reward_pred": 0.0004461277935964366, "train/reward_rate": 0.00013020833333333333, "train_stats/mean_log_entropy": 1.9211719597087187, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.031125761568546295, "report/cont_loss_std": 0.39520224928855896, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.672975063323975, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0034424932673573494, "report/cont_pred": 0.9965635538101196, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.18846309185028076, "report/image_loss_std": 0.0875823125243187, "report/model_loss_mean": 0.8348137140274048, "report/model_loss_std": 0.40855348110198975, "report/post_ent_mag": 48.16855239868164, "report/post_ent_max": 48.16855239868164, "report/post_ent_mean": 47.74648666381836, "report/post_ent_min": 47.393280029296875, "report/post_ent_std": 0.1585230976343155, "report/prior_ent_mag": 47.976806640625, "report/prior_ent_max": 47.976806640625, "report/prior_ent_mean": 45.67070007324219, "report/prior_ent_min": 43.30238342285156, "report/prior_ent_std": 0.8192727565765381, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0003307228325866163, "report/reward_loss_mean": 0.015224832110106945, "report/reward_loss_std": 0.026305651292204857, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.0007584095001220703, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01522483304142952, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0005234361160546541, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.025589941069483757, "eval/cont_loss_std": 0.35367730259895325, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.673364162445068, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0034418022260069847, "eval/cont_pred": 0.9965641498565674, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20230978727340698, "eval/image_loss_std": 0.09777799248695374, "eval/model_loss_mean": 0.8309513330459595, "eval/model_loss_std": 0.3642013669013977, "eval/post_ent_mag": 48.17517852783203, "eval/post_ent_max": 48.17517852783203, "eval/post_ent_mean": 47.73594665527344, "eval/post_ent_min": 47.35646057128906, "eval/post_ent_std": 0.16526763141155243, "eval/prior_ent_mag": 48.033164978027344, "eval/prior_ent_max": 48.033164978027344, "eval/prior_ent_mean": 45.65127944946289, "eval/prior_ent_min": 43.309165954589844, "eval/prior_ent_std": 0.8567960262298584, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0030516525730490685, "eval/reward_loss_std": 0.0001725501351756975, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0007567405700683594, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0030516525730490685, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.000525042531080544, "eval/reward_rate": 0.0, "replay/size": 193985.0, "replay/inserts": 19248.0, "replay/samples": 19248.0, "replay/insert_wait_avg": 1.4253338475278885e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.153424439783009e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 47296.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2704657848318555e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.06655168533325, "timer/env.step_count": 2406.0, "timer/env.step_total": 5.640562057495117, "timer/env.step_frac": 0.011279622759181141, "timer/env.step_avg": 0.0023443732574792674, "timer/env.step_min": 0.001138925552368164, "timer/env.step_max": 0.018520832061767578, "timer/replay._sample_count": 19248.0, "timer/replay._sample_total": 1353.2404413223267, "timer/replay._sample_frac": 2.706120688859536, "timer/replay._sample_avg": 0.07030550921250658, "timer/replay._sample_min": 0.00040078163146972656, "timer/replay._sample_max": 0.13637566566467285, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2984.0, "timer/agent.policy_total": 20.456066846847534, "timer/agent.policy_frac": 0.04090668887552293, "timer/agent.policy_avg": 0.00685525028379609, "timer/agent.policy_min": 0.004883766174316406, "timer/agent.policy_max": 0.01628422737121582, "timer/dataset_train_count": 1203.0, "timer/dataset_train_total": 0.10994315147399902, "timer/dataset_train_frac": 0.0002198570392350111, "timer/dataset_train_avg": 9.139081585536079e-05, "timer/dataset_train_min": 6.866455078125e-05, "timer/dataset_train_max": 0.000263214111328125, "timer/agent.train_count": 1203.0, "timer/agent.train_total": 464.7996520996094, "timer/agent.train_frac": 0.9294755878655216, "timer/agent.train_avg": 0.3863671256023353, "timer/agent.train_min": 0.35031914710998535, "timer/agent.train_max": 0.5402729511260986, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4509618282318115, "timer/agent.report_frac": 0.0009018036233616743, "timer/agent.report_avg": 0.22548091411590576, "timer/agent.report_min": 0.2248241901397705, "timer/agent.report_max": 0.22613763809204102, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.600120544433594e-05, "timer/dataset_eval_frac": 7.199282840054794e-08, "timer/dataset_eval_avg": 3.600120544433594e-05, "timer/dataset_eval_min": 3.600120544433594e-05, "timer/dataset_eval_max": 3.600120544433594e-05, "fps": 38.490423496096916}
{"step": 194864, "episode/length": 288.0, "episode/score": 0.09705271901134438, "episode/reward_rate": 0.0}
{"step": 195000, "episode/length": 288.0, "episode/score": 0.13841590577476381, "episode/reward_rate": 0.0}
{"step": 195600, "episode/length": 288.0, "episode/score": 0.12550621831746867, "episode/reward_rate": 0.0}
{"step": 195968, "episode/length": 288.0, "episode/score": 0.08692862634904941, "episode/reward_rate": 0.0}
{"step": 196144, "episode/length": 288.0, "episode/score": 0.1786910302691922, "episode/reward_rate": 0.0}
{"step": 196168, "episode/length": 288.0, "episode/score": 0.10099189157244837, "episode/reward_rate": 0.0}
{"step": 196232, "episode/length": 288.0, "episode/score": 0.19696856086181924, "episode/reward_rate": 0.0}
{"step": 196312, "episode/length": 288.0, "episode/score": 0.11282933936240624, "episode/reward_rate": 0.0}
{"step": 197176, "episode/length": 288.0, "episode/score": 0.150218459426128, "episode/reward_rate": 0.0}
{"step": 197312, "episode/length": 288.0, "episode/score": 0.18015336876862875, "episode/reward_rate": 0.0}
{"step": 197912, "episode/length": 288.0, "episode/score": 0.24075222783187655, "episode/reward_rate": 0.0}
{"step": 198280, "episode/length": 288.0, "episode/score": 0.2118090205099179, "episode/reward_rate": 0.0}
{"step": 198456, "episode/length": 288.0, "episode/score": 0.2526607016579874, "episode/reward_rate": 0.0}
{"step": 198480, "episode/length": 288.0, "episode/score": 0.22339719663420965, "episode/reward_rate": 0.0}
{"step": 198544, "episode/length": 288.0, "episode/score": 0.24240864859086741, "episode/reward_rate": 0.0}
{"step": 198624, "episode/length": 288.0, "episode/score": 0.1803074586390494, "episode/reward_rate": 0.0}
{"step": 199488, "episode/length": 288.0, "episode/score": 0.21299780673757596, "episode/reward_rate": 0.0}
{"step": 199624, "episode/length": 288.0, "episode/score": 0.20341460099552933, "episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200224, "episode/length": 288.0, "episode/score": 0.19943006625601356, "episode/reward_rate": 0.0}
{"step": 200592, "episode/length": 288.0, "episode/score": 0.11238642531668575, "episode/reward_rate": 0.0}
{"step": 200768, "episode/length": 288.0, "episode/score": 0.23849691176735632, "episode/reward_rate": 0.0}
{"step": 200792, "episode/length": 288.0, "episode/score": 0.21395380861758895, "episode/reward_rate": 0.0}
{"step": 200856, "episode/length": 288.0, "episode/score": 0.19383552632950796, "episode/reward_rate": 0.0}
{"step": 200936, "episode/length": 288.0, "episode/score": 0.16142624272220019, "episode/reward_rate": 0.0}
{"step": 201800, "episode/length": 288.0, "episode/score": 0.201444920144354, "episode/reward_rate": 0.0}
{"step": 201936, "episode/length": 288.0, "episode/score": 0.2578564799106289, "episode/reward_rate": 0.0}
{"step": 202536, "episode/length": 288.0, "episode/score": 0.14992901593905117, "episode/reward_rate": 0.0}
{"step": 202904, "episode/length": 288.0, "episode/score": 0.2409758638900712, "episode/reward_rate": 0.0}
{"step": 203080, "episode/length": 288.0, "episode/score": 0.17089975096769194, "episode/reward_rate": 0.0}
{"step": 203104, "episode/length": 288.0, "episode/score": 0.1972766018702714, "episode/reward_rate": 0.0}
{"step": 203168, "episode/length": 288.0, "episode/score": 0.2306679049813738, "episode/reward_rate": 0.0}
{"step": 203248, "episode/length": 288.0, "episode/score": 0.16592261381970275, "episode/reward_rate": 0.0}
{"step": 204112, "episode/length": 288.0, "episode/score": 0.1522610159506712, "episode/reward_rate": 0.0}
{"step": 204248, "episode/length": 288.0, "episode/score": 0.2003892238909657, "episode/reward_rate": 0.0}
{"step": 204848, "episode/length": 288.0, "episode/score": 0.21844864785975915, "episode/reward_rate": 0.0}
{"step": 205216, "episode/length": 288.0, "episode/score": 0.19892854214208455, "episode/reward_rate": 0.0}
{"step": 205392, "episode/length": 288.0, "episode/score": 0.16582621604402448, "episode/reward_rate": 0.0}
{"step": 205416, "episode/length": 288.0, "episode/score": 0.204669364230881, "episode/reward_rate": 0.0}
{"step": 205480, "episode/length": 288.0, "episode/score": 0.1643386943535461, "episode/reward_rate": 0.0}
{"step": 205560, "episode/length": 288.0, "episode/score": 0.1458147580485729, "episode/reward_rate": 0.0}
{"step": 206424, "episode/length": 288.0, "episode/score": 0.13700714002158065, "episode/reward_rate": 0.0}
{"step": 206560, "episode/length": 288.0, "episode/score": 0.18435216865759685, "episode/reward_rate": 0.0}
{"step": 207160, "episode/length": 288.0, "episode/score": 0.13375551086465975, "episode/reward_rate": 0.0}
{"step": 207528, "episode/length": 288.0, "episode/score": 0.12641933944144057, "episode/reward_rate": 0.0}
{"step": 207704, "episode/length": 288.0, "episode/score": 0.21589026836556968, "episode/reward_rate": 0.0}
{"step": 207728, "episode/length": 288.0, "episode/score": 0.26113204179483773, "episode/reward_rate": 0.0}
{"step": 207792, "episode/length": 288.0, "episode/score": 0.19143188677446688, "episode/reward_rate": 0.0}
{"step": 207872, "episode/length": 288.0, "episode/score": 0.16485429717329225, "episode/reward_rate": 0.0}
{"step": 208736, "episode/length": 288.0, "episode/score": 0.22733191082448911, "episode/reward_rate": 0.0}
{"step": 208872, "episode/length": 288.0, "episode/score": 0.263086419493618, "episode/reward_rate": 0.0}
{"step": 209472, "episode/length": 288.0, "episode/score": 0.27552112129512807, "episode/reward_rate": 0.0}
{"step": 209840, "episode/length": 288.0, "episode/score": 0.18435610480241849, "episode/reward_rate": 0.0}
{"step": 210016, "episode/length": 288.0, "episode/score": 0.274807494970446, "episode/reward_rate": 0.0}
{"step": 210040, "episode/length": 288.0, "episode/score": 0.26713876673966297, "episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 210080, "eval_episode/length": 217.0, "eval_episode/score": 0.3218750059604645, "eval_episode/reward_rate": 0.0045871559633027525}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210104, "episode/length": 288.0, "episode/score": 0.22912062176283143, "episode/reward_rate": 0.0}
{"step": 210184, "episode/length": 288.0, "episode/score": 0.21740727581709507, "episode/reward_rate": 0.0}
{"step": 211048, "episode/length": 288.0, "episode/score": 0.2720908462006264, "episode/reward_rate": 0.0}
{"step": 211184, "episode/length": 288.0, "episode/score": 0.24498161855308354, "episode/reward_rate": 0.0}
{"step": 211784, "episode/length": 288.0, "episode/score": 0.1729723640528391, "episode/reward_rate": 0.0}
{"step": 212152, "episode/length": 288.0, "episode/score": 0.2281879960828519, "episode/reward_rate": 0.0}
{"step": 212328, "episode/length": 288.0, "episode/score": 0.2013809780810334, "episode/reward_rate": 0.0}
{"step": 212352, "episode/length": 288.0, "episode/score": 0.3288601163262683, "episode/reward_rate": 0.0}
{"step": 212416, "episode/length": 288.0, "episode/score": 0.1821283229310211, "episode/reward_rate": 0.0}
{"step": 212496, "episode/length": 288.0, "episode/score": 0.33724001589962427, "episode/reward_rate": 0.0}
{"step": 213360, "episode/length": 288.0, "episode/score": 0.3203815945394126, "episode/reward_rate": 0.0}
{"step": 213496, "episode/length": 288.0, "episode/score": 0.2300610366669389, "episode/reward_rate": 0.0}
{"step": 214096, "episode/length": 288.0, "episode/score": 0.20912443758470545, "episode/reward_rate": 0.0}
{"step": 214137, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.7265803639481707, "train/action_min": 0.0, "train/action_std": 1.5019479287349111, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0010963666884084725, "train/actor_opt_grad_steps": 12670.0, "train/actor_opt_loss": 15.463022519902486, "train/adv_mag": 0.0055230980723854, "train/adv_max": 0.005499297041233962, "train/adv_mean": 0.0018253946128846488, "train/adv_min": -0.0014804507174142978, "train/adv_std": 0.0011160919695715912, "train/cont_avg": 0.9964669080284553, "train/cont_loss_mean": 0.02347878223035212, "train/cont_loss_std": 0.3237828228289519, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.6462324330064115, "train/cont_pos_acc": 0.9999999806163756, "train/cont_pos_loss": 0.0035541536517410986, "train/cont_pred": 0.9964522375323908, "train/cont_rate": 0.9964669080284553, "train/dyn_loss_mean": 1.000002297928663, "train/dyn_loss_std": 7.351114967368483e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.17779544440317688, "train/extr_critic_critic_opt_grad_steps": 12670.0, "train/extr_critic_critic_opt_loss": 3961.6542065628178, "train/extr_critic_mag": 0.17552830048692905, "train/extr_critic_max": 0.17552830048692905, "train/extr_critic_mean": 0.17371137779418047, "train/extr_critic_min": 0.17157895584416583, "train/extr_critic_std": 0.0007070131686918828, "train/extr_return_normed_mag": 0.010005130394687497, "train/extr_return_normed_max": 0.00996473056029498, "train/extr_return_normed_mean": 0.005417888589265686, "train/extr_return_normed_min": 0.0015561178447754402, "train/extr_return_normed_std": 0.0014423753647890881, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.1800836037571837, "train/extr_return_raw_max": 0.1800836037571837, "train/extr_return_raw_mean": 0.17553677088846037, "train/extr_return_raw_min": 0.1716749910416642, "train/extr_return_raw_std": 0.001442375361003224, "train/extr_reward_mag": 0.0018263696655025326, "train/extr_reward_max": 0.0018263696655025326, "train/extr_reward_mean": 0.0008687181388807854, "train/extr_reward_min": 8.162638036216178e-05, "train/extr_reward_std": 0.00039539445831876475, "train/image_loss_mean": 0.20204846875938942, "train/image_loss_std": 0.09723672107225512, "train/model_loss_mean": 0.8423096033615795, "train/model_loss_std": 0.3617150600605864, "train/model_opt_grad_norm": 41.015350667441766, "train/model_opt_grad_steps": 12656.463414634147, "train/model_opt_loss": 2721.400842185912, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3231.7073170731705, "train/policy_entropy_mag": 1.7433191596007929, "train/policy_entropy_max": 1.7433191596007929, "train/policy_entropy_mean": 1.3812994210700678, "train/policy_entropy_min": 0.8100646622781831, "train/policy_entropy_std": 0.13745869038914277, "train/policy_logprob_mag": 4.467279666807594, "train/policy_logprob_max": -0.26460915434408966, "train/policy_logprob_mean": -1.3808023246323191, "train/policy_logprob_min": -4.467279666807594, "train/policy_logprob_std": 0.858268883897037, "train/policy_randomness_mag": 0.8958888834084922, "train/policy_randomness_max": 0.8958888834084922, "train/policy_randomness_mean": 0.7098475294869121, "train/policy_randomness_min": 0.4162909141400965, "train/policy_randomness_std": 0.07063979727435644, "train/post_ent_mag": 46.42063212200878, "train/post_ent_max": 46.42063212200878, "train/post_ent_mean": 45.98101021991513, "train/post_ent_min": 45.620622526339396, "train/post_ent_std": 0.14499203370111743, "train/prior_ent_mag": 47.552407148407724, "train/prior_ent_max": 47.552407148407724, "train/prior_ent_mean": 44.60308338568463, "train/prior_ent_min": 41.840245626806244, "train/prior_ent_std": 0.9294341744446173, "train/rep_loss_mean": 1.000002297928663, "train/rep_loss_std": 7.351114967368483e-05, "train/reward_avg": 0.00045022119486863474, "train/reward_loss_mean": 0.01678095585325869, "train/reward_loss_std": 0.05103957574299681, "train/reward_max_data": 0.05801964646235593, "train/reward_max_pred": 0.0017250718140020603, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.015943723359728247, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.804456075032553, "train/reward_pred": 0.00045356764533837154, "train/reward_rate": 9.527439024390244e-05, "train_stats/mean_log_entropy": 1.4217153707546974, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.030980266630649567, "report/cont_loss_std": 0.38692450523376465, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.554657936096191, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0038768514059484005, "report/cont_pred": 0.9961307048797607, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1988641619682312, "report/image_loss_std": 0.09566449373960495, "report/model_loss_mean": 0.8477426767349243, "report/model_loss_std": 0.3970385491847992, "report/post_ent_mag": 43.52289581298828, "report/post_ent_max": 43.52289581298828, "report/post_ent_mean": 43.092403411865234, "report/post_ent_min": 42.75408172607422, "report/post_ent_std": 0.11084528267383575, "report/prior_ent_mag": 46.21451187133789, "report/prior_ent_max": 46.21451187133789, "report/prior_ent_mean": 43.6489143371582, "report/prior_ent_min": 40.39285659790039, "report/prior_ent_std": 0.9249462485313416, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00046010405640117824, "report/reward_loss_mean": 0.017898187041282654, "report/reward_loss_std": 0.027829688042402267, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.0019102096557617188, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.017898187041282654, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00045506912283599377, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014718144200742245, "eval/cont_loss_std": 0.24507252871990204, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.554657936096191, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0038767775986343622, "eval/cont_pred": 0.9961308240890503, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2134813368320465, "eval/image_loss_std": 0.114597387611866, "eval/model_loss_mean": 0.8305306434631348, "eval/model_loss_std": 0.2735641896724701, "eval/post_ent_mag": 43.55493927001953, "eval/post_ent_max": 43.55493927001953, "eval/post_ent_mean": 43.04962158203125, "eval/post_ent_min": 42.749114990234375, "eval/post_ent_std": 0.1258075088262558, "eval/prior_ent_mag": 45.914127349853516, "eval/prior_ent_max": 45.914127349853516, "eval/prior_ent_mean": 43.656063079833984, "eval/prior_ent_min": 40.83087921142578, "eval/prior_ent_std": 1.0302660465240479, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.002331098075956106, "eval/reward_loss_std": 0.003017178038135171, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.001932382583618164, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002331098075956106, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00037957378663122654, "eval/reward_rate": 0.0, "replay/size": 213633.0, "replay/inserts": 19648.0, "replay/samples": 19648.0, "replay/insert_wait_avg": 1.3564182415070674e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.015316222312007e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 51920.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2907293016110325e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.19816875457764, "timer/env.step_count": 2456.0, "timer/env.step_total": 5.510557413101196, "timer/env.step_frac": 0.011016748475552602, "timer/env.step_avg": 0.0022437123017513016, "timer/env.step_min": 0.0011262893676757812, "timer/env.step_max": 0.025171756744384766, "timer/replay._sample_count": 19648.0, "timer/replay._sample_total": 1358.0880618095398, "timer/replay._sample_frac": 2.7151000276370185, "timer/replay._sample_avg": 0.06912093148460606, "timer/replay._sample_min": 0.0003647804260253906, "timer/replay._sample_max": 0.09960746765136719, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3034.0, "timer/agent.policy_total": 20.24515700340271, "timer/agent.policy_frac": 0.040474272534444244, "timer/agent.policy_avg": 0.00667276104265086, "timer/agent.policy_min": 0.004946231842041016, "timer/agent.policy_max": 0.009801149368286133, "timer/dataset_train_count": 1228.0, "timer/dataset_train_total": 0.10829639434814453, "timer/dataset_train_frac": 0.0002165069788595731, "timer/dataset_train_avg": 8.818924621184408e-05, "timer/dataset_train_min": 7.677078247070312e-05, "timer/dataset_train_max": 0.00039267539978027344, "timer/agent.train_count": 1228.0, "timer/agent.train_total": 465.9994716644287, "timer/agent.train_frac": 0.9316297035327042, "timer/agent.train_avg": 0.3794783971208703, "timer/agent.train_min": 0.35674524307250977, "timer/agent.train_max": 0.471088171005249, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.41417646408081055, "timer/agent.report_frac": 0.0008280247508943327, "timer/agent.report_avg": 0.20708823204040527, "timer/agent.report_min": 0.1965038776397705, "timer/agent.report_max": 0.21767258644104004, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.743171691894531e-05, "timer/dataset_eval_frac": 7.483377440614181e-08, "timer/dataset_eval_avg": 3.743171691894531e-05, "timer/dataset_eval_min": 3.743171691894531e-05, "timer/dataset_eval_max": 3.743171691894531e-05, "fps": 39.279943009937526}
{"step": 214392, "episode/length": 236.0, "episode/score": 0.4623068903993044, "episode/reward_rate": 0.004219409282700422}
{"step": 214464, "episode/length": 288.0, "episode/score": 0.22076947036157435, "episode/reward_rate": 0.0}
{"step": 214640, "episode/length": 288.0, "episode/score": 0.2323290733588692, "episode/reward_rate": 0.0}
{"step": 214664, "episode/length": 288.0, "episode/score": 0.2503413073836782, "episode/reward_rate": 0.0}
{"step": 214728, "episode/length": 288.0, "episode/score": 0.25010881289608733, "episode/reward_rate": 0.0}
{"step": 215672, "episode/length": 288.0, "episode/score": 0.22373518790709568, "episode/reward_rate": 0.0}
{"step": 215808, "episode/length": 288.0, "episode/score": 0.1993834111576689, "episode/reward_rate": 0.0}
{"step": 216408, "episode/length": 288.0, "episode/score": 0.19159633464209946, "episode/reward_rate": 0.0}
{"step": 216704, "episode/length": 288.0, "episode/score": 0.14246513989928644, "episode/reward_rate": 0.0}
{"step": 216776, "episode/length": 288.0, "episode/score": 0.2394534294458026, "episode/reward_rate": 0.0}
{"step": 216952, "episode/length": 288.0, "episode/score": 0.17200802687875694, "episode/reward_rate": 0.0}
{"step": 216976, "episode/length": 288.0, "episode/score": 0.18191209167343914, "episode/reward_rate": 0.0}
{"step": 217040, "episode/length": 288.0, "episode/score": 0.15677961209303248, "episode/reward_rate": 0.0}
{"step": 217984, "episode/length": 288.0, "episode/score": 0.17027153447020282, "episode/reward_rate": 0.0}
{"step": 218120, "episode/length": 288.0, "episode/score": 0.18432067135313446, "episode/reward_rate": 0.0}
{"step": 218720, "episode/length": 288.0, "episode/score": 0.17824905386498813, "episode/reward_rate": 0.0}
{"step": 219016, "episode/length": 288.0, "episode/score": 0.1870954228413666, "episode/reward_rate": 0.0}
{"step": 219088, "episode/length": 288.0, "episode/score": 0.1348808001530415, "episode/reward_rate": 0.0}
{"step": 219264, "episode/length": 288.0, "episode/score": 0.15185208404818695, "episode/reward_rate": 0.0}
{"step": 219288, "episode/length": 288.0, "episode/score": 0.21825267665576575, "episode/reward_rate": 0.0}
{"step": 219352, "episode/length": 288.0, "episode/score": 0.1721198963094821, "episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220296, "episode/length": 288.0, "episode/score": 0.1560014596224164, "episode/reward_rate": 0.0}
{"step": 220432, "episode/length": 288.0, "episode/score": 0.16160480413429923, "episode/reward_rate": 0.0}
{"step": 220984, "episode/length": 236.0, "episode/score": 0.4251394355372895, "episode/reward_rate": 0.004219409282700422}
{"step": 221032, "episode/length": 288.0, "episode/score": 0.18358979417587307, "episode/reward_rate": 0.0}
{"step": 221328, "episode/length": 288.0, "episode/score": 0.3067026942710527, "episode/reward_rate": 0.0}
{"step": 221576, "episode/length": 288.0, "episode/score": 0.2493127132280506, "episode/reward_rate": 0.0}
{"step": 221600, "episode/length": 288.0, "episode/score": 0.21976788592633056, "episode/reward_rate": 0.0}
{"step": 221664, "episode/length": 288.0, "episode/score": 0.26334311270125, "episode/reward_rate": 0.0}
{"step": 222032, "episode/length": 45.0, "episode/score": 0.9191383732559189, "episode/reward_rate": 0.021739130434782608}
{"step": 222608, "episode/length": 288.0, "episode/score": 0.21249183370457558, "episode/reward_rate": 0.0}
{"step": 222744, "episode/length": 288.0, "episode/score": 0.22501083798056243, "episode/reward_rate": 0.0}
{"step": 223296, "episode/length": 288.0, "episode/score": 0.2348735703312741, "episode/reward_rate": 0.0}
{"step": 223344, "episode/length": 288.0, "episode/score": 0.18278095027199015, "episode/reward_rate": 0.0}
{"step": 223640, "episode/length": 288.0, "episode/score": 0.20799838838820506, "episode/reward_rate": 0.0}
{"step": 223888, "episode/length": 288.0, "episode/score": 0.17901183696540102, "episode/reward_rate": 0.0}
{"step": 223912, "episode/length": 288.0, "episode/score": 0.24108791249432215, "episode/reward_rate": 0.0}
{"step": 224344, "episode/length": 288.0, "episode/score": 0.20964625088709, "episode/reward_rate": 0.0}
{"step": 224920, "episode/length": 288.0, "episode/score": 0.15169387080891283, "episode/reward_rate": 0.0}
{"step": 225056, "episode/length": 288.0, "episode/score": 0.23571263871781412, "episode/reward_rate": 0.0}
{"step": 225608, "episode/length": 288.0, "episode/score": 0.17629250562345078, "episode/reward_rate": 0.0}
{"step": 225656, "episode/length": 288.0, "episode/score": 0.16194278964462683, "episode/reward_rate": 0.0}
{"step": 225952, "episode/length": 288.0, "episode/score": 0.1675470433974624, "episode/reward_rate": 0.0}
{"step": 226200, "episode/length": 288.0, "episode/score": 0.18810827610332126, "episode/reward_rate": 0.0}
{"step": 226224, "episode/length": 288.0, "episode/score": 0.25918107277857416, "episode/reward_rate": 0.0}
{"step": 226656, "episode/length": 288.0, "episode/score": 0.22607727699892166, "episode/reward_rate": 0.0}
{"step": 227232, "episode/length": 288.0, "episode/score": 0.22450343798277572, "episode/reward_rate": 0.0}
{"step": 227368, "episode/length": 288.0, "episode/score": 0.24061146908979936, "episode/reward_rate": 0.0}
{"step": 227920, "episode/length": 288.0, "episode/score": 0.1585603390324195, "episode/reward_rate": 0.0}
{"step": 227968, "episode/length": 288.0, "episode/score": 0.15322241567696437, "episode/reward_rate": 0.0}
{"step": 228264, "episode/length": 288.0, "episode/score": 0.096284780535143, "episode/reward_rate": 0.0}
{"step": 228512, "episode/length": 288.0, "episode/score": 0.1251451171140161, "episode/reward_rate": 0.0}
{"step": 228536, "episode/length": 288.0, "episode/score": 0.15902903009259717, "episode/reward_rate": 0.0}
{"step": 228968, "episode/length": 288.0, "episode/score": 0.1095299310277369, "episode/reward_rate": 0.0}
{"step": 229544, "episode/length": 288.0, "episode/score": 0.16448925918916757, "episode/reward_rate": 0.0}
{"step": 229680, "episode/length": 288.0, "episode/score": 0.15966248283393725, "episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 230048, "eval_episode/length": 204.0, "eval_episode/score": 0.36250001192092896, "eval_episode/reward_rate": 0.004878048780487805}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230232, "episode/length": 288.0, "episode/score": 0.1880438643428306, "episode/reward_rate": 0.0}
{"step": 230280, "episode/length": 288.0, "episode/score": 0.21161115388383678, "episode/reward_rate": 0.0}
{"step": 230576, "episode/length": 288.0, "episode/score": 0.20397223155828215, "episode/reward_rate": 0.0}
{"step": 230824, "episode/length": 288.0, "episode/score": 0.18609516009814797, "episode/reward_rate": 0.0}
{"step": 230848, "episode/length": 288.0, "episode/score": 0.14676773723317638, "episode/reward_rate": 0.0}
{"step": 231280, "episode/length": 288.0, "episode/score": 0.26522496906852666, "episode/reward_rate": 0.0}
{"step": 231856, "episode/length": 288.0, "episode/score": 0.18748431524954867, "episode/reward_rate": 0.0}
{"step": 231992, "episode/length": 288.0, "episode/score": 0.18447464169616978, "episode/reward_rate": 0.0}
{"step": 232544, "episode/length": 288.0, "episode/score": 0.19911480613689037, "episode/reward_rate": 0.0}
{"step": 232592, "episode/length": 288.0, "episode/score": 0.17003399584518775, "episode/reward_rate": 0.0}
{"step": 232888, "episode/length": 288.0, "episode/score": 0.16353607823464245, "episode/reward_rate": 0.0}
{"step": 233136, "episode/length": 288.0, "episode/score": 0.25863614006732405, "episode/reward_rate": 0.0}
{"step": 233160, "episode/length": 288.0, "episode/score": 0.25599669768109834, "episode/reward_rate": 0.0}
{"step": 233385, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1627560450025825, "train/action_min": 0.0, "train/action_std": 1.67615856316464, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0018958688039170993, "train/actor_opt_grad_steps": 13890.0, "train/actor_opt_loss": 12.617491769396569, "train/adv_mag": 0.006945465098727833, "train/adv_max": 0.006904381242665378, "train/adv_mean": 0.0015443088937554272, "train/adv_min": -0.0021827100229657387, "train/adv_std": 0.0011983956700991377, "train/cont_avg": 0.9963681559917356, "train/cont_loss_mean": 0.02399489267013413, "train/cont_loss_std": 0.3275251231837103, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.638272117165958, "train/cont_pos_acc": 0.999999982758987, "train/cont_pos_loss": 0.0035282743051802076, "train/cont_pred": 0.9964778048933045, "train/cont_rate": 0.9963681559917356, "train/dyn_loss_mean": 1.000001099484026, "train/dyn_loss_std": 3.514633598652753e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2007836632522916, "train/extr_critic_critic_opt_grad_steps": 13890.0, "train/extr_critic_critic_opt_loss": 9082.705118478822, "train/extr_critic_mag": 0.20707022651167942, "train/extr_critic_max": 0.20707022651167942, "train/extr_critic_mean": 0.20468390283505777, "train/extr_critic_min": 0.20178911705647617, "train/extr_critic_std": 0.0008328583349823983, "train/extr_return_normed_mag": 0.010671404398177282, "train/extr_return_normed_max": 0.010671404398177282, "train/extr_return_normed_mean": 0.00496363064056755, "train/extr_return_normed_min": 0.000685611416485684, "train/extr_return_normed_std": 0.0014759615411951152, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.21193597521171098, "train/extr_return_raw_max": 0.21193597521171098, "train/extr_return_raw_mean": 0.20622821336935374, "train/extr_return_raw_min": 0.20195018223001937, "train/extr_return_raw_std": 0.0014759615493730512, "train/extr_reward_mag": 0.0026674329741927217, "train/extr_reward_max": 0.0026674329741927217, "train/extr_reward_mean": 0.0009118753291997474, "train/extr_reward_min": 3.173627144049022e-05, "train/extr_reward_std": 0.0005211754370584683, "train/image_loss_mean": 0.19674325568124282, "train/image_loss_std": 0.10036506934845743, "train/model_loss_mean": 0.8393161823926878, "train/model_loss_std": 0.38186407070760886, "train/model_opt_grad_norm": 37.69997097835068, "train/model_opt_grad_steps": 13875.396694214876, "train/model_opt_loss": 2342.89306640625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2789.2561983471073, "train/policy_entropy_mag": 1.7945935253269416, "train/policy_entropy_max": 1.7945935253269416, "train/policy_entropy_mean": 1.3214826864644516, "train/policy_entropy_min": 0.5545893084288629, "train/policy_entropy_std": 0.19588719351478845, "train/policy_logprob_mag": 4.869587283489133, "train/policy_logprob_max": -0.1391206736991967, "train/policy_logprob_mean": -1.3221955082633279, "train/policy_logprob_min": -4.869587283489133, "train/policy_logprob_std": 0.9369407079436562, "train/policy_randomness_mag": 0.9222386917792076, "train/policy_randomness_max": 0.9222386917792076, "train/policy_randomness_mean": 0.679107800495526, "train/policy_randomness_min": 0.285002542551884, "train/policy_randomness_std": 0.10066610953408825, "train/post_ent_mag": 41.88233834258781, "train/post_ent_max": 41.88233834258781, "train/post_ent_mean": 41.499878497163124, "train/post_ent_min": 41.11861971390149, "train/post_ent_std": 0.1285479840291433, "train/prior_ent_mag": 44.031843547978674, "train/prior_ent_max": 44.031843547978674, "train/prior_ent_mean": 41.69269754078763, "train/prior_ent_min": 39.32367151433771, "train/prior_ent_std": 0.8588411221819475, "train/rep_loss_mean": 1.000001099484026, "train/rep_loss_std": 3.514633598652753e-05, "train/reward_avg": 0.0005101458540413344, "train/reward_loss_mean": 0.018577353159073464, "train/reward_loss_std": 0.07080533963528053, "train/reward_max_data": 0.08170282413551877, "train/reward_max_pred": 0.002173220815737385, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.016953570267939862, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 7.785723230113154, "train/reward_pred": 0.0004949166077720232, "train/reward_rate": 0.00020983987603305786, "train_stats/mean_log_entropy": 1.3142119957053142, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.01993984542787075, "report/cont_loss_std": 0.30128538608551025, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.578007698059082, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003608598606660962, "report/cont_pred": 0.9963976144790649, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2042568027973175, "report/image_loss_std": 0.10568618029356003, "report/model_loss_mean": 0.8481276035308838, "report/model_loss_std": 0.4529215395450592, "report/post_ent_mag": 40.31678009033203, "report/post_ent_max": 40.31678009033203, "report/post_ent_mean": 40.05738830566406, "report/post_ent_min": 39.730682373046875, "report/post_ent_std": 0.10606570541858673, "report/prior_ent_mag": 41.50350570678711, "report/prior_ent_max": 41.50350570678711, "report/prior_ent_mean": 39.66093444824219, "report/prior_ent_min": 37.94916534423828, "report/prior_ent_std": 0.6480861902236938, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0008369445567950606, "report/reward_loss_mean": 0.023930924013257027, "report/reward_loss_std": 0.1852760761976242, "report/reward_max_data": 0.39937499165534973, "report/reward_max_pred": 0.00499725341796875, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.018207624554634094, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.878864765167236, "report/reward_pred": 0.0006779932882636786, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020418060943484306, "eval/cont_loss_std": 0.3093385696411133, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.723398208618164, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003661018330603838, "eval/cont_pred": 0.9963468313217163, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21023279428482056, "eval/image_loss_std": 0.116521455347538, "eval/model_loss_mean": 0.8339993953704834, "eval/model_loss_std": 0.3264981210231781, "eval/post_ent_mag": 40.34209060668945, "eval/post_ent_max": 40.34209060668945, "eval/post_ent_mean": 40.058349609375, "eval/post_ent_min": 39.726600646972656, "eval/post_ent_std": 0.11476003378629684, "eval/prior_ent_mag": 42.25897216796875, "eval/prior_ent_max": 42.25897216796875, "eval/prior_ent_mean": 39.619178771972656, "eval/prior_ent_min": 37.860633850097656, "eval/prior_ent_std": 0.7414079308509827, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0033485242165625095, "eval/reward_loss_std": 0.0032341978512704372, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.004723072052001953, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0033485242165625095, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0006560352630913258, "eval/reward_rate": 0.0, "replay/size": 232881.0, "replay/inserts": 19248.0, "replay/samples": 19248.0, "replay/insert_wait_avg": 1.3387386539234088e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.704531603818721e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 56544.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2805717626657454e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.23968291282654, "timer/env.step_count": 2406.0, "timer/env.step_total": 5.369752883911133, "timer/env.step_frac": 0.01073436008243849, "timer/env.step_avg": 0.002231817491234885, "timer/env.step_min": 0.0011382102966308594, "timer/env.step_max": 0.010740995407104492, "timer/replay._sample_count": 19248.0, "timer/replay._sample_total": 1328.9326763153076, "timer/replay._sample_frac": 2.65659187327386, "timer/replay._sample_avg": 0.06904263696567475, "timer/replay._sample_min": 0.00036144256591796875, "timer/replay._sample_max": 0.09707903861999512, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2984.0, "timer/agent.policy_total": 20.189966917037964, "timer/agent.policy_frac": 0.040360586348277244, "timer/agent.policy_avg": 0.006766074704101194, "timer/agent.policy_min": 0.0048160552978515625, "timer/agent.policy_max": 0.0624232292175293, "timer/dataset_train_count": 1203.0, "timer/dataset_train_total": 0.10621142387390137, "timer/dataset_train_frac": 0.00021232106828360142, "timer/dataset_train_avg": 8.828879790016738e-05, "timer/dataset_train_min": 7.677078247070312e-05, "timer/dataset_train_max": 0.0001995563507080078, "timer/agent.train_count": 1203.0, "timer/agent.train_total": 466.407438993454, "timer/agent.train_frac": 0.9323679326630545, "timer/agent.train_avg": 0.3877036068108512, "timer/agent.train_min": 0.351071834564209, "timer/agent.train_max": 1.1573562622070312, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48742079734802246, "timer/agent.report_frac": 0.0009743745128531957, "timer/agent.report_avg": 0.24371039867401123, "timer/agent.report_min": 0.20948386192321777, "timer/agent.report_max": 0.2779369354248047, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.91278076171875e-05, "timer/dataset_eval_frac": 1.1819895469486637e-07, "timer/dataset_eval_avg": 5.91278076171875e-05, "timer/dataset_eval_min": 5.91278076171875e-05, "timer/dataset_eval_max": 5.91278076171875e-05, "fps": 38.47689781585499}
{"step": 233592, "episode/length": 288.0, "episode/score": 0.20379127404407882, "episode/reward_rate": 0.0}
{"step": 234168, "episode/length": 288.0, "episode/score": 0.20444912730260967, "episode/reward_rate": 0.0}
{"step": 234304, "episode/length": 288.0, "episode/score": 0.20152089192765743, "episode/reward_rate": 0.0}
{"step": 234856, "episode/length": 288.0, "episode/score": 0.1700457366706587, "episode/reward_rate": 0.0}
{"step": 234904, "episode/length": 288.0, "episode/score": 0.1749429591354783, "episode/reward_rate": 0.0}
{"step": 235200, "episode/length": 288.0, "episode/score": 0.15907111654735218, "episode/reward_rate": 0.0}
{"step": 235448, "episode/length": 288.0, "episode/score": 0.2182763594142898, "episode/reward_rate": 0.0}
{"step": 235472, "episode/length": 288.0, "episode/score": 0.19918943694176505, "episode/reward_rate": 0.0}
{"step": 235904, "episode/length": 288.0, "episode/score": 0.16557114350678148, "episode/reward_rate": 0.0}
{"step": 236480, "episode/length": 288.0, "episode/score": 0.13248913425741193, "episode/reward_rate": 0.0}
{"step": 236616, "episode/length": 288.0, "episode/score": 0.1826557034620464, "episode/reward_rate": 0.0}
{"step": 237168, "episode/length": 288.0, "episode/score": 0.21663376987430638, "episode/reward_rate": 0.0}
{"step": 237216, "episode/length": 288.0, "episode/score": 0.17605026118008027, "episode/reward_rate": 0.0}
{"step": 237512, "episode/length": 288.0, "episode/score": 0.16157078432411254, "episode/reward_rate": 0.0}
{"step": 237760, "episode/length": 288.0, "episode/score": 0.2434404326022559, "episode/reward_rate": 0.0}
{"step": 237784, "episode/length": 288.0, "episode/score": 0.19200802749952572, "episode/reward_rate": 0.0}
{"step": 238216, "episode/length": 288.0, "episode/score": 0.15996762406081189, "episode/reward_rate": 0.0}
{"step": 238792, "episode/length": 288.0, "episode/score": 0.18251154581645324, "episode/reward_rate": 0.0}
{"step": 238928, "episode/length": 288.0, "episode/score": 0.14603134891552827, "episode/reward_rate": 0.0}
{"step": 239480, "episode/length": 288.0, "episode/score": 0.20286617848023525, "episode/reward_rate": 0.0}
{"step": 239528, "episode/length": 288.0, "episode/score": 0.17034482651780536, "episode/reward_rate": 0.0}
{"step": 239824, "episode/length": 288.0, "episode/score": 0.20572881230060602, "episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240072, "episode/length": 288.0, "episode/score": 0.1735321183035694, "episode/reward_rate": 0.0}
{"step": 240096, "episode/length": 288.0, "episode/score": 0.20946132702238174, "episode/reward_rate": 0.0}
{"step": 240528, "episode/length": 288.0, "episode/score": 0.10839464993495085, "episode/reward_rate": 0.0}
{"step": 241104, "episode/length": 288.0, "episode/score": 0.23142993930792954, "episode/reward_rate": 0.0}
{"step": 241240, "episode/length": 288.0, "episode/score": 0.18730226012678486, "episode/reward_rate": 0.0}
{"step": 241792, "episode/length": 288.0, "episode/score": 0.16180493243768979, "episode/reward_rate": 0.0}
{"step": 241840, "episode/length": 288.0, "episode/score": 0.17608616110032926, "episode/reward_rate": 0.0}
{"step": 242136, "episode/length": 288.0, "episode/score": 0.2926632531115274, "episode/reward_rate": 0.0}
{"step": 242384, "episode/length": 288.0, "episode/score": 0.21847534741039, "episode/reward_rate": 0.0}
{"step": 242408, "episode/length": 288.0, "episode/score": 0.240129731793445, "episode/reward_rate": 0.0}
{"step": 242840, "episode/length": 288.0, "episode/score": 0.2763710707067162, "episode/reward_rate": 0.0}
{"step": 243416, "episode/length": 288.0, "episode/score": 0.2864506326340006, "episode/reward_rate": 0.0}
{"step": 243552, "episode/length": 288.0, "episode/score": 0.19743457497423833, "episode/reward_rate": 0.0}
{"step": 244104, "episode/length": 288.0, "episode/score": 0.2479873328747999, "episode/reward_rate": 0.0}
{"step": 244152, "episode/length": 288.0, "episode/score": 0.23003788985533902, "episode/reward_rate": 0.0}
{"step": 244448, "episode/length": 288.0, "episode/score": 0.2336959069734803, "episode/reward_rate": 0.0}
{"step": 244696, "episode/length": 288.0, "episode/score": 0.25199503318162897, "episode/reward_rate": 0.0}
{"step": 244720, "episode/length": 288.0, "episode/score": 0.21605228484168038, "episode/reward_rate": 0.0}
{"step": 245152, "episode/length": 288.0, "episode/score": 0.22524013619386096, "episode/reward_rate": 0.0}
{"step": 245728, "episode/length": 288.0, "episode/score": 0.2641222806823862, "episode/reward_rate": 0.0}
{"step": 245864, "episode/length": 288.0, "episode/score": 0.16759990901664423, "episode/reward_rate": 0.0}
{"step": 246416, "episode/length": 288.0, "episode/score": 0.22669218129203728, "episode/reward_rate": 0.0}
{"step": 246464, "episode/length": 288.0, "episode/score": 0.17172901609683322, "episode/reward_rate": 0.0}
{"step": 246760, "episode/length": 288.0, "episode/score": 0.21000046336484957, "episode/reward_rate": 0.0}
{"step": 247008, "episode/length": 288.0, "episode/score": 0.23395958305718523, "episode/reward_rate": 0.0}
{"step": 247032, "episode/length": 288.0, "episode/score": 0.1508816942196063, "episode/reward_rate": 0.0}
{"step": 247464, "episode/length": 288.0, "episode/score": 0.20786831993518717, "episode/reward_rate": 0.0}
{"step": 248040, "episode/length": 288.0, "episode/score": 0.18425213076579894, "episode/reward_rate": 0.0}
{"step": 248176, "episode/length": 288.0, "episode/score": 0.20691681476910162, "episode/reward_rate": 0.0}
{"step": 248728, "episode/length": 288.0, "episode/score": 0.19291778458909903, "episode/reward_rate": 0.0}
{"step": 248776, "episode/length": 288.0, "episode/score": 0.23171037034308029, "episode/reward_rate": 0.0}
{"step": 249072, "episode/length": 288.0, "episode/score": 0.17054398775667323, "episode/reward_rate": 0.0}
{"step": 249320, "episode/length": 288.0, "episode/score": 0.16374383310107987, "episode/reward_rate": 0.0}
{"step": 249344, "episode/length": 288.0, "episode/score": 0.18488761327034808, "episode/reward_rate": 0.0}
{"step": 249776, "episode/length": 288.0, "episode/score": 0.1369855511516107, "episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250352, "episode/length": 288.0, "episode/score": 0.1559508226619073, "episode/reward_rate": 0.0}
{"step": 250488, "episode/length": 288.0, "episode/score": 0.2093712902792504, "episode/reward_rate": 0.0}
{"step": 251040, "episode/length": 288.0, "episode/score": 0.2532020191158608, "episode/reward_rate": 0.0}
{"step": 251088, "episode/length": 288.0, "episode/score": 0.15093256068348637, "episode/reward_rate": 0.0}
{"step": 251384, "episode/length": 288.0, "episode/score": 0.16245189781034242, "episode/reward_rate": 0.0}
{"step": 251632, "episode/length": 288.0, "episode/score": 0.20906731618651975, "episode/reward_rate": 0.0}
{"step": 251656, "episode/length": 288.0, "episode/score": 0.13291816987475613, "episode/reward_rate": 0.0}
{"step": 252088, "episode/length": 288.0, "episode/score": 0.20154726865848716, "episode/reward_rate": 0.0}
{"step": 252664, "episode/length": 288.0, "episode/score": 0.20416699053453158, "episode/reward_rate": 0.0}
{"step": 252713, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.3287556966145833, "train/action_min": 0.0, "train/action_std": 1.3259097427129745, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0008981143206862422, "train/actor_opt_grad_steps": 15095.0, "train/actor_opt_loss": 7.676863181901475, "train/adv_mag": 0.004621435577670733, "train/adv_max": 0.004319425796469053, "train/adv_mean": 0.0010363335484271374, "train/adv_min": -0.002176048730810483, "train/adv_std": 0.000853439794445876, "train/cont_avg": 0.9962646484375, "train/cont_loss_mean": 0.024638686907322457, "train/cont_loss_std": 0.3344191986392995, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.649569090674905, "train/cont_pos_acc": 0.9999999816219012, "train/cont_pos_loss": 0.003518012825710078, "train/cont_pred": 0.996488098303477, "train/cont_rate": 0.9962646484375, "train/dyn_loss_mean": 1.338011485338211, "train/dyn_loss_std": 0.03587637532151954, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.17300672635125616, "train/extr_critic_critic_opt_grad_steps": 15095.0, "train/extr_critic_critic_opt_loss": 12330.413102213543, "train/extr_critic_mag": 0.23419512510299684, "train/extr_critic_max": 0.23419512510299684, "train/extr_critic_mean": 0.2331791897614797, "train/extr_critic_min": 0.2321892817815145, "train/extr_critic_std": 0.0002837166336879212, "train/extr_return_normed_mag": 0.0070035170763731005, "train/extr_return_normed_max": 0.00686999149620533, "train/extr_return_normed_mean": 0.0034707040915994487, "train/extr_return_normed_min": 0.0002038723478714625, "train/extr_return_normed_std": 0.0009181517877247339, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2376148005326589, "train/extr_return_raw_max": 0.2376148005326589, "train/extr_return_raw_mean": 0.23421552491684755, "train/extr_return_raw_min": 0.23094868138432503, "train/extr_return_raw_std": 0.0009181517889373936, "train/extr_reward_mag": 0.002115740378697713, "train/extr_reward_max": 0.002115740378697713, "train/extr_reward_mean": 0.0008787800220792026, "train/extr_reward_min": 5.082488059997559e-05, "train/extr_reward_std": 0.00028838340913353024, "train/image_loss_mean": 0.23909385775526365, "train/image_loss_std": 0.0871357614795367, "train/model_loss_mean": 1.0858330234885216, "train/model_loss_std": 0.39807050103942554, "train/model_opt_grad_norm": 36.6712460676829, "train/model_opt_grad_steps": 15078.533333333333, "train/model_opt_loss": 2477.063150024414, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1687.5, "train/policy_entropy_mag": 1.5266764680544536, "train/policy_entropy_max": 1.5266764680544536, "train/policy_entropy_mean": 1.352950386206309, "train/policy_entropy_min": 1.0628795425097148, "train/policy_entropy_std": 0.06128754807480921, "train/policy_logprob_mag": 4.593842049439748, "train/policy_logprob_max": -0.5660296389833093, "train/policy_logprob_mean": -1.3531991600990296, "train/policy_logprob_min": -4.593842049439748, "train/policy_logprob_std": 0.8040332118670146, "train/policy_randomness_mag": 0.7845565542578697, "train/policy_randomness_max": 0.7845565542578697, "train/policy_randomness_mean": 0.6952789982159933, "train/policy_randomness_min": 0.5462120678275824, "train/policy_randomness_std": 0.03149557152064517, "train/post_ent_mag": 86.48643379211425, "train/post_ent_max": 86.48643379211425, "train/post_ent_mean": 86.3947743733724, "train/post_ent_min": 86.27684272130331, "train/post_ent_std": 0.034916278576323144, "train/prior_ent_mag": 86.74983463287353, "train/prior_ent_max": 86.74983463287353, "train/prior_ent_mean": 85.93382015228272, "train/prior_ent_min": 85.2931032816569, "train/prior_ent_std": 0.24107656826575596, "train/rep_loss_mean": 1.338011485338211, "train/rep_loss_std": 0.03587637532151954, "train/reward_avg": 0.0005207108687803459, "train/reward_loss_mean": 0.019293561934803923, "train/reward_loss_std": 0.0655894322010378, "train/reward_max_data": 0.0773173598300976, "train/reward_max_pred": 0.001331492265065511, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.017978890418695905, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.520331458041543, "train/reward_pred": 0.0005017727836578463, "train/reward_rate": 0.00015462239583333333, "train_stats/mean_log_entropy": 1.3546019955114885, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020115356892347336, "report/cont_loss_std": 0.3014119267463684, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.580600738525391, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0037770045455545187, "report/cont_pred": 0.9962301254272461, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2581961154937744, "report/image_loss_std": 0.08493180572986603, "report/model_loss_mean": 0.8959590196609497, "report/model_loss_std": 0.3144896924495697, "report/post_ent_mag": 103.60035705566406, "report/post_ent_max": 103.60035705566406, "report/post_ent_mean": 103.58063507080078, "report/post_ent_min": 103.52127075195312, "report/post_ent_std": 0.011546001769602299, "report/prior_ent_mag": 103.03253936767578, "report/prior_ent_max": 103.03253936767578, "report/prior_ent_mean": 102.89501953125, "report/prior_ent_min": 102.78043365478516, "report/prior_ent_std": 0.04875972121953964, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00044482279918156564, "report/reward_loss_mean": 0.01764756441116333, "report/reward_loss_std": 0.02802988700568676, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.0009478330612182617, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01764756441116333, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00041435996536165476, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.025558438152074814, "eval/cont_loss_std": 0.3478296399116516, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.579952239990234, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0037765055894851685, "eval/cont_pred": 0.9962306022644043, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24091283977031708, "eval/image_loss_std": 0.08257095515727997, "eval/model_loss_mean": 0.8686408400535583, "eval/model_loss_std": 0.3557034432888031, "eval/post_ent_mag": 103.59910583496094, "eval/post_ent_max": 103.59910583496094, "eval/post_ent_mean": 103.57862091064453, "eval/post_ent_min": 103.52137756347656, "eval/post_ent_std": 0.011287251487374306, "eval/prior_ent_mag": 103.05016326904297, "eval/prior_ent_max": 103.05016326904297, "eval/prior_ent_mean": 102.88813018798828, "eval/prior_ent_min": 102.78043365478516, "eval/prior_ent_std": 0.04938517510890961, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.002169533632695675, "eval/reward_loss_std": 0.0023180977441370487, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0009368658065795898, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002169533632695675, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0003546177176758647, "eval/reward_rate": 0.0, "replay/size": 252209.0, "replay/inserts": 19328.0, "replay/samples": 19328.0, "replay/insert_wait_avg": 1.3381070056498446e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.595860845995266e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 61168.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2719094959509826e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.2014136314392, "timer/env.step_count": 2416.0, "timer/env.step_total": 5.341494560241699, "timer/env.step_frac": 0.010678687454045151, "timer/env.step_avg": 0.002210883510033816, "timer/env.step_min": 0.0011379718780517578, "timer/env.step_max": 0.024776935577392578, "timer/replay._sample_count": 19328.0, "timer/replay._sample_total": 1326.9668235778809, "timer/replay._sample_frac": 2.6528650008087, "timer/replay._sample_avg": 0.06865515436557744, "timer/replay._sample_min": 0.02212214469909668, "timer/replay._sample_max": 0.10183072090148926, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2994.0, "timer/agent.policy_total": 20.096139669418335, "timer/agent.policy_frac": 0.04017609531232886, "timer/agent.policy_avg": 0.006712137498135717, "timer/agent.policy_min": 0.005002737045288086, "timer/agent.policy_max": 0.01255941390991211, "timer/dataset_train_count": 1208.0, "timer/dataset_train_total": 0.1051473617553711, "timer/dataset_train_frac": 0.00021021004517361535, "timer/dataset_train_avg": 8.704251800941315e-05, "timer/dataset_train_min": 6.29425048828125e-05, "timer/dataset_train_max": 0.00020051002502441406, "timer/agent.train_count": 1208.0, "timer/agent.train_total": 466.5064158439636, "timer/agent.train_frac": 0.9326371400215536, "timer/agent.train_avg": 0.3861808078178507, "timer/agent.train_min": 0.3513643741607666, "timer/agent.train_max": 0.48906517028808594, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4359447956085205, "timer/agent.report_frac": 0.0008715385117438621, "timer/agent.report_avg": 0.21797239780426025, "timer/agent.report_min": 0.21737074851989746, "timer/agent.report_max": 0.21857404708862305, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.600120544433594e-05, "timer/dataset_eval_frac": 7.197341803368536e-08, "timer/dataset_eval_avg": 3.600120544433594e-05, "timer/dataset_eval_min": 3.600120544433594e-05, "timer/dataset_eval_max": 3.600120544433594e-05, "fps": 38.639994160248285}
{"step": 252800, "episode/length": 288.0, "episode/score": 0.2244854585178473, "episode/reward_rate": 0.0}
{"step": 253352, "episode/length": 288.0, "episode/score": 0.18633909076243071, "episode/reward_rate": 0.0}
{"step": 253400, "episode/length": 288.0, "episode/score": 0.2199035891346739, "episode/reward_rate": 0.0}
{"step": 253696, "episode/length": 288.0, "episode/score": 0.13806543152895756, "episode/reward_rate": 0.0}
{"step": 253944, "episode/length": 288.0, "episode/score": 0.11045789092395353, "episode/reward_rate": 0.0}
{"step": 253968, "episode/length": 288.0, "episode/score": 0.18990961983263333, "episode/reward_rate": 0.0}
{"step": 254400, "episode/length": 288.0, "episode/score": 0.1876301043184867, "episode/reward_rate": 0.0}
{"step": 254976, "episode/length": 288.0, "episode/score": 0.18592032329706853, "episode/reward_rate": 0.0}
{"step": 255112, "episode/length": 288.0, "episode/score": 0.18070781996812002, "episode/reward_rate": 0.0}
{"step": 255664, "episode/length": 288.0, "episode/score": 0.1571313053235599, "episode/reward_rate": 0.0}
{"step": 255712, "episode/length": 288.0, "episode/score": 0.09947491733350944, "episode/reward_rate": 0.0}
{"step": 256008, "episode/length": 288.0, "episode/score": 0.1710663747385297, "episode/reward_rate": 0.0}
{"step": 256256, "episode/length": 288.0, "episode/score": 0.1684772036448976, "episode/reward_rate": 0.0}
{"step": 256280, "episode/length": 288.0, "episode/score": 0.1014662555188579, "episode/reward_rate": 0.0}
{"step": 256712, "episode/length": 288.0, "episode/score": 0.15123510567650555, "episode/reward_rate": 0.0}
{"step": 257288, "episode/length": 288.0, "episode/score": 0.18024138507337284, "episode/reward_rate": 0.0}
{"step": 257424, "episode/length": 288.0, "episode/score": 0.12242221479857562, "episode/reward_rate": 0.0}
{"step": 257976, "episode/length": 288.0, "episode/score": 0.20353139986832502, "episode/reward_rate": 0.0}
{"step": 258024, "episode/length": 288.0, "episode/score": 0.18658606758424412, "episode/reward_rate": 0.0}
{"step": 258320, "episode/length": 288.0, "episode/score": 0.12494768795147593, "episode/reward_rate": 0.0}
{"step": 258568, "episode/length": 288.0, "episode/score": 0.2150476684176965, "episode/reward_rate": 0.0}
{"step": 258592, "episode/length": 288.0, "episode/score": 0.1780478218764756, "episode/reward_rate": 0.0}
{"step": 259024, "episode/length": 288.0, "episode/score": 0.15173236999021356, "episode/reward_rate": 0.0}
{"step": 259600, "episode/length": 288.0, "episode/score": 0.11052947425901039, "episode/reward_rate": 0.0}
{"step": 259736, "episode/length": 288.0, "episode/score": 0.19168702332285648, "episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260288, "episode/length": 288.0, "episode/score": 0.17463204796410992, "episode/reward_rate": 0.0}
{"step": 260336, "episode/length": 288.0, "episode/score": 0.21939245668249896, "episode/reward_rate": 0.0}
{"step": 260632, "episode/length": 288.0, "episode/score": 0.11212700058320024, "episode/reward_rate": 0.0}
{"step": 260880, "episode/length": 288.0, "episode/score": 0.21775999189878803, "episode/reward_rate": 0.0}
{"step": 260904, "episode/length": 288.0, "episode/score": 0.1117768231268883, "episode/reward_rate": 0.0}
{"step": 261336, "episode/length": 288.0, "episode/score": 0.216320986254118, "episode/reward_rate": 0.0}
{"step": 261912, "episode/length": 288.0, "episode/score": 0.2642294974724564, "episode/reward_rate": 0.0}
{"step": 262048, "episode/length": 288.0, "episode/score": 0.27753236513763113, "episode/reward_rate": 0.0}
{"step": 262600, "episode/length": 288.0, "episode/score": 0.20473382204841073, "episode/reward_rate": 0.0}
{"step": 262648, "episode/length": 288.0, "episode/score": 0.25882008441794824, "episode/reward_rate": 0.0}
{"step": 262944, "episode/length": 288.0, "episode/score": 0.19663998754640488, "episode/reward_rate": 0.0}
{"step": 263192, "episode/length": 288.0, "episode/score": 0.22586669309384888, "episode/reward_rate": 0.0}
{"step": 263216, "episode/length": 288.0, "episode/score": 0.2225298612906954, "episode/reward_rate": 0.0}
{"step": 263648, "episode/length": 288.0, "episode/score": 0.18652151226888236, "episode/reward_rate": 0.0}
{"step": 264224, "episode/length": 288.0, "episode/score": 0.24618307033051678, "episode/reward_rate": 0.0}
{"step": 264360, "episode/length": 288.0, "episode/score": 0.16736048206485066, "episode/reward_rate": 0.0}
{"step": 264912, "episode/length": 288.0, "episode/score": 0.2993055725355589, "episode/reward_rate": 0.0}
{"step": 264960, "episode/length": 288.0, "episode/score": 0.23242357650269696, "episode/reward_rate": 0.0}
{"step": 265256, "episode/length": 288.0, "episode/score": 0.32084219545913584, "episode/reward_rate": 0.0}
{"step": 265504, "episode/length": 288.0, "episode/score": 0.3338325056301983, "episode/reward_rate": 0.0}
{"step": 265528, "episode/length": 288.0, "episode/score": 0.23073209143831264, "episode/reward_rate": 0.0}
{"step": 265960, "episode/length": 288.0, "episode/score": 0.31041514845901474, "episode/reward_rate": 0.0}
{"step": 266536, "episode/length": 288.0, "episode/score": 0.22184273345101246, "episode/reward_rate": 0.0}
{"step": 266672, "episode/length": 288.0, "episode/score": 0.18428567852606648, "episode/reward_rate": 0.0}
{"step": 267224, "episode/length": 288.0, "episode/score": 0.19999262785040628, "episode/reward_rate": 0.0}
{"step": 267272, "episode/length": 288.0, "episode/score": 0.2516063848561316, "episode/reward_rate": 0.0}
{"step": 267568, "episode/length": 288.0, "episode/score": 0.23621742801242362, "episode/reward_rate": 0.0}
{"step": 267816, "episode/length": 288.0, "episode/score": 0.2140701090766015, "episode/reward_rate": 0.0}
{"step": 267840, "episode/length": 288.0, "episode/score": 0.2061739406644847, "episode/reward_rate": 0.0}
{"step": 268272, "episode/length": 288.0, "episode/score": 0.28892259824988287, "episode/reward_rate": 0.0}
{"step": 268848, "episode/length": 288.0, "episode/score": 0.24535062388076767, "episode/reward_rate": 0.0}
{"step": 268984, "episode/length": 288.0, "episode/score": 0.25153245209457964, "episode/reward_rate": 0.0}
{"step": 269536, "episode/length": 288.0, "episode/score": 0.29886370570056897, "episode/reward_rate": 0.0}
{"step": 269584, "episode/length": 288.0, "episode/score": 0.3001166614931208, "episode/reward_rate": 0.0}
{"step": 269880, "episode/length": 288.0, "episode/score": 0.21349176948342574, "episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270128, "episode/length": 288.0, "episode/score": 0.26211996013898897, "episode/reward_rate": 0.0}
{"step": 270152, "episode/length": 288.0, "episode/score": 0.2341202666107165, "episode/reward_rate": 0.0}
{"step": 270584, "episode/length": 288.0, "episode/score": 0.22917284151799322, "episode/reward_rate": 0.0}
{"step": 271160, "episode/length": 288.0, "episode/score": 0.3041742166496988, "episode/reward_rate": 0.0}
{"step": 271296, "episode/length": 288.0, "episode/score": 0.23081540694147407, "episode/reward_rate": 0.0}
{"step": 271848, "episode/length": 288.0, "episode/score": 0.16909941700032505, "episode/reward_rate": 0.0}
{"step": 271896, "episode/length": 288.0, "episode/score": 0.18791832177566903, "episode/reward_rate": 0.0}
{"step": 272192, "episode/length": 288.0, "episode/score": 0.21602671010691665, "episode/reward_rate": 0.0}
{"step": 272440, "episode/length": 288.0, "episode/score": 0.20928286778416805, "episode/reward_rate": 0.0}
{"step": 272457, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.2831509497857863, "train/action_min": 0.0, "train/action_std": 1.3779862138532823, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0006397247171046347, "train/actor_opt_grad_steps": 16315.0, "train/actor_opt_loss": 0.24150541713160853, "train/adv_mag": 0.003264636762680546, "train/adv_max": 0.0026620181818162243, "train/adv_mean": 0.0004918084038264726, "train/adv_min": -0.002567254127033295, "train/adv_std": 0.0007023613368566598, "train/cont_avg": 0.9962670110887096, "train/cont_loss_mean": 0.02460897547162829, "train/cont_loss_std": 0.3339702147940546, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.6858563188646665, "train/cont_pos_acc": 0.9999999850988388, "train/cont_pos_loss": 0.0034270040961282867, "train/cont_pred": 0.996578949113046, "train/cont_rate": 0.9962670110887096, "train/dyn_loss_mean": 1.0000071544801035, "train/dyn_loss_std": 6.641202028203548e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10435172384079065, "train/extr_critic_critic_opt_grad_steps": 16315.0, "train/extr_critic_critic_opt_loss": 13226.011789629536, "train/extr_critic_mag": 0.24989539000295824, "train/extr_critic_max": 0.24989539000295824, "train/extr_critic_mean": 0.2493370744970537, "train/extr_critic_min": 0.24892838731888803, "train/extr_critic_std": 0.0001297651221149511, "train/extr_return_normed_mag": 0.004563684064534402, "train/extr_return_normed_max": 0.004271502696698712, "train/extr_return_normed_mean": 0.0019985171302781993, "train/extr_return_normed_min": -0.0010310881320507296, "train/extr_return_normed_std": 0.0007092894717765551, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.25210185781601935, "train/extr_return_raw_max": 0.25210185781601935, "train/extr_return_raw_mean": 0.24982888576003812, "train/extr_return_raw_min": 0.24679926698726992, "train/extr_return_raw_std": 0.0007092894717765551, "train/extr_reward_mag": 0.0012620774007612659, "train/extr_reward_max": 0.0012620774007612659, "train/extr_reward_mean": 0.0008309746429609556, "train/extr_reward_min": 4.079553388780163e-05, "train/extr_reward_std": 0.0002763320104173955, "train/image_loss_mean": 0.23967937079648818, "train/image_loss_std": 0.08232630188426664, "train/model_loss_mean": 0.8845695516755504, "train/model_loss_std": 0.3858983583387829, "train/model_opt_grad_norm": 35.58132585402458, "train/model_opt_grad_steps": 16297.943548387097, "train/model_opt_loss": 2193.4204839891004, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2479.8387096774195, "train/policy_entropy_mag": 1.5285712086385297, "train/policy_entropy_max": 1.5285712086385297, "train/policy_entropy_mean": 1.3664830086692688, "train/policy_entropy_min": 1.1859044860447607, "train/policy_entropy_std": 0.052342130667379784, "train/policy_logprob_mag": 4.2237183913107845, "train/policy_logprob_max": -0.5756300749076951, "train/policy_logprob_mean": -1.3661982397879324, "train/policy_logprob_min": -4.2237183913107845, "train/policy_logprob_std": 0.8394699808089964, "train/policy_randomness_mag": 0.7855302542448044, "train/policy_randomness_max": 0.7855302542448044, "train/policy_randomness_mean": 0.7022333991143012, "train/policy_randomness_min": 0.609434386174525, "train/policy_randomness_std": 0.02689853555432731, "train/post_ent_mag": 102.71083296498945, "train/post_ent_max": 102.71083296498945, "train/post_ent_mean": 102.65765706954464, "train/post_ent_min": 102.58879673865533, "train/post_ent_std": 0.019959020218060862, "train/prior_ent_mag": 103.19973834868401, "train/prior_ent_max": 103.19973834868401, "train/prior_ent_mean": 102.86835731998566, "train/prior_ent_min": 102.56788702934018, "train/prior_ent_std": 0.10559408922469424, "train/rep_loss_mean": 1.0000071544801035, "train/rep_loss_std": 6.641202028203548e-05, "train/reward_avg": 0.0005622800677120986, "train/reward_loss_mean": 0.020276892795077255, "train/reward_loss_std": 0.07529955038860921, "train/reward_max_data": 0.09902789126781206, "train/reward_max_pred": 0.001204525270769673, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.018584058439779665, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.60051691532135, "train/reward_pred": 0.0005163877128413128, "train/reward_rate": 0.0001968876008064516, "train_stats/mean_log_entropy": 1.3743432276490806, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020026296377182007, "report/cont_loss_std": 0.3078172206878662, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.698668956756592, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0033407644368708134, "report/cont_pred": 0.9966647624969482, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.19931526482105255, "report/image_loss_std": 0.08824926614761353, "report/model_loss_mean": 0.837958812713623, "report/model_loss_std": 0.3296908140182495, "report/post_ent_mag": 88.34677124023438, "report/post_ent_max": 88.34677124023438, "report/post_ent_mean": 87.89878845214844, "report/post_ent_min": 87.64933776855469, "report/post_ent_std": 0.1092592254281044, "report/prior_ent_mag": 92.57366943359375, "report/prior_ent_max": 92.57366943359375, "report/prior_ent_mean": 90.53219604492188, "report/prior_ent_min": 88.90292358398438, "report/prior_ent_std": 0.5764466524124146, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004720080178231001, "report/reward_loss_mean": 0.01861720159649849, "report/reward_loss_std": 0.028119733557105064, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.0014556646347045898, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01861720159649849, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00046673219185322523, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020032573491334915, "eval/cont_loss_std": 0.308027446269989, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.702561855316162, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003335625398904085, "eval/cont_pred": 0.9966698884963989, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19031596183776855, "eval/image_loss_std": 0.0771537497639656, "eval/model_loss_mean": 0.8125467300415039, "eval/model_loss_std": 0.31866246461868286, "eval/post_ent_mag": 88.34732055664062, "eval/post_ent_max": 88.34732055664062, "eval/post_ent_mean": 87.88795471191406, "eval/post_ent_min": 87.63516235351562, "eval/post_ent_std": 0.10645440965890884, "eval/prior_ent_mag": 92.65132141113281, "eval/prior_ent_max": 92.65132141113281, "eval/prior_ent_mean": 90.5107192993164, "eval/prior_ent_min": 88.97529602050781, "eval/prior_ent_std": 0.5580337047576904, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.002198244910687208, "eval/reward_loss_std": 0.0024967934004962444, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0014556646347045898, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002198244910687208, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00037424778565764427, "eval/reward_rate": 0.0, "replay/size": 271953.0, "replay/inserts": 19744.0, "replay/samples": 19744.0, "replay/insert_wait_avg": 1.3045640586840662e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.231800856814393e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 65792.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.282737329344436e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.1259973049164, "timer/env.step_count": 2468.0, "timer/env.step_total": 5.465207099914551, "timer/env.step_frac": 0.010927660488287971, "timer/env.step_avg": 0.0022144275121209686, "timer/env.step_min": 0.0011224746704101562, "timer/env.step_max": 0.03369784355163574, "timer/replay._sample_count": 19744.0, "timer/replay._sample_total": 1342.3906145095825, "timer/replay._sample_frac": 2.684104849064975, "timer/replay._sample_avg": 0.06798980016762472, "timer/replay._sample_min": 0.0004305839538574219, "timer/replay._sample_max": 0.09911799430847168, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3046.0, "timer/agent.policy_total": 19.874732494354248, "timer/agent.policy_frac": 0.03973945086129373, "timer/agent.policy_avg": 0.00652486293314322, "timer/agent.policy_min": 0.004942655563354492, "timer/agent.policy_max": 0.013004302978515625, "timer/dataset_train_count": 1234.0, "timer/dataset_train_total": 0.10447812080383301, "timer/dataset_train_frac": 0.0002089035990267366, "timer/dataset_train_avg": 8.46662243142893e-05, "timer/dataset_train_min": 6.651878356933594e-05, "timer/dataset_train_max": 0.00020623207092285156, "timer/agent.train_count": 1234.0, "timer/agent.train_total": 466.4267210960388, "timer/agent.train_frac": 0.9326184273753484, "timer/agent.train_avg": 0.3779795146645371, "timer/agent.train_min": 0.348191499710083, "timer/agent.train_max": 0.4409043788909912, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5091314315795898, "timer/agent.report_frac": 0.0010180063310509793, "timer/agent.report_avg": 0.2545657157897949, "timer/agent.report_min": 0.2095503807067871, "timer/agent.report_max": 0.29958105087280273, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.6716461181640625e-05, "timer/dataset_eval_frac": 7.341442232457148e-08, "timer/dataset_eval_avg": 3.6716461181640625e-05, "timer/dataset_eval_min": 3.6716461181640625e-05, "timer/dataset_eval_max": 3.6716461181640625e-05, "fps": 39.477577093784234}
{"step": 272464, "episode/length": 288.0, "episode/score": 0.2599474312455641, "episode/reward_rate": 0.0}
{"step": 272896, "episode/length": 288.0, "episode/score": 0.2851367127593676, "episode/reward_rate": 0.0}
{"step": 273472, "episode/length": 288.0, "episode/score": 0.274384405434148, "episode/reward_rate": 0.0}
{"step": 273608, "episode/length": 288.0, "episode/score": 0.27503937041547033, "episode/reward_rate": 0.0}
{"step": 274160, "episode/length": 288.0, "episode/score": 0.3362190222494519, "episode/reward_rate": 0.0}
{"step": 274208, "episode/length": 288.0, "episode/score": 0.21694465641462557, "episode/reward_rate": 0.0}
{"step": 274504, "episode/length": 288.0, "episode/score": 0.2558252099922811, "episode/reward_rate": 0.0}
{"step": 274752, "episode/length": 288.0, "episode/score": 0.2607566808753745, "episode/reward_rate": 0.0}
{"step": 274776, "episode/length": 288.0, "episode/score": 0.30078070374156596, "episode/reward_rate": 0.0}
{"step": 275208, "episode/length": 288.0, "episode/score": 0.3718101657823354, "episode/reward_rate": 0.0}
{"step": 275784, "episode/length": 288.0, "episode/score": 0.27837722122876585, "episode/reward_rate": 0.0}
{"step": 275920, "episode/length": 288.0, "episode/score": 0.2583583677314891, "episode/reward_rate": 0.0}
{"step": 276456, "episode/length": 209.0, "episode/score": 0.527900505395337, "episode/reward_rate": 0.004761904761904762}
{"step": 276472, "episode/length": 288.0, "episode/score": 0.3003112680680715, "episode/reward_rate": 0.0}
{"step": 276520, "episode/length": 288.0, "episode/score": 0.3378220134845833, "episode/reward_rate": 0.0}
{"step": 276816, "episode/length": 288.0, "episode/score": 0.3224340087363089, "episode/reward_rate": 0.0}
{"step": 277064, "episode/length": 288.0, "episode/score": 0.30332639965035924, "episode/reward_rate": 0.0}
{"step": 277520, "episode/length": 288.0, "episode/score": 0.256220401795872, "episode/reward_rate": 0.0}
{"step": 277960, "episode/length": 54.0, "episode/score": 0.913733163561119, "episode/reward_rate": 0.01818181818181818}
{"step": 278096, "episode/length": 288.0, "episode/score": 0.28620773110924347, "episode/reward_rate": 0.0}
{"step": 278232, "episode/length": 288.0, "episode/score": 0.30110815724765416, "episode/reward_rate": 0.0}
{"step": 278768, "episode/length": 288.0, "episode/score": 0.36428084066437805, "episode/reward_rate": 0.0}
{"step": 278784, "episode/length": 288.0, "episode/score": 0.3188643348221376, "episode/reward_rate": 0.0}
{"step": 278832, "episode/length": 288.0, "episode/score": 0.3127371571281401, "episode/reward_rate": 0.0}
{"step": 279128, "episode/length": 288.0, "episode/score": 0.29947544817969174, "episode/reward_rate": 0.0}
{"step": 279376, "episode/length": 288.0, "episode/score": 0.3389590137267078, "episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280272, "episode/length": 288.0, "episode/score": 0.23079568727052902, "episode/reward_rate": 0.0}
{"step": 280408, "episode/length": 288.0, "episode/score": 0.17263735117057877, "episode/reward_rate": 0.0}
{"step": 280544, "episode/length": 288.0, "episode/score": 0.2998871493732622, "episode/reward_rate": 0.0}
{"step": 281080, "episode/length": 288.0, "episode/score": 0.21625953740431214, "episode/reward_rate": 0.0}
{"step": 281096, "episode/length": 288.0, "episode/score": 0.19060315814340356, "episode/reward_rate": 0.0}
{"step": 281144, "episode/length": 288.0, "episode/score": 0.23492119663023914, "episode/reward_rate": 0.0}
{"step": 281440, "episode/length": 288.0, "episode/score": 0.20455609729333446, "episode/reward_rate": 0.0}
{"step": 281688, "episode/length": 288.0, "episode/score": 0.22469977954938258, "episode/reward_rate": 0.0}
{"step": 282024, "episode/length": 72.0, "episode/score": 0.8490037202266194, "episode/reward_rate": 0.0136986301369863}
{"step": 282352, "episode/length": 225.0, "episode/score": 0.49188623775535234, "episode/reward_rate": 0.004424778761061947}
{"step": 282584, "episode/length": 288.0, "episode/score": 0.19329216943469874, "episode/reward_rate": 0.0}
{"step": 282720, "episode/length": 288.0, "episode/score": 0.29679538507230063, "episode/reward_rate": 0.0}
{"step": 282952, "episode/length": 28.0, "episode/score": 0.9386063619647302, "episode/reward_rate": 0.034482758620689655}
{"step": 283392, "episode/length": 288.0, "episode/score": 0.22420322998755182, "episode/reward_rate": 0.0}
{"step": 283408, "episode/length": 172.0, "episode/score": 0.6019065907819368, "episode/reward_rate": 0.005780346820809248}
{"step": 283408, "episode/length": 288.0, "episode/score": 0.21663928856378334, "episode/reward_rate": 0.0}
{"step": 283456, "episode/length": 288.0, "episode/score": 0.15979504587585325, "episode/reward_rate": 0.0}
{"step": 284000, "episode/length": 288.0, "episode/score": 0.21007037324898192, "episode/reward_rate": 0.0}
{"step": 284664, "episode/length": 288.0, "episode/score": 0.31214942253313893, "episode/reward_rate": 0.0}
{"step": 284896, "episode/length": 288.0, "episode/score": 0.16738149353955123, "episode/reward_rate": 0.0}
{"step": 285264, "episode/length": 288.0, "episode/score": 0.23987763208174329, "episode/reward_rate": 0.0}
{"step": 285704, "episode/length": 288.0, "episode/score": 0.31892563879637237, "episode/reward_rate": 0.0}
{"step": 285720, "episode/length": 288.0, "episode/score": 0.2070048969023901, "episode/reward_rate": 0.0}
{"step": 285720, "episode/length": 288.0, "episode/score": 0.2330749285181355, "episode/reward_rate": 0.0}
{"step": 285744, "episode/length": 105.0, "episode/score": 0.793878810718752, "episode/reward_rate": 0.009433962264150943}
{"step": 285768, "episode/length": 288.0, "episode/score": 0.20405983833120445, "episode/reward_rate": 0.0}
{"step": 286032, "episode/length": 253.0, "episode/score": 0.46886486686594253, "episode/reward_rate": 0.003937007874015748}
{"step": 286976, "episode/length": 288.0, "episode/score": 0.22514324428334476, "episode/reward_rate": 0.0}
{"step": 287576, "episode/length": 288.0, "episode/score": 0.19810977563338383, "episode/reward_rate": 0.0}
{"step": 288016, "episode/length": 288.0, "episode/score": 0.2686643337538044, "episode/reward_rate": 0.0}
{"step": 288032, "episode/length": 288.0, "episode/score": 0.226278976921094, "episode/reward_rate": 0.0}
{"step": 288032, "episode/length": 288.0, "episode/score": 0.2786692320050861, "episode/reward_rate": 0.0}
{"step": 288056, "episode/length": 288.0, "episode/score": 0.24056324214870983, "episode/reward_rate": 0.0}
{"step": 288080, "episode/length": 288.0, "episode/score": 0.22909720932329947, "episode/reward_rate": 0.0}
{"step": 288344, "episode/length": 288.0, "episode/score": 0.18873810626610066, "episode/reward_rate": 0.0}
{"step": 289288, "episode/length": 288.0, "episode/score": 0.217092117707125, "episode/reward_rate": 0.0}
{"step": 289888, "episode/length": 288.0, "episode/score": 0.2753037612769731, "episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290328, "episode/length": 288.0, "episode/score": 0.22199208254482983, "episode/reward_rate": 0.0}
{"step": 290344, "episode/length": 288.0, "episode/score": 0.22953484036906957, "episode/reward_rate": 0.0}
{"step": 290344, "episode/length": 288.0, "episode/score": 0.299727131319969, "episode/reward_rate": 0.0}
{"step": 290368, "episode/length": 288.0, "episode/score": 0.19021890591852753, "episode/reward_rate": 0.0}
{"step": 290392, "episode/length": 288.0, "episode/score": 0.2595639315018161, "episode/reward_rate": 0.0}
{"step": 290656, "episode/length": 288.0, "episode/score": 0.23542299784480747, "episode/reward_rate": 0.0}
{"step": 291208, "episode/length": 101.0, "episode/score": 0.730465590413587, "episode/reward_rate": 0.00980392156862745}
{"step": 291600, "episode/length": 288.0, "episode/score": 0.15721331586973974, "episode/reward_rate": 0.0}
{"step": 292200, "episode/length": 288.0, "episode/score": 0.1652926247893447, "episode/reward_rate": 0.0}
{"step": 292505, "train_stats/mean_log_entropy": 1.3286308960782156, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.8579541015625, "train/action_min": 0.0, "train/action_std": 1.59050528049469, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.001249176386743784, "train/actor_opt_grad_steps": 17560.0, "train/actor_opt_loss": 1.227856501966715, "train/adv_mag": 0.006697195768356323, "train/adv_max": 0.0064014892578125, "train/adv_mean": 0.0006531531907094177, "train/adv_min": -0.003301335334777832, "train/adv_std": 0.0010226827040314675, "train/cont_avg": 0.9963515625, "train/cont_loss_mean": 0.024072250066325067, "train/cont_loss_std": 0.32704844201676314, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.628497838973999, "train/cont_pos_acc": 0.9999999814033508, "train/cont_pos_loss": 0.0035197985209524632, "train/cont_pred": 0.9964860591888428, "train/cont_rate": 0.9963515625, "train/dyn_loss_mean": 1.000072021484375, "train/dyn_loss_std": 0.0014175128134374972, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.06006723873130977, "train/extr_critic_critic_opt_grad_steps": 17560.0, "train/extr_critic_critic_opt_loss": 13464.9141875, "train/extr_critic_mag": 0.2621429824829102, "train/extr_critic_max": 0.2621429824829102, "train/extr_critic_mean": 0.26004083728790284, "train/extr_critic_min": 0.2571907577514648, "train/extr_critic_std": 0.0007155433339066803, "train/extr_return_normed_mag": 0.009166478514671325, "train/extr_return_normed_max": 0.009119504690170288, "train/extr_return_normed_mean": 0.0029115083144279196, "train/extr_return_normed_min": -0.0011780585050582887, "train/extr_return_normed_std": 0.001214721409138292, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2669019739627838, "train/extr_return_raw_max": 0.2669019739627838, "train/extr_return_raw_mean": 0.2606939923763275, "train/extr_return_raw_min": 0.25660441076755525, "train/extr_return_raw_std": 0.001214721410535276, "train/extr_reward_mag": 0.004426104545593262, "train/extr_reward_max": 0.004426104545593262, "train/extr_reward_mean": 0.0009281814368441701, "train/extr_reward_min": 2.8467178344726564e-05, "train/extr_reward_std": 0.0005072558829560876, "train/image_loss_mean": 0.19259043061733247, "train/image_loss_std": 0.09970824497938156, "train/model_loss_mean": 0.8374336733818054, "train/model_loss_std": 0.37156748181581495, "train/model_opt_grad_norm": 33.08521908569336, "train/model_opt_grad_steps": 17542.0, "train/model_opt_loss": 2626.9497880859376, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3140.0, "train/policy_entropy_mag": 1.7786377115249634, "train/policy_entropy_max": 1.7786377115249634, "train/policy_entropy_mean": 1.2953174910545349, "train/policy_entropy_min": 0.4977639159560204, "train/policy_entropy_std": 0.18572740089893341, "train/policy_logprob_mag": 4.965890655517578, "train/policy_logprob_max": -0.11586959792673587, "train/policy_logprob_mean": -1.2961678891181945, "train/policy_logprob_min": -4.965890655517578, "train/policy_logprob_std": 0.946139238357544, "train/policy_randomness_mag": 0.9140390257835388, "train/policy_randomness_max": 0.9140390257835388, "train/policy_randomness_mean": 0.6656615538597107, "train/policy_randomness_min": 0.2558000650405884, "train/policy_randomness_std": 0.09544500917196273, "train/post_ent_mag": 83.20500115966797, "train/post_ent_max": 83.20500115966797, "train/post_ent_mean": 82.32022760009765, "train/post_ent_min": 81.6606167602539, "train/post_ent_std": 0.29720430612564086, "train/prior_ent_mag": 84.75900860595704, "train/prior_ent_max": 84.75900860595704, "train/prior_ent_mean": 81.85951953125, "train/prior_ent_min": 78.75983129882812, "train/prior_ent_std": 1.0339842467308045, "train/rep_loss_mean": 1.000072021484375, "train/rep_loss_std": 0.0014175128134374972, "train/reward_avg": 0.0005538798675406724, "train/reward_loss_mean": 0.02072775910794735, "train/reward_loss_std": 0.05773631848394871, "train/reward_max_data": 0.05565633261576295, "train/reward_max_pred": 0.002319872856140137, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.019652623064815997, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.053882092237473, "train/reward_pred": 0.0005429660081863404, "train/reward_rate": 0.0001328125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02627013623714447, "report/cont_loss_std": 0.35747337341308594, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.728952407836914, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003906676080077887, "report/cont_pred": 0.9961037039756775, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.19735898077487946, "report/image_loss_std": 0.11022128164768219, "report/model_loss_mean": 0.8455262184143066, "report/model_loss_std": 0.3766694962978363, "report/post_ent_mag": 83.49299621582031, "report/post_ent_max": 83.49299621582031, "report/post_ent_mean": 82.48331451416016, "report/post_ent_min": 81.78440856933594, "report/post_ent_std": 0.33370107412338257, "report/prior_ent_mag": 84.659912109375, "report/prior_ent_max": 84.659912109375, "report/prior_ent_mean": 82.47189331054688, "report/prior_ent_min": 79.78675079345703, "report/prior_ent_std": 0.8889512419700623, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0005661892355419695, "report/reward_loss_mean": 0.0218970887362957, "report/reward_loss_std": 0.029679028317332268, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.002192854881286621, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.02189709059894085, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0005327309481799603, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.01520187221467495, "eval/cont_loss_std": 0.25643524527549744, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.809682846069336, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003862378653138876, "eval/cont_pred": 0.9961473941802979, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.000064492225647, "eval/dyn_loss_std": 0.002061589155346155, "eval/image_loss_mean": 0.19248349964618683, "eval/image_loss_std": 0.11619964241981506, "eval/model_loss_mean": 0.8104198575019836, "eval/model_loss_std": 0.2769034504890442, "eval/post_ent_mag": 83.36029052734375, "eval/post_ent_max": 83.36029052734375, "eval/post_ent_mean": 82.422119140625, "eval/post_ent_min": 81.72895050048828, "eval/post_ent_std": 0.31744837760925293, "eval/prior_ent_mag": 84.76351928710938, "eval/prior_ent_max": 84.76351928710938, "eval/prior_ent_mean": 82.39567565917969, "eval/prior_ent_min": 79.70196533203125, "eval/prior_ent_std": 0.8421691656112671, "eval/rep_loss_mean": 1.000064492225647, "eval/rep_loss_std": 0.002061589155346155, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0026958086527884007, "eval/reward_loss_std": 0.003271721536293626, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00215911865234375, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0026958086527884007, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00043580273631960154, "eval/reward_rate": 0.0, "replay/size": 292001.0, "replay/inserts": 20048.0, "replay/samples": 20048.0, "replay/insert_wait_avg": 1.2911564810981963e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.920506056460588e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 70416.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1789963732128737e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.22612476348877, "timer/env.step_count": 2506.0, "timer/env.step_total": 5.27547025680542, "timer/env.step_frac": 0.010546171012758895, "timer/env.step_avg": 0.0021051357768577094, "timer/env.step_min": 0.001104116439819336, "timer/env.step_max": 0.008248567581176758, "timer/replay._sample_count": 20048.0, "timer/replay._sample_total": 1352.146358013153, "timer/replay._sample_frac": 2.703070253782646, "timer/replay._sample_avg": 0.0674454488234813, "timer/replay._sample_min": 0.04511284828186035, "timer/replay._sample_max": 0.0938882827758789, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3084.0, "timer/agent.policy_total": 19.770100355148315, "timer/agent.policy_frac": 0.03952232675671585, "timer/agent.policy_avg": 0.0064105383771557445, "timer/agent.policy_min": 0.004820823669433594, "timer/agent.policy_max": 0.010890722274780273, "timer/dataset_train_count": 1253.0, "timer/dataset_train_total": 0.1056969165802002, "timer/dataset_train_frac": 0.00021129827361610634, "timer/dataset_train_avg": 8.435508106959314e-05, "timer/dataset_train_min": 7.367134094238281e-05, "timer/dataset_train_max": 0.0001850128173828125, "timer/agent.train_count": 1253.0, "timer/agent.train_total": 465.0281312465668, "timer/agent.train_frac": 0.9296358351264362, "timer/agent.train_avg": 0.3711317887043629, "timer/agent.train_min": 0.35141897201538086, "timer/agent.train_max": 0.4692211151123047, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.709242582321167, "timer/agent.report_frac": 0.001417843945388704, "timer/agent.report_avg": 0.3546212911605835, "timer/agent.report_min": 0.2726924419403076, "timer/agent.report_max": 0.4365501403808594, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.315376281738281e-05, "timer/dataset_eval_frac": 8.626851074158968e-08, "timer/dataset_eval_avg": 4.315376281738281e-05, "timer/dataset_eval_min": 4.315376281738281e-05, "timer/dataset_eval_max": 4.315376281738281e-05, "fps": 40.07729105204068}
{"step": 292640, "episode/length": 288.0, "episode/score": 0.17977984447770723, "episode/reward_rate": 0.0}
{"step": 292656, "episode/length": 288.0, "episode/score": 0.12909403910816764, "episode/reward_rate": 0.0}
{"step": 292656, "episode/length": 288.0, "episode/score": 0.25275371861380336, "episode/reward_rate": 0.0}
{"step": 292680, "episode/length": 288.0, "episode/score": 0.16349804547803615, "episode/reward_rate": 0.0}
{"step": 292968, "episode/length": 288.0, "episode/score": 0.15400029859756614, "episode/reward_rate": 0.0}
{"step": 293520, "episode/length": 288.0, "episode/score": 0.22176090534617288, "episode/reward_rate": 0.0}
{"step": 293568, "episode/length": 245.0, "episode/score": 0.38662190826562437, "episode/reward_rate": 0.0040650406504065045}
{"step": 294512, "episode/length": 288.0, "episode/score": 0.16559496417141872, "episode/reward_rate": 0.0}
{"step": 294952, "episode/length": 288.0, "episode/score": 0.1991162970031155, "episode/reward_rate": 0.0}
{"step": 294968, "episode/length": 288.0, "episode/score": 0.16446036976901723, "episode/reward_rate": 0.0}
{"step": 294968, "episode/length": 288.0, "episode/score": 0.14413262164384832, "episode/reward_rate": 0.0}
{"step": 294992, "episode/length": 288.0, "episode/score": 0.12964476848947015, "episode/reward_rate": 0.0}
{"step": 295280, "episode/length": 288.0, "episode/score": 0.14792622128379662, "episode/reward_rate": 0.0}
{"step": 295832, "episode/length": 288.0, "episode/score": 0.11851711118674757, "episode/reward_rate": 0.0}
{"step": 295880, "episode/length": 288.0, "episode/score": 0.1706537114865796, "episode/reward_rate": 0.0}
{"step": 296824, "episode/length": 288.0, "episode/score": 0.10512993779298085, "episode/reward_rate": 0.0}
{"step": 297080, "episode/length": 155.0, "episode/score": 0.653248378696162, "episode/reward_rate": 0.00641025641025641}
{"step": 297096, "episode/length": 265.0, "episode/score": 0.3598585327413275, "episode/reward_rate": 0.0037593984962406013}
{"step": 297264, "episode/length": 288.0, "episode/score": 0.20832816295285284, "episode/reward_rate": 0.0}
{"step": 297280, "episode/length": 288.0, "episode/score": 0.14712041575523926, "episode/reward_rate": 0.0}
{"step": 297304, "episode/length": 288.0, "episode/score": 0.14934895315798258, "episode/reward_rate": 0.0}
{"step": 297592, "episode/length": 288.0, "episode/score": 0.1748914031024924, "episode/reward_rate": 0.0}
{"step": 298192, "episode/length": 288.0, "episode/score": 0.18902971960653758, "episode/reward_rate": 0.0}
{"step": 298392, "episode/length": 140.0, "episode/score": 0.6813885011206366, "episode/reward_rate": 0.0070921985815602835}
{"step": 298992, "episode/length": 236.0, "episode/score": 0.3329216519368856, "episode/reward_rate": 0.004219409282700422}
{"step": 299136, "episode/length": 288.0, "episode/score": 0.08241556305574704, "episode/reward_rate": 0.0}
{"step": 299312, "episode/length": 253.0, "episode/score": 0.37041246841266684, "episode/reward_rate": 0.003937007874015748}
{"step": 299392, "episode/length": 288.0, "episode/score": 0.1852720211235237, "episode/reward_rate": 0.0}
{"step": 299616, "episode/length": 288.0, "episode/score": 0.13397583916730582, "episode/reward_rate": 0.0}
{"step": 299904, "episode/length": 288.0, "episode/score": 0.14153037523090006, "episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 286.0, "eval_episode/score": 0.10625000298023224, "eval_episode/reward_rate": 0.003484320557491289}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300504, "episode/length": 288.0, "episode/score": 0.10408481641570688, "episode/reward_rate": 0.0}
{"step": 300704, "episode/length": 288.0, "episode/score": 0.15192207395011792, "episode/reward_rate": 0.0}
{"step": 301304, "episode/length": 288.0, "episode/score": 0.11479319301452051, "episode/reward_rate": 0.0}
{"step": 301448, "episode/length": 288.0, "episode/score": 0.11619287384604604, "episode/reward_rate": 0.0}
{"step": 301624, "episode/length": 288.0, "episode/score": 0.14147128733657155, "episode/reward_rate": 0.0}
{"step": 301704, "episode/length": 288.0, "episode/score": 0.10194801695126898, "episode/reward_rate": 0.0}
{"step": 301928, "episode/length": 288.0, "episode/score": 0.10942484811096165, "episode/reward_rate": 0.0}
{"step": 302216, "episode/length": 288.0, "episode/score": 0.10662556444032134, "episode/reward_rate": 0.0}
{"step": 302816, "episode/length": 288.0, "episode/score": 0.05324977382895213, "episode/reward_rate": 0.0}
{"step": 303016, "episode/length": 288.0, "episode/score": 0.1267028153563956, "episode/reward_rate": 0.0}
{"step": 303600, "episode/length": 268.0, "episode/score": 0.35007711007330045, "episode/reward_rate": 0.0037174721189591076}
{"step": 303616, "episode/length": 288.0, "episode/score": 0.1763650645964958, "episode/reward_rate": 0.0}
{"step": 303936, "episode/length": 288.0, "episode/score": 0.19909786985755318, "episode/reward_rate": 0.0}
{"step": 304016, "episode/length": 288.0, "episode/score": 0.21647654693663299, "episode/reward_rate": 0.0}
{"step": 304240, "episode/length": 288.0, "episode/score": 0.2327151772896059, "episode/reward_rate": 0.0}
{"step": 304528, "episode/length": 288.0, "episode/score": 0.3154526768556707, "episode/reward_rate": 0.0}
{"step": 305128, "episode/length": 288.0, "episode/score": 0.32172042219917785, "episode/reward_rate": 0.0}
{"step": 305328, "episode/length": 288.0, "episode/score": 0.2218682450294409, "episode/reward_rate": 0.0}
{"step": 305912, "episode/length": 288.0, "episode/score": 0.23388333133971173, "episode/reward_rate": 0.0}
{"step": 305928, "episode/length": 288.0, "episode/score": 0.2865017597118822, "episode/reward_rate": 0.0}
{"step": 306248, "episode/length": 288.0, "episode/score": 0.26702717195303194, "episode/reward_rate": 0.0}
{"step": 306328, "episode/length": 288.0, "episode/score": 0.29821570015656107, "episode/reward_rate": 0.0}
{"step": 306552, "episode/length": 288.0, "episode/score": 0.29883285063033327, "episode/reward_rate": 0.0}
{"step": 306840, "episode/length": 288.0, "episode/score": 0.22389575338820578, "episode/reward_rate": 0.0}
{"step": 307440, "episode/length": 288.0, "episode/score": 0.28812460018025376, "episode/reward_rate": 0.0}
{"step": 307640, "episode/length": 288.0, "episode/score": 0.19190781772067567, "episode/reward_rate": 0.0}
{"step": 308224, "episode/length": 288.0, "episode/score": 0.2814644174691239, "episode/reward_rate": 0.0}
{"step": 308240, "episode/length": 288.0, "episode/score": 0.28330640637705073, "episode/reward_rate": 0.0}
{"step": 308560, "episode/length": 288.0, "episode/score": 0.22161032390840774, "episode/reward_rate": 0.0}
{"step": 308640, "episode/length": 288.0, "episode/score": 0.2050852737202149, "episode/reward_rate": 0.0}
{"step": 308864, "episode/length": 288.0, "episode/score": 0.23184538659188547, "episode/reward_rate": 0.0}
{"step": 309152, "episode/length": 288.0, "episode/score": 0.18679625926279186, "episode/reward_rate": 0.0}
{"step": 309752, "episode/length": 288.0, "episode/score": 0.27247194887331716, "episode/reward_rate": 0.0}
{"step": 309952, "episode/length": 288.0, "episode/score": 0.17679653256300298, "episode/reward_rate": 0.0}
{"step": 310024, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 310024, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 310024, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 310024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310536, "episode/length": 288.0, "episode/score": 0.2501332921337962, "episode/reward_rate": 0.0}
{"step": 310552, "episode/length": 288.0, "episode/score": 0.2922833563527547, "episode/reward_rate": 0.0}
{"step": 310872, "episode/length": 288.0, "episode/score": 0.17255368169685426, "episode/reward_rate": 0.0}
{"step": 310952, "episode/length": 288.0, "episode/score": 0.21097996637922733, "episode/reward_rate": 0.0}
{"step": 311016, "episode/length": 57.0, "episode/score": 0.8742681427538628, "episode/reward_rate": 0.017241379310344827}
{"step": 311176, "episode/length": 288.0, "episode/score": 0.26430273276537264, "episode/reward_rate": 0.0}
{"step": 311440, "episode/length": 112.0, "episode/score": 0.7630206080700646, "episode/reward_rate": 0.008849557522123894}
{"step": 311464, "episode/length": 288.0, "episode/score": 0.14954856387930704, "episode/reward_rate": 0.0}
{"step": 312064, "episode/length": 288.0, "episode/score": 0.23733429211279145, "episode/reward_rate": 0.0}
{"step": 312264, "episode/length": 288.0, "episode/score": 0.21477754588181597, "episode/reward_rate": 0.0}
{"step": 312432, "episode/length": 194.0, "episode/score": 0.5272858359678594, "episode/reward_rate": 0.005128205128205128}
{"step": 312537, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1461875, "train/action_min": 0.0, "train/action_std": 1.5930055322647094, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.001600442225812003, "train/actor_opt_grad_steps": 18810.0, "train/actor_opt_loss": 2.0607673199772836, "train/adv_mag": 0.007093065261840821, "train/adv_max": 0.006611100435256958, "train/adv_mean": 0.000918133794231835, "train/adv_min": -0.00381581711769104, "train/adv_std": 0.0013591386242769658, "train/cont_avg": 0.996484375, "train/cont_loss_mean": 0.023323957681655884, "train/cont_loss_std": 0.32407109379768373, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.616702136993408, "train/cont_pos_acc": 0.9999999842643738, "train/cont_pos_loss": 0.0035956876818090677, "train/cont_pred": 0.9964105319976807, "train/cont_rate": 0.996484375, "train/dyn_loss_mean": 1.0000219249725342, "train/dyn_loss_std": 0.0005719280284829437, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.052065371186472476, "train/extr_critic_critic_opt_grad_steps": 18810.0, "train/extr_critic_critic_opt_loss": 13118.713703125, "train/extr_critic_mag": 0.28848828125, "train/extr_critic_max": 0.28848828125, "train/extr_critic_mean": 0.2858477623462677, "train/extr_critic_min": 0.28265923404693605, "train/extr_critic_std": 0.0008167216819711029, "train/extr_return_normed_mag": 0.01053638482093811, "train/extr_return_normed_max": 0.010530744552612305, "train/extr_return_normed_mean": 0.0042286370771471415, "train/extr_return_normed_min": -0.0006420054435729981, "train/extr_return_normed_std": 0.0015481700506061315, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.29306798601150513, "train/extr_return_raw_max": 0.29306798601150513, "train/extr_return_raw_mean": 0.2867658934593201, "train/extr_return_raw_min": 0.28189523601531985, "train/extr_return_raw_std": 0.0015481700520031153, "train/extr_reward_mag": 0.003473799705505371, "train/extr_reward_max": 0.003473799705505371, "train/extr_reward_mean": 0.0010434765531681478, "train/extr_reward_min": 2.7606010437011718e-05, "train/extr_reward_std": 0.0006444649859331549, "train/image_loss_mean": 0.18876874780654906, "train/image_loss_std": 0.10355714404582977, "train/model_loss_mean": 0.8332055373191833, "train/model_loss_std": 0.3662470281124115, "train/model_opt_grad_norm": 33.0988279876709, "train/model_opt_grad_steps": 18791.44, "train/model_opt_loss": 3000.5189052734377, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3600.0, "train/policy_entropy_mag": 1.756870698928833, "train/policy_entropy_max": 1.756870698928833, "train/policy_entropy_mean": 1.0486926717758178, "train/policy_entropy_min": 0.15646866005659105, "train/policy_entropy_std": 0.30171610057353976, "train/policy_logprob_mag": 5.994693000793457, "train/policy_logprob_max": -0.025799093283712864, "train/policy_logprob_mean": -1.047767638206482, "train/policy_logprob_min": -5.994693000793457, "train/policy_logprob_std": 1.0218604903221131, "train/policy_randomness_mag": 0.9028529920578003, "train/policy_randomness_max": 0.9028529920578003, "train/policy_randomness_mean": 0.5389214539527893, "train/policy_randomness_min": 0.08040898975729942, "train/policy_randomness_std": 0.1550514131784439, "train/post_ent_mag": 84.857130859375, "train/post_ent_max": 84.857130859375, "train/post_ent_mean": 83.8611923828125, "train/post_ent_min": 83.18576141357421, "train/post_ent_std": 0.3192971533536911, "train/prior_ent_mag": 85.43268823242188, "train/prior_ent_max": 85.43268823242188, "train/prior_ent_mean": 83.13993469238281, "train/prior_ent_min": 80.74553686523437, "train/prior_ent_std": 0.7918597784042358, "train/rep_loss_mean": 1.0000219249725342, "train/rep_loss_std": 0.0005719280284829437, "train/reward_avg": 0.0005755187515169382, "train/reward_loss_mean": 0.021099659621715547, "train/reward_loss_std": 0.057351995080709456, "train/reward_max_data": 0.0635176670588553, "train/reward_max_pred": 0.002771529197692871, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.01999933109432459, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 7.712815880775452, "train/reward_pred": 0.0005663112821057439, "train/reward_rate": 0.000140625, "train_stats/mean_log_entropy": 1.0117255862553913, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.03180403262376785, "report/cont_loss_std": 0.40870457887649536, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.864591121673584, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003183882450684905, "report/cont_pred": 0.9968231916427612, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0001463890075684, "report/dyn_loss_std": 0.004683956038206816, "report/image_loss_mean": 0.15238036215305328, "report/image_loss_std": 0.09711392968893051, "report/model_loss_mean": 0.8118587732315063, "report/model_loss_std": 0.5585104823112488, "report/post_ent_mag": 85.56785583496094, "report/post_ent_max": 85.56785583496094, "report/post_ent_mean": 84.64869689941406, "report/post_ent_min": 84.03627014160156, "report/post_ent_std": 0.2815169394016266, "report/prior_ent_mag": 86.70938110351562, "report/prior_ent_max": 86.70938110351562, "report/prior_ent_mean": 84.31990051269531, "report/prior_ent_min": 82.38835144042969, "report/prior_ent_std": 0.7211090922355652, "report/rep_loss_mean": 1.0001463890075684, "report/rep_loss_std": 0.004683956038206816, "report/reward_avg": 0.0008691512048244476, "report/reward_loss_mean": 0.027586495503783226, "report/reward_loss_std": 0.21390503644943237, "report/reward_max_data": 0.34937500953674316, "report/reward_max_pred": 0.0043718814849853516, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.020956814289093018, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 6.809751510620117, "report/reward_pred": 0.000640742713585496, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.03781795874238014, "eval/cont_loss_std": 0.45400771498680115, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.949260711669922, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0029764447826892138, "eval/cont_pred": 0.9970303773880005, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0000368356704712, "eval/dyn_loss_std": 0.0007338978466577828, "eval/image_loss_mean": 0.2079191952943802, "eval/image_loss_std": 0.10501757264137268, "eval/model_loss_mean": 0.8483221530914307, "eval/model_loss_std": 0.4632551074028015, "eval/post_ent_mag": 85.50897216796875, "eval/post_ent_max": 85.50897216796875, "eval/post_ent_mean": 84.57269287109375, "eval/post_ent_min": 83.95767211914062, "eval/post_ent_std": 0.27097079157829285, "eval/prior_ent_mag": 87.46882629394531, "eval/prior_ent_max": 87.46882629394531, "eval/prior_ent_mean": 84.27618408203125, "eval/prior_ent_min": 81.78433227539062, "eval/prior_ent_std": 0.689452588558197, "eval/rep_loss_mean": 1.0000368356704712, "eval/rep_loss_std": 0.0007338978466577828, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0025628027506172657, "eval/reward_loss_std": 0.0030072180088609457, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0037080049514770508, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0025628027506172657, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.000458494178019464, "eval/reward_rate": 0.0, "replay/size": 312033.0, "replay/inserts": 20032.0, "replay/samples": 20032.0, "replay/insert_wait_avg": 1.311433105803907e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.052228018117789e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 75040.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2476242124828089e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 499.9962704181671, "timer/env.step_count": 2504.0, "timer/env.step_total": 5.4119038581848145, "timer/env.step_frac": 0.010823888453525103, "timer/env.step_avg": 0.0021613034577415394, "timer/env.step_min": 0.0011298656463623047, "timer/env.step_max": 0.044252634048461914, "timer/replay._sample_count": 20032.0, "timer/replay._sample_total": 1353.022099018097, "timer/replay._sample_frac": 2.7060643830133166, "timer/replay._sample_avg": 0.0675430360931558, "timer/replay._sample_min": 0.00035309791564941406, "timer/replay._sample_max": 0.10632133483886719, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3082.0, "timer/agent.policy_total": 19.695496082305908, "timer/agent.policy_frac": 0.039391285990661024, "timer/agent.policy_avg": 0.006390491915089522, "timer/agent.policy_min": 0.004743099212646484, "timer/agent.policy_max": 0.013100147247314453, "timer/dataset_train_count": 1252.0, "timer/dataset_train_total": 0.10691571235656738, "timer/dataset_train_frac": 0.00021383301972862607, "timer/dataset_train_avg": 8.539593638703465e-05, "timer/dataset_train_min": 6.67572021484375e-05, "timer/dataset_train_max": 0.00021529197692871094, "timer/agent.train_count": 1252.0, "timer/agent.train_total": 465.8437669277191, "timer/agent.train_frac": 0.9316944835170773, "timer/agent.train_avg": 0.3720796860445041, "timer/agent.train_min": 0.3470919132232666, "timer/agent.train_max": 1.184718370437622, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.6623291969299316, "timer/agent.report_frac": 0.0013246682747773276, "timer/agent.report_avg": 0.3311645984649658, "timer/agent.report_min": 0.20005226135253906, "timer/agent.report_max": 0.4622769355773926, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.600120544433594e-05, "timer/dataset_eval_frac": 7.20029479704452e-08, "timer/dataset_eval_avg": 3.600120544433594e-05, "timer/dataset_eval_min": 3.600120544433594e-05, "timer/dataset_eval_max": 3.600120544433594e-05, "fps": 40.06348989138266}
{"step": 313080, "episode/length": 237.0, "episode/score": 0.38527034243361413, "episode/reward_rate": 0.004201680672268907}
{"step": 313232, "episode/length": 120.0, "episode/score": 0.6893594274752104, "episode/reward_rate": 0.008264462809917356}
{"step": 313264, "episode/length": 288.0, "episode/score": 0.17195168026728425, "episode/reward_rate": 0.0}
{"step": 313328, "episode/length": 288.0, "episode/score": 0.12867426161255935, "episode/reward_rate": 0.0}
{"step": 313752, "episode/length": 288.0, "episode/score": 0.1558719633549117, "episode/reward_rate": 0.0}
{"step": 313776, "episode/length": 288.0, "episode/score": 0.12146302538803866, "episode/reward_rate": 0.0}
{"step": 314376, "episode/length": 288.0, "episode/score": 0.1693949291144463, "episode/reward_rate": 0.0}
{"step": 314744, "episode/length": 184.0, "episode/score": 0.6027150898710261, "episode/reward_rate": 0.005405405405405406}
{"step": 314744, "episode/length": 288.0, "episode/score": 0.14445881163544527, "episode/reward_rate": 0.0}
{"step": 315320, "episode/length": 195.0, "episode/score": 0.5801292010056613, "episode/reward_rate": 0.00510204081632653}
{"step": 315392, "episode/length": 288.0, "episode/score": 0.23270647743697737, "episode/reward_rate": 0.0}
{"step": 315544, "episode/length": 288.0, "episode/score": 0.1719511398572422, "episode/reward_rate": 0.0}
{"step": 315640, "episode/length": 288.0, "episode/score": 0.23351092841835452, "episode/reward_rate": 0.0}
{"step": 315768, "episode/length": 127.0, "episode/score": 0.7491531493773209, "episode/reward_rate": 0.0078125}
{"step": 315832, "episode/length": 35.0, "episode/score": 0.9161964586292015, "episode/reward_rate": 0.027777777777777776}
{"step": 315984, "episode/length": 275.0, "episode/score": 0.3505002542352713, "episode/reward_rate": 0.0036231884057971015}
{"step": 316064, "episode/length": 83.0, "episode/score": 0.8161067680057386, "episode/reward_rate": 0.011904761904761904}
{"step": 316512, "episode/length": 108.0, "episode/score": 0.7494254823477604, "episode/reward_rate": 0.009174311926605505}
{"step": 316552, "episode/length": 153.0, "episode/score": 0.656965082856459, "episode/reward_rate": 0.006493506493506494}
{"step": 316688, "episode/length": 288.0, "episode/score": 0.20282506614694285, "episode/reward_rate": 0.0}
{"step": 316848, "episode/length": 262.0, "episode/score": 0.39497448594522666, "episode/reward_rate": 0.0038022813688212928}
{"step": 316944, "episode/length": 146.0, "episode/score": 0.6623172474219245, "episode/reward_rate": 0.006802721088435374}
{"step": 317104, "episode/length": 19.0, "episode/score": 0.9737853205388092, "episode/reward_rate": 0.05}
{"step": 318144, "episode/length": 288.0, "episode/score": 0.18621595963850268, "episode/reward_rate": 0.0}
{"step": 318296, "episode/length": 288.0, "episode/score": 0.1809355371806305, "episode/reward_rate": 0.0}
{"step": 318376, "episode/length": 288.0, "episode/score": 0.2275566690918822, "episode/reward_rate": 0.0}
{"step": 318600, "episode/length": 255.0, "episode/score": 0.336080401230447, "episode/reward_rate": 0.00390625}
{"step": 318776, "episode/length": 78.0, "episode/score": 0.8116207762477643, "episode/reward_rate": 0.012658227848101266}
{"step": 318824, "episode/length": 288.0, "episode/score": 0.23517744887158187, "episode/reward_rate": 0.0}
{"step": 318872, "episode/length": 61.0, "episode/score": 0.8542251711278368, "episode/reward_rate": 0.016129032258064516}
{"step": 318952, "episode/length": 21.0, "episode/score": 0.9670522094725129, "episode/reward_rate": 0.045454545454545456}
{"step": 319000, "episode/length": 288.0, "episode/score": 0.15237112825752774, "episode/reward_rate": 0.0}
{"step": 319160, "episode/length": 288.0, "episode/score": 0.18094912036849564, "episode/reward_rate": 0.0}
{"step": 319344, "episode/length": 92.0, "episode/score": 0.7641063161395323, "episode/reward_rate": 0.010752688172043012}
{"step": 319416, "episode/length": 288.0, "episode/score": 0.16433008800322568, "episode/reward_rate": 0.0}
{"step": 319488, "episode/length": 66.0, "episode/score": 0.8456828777511873, "episode/reward_rate": 0.014925373134328358}
{"step": 319488, "episode/length": 40.0, "episode/score": 0.9040445580549203, "episode/reward_rate": 0.024390243902439025}
{"step": 319744, "episode/length": 92.0, "episode/score": 0.7795198011469893, "episode/reward_rate": 0.010752688172043012}
{"step": 319944, "episode/length": 133.0, "episode/score": 0.6723941562654545, "episode/reward_rate": 0.007462686567164179}
{"step": 320008, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 320008, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 320008, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 320008, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 320008, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 320008, "eval_episode/length": 207.0, "eval_episode/score": 0.3531250059604645, "eval_episode/reward_rate": 0.004807692307692308}
{"step": 320008, "eval_episode/length": 242.0, "eval_episode/score": 0.24375000596046448, "eval_episode/reward_rate": 0.00411522633744856}
{"step": 320008, "eval_episode/length": 223.0, "eval_episode/score": 0.3031249940395355, "eval_episode/reward_rate": 0.004464285714285714}
{"step": 320224, "episode/length": 91.0, "episode/score": 0.7538303373860344, "episode/reward_rate": 0.010869565217391304}
{"step": 320560, "episode/length": 133.0, "episode/score": 0.6470775949699146, "episode/reward_rate": 0.007462686567164179}
{"step": 320608, "episode/length": 288.0, "episode/score": 0.12898805577651729, "episode/reward_rate": 0.0}
{"step": 320808, "episode/length": 132.0, "episode/score": 0.6112007465735587, "episode/reward_rate": 0.007518796992481203}
{"step": 321136, "episode/length": 288.0, "episode/score": 0.12277453968158625, "episode/reward_rate": 0.0}
{"step": 321248, "episode/length": 85.0, "episode/score": 0.7952783362427454, "episode/reward_rate": 0.011627906976744186}
{"step": 321656, "episode/length": 288.0, "episode/score": 0.10625869319437697, "episode/reward_rate": 0.0}
{"step": 321728, "episode/length": 288.0, "episode/score": 0.09435642658490906, "episode/reward_rate": 0.0}
{"step": 322232, "episode/length": 136.0, "episode/score": 0.6468265843329846, "episode/reward_rate": 0.0072992700729927005}
{"step": 322256, "episode/length": 65.0, "episode/score": 0.8649257306105937, "episode/reward_rate": 0.015151515151515152}
{"step": 322256, "episode/length": 288.0, "episode/score": 0.10566655203911068, "episode/reward_rate": 0.0}
{"step": 322536, "episode/length": 288.0, "episode/score": 0.08347006623205289, "episode/reward_rate": 0.0}
{"step": 322728, "episode/length": 23.0, "episode/score": 0.9545845986376662, "episode/reward_rate": 0.041666666666666664}
{"step": 322920, "episode/length": 288.0, "episode/score": 0.21217426529688055, "episode/reward_rate": 0.0}
{"step": 323120, "episode/length": 288.0, "episode/score": 0.1151923843970053, "episode/reward_rate": 0.0}
{"step": 323464, "episode/length": 150.0, "episode/score": 0.6478681431535733, "episode/reward_rate": 0.006622516556291391}
{"step": 323496, "episode/length": 46.0, "episode/score": 0.9038699316606653, "episode/reward_rate": 0.02127659574468085}
{"step": 323520, "episode/length": 74.0, "episode/score": 0.8419660368890618, "episode/reward_rate": 0.013333333333333334}
{"step": 323544, "episode/length": 235.0, "episode/score": 0.3882243584300795, "episode/reward_rate": 0.00423728813559322}
{"step": 323560, "episode/length": 288.0, "episode/score": 0.17191994766517382, "episode/reward_rate": 0.0}
{"step": 323896, "episode/length": 43.0, "episode/score": 0.9115972147214961, "episode/reward_rate": 0.022727272727272728}
{"step": 324096, "episode/length": 71.0, "episode/score": 0.8495972472037465, "episode/reward_rate": 0.013888888888888888}
{"step": 324208, "episode/length": 184.0, "episode/score": 0.5676761807371804, "episode/reward_rate": 0.005405405405405406}
{"step": 324544, "episode/length": 288.0, "episode/score": 0.153452186495997, "episode/reward_rate": 0.0}
{"step": 324568, "episode/length": 288.0, "episode/score": 0.1801799195145577, "episode/reward_rate": 0.0}
{"step": 324840, "episode/length": 117.0, "episode/score": 0.7382974839247254, "episode/reward_rate": 0.00847457627118644}
{"step": 324936, "episode/length": 90.0, "episode/score": 0.8044067847486076, "episode/reward_rate": 0.01098901098901099}
{"step": 324976, "episode/length": 188.0, "episode/score": 0.535529977027636, "episode/reward_rate": 0.005291005291005291}
{"step": 325080, "episode/length": 66.0, "episode/score": 0.8432092774064586, "episode/reward_rate": 0.014925373134328358}
{"step": 325136, "episode/length": 19.0, "episode/score": 0.957247153044591, "episode/reward_rate": 0.05}
{"step": 325144, "episode/length": 205.0, "episode/score": 0.47883172064211976, "episode/reward_rate": 0.0048543689320388345}
{"step": 325256, "episode/length": 211.0, "episode/score": 0.4781915741209559, "episode/reward_rate": 0.0047169811320754715}
{"step": 325320, "episode/length": 152.0, "episode/score": 0.6448547927593609, "episode/reward_rate": 0.006535947712418301}
{"step": 325344, "episode/length": 24.0, "episode/score": 0.9470104637075565, "episode/reward_rate": 0.04}
{"step": 325480, "episode/length": 113.0, "episode/score": 0.7428861149583099, "episode/reward_rate": 0.008771929824561403}
{"step": 325864, "episode/length": 97.0, "episode/score": 0.753849721305869, "episode/reward_rate": 0.01020408163265306}
{"step": 326312, "episode/length": 131.0, "episode/score": 0.6429450803802865, "episode/reward_rate": 0.007575757575757576}
{"step": 326408, "episode/length": 132.0, "episode/score": 0.6658942544499951, "episode/reward_rate": 0.007518796992481203}
{"step": 326512, "episode/length": 148.0, "episode/score": 0.6311508019466601, "episode/reward_rate": 0.006711409395973154}
{"step": 326712, "episode/length": 221.0, "episode/score": 0.4169507627962048, "episode/reward_rate": 0.0045045045045045045}
{"step": 326832, "episode/length": 64.0, "episode/score": 0.8313026644736965, "episode/reward_rate": 0.015384615384615385}
{"step": 327152, "episode/length": 288.0, "episode/score": 0.11452614737436306, "episode/reward_rate": 0.0}
{"step": 327264, "episode/length": 265.0, "episode/score": 0.26515024013428956, "episode/reward_rate": 0.0037593984962406013}
{"step": 327472, "episode/length": 132.0, "episode/score": 0.6480882866430875, "episode/reward_rate": 0.007518796992481203}
{"step": 327648, "episode/length": 47.0, "episode/score": 0.876030751090866, "episode/reward_rate": 0.020833333333333332}
{"step": 327712, "episode/length": 230.0, "episode/score": 0.38717017339922677, "episode/reward_rate": 0.004329004329004329}
{"step": 327792, "episode/length": 288.0, "episode/score": 0.10317820976865733, "episode/reward_rate": 0.0}
{"step": 327816, "episode/length": 82.0, "episode/score": 0.7708956611124904, "episode/reward_rate": 0.012048192771084338}
{"step": 328824, "episode/length": 288.0, "episode/score": 0.08460572095316365, "episode/reward_rate": 0.0}
{"step": 329024, "episode/length": 288.0, "episode/score": 0.12406628003213882, "episode/reward_rate": 0.0}
{"step": 329144, "episode/length": 288.0, "episode/score": 0.10194102781213132, "episode/reward_rate": 0.0}
{"step": 329784, "episode/length": 288.0, "episode/score": 0.03768139567955586, "episode/reward_rate": 0.0}
{"step": 329800, "episode/length": 121.0, "episode/score": 0.6787902292296621, "episode/reward_rate": 0.00819672131147541}
{"step": 329960, "episode/length": 288.0, "episode/score": 0.09707519468850023, "episode/reward_rate": 0.0}
{"step": 330024, "episode/length": 288.0, "episode/score": 0.0836451686275268, "episode/reward_rate": 0.0}
{"step": 330096, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 330096, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 330096, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 330096, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 330096, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 330096, "eval_episode/length": 186.0, "eval_episode/score": 0.41874998807907104, "eval_episode/reward_rate": 0.0053475935828877}
{"step": 330096, "eval_episode/length": 204.0, "eval_episode/score": 0.36250001192092896, "eval_episode/reward_rate": 0.004878048780487805}
{"step": 330096, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 330104, "episode/length": 288.0, "episode/score": 0.07940953766421899, "episode/reward_rate": 0.0}
{"step": 330128, "episode/length": 288.0, "episode/score": 0.11304871544427897, "episode/reward_rate": 0.0}
{"step": 330216, "episode/length": 148.0, "episode/score": 0.5763256907548566, "episode/reward_rate": 0.006711409395973154}
{"step": 330232, "episode/length": 53.0, "episode/score": 0.8674787772270065, "episode/reward_rate": 0.018518518518518517}
{"step": 330464, "episode/length": 84.0, "episode/score": 0.7772013140752279, "episode/reward_rate": 0.011764705882352941}
{"step": 330560, "episode/length": 56.0, "episode/score": 0.8591091702360245, "episode/reward_rate": 0.017543859649122806}
{"step": 330880, "episode/length": 114.0, "episode/score": 0.6786542305400189, "episode/reward_rate": 0.008695652173913044}
{"step": 331168, "episode/length": 129.0, "episode/score": 0.6371699833706543, "episode/reward_rate": 0.007692307692307693}
{"step": 331216, "episode/length": 148.0, "episode/score": 0.5827063122814025, "episode/reward_rate": 0.006711409395973154}
{"step": 331256, "episode/length": 98.0, "episode/score": 0.7215601254579269, "episode/reward_rate": 0.010101010101010102}
{"step": 331456, "episode/length": 288.0, "episode/score": 0.0781273947104637, "episode/reward_rate": 0.0}
{"step": 331760, "episode/length": 67.0, "episode/score": 0.8089667272072347, "episode/reward_rate": 0.014705882352941176}
{"step": 331928, "episode/length": 130.0, "episode/score": 0.6591542646791595, "episode/reward_rate": 0.007633587786259542}
{"step": 332120, "episode/length": 235.0, "episode/score": 0.3554041028194206, "episode/reward_rate": 0.00423728813559322}
{"step": 332256, "episode/length": 124.0, "episode/score": 0.642174787679096, "episode/reward_rate": 0.008}
{"step": 332392, "episode/length": 152.0, "episode/score": 0.551301771361068, "episode/reward_rate": 0.006535947712418301}
{"step": 332528, "episode/length": 288.0, "episode/score": 0.07685002810490005, "episode/reward_rate": 0.0}
{"step": 332617, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.344455779544891, "train/action_min": 0.0, "train/action_std": 1.6309999388361733, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.002479014615158713, "train/actor_opt_grad_steps": 20065.0, "train/actor_opt_loss": 15.002047381703816, "train/adv_mag": 0.01874467990701161, "train/adv_max": 0.018584717833806597, "train/adv_mean": 0.004457648136683438, "train/adv_min": -0.0052435847501906135, "train/adv_std": 0.003255723900760391, "train/cont_avg": 0.9965045262896826, "train/cont_loss_mean": 0.022842581605627424, "train/cont_loss_std": 0.3131597011686406, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.490914168905039, "train/cont_pos_acc": 0.9999999858084179, "train/cont_pos_loss": 0.0036006827103269713, "train/cont_pred": 0.9964029954539405, "train/cont_rate": 0.9965045262896826, "train/dyn_loss_mean": 1.0000107505964855, "train/dyn_loss_std": 0.0003207265880995519, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.3404892547266735, "train/extr_critic_critic_opt_grad_steps": 20065.0, "train/extr_critic_critic_opt_loss": 8337.228972904266, "train/extr_critic_mag": 0.3390584427212912, "train/extr_critic_max": 0.3390584427212912, "train/extr_critic_mean": 0.3352129390788457, "train/extr_critic_min": 0.3295389773353698, "train/extr_critic_std": 0.0015376283240223687, "train/extr_return_normed_mag": 0.028600407025170704, "train/extr_return_normed_max": 0.028597527080112033, "train/extr_return_normed_mean": 0.013151329220226405, "train/extr_return_normed_min": 0.0028510883687034487, "train/extr_return_normed_std": 0.0037606499381437307, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.35511677203670383, "train/extr_return_raw_max": 0.35511677203670383, "train/extr_return_raw_mean": 0.3396705918841892, "train/extr_return_raw_min": 0.3293703333252952, "train/extr_return_raw_std": 0.0037606499464591108, "train/extr_reward_mag": 0.011653601177155025, "train/extr_reward_max": 0.011653601177155025, "train/extr_reward_mean": 0.0016207013386375611, "train/extr_reward_min": 2.4578874073331317e-05, "train/extr_reward_std": 0.0022428080602179446, "train/image_loss_mean": 0.18274367470589895, "train/image_loss_std": 0.10518477910331317, "train/model_loss_mean": 0.8278940830911908, "train/model_loss_std": 0.380020686085262, "train/model_opt_grad_norm": 31.114553171490865, "train/model_opt_grad_steps": 20045.277777777777, "train/model_opt_loss": 2151.3107096354165, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2599.2063492063494, "train/policy_entropy_mag": 1.683262256402818, "train/policy_entropy_max": 1.683262256402818, "train/policy_entropy_mean": 0.6285627917164848, "train/policy_entropy_min": 0.07630569795294413, "train/policy_entropy_std": 0.33607749593636344, "train/policy_logprob_mag": 6.452421120234898, "train/policy_logprob_max": -0.010653047053705133, "train/policy_logprob_mean": -0.6291008338568702, "train/policy_logprob_min": -6.452421120234898, "train/policy_logprob_std": 0.9535539192812783, "train/policy_randomness_mag": 0.865025737455913, "train/policy_randomness_max": 0.865025737455913, "train/policy_randomness_mean": 0.32301739283970426, "train/policy_randomness_min": 0.039213373961429744, "train/policy_randomness_std": 0.17270967760492886, "train/post_ent_mag": 83.81211229354616, "train/post_ent_max": 83.81211229354616, "train/post_ent_mean": 82.8616692679269, "train/post_ent_min": 82.1948626684764, "train/post_ent_std": 0.288536839660198, "train/prior_ent_mag": 84.4186433459085, "train/prior_ent_max": 84.4186433459085, "train/prior_ent_mean": 82.0895641871861, "train/prior_ent_min": 79.67398955330016, "train/prior_ent_std": 0.798684627290756, "train/rep_loss_mean": 1.0000107505964855, "train/rep_loss_std": 0.0003207265880995519, "train/reward_avg": 0.0006824711643506787, "train/reward_loss_mean": 0.022301353676806367, "train/reward_loss_std": 0.0846116483980228, "train/reward_max_data": 0.16886022896875466, "train/reward_max_pred": 0.006932455395895337, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.020106315110174435, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 6.427509634118331, "train/reward_pred": 0.0006126083326452072, "train/reward_rate": 0.0003410218253968254, "train_stats/mean_log_entropy": 0.6061272997039933, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02509824000298977, "report/cont_loss_std": 0.34850412607192993, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.568700790405273, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0033586223144084215, "report/cont_pred": 0.9966459274291992, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.17739476263523102, "report/image_loss_std": 0.10253655165433884, "report/model_loss_mean": 0.8257972002029419, "report/model_loss_std": 0.3634161353111267, "report/post_ent_mag": 83.4237060546875, "report/post_ent_max": 83.4237060546875, "report/post_ent_mean": 82.4969482421875, "report/post_ent_min": 81.83111572265625, "report/post_ent_std": 0.278730183839798, "report/prior_ent_mag": 84.13943481445312, "report/prior_ent_max": 84.13943481445312, "report/prior_ent_mean": 81.67575073242188, "report/prior_ent_min": 79.43829345703125, "report/prior_ent_std": 0.7678000926971436, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0005891782348044217, "report/reward_loss_mean": 0.023304160684347153, "report/reward_loss_std": 0.029094675555825233, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.00957179069519043, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.023304160684347153, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0008232420077547431, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014921143651008606, "eval/cont_loss_std": 0.264031320810318, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.973405838012695, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0032607039902359247, "eval/cont_pred": 0.9967465400695801, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1927608847618103, "eval/image_loss_std": 0.1087263971567154, "eval/model_loss_mean": 0.8108763098716736, "eval/model_loss_std": 0.2798176109790802, "eval/post_ent_mag": 83.21916198730469, "eval/post_ent_max": 83.21916198730469, "eval/post_ent_mean": 82.44390869140625, "eval/post_ent_min": 81.8330078125, "eval/post_ent_std": 0.25335562229156494, "eval/prior_ent_mag": 83.9186782836914, "eval/prior_ent_max": 83.9186782836914, "eval/prior_ent_mean": 81.5167236328125, "eval/prior_ent_min": 79.50341796875, "eval/prior_ent_std": 0.7245933413505554, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0031943004578351974, "eval/reward_loss_std": 0.003397960215806961, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.005269169807434082, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0031943004578351974, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0005528981564566493, "eval/reward_rate": 0.0, "replay/size": 332113.0, "replay/inserts": 20080.0, "replay/samples": 20080.0, "replay/insert_wait_avg": 1.3167995855627781e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.191284058103523e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 78912.0, "eval_replay/inserts": 3872.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2505276144043474e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.3368937969208, "timer/env.step_count": 2510.0, "timer/env.step_total": 5.511110305786133, "timer/env.step_frac": 0.011014798976673125, "timer/env.step_avg": 0.002195661476408818, "timer/env.step_min": 0.0011148452758789062, "timer/env.step_max": 0.00890350341796875, "timer/replay._sample_count": 20080.0, "timer/replay._sample_total": 1352.3964064121246, "timer/replay._sample_frac": 2.7029715841043735, "timer/replay._sample_avg": 0.06735041864602215, "timer/replay._sample_min": 0.000316619873046875, "timer/replay._sample_max": 0.09333682060241699, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2994.0, "timer/agent.policy_total": 19.20275640487671, "timer/agent.policy_frac": 0.0383796530756551, "timer/agent.policy_avg": 0.0064137462942139975, "timer/agent.policy_min": 0.004906177520751953, "timer/agent.policy_max": 0.011603116989135742, "timer/dataset_train_count": 1255.0, "timer/dataset_train_total": 0.10510659217834473, "timer/dataset_train_frac": 0.00021007164069137367, "timer/dataset_train_avg": 8.375027265206751e-05, "timer/dataset_train_min": 5.9604644775390625e-05, "timer/dataset_train_max": 0.00034356117248535156, "timer/agent.train_count": 1255.0, "timer/agent.train_total": 467.08592200279236, "timer/agent.train_frac": 0.9335428344254292, "timer/agent.train_avg": 0.37218001753210544, "timer/agent.train_min": 0.3510105609893799, "timer/agent.train_max": 0.4223909378051758, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.6880614757537842, "timer/agent.report_frac": 0.0013751963612602552, "timer/agent.report_avg": 0.3440307378768921, "timer/agent.report_min": 0.3187580108642578, "timer/agent.report_max": 0.36930346488952637, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.62396240234375e-05, "timer/dataset_eval_frac": 7.243044531140775e-08, "timer/dataset_eval_avg": 3.62396240234375e-05, "timer/dataset_eval_min": 3.62396240234375e-05, "timer/dataset_eval_max": 3.62396240234375e-05, "fps": 40.13230417245661}
{"step": 332648, "episode/length": 148.0, "episode/score": 0.6191519897770377, "episode/reward_rate": 0.006711409395973154}
{"step": 332872, "episode/length": 288.0, "episode/score": 0.0824772733374175, "episode/reward_rate": 0.0}
{"step": 332880, "episode/length": 77.0, "episode/score": 0.8069111971778966, "episode/reward_rate": 0.01282051282051282}
{"step": 333976, "episode/length": 231.0, "episode/score": 0.35764762424639684, "episode/reward_rate": 0.004310344827586207}
{"step": 334072, "episode/length": 148.0, "episode/score": 0.5916634909630147, "episode/reward_rate": 0.006711409395973154}
{"step": 334072, "episode/length": 288.0, "episode/score": 0.07199518600253896, "episode/reward_rate": 0.0}
{"step": 334104, "episode/length": 213.0, "episode/score": 0.4234508193132456, "episode/reward_rate": 0.004672897196261682}
{"step": 334208, "episode/length": 209.0, "episode/score": 0.4698878818743424, "episode/reward_rate": 0.004761904761904762}
{"step": 334240, "episode/length": 288.0, "episode/score": 0.13077185730617202, "episode/reward_rate": 0.0}
{"step": 334592, "episode/length": 214.0, "episode/score": 0.392889433954565, "episode/reward_rate": 0.004651162790697674}
{"step": 334816, "episode/length": 104.0, "episode/score": 0.717281396031126, "episode/reward_rate": 0.009523809523809525}
{"step": 334960, "episode/length": 288.0, "episode/score": 0.11212083947668816, "episode/reward_rate": 0.0}
{"step": 335192, "episode/length": 46.0, "episode/score": 0.8876694793592605, "episode/reward_rate": 0.02127659574468085}
{"step": 335520, "episode/length": 180.0, "episode/score": 0.47198139733455946, "episode/reward_rate": 0.0055248618784530384}
{"step": 335768, "episode/length": 146.0, "episode/score": 0.5712646890704605, "episode/reward_rate": 0.006802721088435374}
{"step": 336384, "episode/length": 288.0, "episode/score": 0.04188481456367299, "episode/reward_rate": 0.0}
{"step": 336416, "episode/length": 288.0, "episode/score": 0.05455661244747034, "episode/reward_rate": 0.0}
{"step": 336480, "episode/length": 88.0, "episode/score": 0.7804308208710609, "episode/reward_rate": 0.011235955056179775}
{"step": 336520, "episode/length": 288.0, "episode/score": 0.07346657645354071, "episode/reward_rate": 0.0}
{"step": 336552, "episode/length": 288.0, "episode/score": 0.0731923591711734, "episode/reward_rate": 0.0}
{"step": 336712, "episode/length": 28.0, "episode/score": 0.9287060371887037, "episode/reward_rate": 0.034482758620689655}
{"step": 336712, "episode/length": 189.0, "episode/score": 0.4466976570829502, "episode/reward_rate": 0.005263157894736842}
{"step": 336808, "episode/length": 160.0, "episode/score": 0.5443148041493941, "episode/reward_rate": 0.006211180124223602}
{"step": 337272, "episode/length": 288.0, "episode/score": 0.05097102771429718, "episode/reward_rate": 0.0}
{"step": 337488, "episode/length": 120.0, "episode/score": 0.6740230823808133, "episode/reward_rate": 0.008264462809917356}
{"step": 337576, "episode/length": 107.0, "episode/score": 0.7248063219275309, "episode/reward_rate": 0.009259259259259259}
{"step": 337872, "episode/length": 36.0, "episode/score": 0.8933793016257141, "episode/reward_rate": 0.02702702702702703}
{"step": 338120, "episode/length": 175.0, "episode/score": 0.4811526056342359, "episode/reward_rate": 0.005681818181818182}
{"step": 338144, "episode/length": 108.0, "episode/score": 0.6921976541498225, "episode/reward_rate": 0.009174311926605505}
{"step": 338208, "episode/length": 89.0, "episode/score": 0.7686053182362684, "episode/reward_rate": 0.011111111111111112}
{"step": 338216, "episode/length": 42.0, "episode/score": 0.8873736232545753, "episode/reward_rate": 0.023255813953488372}
{"step": 338352, "episode/length": 192.0, "episode/score": 0.4567104982414776, "episode/reward_rate": 0.0051813471502590676}
{"step": 338608, "episode/length": 60.0, "episode/score": 0.837437442013254, "episode/reward_rate": 0.01639344262295082}
{"step": 338648, "episode/length": 282.0, "episode/score": 0.16494824495788407, "episode/reward_rate": 0.0035335689045936395}
{"step": 338728, "episode/length": 288.0, "episode/score": 0.11505967784859195, "episode/reward_rate": 0.0}
{"step": 338824, "episode/length": 21.0, "episode/score": 0.970943767708377, "episode/reward_rate": 0.045454545454545456}
{"step": 338864, "episode/length": 288.0, "episode/score": 0.09631886274155477, "episode/reward_rate": 0.0}
{"step": 338904, "episode/length": 86.0, "episode/score": 0.7983448326253892, "episode/reward_rate": 0.011494252873563218}
{"step": 339016, "episode/length": 108.0, "episode/score": 0.7433213884424958, "episode/reward_rate": 0.009174311926605505}
{"step": 339064, "episode/length": 41.0, "episode/score": 0.9281372941295558, "episode/reward_rate": 0.023809523809523808}
{"step": 339200, "episode/length": 41.0, "episode/score": 0.9069600817911123, "episode/reward_rate": 0.023809523809523808}
{"step": 339480, "episode/length": 51.0, "episode/score": 0.8699976983916713, "episode/reward_rate": 0.019230769230769232}
{"step": 339520, "episode/length": 62.0, "episode/score": 0.8800331154525338, "episode/reward_rate": 0.015873015873015872}
{"step": 340080, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 340080, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 340080, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 340080, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 340080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340184, "episode/length": 169.0, "episode/score": 0.5869038646669651, "episode/reward_rate": 0.0058823529411764705}
{"step": 340328, "episode/length": 105.0, "episode/score": 0.7614552334275686, "episode/reward_rate": 0.009433962264150943}
{"step": 340392, "episode/length": 185.0, "episode/score": 0.5524444522225167, "episode/reward_rate": 0.005376344086021506}
{"step": 340528, "episode/length": 288.0, "episode/score": 0.10518758527098271, "episode/reward_rate": 0.0}
{"step": 340664, "episode/length": 288.0, "episode/score": 0.12721054618845073, "episode/reward_rate": 0.0}
{"step": 340728, "episode/length": 24.0, "episode/score": 0.9470655274130877, "episode/reward_rate": 0.04}
{"step": 340920, "episode/length": 288.0, "episode/score": 0.12150208099984638, "episode/reward_rate": 0.0}
{"step": 341000, "episode/length": 75.0, "episode/score": 0.8003029614615116, "episode/reward_rate": 0.013157894736842105}
{"step": 341376, "episode/length": 148.0, "episode/score": 0.5926819922219693, "episode/reward_rate": 0.006711409395973154}
{"step": 341512, "episode/length": 288.0, "episode/score": 0.09825623091228408, "episode/reward_rate": 0.0}
{"step": 341624, "episode/length": 87.0, "episode/score": 0.7815820647945202, "episode/reward_rate": 0.011363636363636364}
{"step": 341728, "episode/length": 174.0, "episode/score": 0.530383771463903, "episode/reward_rate": 0.005714285714285714}
{"step": 341824, "episode/length": 102.0, "episode/score": 0.7289477152387462, "episode/reward_rate": 0.009708737864077669}
{"step": 341832, "episode/length": 288.0, "episode/score": 0.09732773786981852, "episode/reward_rate": 0.0}
{"step": 341936, "episode/length": 158.0, "episode/score": 0.5696650707182016, "episode/reward_rate": 0.006289308176100629}
{"step": 342144, "episode/length": 95.0, "episode/score": 0.754980251415418, "episode/reward_rate": 0.010416666666666666}
{"step": 342368, "episode/length": 53.0, "episode/score": 0.896500444129515, "episode/reward_rate": 0.018518518518518517}
{"step": 342576, "episode/length": 93.0, "episode/score": 0.7688948195659577, "episode/reward_rate": 0.010638297872340425}
{"step": 342688, "episode/length": 132.0, "episode/score": 0.7036672626315976, "episode/reward_rate": 0.007518796992481203}
{"step": 342920, "episode/length": 96.0, "episode/score": 0.7978621778183879, "episode/reward_rate": 0.010309278350515464}
{"step": 343008, "episode/length": 53.0, "episode/score": 0.8727379883803223, "episode/reward_rate": 0.018518518518518517}
{"step": 343040, "episode/length": 288.0, "episode/score": 0.15100045722397226, "episode/reward_rate": 0.0}
{"step": 343080, "episode/length": 88.0, "episode/score": 0.8043501346191988, "episode/reward_rate": 0.011235955056179775}
{"step": 343224, "episode/length": 66.0, "episode/score": 0.8361461048370984, "episode/reward_rate": 0.014925373134328358}
{"step": 343384, "episode/length": 42.0, "episode/score": 0.9051300677028848, "episode/reward_rate": 0.023255813953488372}
{"step": 343776, "episode/length": 86.0, "episode/score": 0.8032538994407332, "episode/reward_rate": 0.011494252873563218}
{"step": 343824, "episode/length": 288.0, "episode/score": 0.16288834896840854, "episode/reward_rate": 0.0}
{"step": 344040, "episode/length": 288.0, "episode/score": 0.15744391798193647, "episode/reward_rate": 0.0}
{"step": 344144, "episode/length": 288.0, "episode/score": 0.15752611521293147, "episode/reward_rate": 0.0}
{"step": 344224, "episode/length": 124.0, "episode/score": 0.7222694338656765, "episode/reward_rate": 0.008}
{"step": 344232, "episode/length": 152.0, "episode/score": 0.6346171695863632, "episode/reward_rate": 0.006535947712418301}
{"step": 344352, "episode/length": 71.0, "episode/score": 0.8454768915671593, "episode/reward_rate": 0.013888888888888888}
{"step": 344624, "episode/length": 49.0, "episode/score": 0.9000187929295862, "episode/reward_rate": 0.02}
{"step": 344632, "episode/length": 60.0, "episode/score": 0.8600942373977887, "episode/reward_rate": 0.01639344262295082}
{"step": 344920, "episode/length": 70.0, "episode/score": 0.8362025741434991, "episode/reward_rate": 0.014084507042253521}
{"step": 345024, "episode/length": 49.0, "episode/score": 0.8908065389705371, "episode/reward_rate": 0.02}
{"step": 345232, "episode/length": 288.0, "episode/score": 0.184549498272645, "episode/reward_rate": 0.0}
{"step": 345696, "episode/length": 288.0, "episode/score": 0.14720826755592498, "episode/reward_rate": 0.0}
{"step": 345816, "episode/length": 98.0, "episode/score": 0.7829780200390815, "episode/reward_rate": 0.010101010101010102}
{"step": 346064, "episode/length": 142.0, "episode/score": 0.6119603942465801, "episode/reward_rate": 0.006993006993006993}
{"step": 346096, "episode/length": 232.0, "episode/score": 0.3561398022443427, "episode/reward_rate": 0.004291845493562232}
{"step": 346136, "episode/length": 288.0, "episode/score": 0.09898025641132335, "episode/reward_rate": 0.0}
{"step": 346352, "episode/length": 288.0, "episode/score": 0.12667826190363485, "episode/reward_rate": 0.0}
{"step": 346608, "episode/length": 113.0, "episode/score": 0.7430686846155368, "episode/reward_rate": 0.008771929824561403}
{"step": 346656, "episode/length": 73.0, "episode/score": 0.8148709993256489, "episode/reward_rate": 0.013513513513513514}
{"step": 346864, "episode/length": 95.0, "episode/score": 0.7418941495798208, "episode/reward_rate": 0.010416666666666666}
{"step": 346888, "episode/length": 34.0, "episode/score": 0.9258672676178321, "episode/reward_rate": 0.02857142857142857}
{"step": 346904, "episode/length": 68.0, "episode/score": 0.8554405981647051, "episode/reward_rate": 0.014492753623188406}
{"step": 346944, "episode/length": 288.0, "episode/score": 0.11424452740652669, "episode/reward_rate": 0.0}
{"step": 347144, "episode/length": 31.0, "episode/score": 0.9220826586035855, "episode/reward_rate": 0.03125}
{"step": 347400, "episode/length": 56.0, "episode/score": 0.8682932578099098, "episode/reward_rate": 0.017543859649122806}
{"step": 347408, "episode/length": 62.0, "episode/score": 0.8721593279392437, "episode/reward_rate": 0.015873015873015872}
{"step": 347496, "episode/length": 43.0, "episode/score": 0.8963228739680744, "episode/reward_rate": 0.022727272727272728}
{"step": 347496, "episode/length": 104.0, "episode/score": 0.7361142458955783, "episode/reward_rate": 0.009523809523809525}
{"step": 347544, "episode/length": 288.0, "episode/score": 0.10132806237174918, "episode/reward_rate": 0.0}
{"step": 347712, "episode/length": 38.0, "episode/score": 0.9303775630542077, "episode/reward_rate": 0.02564102564102564}
{"step": 347784, "episode/length": 114.0, "episode/score": 0.7259214786511166, "episode/reward_rate": 0.008695652173913044}
{"step": 347808, "episode/length": 38.0, "episode/score": 0.9206438333749247, "episode/reward_rate": 0.02564102564102564}
{"step": 348048, "episode/length": 68.0, "episode/score": 0.8584216616527556, "episode/reward_rate": 0.014492753623188406}
{"step": 348128, "episode/length": 288.0, "episode/score": 0.16738287774251148, "episode/reward_rate": 0.0}
{"step": 348232, "episode/length": 64.0, "episode/score": 0.8594609167612361, "episode/reward_rate": 0.015384615384615385}
{"step": 348448, "episode/length": 288.0, "episode/score": 0.16781046658434207, "episode/reward_rate": 0.0}
{"step": 348744, "episode/length": 86.0, "episode/score": 0.8206869816704057, "episode/reward_rate": 0.011494252873563218}
{"step": 348760, "episode/length": 38.0, "episode/score": 0.9298322378981538, "episode/reward_rate": 0.02564102564102564}
{"step": 348776, "episode/length": 80.0, "episode/score": 0.8190300894739266, "episode/reward_rate": 0.012345679012345678}
{"step": 348888, "episode/length": 81.0, "episode/score": 0.8125239561195485, "episode/reward_rate": 0.012195121951219513}
{"step": 349000, "episode/length": 181.0, "episode/score": 0.5806179200317274, "episode/reward_rate": 0.005494505494505495}
{"step": 349048, "episode/length": 33.0, "episode/score": 0.9292057977108925, "episode/reward_rate": 0.029411764705882353}
{"step": 349376, "episode/length": 60.0, "episode/score": 0.8619789046206279, "episode/reward_rate": 0.01639344262295082}
{"step": 349456, "episode/length": 205.0, "episode/score": 0.4831582906535914, "episode/reward_rate": 0.0048543689320388345}
{"step": 349456, "episode/length": 86.0, "episode/score": 0.7900897891568093, "episode/reward_rate": 0.011494252873563218}
{"step": 349664, "episode/length": 82.0, "episode/score": 0.8026264830905347, "episode/reward_rate": 0.012048192771084338}
{"step": 349720, "episode/length": 288.0, "episode/score": 0.16341243439092068, "episode/reward_rate": 0.0}
{"step": 349776, "episode/length": 90.0, "episode/score": 0.7958659605537832, "episode/reward_rate": 0.01098901098901099}
{"step": 349928, "episode/length": 147.0, "episode/score": 0.6588610920248357, "episode/reward_rate": 0.006756756756756757}
{"step": 349960, "episode/length": 62.0, "episode/score": 0.8477392999739095, "episode/reward_rate": 0.015873015873015872}
{"step": 350064, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 350064, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 350064, "eval_episode/length": 192.0, "eval_episode/score": 0.4000000059604645, "eval_episode/reward_rate": 0.0051813471502590676}
{"step": 350064, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 350064, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 350064, "eval_episode/length": 155.0, "eval_episode/score": 0.515625, "eval_episode/reward_rate": 0.00641025641025641}
{"step": 350064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350096, "episode/length": 288.0, "episode/score": 0.1487426152457374, "episode/reward_rate": 0.0}
{"step": 350272, "episode/length": 68.0, "episode/score": 0.8432505929949912, "episode/reward_rate": 0.014492753623188406}
{"step": 350328, "episode/length": 82.0, "episode/score": 0.8332260640913773, "episode/reward_rate": 0.012048192771084338}
{"step": 350624, "episode/length": 43.0, "episode/score": 0.8986782268457318, "episode/reward_rate": 0.022727272727272728}
{"step": 350960, "episode/length": 124.0, "episode/score": 0.692750164024801, "episode/reward_rate": 0.008}
{"step": 351144, "episode/length": 101.0, "episode/score": 0.737805469947034, "episode/reward_rate": 0.00980392156862745}
{"step": 351488, "episode/length": 107.0, "episode/score": 0.7188077611242534, "episode/reward_rate": 0.009259259259259259}
{"step": 351512, "episode/length": 216.0, "episode/score": 0.4270189511191802, "episode/reward_rate": 0.004608294930875576}
{"step": 351656, "episode/length": 63.0, "episode/score": 0.8310397616687624, "episode/reward_rate": 0.015625}
{"step": 351688, "episode/length": 288.0, "episode/score": 0.1102640747822079, "episode/reward_rate": 0.0}
{"step": 351768, "episode/length": 288.0, "episode/score": 0.10654085348892295, "episode/reward_rate": 0.0}
{"step": 352048, "episode/length": 44.0, "episode/score": 0.9110709050094101, "episode/reward_rate": 0.022222222222222223}
{"step": 352088, "episode/length": 140.0, "episode/score": 0.6534585108804549, "episode/reward_rate": 0.0070921985815602835}
{"step": 352208, "episode/length": 89.0, "episode/score": 0.7748044199470314, "episode/reward_rate": 0.011111111111111112}
{"step": 352240, "episode/length": 288.0, "episode/score": 0.10039520688269477, "episode/reward_rate": 0.0}
{"step": 352408, "episode/length": 288.0, "episode/score": 0.07858425240215183, "episode/reward_rate": 0.0}
{"step": 352536, "episode/length": 109.0, "episode/score": 0.7300846919818014, "episode/reward_rate": 0.00909090909090909}
{"step": 352649, "train_stats/mean_log_entropy": 0.2636671525371425, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.30924658203125, "train/action_min": 0.0, "train/action_std": 1.623667833328247, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0026500090030021966, "train/actor_opt_grad_steps": 21320.0, "train/actor_opt_loss": 13.707973925113677, "train/adv_mag": 0.02550380492210388, "train/adv_max": 0.02523907709121704, "train/adv_mean": 0.006604935242037755, "train/adv_min": -0.008100537776947022, "train/adv_std": 0.004401114534586668, "train/cont_avg": 0.996453125, "train/cont_loss_mean": 0.022910551534965636, "train/cont_loss_std": 0.3106681548431516, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.381943454507922, "train/cont_pos_acc": 0.9999999842643738, "train/cont_pos_loss": 0.0037433509808033703, "train/cont_pred": 0.9962596702575683, "train/cont_rate": 0.996453125, "train/dyn_loss_mean": 1.000007550239563, "train/dyn_loss_std": 0.0001850300584701472, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.39607711281627417, "train/extr_critic_critic_opt_grad_steps": 21320.0, "train/extr_critic_critic_opt_loss": 11208.27748046875, "train/extr_critic_mag": 0.4512126922607422, "train/extr_critic_max": 0.4512126922607422, "train/extr_critic_mean": 0.4454976587295532, "train/extr_critic_min": 0.4320863828659058, "train/extr_critic_std": 0.0030611912487074735, "train/extr_return_normed_mag": 0.039439030170440675, "train/extr_return_normed_max": 0.039342213869094846, "train/extr_return_normed_mean": 0.019584693438053365, "train/extr_return_normed_min": 0.0033354146480560304, "train/extr_return_normed_std": 0.005310334331355989, "train/extr_return_rate": 0.16084583652188303, "train/extr_return_raw_mag": 0.4718600926399231, "train/extr_return_raw_max": 0.4718600926399231, "train/extr_return_raw_mean": 0.4521025948524475, "train/extr_return_raw_min": 0.4358532934188843, "train/extr_return_raw_std": 0.005310334328562021, "train/extr_reward_mag": 0.01387181568145752, "train/extr_reward_max": 0.01387181568145752, "train/extr_reward_mean": 0.002254455088172108, "train/extr_reward_min": 2.4280548095703126e-05, "train/extr_reward_std": 0.003565945309586823, "train/image_loss_mean": 0.17140838730335237, "train/image_loss_std": 0.10668629056215287, "train/model_loss_mean": 0.8169292759895325, "train/model_loss_std": 0.3771294437646866, "train/model_opt_grad_norm": 31.37420349884033, "train/model_opt_grad_steps": 21299.192, "train/model_opt_loss": 2306.848181640625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2820.0, "train/policy_entropy_mag": 1.6111730155944823, "train/policy_entropy_max": 1.6111730155944823, "train/policy_entropy_mean": 0.2964607278108597, "train/policy_entropy_min": 0.06483180809020996, "train/policy_entropy_std": 0.3059980022907257, "train/policy_logprob_mag": 6.550023662567138, "train/policy_logprob_max": -0.008630754590034486, "train/policy_logprob_mean": -0.2951417155265808, "train/policy_logprob_min": -6.550023662567138, "train/policy_logprob_std": 0.8164590134620666, "train/policy_randomness_mag": 0.8279791884422302, "train/policy_randomness_max": 0.8279791884422302, "train/policy_randomness_mean": 0.15235068494081497, "train/policy_randomness_min": 0.033316960543394086, "train/policy_randomness_std": 0.15725187611579894, "train/post_ent_mag": 80.00503997802734, "train/post_ent_max": 80.00503997802734, "train/post_ent_mean": 79.16651818847656, "train/post_ent_min": 78.47349615478515, "train/post_ent_std": 0.2751798025369644, "train/prior_ent_mag": 81.34020880126953, "train/prior_ent_max": 81.34020880126953, "train/prior_ent_mean": 78.39686041259766, "train/prior_ent_min": 75.63573077392579, "train/prior_ent_std": 0.9887228283882141, "train/rep_loss_mean": 1.000007550239563, "train/rep_loss_std": 0.0001850300584701472, "train/reward_avg": 0.0007344102684874087, "train/reward_loss_mean": 0.022605793282389642, "train/reward_loss_std": 0.08563517716526985, "train/reward_max_data": 0.20332306042686105, "train/reward_max_pred": 0.011930698394775391, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.020239272363483905, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.947916424274444, "train/reward_pred": 0.0007307922570034862, "train/reward_rate": 0.0003984375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.017992470413446426, "report/cont_loss_std": 0.2639639973640442, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.777944564819336, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004006324801594019, "report/cont_pred": 0.9959768056869507, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.13808749616146088, "report/image_loss_std": 0.09826008230447769, "report/model_loss_mean": 0.7798467874526978, "report/model_loss_std": 0.35478758811950684, "report/post_ent_mag": 78.80011749267578, "report/post_ent_max": 78.80011749267578, "report/post_ent_mean": 78.01399230957031, "report/post_ent_min": 77.11177825927734, "report/post_ent_std": 0.303284615278244, "report/prior_ent_mag": 79.3956298828125, "report/prior_ent_max": 79.3956298828125, "report/prior_ent_mean": 75.67174530029297, "report/prior_ent_min": 72.08505249023438, "report/prior_ent_std": 1.4283480644226074, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0011875267373397946, "report/reward_loss_mean": 0.023766808211803436, "report/reward_loss_std": 0.1319045126438141, "report/reward_max_data": 0.7221691012382507, "report/reward_max_pred": 0.022973299026489258, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01973147876560688, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.151910781860352, "report/reward_pred": 0.0008580186404287815, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014571869745850563, "eval/cont_loss_std": 0.24373872578144073, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.521643161773682, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0037948216777294874, "eval/cont_pred": 0.9962131381034851, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1947687864303589, "eval/image_loss_std": 0.11158010363578796, "eval/model_loss_mean": 0.8123887181282043, "eval/model_loss_std": 0.26901090145111084, "eval/post_ent_mag": 78.84088134765625, "eval/post_ent_max": 78.84088134765625, "eval/post_ent_mean": 77.93636322021484, "eval/post_ent_min": 77.24803924560547, "eval/post_ent_std": 0.30186665058135986, "eval/prior_ent_mag": 79.3956298828125, "eval/prior_ent_max": 79.3956298828125, "eval/prior_ent_mean": 75.77198791503906, "eval/prior_ent_min": 72.30953979492188, "eval/prior_ent_std": 1.3420060873031616, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.003048041369765997, "eval/reward_loss_std": 0.003222518367692828, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.015401363372802734, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.003048041369765997, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0005424257833510637, "eval/reward_rate": 0.0, "replay/size": 352145.0, "replay/inserts": 20032.0, "replay/samples": 20032.0, "replay/insert_wait_avg": 1.284356315295917e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.934399347335767e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 83536.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2779937070958755e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 499.93837690353394, "timer/env.step_count": 2504.0, "timer/env.step_total": 5.538760662078857, "timer/env.step_frac": 0.011078886754772166, "timer/env.step_avg": 0.0022119651206385215, "timer/env.step_min": 0.0011203289031982422, "timer/env.step_max": 0.00909566879272461, "timer/replay._sample_count": 20032.0, "timer/replay._sample_total": 1352.0955982208252, "timer/replay._sample_frac": 2.704524518792283, "timer/replay._sample_avg": 0.06749678505495334, "timer/replay._sample_min": 0.00047898292541503906, "timer/replay._sample_max": 0.09992074966430664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3082.0, "timer/agent.policy_total": 19.7841956615448, "timer/agent.policy_frac": 0.03957326857778369, "timer/agent.policy_avg": 0.006419271791546009, "timer/agent.policy_min": 0.00501561164855957, "timer/agent.policy_max": 0.010795831680297852, "timer/dataset_train_count": 1252.0, "timer/dataset_train_total": 0.10459709167480469, "timer/dataset_train_frac": 0.00020921996891426343, "timer/dataset_train_avg": 8.354400293514751e-05, "timer/dataset_train_min": 5.9604644775390625e-05, "timer/dataset_train_max": 0.00015735626220703125, "timer/agent.train_count": 1252.0, "timer/agent.train_total": 464.0921893119812, "timer/agent.train_frac": 0.9282987879154765, "timer/agent.train_avg": 0.37068066238976133, "timer/agent.train_min": 0.34953808784484863, "timer/agent.train_max": 0.4343397617340088, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.6064486503601074, "timer/agent.report_frac": 0.0012130468041206713, "timer/agent.report_avg": 0.3032243251800537, "timer/agent.report_min": 0.1892087459564209, "timer/agent.report_max": 0.4172399044036865, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.600120544433594e-05, "timer/dataset_eval_frac": 7.201128600552021e-08, "timer/dataset_eval_avg": 3.600120544433594e-05, "timer/dataset_eval_min": 3.600120544433594e-05, "timer/dataset_eval_max": 3.600120544433594e-05, "fps": 40.068344989112546}
{"step": 352760, "episode/length": 68.0, "episode/score": 0.8371179536568434, "episode/reward_rate": 0.014492753623188406}
{"step": 353824, "episode/length": 288.0, "episode/score": 0.1136230979748234, "episode/reward_rate": 0.0}
{"step": 354080, "episode/length": 288.0, "episode/score": 0.055531537998376734, "episode/reward_rate": 0.0}
{"step": 354208, "episode/length": 15.0, "episode/score": 0.9701376540922411, "episode/reward_rate": 0.0625}
{"step": 354360, "episode/length": 288.0, "episode/score": 0.07593543511745793, "episode/reward_rate": 0.0}
{"step": 354400, "episode/length": 288.0, "episode/score": 0.08560920986883502, "episode/reward_rate": 0.0}
{"step": 354552, "episode/length": 288.0, "episode/score": 0.07056022496124115, "episode/reward_rate": 0.0}
{"step": 354720, "episode/length": 288.0, "episode/score": 0.10866989650071446, "episode/reward_rate": 0.0}
{"step": 354848, "episode/length": 288.0, "episode/score": 0.08009289011044984, "episode/reward_rate": 0.0}
{"step": 355072, "episode/length": 288.0, "episode/score": 0.06341970862058588, "episode/reward_rate": 0.0}
{"step": 355144, "episode/length": 92.0, "episode/score": 0.7873937163963092, "episode/reward_rate": 0.010752688172043012}
{"step": 356128, "episode/length": 220.0, "episode/score": 0.39156850533970555, "episode/reward_rate": 0.004524886877828055}
{"step": 356136, "episode/length": 288.0, "episode/score": 0.0974092620273268, "episode/reward_rate": 0.0}
{"step": 356520, "episode/length": 288.0, "episode/score": 0.06923791701569826, "episode/reward_rate": 0.0}
{"step": 356864, "episode/length": 288.0, "episode/score": 0.07323273657777918, "episode/reward_rate": 0.0}
{"step": 357032, "episode/length": 288.0, "episode/score": 0.10628950627335598, "episode/reward_rate": 0.0}
{"step": 357160, "episode/length": 288.0, "episode/score": 0.06208651435201773, "episode/reward_rate": 0.0}
{"step": 357384, "episode/length": 288.0, "episode/score": 0.08590721845632743, "episode/reward_rate": 0.0}
{"step": 357392, "episode/length": 28.0, "episode/score": 0.9209931803846985, "episode/reward_rate": 0.034482758620689655}
{"step": 357456, "episode/length": 288.0, "episode/score": 0.07206136968704868, "episode/reward_rate": 0.0}
{"step": 357552, "episode/length": 64.0, "episode/score": 0.8266122146704902, "episode/reward_rate": 0.015384615384615385}
{"step": 357792, "episode/length": 158.0, "episode/score": 0.5933748256751414, "episode/reward_rate": 0.006289308176100629}
{"step": 357880, "episode/length": 126.0, "episode/score": 0.6937055229475391, "episode/reward_rate": 0.007874015748031496}
{"step": 358176, "episode/length": 98.0, "episode/score": 0.7307928557678451, "episode/reward_rate": 0.010101010101010102}
{"step": 358440, "episode/length": 288.0, "episode/score": 0.12935070155151607, "episode/reward_rate": 0.0}
{"step": 358448, "episode/length": 288.0, "episode/score": 0.11141841813594056, "episode/reward_rate": 0.0}
{"step": 359704, "episode/length": 288.0, "episode/score": 0.09142869849540602, "episode/reward_rate": 0.0}
{"step": 359736, "episode/length": 160.0, "episode/score": 0.5726158417792249, "episode/reward_rate": 0.006211180124223602}
{"step": 359768, "episode/length": 288.0, "episode/score": 0.09365533030108963, "episode/reward_rate": 0.0}
{"step": 359864, "episode/length": 288.0, "episode/score": 0.05630907545736363, "episode/reward_rate": 0.0}
{"step": 359976, "episode/length": 29.0, "episode/score": 0.9258616577246812, "episode/reward_rate": 0.03333333333333333}
{"step": 360048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360104, "episode/length": 288.0, "episode/score": 0.07188862358503911, "episode/reward_rate": 0.0}
{"step": 360192, "episode/length": 288.0, "episode/score": 0.10254235275419887, "episode/reward_rate": 0.0}
{"step": 360400, "episode/length": 78.0, "episode/score": 0.7979466849905634, "episode/reward_rate": 0.012658227848101266}
{"step": 360488, "episode/length": 288.0, "episode/score": 0.0790161305753827, "episode/reward_rate": 0.0}
{"step": 360712, "episode/length": 105.0, "episode/score": 0.7265492019048452, "episode/reward_rate": 0.009433962264150943}
{"step": 360752, "episode/length": 288.0, "episode/score": 0.07526573164500405, "episode/reward_rate": 0.0}
{"step": 361608, "episode/length": 111.0, "episode/score": 0.7376565710403611, "episode/reward_rate": 0.008928571428571428}
{"step": 361856, "episode/length": 30.0, "episode/score": 0.9112039467587465, "episode/reward_rate": 0.03225806451612903}
{"step": 361912, "episode/length": 241.0, "episode/score": 0.3480806589858503, "episode/reward_rate": 0.004132231404958678}
{"step": 362016, "episode/length": 288.0, "episode/score": 0.08084846273567337, "episode/reward_rate": 0.0}
{"step": 362416, "episode/length": 288.0, "episode/score": 0.11599728130647691, "episode/reward_rate": 0.0}
{"step": 362504, "episode/length": 288.0, "episode/score": 0.11770298858624528, "episode/reward_rate": 0.0}
{"step": 362712, "episode/length": 288.0, "episode/score": 0.12272723644775851, "episode/reward_rate": 0.0}
{"step": 362800, "episode/length": 288.0, "episode/score": 0.06520688386211759, "episode/reward_rate": 0.0}
{"step": 362808, "episode/length": 98.0, "episode/score": 0.7418135597484365, "episode/reward_rate": 0.010101010101010102}
{"step": 363056, "episode/length": 68.0, "episode/score": 0.8329522755788616, "episode/reward_rate": 0.014492753623188406}
{"step": 363064, "episode/length": 288.0, "episode/score": 0.054985946268573116, "episode/reward_rate": 0.0}
{"step": 363872, "episode/length": 251.0, "episode/score": 0.3078149174403393, "episode/reward_rate": 0.003968253968253968}
{"step": 363984, "episode/length": 158.0, "episode/score": 0.5550131081510017, "episode/reward_rate": 0.006289308176100629}
{"step": 364224, "episode/length": 288.0, "episode/score": 0.08286781274802024, "episode/reward_rate": 0.0}
{"step": 364360, "episode/length": 194.0, "episode/score": 0.46794955921768633, "episode/reward_rate": 0.005128205128205128}
{"step": 364456, "episode/length": 174.0, "episode/score": 0.5122114390906631, "episode/reward_rate": 0.005714285714285714}
{"step": 364728, "episode/length": 288.0, "episode/score": 0.061250340326523656, "episode/reward_rate": 0.0}
{"step": 365120, "episode/length": 288.0, "episode/score": 0.0895088255324481, "episode/reward_rate": 0.0}
{"step": 365376, "episode/length": 288.0, "episode/score": 0.07265619084216723, "episode/reward_rate": 0.0}
{"step": 365536, "episode/length": 207.0, "episode/score": 0.4220130154276376, "episode/reward_rate": 0.004807692307692308}
{"step": 365704, "episode/length": 184.0, "episode/score": 0.5220942454700435, "episode/reward_rate": 0.005405405405405406}
{"step": 365848, "episode/length": 232.0, "episode/score": 0.382853929886835, "episode/reward_rate": 0.004291845493562232}
{"step": 366360, "episode/length": 122.0, "episode/score": 0.7227131801200812, "episode/reward_rate": 0.008130081300813009}
{"step": 366432, "episode/length": 258.0, "episode/score": 0.3554610910175029, "episode/reward_rate": 0.003861003861003861}
{"step": 366608, "episode/length": 94.0, "episode/score": 0.8017445599271014, "episode/reward_rate": 0.010526315789473684}
{"step": 366624, "episode/length": 114.0, "episode/score": 0.725730681811001, "episode/reward_rate": 0.008695652173913044}
{"step": 366768, "episode/length": 288.0, "episode/score": 0.19432880364593075, "episode/reward_rate": 0.0}
{"step": 366864, "episode/length": 62.0, "episode/score": 0.8678544336753475, "episode/reward_rate": 0.015873015873015872}
{"step": 367040, "episode/length": 288.0, "episode/score": 0.15473364571408865, "episode/reward_rate": 0.0}
{"step": 367264, "episode/length": 81.0, "episode/score": 0.80121426387268, "episode/reward_rate": 0.012195121951219513}
{"step": 367416, "episode/length": 98.0, "episode/score": 0.7668781621514427, "episode/reward_rate": 0.010101010101010102}
{"step": 367432, "episode/length": 288.0, "episode/score": 0.19532020759112356, "episode/reward_rate": 0.0}
{"step": 367680, "episode/length": 113.0, "episode/score": 0.7409662336758629, "episode/reward_rate": 0.008771929824561403}
{"step": 367848, "episode/length": 288.0, "episode/score": 0.11628629985443695, "episode/reward_rate": 0.0}
{"step": 367968, "episode/length": 115.0, "episode/score": 0.7283285207117842, "episode/reward_rate": 0.008620689655172414}
{"step": 367968, "episode/length": 66.0, "episode/score": 0.8527928329758652, "episode/reward_rate": 0.014925373134328358}
{"step": 368104, "episode/length": 104.0, "episode/score": 0.7507108790132406, "episode/reward_rate": 0.009523809523809525}
{"step": 368448, "episode/length": 95.0, "episode/score": 0.7346308712712926, "episode/reward_rate": 0.010416666666666666}
{"step": 368744, "episode/length": 288.0, "episode/score": 0.09419430341631596, "episode/reward_rate": 0.0}
{"step": 368960, "episode/length": 192.0, "episode/score": 0.5060450600865352, "episode/reward_rate": 0.0051813471502590676}
{"step": 369176, "episode/length": 288.0, "episode/score": 0.10657933686570686, "episode/reward_rate": 0.0}
{"step": 369432, "episode/length": 85.0, "episode/score": 0.8067656530547538, "episode/reward_rate": 0.011627906976744186}
{"step": 369632, "episode/length": 147.0, "episode/score": 0.6485813996714569, "episode/reward_rate": 0.006756756756756757}
{"step": 369904, "episode/length": 90.0, "episode/score": 0.7862873557949115, "episode/reward_rate": 0.01098901098901099}
{"step": 370032, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 370032, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 370032, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 370032, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 370032, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 370032, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 370032, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 370032, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 370096, "episode/length": 141.0, "episode/score": 0.6533248938656016, "episode/reward_rate": 0.007042253521126761}
{"step": 370160, "episode/length": 288.0, "episode/score": 0.13202513170745078, "episode/reward_rate": 0.0}
{"step": 370208, "episode/length": 279.0, "episode/score": 0.2399601846952919, "episode/reward_rate": 0.0035714285714285713}
{"step": 370280, "episode/length": 288.0, "episode/score": 0.08502438351411001, "episode/reward_rate": 0.0}
{"step": 370416, "episode/length": 288.0, "episode/score": 0.10600542493148168, "episode/reward_rate": 0.0}
{"step": 370512, "episode/length": 134.0, "episode/score": 0.6393055386731703, "episode/reward_rate": 0.007407407407407408}
{"step": 370944, "episode/length": 91.0, "episode/score": 0.8074062180212422, "episode/reward_rate": 0.010869565217391304}
{"step": 371232, "episode/length": 133.0, "episode/score": 0.7002001475373163, "episode/reward_rate": 0.007462686567164179}
{"step": 371704, "episode/length": 58.0, "episode/score": 0.8894483352514726, "episode/reward_rate": 0.01694915254237288}
{"step": 371944, "episode/length": 288.0, "episode/score": 0.17375674780214467, "episode/reward_rate": 0.0}
{"step": 372176, "episode/length": 58.0, "episode/score": 0.879370118163024, "episode/reward_rate": 0.01694915254237288}
{"step": 372216, "episode/length": 288.0, "episode/score": 0.11316348198056403, "episode/reward_rate": 0.0}
{"step": 372264, "episode/length": 230.0, "episode/score": 0.4284712570345164, "episode/reward_rate": 0.004329004329004329}
{"step": 372408, "episode/length": 288.0, "episode/score": 0.12801344080207855, "episode/reward_rate": 0.0}
{"step": 372592, "episode/length": 288.0, "episode/score": 0.12705634457483939, "episode/reward_rate": 0.0}
{"step": 372616, "episode/length": 54.0, "episode/score": 0.8760645086676959, "episode/reward_rate": 0.01818181818181818}
{"step": 372809, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1624029250372026, "train/action_min": 0.0, "train/action_std": 1.7134688288446456, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.002366733051271045, "train/actor_opt_grad_steps": 22575.0, "train/actor_opt_loss": 7.289568122535471, "train/adv_mag": 0.025773702632813228, "train/adv_max": 0.025552615759864686, "train/adv_mean": 0.006526747314464522, "train/adv_min": -0.010891262027952407, "train/adv_std": 0.004935672580604515, "train/cont_avg": 0.9960472470238095, "train/cont_loss_mean": 0.02489165499407266, "train/cont_loss_std": 0.3298727424375506, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.3611394233703615, "train/cont_pos_acc": 0.9999999858084179, "train/cont_pos_loss": 0.0037538223171843187, "train/cont_pred": 0.9962465900277334, "train/cont_rate": 0.9960472470238095, "train/dyn_loss_mean": 1.0000175502565172, "train/dyn_loss_std": 0.00045472857983975065, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.4690781963826527, "train/extr_critic_critic_opt_grad_steps": 22575.0, "train/extr_critic_critic_opt_loss": 6245.81281389509, "train/extr_critic_mag": 0.6104260446533324, "train/extr_critic_max": 0.6104260446533324, "train/extr_critic_mean": 0.6052481267187331, "train/extr_critic_min": 0.5923603385213821, "train/extr_critic_std": 0.002903318889106491, "train/extr_return_normed_mag": 0.042207667278865026, "train/extr_return_normed_max": 0.042207667278865026, "train/extr_return_normed_mean": 0.02037645727839498, "train/extr_return_normed_min": 0.001593152681986491, "train/extr_return_normed_std": 0.006046065783482932, "train/extr_return_rate": 1.0, "train/extr_return_raw_mag": 0.63360605211485, "train/extr_return_raw_max": 0.63360605211485, "train/extr_return_raw_mean": 0.6117748679622771, "train/extr_return_raw_min": 0.5929915375179715, "train/extr_return_raw_std": 0.006046065728047064, "train/extr_reward_mag": 0.016943914549691335, "train/extr_reward_max": 0.016943914549691335, "train/extr_reward_mean": 0.0025691927183375115, "train/extr_reward_min": 2.6457839541965062e-05, "train/extr_reward_std": 0.0042157524527745354, "train/image_loss_mean": 0.16613044684368466, "train/image_loss_std": 0.10862101401601519, "train/model_loss_mean": 0.8151296878617907, "train/model_loss_std": 0.41044512544832534, "train/model_opt_grad_norm": 29.710936531187997, "train/model_opt_grad_steps": 22553.134920634922, "train/model_opt_loss": 2462.5722617497518, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3015.873015873016, "train/policy_entropy_mag": 1.5677388575341966, "train/policy_entropy_max": 1.5677388575341966, "train/policy_entropy_mean": 0.20195866222419437, "train/policy_entropy_min": 0.06470635988646084, "train/policy_entropy_std": 0.24376256657498224, "train/policy_logprob_mag": 6.550845479208325, "train/policy_logprob_max": -0.008611404654821233, "train/policy_logprob_mean": -0.201238428907735, "train/policy_logprob_min": -6.550845479208325, "train/policy_logprob_std": 0.7380835470699129, "train/policy_randomness_mag": 0.8056584464179145, "train/policy_randomness_max": 0.8056584464179145, "train/policy_randomness_mean": 0.10378622837246411, "train/policy_randomness_min": 0.03325249313835114, "train/policy_randomness_std": 0.12526918669778203, "train/post_ent_mag": 74.70736464243086, "train/post_ent_max": 74.70736464243086, "train/post_ent_mean": 73.57948375883556, "train/post_ent_min": 72.57495692419627, "train/post_ent_std": 0.3930651784416229, "train/prior_ent_mag": 76.785704658145, "train/prior_ent_max": 76.785704658145, "train/prior_ent_mean": 73.14694274417938, "train/prior_ent_min": 69.97165192498102, "train/prior_ent_std": 1.1907289898584759, "train/rep_loss_mean": 1.0000175502565172, "train/rep_loss_std": 0.00045472857983975065, "train/reward_avg": 0.0008669352530324389, "train/reward_loss_mean": 0.024097033465902012, "train/reward_loss_std": 0.10608830764180138, "train/reward_max_data": 0.28088787969733986, "train/reward_max_pred": 0.01428455776638455, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.020654061240040593, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.68725864092509, "train/reward_pred": 0.000820125274855407, "train/reward_rate": 0.0006045386904761905, "train_stats/mean_log_entropy": 0.1683096825001166, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.030932098627090454, "report/cont_loss_std": 0.3687151074409485, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.701594352722168, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0034036380238831043, "report/cont_pred": 0.9965495467185974, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.15258270502090454, "report/image_loss_std": 0.11705672740936279, "report/model_loss_mean": 0.8242824077606201, "report/model_loss_std": 0.6316145658493042, "report/post_ent_mag": 69.1827163696289, "report/post_ent_max": 69.1827163696289, "report/post_ent_mean": 67.68498229980469, "report/post_ent_min": 66.3453140258789, "report/post_ent_std": 0.4831523001194, "report/prior_ent_mag": 73.3848876953125, "report/prior_ent_max": 73.3848876953125, "report/prior_ent_mean": 69.69747924804688, "report/prior_ent_min": 66.61803436279297, "report/prior_ent_std": 1.1210227012634277, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002465922385454178, "report/reward_loss_mean": 0.04076757654547691, "report/reward_loss_std": 0.305530846118927, "report/reward_max_data": 0.8668750524520874, "report/reward_max_pred": 0.013203144073486328, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.02446668967604637, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.588502883911133, "report/reward_pred": 0.0009303214028477669, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014618951827287674, "eval/cont_loss_std": 0.267819881439209, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.064877510070801, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0027789154555648565, "eval/cont_pred": 0.9972285032272339, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0000091791152954, "eval/dyn_loss_std": 0.0002931861381512135, "eval/image_loss_mean": 0.2212384194135666, "eval/image_loss_std": 0.12642769515514374, "eval/model_loss_mean": 0.8385593891143799, "eval/model_loss_std": 0.291766881942749, "eval/post_ent_mag": 69.14341735839844, "eval/post_ent_max": 69.14341735839844, "eval/post_ent_mean": 67.62959289550781, "eval/post_ent_min": 66.42884826660156, "eval/post_ent_std": 0.4979126453399658, "eval/prior_ent_mag": 73.3848876953125, "eval/prior_ent_max": 73.3848876953125, "eval/prior_ent_mean": 69.66755676269531, "eval/prior_ent_min": 66.80158233642578, "eval/prior_ent_std": 1.163071632385254, "eval/rep_loss_mean": 1.0000091791152954, "eval/rep_loss_std": 0.0002931861381512135, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0026964927092194557, "eval/reward_loss_std": 0.002766810357570648, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.005343317985534668, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0026964927092194557, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0004397754091769457, "eval/reward_rate": 0.0, "replay/size": 372305.0, "replay/inserts": 20160.0, "replay/samples": 20160.0, "replay/insert_wait_avg": 1.2817600416758704e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.098950666094583e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 87320.0, "eval_replay/inserts": 3784.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2256756393400357e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.463472366333, "timer/env.step_count": 2520.0, "timer/env.step_total": 5.3884596824646, "timer/env.step_frac": 0.010766939007529234, "timer/env.step_avg": 0.0021382776517716666, "timer/env.step_min": 0.0010933876037597656, "timer/env.step_max": 0.008834600448608398, "timer/replay._sample_count": 20160.0, "timer/replay._sample_total": 1359.709110736847, "timer/replay._sample_frac": 2.716899805509795, "timer/replay._sample_avg": 0.06744588842940709, "timer/replay._sample_min": 0.00035452842712402344, "timer/replay._sample_max": 0.09916210174560547, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2993.0, "timer/agent.policy_total": 19.181804895401, "timer/agent.policy_frac": 0.038328081777285354, "timer/agent.policy_avg": 0.0064088890395593056, "timer/agent.policy_min": 0.004899263381958008, "timer/agent.policy_max": 0.011624574661254883, "timer/dataset_train_count": 1260.0, "timer/dataset_train_total": 0.10541415214538574, "timer/dataset_train_frac": 0.00021063305908612626, "timer/dataset_train_avg": 8.36620255122109e-05, "timer/dataset_train_min": 6.175041198730469e-05, "timer/dataset_train_max": 0.0001647472381591797, "timer/agent.train_count": 1260.0, "timer/agent.train_total": 467.6647536754608, "timer/agent.train_frac": 0.9344633115064511, "timer/agent.train_avg": 0.3711625029170324, "timer/agent.train_min": 0.3509697914123535, "timer/agent.train_max": 0.41727447509765625, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.7674858570098877, "timer/agent.report_frac": 0.0015335501977416998, "timer/agent.report_avg": 0.38374292850494385, "timer/agent.report_min": 0.3348734378814697, "timer/agent.report_max": 0.43261241912841797, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.528594970703125e-05, "timer/dataset_eval_frac": 7.050654374471984e-08, "timer/dataset_eval_avg": 3.528594970703125e-05, "timer/dataset_eval_min": 3.528594970703125e-05, "timer/dataset_eval_max": 3.528594970703125e-05, "fps": 40.28218330331962}
{"step": 372824, "episode/length": 288.0, "episode/score": 0.10594668968860788, "episode/reward_rate": 0.0}
{"step": 373096, "episode/length": 109.0, "episode/score": 0.7508791700388429, "episode/reward_rate": 0.00909090909090909}
{"step": 373248, "episode/length": 81.0, "episode/score": 0.8152532771318874, "episode/reward_rate": 0.012195121951219513}
{"step": 373256, "episode/length": 288.0, "episode/score": 0.11620800953232902, "episode/reward_rate": 0.0}
{"step": 373696, "episode/length": 178.0, "episode/score": 0.5213673283296885, "episode/reward_rate": 0.00558659217877095}
{"step": 373856, "episode/length": 74.0, "episode/score": 0.8489250776763129, "episode/reward_rate": 0.013333333333333334}
{"step": 374000, "episode/length": 37.0, "episode/score": 0.9110516786499829, "episode/reward_rate": 0.02631578947368421}
{"step": 374256, "episode/length": 288.0, "episode/score": 0.10966401776045132, "episode/reward_rate": 0.0}
{"step": 374720, "episode/length": 288.0, "episode/score": 0.032476159196676235, "episode/reward_rate": 0.0}
{"step": 374928, "episode/length": 288.0, "episode/score": 0.11581480585482495, "episode/reward_rate": 0.0}
{"step": 375136, "episode/length": 288.0, "episode/score": 0.15888658132030287, "episode/reward_rate": 0.0}
{"step": 375408, "episode/length": 288.0, "episode/score": 0.06191653667906394, "episode/reward_rate": 0.0}
{"step": 375560, "episode/length": 288.0, "episode/score": 0.08723231492331252, "episode/reward_rate": 0.0}
{"step": 376168, "episode/length": 288.0, "episode/score": 0.22108211236741226, "episode/reward_rate": 0.0034602076124567475}
{"step": 376312, "episode/length": 288.0, "episode/score": 0.11116699552485443, "episode/reward_rate": 0.0}
{"step": 376568, "episode/length": 288.0, "episode/score": 0.11680730618786583, "episode/reward_rate": 0.0}
{"step": 376832, "episode/length": 211.0, "episode/score": 0.46313361102011186, "episode/reward_rate": 0.0047169811320754715}
{"step": 376872, "episode/length": 242.0, "episode/score": 0.3946549758804849, "episode/reward_rate": 0.00411522633744856}
{"step": 376904, "episode/length": 91.0, "episode/score": 0.8170527053498517, "episode/reward_rate": 0.010869565217391304}
{"step": 377032, "episode/length": 288.0, "episode/score": 0.13552392607880392, "episode/reward_rate": 0.0}
{"step": 377408, "episode/length": 230.0, "episode/score": 0.45371019720050754, "episode/reward_rate": 0.004329004329004329}
{"step": 377424, "episode/length": 68.0, "episode/score": 0.8608064774180093, "episode/reward_rate": 0.014492753623188406}
{"step": 377720, "episode/length": 288.0, "episode/score": 0.14034527233184235, "episode/reward_rate": 0.0}
{"step": 377912, "episode/length": 109.0, "episode/score": 0.7550248404404556, "episode/reward_rate": 0.00909090909090909}
{"step": 378264, "episode/length": 169.0, "episode/score": 0.5811636500106943, "episode/reward_rate": 0.0058823529411764705}
{"step": 378336, "episode/length": 113.0, "episode/score": 0.7435841920737403, "episode/reward_rate": 0.008771929824561403}
{"step": 378624, "episode/length": 288.0, "episode/score": 0.11613894421543591, "episode/reward_rate": 0.0}
{"step": 378880, "episode/length": 288.0, "episode/score": 0.16590126991695797, "episode/reward_rate": 0.0}
{"step": 379144, "episode/length": 288.0, "episode/score": 0.1313929405023373, "episode/reward_rate": 0.0}
{"step": 379224, "episode/length": 42.0, "episode/score": 0.9174599257544287, "episode/reward_rate": 0.023255813953488372}
{"step": 379368, "episode/length": 92.0, "episode/score": 0.7774221761201261, "episode/reward_rate": 0.010752688172043012}
{"step": 379512, "episode/length": 45.0, "episode/score": 0.9094087088587912, "episode/reward_rate": 0.021739130434782608}
{"step": 379720, "episode/length": 288.0, "episode/score": 0.10136144498596877, "episode/reward_rate": 0.0}
{"step": 379744, "episode/length": 46.0, "episode/score": 0.8915923466624918, "episode/reward_rate": 0.02127659574468085}
{"step": 380016, "episode/length": 218.0, "episode/score": 0.4579501462362714, "episode/reward_rate": 0.0045662100456621}
{"step": 380016, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 380016, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 380016, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 380016, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 380016, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 380016, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 380016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380032, "episode/length": 288.0, "episode/score": 0.11183046720270795, "episode/reward_rate": 0.0}
{"step": 380224, "episode/length": 288.0, "episode/score": 0.12001240953281922, "episode/reward_rate": 0.0}
{"step": 380472, "episode/length": 56.0, "episode/score": 0.8628959560455769, "episode/reward_rate": 0.017543859649122806}
{"step": 380544, "episode/length": 99.0, "episode/score": 0.7543163091081624, "episode/reward_rate": 0.01}
{"step": 380608, "episode/length": 136.0, "episode/score": 0.6803101411496755, "episode/reward_rate": 0.0072992700729927005}
{"step": 380648, "episode/length": 288.0, "episode/score": 0.17345592705032686, "episode/reward_rate": 0.0}
{"step": 380696, "episode/length": 82.0, "episode/score": 0.8050640800120163, "episode/reward_rate": 0.012048192771084338}
{"step": 381032, "episode/length": 52.0, "episode/score": 0.8851679317695016, "episode/reward_rate": 0.018867924528301886}
{"step": 381048, "episode/length": 102.0, "episode/score": 0.7573778061807843, "episode/reward_rate": 0.009708737864077669}
{"step": 381120, "episode/length": 71.0, "episode/score": 0.8291464187502697, "episode/reward_rate": 0.013888888888888888}
{"step": 381376, "episode/length": 90.0, "episode/score": 0.7680567251668435, "episode/reward_rate": 0.01098901098901099}
{"step": 381528, "episode/length": 103.0, "episode/score": 0.7371368438944046, "episode/reward_rate": 0.009615384615384616}
{"step": 381536, "episode/length": 288.0, "episode/score": 0.10933436575123778, "episode/reward_rate": 0.0}
{"step": 381552, "episode/length": 53.0, "episode/score": 0.8530433582068326, "episode/reward_rate": 0.018518518518518517}
{"step": 381616, "episode/length": 70.0, "episode/score": 0.8165780540309697, "episode/reward_rate": 0.014084507042253521}
{"step": 381768, "episode/length": 91.0, "episode/score": 0.7537250637162742, "episode/reward_rate": 0.010869565217391304}
{"step": 382032, "episode/length": 288.0, "episode/score": 0.09913240949981628, "episode/reward_rate": 0.0}
{"step": 382088, "episode/length": 69.0, "episode/score": 0.8200810638313669, "episode/reward_rate": 0.014285714285714285}
{"step": 382248, "episode/length": 88.0, "episode/score": 0.7766552535545088, "episode/reward_rate": 0.011235955056179775}
{"step": 382344, "episode/length": 90.0, "episode/score": 0.7590087614621552, "episode/reward_rate": 0.01098901098901099}
{"step": 382360, "episode/length": 100.0, "episode/score": 0.7119468378728016, "episode/reward_rate": 0.009900990099009901}
{"step": 382784, "episode/length": 288.0, "episode/score": 0.09271378236894634, "episode/reward_rate": 0.0}
{"step": 382784, "episode/length": 54.0, "episode/score": 0.8557990233711052, "episode/reward_rate": 0.01818181818181818}
{"step": 383008, "episode/length": 80.0, "episode/score": 0.8170186677115225, "episode/reward_rate": 0.012345679012345678}
{"step": 383240, "episode/length": 183.0, "episode/score": 0.4953431318172079, "episode/reward_rate": 0.005434782608695652}
{"step": 383504, "episode/length": 183.0, "episode/score": 0.47309281060211106, "episode/reward_rate": 0.005434782608695652}
{"step": 383688, "episode/length": 288.0, "episode/score": 0.0894178204932814, "episode/reward_rate": 0.0}
{"step": 383744, "episode/length": 91.0, "episode/score": 0.7778037755307423, "episode/reward_rate": 0.010869565217391304}
{"step": 384064, "episode/length": 69.0, "episode/score": 0.8246485576553368, "episode/reward_rate": 0.014285714285714285}
{"step": 384320, "episode/length": 78.0, "episode/score": 0.7940357947446728, "episode/reward_rate": 0.012658227848101266}
{"step": 384400, "episode/length": 288.0, "episode/score": 0.09430678733906461, "episode/reward_rate": 0.0}
{"step": 384440, "episode/length": 86.0, "episode/score": 0.7860440798083346, "episode/reward_rate": 0.011494252873563218}
{"step": 384480, "episode/length": 51.0, "episode/score": 0.8776100665403419, "episode/reward_rate": 0.019230769230769232}
{"step": 384560, "episode/length": 288.0, "episode/score": 0.14488523979741785, "episode/reward_rate": 0.0}
{"step": 384928, "episode/length": 60.0, "episode/score": 0.8657587726229394, "episode/reward_rate": 0.01639344262295082}
{"step": 385040, "episode/length": 89.0, "episode/score": 0.7856792625264006, "episode/reward_rate": 0.011111111111111112}
{"step": 385096, "episode/length": 288.0, "episode/score": 0.0722458261710699, "episode/reward_rate": 0.0}
{"step": 385096, "episode/length": 288.0, "episode/score": 0.1263937704525233, "episode/reward_rate": 0.0}
{"step": 385360, "episode/length": 109.0, "episode/score": 0.7515774780939637, "episode/reward_rate": 0.00909090909090909}
{"step": 385552, "episode/length": 288.0, "episode/score": 0.16631129167410563, "episode/reward_rate": 0.0}
{"step": 385648, "episode/length": 135.0, "episode/score": 0.737021296697776, "episode/reward_rate": 0.007352941176470588}
{"step": 385840, "episode/length": 99.0, "episode/score": 0.8196883435366544, "episode/reward_rate": 0.01}
{"step": 386064, "episode/length": 141.0, "episode/score": 0.7212811627123301, "episode/reward_rate": 0.007042253521126761}
{"step": 386128, "episode/length": 71.0, "episode/score": 0.8385660009998901, "episode/reward_rate": 0.013888888888888888}
{"step": 386232, "episode/length": 48.0, "episode/score": 0.9081068777322798, "episode/reward_rate": 0.02040816326530612}
{"step": 386568, "episode/length": 270.0, "episode/score": 0.31812929409102253, "episode/reward_rate": 0.0036900369003690036}
{"step": 386792, "episode/length": 142.0, "episode/score": 0.6166958958292525, "episode/reward_rate": 0.006993006993006993}
{"step": 386800, "episode/length": 70.0, "episode/score": 0.8307324628176502, "episode/reward_rate": 0.014084507042253521}
{"step": 386816, "episode/length": 30.0, "episode/score": 0.9365087564092391, "episode/reward_rate": 0.03225806451612903}
{"step": 387320, "episode/length": 65.0, "episode/score": 0.8512925563754834, "episode/reward_rate": 0.015151515151515152}
{"step": 387408, "episode/length": 288.0, "episode/score": 0.15023799287109796, "episode/reward_rate": 0.0}
{"step": 387408, "episode/length": 288.0, "episode/score": 0.1670853950199671, "episode/reward_rate": 0.0}
{"step": 387488, "episode/length": 85.0, "episode/score": 0.8180406562091775, "episode/reward_rate": 0.011627906976744186}
{"step": 387640, "episode/length": 284.0, "episode/score": 0.2338667541380346, "episode/reward_rate": 0.0035087719298245615}
{"step": 387776, "episode/length": 45.0, "episode/score": 0.8993175921536931, "episode/reward_rate": 0.021739130434782608}
{"step": 388376, "episode/length": 288.0, "episode/score": 0.17090118080614047, "episode/reward_rate": 0.0}
{"step": 388440, "episode/length": 288.0, "episode/score": 0.15725327743348316, "episode/reward_rate": 0.0}
{"step": 389064, "episode/length": 217.0, "episode/score": 0.4355603440374125, "episode/reward_rate": 0.0045871559633027525}
{"step": 389128, "episode/length": 288.0, "episode/score": 0.11082939799734959, "episode/reward_rate": 0.0}
{"step": 389720, "episode/length": 288.0, "episode/score": 0.20701728615495085, "episode/reward_rate": 0.0}
{"step": 389800, "episode/length": 288.0, "episode/score": 0.22209746134899433, "episode/reward_rate": 0.0}
{"step": 389952, "episode/length": 288.0, "episode/score": 0.16387164676757493, "episode/reward_rate": 0.0}
{"step": 390000, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 390000, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 390000, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 390000, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 390000, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 390000, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 390000, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 390000, "eval_episode/length": 237.0, "eval_episode/score": 0.2593750059604645, "eval_episode/reward_rate": 0.004201680672268907}
{"step": 390088, "episode/length": 288.0, "episode/score": 0.15873573845237843, "episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.84356689453125, "train/action_min": 0.0, "train/action_std": 1.8639658689498901, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0009402927244082093, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.9031511545181274, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.9970703125, "train/cont_loss_mean": 0.6030933260917664, "train/cont_loss_std": 0.2545482814311981, "train/cont_neg_acc": 0.3333333432674408, "train/cont_neg_loss": 1.037292718887329, "train/cont_pos_acc": 0.7032321095466614, "train/cont_pos_loss": 0.6018174886703491, "train/cont_pred": 0.5646771788597107, "train/cont_rate": 0.9970703125, "train/dyn_loss_mean": 11.015880584716797, "train/dyn_loss_std": 0.37669727206230164, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 10.624882698059082, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 42415.99609375, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 5011.21875, "train/image_loss_std": 40.22592544555664, "train/model_loss_mean": 5023.97265625, "train/model_loss_std": 40.225399017333984, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 50239728.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9417468309402466, "train/policy_entropy_max": 1.9417468309402466, "train/policy_entropy_mean": 1.6524602174758911, "train/policy_entropy_min": 0.6188125610351562, "train/policy_entropy_std": 0.13723517954349518, "train/policy_logprob_mag": 4.467006206512451, "train/policy_logprob_max": -0.1564934253692627, "train/policy_logprob_mean": -1.6626160144805908, "train/policy_logprob_min": -4.467006206512451, "train/policy_logprob_std": 0.7134663462638855, "train/policy_randomness_mag": 0.9978605508804321, "train/policy_randomness_max": 0.9978605508804321, "train/policy_randomness_mean": 0.8491965532302856, "train/policy_randomness_min": 0.3180067539215088, "train/policy_randomness_std": 0.07052493840456009, "train/post_ent_mag": 105.6079330444336, "train/post_ent_max": 105.6079330444336, "train/post_ent_mean": 105.303466796875, "train/post_ent_min": 104.96456909179688, "train/post_ent_std": 0.11016912013292313, "train/prior_ent_mag": 106.47293853759766, "train/prior_ent_max": 106.47293853759766, "train/prior_ent_mean": 105.58053588867188, "train/prior_ent_min": 104.76896667480469, "train/prior_ent_std": 0.2692882716655731, "train/rep_loss_mean": 11.015880584716797, "train/rep_loss_std": 0.37669727206230164, "train/reward_avg": 0.0004971523303538561, "train/reward_loss_mean": 5.541263103485107, "train/reward_loss_std": 6.353558887894906e-07, "train/reward_max_data": 0.0024999999441206455, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541263103485107, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.6243233680725098, "report/cont_loss_std": 0.26378074288368225, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 1.116290807723999, "report/cont_pos_acc": 0.6503427624702454, "report/cont_pos_loss": 0.6228777766227722, "report/cont_pred": 0.5545195937156677, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 11.020055770874023, "report/dyn_loss_std": 0.36561882495880127, "report/image_loss_mean": 5013.88671875, "report/image_loss_std": 39.16914749145508, "report/model_loss_mean": 5026.6640625, "report/model_loss_std": 39.18367004394531, "report/post_ent_mag": 105.640869140625, "report/post_ent_max": 105.640869140625, "report/post_ent_mean": 105.30728149414062, "report/post_ent_min": 104.97511291503906, "report/post_ent_std": 0.10505776107311249, "report/prior_ent_mag": 106.27540588378906, "report/prior_ent_max": 106.27540588378906, "report/prior_ent_mean": 105.55890655517578, "report/prior_ent_min": 104.48725128173828, "report/prior_ent_std": 0.2899479269981384, "report/rep_loss_mean": 11.020055770874023, "report/rep_loss_std": 0.36561882495880127, "report/reward_avg": 0.0004971523303538561, "report/reward_loss_mean": 5.541263103485107, "report/reward_loss_std": 6.353558887894906e-07, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541263103485107, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.6621354818344116, "eval/cont_loss_std": 0.27861613035202026, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 0.7400565147399902, "eval/cont_pos_acc": 0.5847208499908447, "eval/cont_pos_loss": 0.6619065999984741, "eval/cont_pred": 0.5350189208984375, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 11.020511627197266, "eval/dyn_loss_std": 0.36673977971076965, "eval/image_loss_mean": 5004.712890625, "eval/image_loss_std": 38.323646545410156, "eval/model_loss_mean": 5017.529296875, "eval/model_loss_std": 38.33926010131836, "eval/post_ent_mag": 105.5885009765625, "eval/post_ent_max": 105.5885009765625, "eval/post_ent_mean": 105.30186462402344, "eval/post_ent_min": 104.97821807861328, "eval/post_ent_std": 0.10770577937364578, "eval/prior_ent_mag": 106.42543029785156, "eval/prior_ent_max": 106.42543029785156, "eval/prior_ent_mean": 105.57563781738281, "eval/prior_ent_min": 104.72156524658203, "eval/prior_ent_std": 0.27517786622047424, "eval/rep_loss_mean": 11.020511627197266, "eval/rep_loss_std": 0.36673977971076965, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 771152.0, "replay/inserts": 0.0, "replay/samples": 112.0, "replay/insert_wait_avg": NaN, "replay/insert_wait_frac": NaN, "replay/sample_wait_avg": 7.408005850655692e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1808.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.2522250150157286e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.620373044695173e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 106.40603995323181, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 19.470495462417603, "timer/replay._sample_frac": 0.18298299110628857, "timer/replay._sample_avg": 0.17384370948587144, "timer/replay._sample_min": 0.08322381973266602, "timer/replay._sample_max": 0.7067725658416748, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 5.963114976882935, "timer/agent.policy_frac": 0.056041132434811756, "timer/agent.policy_avg": 0.02056246543752736, "timer/agent.policy_min": 0.004622936248779297, "timer/agent.policy_max": 3.334017515182495, "timer/env.step_count": 1.0, "timer/env.step_total": 0.011603832244873047, "timer/env.step_frac": 0.00010905238321032556, "timer/env.step_avg": 0.011603832244873047, "timer/env.step_min": 0.011603832244873047, "timer/env.step_max": 0.011603832244873047, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.409385681152344e-05, "timer/dataset_train_frac": 3.204127963648357e-07, "timer/dataset_train_avg": 3.409385681152344e-05, "timer/dataset_train_min": 3.409385681152344e-05, "timer/dataset_train_max": 3.409385681152344e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 42.04744577407837, "timer/agent.train_frac": 0.3951603291745403, "timer/agent.train_avg": 42.04744577407837, "timer/agent.train_min": 42.04744577407837, "timer/agent.train_max": 42.04744577407837, "timer/agent.report_count": 2.0, "timer/agent.report_total": 9.7203049659729, "timer/agent.report_frac": 0.091351064002055, "timer/agent.report_avg": 4.86015248298645, "timer/agent.report_min": 0.2023327350616455, "timer/agent.report_max": 9.517972230911255, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.9604644775390625e-05, "timer/dataset_eval_frac": 5.601622314070554e-07, "timer/dataset_eval_avg": 5.9604644775390625e-05, "timer/dataset_eval_min": 5.9604644775390625e-05, "timer/dataset_eval_max": 5.9604644775390625e-05}
{"step": 3872, "episode/length": 288.0, "episode/score": 0.13099901853365736, "episode/reward_rate": 0.0}
{"step": 3872, "episode/length": 288.0, "episode/score": 0.09780792840774666, "episode/reward_rate": 0.0}
{"step": 3872, "episode/length": 288.0, "episode/score": 0.11895314843945926, "episode/reward_rate": 0.0}
{"step": 3872, "episode/length": 288.0, "episode/score": 0.14819462779496462, "episode/reward_rate": 0.0}
{"step": 3872, "episode/length": 288.0, "episode/score": 0.16970033212783164, "episode/reward_rate": 0.0}
{"step": 3872, "episode/length": 288.0, "episode/score": 0.11016478288797771, "episode/reward_rate": 0.0}
{"step": 3872, "episode/length": 288.0, "episode/score": 0.13768474685116416, "episode/reward_rate": 0.0}
{"step": 3872, "episode/length": 288.0, "episode/score": 0.19352742175533422, "episode/reward_rate": 0.0}
{"step": 6184, "episode/length": 288.0, "episode/score": 0.16803865645874794, "episode/reward_rate": 0.0}
{"step": 6184, "episode/length": 288.0, "episode/score": 0.1750792132852439, "episode/reward_rate": 0.0}
{"step": 6184, "episode/length": 288.0, "episode/score": 0.12520441349806788, "episode/reward_rate": 0.0}
{"step": 6184, "episode/length": 288.0, "episode/score": 0.14636864544104355, "episode/reward_rate": 0.0}
{"step": 6184, "episode/length": 288.0, "episode/score": 0.1410572677405071, "episode/reward_rate": 0.0}
{"step": 6184, "episode/length": 288.0, "episode/score": 0.15449502920478153, "episode/reward_rate": 0.0}
{"step": 6184, "episode/length": 288.0, "episode/score": 0.17192481532015336, "episode/reward_rate": 0.0}
{"step": 6184, "episode/length": 288.0, "episode/score": 0.13928698110476034, "episode/reward_rate": 0.0}
{"step": 8496, "episode/length": 288.0, "episode/score": 0.09456966668642508, "episode/reward_rate": 0.0}
{"step": 8496, "episode/length": 288.0, "episode/score": 0.12428537247296845, "episode/reward_rate": 0.0}
{"step": 8496, "episode/length": 288.0, "episode/score": 0.10343540006920193, "episode/reward_rate": 0.0}
{"step": 8496, "episode/length": 288.0, "episode/score": 0.10869768127008683, "episode/reward_rate": 0.0}
{"step": 8496, "episode/length": 288.0, "episode/score": 0.09901010987414338, "episode/reward_rate": 0.0}
{"step": 8496, "episode/length": 288.0, "episode/score": 0.11832047971654447, "episode/reward_rate": 0.0}
{"step": 8496, "episode/length": 288.0, "episode/score": 0.127055250555145, "episode/reward_rate": 0.0}
{"step": 8496, "episode/length": 288.0, "episode/score": 0.10230065304529035, "episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10808, "episode/length": 288.0, "episode/score": 0.09197661404027713, "episode/reward_rate": 0.0}
{"step": 10808, "episode/length": 288.0, "episode/score": 0.14888415399775567, "episode/reward_rate": 0.0}
{"step": 10808, "episode/length": 288.0, "episode/score": 0.14319979748916012, "episode/reward_rate": 0.0}
{"step": 10808, "episode/length": 288.0, "episode/score": 0.08094856526622607, "episode/reward_rate": 0.0}
{"step": 10808, "episode/length": 288.0, "episode/score": 0.08964837070334397, "episode/reward_rate": 0.0}
{"step": 10808, "episode/length": 288.0, "episode/score": 0.09804941913728271, "episode/reward_rate": 0.0}
{"step": 10808, "episode/length": 288.0, "episode/score": 0.09733577171982688, "episode/reward_rate": 0.0}
{"step": 10808, "episode/length": 288.0, "episode/score": 0.11036433783840494, "episode/reward_rate": 0.0}
{"step": 13120, "episode/length": 288.0, "episode/score": 0.09144857394721839, "episode/reward_rate": 0.0}
{"step": 13120, "episode/length": 288.0, "episode/score": 0.08568002205572611, "episode/reward_rate": 0.0}
{"step": 13120, "episode/length": 288.0, "episode/score": 0.0947152143236849, "episode/reward_rate": 0.0}
{"step": 13120, "episode/length": 288.0, "episode/score": 0.07046823571181449, "episode/reward_rate": 0.0}
{"step": 13120, "episode/length": 288.0, "episode/score": 0.08013415935153034, "episode/reward_rate": 0.0}
{"step": 13120, "episode/length": 288.0, "episode/score": 0.08176896384662768, "episode/reward_rate": 0.0}
{"step": 13120, "episode/length": 288.0, "episode/score": 0.04838558604785703, "episode/reward_rate": 0.0}
{"step": 13120, "episode/length": 288.0, "episode/score": 0.13191224111500333, "episode/reward_rate": 0.0}
{"step": 15432, "episode/length": 288.0, "episode/score": 0.12542273360236322, "episode/reward_rate": 0.0}
{"step": 15432, "episode/length": 288.0, "episode/score": 0.10909801788551476, "episode/reward_rate": 0.0}
{"step": 15432, "episode/length": 288.0, "episode/score": 0.04737276348657815, "episode/reward_rate": 0.0}
{"step": 15432, "episode/length": 288.0, "episode/score": 0.12013907711394722, "episode/reward_rate": 0.0}
{"step": 15432, "episode/length": 288.0, "episode/score": 0.08457819713208892, "episode/reward_rate": 0.0}
{"step": 15432, "episode/length": 288.0, "episode/score": 0.07930356001958216, "episode/reward_rate": 0.0}
{"step": 15432, "episode/length": 288.0, "episode/score": 0.08345629708969682, "episode/reward_rate": 0.0}
{"step": 15432, "episode/length": 288.0, "episode/score": 0.08193672909789029, "episode/reward_rate": 0.0}
{"step": 17744, "episode/length": 288.0, "episode/score": 0.10526378146238358, "episode/reward_rate": 0.0}
{"step": 17744, "episode/length": 288.0, "episode/score": 0.07917078825710178, "episode/reward_rate": 0.0}
{"step": 17744, "episode/length": 288.0, "episode/score": 0.110559051526252, "episode/reward_rate": 0.0}
{"step": 17744, "episode/length": 288.0, "episode/score": 0.041571743452038845, "episode/reward_rate": 0.0}
{"step": 17744, "episode/length": 288.0, "episode/score": 0.0915452673646655, "episode/reward_rate": 0.0}
{"step": 17744, "episode/length": 288.0, "episode/score": 0.11224617446481489, "episode/reward_rate": 0.0}
{"step": 17744, "episode/length": 288.0, "episode/score": 0.13135608254521003, "episode/reward_rate": 0.0}
{"step": 17744, "episode/length": 288.0, "episode/score": 0.04639418303082721, "episode/reward_rate": 0.0}
{"step": 18792, "episode/length": 130.0, "episode/score": 0.6830457222636142, "episode/reward_rate": 0.007633587786259542}
{"step": 20056, "episode/length": 288.0, "episode/score": 0.1512064752512856, "episode/reward_rate": 0.0}
{"step": 20056, "episode/length": 288.0, "episode/score": 0.13506683693492505, "episode/reward_rate": 0.0}
{"step": 20056, "episode/length": 288.0, "episode/score": 0.09572464283399995, "episode/reward_rate": 0.0}
{"step": 20056, "episode/length": 288.0, "episode/score": 0.1478692232013259, "episode/reward_rate": 0.0}
{"step": 20056, "episode/length": 288.0, "episode/score": 0.13195837917317021, "episode/reward_rate": 0.0}
{"step": 20056, "episode/length": 288.0, "episode/score": 0.10123083138728362, "episode/reward_rate": 0.0}
{"step": 20056, "episode/length": 288.0, "episode/score": 0.13914301297029397, "episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20264, "episode/length": 183.0, "episode/score": 0.5336700065581681, "episode/reward_rate": 0.005434782608695652}
{"step": 21529, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.004662790606099, "train/action_min": 0.0, "train/action_std": 1.9971771749757952, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00197122605036824, "train/actor_opt_grad_steps": 625.0, "train/actor_opt_loss": 69.80753895351964, "train/adv_mag": 0.006701054527506893, "train/adv_max": 0.006701054527506893, "train/adv_mean": 0.003972863621258736, "train/adv_min": 0.0005682110148267468, "train/adv_std": 0.0018452590539400518, "train/cont_avg": 0.9962197580645161, "train/cont_loss_mean": 0.029797956550253496, "train/cont_loss_std": 0.32806963785239324, "train/cont_neg_acc": 0.004958677882990562, "train/cont_neg_loss": 5.550208587784413, "train/cont_pos_acc": 0.9974674572867732, "train/cont_pos_loss": 0.008903808684291078, "train/cont_pred": 0.9924638290559092, "train/cont_rate": 0.9962197580645161, "train/dyn_loss_mean": 1.110359638929367, "train/dyn_loss_std": 0.008199017725019075, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.396280529998964, "train/extr_critic_critic_opt_grad_steps": 625.0, "train/extr_critic_critic_opt_loss": 17395.749936995966, "train/extr_critic_mag": 0.044741569988189206, "train/extr_critic_max": 0.04474156806545873, "train/extr_critic_mean": 0.04468081410343448, "train/extr_critic_min": 0.044610082141814694, "train/extr_critic_std": 1.3957681974680955e-05, "train/extr_return_normed_mag": 0.013044694532296024, "train/extr_return_normed_max": 0.013044692769354261, "train/extr_return_normed_mean": 0.010377739844732899, "train/extr_return_normed_min": 0.007002187391973719, "train/extr_return_normed_std": 0.0018448841627602462, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0513206301039673, "train/extr_return_raw_max": 0.05132062818701079, "train/extr_return_raw_mean": 0.048653677740439764, "train/extr_return_raw_min": 0.04527812282206981, "train/extr_return_raw_std": 0.0018448841707403288, "train/extr_reward_mag": 0.0007629077280721356, "train/extr_reward_max": 0.0007629077280721356, "train/extr_reward_mean": 0.0007620982125386476, "train/extr_reward_min": 0.0007611445842250701, "train/extr_reward_std": 2.1273738182170376e-07, "train/image_loss_mean": 42.11229974512131, "train/image_loss_std": 0.5657801034770185, "train/model_loss_mean": 43.003206812566326, "train/model_loss_std": 0.9463611159233316, "train/model_opt_grad_norm": 105.00225060160567, "train/model_opt_grad_steps": 615.0, "train/model_opt_loss": 817.1550777958286, "train/model_opt_model_opt_grad_overflow": 0.008064516129032258, "train/model_opt_model_opt_grad_scale": 11.576990927419354, "train/policy_entropy_mag": 1.9447799738376372, "train/policy_entropy_max": 1.9447799738376372, "train/policy_entropy_mean": 1.9332114265811058, "train/policy_entropy_min": 1.8763386785022673, "train/policy_entropy_std": 0.005333418057548002, "train/policy_logprob_mag": 2.478697044234122, "train/policy_logprob_max": -1.448590652596566, "train/policy_logprob_mean": -1.9333281026732536, "train/policy_logprob_min": -2.478697044234122, "train/policy_logprob_std": 0.14820897440996864, "train/policy_randomness_mag": 0.9994192628129837, "train/policy_randomness_max": 0.9994192628129837, "train/policy_randomness_mean": 0.9934742008486102, "train/policy_randomness_min": 0.9642473930312742, "train/policy_randomness_std": 0.0027408348560716295, "train/post_ent_mag": 80.97643655346286, "train/post_ent_max": 80.97643655346286, "train/post_ent_mean": 80.871765505883, "train/post_ent_min": 80.78008005695958, "train/post_ent_std": 0.02929194743234304, "train/prior_ent_mag": 86.19368768507435, "train/prior_ent_max": 86.19368768507435, "train/prior_ent_mean": 86.06403504648516, "train/prior_ent_min": 85.84192103724325, "train/prior_ent_std": 0.05152376885375669, "train/rep_loss_mean": 1.110359638929367, "train/rep_loss_std": 0.008199017725019075, "train/reward_avg": 0.0010692696500148985, "train/reward_loss_mean": 0.19489296013489366, "train/reward_loss_std": 0.1773775561593764, "train/reward_max_data": 0.3728927082772697, "train/reward_max_pred": 0.0007621943950653076, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.18819233468703686, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.010276731322794, "train/reward_pred": 0.0007614249442403595, "train/reward_rate": 0.0008741809475806451, "train_stats/mean_log_entropy": 1.9248440522413988, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.04687630385160446, "report/cont_loss_std": 0.48010626435279846, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.457398891448975, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004273754078894854, "report/cont_pred": 0.995735228061676, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2677282392978668, "report/image_loss_std": 0.09072194248437881, "report/model_loss_mean": 0.9446908235549927, "report/model_loss_std": 0.4940880537033081, "report/post_ent_mag": 71.25676727294922, "report/post_ent_max": 71.25676727294922, "report/post_ent_mean": 71.04585266113281, "report/post_ent_min": 71.02262878417969, "report/post_ent_std": 0.03581263870000839, "report/prior_ent_mag": 78.71927642822266, "report/prior_ent_max": 78.71927642822266, "report/prior_ent_mean": 78.65218353271484, "report/prior_ent_min": 78.50567626953125, "report/prior_ent_std": 0.029279110953211784, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006880739238113165, "report/reward_loss_mean": 0.030086247250437737, "report/reward_loss_std": 0.03209059312939644, "report/reward_max_data": 0.0024999999441206455, "report/reward_max_pred": 0.0008947849273681641, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.030086245387792587, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0008926495211198926, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.025575030595064163, "eval/cont_loss_std": 0.3401539921760559, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.457398891448975, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.004273753613233566, "eval/cont_pred": 0.995735228061676, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24898996949195862, "eval/image_loss_std": 0.0817076563835144, "eval/model_loss_mean": 0.8795825839042664, "eval/model_loss_std": 0.35002249479293823, "eval/post_ent_mag": 71.25572204589844, "eval/post_ent_max": 71.25572204589844, "eval/post_ent_mean": 71.044921875, "eval/post_ent_min": 71.02196502685547, "eval/post_ent_std": 0.03321300074458122, "eval/prior_ent_mag": 78.7197265625, "eval/prior_ent_max": 78.7197265625, "eval/prior_ent_mean": 78.65646362304688, "eval/prior_ent_min": 78.50567626953125, "eval/prior_ent_std": 0.028252381831407547, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.005017562303692102, "eval/reward_loss_std": 1.5178392231973703e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0008947849273681641, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.005017562303692102, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0008926305454224348, "eval/reward_rate": 0.0, "replay/size": 790617.0, "replay/inserts": 19465.0, "replay/samples": 19968.0, "replay/insert_wait_avg": 1.2438186422093742e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.404991906422836e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2169453512013578e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 490.7542746067047, "timer/replay._sample_count": 19968.0, "timer/replay._sample_total": 1328.888943195343, "timer/replay._sample_frac": 2.7078499606759974, "timer/replay._sample_avg": 0.06655092864560011, "timer/replay._sample_min": 0.0002923011779785156, "timer/replay._sample_max": 0.10320782661437988, "timer/agent.policy_count": 3074.0, "timer/agent.policy_total": 19.316272974014282, "timer/agent.policy_frac": 0.0393603764113813, "timer/agent.policy_avg": 0.006283758286927223, "timer/agent.policy_min": 0.004990339279174805, "timer/agent.policy_max": 0.01034688949584961, "timer/env.step_count": 2496.0, "timer/env.step_total": 4.821452856063843, "timer/env.step_frac": 0.009824576382809508, "timer/env.step_avg": 0.0019316718173332703, "timer/env.step_min": 0.001077890396118164, "timer/env.step_max": 0.0072307586669921875, "timer/dataset_train_count": 1248.0, "timer/dataset_train_total": 0.09395647048950195, "timer/dataset_train_frac": 0.0001914531881862865, "timer/dataset_train_avg": 7.528563340504964e-05, "timer/dataset_train_min": 4.9591064453125e-05, "timer/dataset_train_max": 0.00019073486328125, "timer/agent.train_count": 1248.0, "timer/agent.train_total": 457.94441413879395, "timer/agent.train_frac": 0.9331440149060242, "timer/agent.train_avg": 0.36694263953429, "timer/agent.train_min": 0.34870338439941406, "timer/agent.train_max": 0.4694974422454834, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.406710147857666, "timer/agent.report_frac": 0.0008287449929674224, "timer/agent.report_avg": 0.203355073928833, "timer/agent.report_min": 0.20302963256835938, "timer/agent.report_max": 0.20368051528930664, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.504753112792969e-05, "timer/dataset_eval_frac": 7.141564106806226e-08, "timer/dataset_eval_avg": 3.504753112792969e-05, "timer/dataset_eval_min": 3.504753112792969e-05, "timer/dataset_eval_max": 3.504753112792969e-05, "fps": 40.68764322618563}
{"step": 22208, "episode/length": 268.0, "episode/score": 0.29787373952103735, "episode/reward_rate": 0.0037174721189591076}
{"step": 22368, "episode/length": 288.0, "episode/score": 0.12835004438579745, "episode/reward_rate": 0.0}
{"step": 22368, "episode/length": 288.0, "episode/score": 0.14094273691375747, "episode/reward_rate": 0.0}
{"step": 22368, "episode/length": 288.0, "episode/score": 0.12512056749505973, "episode/reward_rate": 0.0}
{"step": 22368, "episode/length": 288.0, "episode/score": 0.10083987246275683, "episode/reward_rate": 0.0}
{"step": 22368, "episode/length": 288.0, "episode/score": 0.19868132072087974, "episode/reward_rate": 0.0}
{"step": 22368, "episode/length": 288.0, "episode/score": 0.12963183767988085, "episode/reward_rate": 0.0}
{"step": 22576, "episode/length": 288.0, "episode/score": 0.1734038692404738, "episode/reward_rate": 0.0}
{"step": 24520, "episode/length": 288.0, "episode/score": 0.1431908925165999, "episode/reward_rate": 0.0}
{"step": 24680, "episode/length": 288.0, "episode/score": 0.09878769161286982, "episode/reward_rate": 0.0}
{"step": 24680, "episode/length": 288.0, "episode/score": 0.12432997604275897, "episode/reward_rate": 0.0}
{"step": 24680, "episode/length": 288.0, "episode/score": 0.18675402903988925, "episode/reward_rate": 0.0}
{"step": 24680, "episode/length": 288.0, "episode/score": 0.14803443263042482, "episode/reward_rate": 0.0}
{"step": 24680, "episode/length": 288.0, "episode/score": 0.10605375189220467, "episode/reward_rate": 0.0}
{"step": 24680, "episode/length": 288.0, "episode/score": 0.165277256385707, "episode/reward_rate": 0.0}
{"step": 24888, "episode/length": 288.0, "episode/score": 0.10704911213531432, "episode/reward_rate": 0.0}
{"step": 26832, "episode/length": 288.0, "episode/score": 0.13638903127127833, "episode/reward_rate": 0.0}
{"step": 26992, "episode/length": 288.0, "episode/score": 0.1133290270620364, "episode/reward_rate": 0.0}
{"step": 26992, "episode/length": 288.0, "episode/score": 0.10942832041257589, "episode/reward_rate": 0.0}
{"step": 26992, "episode/length": 288.0, "episode/score": 0.10109532855358339, "episode/reward_rate": 0.0}
{"step": 26992, "episode/length": 288.0, "episode/score": 0.10726507663571283, "episode/reward_rate": 0.0}
{"step": 26992, "episode/length": 288.0, "episode/score": 0.10859323534509713, "episode/reward_rate": 0.0}
{"step": 26992, "episode/length": 288.0, "episode/score": 0.07084107565594877, "episode/reward_rate": 0.0}
{"step": 27200, "episode/length": 288.0, "episode/score": 0.11085819540915054, "episode/reward_rate": 0.0}
{"step": 29144, "episode/length": 288.0, "episode/score": 0.18255288076136367, "episode/reward_rate": 0.0}
{"step": 29304, "episode/length": 288.0, "episode/score": 0.09096431539239802, "episode/reward_rate": 0.0}
{"step": 29304, "episode/length": 288.0, "episode/score": 0.14419901177905103, "episode/reward_rate": 0.0}
{"step": 29304, "episode/length": 288.0, "episode/score": 0.1328622799136383, "episode/reward_rate": 0.0}
{"step": 29304, "episode/length": 288.0, "episode/score": 0.19206459776955853, "episode/reward_rate": 0.0}
{"step": 29304, "episode/length": 288.0, "episode/score": 0.11680624257837735, "episode/reward_rate": 0.0}
{"step": 29304, "episode/length": 288.0, "episode/score": 0.1642326401547507, "episode/reward_rate": 0.0}
{"step": 29512, "episode/length": 288.0, "episode/score": 0.1913357543347729, "episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 31456, "episode/length": 288.0, "episode/score": 0.06814474449515728, "episode/reward_rate": 0.0}
{"step": 31616, "episode/length": 288.0, "episode/score": 0.14173922339409728, "episode/reward_rate": 0.0}
{"step": 31616, "episode/length": 288.0, "episode/score": 0.08680236736063307, "episode/reward_rate": 0.0}
{"step": 31616, "episode/length": 288.0, "episode/score": 0.10422727146396937, "episode/reward_rate": 0.0}
{"step": 31616, "episode/length": 288.0, "episode/score": 0.1506306720257271, "episode/reward_rate": 0.0}
{"step": 31616, "episode/length": 288.0, "episode/score": 0.11990964610754418, "episode/reward_rate": 0.0}
{"step": 31616, "episode/length": 288.0, "episode/score": 0.11654610169250645, "episode/reward_rate": 0.0}
{"step": 31824, "episode/length": 288.0, "episode/score": 0.09093798858589253, "episode/reward_rate": 0.0}
{"step": 33768, "episode/length": 288.0, "episode/score": 0.1373998687436142, "episode/reward_rate": 0.0}
{"step": 33768, "episode/length": 268.0, "episode/score": 0.23096453767402636, "episode/reward_rate": 0.0037174721189591076}
{"step": 33928, "episode/length": 288.0, "episode/score": 0.10378998373494142, "episode/reward_rate": 0.0}
{"step": 33928, "episode/length": 288.0, "episode/score": 0.12291103945779014, "episode/reward_rate": 0.0}
{"step": 33928, "episode/length": 288.0, "episode/score": 0.18478116415917611, "episode/reward_rate": 0.0}
{"step": 33928, "episode/length": 288.0, "episode/score": 0.13988415164737944, "episode/reward_rate": 0.0}
{"step": 33928, "episode/length": 288.0, "episode/score": 0.10795741840911433, "episode/reward_rate": 0.0}
{"step": 34136, "episode/length": 288.0, "episode/score": 0.07410656118918268, "episode/reward_rate": 0.0}
